
PREFACE 
The School of Applied Sciences and Technology, Shahjalal University of Science and 
Technology, Sylhet, organized a Conference on Engineering Education, Research and 
Innovation (CERIE), which held on January 11-13, 2011. The organization of the 
conference was a result of whole-hearted and devoted labor of the teachers, officers 
and employees of all the departments under the school. This conference provided a 
platform for exchanging ideas, knowledge, experiences and research works in various 
areas of engineering and technology among academicians, scientists, technologists 
and engineers. 
 
Around 200 research papers were presented in different sessions. The subject-matter 
of the papers cover vast area of engineering research and education including 
computer science and engineering, electrical and electronics engineering, 
telecommunications, industrial management, architecture, different branches of civil, 
environmental and chemical engineering. Besides delegates from different institutions 
in the country, representatives from different education and research institutions from 
Australia, Japan, Korea and UAE participated in the conference with technical papers.  
 
Within the program-schedule of the conference, two round table discussions were 
arranged. The discussion brought forth fruitful suggestions for improving engineering 
education and research in the country. 
 
The conference closed on January 13, 2011 successfully with high ambition and 
determination for organizing it after every two years with massive participation from 
home and abroad. 
 
With the publication of the papers presented in the proceedings, the organizing 
committee is finally reaching the ‘Finish’. We strongly believe that through the 
proceedings, the readers will have access to recent development in engineering 
research and education.  
 
We would like to thank for their spirit, enthusiasm and efforts, with which they 
brought the publication of the proceedings to a successful end. We are also indebted 
to sponsors for their help in the conference. 
 
CERIE will be held every year regularly and proceedings will appear with updated 
information in various fields of engineering.  
 
   
(Dr. Mushtaq Ahmed) 
Secretary            
Organizing Committee 
CERIE 2011 
 
13 January 2011 
 Sylhet, Bangladesh 
(Professor Dr. Mohammad 
Iqbal) 
Convener  
Organizing Committee  
CERIE 2011  
 
Chief Patron: 
Prof. Dr. Md. Saleh Uddin, Vice Chancellor, 
Shahjalal University of Science & Technology, 
Sylhet, Bangladesh 
 
Advisory Committee: 
Vice-Chancellor, BUET, Dhaka, Bangladesh 
Vice-Chancellor, RUET, Rajshahi, Bangladesh 
Vice-Chancellor, CUET, Chittagong, Bangladesh 
Chancellor, KUET, Khulna, Bangladesh 
Vice-Chancellor, DUET, Dhaka, Bangladesh 
Vice-chancellor, IUT, Gazipur, Bangladesh 
Vice-Chancellor, Ahsanullah University of Science & 
Technology, Dhaka, Bangladesh  
Prof. Dr. Jamilur Reza Choudhury, Former Vice- Chancellor, 
BRAC University, Dhaka, Bangladesh 
Prof. Dr. M. S. J. Hashmi, School of Mechanical and 
Manufacturing Engineering, Dublin City University, Dublin, 
Ireland.   
Prof. Dr. Iqbal Mahmud (Professor Emeritus), Department 
of Chemical Engineering BUET, Dhaka, Bangladesh 
Professor A.F.M. Anwarul Hoque, Head, Dept. of IPE, 
Ahsanullah University of Science & Technology, Dhaka, 
Bangladesh  
Prof. Dr. Feroz Ahmed, Dept. of Civil Engineering, BUET, 
Dhaka, Bangladesh 
Prof. Dr. Ijaz Hossain, Department of Chemical Engineering, 
BUET, Dhaka, Bangladesh 
Prof. Dr. A. K. M. A. Quader, Dept. of Chemical Engineering, 
BUET, Dhaka, Bangladesh 
Prof. Dr. Dil Afroza Begum, Dept. of Chemical Engineering, 
BUET, Dhaka, Bangladesh 
Prof. Dr. M Mahbubur Rahman, Dept. of PMRE, BUET,  
Dhaka, Bangladesh 
Prof. Dr. Mohammad Tamim, Professor, Department of 
PMRE, BUET, Dhaka, Bangladesh 
Prof. Dr. M. Ashraf Ali, Dept. of Civil E Engineering, BUET, 
Dhaka, Bangladesh 
Prof. Dr. Kutubuddin, Dept. of IEM, KUET, Khulna, 
Bangladesh 
Prof. Dr. Md. Nurul Islam, Dept. of Mechanical Engineering, 
RUET, Rajshahi, Bangladesh 
Prof. Dr. Md. Ahsan Akhter Hasin, Dept. of IPE, BUET, 
Dhaka, Bangladesh 
Prof. Dr. S. M. Nazrul Islam, Dept. of Mechanical 
Engineering, BUET, Dhaka,  Bangladesh 
Prof. Dr. M.A. Rashid Sarker, Dept. of Mechanical 
Engineering, BUET, Dhaka, Bangladesh 
Prof. Dr. Kutub Uddin, Dept. of IEM, KUET, Khulna, 
Bangladesh.  
Prof. Khaleda Rashid, Professor, Department of 
Architecture, BUET, Dhaka, Bangladesh 
Prof. Md. Khairul Enam, Professor, Department of 
Architecture, BUET, Dhaka, Bangladesh 
 
Prof. Dr. Kazi Azizul Mowla, Professor, Department of 
Architecture, BUET, Dhaka, Bangladesh  
Prof. Dr. Md. Shahidul Ameen, Professor, Department of 
Architecture, BUET, Dhaka, Bangladesh  
Prof. Dr. Md. Nazrul Islam, Professor, Department of Food 
Technology & Rural Industries, Bangladesh Agricultural 
University, Mymensingh, Bangladesh 
Prof. Dr. Md. Burhan Uddin, Professor, Department of 
Food Technology & Rural Industries, Bangladesh 
Agricultural University, Mymensingh, Bangladesh  
Engr. Mainuddin Ahmed, Director, House Building 
Research Institute, Dhaka, Bangladesh 
Mr. Mukul Jyoti Dutta, Director, Bangladesh Tea Research 
Institute, Srimongal, Bangladesh 
Dr. Mainuddin Ahmed, Chief Scientific Officer, Bangladesh 
Tea Research Institute, Srimongal, Bangladesh 
Prof. Dr. M Kaykobad, Dept. of CSE, BUET, Dhaka, 
Bangladesh 
Prof. Dr. M Zahidur Rahman, Department of CSE, JU, 
Dhaka, Bangladesh 
Prof. Dr. M. M. A. Hashem, Department of CSE, KUET, 
Khulna 
Prof. Dr. Md. Khademul Islam, Department of CSE, RU, 
Rajshahi, Bangladesh 
 
 
 
Organizing Committee: 
Prof. Dr. Mohammad Iqbal, Professor, Dept. of IPE, SUST 
(Convener) 
Dr. Mushtaq Ahmed, Associate Professor, Dept. of CEE, 
SUST (Secretary) 
Dr. M. Jasim Uddin, Associate Professor, Dept. of CEP, SUST 
(Joint Secretary) 
Dr. Md. Mozammel Hoque, Asstt. Professor, Dept. of FET, 
SUST (Joint Secretary) 
Dr. M. Reza Selim, Asstt. Professor, Dept. of CSE, SUST 
(Treasurer) 
Prof. Dr. Muhammad Zafar Iqbal, Dept. of CSE, SUST 
Prof. Dr. Md. Akhtarul Islam, Professor, Dept. of CEP, SUST 
Prof. Dr. Md. Aktarul Islam Chowdhury, Dept. of CEE, SUST 
Prof. Dr. Md. Jahir Bin Alam, Dept. of CEE, SUST 
Dr. Md. Maksudur Rahman Khan, Associate Professor, 
Dept. of CEP, SUST  
Dr. A. M. Mohammad Mukaddes, Associate Professor, 
Dept. of IPE, SUST 
Dr. Md. Ariful Islam, Associate Professor, Dept. of IPE, SUST 
Mr. Mohammad Alamgir, Asstt. Professor, Dept. of CSE, 
SUST 
Mr. Mohammed Maasum, Asstt. Professor, Dept. of CSE, 
SUST    
Eng. Salma Akhter, Asstt. Professor, Dept. of CEP, SUST 
Mr. Md. Mustafizur Rahman, Asstt. Professor, Dept. of 
ARC, SUST 
Mr. Md. Jakaria, Asstt. Professor, Dept. of PGE, SUST 
Content 
SL No. Topic Page No. 
A. Keynote papers 
1.  Designing Engineering Education For The 21st Century 1-7 
2.  3r Options In Industries 8-16 
3.  Rational Use Of Waste Biomass Energy: Potential Of Carbon Sink Development 17-28 
4.  Thermomechanically Treated Advanced Structural Steels To Improve The Earthquake Resistance Of 
Buildings  
29-41 
5.  Tea Industry Of Bangladesh – Past Present And Future 42-59 
B. Civil Engineering & Architecture  
1.  A Study Of The Internal Defects Of Various Types Of Construction Materials By Using Direct Film 
Neutron  Radiography Technique  
60-66 
2.  A Gis Based Study On Urban Rainwater Harvesting Option Using Roof Catchment  67-71 
3.  A Low Cost Temperature Control Unit For Wastewater Respirometer 72-73 
4.  An Observation On The Acoustical Environments Of Auditoriums In Dhaka 74-79 
5.  Building Construction Workers’ Quality And Safety: A Case Study On Sylhet City 80-83 
6.  Chloride Penetration Resistance Of Fly Ash Cement Mortar 84-89 
7.  Challenges And Opportunities Of Eco-Toilet For Low Income Communities Of Sylhet City 90-94 
8.  Climate Change And Climate Refugee Nexus In Bangladesh Context 95-100 
9.  Crisis In The Built Environment Of Dhaka: An Overview 101-106 
10.  Earthquake Vulnarability Assessment Of Schools And Colleges Of Sylhet, A North Eastern City Of 
Bangladesh 
107-112 
11.  Eco‐Housing: Material Technologies For A Sustainable Built Environment 113-120 
12.  Effect Of Soft Storey In Reinforced Concrete Frame Structures  121-126 
13.  Effect Of Finness Modulus Of Sand On Concrerte Properties 127-131  
14.  Effect Of Aggregate Grading On Concrete Compressive Strength  132-136 
15.  Fire Hazard Scenario In Chittagong: A Case Study 137-141 
16.  Informal Sector Water Utility Management: Potential Urban-Slum Upgradation Policies In Bangladesh 142-146 
17.  Integration Of Performance Based Modeling Techniques With Building Design Method 
(Industry/Factory) Considering Energy Efficiency In Bangladesh 
147-152 
18.  Learning From Islamic Heritage: An Assessment Of Climate Change Impacts On Mughal Buildings In 
Dhaka 
153-159 
19.  Modeling Groundwater Flow And Advective Transport Of Salinity In The Unconfined Aquifer Of 
Southwest Bangladesh 
160-165 
20.  Municipal Wastewater Treatment And Heavy Metal Removal By Constructed Wetlands 166-171 
21.  Numerical Investigation Of The Behavior Of Retrofitted Flexural Cracked Beam With External Plate 
Bonding  
172-177 
22.  Rethinking The Form Of Sustainable Cyclone Shelter  178-185 
23.  Renewable Energy Systems For Residential Buildings In New Satellite Towns Of Dhaka: Barriers And 
Probable Solutions 
186-192  
24.  Risk Assessment Of Masonry Buildings In Heritage Area: A Case Study For The Older Part Of Dhaka 
City 
193-199 
25.  Seismic Risk Analysis For The Schools Of Sylhet City, Bangladesh 200-205 
26.  Strengthening Of Square Rc Column Using Low-Cost Square Ferrocement Jacketing Technique 206-211 
27.  Trand Of Urban Heat Island (UHI) In Sylhet City, Bangladesh 212-219 
28.  Ultimate Load Capacity Of Axially Loaded Vertical Piles In Mid-Southern And Mid-Northern Deposits 
Of Bangladesh 
220-224 
29.  Urban Heat Island (UHI) Drift In Rajshahi Metropolitan City 225-232 
C. Chemical Engineering and Polymer Science   
1.  A Composite Photocatalyst For Methylene Blue Degradation Under Visible Light Irradiation 233-238 
2.  A Multivariate Analysis Of Biodiesel Production From The Lipid Of Wastewater Sludge 239-244 
3.  Biogas From Municipal Solid Waste 245-250 
4.  Clinical Waste Management In Sylhet City 251-256 
5.  Comperative Study Of Biodiesel Preparation Methods  257-262 
6.  CRISPR May Give Important Informaton Which Can Be Beneficial In Molecular Biology And 
Biotechnology Study. 
263-267 
7.  Determination Of Mass Transfer Coefficient: A Laboratory Demonstration  268-272 
8.  Development Of Acidic Mesoporous Heterogeneous Catalyst For The Biodiesel Production From The 
Lipid Of Wastewater Sludge 
273-278 
9.  Dissimilar Behavior Of Ag Modified Pt And Pd Cathodes On The Reduction Mechanism Of No 3
- At H+ 
–Conducting Solid Polymer Electrolyte Reactor  
279-280 
10.  Double Chamber Microbial Fuel Cell (MFC) For Electricity Generation  281-287 
11.  Efficient Hydrogen Peroxide Decomposition On Bimetallic Pt–Pd Surface  288-293 
12.  Electrocatalytic No2
- Reduction Using Gc-Pt Electrode 294-299 
13.  Entrepreneurial Management: An International Study 300-308 
14.  Fabrication Of 2D Plasmonic Super Lattice Of Silver Nanocubes For Molecular Sensing Using Surface 
Enhanced Raman Spectroscopy.  
309-310 
15.  Formation Of 1,1,1 Trifluoroethane (143a) In HCFC-22 Reactor 311-315 
16.  Influence Of Weather Parameters On Red Spider Mite- A Major Pest Of Tea In Bangladesh  316-320 
17.  Laser Action In Polyfluorene And Fluorene-Based Co-Polymers Microcontroller Based Automatic 
Liquid Level Control Modeling  
321-321 
2
Nanoporous Polystyrene 
Composites: A Discussion 
2
Jute Fiber 
D. Computer Science & Engineering  
1.  An Effort To Improve Software Teaching In Engineering Education 400-405 
2.  Design A Simple Data Structure Using Multilevel Stack 406-408 
3.  Development Of A Software For Calculting The Thermodymic And Transport Properties Of Libr 
Aqueous Solution 
409-412 
4.  E-Court In Bangladesh: An Empirical Approach 413-417 
5.  Interface Design Of A Clients-Server Distributed System 418-423 
6.  Packing Non-Identical Circles In A Smallest Circular Container By Modified Monotonic Basin Hopping 
Heuristic Approach 
424-434 
7.  Parallel Computing Using Remote Method Invocation 435-438 
8.  Performance Evaluation Of Kalman Filter In Accoustic Echo Cancellation  439-444 
9.  Importance Of Physics Education For The Undergraduate Medical Students Of Bangladesh  445-447 
10.  Visual-MiR: Visualization System Of Precursor MicroRNA 448-456 
E. Electrical & Electronic Engineering  
1.1.  20 kWp Grid Connected Solar Power Station: Monitoring And Assesment  457-460 
2.  A CMOS IC Using Nano-Power Electronic Circuits For Life-Saving Applications In Bangladesh 461-465 
3.  A Comparative Study Of Electrical, Hall Effect And Magnetic Properties OF Co Thin Films Deposited 
On GaAs(001), Si(001) And Glass Substrates 
466-470 
4.  A Recurrent Neural Network Based Back Emf Estimator For Position Sensorless Control Of Ipm 
Synchronous Motor Drive 
471-476 
5.  An AES Processor On A Reconfigurable Hardware 477-482 
18.  Performance Of The Two-Chamber Microbial Fuel Cell 328-333 
19.  Photocatalytic Activities Of Tio  Nanoparticles Synthesized Using Sol-Gel Method With Presence Of 334-339 
20.  Photocatalytic Degradation Of Reactive Dye In Batch And Continuous Modes 340-340 
21.  Preparation Of Biodiesel From Waste Cook Oil By Using Three Step Method 341-346 
22.  Recovery Of Chromium From Tannery Effluent 347-355 
23.  Rule Of Mixture For Predicting The Elastic Modulus Of Polymer-Fiber And Polymer-Fiber-Particle 356-361 
24.  Studies On The Properties Of Epoxy-Based Polymer Modified Mortar  362-367 
25.  Tailoring Mgh  With Mg-Nb-O Towards Hydrogen Storage 368-368 
26.  The Effect Of Percentage Of Hollow Lumen On The Mechanical Properties Of Bangla White Grade B 369-388 
27.  Use Of Waste Plastics With Bitumen For Road Construction 389-399 
6.  Analysis Of The Radiation Properties Of Halfwavelength J -Pole Antenna Arrays  483-485 
7.  BI-EDF-BASED Optical Amplification And Multiwavelength Laser  486-490 
8.  Charge Control Studies  In InxGa1-xN/InN/ InxGa1-xN-Based Double Channel High Electron Mobility 
Transistors (DHEMTs)  
491-494 
9.  Design & Implementation Of Up -Converter On Fpga Hardware With OFDM (Transmitter & Receiver) 
Signal 
495-499 
10.  Design And Fabrication Of A Digital Power Factor Meter  500-503 
11.  Design And Implementation Of A Microcontroller Based Elevator Control Systems  504-507 
12.  Design And Implementation Of A Microcontroller Based Liquid Level Control System  508-511 
13.  Design And Implementation Of A Plc Based Screw Air Compressor For Industrial Applications  512-516 
14.  Design And Implementation Of A Remote Sensing Electricity Supply Control For Industrial 
Applications 
517-519 
15.  Design And Implementation Of An Intellectual Security System For The World Wide Appearance Of 
Owner 
520-524 
16.  Design And Manufacturing Of A Low Cost Synchronous Motor -Generator For Electrical Machine 
Laboratory 
525-529 
17.  Design And Simulation Of A Multi -Language Digital Clock By Switching System  530-534 
18.  Design And Simulation Of Automatic Load Control With Human Counting System Of A Space  535-539 
19.  Design Of AlAs/GaAs/Ge Lattice Matched Multijunction Solar Cells  540-543 
20.  Design Of VLSI Pad Frame Towards A Low Power I/O Architecture With An Efficient Floorplanning  544-548 
21.  Design, Simulation And Performance Analysis Of High Voltage Multistage Pulse Forming Network  549-552 
22.  Designing Birefringence Of Index -Guiding Photonic Crystal Fibers  553-557 
23.  Designing of Armature Winding Using Programming Technique Instead of Using Conventional Method  558-561 
24.  Development Of An Embedded System For Low Power Message Display  562-566 
25.  Direct Torque Control Of 4 -Switch 3-Phase Voltage Source Inverter Fed Induction Motor Drive  567-572 
26.  Economic Impact Of Installing Solar Concentrator Technology In Rural Bangladesh  573-577 
27.  Electrical, Hall Effect And Optical Properties Of Undoped Co Thin Films  578-583 
28.  Experimental Analysis on Wireless Energy Transfer via Strongly Coupled Magnetic Resonances  584-589 
29.  Fast Inter Mode Decision Algorithm For H.264/AVC Video Standard  590-595 
30.  Growth And Characterization Of MOVPE In xGa1-xN (x ~ 0.4) 596-600 
31.  Impedance Matched Compact Zigzag Inverted -F Antenna For Wi -Fi Operation In A Laptop  601-605 
32.  Implementation And Results Of A Microcontroller Based Duobinary Encoder Circuit For 
Communication System  
606-611 
33.  Implementation Of Artificial Intelligence In Embedded System For Automatic Voltage Regulator  612-616 
34.  Implementation Of Boost Converter For Low Power Application  617-621 
35.  Implementation Of  Pid Control And Pwm Technique In Embedded System For Ripple Free And 
Stabilized Sine Wave Inverter  
622-627 
36.  Linearization Of Voltage -Controlled Oscillator By Microcontroller Based Pll  Frequency Synthesizer  628-631 
37.  MAGIC IN VLSI A Precise Demonstration on MAGIC towards VLSI Layout Designing  632-637 
38.  Microcontroller Based Automatic liquid Level Control Modeling  638-647 
39.  Modified Intra_4×4 Prediction Mode Scheme For H.264/AVC Video Coding 648-651 
40.  Performance Analysis Of A Simple Power Quality Conditioner For Mitigation Of Harmonics  652-657 
41.  Prospect Of Grid Connected Solar PV  Power Plant In Bangladesh  658-662 
42.  Radiation From A Large Circular Loop Antenna For A Series Of Fourier H armonic Current Distribution  663-667 
43.  Recurrent Neural Network Based Cost Effective Four Switch Three Phase Inverter Fed Synchronous 
Reluctance Motor Drive  
668-673 
44.  Red Light Violation Monitoring And Reporting Using Microcontroller Controlled Wireless 
Communication 
674-678 
45.  Reduction of PAPR In OFDM Using SLM For Different Route Number  679-683 
46.  Share Market Price Prediction Using Artificial Neural Network (ANN)  684-690 
47.  Smart Room Control Unit Using Standard RC5 Remote Code  691-696 
49.  Steady State Analysis Of A C CI-FED Induction Motor Drive With Field Orientation Control  703-708 
50.  Structural Properties And Temperature Dependence Of Resistivity Of Pure Co  Material Deposited 709-713 
48.  Parameter Measurement of Circular Shaped Cables Using Image Processing Techniques 697-702 
Co/Si(001) and Co/glass Thin Films 
51.  Transciever Circuits For Pulse Based Ultra Wideband  714-718 
52.  Unified Power Quality Conditioner (UPQC): Development Of Hardware Using Facts Technology  719-724 
53.  Variation Of Nonlinear Refractive Index And Nonlinear Absorption Co -Efficient Of LiNb03 Crystal Due 
To Varying Wavelengths 
725-729 
54.  VLSI Design Of An Ultra-Low-Power Functional Chip Using Mirror -Amplifier For Precision Sensor 
Applications 
730-734 
F. Industrial Production Engineering & Mechanical Engineering  
1.  A Model On Industrial Information System (Iis)  735-741 
2.  Application Of Fixed Time Period Model For Optimizing Inventory Level: A Case Study In A 
Pharmaceutical Company 
742-752 
3.  Change Over Time Reduction In Garments Industry Through Smed Methodology.  753-760 
4.  Construction And Visualization Of A Digital Factory Using 3d Modeling Software  761-765 
5.  Deicing Technology For Modern Military And Commercial Aircraft Wing Surfaces  766-770 
6.  Design, Construction And Testing Of An Earth Tube Heat Exchanger (Ethe)  771-774 
7.  Development Of Simulation Software For Designing Duct Of Air Conditioning System  775-778 
8.  Effect Of EGR Ratio To Control Particulate Matter Emission From Diesel Engine Combustion By Using 
High –Speed Combustion Model. 
779-779 
9.  Effect Of Micron Size Particle Content OnTribological Behaviours Of Polymer Matrix Composites  780-785 
10.  Ergonomics And The Prevention Of Musculoskeletal  Strain And Back Injuries.  786-790 
11.  Experimental Analysis On The Heat Transfer Performance Of An Ammonia -Charged Pulsating Heat 
Pipe 
791-796 
12.  Flexible Workstation Design 797-806 
13.  Optimization Of Supply Chain Inventory From Customer Service Level Perspective  807-815 
14.  Problems And Prospects Of Special Economic Zone In Sylhet  816-821 
15.  Production Scheduling In A Garments Manufacturing Company: A Case Study  822-825 
16.  Productivity Improvement Through Cellular Manufacturing In Rmg:  Bangladesh Perspective  826-832 
17.  QFD Approach To Study Customer Requirements, Critical Supply Chain Factors And A System For 
Supply Chain Performance Measure 
833-843 
18.  Redesigning Cycle Rickshaw Wheel To Minimize  Accident Probability And Severity  844-849 
19.  Software Based Evaluation Of Overall Line Effectiveness (O LE) Of A Garment’s Industry  850-858 
20.  Tensile And Electrical Properties Of Wood Saw Dust Reinforced Polymer Matrix Composites  859-864 
21.  The Trends Of Environment Friendly Product Design In Bangladesh  865-869 
G. Information Technology  
1.  An Effective Bayesian Personalized E -Mail Spam Filter Using Word  Tokenization Method  870-874 
2.  An Exploratory Study Of Vision 2021: Status And Challenges  875-880 
3.  Cost Benefit Oriented Analysis For Designing  Optimum Quality Assurance Practices  881-892 
4.  Development Of A Voice Controlled Robotic Arm  893-898 
5.  Dispersion And Dispersion Slope Compensation Using  Linearly Chirped Apodized Fiber Bragg Grating  899-902 
6.  Introducing Green Ict For Digital Bangladesh  903-907 
7.  Mathematical Modeling Of Blood Flow 908-913 
8.  Mathematical Modeling Of Eye Movement  914-919 
9.  Methodology For Cost Effective Web Testing For Ecommerce Web Applications  920-925 
10.  Microwave Analysis Of A MEMS Switch 926-930 
12.  Pattern Optimization Of A Linear Dipole Antenna Through Improving Directivity And Reducing Side 
Lobes 
937-942 
H. Petroleum & Mining Engineering  
1.  A Review Of The Numerical Solutions Of Dimensionless Radial Flow Diffusivity Equation Using 
Laplace Transforms 
943-951 
2.  An Overview Of Geology, Hydrogeology, And Open  Pit Mining Perspective Of The Phulbari 
Gondwana Coal Deposit, Nw Bangladesh  
952-958 
3.  Coal Bed Methane (Cbm) Project, How Far To Minimize The Energy Crisis Of Bangladesh  959-964 
11.  Population Based Heuristic Approach for Packing Identical Circles in a Minimized Circular Container     931-936 
4.  Commonly Used Reserve Estimation Methodology For Gas Reservoirs  965-969 
5.  Comparable Analysis Of Engineering Properties Between Crushed Hardrock Dust Of Maddhyapara 
Granite Mine, Dinajpur And Natural Sand  
970-973 
6.  Engineering Classification Of Shari Ghat River Bed Sand And Prospect Of It’s Utilization In Different 
Construction Sectors 
974-979 
7.  Flowing Gas Material Balance: A Case Study Of Titas Gas Field  980-984 
8.  Formation Water Resistivity Prediction Of Titas Gas Field Using Self -Potential Log Data, Bangladesh  985-988 
9.  Modeling And Analysing Pressure Buildup Data Of Kailastilla Gas Field (Well No. Ktl -01 And Ktl -02) 989-994 
10.  Modern Approach To Estimation Of Gas Reserve With Dynamic Reservoir Simulation. - A Case Study 
Of Narshingdi Gas Field.  
995-1003 
11.  Natural Gas Pipe Line Design From Ashugonj  Valve Station#3 To Zia Fertilizer Company Limited And 
In An Arbitrary Power Plant  
1004-1010 
12.  Numerical Investigation Of Particle Properties On  Coal Gasification Under Co2 Atmosphere  1011-1016 
13.  Pressure Data Analysis And Reservoir Parameter Estimation O f  Kailastilla Gas Field (Well No. Ktl -01& 
Ktl-02) 
1017-1023 
14.  Reservoir Characterization Using Geostatistical Method  1024-1029 
15.  Structural Analysis Of Fenchugonj Gas Field  1030-1033 
16.  The Orientation Of Dauki  Fault: An Approximation Using The 2d Finite Element Modeling  1034-1043 
17.  Underground Or Open Pit Mining Method – An Unresolved Debate Delaying Coal Mining In 
Bangladesh 
1044-1050 
I. Tele Communication Engineering 
1.  Design And Simulation Of Four Bands Microstrip Patch Antenna Array For Multiband Applications  1051-1054 
2.  Free-Space Optical Communication System Under Strong Turbulence With Q -Ary Pulse -Position 
Modulation 
1055-1058 
3.  Intelligent Traffic Control By Cctv, Pic16f877a Microcontroller And Ir Ro ad Sensor  1059-1062 
4.  Interference Reduction And Capacity Enhancement Using Smart Antennas In Cdma Networks  1063-1067 
5.  Multiband Strip Antenna For 2.3/2.5/5.5 Ghz Wimax And 2.4 Ghz Wlan Operations  1068-1073 
6.  Performance Analysis Of Wifi  Network For Indoor Environment  1074-1077 
7.  Performance Of Mimo -Ofdm Over Flat Fading Channel Using Convolution Coding  1078-1082 
8.  The Infrastructural Advancement Of E -Learning In Bangladesh: A Case Study Of Present Status And 
Future Expectations  
1083-1086 
1.  Comparative Study Of Hazards By Floods And Cyclones In Bangladesh  1087-1090 
2.  Development Of A Household Compost Generation System With Organic Household Waste  1091-1094 
3.  Heavy Metal Removal Using Grafted Acrylic Acid  For The Water Coming From Abandoned Mines  1095-1098 
4.  Impact On Sustainability Of Hail Haor By Integrated Water Managemnt Activiies  1099-1104 
5.  Importance And Scope Of Conservation Of Wetland To  Protect Environmental Degradation  1105-1109 
6.  Prediction Of Future Temperature In North -Eastern Region Of Bangladesh By Using Historical Data  1110-1113 
7.  Resource Recovery From Water Treatment Sludge  1114-1118 
8.  Selection Of Potential Strain For The Production Of Citric Acid By  Solid State Bioconversion Using Oil 
Palm Empty Fruit Bunches  
1119-1124 
9.  Techno-Economical Evaluation Of Water Filtration System By Using Local Ingredients  1125-1128 
10.  Vulnerability Analysis Of Bangladesh Due To Multiple Natural Hazards Using Gis  Technique  1129-1134 
 
J. Water Resources & Environmental Engineering 
Simulation of the Breakthrough Curve for the Removal of Methylene Blue from Wastewater by Activated 
Carbon of Bombax Ceiba11.
1135-1138
Designing Engineering Education for the 21st Century 
Dr. A.M.M. Safiullah 
Professor of Civil Engineering, BUET 
Introduction 
Engineering is an art and science of using natural resources for the benefit of mankind. 
Human civilization has now reached a stage where rapid change has become the  principal 
constant in the economic and social life of societies. Behind these changes is the colossal 
growth of knowledge that is taking place every day replacing old ideas and practices. 
Universities as knowledge providers are finding it hard to restrict them to typical teaching 
culture for their students to be useful in the society. A present day engineer while solving a 
problem may find a number of solutions to it. Selection of the most appropriate one would 
usually require knowledge from other disciplines such as commerce, economics, sociology, 
psychology, political science, management etc. Currently these are included in the 
engineering education in a rudimentary form. Perhaps this is the reason why our engineers 
are not proactive or taking the leadership in the development work, the country needs. This 
may also explain why the engineers are not in the position of leadership but have to work 
under people who are inferior to them intellectually or otherwise. Their work though 
essentially consumed by the society, is not recognized. Our engineers are too much 
engrossed in the technical details of engineering work thrust on them and have little time to 
advocate their story to the people. Our engineering education is biased heavily towards 
development of technical skill. Perhaps this is built on the maxim that:  
 
“If a doctor fails then a patient dies but if an engineer fails then it 
becomes a catastrophe and many people die”. 
 
Because of this bias, the present culture of our education gives more emphasis on technical 
skill rather than more indulgence on social issues. The engineer is a part of the society in 
which he is serving. Failure of a project is not necessarily due to its technical contents but 
may be due to social issues neglected by the designers. We are in an era when we have to 
look critically how we are educating our engineers to meet the challenges of development. 
We need to change the culture of our engineering education.  
 
Culture of Engineering Education 
Culture is defined in the dictionary as “advanced development of human powers: 
development of body, mind, and spirit by training and experience ”. It is also defined as 
“evidence of intellectual development (of arts, science etc.) in human society ” (Hornby, et. 
al., 1963). To a sociologist, culture is how a society behaves and works. Therefore, culture of 
engineering education implies how engineers are trained in a society to accomplish their task. 
Presently the engineering education focuses on the excellence of the technical content of 
knowledge. However, it has been now recognized that technical excellence in the traditional 
disciplines on its own is not enough, and it will not be able to meet the needs of the 
engineering graduates themselves and the expectations of the employers and the community 
at large. Ignoring this fact will continue to lead to a declining role for engineers in project 
Page 1
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
involvement and decision making and will reduce the role of engineers relative to non-
engineering business managers, creative designers, administrators and politicians.  
 
Constraints to Engineering Education 
There is a contradictory situation prevailing regarding who should pay for higher education 
including engineering. Society demands more and more on the quality and versatility of its 
professionals. Enhancing education quality means more expenditure. Unfortunately, there is 
a worldwide trend for a decrease in funding and an apparent lack of commitment by society 
for higher education. Universities and other knowledge providers find themselves under 
increasing pressure to do more with less. Never before was there a need to work smarter, as 
well as working harder. This is also reflected by our government attitude. In 2003 one of our 
Education Ministers in a meeting mentioned that: 
 
“The Govt. would cut spending for public universities in phases to reduce the tax 
payers burden.” – The Daily Star, April 30, 2003. 
 
It is not known if he included technical universities in the above categories especially when 
the Government upgraded four Bangladesh Institutes of Technologies (BITs) to the status of 
university. If it is so then we have to rethink about effectiveness of the decision. Education, 
once perceived as an investment in the future of the nation, is now seen as a cost. 
 
One eminent educationist suggested ‘If you think education is expensive, try ignorance ’. 
Nevertheless, user pays principles now apply in many countries, as government seeks to 
share the cost of education with other stakeholders: business, society and students 
themselves. Perhaps this has given a surge of growth of Private Universities mostly within 
Dhaka city. Unfortunately, very few of these universities offer courses in engineering except 
related to computer and information technology. May be this is because of large investment 
required in setting up workshops and laboratories for the engineering programs and ease with 
which other programs can be run. Most of these universities run courses with part-time 
teachers from public universities. Student intake is virtually restricted by the financial 
capability of their parents. Even with high course fee, there is a doubt about the effectiveness 
of the programs run by these private universities. Concern about these universities is raised 
by many and it is said that: 
 
“Many private universities do not have their own campus and sufficient 
teaching staff to ensure quality of education .” 
 
The quality of teachers makes a great difference in the quality of engineering education. In a 
country where political rivalry supersede rational judgment, involvement of teachers and 
students in political grouping results in indiscipline and violence with a devastating effect on 
the peaceful academic atmosphere for learning and program schedule. Teachers teaching 
style, knowledge background, and understanding of the Society, all affect the student’s 
maturity and understanding of the world in which they live. The saying that, “ Any institution 
is as good as its teachers” seems to be forgotten by us. We should have more transparency 
Page 2
and fairness in selecting teachers without government interference. This includes selection of 
institution heads based on proven honesty and quality rather than their political bias. 
 
Availability of physical facilities in most engineering institutions is very poor by world 
standard and perhaps lacking in private universities.  
 
Basis for Engineering Education 
Table 1 show what are the expectations of an engineering graduate, his employer and the 
society (after Moore, 1974). To fulfill the expectations of the society and the employer an 
engineering graduate has to be a little short of a superman, but his own expectations may fall 
short due to the compensation package he is likely to receive in a poor society. This is the 
reality and his education should gracefully give him the message. At the same time, the 
Society should be told to show the recognition he deserves. Otherwise, it would fail to draw 
the most talented students to the engineering profession in Bangladesh. Table 1 also means 
that engineering education can not be limited to technical knowledge only because beside 
engineering solutions, he has to understand political situation, human relations, conflict 
resolution, environmental needs and implementation issues. His curriculum should therefore 
address all these issues.  
 
Table 1. What Engineers, Society and the Employer want? (after Moore, 1974). 
 
What Engineers Want 
 
What Society Needs What Employer Want 
1. Money (economic security} 
2. Recognition (Social status) 
3. Management by Engineers (of 
engineering functions) 
1. Solve conflicting demands 
between: 
Functional needs 
Economic impacts 
Human relations 
Environmental needs 
Political decisions 
2. Effectively communicate facts 
(about decisions made) 
3.  Be effective in implementation 
(application of knowledge) 
1. Technical ability 
2. Integrity 
3. Initiative and creativity 
4. Sensitivity to conflicting 
factors 
5. Communicate effectively with  
Others on team 
Clients 
Regulatory bodies 
Public 
6. Cooperate with others 
7. Good judgment 
8. Ability to take responsibility 
 
Science or Engineering? 
To meet the challenges our profession will face in the future for a sustainable development in 
this country, our engineers must be good at problem solving. One however, must recognize 
the difference between how a solution by an engineer may differ from that of a scientist as 
eloquently expressed by Golder (1948): 
 
“There are two approaches to a natural problem. They are the approaches of the 
pure scientist and that of the engineer. The pure scientist is interested only in the 
truth. For him there is only one answer - the right answer - no matter how long it 
takes to get it. For the engineer, on the other hand, there are many possible 
Page 3
answers, all of which are compromises between truth and time, for the engineer 
must have an answer now; his answer must be sufficient for a given purpose, 
even if not true. For this reason an engineer must make assumptions which in 
some cases he knows to be not strictly correct- but which will enable him to arrive 
at an answer which is sufficiently true for the immediate purpose.”  
 
We would do our society and ourselves as educators and employers a big favor by having 
this in mind and instilling this attitude in our engineering students. 
 
Engineers should essentially be skilled in synthesizing. Engineering is the conceptualization, 
design, construction, and administration of products and projects. Hence engineering 
education must find a balance between analysis and synthesis and find ways to promote 
creativity and risk taking (Steenfelt, 2001). 
 
Educational Objective 
Based on what has been mentioned, educational objective of engineering should be (after 
Poulos, 2000): 
 
1. Engineers must be trained to do competent technical work. 
2. They should be trained to have appreciation of experience or empirical knowledge 
based on what has been found to work in the past. 
3. They should be trained to recognize the need for imagination, judgment and ingenuity 
in solving problems. 
4. They should be trained to recognize the importance of human relations and political 
factors. 
5. They should have an appreciation of peripheral sciences such as biology, chemistry 
and psychology. 
6. They should be trained to communicate, both in writing and orally. 
7. They should learn the need to make decisions from alternative choices. 
8. They must learn the importance of implementation and completing a job. 
 
Thus, we must pay more attention to the development of personal qualities in our future 
engineers for their survival in our competitive world. 
 
Teaching Styles, Learning Methods and Aids 
The Boyer Commission on Educating Undergraduates in the Research University (Boyer 
Commission, 1998) recommends the following “ten ways to change undergraduate 
education”. 
 
1. Make research-based learning standard 
2. Build on the freshman foundation 
3. Link communication skills and coursework 
4. Culminate with capstone experience 
5. Change faculty reward systems 
Page 4
6. Construct an inquiry-based freshman year 
7. Remove barriers to interdisciplinary education 
8. Use information technology creatively 
9. Educate graduate students as apprentice teachers 
10. Cultivate a sense of community 
 
Further the Commission asserts the ‘students’ bill of rights” as follows:  
 
1. Opportunity to learn through inquiry rather than simple transmission of 
knowledge 
2. Training in skills necessary for oral and written communications 
3. Appreciation of arts, humanities, sciences and social sciences 
4. Preparation for graduate school, professional school or first professional 
position 
 
Although the above is based on American experience and educational system, the advice 
has universal application. 
 
Need for a Change  
The position of an engineer in the Society has changed so has the need for change in 
engineering education. Increasing pressure of globalization has put more demand on 
engineer’s quality and capability. He has now to compete beyond his national boundary. 
Lack of employment within the country, cost of higher education, and declining support for 
public education has brought new challenges for engineering educators.  
 
Competition from other disciplines and the declining role of engineers and increasing role of 
business professionals in high ranking management is likely to discourage high academic 
achievers to take up engineering profession.  
 
Increased involvement of applied scientists in designing and implementing engineering 
projects and accessibility of engineering knowledge and scientific software to non-engineers 
has reduced the need for services of engineering professionals nationally and globally. 
Emergence of information and service based economies and associated diverse, flexible and 
non-traditional educational and career opportunities has also added to the this because in a 
market driven economy investors compromise between investment and profit sometimes 
ignoring quality. 
 
In order to remedy the situation, the engineers must play a model role of leaders with 
significant contribution to the society other than engineering projects. 
 
Direction for Change 
Shanableh (2003) identified aspects of engineering education that need to be changed in the 
context of emerging situations described above. His proposal for change in the culture of 
engineering education is shown in Table 2. 
Page 5
 
Table 2. Two Approaches to Engineering Education (Shanableh, 2003). 
 
The Traditional The Progressive 
Maximize technical content and do not worry 
about generic skill 
Balance technical content and generic skills 
Excellence in engineering is all about finding 
numerical solutions to formulated project 
problems 
Engineers involvement in projects involves 
more than finding numerical solutions to 
formulated project problems 
Formalizing the development of social and 
environmental concerns is nonsense and 
wasteful 
The profession is about serving the community 
Given the data are supplied in full, there is a 
‘right’ technique to use in solving problems, and 
there is clear-cut, ‘right’ engineering answer 
The problem must be defined from incomplete 
and uncertain data, various solution techniques 
may apply, and several answers are possible 
depending on weight given to factors 
Deferring some technical skills to continuing 
professional education and graduate studies is 
not satisfactory 
Deferring some technical skills to continuing 
professional education and graduate studies is 
necessary 
The engineer is the center of the project universe 
and the solution he/she provides is the backbone 
of project development and implementation 
The engineer is a member of a project team and 
should be able to get involved in diverse roles in 
projects development and implementation 
Engineering education should only be open to 
the academically high achieving competitive 
students 
Excellence in engineering requires a variety of 
skills and abilities of which creativity and 
collaboration are essential 
 
It is important to note several points that bring departure from the traditional education: 
 
1. Balance between technical and generic knowledge and skill. 
2. Imparting skill in formulating the problem. Solution is in formulating the 
problem. 
3. Emphasis on the services to the community, leadership, development of mental 
and moral growth. 
4. Motivating graduates towards self-education and continuing education goals. 
5. Developing creativity and collaboration with other professionals as a part of a 
team. 
6. Develop an appreciation for innovative developments and new disciplines. 
 
Conclusions 
Our graduates are high academic achievers, well educated persons in the Society but have 
been unable to take leadership in the decision making process. Our goal should be to lead and 
not just survive. 
 
Our aim should be to lead the community in service and not merely serve the industry. 
 
Our educational program needs to be changed in a way that it helps our graduates grow and 
develop morally, mentally, personally and knowledge-wise being able to take up the 
leadership in serving the community.  
 
Page 6
REFERENCES 
Boyer Commission (1998).”Reinventing Undergraduate Education: A Blueprint for 
America’s Research Universities”, http://notes.sunysb.edu/pres/boyer.nsf/webform  
Hornby, A.S., Gatenby, E.V. and Wakefield, H. (1963). The Advanced Learner’s Dictionary 
of Current English, 2nd Ed., Oxford University Press. 
Poulos, H.G. (2000). “Geotechnical Education for 2000 and Beyond”, Proc. 11 th Asian 
Regional Conf. On Soil Mech & Geotech. Engineering, Seoul,16-20 Aug.,1999; Hong et 
al (Eds.), Vol. 2, A.A. Balkema Publishers, pp.579-590. 
Shanableh (2003), “Changing the Culture of Engineering Education: Needs and Directions”, 
E-mail: shanableh@sharjah.ac.ae 
Steenfelt, J.S. (2001). “Teaching for the Millennium- or for the Students?”  GeoEng2000, 
Proc. International Conf. On Geotechnical & Geological Engineering, Vol.1, Melbourne, 
Technomic Publishing Co., Inc, pp.826-840. 
Page 7
 3R Options in Industries 
Dr. Ijaz Hossain 
Professor 
Chemical Engineering Department, BUET, Dhaka 
 
Industrial Waste  
 
Before substantial government regulation began in the late 1970s, most industrial waste was 
disposed of in landfills, stored in surface impoundments such as lagoons or pits, discharged 
into surface waters with little or no treatment or burned. Mismanagement of industrial as well 
as "hazardous" waste has resulted in polluted groundwater, streams, lakes and rivers as well 
as damage to wildlife and vegetation. Meanwhile, high levels of toxic contaminants have 
been found in animals and humans, particularly those, like farm workers and oil and gas 
workers, who are continually exposed to such waste streams.  
 
Industrial waste management generally refers to a set of strategies and approaches that aim to 
eliminate, reduce, reprocess or dispose of waste produced in an industrial setting. Some of the 
common approaches to industrial waste management include emphasis on recycling 
programs, incineration, and landfills. Whatever method is employed, the focus is in 
complying with the relevant government laws. Some of these laws propose penalties in the 
forms of fines or increased taxes. 
 
There are many different approaches to industrial waste management. Waste may be 
collected and transported for disposal at another location, or it might be disposed of on site. 
Recycling and reusing are other solutions that industrial companies are implementing. All 
these solutions can help reduce the amount of industrial waste a company has to dispose. 
Industrial wastes are best classified into three types based on their state as follows.  
1. Gaseous emissions (from stack and fugitive emissions)  
2. Liquid effluent (from process and cleaning)  
3. Solid discharge (from process and from effluent treatment plant)  
 
The most common gaseous emission is flue gas from the combustion of fossil fuels. Along 
with CO2, oxides of sulfur, oxides of nitrogen, volatile organic compounds and other harmful 
gases in trace quantities can be found. In chemical industries where many types of chemicals 
are burned/roasted/reacted, a variety of gaseous compounds many of which are hazardous 
may be emitted. Most chemical industries tend to have leaks and vents. Through these leaks 
volatile compounds are continuously leaking out. If the concentrations of these compounds 
go beyond a certain level, then the health and safety of workers may be jeopardized.  
 
Liquid effluents are also very common in chemical industries. Some examples are paper and 
pulp, food and beverage, textile dyeing plants. Liquid effluents are usually discharged into 
rivers, large bodies of water, and sometimes as runoff into low lands. All kinds of pollutants 
including hazardous ones can be present in liquid effluents. The non hazardous ones can 
usually be discharged into rivers provided their BOD and COD are within acceptable limits. 
With hazardous wastes sophisticated techniques must be applied to collect the pollutant in a 
solid form or in a concentrated form for safe disposal in a designated landfill.  
 
Solid effluents can also be classified into two types – hazardous and ordinary. The hazardous 
type must be disposed off following strict guidelines. Usually it is given away to a third party 
Page 8ISBN: 978-984-33-2140-4
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 for disposal for a fee. The ordinary waste is usually dealt with by deep burial. If the material 
is safe it can even go to a municipal solid waste landfill. Gaseous emissions and liquid 
discharges are treated to meet environmental standards set by the pollution control board. 
These treatment processes usually result in the creation of solid pollutants that must be 
disposed off. Two examples are solid discharges from electrostatic precipitator for gaseous 
emissions and sludge from a liquid effluent treatment plant.  
 
Two of the most common methods of waste disposal are the use of landfills and incineration 
devices. Depending on the type of waste, it can be disposed of or buried underground at a 
landfill site. This approach, however, is limited to materials which are not dangerous. 
Chemical waste or other types of toxic waste are not to be dumped at landfills because it can 
seep into the groundwater and present a health concern to nearby populations. Incinerators 
are also used to burn waste materials in appropriate cases. Environmental groups, however, 
typically do not favor this approach because of the related emission of hazardous gases.  
 
The manner in which industries deal with wastes is best summarized in Figure 1. Historically, 
the tendency was to ignore the problem. As environmental regulations started being 
tightened, the tendency was to tackle the problem by Dilute and Disperse. As pollution 
started to build up in surface water, land and air, the dispersion technique was no longer 
acceptable, and Treatment was the preferred approach. Eventually the higher concepts of 
waste management, such as 3R and Cleaner Production started taking root, and industries 
started moving towards Prevention. Many different names have been used to describe 
industrial waste management. Figure 2 shows how different approaches deal with waste, 
while Figure 3 shows the evolution of industrial waste management over the years.  
 
Historically industries, for complying with environmental regulations, have opted for the 
End-of-Pipe Treatment. Industries have searched for devices or processes to reduce emission 
just to the point that it can meet the environmental regulations. Recent advances in industrial 
technology, materials and newer chemicals have made many processes available which can 
dramatically reduce waste. Industrialists usually shy away from any new process. The 
preventive approaches will not only help industries to meet all environmental regulations, it 
will enhance their performance under CSR, and in most cases be no more expensive than the 
End-of-Pipe Treatment. In many cases, the new process can actually save the industry money.  
 
 
Page 9
3 
 
Figure 1:    Response of industries to waste treatment1  
                                               
1 UNIDO/UNEP   
Page 10
  
Figure 2:    Different approaches for dealing with industrial waste2  
 
 
Figure 3:    Evolution of waste treatment by industries3  
                                               
2 UNIDO/UNEP; Modified from: Berkel, R. Van & J.V.D. Meer (1997), Training Course for Future Trainers on 
Environmentally Sound Technology Transfer. IVAM Environmental Research, University of Amsterdam. 
3 UNIDO/UNEP  
Page 11
 What is 3R?  
 
3R stands for, Reduce, Reuse and Recycle. In the different approaches to environmental 
management 3R is one of the newer ones along with Cleaner Production (CP) for managing 
wastes. The meanings of the 3Rs are elaborated in the following paragraphs.  
 
Reduce – This is the highest form of managing wastes. The idea is that if the industrial 
operation can be done in such a way that it produces no or very little waste then that is the 
ideal situation.  
 
Reuse – It is not always possible to produce zero waste from an industrial process however 
hard one may try. In that case, the next best management option is to reuse the waste. If 
100% of the waste can be reused then that is the second best option.  
 
Recycle – In practice it is not possible to get rid of all waste through only reduce and reuse. 
In that case the minimum must-do option is recycle. As the term implies wastes are treated in 
a variety of ways, sometimes in very complex and complicated manner to produce either zero 
waste or completely harmless wastes as determined by meeting some international standard.  
 
In the 3R philosophy, the real focus is on the first R, i.e., REDUCE. As one move down the 
hierarchy from Reduce to Recycle the value of 3R diminishes. It must be appreciated that 
industries have been practicing Recycle for a long time, especially when the recycling 
operation is profitable. Bangladesh is replete with excellent examples (recycling of plastics, 
steel and glass are good examples). In other cases the need to comply with the environmental 
regulations has forced industries to recycle.  
 
Fundamental concept is SOURCE REDUCTION. Prevent the creation of the waste by:  
1. Using a better process and plant  
2. Using high quality raw materials  
3. Cleaner operation and regular maintenance  
 
Some examples of source reduction are shown in the Box below.  
 
 
 
Page 12
 Sǿgard and Madsen (2007)4 have analyzed the environmental performance and financial 
performance of industries with respect to the type of production as illustrated in Figure 4. 
They show that “Sustainable Production” results when both financial and environmental 
performances are strong; whereas when both the indicators are weak, the operation is 
“Unstable Production”. There are instances of “Shortsighted Production” where despite 
having a strong financial performance the industry displays a weak environmental 
performance, and there are instances of “Philanthropic Production” where an industry tries to 
have a strong environmental performance with a weak financial performance.  
 
The fundamental concept of 3R is that it is a preventive approach rather than a reactive 
approach. In the reactive approach, as the name implies, industries are forced to take action 
because the waste has already been created. The reactive approach is the End-of-Pipe 
Treatment. In the preventive approach, which goes by the name Cleaner Production or 3R, 
the idea is to prevent the formation of the waste in the first place. Therefore, it is imperative 
that action is taken beforehand. The distinction between the reactive and preventive approach 
is best illustrated (see Box below) with an example from the Textile Dyeing industry, which 
is a large polluter in Bangladesh. In the reactive approach there are four levels of treatment 
possible. As one moves from dilution to flocculation to activated sludge to membrane 
separation one achieves better and better recovery of materials and cleanup of waste, but the 
cost increases correspondingly. It is worth noting here that even though Membrane 
Separation is a very high level and expensive operation, it is still a reactive approach. It is 
supported by the 3R approach only at the lowest level, i.e., in recycle. To achieve Cleaner 
Production or the higher Rs of the 3R process, one must go to the preventive approach. In this 
approach after auditing and housekeeping, one needs to search for a better process in terms of 
operation and raw material so that a minimum of waste is created. If possible the highest 
form of 3R, i.e., industrial ecology through better product design may be sought.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
ENVIRONMENTAL PERFORMANCE 
 
                Source: adapted from Søgard & Madsen (2007) 
 
Shortsighted 
production 
Sustainable 
production 
Unstable 
production 
Philanthropic 
production 
STRONG 
WEAK 
WEAK STRONG 
F 
I 
N 
A  
N  
C 
I 
A 
L 
 
P  
E 
R 
F 
O 
R 
M 
A 
N 
C 
E 
 
 
Figure 4:  Production based on financial and environmental performances 
                                               
4 Sǿgard and Madsen (2007): Adapted by: Centre for Enterprise and Economic Development Research, 
Middlesex University Business School. Ian Vickers, Prashant Vaze, Leah Corr, Eva Kasparova, Fergus Lyon.  
Page 13
  
 
Industries are a major source of pollution. Industries emit all types of wastes – gaseous, liquid 
and solid. In addition, industries are a source of noise pollution and even radioactive 
pollution. In the early days of industrialization pollution and environmental degradation were 
of little concern because of the low level of industrialization worldwide, but the pace of 
industrialization has become so great that even developing counties have to come to terms 
with the enormous dangers of environmental degradation.  
 
Today we see the visible signs of industrial pollution in rivers that can no longer sustain life. 
There are many industries that dispose off their wastes in a haphazard and unsafe manner in 
low lying area around the factories, nearby wetland and river. The following are some major 
sources of industrial pollution in Bangladesh.  
1. Brick Kilns – Gaseous and solid (both air borne particulates and ash)  
2. Leather – Gaseous (H2S), Liquid (chromium laden water), solid (shavings)  
3. Textile – Liquid effluent containing salts, alkalis and dyes  
4. Ceramic – Solid (broken fired materials)  
5. Pulp and Paper – Liquid effluent containing chemicals and pulp  
 
3R Options for Industry  
 
The following is a hierarchy of steps that can be followed to achieve 3R in industries.  
1. Waste Audit and Housekeeping  
2. Change Raw Materials  
3. Existing Process Modification  
4. Processes that Produce Less Waste  
5. Product Design: to produce less waste  
 
Waste audit (material and energy balance) is the first step for achieving waste reduction. 
When a well performed waste audit is combined with housekeeping 10-20% waste reduction 
is possible. This is sometimes no or low cost option. But often it is found that industries 
haven’t even taken this first step in waste minimization. To perform a good audit professional 
auditor must be engaged.  
 
There is a strong tendency of industrialists in developing countries to use cheap raw 
materials. The quality of raw material is a big factor in the amount of waste a process will 
create. If the raw material contains undesired product it will have to be removed thus creating 
Page 14
 waste. Often bad raw materials consume excessive amounts of other processing chemicals 
and aids thus creating more waste. A good example (see Figure 5) is the use of low-sulfur, 
low-ash coal instead of high-sulfur, high-ash coal. The process will produce less SO2 
emission, less fly ash and less bottom ash. In addition the combustion process will be better 
and the vessel internals will be less corroded. In this case the benefits will more than pay for 
the extra cost of the high quality raw material.  
 
Process modification or retrofit as it is commonly called in industry is a standard method of 
enhancing performance and reducing emissions. Many old plants have been fitted with 
electrostatic precipitators and NOx control units after many years of operation of the plant. 
Often it is found changing one or two units can dramatically reduce pollution.  
 
When a new plant is being built, the option to build a plant which will produce less waste is a 
ready option. In the present industrial scenario there are many processes available to produce 
the same product. Of course the decision is made on a financial basis, but more often than not 
a process that will produce less waste is ignored because it is perceived to be expensive, even 
though on the long run it will be cheaper especially if environmental regulations get tightened 
(see Figure 6). There are standard technologies, state-of-the-art technologies and advanced 
technologies, and in fact there are sub-standard technologies available in the market. Careful 
considerations to the aspect of waste creation can lead to a proper choice of technology.  
 
Product Design is an entirely new concept that is taking root. Through computer modeling 
one can arrive at a product that will have the same function as a given product and produce 
minimal waste. Even though this is still in the realm of research, one or two products are 
creeping into practice, and numerous others are being tested in laboratories.  
 
EMS to Life-cycle Analysis to Industrial Ecology  
 
The following are the steps leading to sustainable industrial waste management.  
 First, meet all environmental standards  
 After that, establish an Environmental Management System (EMS)  
 Get ISO 14001 certification for factory and operations  
 Conduct Life Cycle Analysis (LCA) to decide on waste management options  
 Move towards Industrial Ecology  
 
EMS is a set of procedures that an establishment follows to achieve progressively higher and 
higher levels of environmental compliance, safe working conditions and sustainable 
development. LCA compares alternatives from cradle to grave and usually the criterion is 
economic cost using a suitable discount rate. But better criteria is material and/or energy use. 
The life cycle methodology advocates opting for the option which is cheaper (or uses less 
material/energy in the long run).  
 
Industrial Ecology is the highest form of industrial operation that essential achieves 
sustainable development through the following.  
 Dematerialization (by a factor of 10)  
 Minimization of energy use (by a factor of 5)  
 100% renewable energy  
 Zero waste – 100% material recycling thus closing the material LOOP  
Page 15
  
 
Figure 5:    Use of low ash coal to generate less waste in a combustor  
 
 
 
 
Figure 6:    Effect of environmental standards on type of waste management used  
 
Page 16
 Rational Use of Waste Biomass Energy: Potential of Carbon Sink 
Development 
Prof. Dr. AKM Sadrul Islam 1 and M. Ahiduzzaman 2 
1Islamic University of Technology, Board Bazar, Gazipur-1704, Bangladesh 
2Bangladesh Rice Research Institute, Gazipur-1701, Bangladesh. 
 
Abstract 
Biomass energy is playing an important role in the energy sector in developing countries. At 
present the biomass is used in a very traditional primitive conversion technologies and causing 
wastage a lot of energy. There is extra pressure on the forest due the growth of extra million of 
population every year. Rice husk briquetting is getting popularity in some areas where, scarcity 
of fuel wood. The rice husk briquette fuel is very good alternative of fuel wood both in terms 
price and the performance of fuel. In case of Bangladesh where the fuel wood comes from non-
sustainable source, the briquette fuel can easily enter the carbon market. The forest area 
developed after replacing the wood fuel is 20.39 thousand hectare in 2000 and this forest land is 
increased to 40.92 thousand hectare in 2030. The carbon dioxide reduction is 6.29 million tonne 
in 2000 and this value is increased to 12.62 million tonne in 2030. By reducing deforestation the 
forest area is increased to 2.22 million hectare which is equivalent to the forest area that was in 
1971. Rational use of waste biomass energy can substitute a significant amount of wood fuel that 
could reduce extra pressure on our environment. Hence reduction of deforestation would develop 
a carbon sink in the existing forest thus would led to sustainable development of forest resources 
in developing countries. 
1. Introduction 
Energy, the basic ingredients to alleviate poverty and socio - economic development. 
Worldwide, there is a major transition underway in the energy sector due to decline in fossil fuel 
availability,  reduction of global emissions for mitigating climate change  and energy security. 
About 2.5 billion people depend on traditional biomass energy [1]. Agro-residue is one of the 
main sources of traditional biomass. Biomass fuels from forest are using beyond their 
regenerative limits due to high pressure of population. There is severe shortage cooking fuel 
requirement in developing countries. There is a limitation of expansion of the forest area for 
wood fuel. Developing countries are facing problem with the deforesting process due to lack of 
fuel in small cities, public centers, small entrepreneur, tea stall, restaurants and rural areas. 
Biomass briquetting process is one of the process that can transform the loose biomass into solid, 
woody, high bulk density, regular shape which can be easily stored and transported [2]. The 
briquette fuel is getting popularity as alternative to wood fuel in different countries like Thailand, 
Vietnam, Bangladesh, India, Myanmar etc. Therefore, conversion of loose biomass into wood 
fuel is important to meet the demand of cooking fuel. The waste biomass like husk, straws, 
Page 17
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
ISBN: 978-984-33-2140-4
 municipal waste, that account for a substantial share in total energy consumption of many 
developing counties. The main problem of this waste biomass is its low bulk density that creates 
transportation and storage problem. Since the fuel wood comes from non-sustainable source of 
forest in developing countries, the use of fuelwood causes emission of greenhouse gas. The 
greenhouse gas emitted from the use of non-sustainable forest can be omitted by using any other 
fuel from sustainable source like agro-residues. In that case the waste biomass briquette can play 
a vital role to reduce the consumption of fuel wood from non-sustainable forest as well as to 
reduce the greenhouse gas emission. 
2. Is Biomass renewable? 
Biomass is part of the carbon cycle. Carbon from the atmosphere is converted into biological 
matter by photosynthesis. On death or combustion of the biomass material, the carbon goes 
back into the atmosphere as carbon dioxide (CO2). This happens over a relatively short 
timescale. Biomass used as a fuel can be constantly replaced by planting for new growth. 
Therefore, a reasonably stable level of atmospheric carbon results from the use of biomass as 
a fuel. The carbon cycle of biomass fuel is shown in Fig. 1. 
 
Fig.1: Life cycle of biomass carbon 
Though biomass is a renewable fuel, and is sometimes called a "carbon neutral" fuel, its use can 
still contribute to global warming. This happens when the natural carbon equilibrium is 
disturbed: by deforestation and by urbanization of green sites. 
 
 
Page 18
 3. Source of Biomass 
The main sources of biomass are forest product, agro-waste, animal waste, municipal waste and 
energy crops etc. These biomass sources include jute stick, straws, husk, bagasse, firewood, 
twigs leaves, household wastes etc. Share of renewable energy is 18% globally and biomass 
contributes 13% of total energy consumption in the world [3]. Installed power capacity for 
electricity generation is 52 GW globally whereas hot water and heating capacity is 250 GW th [4]. 
Global productions of selected biomass viz. firewood, bagasse and rice husk production are 835, 
211 and 132 million tonne, respectively [4, 5]. 
In Bangladesh, different types of biomass are produced viz. rice straw, cowdung, rice husk, 
firewood, jute stick, bagasse, twigs and leaves etc. There are significant amounts of waste 
biomass produced in country (Fig. 2). Agro-waste biomass dominates the traditional energy 
sector in the country. Agro waste production is increased in trends with an annual growth rate of 
2.35%. 
 
0
2
4
6
8
10
12
14
16
18
20
2000-01 2001-02 2002-03 2003-04 2004-05
M
ill
io
n 
to
nn
e
Year
Rice straw
Cowdung
Rice husk
Firewood
Twigs & leaves
Jute stick
Bagasse
 
Fig.2: Different types of traditional biomass production in Bangladesh [6] 
 
 
Page 19
 4. Consumption of biomass energy 
Biomass is the main primary energy source for the people of developing countries. About 52% of 
world population relies on the traditional biomass energy. About 80% of total population of 
Bangladesh lives in rural area, where biomass is the only available energy source and it is 
estimated that 88% of energy demand is for household cooking, this being almost completely 
supplied by biomass resources [7]. Biomass is consumed in the form of as it is available. The 
conversion technology of biomass energy is very much traditional having very low thermal 
efficiency. The thermal efficiency of traditional biomass cook stove ranges 6 to 10%. Improved 
cook stove is the alternate option for saving of the biomass energy by 50% of traditionally 
consumed. 
Rice husk biomass is obtained as byproduct of agro-processing centers. The rice husk is dumped 
and open fired in many countries. In Bangladesh, rice husk is mainly consumed for producing 
process heat of parboiling in the rice milling industries. About 5 million tonne of rice husk 
consumed in Bangladesh for rice parboiling. The boiler used in rice mills is very much 
inefficient and it can utilize only 20% of thermal energy [8]. Huge amount rice husk can be 
saved simply by replacing the traditional boiler with improved one. About 2 million ton of rice 
husk could be saved every year in Bangladesh if the rice millers would adopt this improved rice 
parboiling system. Therefore, there is a scope to save biomass energy without scarifying the net 
energy demand by using the biomass energy rationally. 
5. Woody biomass fuel from waste loose biomass  
The waste biomass like rice husk, rice straw, sawdust, bagasse, jute stick etc. account for a 
substantial share in total energy consumption of Bangladesh. The main problems of this energy 
are their low bulk densities and high moisture content as well as this traditional energy is not in 
an organized form. People have to spent time to gathering and drying of a bulk volume before 
using. Biomass densification process can transform this biomass into solid, high bulk densities, 
regular shape. This densified biomass (briquette) fuel can be easily stored and transported. After 
densification it looks like dry woody material (Fig. 3) and its calorific value ranges from 14.2 to 
17.5 MJ/kg and it is equivalent to “B” grade coal in terms of calorific value [9]. It burns slowly 
with less smoke than wood fuel. The biomass briquette has very high bulk density and size and 
shape is comparable with fire wood (Table 1). Therefore, there is a potential to replace the wood 
fuel with this biomass briquette fuel from wastes.   
In recent years the use and production of rice husk briquette fuel have been increased in certain 
areas of Bangladesh.  A majority of tea stall and small food shops in Sylhet and Chittagong 
district of Bangladesh has shifted from using fuelwood to rice husk briquettes [10, 11]. In 
Mymensing town , most of tea stall, street food stall and restaurant have been shifted from wood 
fuel to rice husk briquette fuel. The consumption pattern widely varied among the users. The 
highest consumption rate was found to be 114 kg/day per restaurant. The average consumption 
rate of tea stall, street food stall and household were found to be 16 kg/day and 12 kg/day and 2.5 
Page 20
 kg/day per household, respectively (Fig. 4). The wood consumption rate was higher than the 
briquette fuel (130 kg/day for restaurant and 30 kg/day for tea stalls) [12]. The consumers of 
briquette fuel reported that on an average 1 kg of densified biofuel could provide same service of 
1.63 kg of wood fuel. However, this ratio differed when it was calculated based on consumption 
data (1.48 kg of wood fuel is equal to 1 kg of briquette fuel) and laboratory test data (1.21 kg of 
wood fuel is equivalent to 1 kg of briquette fuel). Use of rice husk briquette fuel instead of wood 
fuel has been increased in several areas of Bangladesh, that ensures that loose waste biomass 
could be a viable option to reduce pressure on the forest wood fuel. 
 
  
(a) Dumping of loose rice husk (b) Rice husk briquette 
Fig. 3: Loose rice husk  (a) and rice husk briquette fuel (b) after densification looks like woody 
biomass 
 
Table 1. Properties of loose rice husk and compact briquette fuel 
Fuel properties Loose rice husk Briquette fuel 
Bulk density, kg/m³ 117   825 
Length length : 6- 8 mm 
 
length : 60- 100 cm 
 
Width/Diameter width: 2-3 mm diameter = 5.6 – 6.0 cm  
Inner hole diameter = 1.8 – 2.4 cm  
Calorific value, MJ/kg 12.70 14.67 
 
 
Page 21
  
Fig. 4: Photograph of different type of rice husk briiquette fuel users and their daily consumption 
6. Deforestation 
Many households in Africa and South Asia still do not have access to modern fuels and have to 
rely on fuel wood and waste for cooking. This represents a heavy burden in terms of time and 
money spent to obtain these fuels. In addition, reliance on fuel wood contributes to deforestation. 
Widespread use of natural forests as a source of wood for fuel this could cause deforestation, 
with serious ecological and social results. This is currently occurring in Nepal, parts of India, 
South America and in sub-Saharan Africa. In many Asian countries much of the wood used for 
energy purposes comes from natural forest areas, which could become deforested if overused. 
Net forest loss was estimate to be 8.3 million ha per year during 1990s. However the forest loss 
during the period of 2000-2010 is 5.2 million ha per year globally [14]. Bangladesh is facing 
problems with severe deforestation. According to the different reports the deforestation rate for 
Bangladesh ranges from 2.86 to 3.3% annually [15, 16]. The deforestation rate is reported to be 4 
hectare per hour in Bangladesh [17]. The total deforested land is estimated to be 1.442 to 2.228 
million hectare during the period of 1971 to 2006 (Table 2) [18]. 
 
Page 22
  
Fig. 5: Annual changes of forest area globally 
 
Table 2. Deforestation rate in Bangladesh [15, 16, 17, 18] 
Source  of reporting Deforestation  
M.A.L. Mia 2009 (XIII World forest congress, 
Aregntina)  
3.3%  
FAO 2000, NFA 2007  2.86%  
Janakantha 2005  4 ha per hour  
Forest area decrease during 1971 to 2006, million ha 
(FRA 2000, NFA 2007)  
2.228 to 1.442  
 
 
 
Page 23
 7. Reduced pressure on forest wood fuel 
CASE STUDY: Replacement of fire wood with rice husk briquette fuel in Mymensingh town 
• Total demand of briquette  = 600 tonne/month 
• Local production   = 97 tonne/month 
• Supply from surrouding  = 503 tonne/month  
 
 
Fig. 6: Rice husk briquette production in greater Mymensingh region [12] 
Use of rice husk briquette in Mymensingh 
 Tea stalls, small retailers and poor household are the users of rice husk briquette. 
 The main reason for this shift is that firewood is becoming scarce 
 Briquette exerts less smoke and uniform quality compared to wood 
 The households who could not avail the gas grid connection are using rice husk briquette 
fuel 
 
Reduction of CO2 emission 
CO2 equivalent emission results for wood fuel and rice husk briquette fuel options are calculated. 
The results are shown in Table 3. the CO2 emission amounting 17370 tonne per year was 
obtained from wood fuel use from non-sustainable forest and the lowest CO2 emission 
amounting 954 tonne was obtained from rice husk briquette fuel use option. The annual saving of 
CO2 emission is 16.42 thousand tonne per year in Mymensingh town due to the use of briquette 
fuel instead of wood fuel. The annual return from CO2 emission saving by using 100% briquette 
fuel instead of wood fuel in the study area would be equivalent to US$197.04103 annual worth. 
Therefore, there is great potential to reduce global emission by using waste biomass energy 
instead of wood fuel [2]. 
Page 24
  
Table 3. Reduction of CO2 emission by using rice husk briquette fuel over wood fuel 
Option Annual 
demand 
 106 
CO2 equivalent 
 103 ton/annum 
Net CO2 saving over 
100% wood system, 
 103 ton/annum 
Return from CO2 
abatement  103 
US$/annum 
Wood fuel 14.244 kg 17.370 - - 
Rice husk briquette 
fuel 
9.039 kg 0.954 16.42 197.04 
[CO2 reduction trade, US$ 12.00/ton] 
 
7. Potential of carbon sink development 
Waste biomass energy needs to conversion into usable form to replace the wood fuel. Rice husk 
briquette fuel can replace wood fuel successfully as discussed in previous section. Rational use 
of rice husk energy can develop carbon sink by increasing the carbon storage in forest through 
reducing the deforestation of non-sustainable forest as described in the following block diagram. 
The potential production o briquette fuel and replacement of wood by briquette are shown in 
Fig.7.  
 
 
Fig. 7: Scenario for production of rice husk briquette and replacement of wood fuel 
Page 25
 Rice husk briquette replaces the wood fuel coming from non-sustainable sources or deforestation 
processes. When the potential equivalent of wood fuel from rice husk briquette is added with 
wood fuel from sustainable source, it reaches the total present consumption of wood fuel. It 
reveals that if the rice husk briquette can be introduced in the wood fuel market then intrusion of 
wood fuel from deforestation process can be prevented. The scenario of total wood fuel 
equivalent i.e. combination of rice husk briquette and wood fuel from sustainable source seems 
to be increase in trends and sustainable (Fig. 8). 
 
Fig. 8: Scenario of impact of rice husk briquette on total wood fuel equivalent 
The forest area developed under the proposed model is 20.39 thousand hectare in 2000 and this 
forest land is increased to 40.92 thousand hectare in 2030. The carbon dioxide reduction is 6.29 
million tonne in 2000 and this value is increased to 12.62 million tonne in 2030. The forest area 
saved each year is cumulated with present forest area then scenario of forest area in future is 
found. The scenario of total forest area shows that the forest area is increased to 2.22 million 
hectare which is equivalent to the forest area that was in 1971 (Fig. 9). Therefore, a sustainable 
forest growth could be achieved if the proposed model of rice husk energy use is executed. 
 
Page 26
  
Fig. 9: Potential increase of forest area in Bangladesh 
 
8. Conclusion  
Biomass energy is playing an important role in the energy sector in developing countries. At 
present the biomass is used in a very traditional primitive conversion technologies and causing 
wastage a lot of energy. There is extra pressure on the forest due the growth of extra million of 
population every year. Rice husk briquetting is getting popularity in some areas where, scarcity 
of fuel wood. Rice husk and rice husk ask a product gifted by nature, they are environment 
friendly with local habitat. The rice husk briquette fuel is very good alternative of fuel wood both 
in terms price and the performance of fuel. In case of Bangladesh where the fuel wood comes 
from non-sustainable source, the briquette fuel can easily enter the carbon market. Rational use 
of waste biomass energy can substitute a significant amount of wood fuel that could reduce extra 
pressure on our environment. Hence reduction of deforestation would develop a carbon sink in 
the existing forest thus would led to sustainable development of forest resources in developing 
countries. 
References 
[1] World Energy Outlook 2006 
[2] Ahiduzzaman, M.  and Sadrul Islam, AKM. (2009). Environmental Impact of Rice Husk 
Briquette Fuel Use in Bangladesh: A Case Study of Mymensingh. 1 st International 
Conference on the Developments in Renewable Energy Technology (ICDRET’09), 
December 17-20, 2009, Dhaka, Bangladesh. 
Page 27
 [3] Renewables 2007, REN21 
[4] Renewables 2009 Updates, REN21 
[5] FAOSTAT. www.fao.org. accessed on 20.01.11. 
[6] BBS (2008): Statistical Pocket Book of Bangladesh. Bangladesh Bureau of Statistics. 
Planning Division, Ministry of Planning, published in January 2009. p. 6-11, 233-246. 
[7] Ellery, M.; Siddiqi, F.A.; Newman, P. (2000): Sustainable Rural Development: Prospects of 
Renewable Energy in Bangladesh. Science, Technology and Development. Bangladesh 
Council of Scientific and Industrial Research. Vol. 1 No. 2. December 2000, Dhaka, p. 6-13. 
[8] M. Ahiduzzaman, and A. K.M. Sadrul Islam, Energy Utilization and Environmental Aspects 
of Rice Processing Industries in Bangladesh. Energies 2009, 2, 134-149; 
doi:10.3390/en20100134 
[9] Moral, M.N.A, and Rahman, A.N.M.M. (1999): Briquetting Activities in Bangladesh. 
Proceedings of Training Workshop on Renewable Energy Education and Application for 
Rural Communities in Bangladesh. Nov.27-Dec.03, 1999. Organized by Center for Energy 
Studies, Bangladesh University of Engineering and Technology, Dhaka, Bangladesh. 
pp.368-379. 
[10] Sarker M. A.R, Obaidullah, M., Das, D.K. and Huq, A.M.A. (1999): Availability of 
Renewable Energy Resources in Bangladesh. Proceedings of Training Workshop on 
Renewable Energy Education and Application for Rural Communities in Bangladesh. 
Nov.27-Dec.03, 1999. Organized by Center for Energy Studies, Bangladesh University of 
Engineering and Technology, Dhaka, Bangladesh. pp.12-13. 
[11] Dasgupta, N., Baqui, M. A., Dhingra S., Raman, P., Ahiduzzaman, M. And Kishore, V.V. 
N. (2003): Benefits of Improved Rice Husk Combustion, Bangladesh. NRI report no. 2764. 
p. 8, 21, 67. 
[12] Ahiduzzaman, M. (2006). Production and Use of Densified Biofuel in Mymensingh District 
(Bangladesh) under Technical and Socio-economical Aspects, M.Sc. Thesis , Submitted to 
Department of Sustainable Energy Systems and Management, University of Flensburg, 
Germany, March 2006. 
[13] World Energy Council 2008. Energy Efficiency Policies around the World: Review and 
Evaluation 
[14] http://www.unece.org/timber/mis/presentations/PepkeGlobalWoodMkts050510.pdf accessed on 
19-03-2011. 
[15] http://www.cfm2009.org/es/programapost/trabajos/Social_forestry_FD.pdf 
[16] FRA 2000. Forest Resource of Bangladesh. Country Report. Rome 2000. 
[17]  NFA 2007. Forest and Tree Resources Assessment 2005-2007. Bangladesh. 
http://www.fao.org/forestry/49735/en/bgd/, date 31.03.10 
[18] Janakontha. (2005): The daily Janakontha. Janakontha Bhaban, 24/A New Eskaton Road, 
Dhaka, Bangladesh. Published on 02.06.2005. www.janakantha.com/ p1/ln.pdf, page 3. 
Accessed on 02.06.05. 
Page 28
  
 
THERMOMECHANICALLY TREATED ADVANCED STRUCTURAL 
STEELS TO IMPROVE THE EARTHQUAKE RESISTANCE OF 
BUILDINGS     
 
Md. Aminul Islam* 
Materials and Metallurgical Engineering Department 
BUET, Dhaka-1000 
 
 
Earthquake is a part of natural activity similar to typhoon or ocean wave. However, it is very difficult to anyone 
around the world to predict the exact time, location and right magnitude of an earthquake. As a result, earthquake 
related damages are more uncertain and threatful for mankind. Although the occurrence of earthquake is very 
unpredictable, but the earthquake related damages to life and property can still be minimized by proper structural 
designs and using better materials for the structures. For modern taller multi-story buildings a large volume of 
steel bar is used to reinforce the concrete. The quantity, quality and properties of these steel bars used play the 
pioneer role for the safety of the buildings. Materials scientists have developed several advanced structural steels 
through various thermomechanical treatment routes. In this papers, production routes and various essential 
mechanical properties of two different thermomechanically treated advanced structural steels having high 
earthquake resistance (quenched and tempered; QT steel and transformation induced plasticity steel; TRIP) will 
be compared with conventional steels of similar chemical compositions and/or strengths. Initiative will also be 
taken to discuss the benefits of these advanced structural steels, if they are used as reinforcing bars in multistory 
buildings, especially in the earthquake sensitive areas.  
Keywords: Earthquake, High-rise buildings, Reinforcing steel bars, Thermomechanically treated steels. 
1.  INTRODUCTION 
 Earthquakes cause the ground to shake violently in 
the form of wave (Fig. 1) there by triggering the 
landslides, creating floods, causing the ground along 
with its various manmade or natural structures to 
heave and crack with subsequent destruction to life 
and property. The study of why and where 
earthquakes might occur is the subject matter of 
geology. The study of the characteristics of the 
earthquake ground motion and its effects on 
engineered structures are the subjects of earthquake 
engineering. In particular, the effect of earthquakes 
on structures and design of structures to withstand 
earthquakes with no or minimum damage is the 
subject of earthquake resistant structural design. 
_______________________________________ 
 
Here it is to be realized that without materials there is 
no engineering. Material is the most vital factor for 
any engineering field. As a result, the success or 
failure in any engineering and/or design mostly 
depends on the performance of the materials utilized 
for that. Because, if worst material is used in the case 
of any structure where the best design criteria have 
been followed, the structure will not be sustainable 
accordingly. So, design engineers in any field must 
consider the performance of materials used or to be 
used for any targeted work.   
For any structure to be earthquake resistant, the 
ductility of reinforcing materials used for the 
structure plays an important role [1-3]. Here it is to 
be mentioned that, the qualities of compressive load  *Corresponding Author: M.A. Islam 
E-mail: aminulislam@mme.buet.ac.bd 
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
Page 29
ISBN: 978-984-33-2140-4
  
 
 
 
 
 
 
 
 
bearing materials as cement, gravel, sand, etc. are 
also very important [4,5]. Ductility is the property, 
which allows the structure to undergo large plastic 
deformations without significant loss of strength, Fig. 
2a. On the other hand, hysteretic energy is the energy 
dissipated by inelastic cyclic deformations and is 
given by the area within the load-deformation curve, 
which is also known as hysteretic curve, Figs. 2b and 
c.  Structures having low hysteretic energy 
dissipation capacities, even if the deformations are 
well below the ultimate deformation, are likely to 
collapse due to low cycle fatigue effect.  Because all 
fatigue failures are of brittle nature [6,7], which take 
place under stress levels below of the respective yield 
stresses of the materials used. Here it is mentioned 
that earthquake loading produces a large deformation 
as well as cyclic loading depending on intensity and 
duration of the earthquake [1], Fig. 3. Higher energy 
dissipation means better earthquake resistance, which 
is controlled by the level of ductility of materials. On 
the other hand, resistance of the structures to repeated 
shocks caused by a single or several earthquakes 
depends on the low cycle fatigue resistance of the 
materials used for the structures [1,2]. As a result, 
both ductility and low cycle fatigue resistance are 
very important for making any material to be 
earthquake resistant.  
In many countries, especially in vulnerable areas of 
Japan and U.S.A., there has been a tremendous 
progress in earthquake resistant buildings. For overall 
success, materials scientists have also contributed a 
lot towards making the engineered structures to be 
safer under earthquake through the development of 
various heavy duty materials essential for structural  
building such as cement, mortars, bricks, reinforcing  
 
 
 
 
 
 
 
 
 
 
bars, etc. In any modern earthquake resistant multi-
story building, a large volume of reinforcing bar is 
used, which is very clear from Fig. 4. It has been 
observed that the degree of earthquake related 
damage is proportional to the overall weight as well 
as the height of the building. In order to reduce the 
total weight of structural buildings, design engineers 
are suggesting high strength steel bars for high-rise 
buildings. Through the addition of various alloying 
elements, such as chromium, nickel, molybdenum, 
vanadium, etc. the strength of the structural steel can 
be increased. But the key problem concerning this 
steel strengthening route is that it reduces the 
ductility of the steel as well as the bendability [8-11], 
which is the key property for earthquake resistant 
reinforcing steel bar. In order to avoid problem 
related to inferior ductility, materials scientists have 
developed various advanced structural steels by 
proper control of microstructures of steels through 
thermomechanical treatments. Thermomechanically 
treated steels might be plain carbon as well as alloy 
steels. The latter group of steels (alloy steels) are 
designed to achieve further higher strength along 
with other functional property requirements 
depending on service conditions [12,13].  
The main objective of this paper is to present and 
discuss various types of advanced structural steels, 
especially QT and TRIP steels and their benefits if 
they are used as reinforcing steel bars in the place of 
conventional steel bars for making earthquake 
resistant buildings and other structures where steel 
reinforced concretes are used. 
 
Fig. 1: Wave pattern ground shaking created by earthquake. 
Page 30
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Ductile Metal 
Brittle Metal S
tr
es
s 
Deformation 
St
re
ss
 
Deformation 
St
re
ss
 
Elongation 
(a) (b) (c) 
Fig. 2: (a) Stress-elongation curves of brittle and ductile materials, (b) and (c) are, respectively, 
hysteretic diagrams of brittle and ductile materials. 
D
is
pl
ac
em
en
t 
Number of Cycles 
              Fig. 3: Cyclic displacement caused by an earthquake. 
    Fig. 4: Use of reinforcing steel bars in a modern earthquake resistant building. 
Page 31
2.  RESULTS AND DISCUSSION 
In this paper production processes of several 
thermomechanically treated high strength steels and 
their microstructures along with mechanical 
properties (strength, ductility and fatigue resistance) 
will be compared to that of conventional steels of 
similar chemical compositions and/or strengths.  
2.1 Production and Microstructures of 
Thermomechanically Treated High Strength 
Structural Steels 
For conventional reinforcing structural steels, the hot 
rolled steel bars are cooled naturally in air after final 
rolling. So, the microstructure of this steel becomes 
to be composed of normalized ferrite-pearlite, Fig. 5. 
Here it is important to mention that the white and 
black grains of the microstructure, respectively, are 
ferrite and pearlite. Conventional plain carbon hot 
rolled structural steel results a very high level of 
ductility, however, its yield strength is relatively low. 
Although this steel shows high earthquake resistance, 
but it is not wise to use it for high rise buildings 
because of higher proportion of steel consumption, 
which increases the overall weight of buildings. In 
order to reduce the proportion of steel consumption, 
steel producers are trying to increase the strength of 
the conventional hot rolled steels by adding more 
carbon or alloying elements. This initiative helped in 
reducing the steel consumption. However, the 
ductility level of the steel decreases, which means 
reduction in earthquake resistance of the steel bars. 
 
 
 
 
 
 
 
 
 
 
 
For strengthening steel bars, there are various 
thermomechanical treatment options. One of these 
options is quenching and tempering (QT steel). For 
QT steel, after final pass of rolling, the hot rolled 
steel bars are quickly passed through a chamber with 
water flow from different directions. Finally, the 
dynamically quenched bar is naturally cooled in air 
on specially made cooling bed, Fig. 6. So, the 
microstructure of outer layers of the bars become 
tempered martensite because of quick quenching 
action on surface layers and the core remains to be 
normal ferrite-pearlite, Fig. 7. However, there might 
be a zone with microstructures in between ferrite-
pearlite (at core) and tempered martensite (outer 
case), which is popularly known as transition zone. 
Recently, several local industries have started to 
produce this grade of steel. 
Another option of increasing the strength of structural 
steel is by reducing the ferrite and pearlite grains to a 
very fine level (ultra fine grain; UFG steel) through 
drastic deformation during rolling process. Typical 
microstructure of UFG steel is shown in Fig. 8. Latest 
thermomechanically treated high strength structural 
steel is the transformation induced plasticity; TRIP 
steel. The production of TRIP steel is little bit 
difficult. Because it needs very close control on 
chemical compositions, hot rolling temperature, 
deformation in each pass, holding time and 
temperature after each pass of rolling, etc. As a 
result, the production cost of this steel is very high 
and that this steel is not commercially produced in 
many countries. The final structure of this steel is 
composed of several different phases like ferrite (F), 
retained austenite (RA), bainite (B) and martensite 
(M) of varying proportions, Fig. 9. So, TRIP steel is 
occasionally named as multiphase high strength steel.   
2.2  Tensile Behaviours of Conventional and 
Thermomechanically Treated Steels 
It has been mentioned that the microstructure of 
conventional structural steel is composed of ferrite 
and pearlite. Having similar carbon equivalent (CE) 
and carbon (e.g. 0.4 CE and 0.2% C), the 
conventional structural steel will result lower yield 
and ultimate tensile strength along with a very high 
elongation (more than 25% in general). Here it is 
important to note that yield strength of the 
reinforcing steel bar is a very important parameter as 
it is directly considered for any structural design. If 
low yield strength structural steels are used in 
buildings, the consumption of steel will be high, 
which means overall weight  of  the structure will be  
Fig. 5: Ferrite-pearlite structures of conventional     
structural steel. 
Ferrite 
Pearlite 
Page 32
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                       Fig. 6: Production of QT steel. 
Tempered Martensite 
  Transition Structure 
Ferrite-Pearlite Structure 
     Fig. 7: Microstructures of QT steel. Fig. 8: Ferrite-pearlite microstructures of an ultra 
fine grain (UFG) structural steel. 
Fig. 9: Microstructures of transformation induced 
plasticity (TRIP) steel. 
Page 33
relatively high. If insufficient amount of low strength 
and high ductility bars are used to reduce the steel 
consumption as well as the weight of the structures, 
then there might be ductile failure under earthquake 
as shown in Fig. 10. On the other hand, from 
earthquake point of view, it is wise to reduce the total 
weight of the structure as minimum as possible 
without compromising the safety of the building. 
Because, in general, the degree of earthquake related 
damage of any structure is proportional to its overall 
weight. If high strength ductile steel bars are used in 
the place of conventional low strength steel bars then 
steel consumption will be lower. At the same time, 
the structure will also be safer.  
Another option to increase the strength of steel bars 
by thermomechanical treatment route is by cold 
working. But, cold working severely reduces the 
ductility of reinforcing bar, which should not be 
compromised at all for the construction of earthquake 
resistant buildings. Moreover, the corrosion 
resistance of the cold worked steels becomes very 
poor. So, within a very short period of time the 
reinforcing steel bars become severely rusted and the 
plaster along with the part of reinforced concrete 
collapses causing the steel bars to be exposed to the 
atmosphere, Fig. 11. This phenomena decrease the 
total safe service life of buildings.  
Addition of more carbon (note: in Bangladesh up to 
0.4% carbon is found in structural steel bar) increases 
the strength, however, both ductility (Fig. 12) and 
corrosion resistance of the steel bar become inferior. 
So, it is also not wise to produce structural steel bars 
with carbon content more that 0.32%. 
Another option of strengthening steel bar that is 
widely practiced in Bangladesh is the addition of 
various alloying elements such as manganese, 
chromium, nickel, copper, etc.  There is no doubt that 
addition of chromium, nickel and copper increases 
the corrosion resistance of the steel bar. But, the 
ductility level and bending property decrease 
drastically, which is an important reason of more 
frequent structural failure in Bangladesh. The reason 
of drastic decrease in ductility and bendability is that 
local industries are producing reinforcing alloy grade 
of steel bars by melting various types of ferrous 
scraps in induction furnace, which is a very bad 
practice. Because in induction furnace, no refining, 
degassing or elimination of slag inclusions is 
possible. So, the levels of porosity, gas pockets, 
inclusion particles, etc. remain to a very high level. If 
these defective steel bars are used in structures, they 
will face high level of damage during earthquake 
because of stress concentration at the defective areas. 
On the other hand, QT, UFG and TRIP steels show 
very high strengths, Fig. 13. Except for UFG steel, 
the ductility levels of other two (QT and TRIP) 
thermomechanically treated steels are also very high. 
In this respect, TRIP steel shows exceptionally a very 
high elongation (in general it is more than 30%).    
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig: 10. Column failure due to insufficient proportion 
of low strength highly ductile reinforcing steel bars. 
Fig. 11: Rusted and exposed concrete reinforcing steel 
bars  because of severe corrosion. 
Page 34
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 12: Effect of carbon content on the strength and ductility of plain carbon structural steel. 
Ultimate Tensile Strength 
Ductility 
800 
    0 
400 
200 
600 
40 
 0 
20 
10 
30 
0          0.2          0.4          0.6           0.8           1.0         1.2        1.4 
U
lti
m
at
e 
Te
ns
ile
 S
tr
en
gt
h,
 M
Pa
 
D
uctility, %
 
Carbon Content (wt%) 
                  Fig. 13: Stress-ductility diagram of various structural steels. 
10 20 30 40 0 
%Ductility 
St
re
ss
 
Conventional 
Structural Steel 
TRIP Aided 
Structural Steel 
Alloyed  Structural 
Steel 
QT Structural 
Steel 
UFG Structural 
Steel 
Page 35
  
 
 
 
 
 
 
 
 
 
 
 
2.3  Fatigue Behaviours of Conventional and 
Thermomechanically Treated Steels 
It has been proved that the total fatigue life of a 
component is composed of two different periods, 
namely crack initiation period and crack propagation 
period, Fig. 14. In general, total fatigue life is 
dominated by crack initiation period, which is also 
clear in the figure. Longer the crack initiation period, 
higher will be the total fatigue life. It is also proved 
that higher the yield strength of material means 
longer crack nucleation period, Fig. 15. In the case of 
cyclic or fatigue loading, maximum tensile stress is 
induced at surface areas. Here it is important to 
mention that, during cyclic loading, fatigue crack 
initiates from surface having highest level of 
effective tensile stress. So, better surface finish as 
well as the yield strength of surface material plays 
important role to control the total fatigue life. In this 
case, QT steel shows unique combination of surface 
finish along with higher surface strength. It has been 
mentioned that after final pass of rolling, QT steel 
bars are quenched by controlled water flow. Due to 
this controlled water flow the material at the surface 
layer is only selectively quenched and subsequently 
tempered resulting tempered martensitic structure 
there. As a result, surface layer of QT steel bars 
becomes very strong, which is also a pre-requisite 
condition to resist early crack formation. So, QT steel  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
bars show unparallel fatigue life compared to any 
other conventional structural steel having similar 
chemical compositions and/or average strength level. 
 
Crack Initiation Period 
Crack Propagation Period 
Total Fatigue Life 
St
re
ss
 L
ev
el
 
Fig. 14: Effect of applied cyclic stress level on the total fatigue life of a component. 
QT Steel 
Conventional Steel 
Fatigue Crack Initiation Time 
Y
ie
ld
 S
tr
es
s o
f S
ur
fa
ce
 L
ev
el
 
Fig. 15: Effect of surface yield strength on 
fatigue crack initiation time of a component. 
Page 36
  
 
 
 
 
 
 
 
 
 
 
In general, the fatigue fracture is a brittle type of 
failure and it initiates below the yield strength of the 
material, which has already been mentioned. For 
ductile material, fatigue limit is also controlled by its 
ultimate tensile strength (UTS) which is 50% of the 
UTS, Fig. 16. Here it is to be mentioned that for 
ductile material, the yield strength (YS) is about 55 to 
65% of its UTS, which means fatigue limit is well 
below the YS of the ductile materials. However, this 
rough assumption is not true for notched (materials 
with rough surface) or brittle materials. For structural 
applications, reinforcing steel bars must show more 
that 12% ductility. In our country, for many cases, 
ductility level is frequently found to be below 10%. 
At the same time, bend test samples frequently break 
below 45o angle of bend, which is not be expected for 
any good quality structural steel bar. This observation 
is mostly for alloy grade and/or high carbon grade of 
structural steel. In brief, we can say that this steel is 
too brittle for reinforcing concrete. Even though this 
steel shows higher YS or UTS, their fatigue limit is 
very low, which also means low fatigue property. To 
be earthquake resistant, the steel must have high 
ductility. As a result, structures reinforced by 
conventional high strength steel bars of lower 
ductility level are unable to give proper safety of the 
building during the period of earthquake.  
Here it is to be noted that thermomechanically treated 
UFG steel is a grade of high strength steel. However, 
this grade of steel is not good for earthquake resistant 
building because of its insufficient ductility, Fig. 13.  
 
 
 
 
 
 
 
 
 
 
 
It has been mentioned that thermomechanically 
treated QT steel has a very high earthquake 
resistance. In terms of earthquake resistance, TRIP 
steel is one step ahead compared to that of QT group. 
The reasons of this superiority of TRIP steel over QT 
will be discussed now. QT steel is produced by 
dynamically quenched in water, which results 
tempered martensite. This tempered martensite is not 
completely residual stress free. So, having similar 
chemical compositions, corrosion resistance of TRIP 
steel is better than that of QT steel. Improper 
quenching and tempering might cause brittle zone on 
the surface areas of QT steel. In such case, if there is 
any surface imperfection, then QT steel might behave 
as a notched or brittle material and subsequently 
result lower fatigue limit as shown in Fig. 16. But 
TRIP steel, from surface to core, has uniform 
microstructures with higher ductility level having no 
particular zone with residual stress. Moreover, for 
conventional or QT steel total applied load is 
absorbed by elastic and plastic deformations. As a 
result, continuously, dislocation pile-up causes easy 
and early necking with subsequent failures in the case 
these steels. On the other hand, TRIP steel is not very 
soft like conventional carbon steel or very hard like 
conventional alloy steel bars or tempered martensite 
of surface layer of QT steel. As a result, total 
elongation related to elastic and inelastic deformation 
of TRIP steel is expected to be of moderate type. In 
the case of TRIP steel, another source of elongation 
is due to its strain-induced plasticity. During 
monotonic (e.g. like uniaxial Fig. 17) or cyclic  
800 
600 
400 
200 
   0 
0 400 800 1200 1600 
Scatter Band of Fatigue 
Limits of Ductile Steels 
For most Steel Fatigue 
Limit  ≈ 0.5 of UTS 
Scatter Band of Fatigue Limits 
of Notched/Brittle Steels 
Ultimate Tensile Strength (UTS), 
Fa
tig
ue
 L
im
it,
 M
Pa
 
Fig. 16: UTS and fatigue limit relationship of ductile and brittle steel.  
Page 37
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 17: Transformation of retained austenite (empty or filled black 
circles) to martensite (red filled circles) under tensile loading of TRIP 
steel (a) initial stage, (b) just after necking and (c) after a significant 
amount of necking.  
(a)  (b)  (c)  
Fig. 18: Cyclic bending stress on TRIP steel sheet.  
Page 38
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
loading (e.g. cyclic bending, Fig. 18), when the 
applied load causes effective stress beyond the yield 
strength of any zone of the TRIP steel, retained 
austenite in this steel starts to transform, which is 
clear from XRD spectra presented in Fig. 19. This 
transformation of austenite ( 200 and 220 peaks) to 
bainite/martensite ( 110, 200 and 211 peaks) is an 
endothermic process, which needs some external 
energy. If the earthquake related strain causes 
sufficient stress on the TRIP steel bars and retained 
austenite  is  transformed  to  bainite  by  absorbing  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
fraction of shock energy of earthquake. As a result, 
effective shock energy to damage any structure will 
be somewhat lower. This behaviour of TRIP steel 
provides double guard for the buildings; I. by 
absorbing certain fraction of earthquake related 
stress, which will ultimately reduce the effective 
intensity of earthquake and II. transformation of   
austenite to bainite strengthens the steel (14-16). 
Altogether, the fatigue property of TRIP steel is 
really excellent. As a result, TRIP type structural 
steel shows better fatigue life, which is many times 
higher than that of the conventional steel having 
similar level of tensile strength, Fig. 20.    
Fig. 19: XRD spectra showing the retained austenite transformation in TRIP steel (a) 
before fatigue test and (b) after fatigue test. 
Page 39
  
 
 
 
 
 
 
 
From Fig. 20 it is clear that TRIP steel provides 
approximately ten times of fatigue life compared to 
that of conventional steel and that the fatigue limit of 
the TRIP steel is also nearly double. 
3.  CONCLUSIONS  
Reinforcing steel bars play the vital role for the safety 
of the structural buildings. In the case of earthquake 
resistant structural buildings, a large amount of 
reinforcing steel bars is used. If conventional hot 
rolled steel bars are used, the steel consumption   will 
be rather high, which is not good from earthquake 
point of view. Because, heavy consumption of steel 
bars makes the structure to be relatively bulky and 
that earthquake related damage is proportional to the 
overall weight of the structure. High strength low 
alloy steel bars made from secondary steel are also 
not good because of their low ductility and poor 
bendability levels. In this situation, use of 
thermomechanically treated high strength and high 
ductility steel bars might provide necessary solution. 
Use of QT type thermomechanically steel bars will 
reduce the overall weight of the structure and risk of 
earthquake related damage. In this regard, TRIP type 
thermomechanically treated steels  provide extra 
benefit as it absorbs a certain fraction of the 
earthquake energy when they experiences 
deformation by endothermic phase transformation 
and causes reduction in the intensity of the 
earthquake.  
 
 
 
 
 
 
 
 
 
 
 
4.  REFERENCES 
1.   Jha, G., Sing, A.K, Bandyopadhyay, N .and 
Mohanty, O.N., (2001), “Seismic Resistant 
Reinforcing Bars”, Journal of Practical Failure 
Analysis, 1(5), pp. 53-56.  
2.     Otani, S., (2001), “Earthquake Resistant Design 
of  Reinforced  Concrete  Buildings”,  Keynote 
         Paper of 1st International Conference on 
Concrete and Development, at Tehran, Islamic 
Republic of Iran. 
3.  Australian/New Zealand Standard for Steel 
Reinforcing Materials, AS/NZS 4671, 2001.  
4.      M.A. Saleem and M. Ashraf, (2008),“Low Cost 
Earthquake Resistant Ferrocement for Small 
House” Pakistan Journal of Engineering and 
Applied Science, 2, pp. 59-64. 
5.  Commonwealth Report, (2001), “Earthquake 
Resistant Construction in Developing 
Countries” Commonwealth Hazard Centre 
News Letter, 4(3), pp. 1-8. 
6.    T.L Anderson, Fracture Mechanics 
Fundamentals and Applications, Second 
Edition, CRC Press. 
7.   G.E. Dieter, Mechanical Metallurgy, SI Metric 
Edition, McGraw-Hill Book Company. 
8.  Takashi, M., Kawano, O., Hayashida, T., 
Okamoto, R. and Taniguchi, H., (2003) “High 
Strength Hot-rolled Steel Sheet for 
Automobiles”, Nippon Steel Technical Report  
88, pp. 1-12..  
9.    Beynon, D., Jones, T.B. and Fourlaris, G., 
(2005), “Effect of High Strain Rate 
Deformation on Microstructure of Trip Steels 
Tested Under Dynamic Tensile Conditions”, 
250
300
350
400
450
500
1.E+04 1.E+05 1.E+06 1.E+07 1.E+08
Cycles, Nf
M
ax
im
um
 S
tr
es
s,
 M
Pa
 
TRIP Steel Conventional Steel 
250
300
350
400
450
500
1.00E+04 1.00E+05 1.00E+06 1.00E+07 1.00E+08
Fig. 20: Comparison of fatigue lives of TRIP and conventional structural steels having similar 
level of strength. 
Page 40
Materials Science and Technology, 21(1), pp. 
103-112. 
10.   Tomota, Y., Tokuda, H, Adachi, Y., Wakita, M., 
Minakawa, N., Moriai, A. and Morii, Y., (204), 
“Tensile Behavior of TRIP-aided Multiphase 
Steel Studied by In-situ Neutron Diffraction”, 
52, pp. 5737-5745. 
11.   Hulka, K., (2005), “The Role of Niobium in 
Cold Rolled TRIP Steel”, J. Materials Science 
Forum, 473, pp. 91-102. 
12.  Panigrahi, B.K., Srikanth, S. and Sahoo, G., 
(2009), “Effect of Alloying Elements on 
Tensile Properties, Microstructure and 
Corrosion Resistance of Reinforcing Bar Steel”, 
J. Mat. Engg. Perform., ASM International, 18, 
pp. 1102-1108. 
13.   Manoharan, R., Jayabalan, P. and Palanisamy, 
K., (2008), “Experimental Study on Corrosion 
Resistance of TMT Bar in Concrete”, ICCBT, 
pp. 239-250. 
         14.   Islam, M.A., Chain, S. and Tomota, Y., (2007), 
“Tensile and Plane Bending Fatigue Properties 
of Two TRIP Steels at Room Temperature in 
the Air- A Comparative Study” Published in the 
Journal of Materials Engineering and 
Performance, ASM International, 16(2), pp. 
248-253. 
         15.  Islam, M.A., “Structure and Properties of 
Thermomechanically Treated TRIP Steel”, 
(2008), BSME-ASME Conference, Held in 
Dhaka, pp. 245-251. 
16.  Islam, M.A. and Tomota, Y., (2006), “Plane 
Bending Fatigue Behaviour of Interstitial Free 
Steel at Room Temperature” International 
Journal of Materials Research (formerly 
Metallkunde, German), 97(11), pp. 1559-1565. 
Page 41
 TEA INDUSTRY OF BANGLADESH – PAST PRESENT AND FUTURE 
Dr. Mainuddin Ahmed 
Chief Scientific Officer 
Bangladesh Tea Research Institute, Srimangal, Moulvibazar, Bangladesh 
 
1.0 Introduction 
History of tea as a beverage for human traces back to the Chinese civilization as well as to the 
monks who were preaching Buddhism from India to China. Its botany had its first natural footholds 
in China and India - rather Indo-China. During its thousands of years of drinking history from 
dynastic royal people to the down-to-earth common people, it is not only the cheapest beverage but 
also an established health drink based on scientific supports. At present, this crop is grown in more 
than 50 countries around the world from Georgia 43° N latitude to Nelson (South Island) in New 
Zealand 42° S latitude and from sea level to 2300 m above mean sea level. Tea’s journey of 
commercial cultivation in Bangladesh started only in one and a half centuries ago flourishing to its 
present status. 
 
The geographical location of growing tea in Bangladesh is only restricted to some green specks 
between 21°30´ and 25°10´ north latitude and between 91°10´ and 92°41´ east longitude. Tea is an 
important commodity of international trade. It is a major cash crops as well as an export item of 
Bangladesh. The industry and related trade is providing employment for about 0.2 million people. 
An overview of the world tea vis-a-vis Bangladesh tea is presented in Table.1 
 
Table 1. World Tea vis-a-vis Bangladesh tea – an overview  
Country Area Production Export Yield 
(kg/ha) 000ha % Position mkg % Position mkg % Position 
China 11613 50 1st 1200 31.5 1st 297 18 2nd 700 
India 575 16.8 2nd 981 26 2nd 193 12 3rd 1707 
Kenya 149 5 4th 370 10 3rd 383 23.4 1st 2190 
Sri  Lanka 189 6 3rd 305 8 4th 297 18 2nd 1697 
Turkey 79 2 7th 178 5 5th 4.5 0.3 11th 1987 
Indonesia 134 4 5th 150 4 6th 96 5.9 5th 1038 
Vietnam 93 3 6th 148 4 7th 104 6.3 4th 1237 
Japan 47 1 9th 100 3 8th 1.8 0.1 12th 1938 
Argentina 37 1 10th 90 2 9th 77 4.7 6th 1895 
Bangladesh 54 2 8th 58 1.5 10th 8.4 0.5 10th 1236 
Malawi 19 1 13th 48 1 11th 47 3 7th 2581 
Uganda 23 1 11th 45 1 12th 42 2.6 8th 1792 
Tanzania 23 1 12th 35 1 13th 24.8 1.5 9th 1391 
Others 241 1 - 158 4 - 109.5 6.7 - 771 
Total 3276 100 - 3795 - - 1549 100 - - 
 
Page 42
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
2.0 Historical perspectives 
2.1 Origin of tea 
Like many other crop plants, it is believed that tea plants originated somewhere in North of China, 
probably in Central Mongolia and disperse two directions. The China variety Camelia sinensis (L.) 
var. snensis O. Kuntze spread towards the South-East direction of China along the river Mekong 
while the Assamica variety dispersed in South-West direction along the river Irrawady from 
secondary point in South China (Fig.1).  
 
From there it migrated southwards to Central China. Tea was used as early as 3500 B.C. in China 
mainly as a medicinal drink. Later it became a common beverage. With the spread of Buddihism 
tea was introduced in Japan around 600 A.D. Its use, however, remained confined to these two 
countries for a long time. Tea was introduced to the West only in 1700 A.D. The generic name of 
Camellia was given after George Joseph Kamel, a German missionary in the Philippines from 1661 
to 1706, who wrote on plants in Asia. Robert Sweet (1818) united both the genera Thea and 
Camellia in to one genus Camellia. In Sixth International Botanic Congress held at Amsterdam in 
1935, Camellia was finally adopted as the correct name for the genus (Bezbarua, 1999).  
     
 
 
The increasing popularity of tea all over the world induced countries like India and Indonesia to try 
tea cultivation with the “china” variety, which made little success. But another variety “assamica” 
was known to the people of North-East India and Northern Myanmar (Burma) science pre-
historical times. Only in early eighteen century it became known to the outside world and later this 
variety was successfully grown in other countries. 
1 
1 
Page 43
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
Another variety known as “cambod” from South-East Asia was also known for a long time and was 
introduced to the outside world in the beginning of 19th century. Upper Burma, Northern part of 
Thailand together with Southern part of Yunnan province of China, are considered to be the 
original home of tea and the people of the region had been using tea for a long time. However, 
organized cultivation in Burma and Thailand was not done.  
 
In India, the British tried to introduce tea from the middle of the 18th century. In 1780, seeds from 
China were brought by a captain of East India Company and were tried at Sibpur Botanical Garden 
in Calcutta by Lt. Kyd. On the basis of the results obtained at Sibpur, the first practical step 
introduced tea in India taken by Sir Joseph Banks in 1788. However, it took a considerably long 
time to take final decision on the matter ultimately in 1834, a Tea Committee was appointed by Sir 
William Bentinck, the Governor General of India, to organized a tea cultivation in India. George 
James Gordon, who was appointed as the secretary to the committee was sent to China to procure 
tea seeds and plants. He brought back some seeds in 1835. These seeds and later consignments 
from China by different collectors were grown in Assam, the Kumaon Hills and in the Nilgiris. 
This process of seed consignments from China continued till the middle of sixties, in spite of the 
discovery of indigenous Assam tea in 1823. 
 
Major Bobert Bruce reported about the “Assam” tea plant presented to him by a Singpho Chief. Lt. 
Charlton, raised these plants and sends some specimen to the Agri-Horticultural Society of Calcutta 
in 1831. C.A. Bruce, who was maintaining the nurseries for the Tea Committee, also maintained 
the nursery of the “Assam” plants, an extension of the original started in 1825 by Robert Bruce.  In 
1836, a small sample of tea prepared from these “Assam” plants was sent to Calcutta for evaluation 
and was “Pronounced good”. A year later, a large sample of “Assam” tea was prepared and sent to 
the Govt. of India. The Governor General was pleased to observe that the tea would be considered 
as a marketable quality. In March 1838, the Tea Committee despatched 12 boxes of tea to London. 
The tea was first put up to auction in London in January 1839, and the Court of Directors 
commented the samples of “Assam” tea were satisfactory. 
 
During the early years, when tea was first introduced to India most people associated with tea 
cultivation, were under the impression that only China tea bush could produce real tea and believed 
that “Assam” variety will never be able to compete with the “China” tea. This incidence, therefore, 
marked the turning point for the tea industry in India as well the whole world. The indigenous 
“Assam” plants came to the forefront as equally good source of commercial tea as its competitor 
from China and plantations were successfully established in different parts of Asia, Europe, Africa, 
America and Australia (Fig. 1).  
 
2.2 Gamut of Bangladesh Tea 
Tea plantation started in Bangladesh in the early 1840’s. The early history of our tea is the history 
of tea in North-East India, to be more precise the Surma valley. The period 1827-1857 is very 
important in terms of beginning of tea in this Sub-continent in general and in present Bangladesh 
region in particular. The end of the period marks the beginning of extensive tea cultivation both in 
greater Chittagong and Sylhet districts. The introduction of tea in Chittagong dates from 1839-40. 
Page 44
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
The plant types were mainly hybrids but there were some Assam indigenous as well as China types. 
Mr. Sconce, the collector of the district, first received some tea seeds from Assam and some plants 
from China from the Calcutta Botanical Garden and planted them. The first tea plantation in 
Chittagong was rightly named ‘Pioneer’. The first tea plantation established in Sylhet was at 
Malnicherra in 1854 and it still exists as an estate. This was the beginning of tea plantations in 
Sylhet (Zaman, 1989).  
 
3.0 Bangladesh tea at present  
Bangladesh tea has undergone a radical metamorphosis since founding of a tea estate in the British 
period to the present day status of the whole industry. Towards the close of the nineteenth century, 
the development was directed to the creation of many limited liability companies dominated by the 
British entrepreneurs. It is important to analyze the growth of Bangladesh tea industry in respect of 
area, production and yield against in time of retrospect for rational future planning for increase in 
area, production and yield (Table 2).  
Table 2. Area, production and yield of tea in Bangladesh at different periods 
 
Year 
Area (ha)  Production (mKg) Yield (Kg/ha)   
Remark Total Increase/ 
Decrease* 
Total Increase/ 
Decrease* 
Total Increase/ 
Decrease* 
1947 30353  - 18.88  - 622  - At partition of India  
1957 31287  +    934  25.55 +  6665  817  + 195 Pre-mandatory extension period 
1970 42688  + 11401  31.38 +  5832  735  -   82 Upto Pre-liberation period 
1980 43732  +  1044  40.04 +  8657  916  + 181 Pre-BTRP status 
1992 47781  +  4049 48.93 +  8892 1040  + 124 Closing of BTRP status 
1998 48735* +   954 55.82 +  6894 1145 + 105 BTRP Impact 
2001 50974 +  2239 56.82 +   996 1115 -   30   
2003 52202 +  1228 59.21 +  2390 1247 + 132   
2006 53350 +  100 53.10 -  6510 1001 -  284 Drought Year 
2007 53500 +  150 57.25 + 4152 1109 + 235   
2008 53570 +    70 58.65 + 1398 1236 +  75 Drought Year 
2009 53000 -   570 60.00 + 1340 1300 +  64 Drought Year 
 
Source: Bangladesh Tea Board, PDU and BCS (2009), (Area in Hectare, production in million kilogram, Yield in kg/ha)  
 
3.1 Ecological Zones 
Bangladesh tea grows in three fairly divergent ecological zones- namely Surma valley in greater 
Sylhet, Halda valley in Chittagong and Karatoa valley in Panchagarh (extreme north-west of 
Bangladesh).      
 
3.2 Management category 
Tea gardens in Bangladesh are under diverse management ownership. 27 tea estates are managed 
by Sterling companies consisting of Messers James Finlay, Duncun Brothers (Bangladesh) Ltd., 
and Deundi Tea Co. Ltd., 13 TEs run by the National Tea Co. (NTC) which is a public limited 
Page 45
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
company where the government owned institutions have the majority of shares. There are 120 TEs 
which are either proprietary or owned by local companies and 3 estates are managed by Bangladesh 
Tea Board under Ministry of Commerce.  
 
3.3 Agroclimatic conditions 
Bangladesh is situated in the tropical monsoon climatic zone with three distinct seasons. Warm 
season (mid-February to mid-May), Monsoon season (mid-May to mid-October) and Cold season 
(mid-October to mid-February). The year begins and ends with dry periods. The climate of 
Bangladesh tea area can be classified regime-wise under four important parameters: rainfall, 
temperature, humidity and sunshine which are responsible for successful tea culture (Sana, 1989).  
 
3.3.1 Rainfall  
The quantitative and qualitative rainfall pattern in Bangladesh is zonal. The annual rainfall ranges 
from 1400mm to 4500mm. Chittagong and & Hill districts receive rainfall not exceeding 3000mm. 
The tea growing area of Sylhet and Chittagong fall in the wet area. Tea zones experience dry 
season from Nov. to April while the rainy season continues from May to October and above 80 
percent of annual rainfall is obtained during June-September. The quantity of annual rainfall is 
higher in North Sylhet circle and is reduced in the lower western valley, the Luskerpur circle. 
 
Reliable meteorological data can be utilized in the prediction of a crop like tea which can be 
understood from an example of a statistically analytical work at the Institute using information on 
rainfall. A crop forecast model based on rainfall pattern for the valleys in Sylhet has been 
developed from available data from 1978-87 (BTRI Biennial Rept. 1993-94). The models that have 
been derived under this study for forecasting the annual production of tea are not permanent ones, 
but are subject to change, when data of more consistent production contributory factors over a 
period of considerable years are included in the model under changed circumstances.     
 
3.3.2 Temperature  
In Bangladesh, temperature becomes generally highest in April or May, drops slightly during 
monsoon period and gradually falls after September or October. Prolonged drought occasionally 
occurs after November or December when rain is meager. In the tea areas of Sylhet, Chittagong and 
Panchagarh, temperature reaches up to a maximum of 40oC. On the other hand, the extreme 
minimum in Chittagong zone drops to the extent of 7.8oC to 8.9oC. 
3.3.3 Humidity-Evaporation  
Relative humidity is generally the highest during night, eases in the morning and is lowest during 
midday. Average monthly humidity approaches 90% during the monsoon months of June through 
October falling to 65% for March. An overall relative humidity in Sylhet and Chittagong Tea zone 
varies from 56 to 80% and 68 to 80%, respectively. It is also known that the rainfall in tea zones 
exceeds evaporation during the greater part of the year. A deficit of water balance occurs normally 
from October end until April. Water-stress usually develops after January and lasts up to the first 
week of March. The overall picture of evaporation regime of Bangladesh shows a primary 
maximum between April and May when temperature conditions over the country are at the highest. 
Page 46
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
A secondary maximum appears at random, even during the period of high rainfall or after it has 
began to recede. In December -January evaporation is the lowest when temperature is also lowest. 
Sylhet and Chittagong tea zones, however, experience less evaporation than the northern districts of 
Bangladesh. 
 
3.3.4 Sunshine  
The intensity and duration of sunshine has also an important influence on the growth of tea plants. 
It appears that winter dormancy in tea occurs only in those tea areas that are at higher latitudes as 
tea is sensitive to the day length (photoperiod). Day length is the shortest in December, the average 
lowest being 10.6 hrs to average longest in June, being 13.7 hrs. The hours of bright sunshine are 
fewer in the rainy season of Bangladesh due to the overcast clouds. 
 
3.4 Characteristics of Bangladesh Tea Soil 
Tea may be grown on soil of diverse geological origin. In Bangladesh most soils are quaternary and 
recent alluvia. There are many soils, formed in situ from the genesis and sandstone below. Tea soils 
are highly weathered, extremely acidic and low fertility status. Furthermore these soils do not 
receive deposits of fertile silt by flooding, rather they suffer from erosion. The soils are medium 
textured with low contents of organic matter and nitrogen. Mineralogical studies of Bangladesh tea 
soil have shown that it consists of kaolinite, quartz, hematite, geothite and gibsite types minerals. 
Besides, Bangladesh tea soils contain over 85% aluminum in the exchangeable sites (Ahsan, 1984) 
and its high concentration is known to interfere in the uptake of essential nutrients such as Ca, P, 
Mg and Fe and produce some deficiency symptoms and aluminum toxicity. In tea soils of 
Bangladesh, an overall content of nitrogen and organic matter varies respectively from 0.07 to 0.09 
per cent and 1.0 to 1.2 per cent. The critical values have been fixed at 0.1% for nitrogen and 1% for 
organic matter. The amount of available phosphorus, magnesium and base-saturation is low. The 
minimum level (critical level) of nutrient status of tea soil should be 10µg/g for P, 80µg/g for K, 
25µg/g for Mg and 90µg/g for Ca. The C-N ratio should be 10. The most suitable tea soil is thought 
to be light friable, well drained having soil pH ranging from 4.5 to 5.8.   
 
3.5 Tea populations and plant type 
Since the British era, the plantations raised here, had some common ancestry as those in N.E. Due 
to local adaptation and selection pressure, only a few types particularly dark to semi-dark green and 
medium to large leaf plants become preponderant. In course of time, many seed orchards were 
established which mothered the seedling populations. Dark leaf hardy Assamica variety with 
intermediate leaf size and early flushing habit was the specialty of many seed jats in Bangladesh. In 
recent assessment, it has been calculated that out of the total tea plantation at least 80% are still 
seedling tea, the rest 20% being clonal plantation comprising largely of eighteen high yielding and 
quality clones and four biclonal seed stock released by BTRI, some garden clones and a few 
introduced clones. Thus seedling tea has been and will continue to play a dominating role in 
limiting the tea production in near future too (Alam, 1994).  
Page 47
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
3.6 Fertilizer use in tea                         
The use of fertilizer in Bangladesh tea is indispensable where deficiencies of major and minor 
nutrients are easily recognized. A huge amount of nutrients are being lost from the soil due to high 
rainfall, leaching fixation, crop removal, volatilization, evapo-transpiration etc. So the different 
essential nutrients in the form of inorganic fertilizer must be added to the soil in order to enrich the 
soil with balanced nutrients and make up the deficiencies of nutrients in the plant.  
During Nineteen sixties ammonium sulphate alone had been used in tea as the only source of 
nitrogen as inorganic fertilizer. Later on different tests and trials on tea soils proved beyond doubt 
that the pH of tea soil has dropped drastically to a point, where no sulphate of ammonia should be 
used any further (Choudhury, 1983) because, this acid forming fertilizer sulphate of ammonia is 
responsible for strong acidity of soil. Then from 1978 onwards, the other source of nitrogen from 
urea was searched out. Different trials on the use of urea and singly or in combination with sulphate 
of ammonia were conducted in Bangladesh tea soils. Significant increase in yield had been obtained 
on the use of urea alone and in combination with sulphate of ammonia than sulphate of ammonia 
alone.  
3.7 Tea Agro-techniques 
Tea production-technology involves various agro-techniques which may be broadly put under two 
management components, viz. Nursery Management and Crop Management. The methods of 
propagation and multiplication of tea seeds, cuttings, saplings etc are included under the nursery 
management, while the crop management embraces various field techniques of bringing up tea, 
ancillary crops that are intended to exploit the highest possible productivity from a tea plantation.  
 
In the sixties with the spacing of 120 cm x 75 cm to 120 cm x 60 cm depending on topography, 
population range of 11,000 to 14,000 plants/ha and three and four year pruning cycle were the 
conventional recommendations. With the change of time, like many other tea growing countries, 
from long term results, spacing from 120 cm x 75 cm to 90 cm x 60 cm with a population load of 
15,500 to 18,000 and four-year pruning cycle have been adopted to increase the productivity of tea 
(BTRI Annual Report, 1992).  
 
3.8 Tea Pest Management 
Tea crop protection is an essential component of tea husbandry to safeguard tea plants from the 
ravages of a multitude of pests, diseases and other maladies. Pest management implies the 
regulation of pest-activity by adopting suitable methods so as to minimize their effects and 
maximize the activities of benefactors.  
 
Bangladesh tea eco-system comprises tea, shade trees, green crops, forest etc. The intensive 
monoculture over 150 years had formed a stable eco-system which provided unlimited opportunity 
for perpetuation and spread of endemic or introduced pests. Therefore, management of tea pests 
posed a more complex challenge than any other crop in Bangladesh. So far 25 insects, 4 mites, 12 
nematodes, 18 fungal and 1 algal diseases and 37 preponderant weed species have been recorded 
(Ahmed, 2005). Crop loss caused by pest attack is reported to be about 15% annually (Ahmed, 
Page 48
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
1991). The overall pest spectrum of Bangladesh tea is similar to that of the Brahmaputra valley, 
Assam. It seems that most of the major pests and diseases of tea have been introduced initially from 
the contiguous areas of Cachar, Assam or from the legacy of forest trees and wild or cultivated 
plants in this area. Red spider mite, Tea mosquito bug and Termite predominate and are widely 
distributed in all valley circles. Other pests like Flushworm, Jassid, Aphid, Scarlet mite, Blister 
blight disease are found to be restricted in localized areas or ecological zones.  
 
Looking back into the early records of tea pest control history, natural product e.g. tobacco extract, 
liquid cowdung, muddy water and lime sulphur were the principal materials for pest control. With 
no exception in other tea growing countries, in Bangladesh also chemical control has been a 
dominating feature in pest control of tea and passed through three generations of pesticides. The 
first generation chemicals-DDT and its other analogues dominated till 1970. Now they are banned. 
Only Endosufan is permitted on plucking tea whose MRL of 30 ppm is approved by EPA, Codex 
Alimentarus and FAO/WHO. Second generation of organo-phosphorus compounds (Ethion, 
Malathion etc.) and Carbamate (Cabaryl and Carbofuran) introduced since 1960 were only used 
where the pest became resistant to organo-chlorine compounds. Synthetic pyrethroids, the third 
generation pesticides, were introduced in 1980. Besides these three generations of pesticides, a 
fourth generation is in the process of coming up which consists of bio-pesticides like neem or its 
derivatives and other indigenous plant extracts; Bacillus thuringiensis (BT), insect juvenile 
hormone, etc., but they are yet to be introduced on a commercial scale in Bangladesh tea (Ahmed, 
1991). BTRI underscores adoption of IPM with cultural practice and biological control as much as 
possible within the purview of decision analysis techniques.  
 
3.9 Bio-chemical 
 
Biochemistry refers to the chemical reactions initiated due to synthesis and burning of foods for 
live process. The biochemistry of tea is started during soaking a tea seed for germination and 
ceased during firing of tea. Tea leaves and made tea contain several chemical compounds having 
nutritional and medicinal values, such as, caffeine, polyphenol and alkoloids- catechins (Table 3). 
This is the caffeine that acts as a mild stimulant, while polyphenols contribute to colour and 
strength of the liquor. Other non-addictive drugs, such as theobromine, theophylline, useful 
fluorides, volatile oils and vitamins are also present. Quality of black tea depends on mainly the 
polyphenolic compounds obviously it is great interest of black tea manufactures to search and 
exploit for the quality production. 
 
Page 49
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
Table 3: Chemical components of black tea of nutritional and pharmacological importance 
 
Chemical components Approximate quantity in a cup mg (3g/150ml) 
Unoxidised catechins  
(epigallocatechins, purins) 
25-50 
Theaflavins 12-60 
Thearubigins 200-500 
Caffeine 60-120 
Lysine 0.7 
Threonine 0.7 
Leucine/ Isoleucine 3.0 
Phynailalanine 3.0 
Valine 3.6 
Potassium 50 
Phosphorus 3.0 
Calcium < 1 
 
3.10 Tea Processing 
In any food production process, the quality of the final product depends largely on the quality of the 
input material and the processes involved in obtaining the final product. Tea is not an exception. 
With the evaluation of newer generations of tea machinery, at different times and its revolutionary 
impact on tea processing with inevitable influence on tea trades elsewhere, Bangladesh is no 
exception. The age old orthodox process of manufacture showed a declining trend in the early 
sixties with the introduction of Legg-cut and CTC (Crush, Tear and Curl) process of manufacture. 
However, the Legg-cut process was very short lived, so the orthodox process rose up to 60% in the 
mid seventies, whereas the CTC process of manufacture continued to gain popularity at a faster rate 
until it reached a peak of about 99% of the total manufacture today. The starting material in black 
tea processing is the young shoot, the terminal bud and the two adjacent leaves. The salient features 
of black tea manufacture involve following operations, viz. plucking and handling of tea shoots, 
Withering, Processing, Fermentation, Drying/Firing, Sorting and Packaging.  All these operations 
call for the necessary of meticulous care and technology maneuvers to produce a better quality tea. 
Amongst the steps, fermentation is the most important to be considered upon which quality of tea 
and hence the earnings of the factory depends. The flush is processed in distinct stages. Each stage 
involves characteristics changes in the physical and biochemical composition of the leaves and the 
cumulative effects of these changes are ultimately reflected the quality of the finished product, 
namely, the black tea. Today’s Bangladesh tea production and trade both domestic and export are 
determined by CTC teas. But the prospect of Bangladesh tea in next millennium will depend on the 
capacity and timely adoption of advanced manufacturing technology of better performance and 
economy.  
 
3.11 Trends in production, consumption, export and projections up to 2010   
 
Tea in Bangladesh had been an export oriented product with domestic consumption having a minor 
share. Now because of population growth and rapid urbanization, the internal consumption is 
increasing faster and by 2020 will far supersede the export share. At present land utilization for tea 
is about 42% of the allotted land for tea estates.  
 
Page 50
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
Past progress and trend of land coverage and growth in yield, production, consumption and export 
have been reviewed. On this basis a conservative and easily achievable target of 58,000 ha covering 
50% cultivation with tea has been set which will produce about 94 million kg of tea by 2020. The 
national average in yield is expected to rise over 1600 kg/ha although a few organized management 
units have already exceeded, or are about to reach the mark. The projections in area, production, 
consumption and export up to 2020 have been furnished in Table 4 and trend thereof in Fig. 2. 
There should be two dimensional thrusts i.e. horizontally by increasing plantation area and 
vertically by increasing per hectare production through introduction of high yielding quality clones 
and seeds, efficient use of recommended fertilizer, improving agronomic practices, control of pest 
and diseases, etc. 
 
Table 4. Target plantation area, yield, consumption and export up to 2020   
Year Area  
(ha) 
Yield  
(Kg/ha) 
Production 
(mkg) 
Consumption 
(mkg) 
Export  
(mkg) 
1995 48,000 10.42 50.00 25 25 
2000 50,000 11.75 56.82 39 17.82 
2005 53,000 12.47 59.21 49 10.21 
2010 55,000 12.45 60.65 54 6.65 
2015 60,000 14.50 70.62 69 1.62 
2020 65,000 15.20 82.34 82 0.34 
 
Fig. 1. Target of area, yield, production, consumption and export in 
Bangladesh tea
0
10
20
30
40
50
60
70
80
90
1995 2000 2005 2010 2015 2020
Year
Area ('000'ha) Yield (Kg/ha) Production (mkg)
Consumption (mkg) Export (mkg)
 
 
4.0 Tea Industry Related Organizations 
4.1 Government Organizations 
4.1.1 Bangladesh Tea Board (BTB) 
Bangladesh Tea Board is a statutory body constituted under the Tea Ordinance 1977 to regulate, 
control and promote the cultivation and sale of Tea in Bangladesh. Tea industry in this part of the 
sub-continent was controlled by the Indian Tea Cess Act, 1903 till partition in 1947. An eleven 
2 
Page 51
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
member Pakistan Tea Board with a five member Pakistan Tea Licensing Committee was 
constituted in 1951 under the Pakistan Tea Act, 1950. This Act was repealed by the Tea Ordinance 
1959 and an eleven member Tea Board with the provision of a five member Tea Development 
Committee was constituted. After the independence of Bangladesh, Tea Ordinance, 1977 was 
promulgated constituting Bangladesh Tea Board of three whole time members with the provision of 
an Advisory Committee to be formed by the Government with not more than twenty five members. 
Later the members of the Board were raised to eleven by the Tea (Amendment) Ordinance, 
1986.The Head Office of the Board was in Dhaka till it had been transferred to Chittagong in 1984. 
The Board consists of the following members 
 A Chairman to be appointed by the Government 
 Two full time members to be appointed by the Government 
 Chairman, Bangladeshiyo Cha Sangsad, ex-officio 
 Chairman, Tea Traders Association of Bangladesh, ex-officio 
 Joint Secretary (Export), Ministry of Commerce, ex-officio 
 Commissioner, Chittagong Division, ex-officio 
 Chief Conservator of Forests, ex-officio 
 One member to be appointed by the Government from among tea brokers 
 Two members to be appointed by the Government from among tea planters. 
 
The main functions of the Board 
 To regulate, control and promote the cultivation, sale and export of tea. 
 To control and improve the quality of tea. 
 To conduct comprehensive scientific and technological research to raise productivity of tea and 
improve its quality. 
 To register tea estates with the Board and grant licenses to the planters, manufacturers and other 
dealers engaged in the business of tea. 
 To assist establishing new tea gardens and improving productivity of existing tea gardens. 
 To undertake welfare measures for tea garden laborers and employees. 
 To undertake, acquire or manage any tea concern or to take such measures in the interest of the 
tea industry as directed by the Government, from time to time. 
 
4.1.1.1 Bangladesh Tea Research Institute (BTRI) 
Bangladesh Tea Research Institute (BTRI) is the research wing of Bangladesh Tea Board engaged in 
conducting comprehensive scientific, technological and economic research for the Tea Industry. It 
has provision for 182 personnel including research and technical staffs. It was initially established 
by the Board in 1957 at its present location in Srimangal as Research Station to provide technical 
support to the Tea Industry and subsequently was converted into a full-fledged Research Institute in 
1973. Now it has three major research departments with 6 divisions as under Department of 
Chemistry comprising Soil Science and Biochemistry Divisions, Department of Crop Production 
comprising Botany and Agronomy Divisions, Department of Pest Management -comprising 
Entomology and Plant Pathology Divisions. It has two more research divisions namely, Tea 
Technology Division and Statistics-Economics Division.  
Page 52
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
4.1.1.1.1 Mandate 
 Conducting research – strategic and basic 
 Conserve gene resources 
 Man power development 
 Advisory & extension services 
 Scientific linkage – national and international 
 Develop information and communication 
4.1.1.1.2 Objectives 
 To increase yield  and improve quality of our tea  
 To render advisory service to tea industry 
 To transfer  technologies to the tea industry 
4.1.1.1.3 Some research innovations 
 
4.1.1.1.3.1 Varietal Improvement 
 
 Eighteen clones of high yield and quality evolved and released. 
 Four hybrid tea seed of biclonal stocks developed. 
 General seed stocks re-evaluated and ten good seed orchards registered.  
 Gene bank being established for germplasm conservation. 
4.1.1.1.3.2 VP Techniques 
 Standardized vegetative propagation (VP) techniques for tea. 
 Nucleus clone plot establishment and management determined. 
 
4.1.1.1.3.3 Tea Soil Management 
 Fertilizer policy for mature tea and young tea upgraded on yield basis. 
 Management of soil properties like texture, structure, organic matter, ph, nutrients, etc. established. 
 Critical values of nutrients in tea soil determined. 
 Replacement of SOA by urea as a cheap nitrogenous fertilizer. 
 Rock phosphate as economy fertilizer substitutes for other phosphatic fertilizers. 
 Soil rehabilitation methods recommended. 
 Proper soil mapping initiated. 
 Possible new areas surveyed. 
4.1.1.1.3.4 Agronomical Practices 
 Pruning cycle for optimum crop production determined. 
 Crop harvesting methods to optimize yield and quality of crop determined. 
 Ideal plant population, planting methods, pre-and post – planting practices determined 
 Grafting method for rapid mother bush establishment   determined. 
 
4.1.1.1.3.5 Tea Pest Management 
 Tea pest complex surveyed and major pests identified (insects, mites, nematodes, diseases and weeds). 
 Bio-ecology of major pests studied. 
 Biotic potential for three major pests determined. 
 Crop loss assessment for four major pests assessed (insects, mites, nematodes, diseases and weed). 
 Integrated pest management method optimized and decision.  
 Appropriate spraying technique and schedule determined. 
 Awareness on MRL of pesticides created. 
 Resistant agro types and vars. of tea to termite pest identified. 
 Compatibility of pesticides determined. 
 Few bio - control agents identified 
Page 53
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
4.1.1.1.3.1.6 Tea Processing 
 Performance of different preconditioning methods for CTC processing determined. 
4.1.1.1.3.1.7 Biochemical 
 Correlation between theaflavin level and temperature during processing and fermentation established. 
4.1.1.1.3.1.8 Statistics & Economics 
 Annual crop forecasting method determined. 
 Production cost of tea analyzed. 
 Economic size of a tea estate determined. 
 
4.1.1.1.4 Sub-stations 
BTRI has four sub-stations located at- 
1. Kality (Moulvibazar), 2. Sylhet, 3. Oodaleah (Fatikchari, Chittagong), and  4. Panchagarh 
 
4.1.1.1.4 Activities of Sub stations 
 Demonstration of zonal field experiments 
 Multiplication of improved planting 
 Materials and distribution 
 Zonal information and training venue 
4.1.1.1.5 Technology transfer to T,Es. 
Research is a complex process and involves trained scientists, technical assistants, equipments and 
materials. The output includes knowledge and technology packages. Productivity and cost 
effectiveness depend mainly on the effective dissemination of technology to the end users. 
Following are the official fora through which technologies are disseminated to the industry by 
BTRI. Annual courses, Routine visit, Request visit, Special visit and training. 
 
4.1.1.2. Project Development Unit (PDU) 
Project Development Unit is a wing of the Tea Board acting in the field of development with a 
separate office at Srimangal. It was established in 1980 as a component of the Bangladesh Tea 
Rehabilitation Project (1980-92) implemented with financial and technical assistance of Overseas 
Development Agency (ODA) & European Economic Committee (EEC). Its manpower with 51 
posts was absorbed in the revenue budget of the Board in 1988.The Board undertakes various 
development activities such as, preparation and implementation of development projects, assisting 
the tea estates in preparation and implementation of development schemes, monitoring of 
development activities of the tea estates, providing advisory services to the estates for 
dissemination of improved technology, imparting training to the management personnel of the tea 
estate, implementation of various labor welfare programs etc through PDU.  
4.1.2 Bangladesh Krishi Bank (BKB) 
Bangladesh Krishi Bank (BKB) is the only designated bank to provide both crop and along term 
development loan to tea industry. All grants/loans that had been provided by the UK Government 
and Bangladesh Government were channeled and continue to be channeled through BKB. BKB 
provides annually 180-220 crore taka as crop loan @ 10% interest to the tea industry. It has also 
provided long term development loan of around 200 crore taka to the tea industry from its own 
source. Re-payment of loans by the industry is well over 98% a credit to both the tea owners and 
the bank.   
Page 54
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
4.2 Non Government Organizations 
4.2.1 Bangladesh Tea Association (BTA) 
Bangladesh Tea Association is only the representing all owners of Tea Gardens of Bangladesh. The 
Association elects every two years a central committee from amongst its members who run its 
members who run the business of the Association. Its Head Office is in Chittagong. BTA interacts 
with the Government in such diverse issues as bank loans to land lease. BTA undertakes to 
negotiate wages for the staffs and workers of the entire tea industry with their respective unions. 
These wage agreements are negotiated every two years. It also settles disputes between tea 
companies and Labour Unions. BTA has two regional committees- Sylhet and Chittagong to after 
the interest of its members.  
4.2.2 Tea Traders Association of Bangladesh (TTAB) 
 
TTAB is the Association that represents the buyers of tea. Producers can also be its member. It has 
its Head office at Chittagong. TTAB along with BTB conduct and regulate the weekly Tea 
Auctions that is held every Tuesday at the Port City of Chittagong. TTAB and BTA maintain a 
close liaison and work jointly on many issues related to marketing of tea.  
5.0 Bangladesh Tea Rehabilitation Project (BTRP) 
During the war of liberation in 1971 the industry was severely damaged since most of the tea 
estates are on the international boundary between Bangladesh and India. As such the industry 
suffered a serious set-back after the liberation war due to high production cost, poor quality tea, 
competitive world market, low sale price etc. A number of studies were carried out to find out the 
ways and means to rehabilitate the war torn tea industry by various national and international 
committees and missions after the independence. On the basis of their recommendations the Govt. 
of Bangladesh took a massive development program in 1980 in the name of Bangladesh Tea 
Rehabilitation Project (BTRP) with the financial and technical assistance from British ODA, EEC 
& GOB.   
5.1 Effect of Bangladesh Tea Rehabilitation Project (BTRP) on tea industry 
This project has made a very positive contribution to the industry, which brought the present per 
hectare yield of Bangladesh tea to 1145 kg with the total production of 55.82 m. kg in 1998. The 
cost of production (COP) could be kept under control reasonably although the price of various 
inputs increased manifolds over the years. But the quality of tea attained a radical improvement and 
could easily be compared with the lower Assam tea. As a result of this achievement, Bangladesh 
tea now could find its way in the export market with remunerative price. Labour productivity has 
also been improved to a great extent and less absenteeism was observed. Health and education 
facilities in tea estates were improved reasonably. These altogether made tea industry more 
sustainable while the jute industry followed the path of peril.  
 
Page 55
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
5.2 Small holding tea cultivation concepts 
 
In most of the major tea producing countries viz. India, Indonesia, Kenya and Sri Lanka, the small 
holding tea cultivation co-exist along with the large estates and contribute significantly to the 
national tea production. The ideas of establishing small holding tea cultivation in Bangladesh were 
firstly formulated in the Tea policy for 1984-85. Thereafter few tea professional of the country took 
certain positive steps to promote small holding tea cultivation in Tetulia, Panchagarh district by 
forming a company titled Tetulia Tea Company Limited (TTCL) which is a private initiative 
(TTCL, 2000). A joint project of Bangladesh Tea Board and Rajshahi Krishi Unnayan Bank 
entitled “Development of Small Holding Tea Cultivation in Northern Bangladesh” with an 
estimated cost of Tk. 1096.70 lakh has been initiated in 600 ha area of Thakurgaon, Nilphamari, 
Lalmonirhat and Dinajpur districts within 8 years (2002-2009). Furthermore another project 
entitled “Small Holding Tea Cultivation at Chittagong Hill Tracts” with an estimated cost of 
Tk. 1070.21 lakh has been approved by the Government. The objective of the project is to plant tea 
100 ha in Rangamati, 300 ha in Bandarban and 100 ha in Khagracherri by organizing farmers to 
grow tea in small holding. Furthermore a development project entitled “Expansion of tea export 
by raising and distributing HYV clonal tea plants to the poor ethnic small growers of 
Bandarban hill districts” with an estimated cost of Tk. 93.60 lakh has been undertaken. It is 
mentionable that BTB has drawn up a 20 year Strategic Plan (2004-2023) for development of 
Bangladesh Tea Industry (Ahammed, 2007). Now there are 8 registered tea estates in Panchagarh 
district. The tea planters of Panchagarh produced 4 million kg of made tea from 908.90 ha area in 
2009. 
5.3 New tea area surveyed 
The feasibility study for growing tea in Small Holding at Jamalpur, Sherpur, Mymensingh and 
Thakurgaon has been done by BTB in 2004. It is found that 8522 ha of land are suitable for in these 
areas. These lands are unused now, which can be effectively used for tea maximizing incomes of 
the families. Besides, an area of 7822 ha is suitable in Lahagara to Cox’s Bazar, Satkania to 
Banskhali and Sitakunda to Mirsharai areas. These lands can also be brought under Small holding 
tea cultivation.       
 
6.0 Pesticide Residue Analytical Laboratory: An Institutional Development 
 
Pesticide residue in made tea means what is left over or remains of a pesticide in the made tea after 
the application of a pesticide to tea bushes in the field prior to plucking and subsequent 
manufacturing. As tea is a consumable commodity, the effect of residue of pesticides in made tea is 
harmful to human health. Tea produced in Bangladesh is exported to different countries of the 
world particularly West and East European as well as Middle Eastern countries. The consumers of 
these countries have become more conscious about the residue of the pesticides. In this perspective, 
EPA/ Codex Alimentarious/ FAO/WHO, German Law etc. have given restrictions on producing 
and procuring tea having pesticide residue. 
Bangladesh Tea Research Institute at Srimangal has established a well-equipped sophisticated 
pesticide residue analytical laboratory at its own premise and is run by trained personnel since 
Page 56
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
January 2003. All sorts of precision analyses of international standard of different groups of 
pesticides like Organochlorine, Organophosphate, Carbamate, synthetic Pyrethroid and some 
unclassified groups are done successfully. Standards of Good Agricultural Practices (GAP) and 
Good Laboratory Practices (GLP) are strictly followed. The facilities are now open to the tea 
industry and they have already started deriving benefit out of it. So the producers and traders should 
start scrutinizing their teas on regular basis at field, factory and trade points without delay. They 
should contact BTRI and harness the full advantage of the available facilities. The laboratory has 
already selected as one of the 11 laboratory by Intergovernmental Group (IGG) of FAO for ring 
tests to fix MRL in black tea globally (FAO, 2009). Pesticide residue analytical laboratory is 
equipped with Gas Chromatograph (Shimadzu GC-14B) with other necessary equipments.  
 
6.1 Role of Bangladesh tea producers and traders 
As tea is a consumable commodity, tea drinkers in advanced countries are quite conscious of health 
hazards out of pesticides in their food and drinks and tea is no exception. Even our domestic 
consumers are elevating their choice for such toxicity free food products. Choice for organic food 
has been getting momentum. A substantial portion of our tea is exported to western and middle-
eastern countries. We should be aware of these conscious markets. So our producers and traders 
should start scrutinising their teas at field, factory and trade points now. They should contact BTRI 
and harness the full advantage of the available facilities. 
6.2 How the tea industry will benefit 
The Residue Laboratory at BTRI is at the doorstep of the tea industry. They can easily take reliable 
as well as economic service within a short time which would involve more money, time and longer 
process to get samples tested from any other laboratory in the country or outside. At present the 
Institute can analyze about 200 tea samples per annum at different levels e.g. field application, 
made tea at factory, experimental samples, auction point, export point and random samples in the 
market point. The volume of analyses will be extended further. Thus the Institute plans to ensure 
MRL safe tea for the consumers home and abroad.  
6.3 Running residue project 
“Determination of residue level of different pesticides at different days after spraying” Core 
Research Programme/Project implemented during the year 2007-10 under “Research Grant” of 
BARC 
Table 5. Safe harvest intervals for some common chemicals 
Chemical Dose /ha Residue level* (ppm) Safe harvest interval (days) 
Endosulfan 1.5 lit. 1.40 7 
Propargite 1.0 lit. 3.52 7 
Ethion 1.0 lit. 4.66 8 
Bifenthrin 500 ml 0.043 7 
Cypermethrin 500 ml 0.85 7 
Dimethoate 2.25 lit. ND 7 
Sulphur 2.25 Kg ND 7 
* at 7 days after spraying  
 
Page 57
Keynote paper on Tea Industry of Bangladesh – Past Present and Future                                                             Dr. Mainuddin Ahmed 
The residue level of above mentioned pesticides at 7 days after plucking is below the MRL fixed by 
EPA, Codex Commission, EEC/EU and German Law (Ahmed et al., 2009). 
7.0 Major research thrust areas 
 HYV & quality clone 
 Raising organic matter status  
 Biotechnology for plant improvement 
 Drainage,  irrigation & drought management 
 Integrated pest management (IPM) with special emphasis on biocontrol 
 Pesticide residue in tea 
 Crop diversification 
 Socio-economic study 
 R & D management 
 
The success of BTRI in the past to render scientific support to the tea industry was quite 
considerable. Innovations and adoption of newer technologies are expected from the future thrust 
areas. Their efficient management is expected to meet the challenges of future consolidating 
Bangladesh tea industry to play its due role in the economic development of Bangladesh.  
 
8.0 Collaborative Research 
The research group  at the Tea Biochemistry Cell at the University of Cambridge in England in 
collaboration with Tocklai Experimental Station at Assam in British India in early 1940’s, may be 
cited as a very good example of a pioneering work of Dr. E.A.H. Roberts & team on tea 
biochemistry which unveiled the contributions of Theaflavins (TF) and Thearubigins (TR) towards 
colour, strength, briskness and creaming properties of the brew, the role of chlorophyll in 
appearance, and volatile components like linalool for flavour and quality have been established.  
 
9.0 Some suggested researches in the academic institutions like SUST 
BTRI is engaged mainly in adaptive researches on tea by which the tea industry could benefit 
immediately but much remains to be done on basic research where higher academic 
institutions like SUST and other universities may come forward and complement the gap to 
generate adaptive technologies to improve our tea.  
Some proposed fields may be as follows: 
 
 The pharmacological values of tea 
 Pharmacokinetics of tea 
 Heavy metals in made tea and tea soils 
 Applied physiology of tea plant  
 Tissue culture, Genetic mapping and engineering to evolve transgenic tea 
 Remote Sensing Technology to be utilized to identify the geomorphic units to formulate  
drainage planning based on topography and geomorphology  
 Advanced studies on the ground water potential in some selective tea areas  
 Catchments planning at estate level to be practiced to tackle the drainage problem 
 Biodegradable jute geo-textiles  as effective in reducing soil erosion in tea uplands 
Page 58
10.0 References 
Ahammed, K.M. 2007. Reduction of rural poverty through small holding tea cultivation in 
Bangladesh: A Socio-Economic Study. Arthanity Journal 12(1): 159-203.  
Ahmed, M. 1991. Decision analysis of tea pest management in Bangladesh, M.Sc. Thesis, Imperial 
College of Science, Technology and Medicine, University of London, UK. pp. 1-110.  
Ahmed, M. 2005. Tea Pest Management. Evergreen Printing & Packaging, Dhaka. pp 118.  
Ahmed, M; M.S.A. Mamun and S.K. Paul. 2009. Determination of pesticide residues in black tea at 
different plucking intervals after spraying. Bangladesh J. Entomol. 19(2): 91-99. 
Ahsan, Q. 1984. Evaluation of some old tea soils of Bangladesh with particular reference to soil 
fertility and soil management. M.Sc. Thesis, University of Aberdeen, Scotland, UK.   
Alam, A.F.M.B. 1994. Influence of improved genetic material towards higher productivity of tea in 
Bangladesh. Proc. of the International seminar on “Integrated Crop Management in Tea: 
Towards Higher Productivity” Sri Lanka 1994, pp. 33-49. 
Alam, A.F.M.B. 1999. Profile of tea industry in Bangladesh. pp. 1-22. Global Advances in Tea 
Science (ed. by Jain, N.K.). Aravali Books International (P) Ltd., New Delhi, India.  
Bangladesh Tea Research Institute. 1992. Annual Report. Agronomy Division, pp. 49-55. 
Bangladesh Tea Research Institute. 1993-94. Biennial Report. Statistics & Economics Division, pp. 
98-110. 
Bezbarua, H.P. 1999. Origin and history of development of tea. pp. 383-392. Global Advances in 
Tea Science (ed. by Jain, N.K.). Aravali Books International (P) Ltd., New Delhi, India.  
Choudhury, S.H. 1983. Nutrient requirements of tea plants. PhD. Thesis. University of Reading, 
UK.    
FAO, 2009. ‘Report of the intergovernmental group on tea meeting of the working groups on tea 
trade and quality, maximum residue levels and geographical indications’ held on 20-22 
May, 2009. Food and Agriculture Organization of the United Nations. Rome, Italy.      
Muraleedharan N. and Chen, Z.M.1997. Pests and diseases of tea and their management. Journal of 
Plantation Crops. 25 (1): 15-43. 
Pakistan Tea Research Station (PTRS). 1963. Annual report, Chemistry Division. pp. 12-13.   
Roberts, E.A.H. & Smith, R.F. (1963). Phenolic substances of manufactured tea. II. 
Spectrophotometric evaluation of tea liqours. J. of Science, Food and Agriculture. 14; 689-
700. 
Roberts, E.A.H. (1941). The fermentation process in tea manufacture. The influence of external 
factors of fermentation rate. Biochem. J. Sep. 35 (8-9): 909-919.       
Sana, D.L. 1989. Tea Science. Ashrafia Boi Ghar, Bangla Bazar, Dhaka, Bangladesh, pp. 1-89.  
Zaman, M.A. 1989. The Bulletin-Periodical Newsletter of the Bangladesh Tea Rehabilitation 
Project, 2(3), pp. 13-16.  
 
 
Page 59
A STUDY OF THE INTERNAL DEFECTS OF VARIOUS TYPES OF 
CONSTRUCTION MATERIALS BY USING DIRECT FILM NEUTRON 
RADIOGRAPHY TECHNIQUE 
Sudipta Saha, A.K.M. Azad Rahman, M.N. Islam 1, M.K. Alam1 and M.H. Ahsan 
 
Department of Physics, Shahjalal University of Science and Technology, Sylhet, Bangladesh 
 
1 Institute of Nuclear Science and Technology, Atomic Energy Research Establishment, 
   Savar, Dhaka, Bangladesh 
 
 
 
 
 
 
Summary: Neutron radiography technique has been utilized in the work for studying internal 
defects of various types of construction materials through optical density measurements of the 
samples. Two kinds of locally developed construction materials have been used as samples in our 
experiment. They are Terrazzo and Engraved construction materials. Tangential Neutron 
Radiography Facility of 3 MW TRIGA Mark-II research reactor is used here to find out the 
internal defects of the samples. From the observation of neutron radiographic images of the 
samples and variation of optical density at different positions, it revealed that the associated 
composites of Terrazzo construction material are uniformly distributed. No voids or any inclusions 
in the materials have been observed in the radiograph. The neutron radiographic image of 
engraved construction material shows that the optical density values at different reference 
positions are different. The density at the central position of the image is different from its 
neighboring reference positions.  Moreover, some voids are observed in the neutron radiograph of 
the material. This confirms that in this material the associated composites are not uniformly mixed 
and distributed during its fabrication. So, the fabrication of this construction material is relatively 
faulty. This faulty material may have several bad impacts while it is used as a construction 
material. It can absorb rainwater and thus may be damaged. Due to its structural disorder, its 
strength is deteriorated and may be damaged easily from even a very minor environmental 
turmoil. 
 
Keywords: Neutron Radiography, Non-destructive testing, Optical density  
 
Introduction 
 
Neutron Radiography (NR) is an imaging technique, which provides images similar to X-ray and 
Gamma-ray radiography. Interactions of neutron with matter can be divided into scattering and 
absorption. Neutrons can detect light elements, which have large neutron absorption cross-sections 
like hydrogen and boron. The information provided by spatial and temporal beam attenuation is 
recorded on magnetic media via analogy or digital signals. 
 
 Author for correspondence: Professor Dr. M. Habibul Ahsan, E-mail h.ahsan@sust.edu 
Page 60
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
All radiographic methods, whether making use of X-rays, -rays or neutron beams are based on 
the same general principle that, radiation is attenuated on passing through an object (sample). The 
object under examination is placed in the incident radiation beam. The beam, which remains after 
passing through, enters a detector that registers the fraction of the initial radiation intensity that has 
been transmitted through each point of the object. Any inhomogeneity in the object or an internal 
defect (such as voids, cracks, porosity, inclusion, corrosion etc.) will show up as change in 
radiation intensity reaching the detector. 
Neutron Radiography [1] is a non-destructive testing (NDT) technique of testing the nuclear and 
non-nuclear materials as well as industrial products. It concerns neutrons and radiography using 
neutron beam. 
Recently NR method has been applied to detect faults and to study water absorption properties of 
building materials [2]. A neutron radiography standard testing method for the moisture analysis 
was introduced by Peterka et al. [3] to the building industries in order to evaluate the properties, 
functions and the efficiency of their water protective agents against the penetration of water, water 
solution etc. In another study [4] quality of leather and ceramics has been studied. Study of 
corrosion in aluminium has been reported by M.N. Islam et al. [5]. In the present study, the NR set 
up at the tangential beam port of the 3.0 MW TRIGA Mark-II research reactor of AERE, Savar, 
Dhaka, Bangladesh has been used. Details of the NR facility of AERE, Savar, Dhaka can be found 
in reference [6]. Details of the parameters of the facility has been given in [7]. A study of defects 
and water absorption behaviour of jute products was reported by A.K.M. Azad Rahman et al. [8]. 
The following experiments have been carried out in the present study using direct film neutron 
radiography technique: 
 
A. Determination of optimum irradiation time for the present sample. 
 
B. Determination of defects in the samples through optical density variation measurements. 
 
Any inhomogeneity in the object or an internal defect e.g. void, crack, porosity or inclusion will 
show up as a change in radiation intensity reaching the detector, Irradiation intensity varies after 
passing through an object under examination. This intensity variation obeys the general 
attenuation law applicable for X-rays, gamma rays or neutrons 
 
 xeII  0    .................................  (1)                                                   
where, 
I0 = initial intensity of the incident beam, 
I  = intensity of the emergent beam from the object, 
µ = attenuation coefficient, 
x = thickness of the object. 
 
When the radiation beam is neutron, the above equation can be written as 
 
 xNs e
  0    .................................       (2) 
where, 
s  = number of neutrons transmitted through the sample, n cm
-2 sec-1, 
0 = number of neutrons incident upon the sample cm
-2 sec-1, 
N = number of nuclei per cm3, 
σ = microscopic cross-section, cm2, 
Page 61
x = thickness of the sample, cm. 
 
The attenuated neutron beam enters a detector that registers the fraction of the initial radiation 
intensity reaching the detector and is then recorded in the X-ray film. This is the principle of NR. 
The rate of depletion of the control rod material can also be detected by taking regular neutron 
radiographs. Irradiated TRIGA fuel elements could be used as object for all these experiments.  
 
Experimental Procedure 
Pre-Irradiation Procedure 
Before performing the irradiation of the experimental objects, the following steps were undertaken 
in the present experiment: 
1. Sample collection/preparation 
2. Loading the film and converter foil in the NR cassette  
3. Setting the sample in the neutron beam 
Sample preparation/collection 
Some locally developed construction materials have been collected from the Concord Ready-Mix 
and Concrete Products Ltd, Gulshan, Dhaka. The names of these products are terrazzo 
construction product and engraved construction product. Terrazzo building product is made from 
marble chips, marble dust and white cement. Engraved product is made from cement, sand and 
pigment. 
 
Loading the Film and Foil in the NR Cassette 
Gadolinium (Gd) metal foil of 25m thickness was used as converter in the NR cassette and Agfa 
structruix D4pDW industrial X-ray films were used as detector in our experiment. The films have 
emulsions in single side only. The sample and the NR camera were placed on their respective 
tables across the neutron beam. In this position the camera was placed just after the sample. The 
sample holder table was set at the optimum sample position from the reactor biological shielding 
assembly. 
 
Irradiation of the Sample 
To find out the optimum irradiation time of the sample a series of experiments were performed 
with different exposure time. To do these experiments the reactor was operated at 250 kW power 
level. Finally, we found the optimum irradiation/exposure time for the sample. From the 
observation of the final radiograph we found out the internal details such as cracks, voids, 
homogeneity of their compositions etc. of the sample. 
 
Post Irradiation 
After irradiation of the sample, the irradiated film was separated from the NR camera in the dark 
room and then following procedures have been carried out to make the radiographic image of the 
irradiated samples: 
 
a. Developing 
Developing ensures latent image, which was produced during irradiation to visual one. The film 
was then immersed into the developer for some time and was then agitated into the developer 
horizontally without touching the beaker (which contains the developer chemicals). 
b. Washing  
Page 62
For cleaning the developing chemicals, the film was washed in cool water for a few minutes. 
 
c. Fixing  
The developed film was immersed in the fixture chemicals to obtain the clear image. 
 
d. Final washing 
The silver compounds, which were formed during the fixing stage, must be removed, since they 
can affect the silver image at the later stage.  For this reason the film must be washed thoroughly 
in running water. 
 
e. Drying 
After the final washing, the films were dried by clipping it in a hanger and simultaneously flowing 
fresh air from the air cooler. 
 
The neutron radiographic images of the sample show that the region in which the sample was at 
close contact on neutron radiography cassette were light whereas, the backgrounds were 
comparatively dark. This is because more neutrons were attenuated by the test sample and 
allowing more neutrons to pass freely through the rest. 
 
Basic Principle of the Study for the Sample 
 
The quality/homogeneity of an object depends on the proper distribution of the composite 
materials. In the present work we have studied the quality of the test samples by the densitometric 
measurements the neutron radiographic images of the sample. 
When neutron beam hit an absorber, some of them are absorbed and scattered while the rest pass 
through it. Attenuation of radiation in the object is the difference between the radiation intensity 
before and after passing through this object. It can be expressed as [9]:  
xeII  0      (3) 
 
where e=base of natural logarithms, x = thickness of the test object,  = linear neutron attenuation 
coefficient, which depends on the atomic number and the density of the material. I and I0 is the 
neutron intensity after passing the object and the neutron incident on the object. 
 
In this work, the term homogeneity means the uniformity in the distribution of the composite 
materials. The homogeneity of a material depends of the proper distribution of the composite 
materials. Measuring the optical density of the radiographic film background (with out image), the 
optical density of the center point of the sample image, and at different reference levels of the 
radiographic image of the sample, one can comment about its homogeneity/inhomogeneity. The 
best homogeneity is ensured would constant optical density values at all places/levels. 
 
The mathematical expression [10] for the optical density, D, at a point of the film/image is given 
by:  







A
A
D 0ln      (4) 
 
Page 63
Here,  A0 = response of densitometer without the image and A = response of densitometer with 
the image.  
 
Fractional change in image density of neutron radiograph can be represented by ΔD and the 
expression can be written as, 





 

c
nc
D
DDD                            (5) 
where Dc = Average optical density of the total radiographic image and Dn = Optical density at  
different positions of the radiographic image. 
 
We have measured the optical density, of the neutron radiographic images of the sample by a 
digital densitometer (Model – 07 -424, S - 23285 Victorian Inc., USA). Densitometric data of 
optical density of the radiographic image of the sample is shown in Table below. 
 
 
Result and Discussion 
 
Table - 1 Optimum irradiation/exposure time of the objects 
Samples Irradiation time 
(minute) 
Optimum irradiation time 
(minute) 
 
Terrazzo construction 
material 
60 
50 
40 
45 
 
                   45 
 
Engraved construction 
material 
60 
50 
40 
45 
 
                    45 
 
Neutron Radiographic images of Terrazzo and Engraved construction materials are shown below: 
 
 
Fig. 1a : Neutron Radiographic Image of Terrazzo             Fig. 1b : Neutron Radiographic Image of Engraved 
  
Page 64
 Table - 2 Densitometric data for Terrazzo and Engraved building materials. 
 
Samples 
Optical density 
at the centre 
Average 
density (Dc) 
Optical density 
at the different 
positions         
(Dn) 
Fractional change in 
image density ΔD =     
( Dc-Dn ) / Dc 
 
 
 
Terrazzo 
construction 
material 
 
2.54 
2.54 
2.54 
2.53 
2.53 
2.54 
 
 
 
2.54 
2.54 
2.54 
2.54 
2.55 
2.54 
2.54 
2.54 
2.55 
2.54 
0.000 
0.000 
0.000 
0.004 
0.000 
0.000 
0.000 
0.004 
0.000 
 
 
 
Engraved 
construction 
material 
 
2.48 
2.48 
2.48 
2.48 
2.48 
2.47 
 
 
 
2.48 
2.48 
2.50 
2.47 
2.52 
2.49 
2.44 
2.50 
2.44 
0.000 
0.008 
0.004 
0.016 
0.004 
0.016 
0.008 
0.016 
 
Conclusion 
 
We have seen that, the mixture of the constituent elements of the sample of Terrazzo construction 
materials was uniform. Because the radiographs we have found, are approximately clear. In the 
case of Engraved construction materials the sample was not perfectly homogeneous as the 
radiograph has been found, not clear and cannot be said uniform at all. 
 
Acknowledgement 
 
The authors would like to thank Bangladesh Atomic Energy Commission and Scientists of the 
Institute of Nuclear Science and Technology, AERE, Savar, Dhaka and the Bangladesh Research 
Reactor administration for allowing the reactor facility and other laboratory facilities for the 
research work. The authors also like to acknowledge Shahjalal University authority for funding the 
research project. 
 
References 
 
1. Berger, H.1965. Neutron Radiography, Elsevier, Amsterdam . Berger, H. 1964. ANL-6846 . 
 
2. Islam, M.N., Alam, M.K., Zaman, M.A. Ahsan, M.H. and Molla, N.I. 2000, Application of 
neutron radiography to building industries. Indian Journal of Physics, 38: 348-354. 
 
Page 65
3. Peterka, F., Bock, H. and Pleinert, H. 1994. Neutron radiography standard testing method 
for the moisture analysis in building materials, Neutron Radiography (4), Gordon and Breach 
Scientific Publishers. pp. 75-86.  
 
4. Ahasan, M.M., Alam, M.K., Ahsan, M.H.,  and Zaman, M.A. 1996. A neutron radiographic 
study of some industrial products using the facility of AERE, Savar. Jahangirnagar University 
Journal of Science, 20: 151-160. 
 
5. Islam, M.N., Saklayen, M.A., Alam, M.K., Islam, S.M.A., Zaman, M.A. and Ahsan, M.H. 
2000. Study of corrosion in Aluminium using neutron radiographic technique. Indian Journal 
of Pure and Applied Physics, 38: 670-674. 
 
6. Rahman, M.A., Podder, J, and Kamal, I. 1990. Neutron radiography (3) Kluwer Academic 
Publishers, Dordrecht, Netherlands. pp. 179-187.  
 
7. Ahsan, M.H., Islam, M.N. and Alam, M.K. 1995. Installation and determination of useful 
parameters of Bangladesh neutron radiography facility, Proc. of the 2nd Int. Topical Meeting 
on NR System Design and Characterization, Shonan Village Centre/Rikkyo University, Japan, 
November 12-18, pp. 30-37. 
 
8. Azad Rahman, A.K.M., Saiful Islam Bhuiyan, A.K.M., Ahsan, M.H.,Alam, M.K. and 
Islam, M.N. 2007. A study of defects and water absorption behaviour in Jute/Cordenka 
reinforced polypropylene hybrid composites by using neutron radiography, SUST Studies, 
8(2), pp. 10-15. 
 
9. Norris, P.M., Brenizer, J.S., Raine, D.A. and Bostain, D.A. 1997. Neutron Radiography (5), 
DGZFP Publisher, Germany.  pp-602-611. 
 
10. Harms, A.A. and Wyman, D.R. 1986. Mathematics and Physics of Neutron Radiography,  D. 
Reidel Publishing Company. p-22-45. 
Page 66
Proceedings of the
Conference on Engineering Research, Innovation and Education 2011
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh
* Corresponding Author: Shams Al-Amin, 
E-mail: iamtanim@gmail.com
A GIS BASED STUDY ON URBAN RAINWATER HARVESTING OPTION 
USING ROOF CATCHMENT
Ahmed Ridwan Deep1 & Shams Al-Amin2*
1Disaster Shelter System Phase-1, Resource Planning and Management Consultant Ltd. Uttara, 
Sector-13, Dhaka-1230
2 Department of Civil Engineering, Ahsanullah University of Science and Technology, Dhaka
Depletion of groundwater of the last few decades has led to a serious problem of scarcity of drinking water 
in Dhaka. In the urban areas, specially in Dhaka city application of standard technologies for extracting and 
delivering drinking water have become difficult and expensive. In this situation, the development of 
alternative sources of drinking water has become important. Rainwater harvesting is one of the alternative 
technologies for delivering drinking water. The primary objective of the study is to investigate possibility of 
using rainwater as an alternative source in Dhanmondi, one of the most densely populated thana in Dhaka. 
The roof top area has been considered as catchment area in the study zone and rainfall data from 2004 to 
2009 has been considered for rainwater harvesting possibility.GIS has been used to extracte effective 
catchment area in the study area. The amount of rainwater obtainable is calculated by rational method and 
compared with water demand in Dhanmondi in 2010 for analyzing feasibility. Since rainwater in Dhaka is 
predominant in Monsoon Rainwater Harvesting has been found to be more effective in this period. Due to 
the unavailability of rainwater from November to April Rainwater harvesting does not seem feasible in this 
time of year. The % of water available through rainwater harvesting is little compared to the demand. 
However, considering cost and water quality, rainwater may be used as a supplementary source to minimize 
ever increasing pressure on groundwater. Rainwater harvesting may also have positive impact on water 
logging which is common in Dhanmondi during Monsoon. Considering all the aspects, this paper suggests 
introduction of rainwater harvesting as an alternate water source in the city.  
.  
Key words: Rainwater Harvesting, GIS, Dhaka, water supply, rational method
1. INTRODUCTION
Fresh water, a renewable but limited resource, is 
scarce in many areas of the developing world 
because of unplanned withdrawal of waters from 
rivers and underground aquifers causing severe 
environmental problems like arsenic contamination 
(Rahman et al. 2003). In many countries, the 
amount of water being consumed has exceeded the 
annual amount of renewal creating an unsustainable 
situation (Choudhury & Vasudevan, 2003). In 
addition to that, rainwater run-off during rainfall 
from roofs and other paved and impermeable
surfaces during heavy rain are leading to 
accumulated flooding in the urban areas of many 
countries like Bangladesh where the drainage 
system was not designed including the volume of 
rainwater runoff. In the early days of civilization, 
rainwater harvesting, the system of collecting and 
using the precipitation from a catchment area is 
considered as an alternative option for water supply 
in Bangladesh (Yusuf, 1999). Unless it comes into 
contact with a surface or collection system, the 
quality of rainwater meets Environmental 
Protection Agency standards(Choudhury & 
Vasudevan, 2003) and the independent 
characteristic of its harvesting system has made it 
suitable for scattered settlement and individual 
operation (Rahman & Yusuf, 2000).
2. BACKGROUND STUDY
2.1 Historical Background
Rainwater harvesting (RWH) is a common practice 
in the countries and areas where the annual 
precipitation is high and pure drinking and usable 
water is scarce. All over the world, economical 
condition has prompted the low-income groups to 
Page 67ISBN: 978-984-33-2140-4
harvest the rainwater for household and essential 
uses. Several countries of the world in different 
regions have showed the popularity of this method. 
Originated almost 5000 years ago in Iraq, rainwater 
harvesting is practiced throughout the Middle East, 
the Indian subcontinent, in Mexico, Africa as well 
as in Australia and United States. As the population 
of the world increased, irrigation, the most water 
consuming human activity, as well as domestic 
water usage increased, leading to a consequence of 
crisis of water supply in different region. Among 
other available alternative sources for water supply, 
rainwater harvesting has become the most 
economic solution for the water crisis (Boers and 
Ben-Asher,1982).
2.2 RWH: context of urban Dhaka city
The present water supply system of Dhaka almost 
entirely depends on groundwater. But exploitation 
of groundwater has its limit and depends on how 
much water is replenished during the monsoon of 
every year. At present, DWASA is operating 520
deep tube wells and four water treatment plants on 
the bank of surrounding Rivers. The contribution of 
four treatment plants in total water supply is 
insignificant and most of the water supply comes 
from exploitation of groundwater. The excessive 
groundwater extraction has led to lowering of water 
table. Figure 1 shows change of groundwater table 
over time.
Fig1: Groundwater hydrograph of seven 
observation wells of Dhaka city from 1986 to 2005
With the ever increasing water demand, urban 
authority has long been looking for increasing 
supply of water to the consumers. With respect to 
the physical alternatives to fulfill sustainable 
management of freshwater, there are two solutions: 
finding alternate or additional water resources using 
conventional centralized approaches; or better 
utilizing the limited amount of water resources 
available in a more efficient way. To date in 
Bangladesh, much attention has been given to the 
first option and only limited attention has been 
given to optimizing water management systems. 
Among the various alternative technologies to 
augment freshwater resources, rainwater harvesting 
(RWH) and utilization is a decentralized, 
environmentally sound solution, which can avoid 
many environmental problems often caused in 
conventional large-scale projects using centralized 
approaches. Rainwater harvesting, in its broadest 
sense, is a technology used for collecting and
storing rainwater for human use from rooftops, land 
surfaces or rock catchments using simple 
techniques such as jars and pots as well as 
engineered techniques. Harvesting rainwater on the 
rooftop can be a possible alternative solution to 
acute water crisis in Dhaka city.
3. METHODOLOGY
3.1 Study Area
Dhanmondi has been chosen as the study area (Fig-
2) as it is one of the most crowded and planned 
areas in Dhaka city. Its origins can be traced back 
to the late 1950s. Dhanmondi began as an affluent 
residential area, and over the decades it has evolved 
into a miniature city, where one can find everything 
from hospitals to malls, schools, banks, offices and 
universities. Water supply in Dhanmondi is 
facilitated entirely with ground water based pump 
system. In the peak demand hours Dhanmondi 
suffers from deficiency of supply water which can 
be pacified by adopting suitable rainwater 
harvesting technique. Cluster distribution pattern of 
buildings has been found in the study area
Fig 2: Study area for rainwater harvesting analysis
Page 68
3.2 Estimation of Rainwater Harvesting
3.2.1 Runoff Coefficient
Rational Method has been adopted to calculate 
amount of water harvestable by utilizing roof top 
area. The runoff coefficient depends on the rooftop 
material. General values are tabulated in table 1, 
which may be utilized for assessing the runoff 
availability (Pacey & Cullis, 1989). A runoff 
coefficient value of 0.65 has been used.
Table 1: Runoff Coefficient for different catchment
Type of catchment Runoff coefficient
Roof 
Catchments
• Tiles
• Corrugated 
Metal Sheets
0.8-0.9
0.7-0.9
Ground 
surface 
coverings
• Concrete
• Brick Pavement
0.6 - 0.8
0.5 – 0.6
Untreated 
ground 
catchments
• Rocky natural 
catchments
• Green area
  0.2 – 0.5
0.05 - 0.10
3.2.2 Rainfall Intensity
Rainfall data from 2004 to 2009 has been used for 
calculating rainfall intensity. Rainfall data used in 
this paper is collected from secondary sources like 
Bangladesh Meterological Department & 
Bangladesh Water Development Board.
3.2.3 Catchment Area
Catchment area has been calculated using GIS for 
the specified zone. ArcGIS 9.2 has been used for 
this purpose. Roof top area has been extracted from 
the foor top map of the study area. For 
simplification, roof top characteristics has been 
considered same for the whole area. 30 parcent area 
of the roof top is assumed to be used for rainwater 
harvesting.
3.2.4 Water Demand 
Estimated population data of 2010 has been taken 
from Dhaka Water Supply Project (Carl Bro, 2007). 
For demand calculation, water demand is taken as 
220 lpd following DWASA design approach. 
Population density and concentration of demand are 
assumed to be uniformly distributed. For the 
rainwater available from 2004 to 2009, demand 
supplimented by rainwater available has been 
investigated.
Fig 2: Roof top Catchment area in Dhanmondi
4. ILLUSTRATIONS
4.1 Availability of Rainfall
Rainfall in Bangladesh is predominant in monsoon.  
Average normal rainfall is recorded higher from 
May to September. Rainwater harvesting is, 
therefore, found to be more feasible during 
monsoon season. Figure 3 shows average normal 
rainfall in Dhaka.
Fig 3: Average Normal Rainfall in Dhaka.
Figure 4 shows net rainfall harvestable in months, 
which is compared with water demand for 2009. 
The water available through rainwater harvesting 
has been found to supplement 2.8% in September 
where as rainwater harvesting from October to 
April seems difficult due to lower rainfall.
Page 69
Figure 4: Demand supplemented by Rainwater
4.2 Rainwater available in Monsoon
Table 2 shows net harvestable rainfall in monsoon, 
which is compared with water demand for the   
time period from 2004 to 2008. 
Table 2:supplymentary water available byRWH
Month Net Rainfall Harvestable
(lpd)
Supplementary 
water (%)
June,2004 928023.642 2.02437398
July,2004 556587.7766 1.214130505
August,2004 360367.0011 0.786098056
September,2004 1635739.151 3.568171785
Monsoon,2004 863430.1794 1.88347097
June,2005 504954.0405 1.101497607
July,2005 1022612.118 2.230707571
August,2005 681112.4995 1.485766482
September,2005 1002109.563 2.185983668
Monsoon,2005 803503.0431 1.752746999
June,2006 635579.217 1.386441003
July,2006 624510.3527 1.362295583
August,2006 315085.2837 0.687321337
September,2006 1292604.359 2.819663759
Monsoon,2006 712893.2131 1.555092356
June,2007 1224367.326 2.670812731
July,2007 1420713.884 3.099119559
August,2007 952802.804 2.078426796
September,2007 348983.6805 0.761266686
Monsoon,2007 989996.2912 2.159559996
June,2008 1124936.222 2.453915518
July,2008 1062233.621 2.3171372
August,2008 601869.494 1.312907224
September,2008 543946.6305 1.186555337
Monsoon,2008 833226.9027 1.817586089
The water available through rainwater harvesting 
has been found to supplement around 2% of water 
demand in the study area. Figure 5 shows 
contribution of rainwater harvesting as a 
supplementary water source compared to water 
demand in the study area.
Figure 5: Contribution of Rainwater Harvesting as a 
Supplementary Water Source
The contribution of rainwater useable is not 
enormous compared to ever increasing water 
demand. But, since water available in this manner 
is less costly compared to ground water supplied,
rainwater harvesting should be treated as a potential 
water source. The usual use of rainwater in
household activities as practiced globally is mostly 
for flushing, cloth washing and car washing. Water 
used in this purposes require minimum water 
treatment which avails the minimum running cost 
of rainwater harvesting practice. The possible 
positive affect of RWH on water clogging problem, 
which is severe during monsoon should also be 
taken in consideration.
4.3 Rainwater Chemistry 
Rainwater is the purest form of water in the nature, 
but only problem is the possibilities of 
bacteriological contamination during collection and 
use; if not done in a hygienic way. Several studies
have been undertaken by researchers on rainwater 
chemistry for obtaining potable water. Considering 
the cost, availability and effectiveness, chlorination
seems to be the most appropriate one to use for this 
purpose (Sultana, 2007). Contamination with bird 
droppings or solid particles is common in rainwater 
harvesting and constitutes the major water quality 
concern unless the roof catchment area and other 
system components are kept clean before each 
rainfall event (Al Muyeed, 2004). However 
analysis of rainwater collected in urban Dhaka must 
be undertaken for understanding complete scenario.
Page 70
7. CONCLUSIONS
Rainwater harvesting can effectively be utilized as 
a supplementary source for water supply in Dhaka 
during monsoon. For sustainable urban growth and 
replenishment of groundwater RWH can be a very
significant tool. Considering the cluster distribution 
pattern of housing in Dhaka, community based 
rainwater harvesting can be more effective and 
needs further study. The rainwater chemistry of 
Dhaka should also be analyzed to decide 
appropriate treatment technique.
REFERENCES
1. Akbar HMD, Minnery JR, van Horen B, Smith 
P (2007) Community water supply for the 
urban poor in developing countries: The case 
of Dhaka, Bangladesh. Habitat International
31, 24-35.
2. Ali AMS (2007) Population pressure,  
agricultural intensification and changes in rural 
systems in Bangladesh. Geoforum 38, 720-738.
3. Buschmann J, Berg M, Stengel C, Winkel L, 
Sampson ML, Trang PTK, Viet PH (2008) 
Contamination of drinking water resources in 
the Mekong delta floodplains: Arsenic and 
other trace metals pose serious health risks to 
population. Environment International 34, 756-
764.
4. Datta KK, de Jong C, Singh OP (2000) 
Reclaiming salt-affected land through drainage 
in Haryana, India: a financial analysis. 
Agricultural Water Management 46, 55-71.
5. Nemade PD, Kadam AM, Shankar HS (2009) 
Removal of iron, arsenic and coliform bacteria 
from water by novel constructed soil filter 
system. Ecological Engineering 35, 1152-
1157.
6. Panigrahi B, Panda SN, Mal BC (2007) 
Rainwater conservation and recycling by 
optimal size on-farm reservoir. Resources, 
Conservation and Recycling 50, 459-474.
7. Pantuwan G, Fukai S, Cooper M, 
Rajatasereekul S, O'Toole JC (2002) Yield 
response of rice (Oryza sativa L.) genotypes to 
different types of drought under rainfed 
lowlands: Part 1. Grain yield and yield 
components. Field Crops Research 73, 153-
168.
8. Roy D, Panda SN, Panigrahi B (2009) Water 
balance simulation model for optimal sizing of 
on-farm reservoir in rainfed farming system. 
Computers and Electronics in Agriculture 65, 
114-124.
9. Sharma PK, De Datta SK, Donald LS (1994) 
Rainwater Utilization Efficiency in Rain-Fed 
Lowland Rice. In 'Advances in Agronomy' pp. 
85-120. (Academic Press).
10. Tsubo M, Fukai S, Tuong TP, Ouk M (2007) A 
water balance model for rainfed lowland rice 
fields emphasising lateral water movement 
within a toposequence. Ecological Modelling
204, 503-515.
Page 71
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
*
 Corresponding Author: Mohammad Shahidur Rahman,  
E-mail: msrahman_sust@yahoo.com 
A LOW COST TEMPERATURE CONTROL UNIT FOR 
WASTEWATER RESPIROMETER 
 
M.S. Rahman* and M.A. Islam  
 
Centre for Environmental Process Engineering, 
Department of Chemical Engineering and Polymer Science, 
Shahjalal University of Science and Technology, Sylhet, Bangladesh 
 
 
A device for maintaining constant temperature in the reaction and control flask of wastewater respirometer is 
described. It consists of a water bath having a temperature control over 18
0
C to 32
0
C and a reverse mode 
peristaltic pump operated at the capacity of 100 ml per min. The water bath is incorporated with an 
automatic aquarium water heater. A thermometer is provided to monitor the temperature profile. The 
peristaltic pump can reverse the fluid circulation between the respirometer and water bath. The pump head 
devised with a replaceable silicon tube of 8 mm dia which is operated by a 9V DC motor. 
 
Keywords: Water bath; Peristaltic pump; Reverse mode; Low cost; Respirometer 
 
1. INTRODUCTION 
 
Temperature control unit is a device or a vessel for 
regulating the temperature of any experimental 
vessel subjected to heat, by surrounding it with 
another larger tank containing water which can be 
kept at a desired temperature. It is extensively used 
in different types of laboratory experiments related 
to Chemical Engineering, Environmental 
Engineering, Biochemistry, Microbiology etc. A 
number of commercial temperature control units 
are available in the market [1]. But the facilities are 
offered to a certain extent. The BIOSCAN 
temperature control unit is a specially designed 
device in accordance with the requirement of 
BIOSCAN respirometer for the study of 
biodegradation process of wastewater and biosolids 
[2].  
 
2. DESCRIPTION 
 
Fig. 1 shows the major components of the 
temperature control unit which mainly consists of 
1) a water bath with an automatic aquarium heater 
and 2) a reverse mode peristaltic pump. 
 
2.1 Water bath unit 
The main tank is made of 20 gauge metal sheet 
which is insulated with Styrofoam. One wooden 
platform is provided to hold the device on it. A 
normal thermometer is incorporated for monitoring 
temperature profile during the experiment. A fully 
submersible automatic aquarium heater is placed 
inside the water tank. The typical components as 
well as the technical specifications are provided in 
the table 1. 
 
 
 
 
 
 
 
 
2.2 Peristaltic pump unit 
The Bioscan peristaltic pump can alter the water 
flow from water tank to experimental reactor of the 
attached respirometer. Fig. 2 shows the pump head 
assembly with silicon tube. A DPDT (Double Pole, 
Double Throw) switch wired up as reverse circuit 
for the operation of the motor is shown in fig. 3. 
 
 
Fig. 1: Bioscan Water Bath (1.Water tank with lid, 2.Platform, 
3.Automatic aquarium heater, 4.Outlet Pipe, 5.Thermometer, 
6.Peristaltic pump. 7.Pump head, 8.Silicon tube, 9. Pump Inlet pipe 
and 10.Pump outlet pipe. 
 
 
Fig. 2: Peristaltic Pump Head (1.Head chamber, 2.Shaft, 3.Roller, 
4.Silicon tube). 
 
Page 72ISBN: 978-984-33-2140-4
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Table 1: Technical Specifications 
 
 
 
3. PERFORMANCE TEST  
 
3.1 Water bath unit 
Any small change of temperature in the reactor may 
greatly influence the biodegradation kinetics of 
wastewater microbes [3]. Therefore, it is utmost 
important to maintain the surrounding temperature 
of the reactor constant during the experiment. In 
this regard, peristaltic pump plays a significant role 
to ensure quick thermal diffusion of water by 
reversing the flow time to time between the tank 
and respirometer. Fig. 4 represents the prolong 
temperature profile against time interval. It is quite 
apparent that the water bath can maintain constant 
thermal environment over a desire period of time. 
However a temperature lag of 2.5
0
C is observed in 
the reactor vessel which can be minimized by 
setting the heater temperature value at 2.5
0
C higher 
than the target temperature. 
 
 
 
 
 
 
 
 
 
 
 
 
3.2 Peristaltic pump unit 
Fig. 5 shows the discharge capacity of the 
peristaltic pump in both clockwise and 
anticlockwise rotation. It is quite clear from the 
result that the discharge trend is almost typical in 
both the condition which ensures good reversing 
operation of the pump. 
 
 
 
 
 
 
 
 
 
 
 
4. CONCLUSION 
 
The study revealed that the low cost temperature 
control unit facilitated with the reverse mode 
peristaltic pump can be successfully used to 
maintain constant thermal background for the 
biodegradation kinetics study of wastewater using 
the Bioscan respirometers which were locally 
fabricated at SUST. 
 
5. REFERENCES 
 
1. www. alibaba.com/showroom/water-bath.html. 
2. Gautam Chalasani and Weimin Sun, (2007), A 
Report On Measurement of Temperature Effects on 
Oxygen Uptake Rate in Activated Sludge 
Treatment. MUCE, USA. 
3. M.A. Islam and M.S. Rahman, (2010), 
Application of a simple manometric respirometer 
for measuring the oxygen uptake rate of 
wastewater, Proceedings of the Conference CERIE 
2010, 11-13 January, Sylhet, Bangladesh, pp.1-3. 
N
o. Item Description 
(1
) 
W
at
er
 b
at
h
 u
n
it
 
1. Water tank Dimensions  360 x 190 x 270 mm 
Weight 3.5 kg 
Thermal 
insulator  
Styrofoam of 10 mm 
thickness 
Capacity  9 liter 
 
2. Automatic  
aquarium 
heater 
Brand Name Weipro  
Model no HA-200w 
Type  Submersible 
Watt 200 w 
Volt AC 230V/50Hz      
Materials Borosilicate glass 
Length 21 cm 
Temperature 
range 
18-32°C ±1°C 
3. Platform Dimensions Wooden frame (350 
x 200 x 35 mm) 
(2
) 
P
er
is
ta
lt
ic
 p
u
m
p
 u
n
it
 
1. Single head 
reverse mode 
peristaltic 
pump 
 
Dimensions 130 x 100 x 110 mm 
Weight 1 kg 
Pump head single roller mounted 
on an eccentric 
portion of a drive 
shaft 
Motor type DC 9 volt Motor 
(input voltage 220-
240 V AC) 
Discharge 
rate 
100 ml/min 
2.Silicon 
Tube 
 
Tube size Inner dia 6mm 
outer dia- 8mm  
Tube matter Silicone 
3. Inlet/outlet 
pipe 
Pipe size Inner dia- 6mm  
Outer dia- 8mm 
Pipe matter Plastic 
 
 Fig. 3: Circuit Diagram of a Reverse Mode DC Motor. 
 
 
18
20
22
24
26
28
30
32
34
0 1 2 3 4 5
T
e
m
p
e
r
a
tu
r
e
 P
r
o
fi
le
, 
ºC
 
Time, hr
Series1 Series2
Fig. 4: Performance Test Curve for the Bioscan Water Bath. 
 
R actor Water  bath 
Initial water temperature=18oC 
Target temperature= 27oC 
Temperature 
Lag 
 
 
0
20
40
60
80
100
120
140
160
0 50 100 150 200C
u
m
u
la
ti
v
e
 d
is
ch
a
r
g
e
, 
m
l
Time, sec
Fig. 5: Performance Test Curve for the Bioscan Peristaltic Pump 
 
Anti clockwise 
      rotation 
Clockwise 
   rotation 
Page 73
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Matluba Khan,  
E-mail: matluba@arch.buet.ac.bd, matluba_k@yahoo.com  
AN OBSERVATION ON THE ACOUSTICAL ENVIRONMENTS OF 
AUDITORIUMS IN DHAKA 
 
Matluba Khan* 
Department of Architecture, Bangladesh University of Engineering & Technology, Dhaka- 1000 
 
 
This paper reports the findings of a study of existing acoustical condition of several auditoriums in Dhaka 
aimed at an understanding of their sonic environments. Good acoustical design is a pre-requisite for a hearty 
musical performance, which is badly ignored in the cases of auditoriums in Bangladesh. Ignorance about 
acoustics and also lack of expertise are responsible for this. Acoustic measurements have been carried out in 
four auditoriums in Dhaka, and the study was focused on the evaluation of musical performance there. These 
halls with capacity ranging from about 600 to 800 people are all frequented by major musical concerts and 
dramas. Measurements of Reverberation Time (RT) were done and feedbacks are taken from the performers 
and audience about the existing conditions prevailing in the widely known auditoriums. 
 
The major objective of the study is to know about the existing acoustical condition of these auditoriums and 
compare their conditions. The analysis of data was focused on finding possible relationships between 
objective and subjective parameters of the acoustics of these halls. This may act as a basis for further study 
in this specific field for designing better acoustical environment in these auditoriums.   
 
Key words: Acoustics, musical performance, Reverberation Time (RT), auditoriums, subjective parameters  
 
1. INTRODUCTION 
 
Among audience and performers alike it is a well 
known fact that to a large degree bad acoustics can 
ruin the joy of a musical performance. As a matter 
of fact both performers and audience sometimes 
choose not to go to a venue because of 
unsatisfactory acoustical conditions. Considerations 
for acoustics are seldom taken in Bangladesh while 
designing of auditoriums. Architects are more 
conscious about the form and massing of the 
auditoriums and as such most often ignore the 
requirements of good acoustical design for better 
functioning of auditoriums as places where musical 
concerts are held. 
 
Knowledge about acoustics is a must for designing 
a well performing auditorium. The acoustics must 
be considered during the design phase which makes 
the installation of different acoustical materials 
easy and can be adjusted with the aesthetics and 
functions of the halls. In the auditoriums where 
acoustics not considered in the design phase may 
need expertise in acoustics for better functioning 
based on the existing conditions. This paper aims to 
explore the existing acoustical condition of several 
auditoriums in Dhaka city and create a basis for 
further study in the specific field. 
 
2. OBJECTIVES 
 
This study seeks to have a clear idea about the 
present acoustical condition of the places for 
musical performance in Bangladesh. This paper is 
outlined to reach the specific objectives i.e. 
 
a. To take the measurements of the objective 
parameters (RT) of the auditoriums. 
b. To know about the subjective parameters 
(intimacy, clarity etc). 
c. To find possible relationships between objective 
and subjective parameters of the acoustics of these 
halls. 
d. To compare the existing conditions of the halls 
which may act as a base for the up gradation of 
poorly performed halls. 
 
This study is more concentrated on the evaluation 
of the halls in terms of overall musical performance 
and the survey was limited in four auditoriums in 
Dhaka city (Khan: 2010). 
 
3. RESEARCH METHODS 
 
The Case studies depend on direct observations, 
acoustical measurements, sketches and photographs 
and questionnaire survey of musicians and 
audiences which are used to trace the present status 
Page 74ISBN: 978-984-33-2140-4
  
of the halls. The literature reviews served the 
purpose of making the knowledge base about the 
criteria of a good room for music. The auditoriums 
surveyed were selected from the standpoints of  
 
a) They should be widely known as venues for 
programs 
b) The capacity of audience ranges from 600 to 
800. 
It must be emphasized that the regular subscribers 
to performances in all of these houses spoke 
favorably for their acoustics. 
 
4. OBJECTIVE & SUBJECTIVE 
ATTRIBUTES OF A ROOM FOR 
MUSIC 
 
4.1 Objective acoustical attributes of a room 
for music  
 
The objective acoustical attributes or a room for 
music in db are RT (Reverberation Time), EDT 
(Early Decay Time), ITDG (Initial Time Delay 
Gap), strength factor G (average sound pressure 
level for 500 hz and 1000 hz bands) etc. only RT is 
calculated in this particular study which objectively 
describes the echoic quality of the room. It is the 
time that takes for a sound level in a room to be 
reduced by 60 decibels after turning off the sound 
source. It is vital in establishing quality of music 
(long RT) and speech intelligibility (short RT). It is 
different for different music types and speech. 
Reverberation Time is calculated using Sabine 
Formula : 
 
RT= .05 V/A (FPS) 
Or, RT= .161 V/A (MKS) where V= Volume of 
Space and A= total Absorption 
 
Music requires high RT than speech, a reasonable 
degree of blurring and overlapping in musical 
sounds is often considered acceptable and even 
desirable. For various styles of music it is found 
that (Hong Kong Academy for Performing Arts: 
1986), 
Table 1.  Different RT for different type of music  
RT in sec Type of Music 
1.0  Baroque Music 
1.5 Classical and Modern Music 
2.0 Romantic Music 
 
4.2 Subjective acoustical attributes of a 
room for music  
 
Leo Leroy Beranek subjectively analyzed 54 
concert halls and devised a set of 18 design 
attributes incorporating the subjective qualities and 
the physical attributes of the auditorium. The 
attributes are (Beranek: 1996) : 
 
1. Intimacy ( presence, familiarity, closeness, 
relationship ) 
2. Liveness (fullness of Tone or how long a sound is 
heard, Reverberation) 
3. Warmth (affection, hospitality, long lower 
frequency RT) 
4. Loudness of the direct sound  
5. Loudness of the reverberant sound 
6. Definition, clarity- how well an individual sound 
can be heard within a performance 
a) Horizontal Definition- how distinguishable 
sounds following each other are 
b) Vertical Definition- how distinguishable sounds 
that occur at the same time (chords) are from other 
sounds 
7. Brilliance (vividness) 
8. Diffusion (spreading, dissemination) 
9. Balance (symmetry, equilibrium) 
10. Blend (mix, merge) 
11. Ensemble (as a whole, as a group) 
12. Response, Attack 
13. Texture (feel, grain) 
14. No echo 
15. Quiet (soft) 
16. Dynamic Range (vibrant) 
17. No distortion 
18. Uniformity (homogeny) 
 
If the music gives the impression of being 
performed in a small intimate hall, the auditorium is 
said to have ‘acoustical intimacy’. When an 
auditorium has a large volume relative to the 
audience capacity, with predominant sound 
reflective enclosures, it is said to be ‘live’. A live 
hall has a relatively long reverberation time, giving 
a long sustaining tone. When the hall has a 
relatively long RT at lower frequencies, it has the 
acoustical quality of ‘warmth’. If the RT is 
adequately controlled, a pleasant ‘fullness of tone’ 
is noticeable. If the sounds of different musical 
instruments are easily distinguishable and if the 
sounds within a rapid passage are heard separately, 
the room is said to possess ‘definition’ or ‘clarity’. 
If the reflected sound waves approaching the 
listener from every direction are equal in amount, 
the result is ‘diffusion’. There are some other 
important qualities like balance, blend, ensemble 
etc. freedom from noise that is the reduction of 
exterior and interior noise to inaudibility is one of 
the most important characteristic of a place for 
music. 
 
 
 
Page 75
  
5. OBSERVATIONS AND FINDINGS  
The four auditoriums surveyed for this research are- 
1. BUET Auditorium 
2. National Museum Auditorium 
3. Bangladesh Shishu Academy Auditorium 
4. Main Auditorium of Jatiyo Natyoshala 
 
5.1 Objective acoustical attributes of the 
surveyed auditoriums 
 
 
 
 
Fig. 1: plan of BUET 
Auditorium 
 
Fig. 2: section of BUET 
Auditorium 
 
 
 
Fig. 3: view of the stage 
of BUET Auditorium 
 
Fig. 4: View of 
Auditorium from stage 
 
Table 2:  Calculation of RT of BUET Auditorium 
(from field survey conducted by author in 2010) 
Calculation of absorption of materials 
Wall 
surface 
Area/ 
Volume/ 
Number 
Surface 
treatment 
Designed 
Surface 
Area 
Absorption 
Co-
efficient 
Absorption 
by surfaces 
sft.sabins 
North wall 1620 sft Wooden 
door 
308 0.15 46.2 
    Brick with 
plaster 
1312 0.02 26.24 
Balcony 
railing 
180 sft Brick with 
plaster 
180 0.02 3.6 
South side  1890 sft wood 625 0.15 93.75 
  Proscenium 
opening 
1265   0 
East wall  2676sft ½ wood 1488 0.15 223.2 
  ½ drapery 1488 0.49 729.12 
West wall  2676sft ½ wood 1488 0.15 223.2 
  ½ drapery 1488 0.49 729.12 
Ceiling  5616 sft Plywood  5616 0.17 954.72 
Floor Main 5616 sft Net cement 
finish 
5616 0.02 112.32 
Floor 
Mezannine 
1770 sft Net cement 
finish 
1770 0.02 35.4 
Audience 
in 
upholstered 
seats 
700 nos   700 0.4 280 
Air  199290 
cft 
  199290 0.003 597.87 
A, Designed total absorption 4054.74 
V, volume in cft  199290 
Therefore, RT 2.4574941 
 
 
 
Fig. 5: plan of National 
Museum Auditorium  
Fig. 6: Section through 
National Museum 
Auditorium 
 
 
 
Fig. 7: view of the stage of 
BUET Auditorium 
 
Fig. 8: View of 
Auditorium from stage 
 
Table 3: Calculation of RT of Main Auditorium, 
Bangladesh National Museum (from field survey 
conducted by author in 2010) 
Calculation of absorption of materials 
Wall 
surface 
Area/ 
Volume/ 
Number 
Surface 
treatment 
Designe
d 
Surface 
Area 
Absorptio
n Co-
efficient 
Absorption 
by surfaces 
sft.sabins 
South wall 1425 sft Brick  1248 0.02 24.96 
North side  1425 sft Brick  1248 0.02 24.96 
East wall  3168 sft Wood on 
coir foam 
3084 0.7 2158.8 
Wooden 
doors 4 
0.15 12.6 
West wall  1195 sft Prosceniu
m 
opening 
855   0 
  wood 
40 
0.15 51 
Ceiling  4284 sft wood  4284 0.15 642.6 
Floor  4284 sft Net 
cement 
finish 
3940 0.05 197 
Carpeted 344 0.5 172 
Audience 
in 
upholstere
d seats 
725 nos   725 0.4 290 
Air  111384 
cft 
  111384 0.003 334.152 
A, Designed total absorption 3908.072 
V, volume in cft  111384 
Therefore, RT 1.42505051 
 
Fig. 9: plan of Bangladesh 
Shishu Academy 
Auditorium 
Fig. 10: View from stage  
Page 76
  
Table 4: Calculation of RT of Main Auditorium, 
Bangladesh Shishu Academy (from field survey 
conducted by author in 2010) 
 
Calculation of absorption of materials 
Wall 
surface 
Area/ 
Volume/ 
Number 
Surface 
treatment 
Designed 
Surface 
Area 
Absorption 
Co-efficient 
Absorption 
by surfaces 
sft.sabins 
South 
wall 
1425 sft Absorptiv
e surface 
1197 0.7 837.9 
North 
side  
2280 sft Prosceniu
m opening 
1295   0 
Wood 598.5 0.15 89.775 
plaster 390 0.02 7.8 
East 
wall  
2920 sft ¼ 
reflective 
730 0.02 14.6 
¾ 
absorptive 
2190 0.7 1533 
West 
wall  
2920 sft ¼ 
reflective 
730 0.02 14.6 
¾ 
absorptive 
2190 0.7 1533 
Ceiling  4360 sft Plywood  4360 0.17 741.2 
Floor  4360 sft Net 
cement 
finish 
4360 0.02 87.2 
Audien
ce in 
upholst
ered 
seats 
650 nos   650 0.4 260 
Air  130800 
cft 
  130800 0.003 392.4 
A, Designed total absorption 5511.475 
V, volume in cft  130800 
Therefore, RT 1.18661519
8 
 
 
1ST FLOOR PLAN
LIFT  # 2LIFT # 1
L IF T #  5
LIFT  # 4
LIFT  # 3
UP
D5
D 4
F.  TO I LET
WORK  SH OP
AW4
L. M. ROOM
A9
A8
UP
A 4 AW6AW6
D7
F OY ER
L  B  B  Y
+ 4 50
D 3
A W5
A W5
AW4SE CUR IT Y
D 3
+ 150+ 00
A W5 AW5G. RO OM
U P
L  O  B  B  Y
D 5
D 5
AW20a
H
A W20
H
A W20
H
D 3
D2
+  30 0
+ 450
+  00
D 2 D 2
F  O   Y   E  R
A W4
KI TC HEN  /  PA NTR Y
+ 450
D 2
D 3
D3
D4
A W5
D5
D5
TOI LET
+ 0 0 + 0 0
S  T O R E
R  E S T U R A N T
+  450
C A F E  T E R I  A
D2
AW1
A W2
A W3
UP
D1 2 000 x 2100
1 500 x 2100D2
1 000 x 2100D3
8 75 x 2100D4
7 50 x 2100D5
3 000 x 2100D7
DOOR S CHEDULE
AW8
D3
D3
D5D5D 5
D3 D 5 D 5 D 5
D RESS DRE SS D RESS
G.  M.  ROOM
D5D 5D5
TOI LET TOILET TOI LET
TOI LETTOI LET TOI LET
DRE SSD RESS
D 5D3
D RESS
D 5D 5
B  A  C  K   S  T  A  G E
S  T  A  G E
S  I   D  E    S T A  G  E
+ 3 0 0 0
M O S A  I C
HOMOGE NOUS WOOD FLOOR ING FOR ACOUS TIC WOR KS
+ 3 0  0 0
+  3 0 0 0
W O O D E  N
+  1 975
GRANI TE
UP
GR ANITE
+  27 25
+  2 725+  1 975 CARPET
A A
B
BC
C
SO UND
LOC K
GLASS BR ICK
SL ID IN G DO OR
LOC K
S OUN D
LO CK
SO UND
LOC K
SO UN D
V. I .P.  R OOM
TOI LET
 
EX
PE
R
IM
EN
TA
L 
TH
EA
TR
E
SECOND FLOOR PLAN
LIFT LIFT
L OB BY
TOIL ET
S 
T 
A 
G
 E
LOUNGE
BACK STAGE
F. TOI LET
LI FT
LIFT
LI FT
F. TOILE T
DN
DN
TOILET TOILE T
LIGHT CON TROL
S OUND CONTROL
PROJECTION
STORE
 
Fig. 11: First Floor Plan 
of Jatiyo Natyoshala 
Fig. 12 2nd Floor Plan 
of Jatiyo Natyoshala 
 
SECTION  A-A
SCALE : 1 /8'' =1 ' -0 ''
16 '-10 "
Note :
8'-3"
2'
1
'-
6"
6"
3
'
TERR ACOTA
TERRACO TA TER RACOTA
M .S. PIPE FRAM E TR USS
6' '
8'
-0
''
REFLECTOR
R EFLECTOR
6"6"
2
'
17' -8  1 /2"
11
"
2'
6"
R EFLECTO R
2'
ABSOR BER
2
5'-
7
"
49
'-
2"
37
'
-
5"
10"
1
2'
-2
 1
/2
"
6"
2
'
2'6"
11
'-
1 
1/
2"
1'5 '
6'
'
1'
WALKING DECK
(SAME AS WALL WITH ABSORBTION)
REFLECTO R
Wooden Panel  (3 /4 ' ' x  6' ') fixed to  Wal l  fla t s ide wi th  1 /8 ' ' g rov e
(SA ME AS WALL WITH ABSO RBTION)
ABSO RB
1
3
'-2
"
1
5
'-8
"
 
 
Fig. 13: Section of 
Jatiyo Natyoshala  
Fig. 14: View of stage 
of Jatiyo Natyoshala  
 
Table 5: Calculation of RT of Main Auditorium, 
Jatiyo Natyoshala (from field survey conducted by 
author in 2010) 
 
Calculation of absorption of materials 
Wall 
surface 
Area/ 
Volume
/ 
Numbe
r 
Surface 
treatment 
Designe
d 
Surface 
Area 
Absorptio
n Co-
efficient 
Absorption 
by surfaces 
sft.sabins 
North 
wall 
79x22-
2(4.9x8.8
) 
1652 sft Absorptive 
surface 
1652 0.7 1156.4 
Balcony 
railing 
79x2.5 
198 sft Wood 
paneling 
198 0.15 29.7 
South 
side 
79x40 
3160 sft Proscenium 
opening 
1280   0 
  Reflective 
surface 
1880 0.02 37.6 
East wall  2165 sft ¼ reflective 541.25 0.02 10.825 
69x32-
1(4.9x8.8
) 
  ¾ 
absorptive 
1623.75 0.7 1136.625 
West 
wall  
2165 sft ¼ reflective 541.25 0.02 10.825 
69x32-
1(4.9x8.8
) 
  ¾ 
absorptive 
1623.75 0.7 1136.625 
Ceiling 
69x79 
5451 sft ¼ wood 
paneling 
1362.75 0.15 204.4125 
  ¾  
reflective 
4088.25 0.01 40.8825 
Soffit 
23x79 
1817 sft 15% 
reflective 
272.55 0.02 5.451 
  85% 
absorptive 
1544.45 0.7 1081.115 
Floor 
main 
69x79 
5451 sft ¼ carpeted 1362.75 0.5 681.375 
Floor 
balcony 
79x23 
1817 sft ¼ carpeted 454.25 0.5 227.125 
Audience 
in 
upholster
ed seats 
750 nos   750 0.4 300 
Air  174432 
cft 
  174432 0.003 523.296 
A, Designed total absorption 6582.257 
V, volume in cft  174432 
Therefore, RT 1.32501663 
 
It is seen from the graph (Figure 15)that the RT of 
BUET auditorium is highest and 2.45 sec and the 
RT of Shishu Academy Auditorium is the lowest 
and 1.18. 
Page 77
  
 
Fig.15  Reverberation Time of 
different auditoriums 
5.2 Subjective acoustical attributes of the 
surveyed auditoriums 
 
10 performers and 10 listeners for each auditorium 
are surveyed. They were asked for the ratings of 
acoustics of the auditoriums that they know well. 
They evaluated different criteria of the acoustic of a 
hall for music such as intimacy, spaciousness etc 
and rated on a scale from poor to good conditions 
which are assigned the numbers 1 to 10. They were 
asked for the ratings of the overall impression about 
the auditoriums on scale that had five steps- very 
poor, poor, passable, good, very good which were 
assigned the numbers 1 to 5. 
 
Fig.16 Subjective qualities of different auditoriums 
 
A comparative evaluation of the subjective criteria 
of acoustic of auditoriums is seen in Figure 16. The 
National Theatre (Jatiya Natyashala) is the most 
live and the National Museum Auditorium is the 
most intimate one. The strength of sound is the 
most in BUET Auditorium but clarity is poor. 
Spatiality, reverberance, volume and 
comprehension are most in Jatiya Natyashala and 
National Museum Auditorium. Background sound 
is perceptible in BUET Auditorium and National 
Museum Auditorium is perceptible but 
uncomfortable in the rest two (Figure 17). The 
overall rating shows that Jatiya Natyashala and 
National Museum Auditorium are good, Shishu 
Academy is poor but BUET auditorium is very 
poor (Figure 18) 
 
Fig.17  Background 
sound when the music is 
off 
Fig.18 Overall 
impression rated by 
people  for different 
auditoriums 
5.3 Findings from the objective 
measurements and relation to the 
questionnaire 
 
There is a parallel relationship of Reverberation 
time with liveness of a hall, the more the RT, the 
more live the hill is and vice versa. Again if it 
exceeds an acceptable level, the hall is no longer 
live. In BUET Auditorium, RT is more than 2 
which makes the hall no longer live. Again we can 
see that, longer RT of it enhanced the loudness. The 
lower RT in the other 3 halls has impact on the 
comparatively weak sound there, but overally 
sound is strong in those auditoriums.  The RT is 
less in the other 3 auditoriums and as such clarity is 
more there than BUET Auditorium.  
.  
 
Fig.19 Correlation between objective and 
subjective parameters of auditorium acoustics 
 
6. PROBLEM IDENTIFICATION & 
DISCUSSION 
 
The overall acoustical environment in the Natonal 
Theatre and National Museum Auditorium is good 
but poor in the other two. In case of BUET 
Auditorium, loudness is higher but the other 
parameters like intimacy, spatiality, clarity are 
lower. Loudness is the outcome of longer RT, but 
intimacy, spatiality depends on some other factors. 
But though in Shishu Academy Auditorium the RT 
is within acceptable range but the performance is 
poor, its due to other factors like EDT, ITDG. Due 
to poor performance, mechanical sound system is 
always used in BUET Auditorium and Shishu 
Academy Auditorium. With the use of external 
sound system the performance is better, but the 
Page 78
  
volume of the auditoriums are below 300000 cft 
which means that the acoustic design must perform 
well without any mechanical aid. The RT of BUET 
Auditorium must be reduced to below 1.5 sec either 
by the use of absorptive materials or reducing the 
volume. Again, in case of well performed 
auditorium it is seen that the background sound 
becomes uncomfortable which need to be 
controlled. The auditoriums must be acoustically 
treated by experts in acoustic design. 
 
In our country awareness about acoustics is very 
rare among people. They are not bothered even by 
tremendous noise pollution by traffic or continuous 
loud music in speakers. People attending different 
musical concerts are also less concerned about the 
acoustics of the hall, so its also tough to get the true 
response from questionnaire survey from the people 
without acoustical knowledge. There is tremendous 
scope to improve upon the situation. Extensive 
research work is required to scientifically  
 
i) Establish the problem 
ii) Identify which groups(occupation/gender/age) 
are effected most and how 
iii) Ascertain the reasons behind the problems 
iv) Evolve low cost corrective measures (design, 
equipment, job description) (Ahmed: 2010) 
v) Discover the potentiality of local materials 
vi) Find out the required RT for different type of 
music of our country 
 
From the above discussion it can be stated that for 
the design of musical auditoriums the following 
things need to be considered-  
•Since no music hall is built for a specific type of 
music, RT must always be a compromise. But it 
must not exceed the acceptable range. 
•Echo will be particularly noticeable if the RT is 
short and diffusion is inadequate. Longer RT of the 
room provides less trouble from echo. 
•Many music (Bhaoaiya, Bhatiali, Rabindra 
Sangeet) of our country are lyric based i.e. the 
complete enjoyment depend on the understanding 
of every word, so intelligibility is an important 
acoustic criteria which must be considered. 
•Particular attention is required to control noises 
and vibrations originating from the heating, 
ventilating and air conditioning systems and 
coming from external noise sources like traffic. 
•Intimacy, clarity, spatiality, comprehension, 
definition, warmth, brilliance, loudness, liveness 
need to be achieved considering the other factors. 
•Proper positioning of absorptive and reflective 
materials is important. Acoustic design does not 
mean to cover the surfaces with absorptive 
materials, reflective materials need to be used at 
proper locations to enhance the strength of sound. 
•Acoustical design must merge with the overall 
architectural expression and for such it need to be 
considered during design phase. 
 
7. CONCLUDING REMARKS 
Acoustics is an important aspect that an architect 
has to encounter, knowingly or otherwise, to attain 
a building that is functionally effective. Generally 
very few architects or engineers in our country 
think of sound as a design element or an issue of 
concern at the design stage i.e. when they are 
drawing up the detail plans consulting with the 
building owner. It is commonly believed and 
wrongly so that with all other elements put into 
their respective slots, sound will be a natural and 
positive outcome. If an auditorium designed for 
music does not perform well, the main purpose of 
that space is not served though that can be a good 
architecture. It is the common case in most of the 
auditoriums in Dhaka. As to serve the function is 
the prime purpose of a good architecture, an 
auditorium must be acoustically sound. So the ill 
performed auditoriums must be treated properly by 
experts in the specific field. This study (performed 
within limited scope) works as a basis for further 
study and research in this specific field. 
 
 
ACKNOWLEDGEMENT 
 
The research work for this paper has been 
conducted in M. Arch Course ARCH 6102(Sonic 
Environment and Built Form) in Department of 
Architecture, Bangladesh University of Engineering 
& Technology, Dhaka, Bangladesh. 
 
REFERENCES 
 
1. Khan Matluba (2010) , Study of the 
performance of several auditoriums in Dhaka, 
Bangladesh (Term paper for the partial 
fulfillment of the M.Arch Course Arch 6102 
(Sonic Environment and Built Form) 
2. Hong Kong Academy for Performing Arts 
(1986), Auditorium Acoustic Design, 
Department of Architecture, The University of 
Hong Kong 
3. Beranek, L L (1996), Concert and Opera Halls: 
How they sound, Acoustical Society of 
America,  
4. Ahmed, Nizamuddin Dr (2010), Acoustics for 
Architects, BUET. 
Page 79
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: M.S.Islam 
E-mail: saiful-cee@sust.edu 
BUILDING CONSTRUCTION WORKERS’ QUALITY AND SAFETY: 
A CASE STUDY ON SYLHET CITY 
 
 
K. M. Khaleduzzaman; M. S. Islam*; S. K. Kundu; S. Shil 
Department of Civil & Environmental Engineering 
Shahjalal University of Science and Technology, 
Sylhet 
 
 
Sylhet is a densely populated city with approximately half million inhabitants living in an area of 26.5 sq.km 
where growth rate of population is high. Due to rapid urbanization process, a number of high rise buildings 
are constructing here. Since Sylhet city is vulnerable to earthquake, proper guideline and building codes 
should be followed for structurally sound construction. A huge number of people are involved with the 
building construction process. Most of the workers’ are from poor level of the society and are illiterate. They 
have no institutional training and are not conscious about the safety during construction. As a result, accident 
at construction site has become a very common phenomenon of this city. This project is done by field visit 
report which is focused on ten high rise buildings at different locations in Sylhet city where various types of 
data were collected from field visit report, such as project areas, structural methods of those projects, number 
of workers, materials mixing ratios, construction safety measures, quality control of materials etc. the 
present condition of the construction workers’ quality and their safety at the time of construction is evaluated 
here. Some other problems related to construction process are addressed in this study and some guideline is 
given as the solution of it. 
. 
Key words: construction worker, quality, Sylhet city, training, safety 
 
 
1. INTRODUCTION 
 
Work at construction sites is one of the most 
dangerous occupations in both developing and 
industrialized countries. According to the 
International Labor Organization (ILO), 337 
million occupational accidents occur on the job 
annually, while the number of people dying of 
different work-related diseases is close to 2 million 
(1). According to the Building and Workers 
International (BWI) report, at least 108,000 
workers are killed on the spot every year at 
construction sites. The report also states that 
construction sites account for 30 percent of all fatal 
injuries. This means that one person dies every five 
minutes due to poor and/or illegal working 
conditions (2).Construction is one of the important 
labor intensive industries in Bangladesh which 
plays a significant role in the domestic economy. It 
provides direct employment for 1.5 million people, 
which is equivalent to 3% of the total economically 
active working population (aged 15 years and 
above). This estimate comprises 1.4 million men 
and 104,000 women. Almost all of them are 
illiterate and don’t have any educational 
qualification on construction. As a result, 
sometimes, it becomes tough to control the 
soundness of the structure and maintain the cost. 
Injury and death of workers, due to ignorance of 
safety measures at the time of construction, is also a 
very common phenomenon in this country. 
Construction management is essential for achieving 
any pre-determined objective. It is, however, seen 
that in spite of construction management, majority 
of the project do not keep up their original time 
schedule and their completion cost is also higher as 
compared with the estimated cost. Quality control 
and safety represent increasingly important 
concerns for project managers. 
 
2. STUDY AREA: 
 
Sylhet is one of the rapidly growing metropolitan 
areas, located in the northeast region of Bangladesh 
and situated at 24.85° latitude and 91.80° longitudes. 
Sylhet was changed to a city corporation from a 
municipal board in 2001and in 2002 the city was 
administrated by the Sylhet City Corporation (SCC) 
and finally was granted metropolitan city status in 
31st March 2009(3).SCC  occupies a total area of 
Page 80ISBN: 978-984-33-2140-4
 26.5 sq. km with a population of around 0.5 million. 
Population density is 17,479/km2. For Sylhet 
historical background, fine climatic condition, most 
of the divisional head office, better quality of life, 
better job opportunities and for higher educational 
facilities; migration of population towards Sylhet city 
increases results elevated population density. 
Nowadays, a lots of  high rise building is constructed 
in this reason. This study is performed to analyze the 
present condition of the management sector regarding 
construction workers’ quality and their safety.  
 
3.  METHODOLOGY: 
 
 This project is done by field visit report. Ten high 
rises building at different location in Sylhet city were 
focused for the study.  All types of data were 
collected from field visit report and questionnaire 
survey related on  project area, structural method, 
number of workers, educational qualification of 
workers, materials mixing ratios, construction safety 
measures, quality control of materials etc. A 
questionnaire consisting of 13 questions which are 
directly related to the safety of the workers has been 
carried out .Finally, by analyzing the collected data 
and considering some other parameters related to the 
surveyed area, some recommendations has been 
given which can be followed for ensuring better 
quality and safety of workers’. 
 
 
4. DATA COLLECTION AND ANALYSIS 
 
Construction workers’ safety is widely related to 
the construction method, construction site, 
construction materials and equipments etc. 
workers’ qualification and awareness about safety 
is also a matter of it. It is seen that the educated 
and qualified workers are more conscious about 
their safety then the less qualified workers. The 
structural data were collected from the 
constructors, site engineers and construction firms. 
The questionnaire survey was carried out over 
more than 110 construction workers who were 
involved with the construction work of the ten 
buildings. Table: 1 is showing the structural data of 
the ten buildings that has been surveyed. Table: 2 
is representation the present workers’ safety 
condition of that construction site. Educational 
qualification and sex of the workers’ also play a 
vital rule in the construction sector. 
 
 
 
 
 
Table 1: Structural Data 
 
Serial 
No. 
Name of Project 
(Location) 
Square 
area 
Floor Foundation 
Type 
Laborer 
(Minimum) 
Design 
Method 
Construction  
Period(Year) 
1 Sylcoo Tower 
(Jail Road) 
4500 10 Pile 15-20 WSD 3 
2 Karim Tower 
(Jail Road) 
4000 10 Pile 30-35 WSD 2 
3 Safic Tower 
(Bondor) 
4500 10 Pile 25-30 WSD 2.5 
4 Rong Mohal 
Tower 
(Bondor) 
8000 10 Pile 30-35 WSD 2.5 
5 Silver Star Tower 
(Subid bazar) 
7650 12 Pile +  semi 
Mat 
30-35 USD 3 
6 Indiana Height 
(Subid bazar) 
4000 12 Raft 20-25 WSD 2.5 
7 M.  Ahamed 
Tower 
(Dorshondeuri) 
12000 17 Mat 40-45 USD 4 
8 W  Tower 
(Naiorpul) 
4000 10 Pile 20-25 WSD 2.5 
9 Shajalal Tower 
(Mira bazar) 
6000 12 Pile 30-35 WSD 2 
10 Star Plaza 
(Zindabazar) 
16000 17 Pile 45-50 WSD 4 
 
 
 
 
 
 
Page 81
 *
 
 
 
 
Table 2: Safety related questionnaire survey 
 
Question  Yes(percentage) No(percentage) 
Chance that a person may fall from any dangerous height? 100 0 
Chance that a person may fall on the working level? 60 40 
Is there any chance that a person may fall through hollow shafts, 
ducts or chutes? 
30 70 
Is there any chance that a person may be struck by any falling 
material? 
100 0 
Is there any chance that a person may be struck by moving 
vehicles or machineries? 
10 90 
Is there any chance that a person may be pierced by any sharp 
edge or any hard object?  
70 30 
Is there any chance that a person can get electric shock?  80 20 
Is there anything that can cause fire related accidents? 50 50 
Is there any chance of accidents from mechanical failure? 80 20 
Are the workers well equipped with their personal safety devices 
against accidents? 
10 90 
Is there adequate facility of first aid treatment? 70 30 
Are the workers willing to use safety devices? 65 35 
Do the workers have any institutional training? 0 100 
 
 
 
                 
 Figure1: Educational Qualification of workers’  
 
 
                  Figure1: Sex of workers’
 
5. RESULTS AND DISCUSSION: 
 
From the data analysis, it is very clear that the 
construction workers’ are working with a high risk 
of injury, even death. Almost in 70 percent cases, 
safety measures are not taken by the workers’, 
even some of them are not willing to use the safety 
equipments. Use of hamlet, groves and safety 
goggles is almost zero. The Owner and supervisor 
are not also aware about the safety. As a result of 
it, workers’ physical injury has become a very 
common phenomenon. Since the workers are not 
institutionally trained, the quality of the structures 
can’t be ensured all the time. So sometimes the 
cost of construction is to be increased and the 
construction period is become higher. 
 
 
6. CONCLUSION: 
 
The construction sector in Bangladesh is widely 
known as a ‘death trap’ due to its poor health and 
safety record and the high rate of occupational 
accidents occurring in the country each year.(5) 
And the rate is increasing in every year. At 
Bangladeshi construction sites, ordinary workers 
normally do their job according to the instructions 
given by the contractors or subcontractors who 
employ them. As a result it may affect on the 
quality of the construction. Sylhet is a developing 
city where building construction is increasing day 
by day. So it is the high time to increase the quality 
of the workers’ and safety measures of the 
workers’. Some recommendations which are the 
outcome of the study is given below that should be 
36%
29%
27%
8%
0%
<class 5
Class 5-8
Class 8-10
S.S.C Pass
H.S.C.Pass
69%
31% Male 
Worker 
Female 
Worker
Page 82
  
followed to minimize/neutralize the amount of 
injury at the construction site 
 regular inspection of safety situation 
should be ensured 
 the records of all accidents should be to 
keep compulsorily 
 The owner, contractor and workers should 
be aware about safety issues through 
awareness programme. 
 formal institutional training on safety 
precautions to the workers and contractors 
is to be ensured 
 
7. REFERENCES 
 
1. Xinhua net. This year the gross value of 
industrial output of food industries reached 
4.9 trillion RMB in China.  
2. The National 11th Five Year Development 
Plan of Agro-product Processing 
Industries. China Agro-product Processing 
net.   
3. Statistical Pocket Book of Bangladesh, 
Bangladesh Bureau of Statistics. January 
2009. Retrieved on 26 May 2009. 
4. Asian-Pacific Newsletter on Occupational 
Health and Safety, Volume 17, number 1, 
May 2010 
5. B.A. Gilly, A. Touran, and T. Asai, 
"Quality Control Circles in Construction," 
ASCE Journal of Construction 
Engineering and Management, Vol. 113, 
No. 3, 1987 
 
Page 83
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Md. Moinul Islam,  
E-mail: moinul91@yahoo.com   
CHLORIDE PENETRATION RESISTANCE OF FLY ASH CEMENT 
MORTAR 
 
Md. Moinul Islam1*and Dr. Md. Saiful Islam 1 
1
 Department of Civil Engineering, Chittagong University of Engineering& Technology, 
Chittagong-4349, Bangladesh. 
 
ABSTRACT: Durability is an important issue for concrete in aggressive environment. Concrete structures 
are often deteriorated due to chloride and sulfate attack in marine environment. This paper investigates the 
performance of fly ash mortar regarding chloride penetration resistance and compressive strength 
development up to the curing period of 90 days. Cement was partially replaced with six percentages (10%, 
20%, 30%, 40%, 50% and 60%) of Class F fly ash by weight. Ordinary Portland cement (OPC) mortar was 
also prepared as reference mortar. A total of 200 specimen of 50 mm cube were cast for compressive 
strength test and other 30 cylindrical specimen of size 100 mm diameter and 50 mm height to determine the 
chloride ion penetration resistance. Among the six fly ash mortars, the optimum amount of cement 
replacement is reported to about 40%, which provides around 16% higher compressive strength and also 
51% higher chloride penetration resistance compared to OPC mortar. Fly ash mortar also shows better 
resistance against chloride ion penetration. The study reveals that fly ash may improve the durability 
characteristics of concrete in aggressive environment due to its high fineness, which after hydration 
markedly reduces the permeability of concrete that limits the penetration of aggressive spices and also 
improve the strength characteristics.  
 
Keywords: Cement; Chloride Penetration Resistance; Compressive Strength; Durability; Fly Ash. 
 
1. INTRODUCTION 
 
The seas and oceans make up of about 80% of the 
total surface of the earth. Apart from their use for 
navigation purposes, seas and their beds are being 
widely used as the space for both onshore and 
offshore structure throughout the world. The 
reinforced concrete structures constructed in marine 
environment have to face the sea salt loadings apart 
from the normal loading. In a marine environment, 
chloride ion penetrating into the concrete from sea 
water reacts with Ca(OH)2 liberated from cement 
hydration and form calcium chloroaluminate 
(Friedels Salt). On the other hand, sulfate that 
penetrates inside concrete from seawater forms 
gypsum and a complex compound namely calcium 
sulphoaluminate (Ettringite). Both the products 
occupy a greater volume after crystallization in the 
pores of concrete than the compounds they replace. 
The formation of gypsum hydrate causes an 
increase in volume of 17.7% in concrete (Bougue, 
1971). Thus, the durability of structural concrete 
has received increasing attention in modern 
concrete technology and pozzolanic cementitious 
materials are known for their beneficial effect on 
durability of concrete structures (Swamy, 2000). 
When used as a concrete additive, these materials 
react with calcium hydroxide liberated during the 
hydration of cement to form additional 
cementitious compound, namely calcium silicate 
hydrate (CSH) and is more chemically resistant, 
mainly by virtue of its more refined microscopic 
pore structure (Roy et. al., 2001). 
The resistance to chloride penetration of mortar and 
concrete is one of the most important issues 
concerning the durability of concrete structures. 
When the chloride concentration of mortar or 
concrete exceeds a certain threshold value, 
depassivation of steel occurs and reinforced steel 
starts to corrode (Alonso et. al., 2000). It is 
generally accepted that incorporation of a pozzolan 
improves the resistance to chloride penetration and 
reduces chloride-induced corrosion initiation period 
of steel reinforcement. This is mainly due to the 
reduction of permeability/diffusivity, particularly to 
chloride ion transportation properties of the blended 
cement concrete (Tomas et. al., 1999). 
Most cement plants consume large amounts of 
energy and produce a number of undesirable 
products which provide negative impact to 
environment. Production of every tone of cement 
emits carbon dioxide to the tune of about 0.87 ton 
(Shetty, 2002) and around 7% of the world’s carbon 
dioxide emission is attributable to Portland cement 
industry. Because of significant contribution to the 
environmental pollution and to the high 
Page 84
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
  
consumption of natural resources like limestone 
etc., it would not be wise to produce more and more 
cement without thinking the proper substitute for it. 
Now a days, cement manufacturers are blending or 
intergrinding mineral additives such as fly ash, slag 
and natural pozzolana into the cement. The main 
objectives of using these materials are to reduce 
heat generation and the permeability characteristics, 
which lead to improve the durability properties of 
concrete (Detwiler et. al., 1991). 
An industry by-product which is now being used 
quite extensively as pozzolan in blended cements is 
fly ash. The incorporation of fly ash enhances the 
performance of concrete by imparting proper 
resistance to chloride and sulfate induced 
deterioration after modifying the chemistry of pore 
characteristics of the hardened concrete (Zichao et. 
al., 2003). Fineness of fly ash is higher than 
ordinary Portland cement particles (Tarun et. al., 
2006). As a result, it makes concrete more 
impermeable, which may greatly reduce penetration 
of chloride and sulfate ions, thereby increasing the 
durability of concrete (Oner et. al., 2003). Fly ash 
reacts with the product liberated at early ages 
during hydration and form secondary C-S-H gel 
which is less dense and has more volume than 
primary C-S-H gel. Therefore it fills all the pores 
inside concrete and makes the concrete more 
impermeable. The use of fly ash usually leads to a 
less permeable paste, denser interfacial zone 
between aggregate and the matrix (Chindaprasirt et. 
al., 2005). It has been shown that the use of fine fly 
ash results in better mechanical properties of 
concrete than those with the coarser fly ash. It 
increases strength, resistance to sulfate solution and 
resistance to chloride penetration of concrete 
(Chindaprasirt et. al., 2004). Fly ash, when used in 
mortar/concrete, contributes to the strength of 
mortar/concrete due to its pozzolanic reactivity. 
However, since the pozzolanic reaction proceeds 
slowly, the initial strength of fly ash concrete tends 
to be lower than that of concrete without fly ash 
(Aydin et al., 2007). Due to continued pozzolanic 
reactivity, such concrete develops strength at later 
age, which may exceed the strength of the concrete 
without fly ash. 
The objective of this research is to study the 
strength and chloride ion penetration resistance of 
blended cement mortar containing fly ash. The 
results of the study will be beneficial for future 
applications of such material for increasing the 
durability of concrete in chloride based 
environment. 
 
2. EXPERIMENTAL PROGRAM 
 
The experimental program was planed to study the 
compressive strength and chloride ion penetration 
resistance of mortars using fly ash as replacement 
of cement. Cement replacement at various 
percentage levels were used in this investigation to 
observe the effects of different fly ash levels in 
mortar in contributing the compressive strength at 
different curing ages and chloride ion penetration 
resistance. 
(a) Materials: 
(i) Cement: ASTM Type I Portland Cement was 
used as binding material. The physical properties 
and chemical compositions of cement are given in 
Table-1. 
(ii) Fly ash: A low calcium ASTM Class F fly ash 
was used in this investigation. Physical properties 
and chemical compositions of the used fly ash are 
given in Table-1. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
(iii) Sand: Locally available natural sand passing 
through 4.75 mm sieve and retained on 0.015 mm 
sieve was used for this program. Gradation of this 
sand is given in Table-2. 
 
 
 
 
 
 
 
 
 
Table 1. Physical properties and chemical analysis 
of ordinary Portland  cement and fly ash 
 
Physical properties 
ASTM 
Type-I 
Cement 
ASTM 
Class F 
Fly ash 
Fineness   
Passing #200 Sieve, % 95% 99% 
Blains, m2/kg 340 400 
Vicat Setting Time, min   
Initial 145 -- 
Final 190 -- 
Compressive Strength, MPa 
3 days 15.4 -- 
7 days 19.9 -- 
28 days 30.2 -- 
Specific gravity 3.15 -- 
Chemical analysis, %   
Calcium oxide, CaO 65.18 8.6 
Silicon dioxide, SiO2 20.80 59.3 
Aluminum oxide, Al2O3 5.22 23.4 
Ferric oxide, Fe2O3 3.15 4.8 
Magnesium oxide, MgO 1.16 0.6 
Sulfur trioxide, SO3 2.19 0.1 
Sodium Oxide, Na2O -- 3.2 
Loss on ignition 1.70 -- 
Insoluble residue 0.6 -- 
 
Table 2. Grading of fine aggregate 
 
Sieve size Cumulative % Passing  
1.18 mm (No. 16) 100 
600 µm  (No. 30) 97 
425 µm  (No. 40) 73 
300 µm  (No. 50) 28 
150 µm   (No. 100) 3 
 
Page 85
  
(b) Mortar quality: Six different mix proportions 
of cement fly ash (90:10, 80:20, 70:30, 60:40, 
50:50, 40:60) were used as cmentitious material. 
The mortar mixes are designated as 10%, 20%, 
30%, 40%, 50% and 60% fly ash mortar. Cement 
fly ash mix ratio of 100:0 i.e. plain cement mortar 
specimens were also cast as reference mortar for 
comparing the properties of fly ash mortars. The fly 
ash mortar means the mortar made by using cement 
and fly ash as cementitious material with sand and 
water. 
(c) Mix proportions and curing: Sand to 
cementitious material ratio of 2.75 by weight and 
water to cementittious material ratio of 0.485 were 
used in making mortar specimens for compressive 
strength and chloride ion penetration resistance test. 
Super plasticizer was incorporated in order to 
obtain mortar mixes with a similar flow of 110±5% 
in accordance with ASTM C109. The cast 
specimens were covered with polythene sheet and 
damped cloth and placed in 27±2ºC Chamber. They 
were demoulded at the age of one day and cured in 
water at 27±2ºC. 
(d) Compressive strength: The 50 mm cube 
specimens were prepared in accordance with 
ASTM C109. They were tested at the age of 3, 7, 
28, 60 and 90 days. The reported results for each 
test variables are taken as the average of three 
sample test readings. 
(e) Rapid chloride penetration resistance: The 
100 x 200 mm cylinders were prepared for chloride 
penetration resistance in accordance with ASTM 
C39. After being cured in water for the age of 27 
days, they were cut into 50 mm slices with the 50 
mm ends discarded. The 50 mm slices were epoxy-
coated around the cylindrical surface. The 100 mm 
dia. x 50 mm epoxy-coated specimens were tested 
at the age of 28 days for rapid chloride penetration 
test (RCPT) in accordance with the method 
described in ASTM C1202. The reported results are 
taken as the average of three samples. The test 
setup for determination of chloride ion penetration 
resistance is shown in Fig.1 to 4. The ASTM 
guidelines concerning the chloride ion penetrability 
are given in Table-3.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 Fig. 1: Sealing of the sample with in the cell 
Fig. 2: Pouring 3% NaCl and NaOH solution in 
the cells 
Fig. 3: Test arrangement for resistance to chloride             
ion penetration 
Fig. 4: Display unit for chloride ion penetration             
resistant equipment 
 
Table 3. Guidelines for Chloride-ion penetrability                 
based on charge passed (ASTM C 1202) 
 
Charge passed,  
Coulombs 
Chloride ion 
penetrability 
>4000 High 
2000-4000 Moderate 
1000-2000 Low 
100-1000 Very Low 
<100 Negligible 
 
Page 86
  
3. RESULTS AND DISCUSSION 
  
Various types of specimens made from different 
proportion of OPC and fly ash mortar were exposed 
to plain water to determine compressive strength 
and resistance to chloride ion penetration for 
various exposure periods. OPC mortar is considered 
as datum and used to compare the effect of fly ash 
in strength gaining and against chloride ion 
penetration. 
 
3.1. Compressive Strength 
The compressive strength of OPC and fly ash 
mortars as listed in Table-4, has been graphically 
represented in Fig.5. Also for the ease of 
comparison, the relative compressive strengths are 
plotted in Fig.6. Among all the mixes, for 3 days 
and 7 days compressive strength, no fly ash mortar 
achieves as much strength as that of OPC mortar. 
Test results showed that the 3 days compressive 
strength for OPC mortar is 9%, 15%, 23%, 29%, 
45% and 59% higher than 10%, 20%, 30%, 40%, 
50% and 60% fly ash mortar respectively. Up to 
curing period of 7 days, compressive strength is 
seen to decrease with the increase in fly ash content 
when compared with no fly ash mortar. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
28 days compressive strength of the specimens up 
to 50% replacement level was reported to be similar 
with OPC mortar strength. Compressive strength 
are slightly lower by 3%,1%, 1% and 9% for fly 
ash mortar of cement fly ash ratio 90:10, 80:20, 
50:50 and 40:60 respectively when compared with 
OPC mortar. 28 days strength for the 30% and 40% 
fly ash mortar was observed to be 2% and 4% 
higher when compared with no fly ash mortar. 
60 days compressive strength data obtained for 
10%, 20%, 30%, 40% and 50% fly ash mortar were 
respectively 5%, 9%, 11%, 15% and 7% higher 
than no fly ash mortar, whereas 60% fly ash mortar 
strength was lower than OPC mortar by 7%. After 
90 days, maximum compressive strength was 
obtained for 30% and 40% fly ash mortar 
specimens with an increase in strength of 13% and 
16% respectively as compared to OPC mortar. Also 
10%, 20% and 50% replacement level provided an 
increase in strength of 7%, 10% and 9% 
respectively as compared with no fly ash mortar. 
Cement normally gains its maximum strength 
within 28 days. During that period, lime produced 
form cement hydration remains within the 
hydration product. Generally, this lime reacts with 
fly ash and imparts more strength. For this reason, 
mortar made with fly ash will have almost same 
strength as that of OPC mortar up to 28 days and 
substantially higher strength within 90 days. Fly 
ash retards the hydration of C3S in the early stages 
but accelerates it at later stages (Jawed and Skalny, 
1981). Conversely in cement mortar, this lime 
would remain intact and with time it would be 
susceptible to the effects of weathering and loss of 
strength and durability. Yamato and Sugita (1983) 
found that the later age strength of fly ash concrete 
was higher than that of the control concrete and that 
the modulus of elasticity was comparable to that of 
concrete made with moderate heat Portland cement. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Table 4. Compressive strength (MPa) of cement : fly ash mortars for various replacement level 
                      
Replacement 
Level Ce:FA  Ce:FA Ce:FA Ce:FA Ce:FA Ce:FA Ce:FA 
Curing 
Period (days) 100:0 90:10 80:20 70:30 60:40 50:50 40:60 
3 14.3 13.0 12.2 11.0 10.1 7.8 5.9 
7 20.3 19.1 18.4 17.0 16.2 13.0 10.9 
28 28.0 27.2 27.7 28.4 29.1 27.7 25.5 
60 30.9 32.3 33.8 34.4 35.5 33.1 28.9 
90 33.3 35.7 36.5 37.8 38.7 36.2 31.2 
 
        Ce : Cement ;  FA: Fly Ash 
0 10 20 30 40 50 60 70 80 90 100
0
5
10
15
20
25
30
35
40
Ce  =  Cement
FA  =  Fly Ash
Ce : FA
Fig. 5: Compressive strength- exposure time relation for  
            cement:fly ash mortars          
Co
m
pr
es
si
v
e 
St
re
n
gt
h 
(M
Pa
)
Exposure Period (days)
 100 : 0
 90 : 10
 80 : 20
 70 : 30
 60 : 40
 50 : 50
 40 : 60
Page 87
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
3.2. Resistance to Chloride Ion Penetration 
Chloride ion penetration resistance value for OPC 
and fly ash mortar cured for 28 days period are 
shown in Table-5 as well as graphically presented 
in Fig.7.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
In case of OPC mortar, amount of passing charge is 
6900 coulombs whereas the similar value for fly 
ash mortars are 4300, 3900, 3400, 2700, 2300 and 
2000 coulombs for 10%, 20%, 30%, 40%, 50% and 
60% fly ash mortars respectively. The incorporation 
of pozzolanic materials improves the resistance to 
chloride penetration of mortar as confirmed by 
other researchers (Janotka and Krajci, 2000). A 
close observation of the data shows that fly ash 
mortar has relatively better resistance against 
chloride ion penetration. Fly ash has high fineness 
and can react with the products liberated during 
hydration. It forms secondary C-S-H gel that fills 
all the pores inside concrete and makes it more 
impermeable (Yalbot et. al., 1995). So it reduces 
the amount of charge passed thorough the concrete. 
Experimental result shows that as the amount of fly 
ash used in mortar is increased, charge flow 
through the mortar sample is decreased. This is due 
to the reduction of the pore spaces inside the mortar 
specimen that makes the mortar dense and compact 
and as a result the amount of charge flow is 
decreased. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Overall observation shows that after 90 days curing 
compressive strength values obtained for 20%, 
30%, 40% and 50%  fly ash mortar were 10%, 
13%, 16% and 9% higher than OPC mortar 
respectively, whereas chloride penetration 
resistance is 43%, 51%, 61% and 67% higher as 
compared to OPC mortar. From both strength and 
chloride penetration resistance point of view, these 
four types of mortar are comparable. Among them 
20%, 30% and 40% fly ash mortar are better from 
strength consideration. Again from the three mortar 
mix 40% fly ash mortar has better resistance 
against chloride ion penetration. Also all the values 
lie in the moderate range as per ASTM guidelines. 
60% fly ash mortar shows best result against 
chloride ion penetration which is 71% better as 
compared to OPC mortar but strength is 6% lower 
as compared to OPC mortar. So this mortar is not 
good form strength point of view. After analyzing 
all the experimental result, it may be concluded that 
40% fly ash mortar is best from durability as well 
as strength point of view. 
0 10 20 30 40 50 60 70 80 90 100
30
40
50
60
70
80
90
100
110
120
Ce  =  Cement
FA  =  Fly Ash
Ce : FA
 
 
Fig. 6:  Relative compressive strength-exposure time relation
             for cement:fly ash mortars            
Re
la
tiv
e
 
Co
m
pr
e
ss
iv
e 
St
re
n
gt
h 
(%
)
Exposure Period (days)
 100 : 0
 90 : 10
 80 : 20
 70 : 30
 60 : 40
 50 : 50
 40 : 60
Table 5. Chloride ion penetration Resistance      
(Coulombs) 
Type of Mortar Charge Passed  
Curing 
Period 
OPC Mortar 6900 
28 Days 
Fly ash Mortar 
(10% Fly ash) 4300 
Fly ash Mortar 
(20% Fly ash) 3900 
Fly ash Mortar 
(30% Fly ash) 3400 
Fly ash Mortar 
(40% Fly ash) 2700 
Fly ash Mortar 
(50% Fly ash) 2300 
Fly ash Mortar 
(60% Fly ash) 2000 
 
OPC 10% FA 20% FA 30% FA 40% FA 50% FA 60% FA
0
1000
2000
3000
4000
5000
6000
7000
Ce  =  Cement
FA  =  Fly Ash
Ce : FA
OPC        100:0
10% FA   90:10
20% FA   80:20
30% FA   70:30
40% FA   60:40
50% FA   50:50
60% FA   40:60
Fig. 7: Charge passed of rapid chloride penerration test (RCPT)
Ch
ar
ge
 
pa
ss
ed
 
(C
o
u
lo
m
b)
Types of Mortar
Page 88
  
4. CONCLUSION 
 
Based on limited number of test variables studied 
and the results of the investigation conducted on 
different types of mortars, the following 
conclusions are drawn. 
 
(1) The rate of gain in strength of fly ash mortar 
specimens is observed to be lower than the 
corresponding OPC mortar at early ages of curing. 
(2) Fly ash mortar mix having various cement 
replacement level up to 50% exhibited satisfactory 
results for both compressive strength and chloride 
ion penetration resistance.  
(3) Fly ash blended mortar of replacement level 
40% to 60% exhibited moderate penetrability to 
chloride ions diffusion as per ASTM guideline, 
whereas OPC mortar falls within the high range of 
chloride penetrability.  
(4) From both strength and chloride resistance 
consideration, the optimum fly ash content is 
observed to be 40% of cement. After 90 days 
curing, fly ash mortars with 40% cement 
replacement shows around 16% higher compressive 
strength compared to OPC mortar. Also, it shows 
around 51% higher resistance against chloride ion 
penetration.   
(5) In addition to lower chloride penetrability, use 
of fly ash as a partial replacement of cement in any 
construction work, provides lower impact on 
environment (reduce CO2 emission) and judicious 
use of resources (energy conservation, use of by-
product) 
 
REFERENCES 
 
Alonso, C., Andrade, C., Castellote, M., Castro, P., 
(2000), Chloride threshold values to de passivate 
reinforcing bars embedded in a standardized OPC 
mortar, Cement Concrete Research journal, Vol.30, 
No.7, pp.1047-1055. 
Aydin, Serdar. & Bulent, Baradan., (2007), Effect 
of Pumice and Fly Ash incorporation on High 
Temperature Resistance of Cement Based Mortars, 
Cement and Concrete Research Journal, Vol. 37, 
pp.988-995. 
Bougue, R. H., (1971), Chemistry of Portland 
Cement, Reinhold Publishing Company’s, New 
York. 
Chindaprasirt, p., Homwuttiwong, S., 
Sirivivatnanon, V., (2004), Influence of fly ash 
fineness on strength, drying shrinkage and sulfate 
resistance of blended cement mortar, Cement 
Concrete Research Journal, Vol.34, pp.1087-1092. 
 
Chindaprasirt, p., Jaturapitakkul, C., Sinsiri, T., 
(2005), Effect of fly ash fineness on compressive 
strength and pore size of blended cement paste, 
Cement Concrete Composite Journal, Vol.27, No.4, 
pp. 425-428. 
Detwiler, R. J., Kjellsen, K. O. and Gjorv, O. E., 
(1991), Resistance of Chloride Intrusion of 
Concrete Cured at Different Temperature, ACI 
Material Journal, Vol.88, No.1, pp. 19-24. 
Janotka. I., and Krajci, L., (2000), In: Malhotra VM 
(ed) Proceedings of the fifth CANMET/ACI 
international conference on durability of concrete, 
SP-192, pp. 223. 
Jawed, I., and Skalny, J., (1981), Hydration of 
tricalcium silicate in the presence of fly ash, Effects 
of Fly Ash Incorporation in Cement and Concrete, 
Proceedings, Symposium Materials Research 
Society, Sidney, pp.60-70. 
Oner, M., Erdogdu, K., and Gunlu, A., (2003), 
Effect of Components Fineness on Strength of Blast 
Furnace Slag Cement, Cement and Concrete 
Research Journal, Vol.33, No.4, pp. 463-469. 
Roy, D. M., Arjunan, P. and Silsbee, M. R., (2001) 
Cement Concrete Research Journal, Vol.31, 
pp.1809. 
Shetty, M.S., (2002), Concrete Technology, 
Chapter – 5, pp-176, 2002. 
Swamy, R. N., (2000), Proceedings of the 
CANMET/ACI International Symposium on 
Concrete Technology for Sustainable Development, 
Vancouver, BC, Canada. 
Talbot, C., Pigeon, M., Maarchand, M., Hornain, J., 
(1995), In: Proceeding of the fifth international 
conference on the use of fly ash , silica fume, slag, 
and natural pozzolana in Concrete, Milwaukee, ACI 
SP 153, pp. 125. 
Tarun, R. Naik., Rudolph, N. Kaaus., and Rafat, 
Siddique., Yoon, Moon. Chun., (2006), Properties 
of Controlled Low Strength Materials Made with 
Wood Fly Ash, Journal of ASTM International, 
Vol. 1, No. 6, www.astm.org, June. 
Thomas, M. D.A, Bamforth, P. B., (1999), 
Modeling Chloride Diffusion in Concrete: Effect of 
fly ash and slag, Cement Concrete Research 
Journal, Vol.29, No.4, pp.487-495. 
Yamato, Takeshi and Sugita, Hideaki., (1983), 
Shrinkage and Creep of Mass Concrete Containing 
Fly Ash, Fly Ash, Silica Fume, Slag and Other 
Mineral By- Products in Concrete, ACI SP-79, 
pp. 87-102. 
Zichao, Wu., and Tarun, R. Naik., (2003), 
Chemically Activated Blended Cements, ACI 
Materials Journal, Vol.100, No.5, pp. 434-439. 
 
Page 89
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*Corresponding Author: A. A. Masrur Ahmed 
E-mail: aa_masrurahmed@yahoo.com 
 
 
People 
Plants  
Pathogen 
destruction  
Excreta 
Safe fertilizer + soil 
conditioner 
Safe and nutritious 
food 
Harvested crop 
 
Transport 
Storage 
Processing  
 
CHALLENGES AND OPPORTUNITIES OF ECO-TOILET FOR LOW 
INCOME COMMUNITIES OF SYLHET CITY 
*A. A. Masrur Ahmed1, A. A. M. Ahmed2, M. J. B. Alam3 and S. B. Faruque1  
1Department of Civil Engineering, Leading University, Sylhet, Bangladesh 
1Department of Business Administration, Leading University, Sylhet, Bangladesh 
3Department of Civil and Environmental Engineering, Shahjalal University Of science and 
Technology, Sylhet, Bangladesh 
 
ABSTRACT 
Eco-sanitation technology has been implemented in various part of the world, including both developed and 
developing countries as a sustainable sanitation option. Eco sanitation is good for environment, inexpensive 
and provides the only sustainable solutions available to problems of water shortage and sanitation problems. 
Eco toilet as a sustainable option can play an important rule to human waste disposal, retrieve and reuse the 
nutrients from human waste, and reduces use of water. Recycling of human excreta as fertilizer is the main 
reason to be appreciated by the users. Eco-toilet is new to Bangladesh. Some of NGOs implemented eco 
toilet in some areas of the country. This study focuses on the challenges and opportunities of eco toilet 
installation. In Sylhet city a huge number of slum people exist. Due to lack of fund and people awareness 
eco toilet are becoming very difficult to install. People have very short opportunity to use the fertilizers 
produced from the eco toilet by them. People have also superstition in having the vegetable produced by 
using the fertilizers from eco toilet.  A family of 5 members produces the waste which has a value of BDT 
5292.5. If government and other nongovernmental organization come forward the challenges can be 
removed. 
Keywords: Eco-sanitation, human waste, eco-toilet, challenges etc. 
 
1. INTRODUCTION 
 
Sylhet is a tea producing area of Bangladesh 
situated in north eastern part of the country, where 
a huge amount of migrated people live in slums [1]. 
Open defecation is a very common practice in the 
slums. Children practice open defecation more than 
adults. In maximum number of slums there are 
unhealthy sanitary latrines and proper disposal 
facilities. About 70% children in slums practice 
open defecation. It is evident that about 27.8% slum 
people practices open defecation in average and 
about 39% slum people uses unsanitary latrine and 
27% uses low cost sanitary latrines. Only 6.2% 
people have paka (RCC structure) latrines available 
to use [3].  
Eco-sanitation is a new way of looking at 
sanitation.  It treats human waste as a resource, and 
seeks to reintegrate sanitation with agriculture in a 
safe way, in order to reduce disease and improve 
low-income farmers’ access to high-quality 
fertilizer [2].  It also looks at reducing waste of 
water, recharging ground water, and ensuring that 
people’s need for water is met in a sustainable 
manner. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 1: Safe, green and valuable ecological 
sanitation 
 
Eco-sanitation offers important solutions to many 
of the pressing and related problems of water and 
sanitation. Eco-sanitation involves extensive 
systems with multiple components. It can include 
systems for rainwater collection and use. It can 
Page 90ISBN: 978-984-33-2140-4
  
Vent Pipe 
Heat Panel 
Anal 
Cleansing 
Place 
Pedestal  
Eco Plastic 
Fiber Pan 
involve reuse of grey water (the water from sinks 
and showers that otherwise goes down drains) to 
flush toilets or water plants or for agriculture. It can 
involve separation and composting of human waste 
in such a way as to benefit agriculture by providing 
needed fertilizer while also increasing access to 
clean and odor-free toilets for the poor. Eco toilet is 
a helpful tool for eco- friendly sanitation practice. It 
is designed to establish a way of sanitation practice 
which will enable fair waste management through 
collection and recycling. In an eco-toilet the human 
feces, urines and water used in latrine are collected 
separately. The basic function of eco toilet is 
collecting human feces as a dry waste. To do so eco 
toilet contains a heat panel. Figure 2 shows the 
internal model of eco toilet. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 2: Internal portion of Eco-toilet 
 
Benefits of eco toilet: 
Eco toilet is environmental friendly and it provides 
so many facilities to manage the human excreta in a 
sustainable ways such as- 
• It reduces water pollution; indirectly 
prevent the water born diseases which 
exist in Bangladesh at a huge rate. 
• Since eco toilet needs no flushing water 
hence it reduces the consumption of water. 
• In Bangladesh and many other agricultural 
country scarcity of fertilizer hampers 
agricultural production. By using eco toilet 
big amount of fertilizer can be produce, 
which is environment friendly. 
• The life cycle of human excreta in the eco 
toilet system starts from the people and 
ends to the people, which maintain the 
ecological balance. Figure 2 shows the 
cycle involved in disposing of human 
excreta through eco toilet. 
• In eco toilet system there is no smell 
problem, no fly nuisance and no insect 
breeding. 
• Young children can use it safely. 
• Poor people can be free of the scarcity of 
fertilizer. 
• Reduce the rate of diseases suffered by the 
people. 
Cost of installation & price of recycled products: 
In installation of an eco toilet the involved costs are  
• Land cost 
• Construction cost 
• Cost of ash 
Cost of ash and the land is not considered in this 
study. The main cost is the construction cost is 
about BDT 12500-1500. In a family of 5 members 
the total solid component from urine and feces is 
about 529.25 kg. The price of the waste is about 
BDT 5292.5; assuming the price of the fertilizer is 
about BDT 10. Additionally, the water 
consumption is reduced by 5475 liters/year in eco 
toilet practice by a family of 5 members. 
 
Table 1: Solid materials produced from the 
urine and feaces and their value. 
 
Human 
Waste 
Compo
nent 
HH 
Member
s 
Yearly 
Producti
on(Kg) 
Value
(Tk) 
Feces Solid 5 91.25 912.5 
Urine Solid 5 438 4380 
 
Challenges: 
The main challenges to introduce the eco toilet are 
• Cost 
• Low awareness level 
• Proper maintenance 
Most of the people become interested in seeing the 
opportunity of eco toilet. But due to lack of funds 
they cannot take the steps to introduce it. In 
Bangladesh the open defecation and unsanitary 
sanitation practice is common among the low 
income people. They are even not educated and 
aware. To ensure the effective practice of eco toilet 
training is essential to teach the maintenance 
procedure of eco toilet. 
To overcome the challenges of the eco toilet 
installation and practice the parties which can be 
very effective are as follows- 
• Local organizations and NGOs. 
• Government and official bodies. 
• Commercial and private sectors. 
Page 91
  
Table 1: Name, Location and identity of the study area
• International development organizations 
and donors. 
• Educational and research institutions.
• Technical schools and technology centers.
• Professional association and bodies.
2. METHODOLOGY 
 
This study has done mainly to assess 
and opportunities to introduce the eco
sustainable sanitation option to the low income 
people. For this reason 6 slums were selected from 
the different area of Sylhet city. Two slums were 
selected from village area (Mirerchar, Kamal 
Bazar); two were selected from town 
Subhanighat) and two from tea garden area
(Malnicherra, Lakkatura).  
 
 
 
 
Relevant data from each zone were collected that 
included socio-economic conditions of the slum 
dwellers, rate of people have problem in installing 
toilet, access to quantity and quality of water, 
access to basic sanitation services and sanitation 
behavior of the people. The awareness level and 
educational attainment of the people were also 
taken into account. Several approaches to data 
collection were used that included household 
survey, key informants’ interviews and case 
studies.  
 
3. RESULT  
 
In case of eco toilet installation in the place of 
existing toilet an initial investment is needed. Since 
the slum people are very low income people hence 
they cannot provide the fund for establishing eco 
toilet. Figure-1 shows the rate of people considered 
they have economic problem to install the eco 
toilet. It is found that in Z-4 89.5% people have 
economic problem to introduce the eco toilet.
Identity 
 
Name of the slum 
 
Z-1 Mejortila 
 
Town slum
Z-2 Subhanighat 
 
Town slum
Z-3 Mirerchar 
 
Village slum
Z-4 Kamal bazaar 
 
Village slum
Z-5 Malnicherra 
 
Tea estate slum
Z-6 Lakkatura 
 
Tea estate Slum
 
 
 
 
the challenges 
-toilet as a 
(Mejortila, 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1: Rate of people have economic problem 
to install eco-toilet. 
 
 
 
 
Practice of the eco toilet is different from the 
existing toilet to ensure the separation of urine, 
feces and water. In Z-6 61.7% and in Z
slum people think that that there have problem in 
eco toilet practice.Figure-2 shows the rate of people 
think that eco toilet have problems in use.
 
 
Figure 2: Rate of people have problem in eco 
toilet practice. 
0%
10%
20%
30%
40%
Z-1 Z-2 Z-3 Z-4 Z-
Catagory  Location 
 
 North eastern part of Sylhet, outside the City 
Corporation  ( Near to Ward No. 25) 
 Southeast part of Sylhet city (Ward No. 15)
 Near Biswanath Upozila  
 Southwestern part of Sylhet, outside the City 
Corporation. ( Near to Ward No. 20) 
 Northern portion of the city (Ward No. 17)
 Northern portion of the city (Ward No. 17)
0%
5%
10%
15%
20%
25%
30%
35%
40%
Z-1 Z-2 Z-3 Z-4 Z-5
-2 36.2% 
 
 
5 Z-6
 
 
 
Z-6
Page 92
Conference on Engineering Research, Innovation and Education 2011
 
 
The slum people are not educated enough and they 
have very low level of awareness and knowledge 
about eco toilet practice. It is determined that in Z
13% people are aware and in Z-6 only 5.4% people 
are aware about the eco toilet practice and its 
benefits.Figure-3 shows the rate of people aware 
about the eco toilet. Mentionable there have few 
program undertaken to increase the awareness level 
of the people of the study area. 
 
 
Figure 3: Rate of awareness of the people.
The slums in the village area have more 
opportunity to use the produced fertilizer from the 
eco toilet than the slums in town area. Thi
because the village slums have more open place for 
farming than town slums. In Z-1 and Z
and 6% people have this opportunity respectively. 
In Z-4 27% people have this opportunity. In Z
and Z-6 above 40% people have opportunity to use 
the fertilizers by themselves. Figure 4 shows the 
rate people have opportunity to use the fertilizer by 
themselves. 
 
 
Figure 4: Rate of people has fertilizer using
opportunity produced from the eco toilet by 
them. 
0%
2%
4%
6%
8%
10%
12%
14%
16%
Z-1 Z-2 Z-3 Z-4 Z-
0%
5%
10%
15%
20%
25%
30%
35%
40%
Z-1 Z-2 Z-3 Z-4 Z-5
Proceedings of the
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh
-1 
 
 
s is 
-2 only 105 
-5 
 
 
Though there are problems involved in eco
installation and practice, but still now 
good motivation to the benefits of eco toilet. In case 
of tea garden slum motivation level is mentionable. 
In Z-5 and Z-6 above 37% people are motivated to 
the eco toilet.  Figure 5 shows the rate of people 
motivated to the eco toilet. 
 
 
Figure 5: Motivation rate of the people to use the 
eco toilet. 
As we know that the slum peoples are not educated 
enough they have superstition in having the 
vegetables produced by using the fertilizers from 
eco toilet. The superstition is high in case of village 
slum and tea garden slum people. In Z
people disagree to have the vegetable and in Z
47.1 % people have disagreed to have these 
vegetables. 
 
 
Figure 6: Rate of people disagree to have the 
vegetable produced from the fertilizers of eco 
toilet. 
 
5 Z-6
Z-6
0%
5%
10%
15%
20%
25%
30%
35%
40%
Z-1 Z-2 Z-3 Z-4 Z-5
0%
10%
20%
30%
40%
50%
Z-1 Z-2 Z-3 Z-4 Z
 
 
 
-toilet 
people have 
 
-3 42.5% 
-5 
 
Z-6
-5 Z-6
Page 93
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
 
4. CONCLUSION  
Installation of eco toilet is very much challenging 
in case of low income people. It is shown that the 
low income people are not able to provide the fund 
needed for the eco toilet installation. They are not 
aware also. But there have many mentionable 
benefits of eco toilet. To install the eco toilet the 
following steps are recommended- 
• Government organization should provide 
the funds and organize programs to 
increase the awareness and knowledge of 
the people. 
• Micro credit can be provided for the eco 
toilet installation. 
• Scientific explanation about the healthy 
consumption of the vegetable produced by 
the fertilizers from the eco toilet needed to 
be established and communicated. 
• Benefits of eco toilet should be 
communicated with mass people.  
• The produced fertilizers can be 
manufactured and lunched at the market. 
REFERENCES 
1. Ahmed, A. A. M., Alam, M. J. B., Ahmed, A. 
A. M., (2010) “Evaluation of sanitation 
hygiene: a case study of slums in sylhet”, 
Procedeengs of the Regional Conference on 
Appropriate Water Supply, Sanitation, and 
Hygiene (WASH) Solutions for Informal 
Settlements and Marginalized Communities, 
Kathmandu, Nepal, May 19-21, 2010. Pp 1-10.  
2. Arafat, I., Rahman, R., (2010) “Evaluation of 
sanitation hygiene: a case study of slums in 
sylhet”, Procedeengs of the Regional 
Conference on Appropriate Water Supply, 
Sanitation, and Hygiene (WASH) Solutions for 
Informal Settlements and Marginalized 
Communities, Kathmandu, Nepal, May 19-21, 
2010. Pp 105-112.  
3. Mishra, N.K., (2003). Ecosan in Past and 
Present Effort in Nepal, International 
Symposium on Scological Sanitation, 
Incorporating the 1st IWA Specialist Group 
Conference on Sustainable Sanitation, Lubeck, 
Germany.  
Page 94
* Corresponding Author: Qazi Azizul Mowla,  
E-mail: qmowla@yahoo.co.uk  
CLIMATE CHANGE AND CLIMATE REFUGEE NEXUS IN 
BANGLADESH CONTEXT 
 
 
Bayezid Ismail Choudhury   
Research Student at the University of Sydney, Australia & Former Assistant Professor, BUET. 
 
Qazi Azizul Mowla 
Professor, Department of Architecture, Bangladesh University of Engineering and Technology 
(BUET), Dhaka-1000, Bangladesh.  
 
 
Due to the climate change and consequent sea level rise (SLR), extreme environmental phenomenons are 
presumed to occur more frequently and more intensely in Bangladesh. It is feared that this will result in huge 
population exodus. Dhaka being the capital city and most desired destination for most migrants (Climate 
Refugees-CR), will put great pressure on it. Dhaka is already burdened with many problems including; 
overcrowding, environmental degradation, lack of infrastructure and services, poor governance etc. and has 
limited physical and managerial capacity to cope with such problems and the CRs would be an added 
pressure on it. The objective of his paper is discuss SLR scenario and explore for a range of adaptive 
measures to respond to SLR induced situation. It is believed that the proposed measures will prevent large 
scale migrations and Dhaka would be saved from further deterioration due to CR induced overcrowding 
whilst helping them to avoid the misery of urban life in the slums of Dhaka. 
 
Keywords: Environment; Climate Change; Climate Refugee; Adaptation; Urban.  
 
1. INTRODUCTION 
 
The global climate is changing due to both 
anthropogenic and natural process. The United 
Nations Development Programme reiterates that the 
scientific evidence supporting climate change is 
clear and that climate change is now a reality 
(UNDP, 2007/2008). In its 2007 report, the UN 
Intergovernmental Panel on Climate Change1 
(IPCC) provides convincing evidence of the 
ongoing processes of climate change and the 
contributing factors. 
The impact of climate change is vast and complex. 
One of the significant impacts is the increased 
population displacements. The IPCC (2007) report 
estimated that by 2050, 150 million people could be 
displaced by climate change related phenomenon. 
Bangladesh, with its low-lying deltaic environment, 
will be severely affected by the climate change. 
According to UNDP (2010), by the year 2050, 
Bangladesh could loose 18 % of its land due to 
rising sea levels (SLR), resulting in 30 million 
                                               
1 The intergovernmental PANEL ON Climate Change (IPCC) 
formed in 1988 is a scientific intergovernmental body tasked 
with evaluating the risk of climate change caused by human 
activity.  The IPCC shared the 2007 Nobel Peace Prize.  
displaced people or climate refugees (CR). The 
displacement of people to new and existing 
settlements will put additional pressure on 
infrastructure and other services (IPCC, 2007). 
Factors like resources to move, livelihoods and 
social networks are regarded as the cause of 
migration. For social networking and secured 
livelihood reasons, options to migrate to Dhaka are 
most probable for CRs (Sirajee, 2010). 
Dhaka is already burdened by many problems such 
as overpopulation, unplanned and inadequate 
services and infrastructure, poor governance, severe 
traffic congestion and environmental degradation. 
Additionally, when migrants end up invariably in 
the slums of Dhaka, the situation will further 
worsen. According to Begum (1999) more than 
90% of migrants admitted to being influenced by 
the capital city status of Dhaka and nearly two 
thirds had over-estimated the facilities available in 
Dhaka. As a result, Dhaka has become long 
established and ultimate destination for most 
internal migrants, whether they are CRs or not 
(Courier, 2009). “Migrants to the city of Dhaka are 
not all single minded individuals who possess 
transferable skills; many tend to be illiterate, 
unskilled, old, and ill equipped for the city” 
(Begum,1999,p4). As such, migration to Dhaka 
Page 95
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
  
places an additional burden to already fragile urban 
infrastructure and population. 
 
2. STUDY FRAMEWORK 
 
2.1. Study Issues:  
The paper aims to see various scenarios of adaptive 
measures to accommodate the CRs. Research on 
SLR, CR and adaptation measures in the human 
settlement is almost non-existent. Courier (2009) 
thinks that enough reliable, holistic research simply 
doesn't exist on CRs. It can be suggested that a 
planned migration process can be undertaken which 
could be proposed under the scope of National level 
and Regional level adaptive measures. These need 
to be undertaken in a process where first option is 
to retain people within the effected areas and the 2nd 
option could be to encourage them to move to 
regional cities and gradually to bigger cities. This 
paper is concerned with the first option ie, retaining 
people in their place through local level adaptive 
measures.  
2.2. Understanding the Context:  
Climate change refers to a change of climate that is 
caused by human activity directly or indirectly, 
thus resulting in change in global atmosphere in 
addition to that climate variability observed over 
comparable time periods (IPCC, 2007). As early as 
1990 the IPCC also noted that “The greatest single 
impact of climate change might be on human 
migration - with millions of people displaced by 
shoreline erosion, coastal flooding and agricultural 
disruption”. Salehyan (2005) stated - 
“Environmental pressures have shaped human 
migration and settlement patterns for the 
millennia”. In general, the International 
Organization for Migration (IOM) proposes the 
following definition of such migrants. 
“Environmental migrants are persons or 
groups of persons, who, for compelling 
reasons of sudden or progressive changes in 
the environment that adversely affect their 
lives or living conditions, are obliged to leave 
their habitual homes, or chose to do so, either 
temporarily or permanently, and who move 
either within their country or 
abroad”.(IOM,2008,p1-2) 
The problems generated from CR induced ethnic 
tension, distrust and other conditions may de-
stabilize host areas. “Conflict may erupt in 
receiving areas in response to competition, as CRs 
may burden the economic and resource base of the 
receiving area and competing for the resources.” 
(Mowla &Zareen, 2005; Mowla, 2008). Often 
conflict in some cases may erupt due to resource 
scarcity and competition and this conflict can lead 
to greater migration. (Salehyan,2005). Dhaka being 
already burdened with social tension is extremely 
susceptible to such conflict.  
 
3. CLIMATE CHANGE AND 
CLIMATE REFUGEE NEXUS IN 
BANGLADESH CONTEXT 
 
The victims of climate change may be affected by 
four different phenomenon such as Deluge of a 
large part of the country; Intrusion of Salinity; 
Destabilization of rivers; Increase in extreme 
weather event (Islam, S. 2010). All such 
phenomenon is already contributing to the cause of 
CRs to Dhaka of both temporary and permanent 
type (Shafi, 2010). Severe conditions already 
prevail in Southern part of Bangladesh and will 
continue hitting the area more frequently in near 
future. Drought will also have some impact on the 
western part of the country. Flood will have adverse 
impact especially on the Gangetic plain. At present 
CRs gets displaced from these regions. 
Adaptation can be defined as a method of 
adjustment or coping mechanism with its 
surrounding that helps improve the quality of life 
under strenuous circumstances (Mowla & Zereen, 
2005). The proposed adaptive measures at the local 
level will mostly fall under the category of: 
a) Shared losses (providing subsidies to people), 
b) Modifying the threat (e.g. switching to alternate 
means and pattern etc), 
c) Preventing the impact (Building of protective 
infrastructure etc.), 
d) Change use (livelihood change etc.) etc. (Ahmed 
at el., 1999).  
The planned measures will bolster the performance 
of spontaneous adaptive measure which the people 
of Bangladesh have practiced and developed over 
centuries. According to Ahmed et al (1999) 
“Adaptation at the micro (local) level often takes 
place spontaneously. People at grassroots often 
adjust to a given situation on a short term basis and 
as such; adaptation often follows the cycle of act-
learn-act”. If liveability can be increased at the 
effected level, migration can be brought under 
control (Mowla, 2000&2005). People participation 
and feedback is a necessary component to enhance 
the performance of adaptive measure at local level.  
3.1 Shared losses  
3.1.1 Subsidy: If people are provided with grants, 
soft loans and other form of financial help during 
the time of dire need, it is assumed that they will 
deter from migrating. It is an accepted notion that 
most people tend to fight back (Mowla,2000) and 
this spirit can be enhanced by financial support. As 
Page 96
  
Kulsum (2010) states “It is proved that coastal 
vulnerable communities are positive to adapt 
themselves to changing environment but the major 
challenges are their limited financial resources.”  
3.1.2 Insurance: Insurance against climatic events 
is expected to help people to retain life after 
devastation. According to the UNFCCC (2008) 
Convention (Article 4.8), insurance related actions 
constitute one of the three main means of response 
to the adverse effects of climate change, alongside 
funding and technology transfer. UNFCCC (2008) 
opines, “[insurance] can enhance financial 
resilience to external shocks and provide a unique 
opportunity to spread and transfer risk’. For private 
enterprise, such measure could be a challenge and 
opportunity at the same time. It is expected that 
insurance related to housing will reduce CRs 
significantly. 
3.1.3 Disaster Relief Management: Through 
proper disaster relief and recovery management CR 
could be reduced. Depending on the nature and 
scale of climate change, these type of management 
continue from several month to several year. 
Government, N.G.O (Non Govt. Organisation) and 
C.B.O (Community Based Organisation) could play 
a pivotal role in such operations. 
3.2. Modifying the Threat 
Such measures require a comprehensive 
environmental rehabilitation approach linked to 
agriculture fisheries and livestock, as these sectors 
provide bulk of food required (Ketel,2008). Proper 
water harvesting will also lessen displacement and 
increase liveability in the effected areas.  
3.2.1 Agriculture: Adaptation of agriculture 
systems in SLR areas can increase food security. In 
this context, floating agriculture in the water logged 
area could be a solution. Diversification of 
agriculture and change in crop calendar, use of 
paddy fields with irrigation and mulching/green 
manuring, change of fertiliser use and application 
can be implemented. For salinity intrusion, saline 
tolerant crop varieties could be introduced (Islam, 
S. 2010). Major problems of rice production relate 
to different kinds of stresses such as abiotic stress 
(submergence, salinity intrusion, drought, low/cold 
temp, high temp, and soil fertility), biotic stress 
(disease, insect, and weed) and socio-economic 
stress (Islam,2010). Such stress resistant rice should 
be cultivated in local area prone to extreme climatic 
events to solve food shortage. In the field of 
agriculture, scientists have already succeeded in 
developing many varieties suitable for particular 
agro-ecological zones (Ahmed et al, 1999).  
3.2.2 Water Resources Management: Fresh Water 
is an essential element in retaining people within 
area. In this context protection of water catchment 
areas and ground water, rainwater harvesting and 
desalination is important at the local level. Water 
policy reform including pricing and irrigation 
policies can be developed at national level to 
address the problem of water at local level 
(UNFCCC,2008). The heavy seasonal rain fall in 
Bangladesh makes rainwater harvesting a possible 
option for storage of drinking water. Due to 
unfavourable geo-physical condition of coastal 
areas some people have already been practicing this 
for storage of water. This may be further improved.    
3.3. Preventing the Impact 
Ketel (2008) suggests that with a better 
understanding of what causes displacement, pre 
emptive measures can be applied which will help 
people overcome their difficulties at an early stage, 
thereby enabling them to remain in their home area. 
Such activities occur in the pre-disaster phase, and 
include among others preparedness and mitigation 
in the following ways (Shaw, K, 2009):  
3.3.1 Structural:  
i. Infrastructure: The Construction of roads, Water 
retention ponds, culvert, embankment  improves 
communication and at the same time protect area 
from natural disaster that devastate houses and 
render people homeless. Infrastructures like 
cyclone shelter, flood shelter also provides refuge 
during the extreme weather event. 
ii. Housing: People mainly migrate due to 
homelessness. House and settlement pattern may 
need modification to better cope with the changing 
conditions and reduce homelessness. Roofs should 
be properly designed and tied with base or main 
structure (Kulsum,2010). Flood and cyclone 
responsive shelter may be built in the worst 
affected areas.  
iii. Renewable Energy: The provision of alternate 
energy will increase liveability, enabling villagers 
to use it for productive and social activities. 
Renewable energy is sustainable and enhances 
liveability (Mowla, 2007 & 2008). With an increase 
in liveability it is expected that the tendency of 
people to migrate will decrease. Alternate energy 
sources could be Solar, wind, bio-gas etc. 
3.3.2 Non Structural:  
i. Forestry, Natural Resources and Terrestrial 
Ecosystem: Reduction of climate change hazards 
through coastal afforestation with community 
participation is a priority issue (Mowla, 2000). 
Coastal mangrove afforestation, tall trees next to 
tidal free zone, bamboo and cane cultivation as 
windbreaker, cultivation of horticulture species, 
agro forestry, and coast specific wood trees are also 
required to combat climatic events (Islam,S. 2010). 
Page 97
  
Besides material from trees such as thatch, leaves, 
woods will help people to undertake alternate 
livelihood after disaster. Other anticipatory 
adaptive measure like creation of parks/reserves, 
protected areas and biodiversity corridors, 
Identification / development of species resistant to 
climate change, better assessment of the 
vulnerability of ecosystems, monitoring of species, 
development and maintenance of seed banks etc 
need to be adopted (UNFCCC,2008). All these 
measure will enhance environmental performance 
that will motivate people to stay in their own area 
instead of migrating. 
ii. Health: Due to climate change events, there will 
be a propensity of post traumatic stress and other 
sort of psychological and physical stress. In the 
absence of proper health support many people 
would migrate from affected areas. Reactive health 
measure such as emergency response and 
anticipatory adaptive measures such as better and 
/or improved disease/vector surveillance should be 
undertaken to help victims of climatic events 
(UNFCCC,2008). 
3.3.3 Community Based Adaptation:  
i. Motivation: Community level motivation 
programme could be more effective in combating 
climate change impacts (Maarten, van Aalst, 2008). 
Community-level adaptation strategies and 
implementation management plans like excavation 
to reduce water logging, raising of embankment to 
prevent intrusion of saline tidal water; pond sand-
filter for safe drinking water, construction of new 
multipurpose cyclone shelters etc. to reinforce 
liveability in rural area (Islam, A. 2010) may be 
developed and implemented. This type of 
community level adaptation strategy will enhance 
community feeling and sense of belonging to the 
local area and will deter people from migrating 
because of such feeling and support. The local 
community’s views and experience on climate 
change impact, adaptation through programmes like 
community consultation, group meeting, youth 
group activation and capacity building, the idea of 
out- migration can be stalled.   
ii. Public Awareness: Through public awareness 
and dissemination of ideas related to grim future of 
Dhaka bound migration, a major breakthrough can 
be achieved. Improving public awareness and 
developing overall communications strategies at 
local level could make information related to 
climate change induced migration available to the 
average citizen and can reduce out migration 
(UNFCCC, 2008). 
iii. Knowledge Base Education: Inclusion of 
climate change related issues in the curriculum 
could discourage people to migrate out particularly 
to Dhaka. Knowledge should be made available as 
such and shared at the local level facing difficulties 
that leads migration towards Dhaka. In support to 
this initiative, there is a need to establish 
mechanisms for accessing and analysing current 
knowledge on migration and address priority gaps 
in current knowledge (Ahmed et al,1999). 
3.4. Change Use 
3.4.1 Fisheries: Adaptation of fisheries in areas 
prone to enhanced flooding in North East and 
Central Regions through adaptive and diversified 
fish culture practice can increase food security. 
Promoting adaptation to coastal fisheries through 
culture of salt tolerant fish especially in the coastal 
areas of Bangladesh will help increase liveability 
by increasing livelihood and food security. 
(Islam,A.2010) 
3.4.2 Livelihood diversification: Livelihood 
diversification is essential element to adaptive 
resilience to climatic disasters. When people loose 
their livelihood from agriculture and fisheries, 
alternative livelihood provides them a means to 
survive within their area. The alternative 
livelihoods supplementary to their main livelihoods 
can be crab fattening, livestock raring and non-farm 
activities. The non farm activities may include 
cottage industry such as weaving, articles, baskets 
and mat making from bamboo, local reed variety 
(Kulsum, 2010). All these will help local people 
resort to a new life instead of migrating to Dhaka. 
 
4. DISCUSSION AND  
RECOMMENDATION  
 
4.1. Discussion:  
The concept of anthropogenic (human induced) 
climate change migration is relatively new as the 
phenomenon started to appear since industrial 
revolution with the emission of GHG (Green House 
Gas) mainly by industrial activities.  Globally, CR 
surfaced with the inception of IPCC in 1988. As 
Haq (2007, p11) opines, “Climate change is a fairly 
new issue and that adaptation is even younger. We 
are learning by doing”.   
The mitigation measures for CR’s towards Dhaka at 
the root level are  subsidy, insurance, disaster relief 
management, innovative agriculture, water resource 
harvesting, building infrastructure, building houses, 
enhancing natural resources, improving health, 
community base adaptation, raising public 
awareness etc as discussed. The priority issues in 
implementing such solutions are funding, 
development of a knowledge base, capacity 
building, public awareness and finally Government 
commitment and will. To develop a knowledge 
base and capacity building with civil society, 
Page 98
  
universities, NGOs and other international and 
national body can contribute significantly. 
Ultimately it is the government with community 
support who should initiate and monitor all 
activities.  
The constraints of implementing the adaptive 
measures at local level are huge and pose a major 
challenge.  In terms of funding, it  will be difficult 
to arrange extensive funds from Government’s own 
resource, when the government  is  grappling with 
the problems like poverty, high unemployment, low 
literacy rate, insufficient  basic health care issues 
for people of Bangladesh. The chance of obtaining 
substantial funds from foreign sources appears 
remote which was evident from last global 
conference on climate change in Copenhagen. 
Limited institutional capacity, limited technical 
capacity is also major deterrents for smooth 
operation of such adaptive measures. Moreover 
corruption and extreme level of politicization of 
administration are also a major deterrent from 
implementing such adaptive measures. Despite all 
constraints, Government has initiated some sign in 
positive direction by formulating Climate Change 
Strategy and Action Plan and National Adaptation 
Program of Action (NAPA).  
The successful implementation of adaptive 
measures at the local level will increase the 
liveability in those areas and will contribute 
significantly in reducing out migration. Each of the 
proposed adaptive measures at the local level 
should be regarded as ‘guideline solution’. People 
are responding well in the hostile climatic effect 
situations (like Sidr, Aila, or Beel Dakatia), their 
experience may be shared in the SLR and CR 
management. More research should be initiated on 
each of the adaptive measure by specialists and 
related experts.  
4.2 Recommendations 
1. A National Policy (Bangladesh) should be 
formulated addressing environmental 
migrant (CR) issues. 
2. National Policies (Bangladesh) need be 
formulated related to adaptive measures at 
different level (local, regional and national) 
to minimize migrant flow to Dhaka. 
3. A separate fund should be allocated from 
‘Climate Change Fund’ for the specific 
purpose to address adaptive measures to 
minimize migrant flow to urban areas like 
Dhaka. 
4. NGOs and CBOs and international agencies 
should be given enough support and freedom 
from all levels of administration to undertake 
and facilitate these adaptive measures. 
5. Climate Change Strategy and Action Plan 
and National Adaptation Program of Action 
(NAPA) should be revised in order to 
provide more importance and significance to 
issues related to environmental migrants 
(CR) issue, specifically migrants to Dhaka. 
6. As environmental migrants are innocent 
victim of situation caused by GHG emission 
mainly by developed nations, a ‘Multi-Donor 
Trust Fund' need to be formulated 
comprising compensation from foreign 
countries. 
7. Slum policy for Dhaka should be formulated 
in order to ameliorate the suffering of slum 
dwellers, which is the ultimate abode of such 
environmental rural migrants. 
8. Climate change migration issue should be 
included in the curriculum at secondary and 
tertiary educational institution, discouraging 
people to migrate out especially to Dhaka. 
9. National media should provide due coverage 
underscoring the need to retain 
environmentally affected people within local 
area or migrate to regional growth centres 
instead of migrating to Dhaka. 
 
5. CONCLUSION 
 
In implementing such adaptive measures local 
government need collaboration with National level 
administration. In addition, local government 
administration with the help of NGO (Non 
Government Organization), CBO (Community 
Based Organisations) and people’s representatives 
can develop programs for implementing such 
adaptive measures. NGOs and CBOs should be 
given enough support and freedom from all levels 
of administration to undertake and facilitate these 
adaptive measures. 
IOM’s (International Organisation of Migration) 
policy and notion in general opposes migration 
towards urban areas and thinks migration hinders 
development in at least four ways; by increasing 
pressure on urban infrastructure and services, by 
undermining economic growth, by increasing the 
risk of conflict and by leading to worsening health, 
educational and social indicators among migrants 
themselves. (IOM, 2008). It can be argued that 
local level adaptive measure would not only reduce 
migration to Dhaka but also to other cities.   
In nutshell, the climate change induced migration 
should be given due priority and importance 
nationally as a major new field of inquiry. As Ketel 
(2008) suggests, human migration caused by 
climate change might well be one of the major 
development problems of the third millennium. As 
such, utmost importance should be provided from 
Page 99
  
the part of governments and international 
humanitarian, development, and environmental 
agencies to this pressing issue.  
 
REFERENCES 
 
1. Ahmed A.M., A. Rahman (1999). Adaptation to 
Climate Change in Bangladesh: Future Outlook. 
Vulnerability and Adaptation to Climate 
Change for Bangladesh. Huq, & Asaduzzaman. 
Dhaka, Kulwar Academic Publishers. 
2. Begum, A. (1999). Destination Dhaka, Urban 
Migration: Expectation and Reality. Dhaka, The 
University Press Limited. 
3. Courier (2009). Swimming Against The Tide. 
Dhaka Courier. Dhaka, Dhaka Courier. 13. 
4. Huq, H. (2007). Community based adaptation: 
A vital approach to the threat climate change 
poses to the poor. London, International 
Institute for Environment and Development. 
5. IOM (2008). Migration and Climate Change. 
Migration Research Series. Geneva, IOM. 
6. IPCC (2007). "Climate Change 2007 synthesis 
Report." Retrieved 3-3-10, from http://www. 
ipcc.ch/pdf/assessment-report/ar4/syr/ar4_syr.    
7. Islam, A. (2010). Adaptation Preparedness to 
Address Climate Change threats on Sustainable 
Development Strategies for Coastal 
Communities in Bangladesh. Climate Change 
Effects in the Deltaic Environment of 
Bangladesh. Dhaka: 101-113. 
8. Islam, S. (2010). Climate Change and Rice 
Production: Present Status and Future Strategy. 
Climate Change Effects in the Deltaic 
Environment of Bangladesh. Dhaka, BAPA-
BEN: 130-147. 
9. Ketel, H. J. (2008). "Global Warming and 
Human Migration." Retrieved 10-3-10, from 
http://www.eolss.net/ebooks/Sample%20Chapte
rs/C12/E1-04-03-04.pdf. 
10. Kulsum, U. (2010). Community Based 
Adaptation: Civil Society's Role in Southwest 
Coastal Bangladesh. Climate Change Effects in 
the Deltaic Environment of Bangladesh. BAPA-
BEN: 114-130. 
11. Maarten K. van Aalast, T. C., Ian Burton 
(2008). "Community Level adaptation to 
climate change: The potential role of 
participatory community risk assessment." 
Global Environmental Change 18: 166-179. 
12. Mowla, Q.A. (2000). Human Settlements in the 
Coastal Areas and the Offshore islands of 
Bangladesh: The Urir Char Experience, Matin, 
Bhuyan & Datta (Eds.) ‘Coastal Environment 
and Energy Resources in Bangladesh’ 
Published by Khulna University, UGC & USIS-
Bangladesh, 2000, pp.66-74. 
13. Mowla, Q.A.(2005). Eco-systems and 
Sustainable Urban Design Nexus – A 
Borderless Concept, in the Global IIT 2005 
Alumni Conference On Beyond ii Technology, 
with the theme “Technology without Borders” 
May 20-22, 2005, Washington DC, USA. 
14. Mowla, Q.A.(2007). Living Environment for 
Dhaka’s Urban Poor - An Analysis; Proceeding 
for International Seminar on ‘Architecture for 
the Economically Disadvantaged’ 23-24 
March’2007, Dhaka, pp.8-13 
15. Mowla, Q.A. (2008). Eco-Sustainability of 
Urban Environment – the Case of Dhaka, 
presented in the International Continuing 
Education Meet on Sustainable Communities – 
Bridging the Gap between Research and Action, 
jointly organized by TKK-Finland, AIT-
Thailand, UN-HABITAT and UNEP, 11-22 
August 2008, AIT Bangkok. 
16. Mowla, Q.A. and Zereen, N.(2005).  Ecological 
Interpretation of Community Structure and 
Urban Growth, Asian Studies, Vol. 24. 2005, 
31-42. 
17. Salehyan, I. (2005). "Refugees, Climate 
Change, and Instability." Retrieved 12-3-2010, 
2010, from http://www.gechs.org/downloads 
/holmen/Salehyan.pdf. 
18. Shaw, R. K. (2009). Disaster Management: 
Global Challenges and Local Solution. 
Hyderabad, University Press. 
19. Shafi, S. (2010). Natural Disaster and Land 
Tenure: Impact of Climate Change on 
Settlements, Migration and Urbanisation. 
Climate Change Effects in the Deltaic 
Environment of Bangladesh. Dhaka: 196-205. 
20. Sirajee, A. (2010). "Stuck Here on Earth." 
Retrieved 3.03.10, from http://www.the 
dailystar.net/forum/2010/january/earth.htm. 
21. UNDP (2007/2008). "Human Development 
Report 2007/2008." From http://hdr.undp.org/en 
/media/HDR_20072008_Summary_English.pdf. 
22. UNDP (2010). "Climate Change and UNDP." 
From http://www.undp.org/climatechange/docs/ 
English/FF-climate.pdf. 
23. UNFCCC (2008). Impacts, Vulnerability and 
Adaptation in Developing Countries. Germany, 
UNFCCC. 
Page 100
 * Corresponding Author: Qazi Azizul Mowla,  
E-mail: qmowla@yahoo.co.uk 
CRISIS IN THE BUILT ENVIRONMENT OF DHAKA:  
AN OVERVIEW 
 
 
Qazi Azizul Mowla* 
Professor, Department of Architecture, Bangladesh University of Engineering and Technology 
(BUET), Dhaka-1000, Bangladesh.   
 
 
Dhaka has grown from a small settlement to a sprawling metropolis of about fifteen million people. 
Traditional physical development in this region offered the best and integrated solutions towards human 
needs, in their relation with the nature and the community but contemporary development has ignored living 
with nature. Studies show that much greater environmental as well as socio-economic advantages can be 
achieved through design with ecological principles in mind than without it. This paper aims at understanding 
the development trend in Dhaka, the crises it is facing and the possible strategies to overcome the problem. It 
is concluded that fragmented approach of planning must be avoided and that the development taking care of 
geomorphology and hydrological behaviour of the place would result in a sustainable environment. 
 
Keywords: Crisis; Built-environment; Ecology; urban design; Dhaka.  
 
1. INTRODUCTION 
 
Dhaka is located in the midst of an active delta – 
the largest in the world. Siltation process is going 
on for ages in both water channels as well as in the 
flood plains thereby their relative depth remains 
almost constant and the shore line moves south 
ward with the accretion of new lands. In his 
context, Dhaka has grown from a small trading 
settlement to a sprawling metropolis of about 
fifteen million people. The spatial development 
followed the prong of flood free terrace originating 
from the old nucleus along Bouriganga River 
towards north as a part of Madhupur terrace (Dhaka 
Terrace). The Dhaka Terrace sloped towards 
eastern and western flood plains, marshes and 
Rivers. The Dhaka terrace was also crisscrossed by 
numerous water channels that drained the city as 
well as served as a main source of service and 
communication line.  
In this setting, after independence in 1971, 
tremendous population pressure has put Dhaka’s 
built-environment in a crisis situation. The 
objective of this paper is to understand the nature of 
the crisis and to explore for possible strategies to 
overcome the crisis.      
 
2. DHAKA’S URBAN GROWHT 
SCENARIO:  
 
Traditional settlement pattern in this region offered 
the best and integrated solutions towards human 
needs, in their relation with the nature, ecosystems 
and the community but contemporary development 
has ignored living with nature. The physiographic 
effect of water and land can be seen on the 
traditional settlement pattern, which sited on 
available ground or on artificial mounds created on 
the flood plains (Mowla,2008).  
 
Figure-1: Water bodies are illegally encroached 
upon creating drainage and water logging problems.  
In forties, about 50% of present Dhaka was low 
laying flood plain and wetlands. Many of the roads 
in Dhaka are developed by filling the water bodies 
or by making box-culverts, thus shrinking the water 
carrying capacity as well as reducing ground water 
replenishment. Destruction of these water channels 
and depressions has resulted in the disruption and 
alteration of the natural process of land accretion, 
land formation and ecosystems. Water logging 
(Fig-1) is an inherent problem associated with 
Page 101ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
  
uncontrolled urbanization and lack of holistic 
planning in Dhaka. 
 
3. POPULATION GROWTH,  
    MIGRATION AND HOUSING  
 
The population density in the slums is about 
531,000 persons per square mile which is still 
growing and occupy an area of only 4% of the total 
Dhaka Metropolitan Area (DMA), whereas the 
urban poor population is about one-third. It has 
been reported that only 30% people of this city 
shares 80% of the total residential area and the rest 
70% shares only 20% of residential area. Around 
3000 slums and squatters exist in the city in which 
almost 3 million people live with very little utility 
facilities (Fig-2). 
 
Figure-2: Uncontrolled Development at Koril 
The population growth in Dhaka is due to natural 
growth and huge in-migration. Currently, the 
population is estimated to be about 15 million 
people (about half of which live below the poverty 
line) live in about 340sq.km area of Dhaka. The 
existing overall, gross urban development density is 
89 persons per acre (ppa). In the inner zones, 
densities average 179 ppa, reaching a high density of 
323 ppa in the older quarters. Statistics show that the 
housing demand of the residents in Dhaka city 
increases by around 10 percent each year. It is 
estimated that about five lakh people migrate to 
Dhaka every year requiring about one lakh housing 
units and 95 percent of such people are poor. Public 
and private sectors combined together build around 
15,000-20,000 housing units a year to meet the 
staggering demand of about 100,000 units/year, of 
which real estate developers contribute only about 
5% of units in Dhaka each year that too for mostly 
higher income segment of the population. 
Approximately, 56 percent of the Dhaka city’s 
population lives in informal housing.  
Huge majority of migrants to Dhaka choose Dhaka 
because of centralized opportunities and central 
location. Migrants to the city of Dhaka are not all 
single minded individuals who possess transferable 
skills; many tend to be illiterate, unskilled, old, and 
ill equipped for the city. As such, migration to 
Dhaka places an additional burden to already 
fragile urban infrastructure and population. A study 
in 1987 revealed that 2.8 million of the poorest 
people lived on just 7 sq km of land and most of the 
residential development is unplanned. Motijheel is 
the Central Business District (CBD) of Dhaka city 
where 85% of housing is unplanned. The 
interesting case is Mirpur residential area where 
90% of housing is unplanned. According to same 
investigation about 75 % of the housing stock in 
Dhaka is unauthorized. The residential density in 
Old Dhaka is 313 persons to an acre. A 
conservative estimate of the person / room ratio in 
the residential quarters of old Dhaka is 7.5. Though 
this seems very dense, the average Floor Area Ratio 
(FAR) in Choukbazar was found to be only 0.85. 
There are only 17 acres of open space for over 
600,000 people.  
The gender composition of Dhaka’s population is 
balanced, but a significant portion of population is 
not stable. Most of the economically lower class 
people are single with their families in rural areas. 
UNCHS attributed this factor to the growing 
garment sector industries, which alone employ over 
700,000 women. Centralization of urban amenities 
and activities in Dhaka has resulted in population 
explosion. The rapid increase in urban population 
has made a tremendous claim on the already over-
utilized civic facilities and has created a state of 
disequilibria in the urban environment. 
 
 Figure-3: Concrete Jungle in Motijeel Area. 
Decentralization of facilities and amenities is 
therefore essential for Dhaka to survive (Fig-3&4). 
Page 102
  
Establishment of New Satellite towns around 
Dhaka to reduce pressure from it are however not 
suitable proposition in Bangladesh context where 
land is scarce and cultivatable land, wetland and 
open spaces are meagre. Existing urban centres 
around Dhaka (Savar, Narayanganj, Tongi, Gazipur 
etc. or across Bouriganga River) may be 
consolidated, controlled and planned to shift / 
neutralize some of Dhaka’s functions, particularly 
the activities that don’t need to be at the centre. 
However, these centres must have rapid, efficient 
and cheap communication connectivity with Dhaka. 
 
Figure-4: Traffic Congestion in Motijeel Area. 
 
4. TRAFFIC AND TRANSPORTATION 
 
Increase in population and number of automobiles 
without matching development of traffic and 
transportation infrastructure has almost resulted in a 
system break down (Fig-4&5). At present about 
2500km of road in Dhaka have to carry about 8 
lakh vehicles. Land use and traffic and 
transportation depend on each other. Land use 
distribution giving rise to the propensity to travel is 
one of the problems. For example, concentration of 
numerous ghats along Bouriganga river generates 
huge traffic that has to move to and fro through the 
city. If transportation cost and time spent in travel 
is considered, the relocation of some of the ghats to 
(say) Mirpur or Tongi where they are more needed 
would be more economical. Dispersal of 
warehouses, transport agencies and other relevant 
activities will automatically follow to newer 
location. Therefore, planned relocation of some 
strategic land use will have positive effect on the 
traffic and transportation situation. 
Mass transit is essential for any mega city, as an 
economic first step towards this end in Dhaka 
context, initially Narayanganj – Dhaka – Tongi 
railway tract may be used as high frequency shuttle 
trains (mass transit spine) and important stations 
hooked up with the city’s road transportation grid. 
‘Bus only’ lanes or segregated right-of-way for 
public transport vehicles in the major routes may 
have a positive effect on the otherwise precarious 
traffic and transportation situation of Dhaka. 
Efficient traffic management and efficient use of 
road space may substantially reduce the traffic 
problem of Dhaka in the short term. Alternate mode 
of traffic and transportation is needed, as such; fast 
moving water taxi may be introduced around Dhaka 
that will reduce much of the through traffic from 
Dhaka. Development of Western embankment road 
and eastern by pass road integrated with the city’s 
grid will complement circular water way. Water-
route and by-pass route must also be adequately 
hooked up with the city’s road transportation grid. 
 
Figure-5: Unbalanced Development: Panthapath 
 
Pedestrian traffic makes up the lion share of the 
total traffic (in terms of persons moving) but it is 
surprising to note that almost no provision of 
pedestrian traffic is present in any level of planning 
and design – that contribute significantly towards 
overall traffic problem of the city. Other approaches 
that can be adopted simultaneously to tackle the 
problem are: a) Area licensing whereby low-
occupancy vehicles pay to enter the designated 
congested areas; b) Road pricing, where by vehicles 
are charged for using certain roads. c) Physical 
restraints to discourage the movement of private 
cars across certain areas. d) Adequate parking 
facilities and parking Controls to prevent long term 
parking in busy areas. e) Staggered timing of city’s 
traffic generating activities; f) restricted entry to 
certain types of vehicles to certain areas; g) 
Pedestrian amenities, efficient footpath and 
pedestrian routes, and h) land use control to 
influence the magnitude and type of transport 
demand. 
 
5.  OPEN-SPACE, WATER BODIES AND  
     URBAN ENVIRONMENT  
 
Dhaka being encircled by a river system provides 
relief to otherwise congested metropolis. Fringe 
areas are generally low, flood plains, depressions 
etc. Filling up of water bodies posses two prong 
Page 103
  
problem of unsuitability of construction and 
reduced water retention capacity. But the scenario 
is that, in old Dhaka only 5% and new Dhaka 12% 
of land is green and open. The total amount of open 
space in greater Dhaka is about 17%-18% of city 
area. The total stock of public open space in Dhaka 
City is hardly over 5000 acres. 
5.1 Traditional Response:  
Traditional response to the conext gave rise to a 
richly woven urban fabric at the human scale. The 
rivers spilling over the flood plains and into canals / 
khals or connecting inland depressions or lakes 
together provided a hierarchy and network of water 
bodies and navigation routes giving rise to 
settlements alongside. There were flights of steps, 
locally known as ghats at intervals rising up to the 
lanes or community spaces. The ghats on the bigger 
water bodies or rivers were major community 
spaces where the daily activities take place. 
(Mowla, 2000 & 2010). The trend of ignoring 
channels and ponds so vital to the city’s life line 
has caused social, health, sanitation and water 
logging problems.  
5.2 Water based Urbanism:  
5.2.1 Water Retention and Drainage: A tendency 
of filling of water bodies and flood plains resulting 
in the reduction of water retention capacity, 
diminishing public spaces and increasing water 
logging or flooding. In this respect the localities 
situated inside the city suffers most. Degradation, 
obstruction, filling and demolition of natural 
drainage systems are causes of flood's severity in 
some parts of the city. 
5.2.2 Ground water extraction: Being one of the 
mega cities in the world and without any 
hydrological planning and remaining surface water 
being excessively polluted or destroyed, Dhaka is 
facing continuous potable water-related problems 
over the last few decades. Ground water extraction 
poses a great threat to the sustainability of the city 
itself. There is no strategy for planned 
replenishment of ground water, and that is in a 
place that receives one of the highest rates of rain 
fall in the world. Flood water retention and 
rainwater harvesting could be a better alternative to 
ground water extraction. Surface water compliment 
and supplement underground water. The ground 
water replenishment rate is much slower than the 
extraction rate. Dhaka Water and Sewerage 
Authority (WASA) extract about 1200MI / day for 
urban water supply from about 423 deep tube wells. 
In 2001, underground water table in Dhaka was at a 
depth of between 200-300 feet. In 2010, this has 
deepened to 1,000 -1200 feet. This is not a matter 
of concern only with respect to diminishing water 
supply source but because a large vacuum between 
surface and under-groundwater has developed 
which might trigger land slide or subsidence 
particularly in the event of earth quakes. 
5.3 Mismanagement of Urban Water:  
Dhaka WASA utilizes the existing canals and 
sewerage pipes to collect the waste water from 
different residential areas, carry the effluent to 
depose, most of it, into surrounding river systems 
without any treatment. Many canals are cut off and 
transformed into lakes. Even these lakes are getting 
highly polluted due to disposal of waste waters 
collected from the municipal sewages.  
In terms of utility services, a few key points are 
important. The lower the density, the higher the 
cost of providing services. Second, drainage cannot 
happen when all available space is paved over and 
built on. Third, as with transport, so is with utilities: 
attempting to meet constantly expanding demand 
with supply is an expensive and impossible 
proposition, therefore a holistic and long term 
planning is needed. 
 
6. DHAKA’S WATER SCENARIO IN 
DMDP AND DAP  
 
Patrick Geddes plan of in 1917 was a good concept 
for Dhaka’s development but was never given a trial.  
First formal Master plan for Dhaka was prepared in 
1958 for an anticipated population of 2 million. The 
Dhaka Metropolitan Area Development Plan 
(DMDP’95) was quite comprehensive, but could not 
be adopted due to mysterious reasons. Detail Area 
Plan (DAP’2010) supposed to have evolved from 
DMDP’95 is under serious public scrutiny because of 
its deviation from DMDP’95 and present reality.  
A formal holistic policy and plan at national level 
sets priorities identifying major areas and quantities 
of uses. Urban structure plan (SP such as Fig. 6: 
DMDP, 95) is the second level plan within broad 
urbanization policy guidelines of national vision. 
The third level planning and designing is the detail 
area plan (DAP) within the guidelines set in SP. In 
the fourth level is small area and plot level 
designing. Such a sequential plan is not evident in 
the DAP, 2010, which rather than setting aside 
adequate space for water retention ponds and for 
green surfaces, focuses instead on roads and 
buildings, embankment and pump oriented flood 
control approach which further intensifies the 
suffering of Dhaka residents due to flooding. 
Considering the geo-morphology of Dhaka, flood 
management and a detention reservoir-based 
gravity drainage system is expected to be more 
reliable and appropriate for storm water drainage 
system in a floodplain landscape like Dhaka with 
rivers encircling the city (Mowla, 2010). Some 
Page 104
  
sporadic attempts to integrate water bodies with the 
settlement pattern are observed in Dhaka without 
any link with upper and lower level planning and 
design framework. 
 
Figure-6: DMDP’ 95 - Structure Plan Policy  
Areas i.e. built and natural areas for Dhaka. 
 
6.1 Contextual Brief:  
Dhaka Metropolitan Development Plan (DMDP, 
1995) considered retaining at least eight flood-flow 
zones undisturbed. It is said that Dhaka must have 
at least 20 retention ponds of Hatirjheel size to 
tackle the storm water (Bangladeshnews, 2009). 
Transparency International Bangladesh - TIB 
informed that around 1,000 ponds, which were in 
the city, have now been totally destroyed 
(Bangladeshnews, 2009). TIB reports that 800 acres 
of land in 5 rivers including Bouriganga and 
Sitalakkhya were illegally grabbed violating the 
Wetland Protection Act, 2000. The fact is that the 
contemporary planning process never took water 
systems as the driving force in any physical 
planning in this delta. IRS images of 1996 and 2000 
clearly shows that water bodies measuring about 
2300sq.m were filled in by the Bashundhara and 
Bashumoti housing estates and 66 acres filled by 
Aftabnagar Housing. In 1996 there were 211 acres 
of water bodies in the Mohamadia Housing Estate 
and Adabor area of which 91 acres disappeared 
between 1996 and 2006 and 68 acres from 2006 to 
2009. RAJUK, the main planning body for Dhaka 
is the major violator of its own plans. RAJUK 
initiated a residential project in the southern part of 
Bouriganga River covering an area of 381 acres – 
over the last two years 3000sq.m of natural water 
bodies has already disappeared. Purbachal housing 
is another recent example of many such violations 
of DMDP, 95. 
6.2 Crisis and Mitigation Approach:  
Bangladesh is a deltaic country and has abundant 
rainfall, but due to the absence of clear policy-
guidelines and regulatory laws, useable water 
quantity is declining fast. Wetland Protection Act, 
2000 in Bangladesh restricts change in the wetland 
areas but doesn’t regulate the use of water.  In fact 
none of the rules calls for integrating natural water 
bodies or channels into the urban planning and 
design frame work. 
Studies show that around 40% of the wetlands of 
Dhaka city has disappeared in 20 years due to 
indiscriminate filling up of lowland and flood flow 
zones that also has reduces its drainage capacity. It 
says that the temporary wetland area in DMDP, 
1995 was 1,528 sq.km. this was 40,765 hectare in 
1989 and came down to 35,740 hectare in 1999 and 
24,208 hectare in 2005 (Bangladeshnews, 2010). 
Same study informs that to protect eastern Dhaka 
from floods, at least 40% (66 sq.km) of the 
drainage catchment area must be delineated and 
protected as wetlands and water bodies considering 
this as an ‘ecologically critical area’. Of the 
recommended 40% drainage area, a minimum of 
12% (about 20 sq.km) can be made available as 
reserved ponds or lakes and another 38% (about 46 
sq.km) protected as natural wet lands for retention 
of storm water. A Dhaka University study reveals 
that the government owns about 33 lakh acres of 
khas (Government)  land of which about a quarter 
is water bodies. DAP (2010) covers the area of 
DMDP, 1995 but did not follow the planning 
guidelines provided in it. Against the 40% 
requirement, DAP, 2010 recommends 21% of 
Dhaka’s land as water bodies where no 
development would be permitted. DAP 
recommends 50m land from riverbanks to be 
earmarked for walkway or driveway; enlisting 
parks, playgrounds and open spaces; and marking 
existing canals in the maps (DAP, 2010). Though 
no basis of this recommendation is given, it seems 
better than none. 
Considering the geo-morphology of Dhaka, it 
seems essential that if and when needed the earth 
cutting to fill / raise lands must be judiciously 
planned and invariably done on the channel ward 
side that would get rapidly filled up by the natural 
process of sedimentation / accretion. The western 
embankment of Dhaka is a response to the floods. 
The attitude of zero tolerance for floods amounts to 
demanding equal protection from floods along 
different stretches of rivers irrespective of the 
Detention 
Ponds 
Main flood 
Flow Zone 
Sub-Flood 
Flow Zone 
Bouriganga 
River  
Reserved 
Wetlands and 
Retention Ponds 
DMDP’ 1995-2015 
Dhaka 
Page 105
  
geographical difference found there, which in 
practice is not possible. It increases the ferocity of 
flood flow in the lower reaches. Embankments 
saves some areas at the expanse of some other areas 
but have a long term effect of higher river beds than 
their surrounding, insufficient percolation and 
diminishing soil fertility.  
Traditional approach of planning and design of 
living with nature is still valid without sacrificing 
contemporary needs and that natural areas may be 
strictly controlled by regulations. It is also 
suggested that the Planning and regulatory agencies 
like RAJUK must not indulge in (real estate) 
development since monitoring and execution are 
conflicting roles with conflict of interest (like 
judiciary and bureaucracy). 
 
7. DISCUSSIONS AND  
RECOMMENDATIONS  
 
Review of Dhaka’s geomorphology reveals that for 
the sake of sustainability needs, natural systems 
must be protected. Studies show that much greater 
environmental as well as socio-economic success 
can be achieved through design with ecological 
principles in mind than without it. Planning must be 
holistic in nature and piecemeal solutions be 
avoided. Mass housing and mass transit with 
ecological imperatives should get priority in the 
Dhaka’s development process in the present context 
to minimize crisis.  
Considering Dhaka’s geomorphology and 
hydrological profile, finger shaped open ended 
dykes may be constructed for settlements, 
particularly in the fringe areas to allow free flow of 
flood water in and out of the urban areas. Lower 
elevation plains may be used as vegetation areas 
(parks or open spaces) during lean seasons. 
Restoration of natural (gravity) drainage system 
and creation of adequate water bodies is needed for 
a sustainable ecosystem in Dhaka.  
Houses with elevated floors built on earth mounds 
created by adjacent excavation thus having similar 
storage capacity and evacuation boats kept 
available for emergency were the traditional 
concept of settlements in the flood plains. It is 
considered a highly developed form of culture born 
out of necessity to live with hydraulic dynamics.  
 
8. CONCLUSION 
 
Traditional Architecture, Urban Design and 
planning in this region offered the best and 
integrated solutions towards human needs, in their 
relation with the nature, ecosystems and the 
community but contemporary development ignored 
living with nature.  
Urban development with natural context as focus 
was not given a trial during rapid urbanization over 
the last 100 years. Review of Dhaka’s geo-
morphology reveals that for the sake of ecological, 
hydrological integrity and development 
sustainability, natural systems must be protected 
and can be protected. DAP, 2010, though quite 
conservative and has compromised, if strictly 
followed is still expected to improve this situation. 
Studies show that much greater environmental as 
well as socio-economic advantages can be achieved 
through design with ecological principles in mind 
than without it. Fragmented approach of planning 
must be avoided, and further compromise with 
DAP will be suicidal in the long run. 
 
REFERENCES 
 
1. Bangladeshnews (2009). http://www. 
bangladeshnews.com.bd/2009/07/30/restore-
canals-wetlands-to-stop-waterlogging/ 30 June. 
2. Bangladeshnews (2010). http://www. 
bangladeshnews.com.bd/2010/06/29/40pc-
wetlands-go-in-20-years/ (June 29, 2010) 
3. DAP (2010). Detailed Area Plan for Dhaka 
Metropolitan Development Plan, GOB, 2010. 
4. DMDP (1995). Dhaka Metropolitan 
Development Plan 1995-2015, GOB, Dhaka. 
5. Mowla, Q.A. (2000). Human Settlements in the 
Coastal Areas and the Offshore islands of 
Bangladesh: The Urir Char Experience, Matin, 
Bhuyan & Datta (Eds.) ‘Coastal Environment 
and Energy Resources in Bangladesh’ 
Published Jointly by Khulna University, UGC-
Bangladesh & USIS-Bangladesh, 2000, 66-74. 
6. Mowla, Q.A. (2008). Eco-Sustainability of 
Urban Environment – the Case of Dhaka, 
presented in the International Continuing 
Education Meet on Sustainable Communities – 
Bridging the Gap between Research and 
Action, jointly organized by TKK-Finland, 
AIT-Thailand, UN-HABITAT and UNEP, 11-
22 August 2008, AIT Bangkok. 
7. Mowla, Q.A. (2010). Role of Water Bodies in 
Dhaka for Sustainable Urban Design, 
Jahangirnagar Planning Review, 2010: Vol.08, 
pp.1-10.  
Page 106
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: K.M.Khaleduzzaman  
E-mail: nayansustcee@yahoo.com 
EARTHQUAKE VULNARABILITY ASSESSMENT OF SCHOOLS 
AND COLLEGES OF SYLHET, A NORTH EASTERN CITY OF 
BANGLADESH 
 
 
M.Ahmed, K.M.Khaleduzzaman*,N.A.Siddique, S.Islam 
Department of Civil & Environmental Engineering 
Shahjalal University of Science and Technology, 
Sylhet 
 
 
In this paper, seismic safety of the school and college buildings of the Sylhet city, the north-eastern 
divisional city of Bangladesh, has been discussed. This study is an outcome of the combination of Rapid 
Visual Screening (RVS) survey and Modified Turkish Method carried out to evaluate the existing school and 
college building stoke of Sylhet City Corporation area. More than fifty school and college have been 
surveyed with an objective to evaluate the present condition and to identify the retrofit buildings in future 
earthquake. The field observation regarding soil condition, zone type, apparent quality and structural state 
has been reported. After the work down evaluation, preliminary assessment is done as it is essential for final 
structural and non-structural evaluation.7.55%, 9.31% and 11.36% school and/or college building has been 
found highly vulnerable to earthquake when the distance of fault is within 9-15km, 5-8km and less than 4km 
respectively. Some recommendations has been provided that might be followed to avoid or minimize 
structural damage of the school and college buildings  
. 
Key words: earthquake, vulnerability assessment, Sylhet city, school, college 
 
 
1. INTRODUCTION 
 
In earthquake prone areas there is a need for the 
assessment of the capacities of large numbers of 
existing buildings. The results of such assessment 
are essential for rational planning of retrofit 
programs for existing buildings before the 
occurrence of a strong earthquake, for the allocation 
of rescue forces and equipment to optimally deal 
with the forecasted damage, etc. (1)  the seismic 
evaluation and retrofitting of school buildings 
laying in high seismic zones is important  towards 
initiation of disaster mitigation as the damage of a 
house kills a family but damage to a school creates 
panic to many families and more importantly next 
generation.  Sylhet, a divisional city of north-
eastern region of Bangladesh, is one of the most 
vulnerable cities of Bangladesh. Literacy rate is 
more than 70 percent (2) and it is increasing day by 
day. More than one hundred educational institutions 
are located in this area. But lots of school and 
college in this historic city are very old. Most of the 
existing school and college buildings are 2 or 3 
storied reinforced concrete frame buildings with 
infill brick walls and 1 storied brick masonry 
buildings with reinforced concrete roofs and using 
cement mortar in most of the cases. Just A 
moderate level earthquake may create a huge 
damage to property and valuable lives. That is why 
this earthquake risk assessment is done to evaluate 
the existing condition of the school and college of 
this region. 
 
2. STUDY AREA: 
 
Sylhet is one of the rapidly growing metropolitan 
areas, located in the northeast region of Bangladesh 
and situated at 24.85° latitude and 91.80° 
longitudes. Sylhet was changed to a city 
corporation from a municipal board in 2001and in 
2002 the city was administrated by the Sylhet City 
Corporation (SCC) and finally was granted 
metropolitan city status in 31st March 2009(4).SCC  
occupies a total area of 26.5 sq. km with a 
population of around 0.5 million. Population 
density is 17,479/km2. There are 22 intermediate 
college, 36 high schools, 11 English medium 
school, 7 madrashas in this city (5).we have 
collected data from 53 schools and colleges which 
are located in different Wards of the City 
Corporations. Here, only the 7 or less than 7 storied 
reinforced concrete frame buildings are considered 
Page 107
ISBN: 978-984-33-2140-4
 *
 Corresponding Author: K.M.Khaleduzzaman  
E-mail: nayansustcee@yahoo.com 
 
for the assessment .Figure:1 is showing the 
locations of the evaluated schools and colleges. 
 
 
 
Fig. 1: Location of the surveyed Schools and 
colleges in Sylhet City Corporation 
 
2.  METHODOLOGY: 
 
Different techniques are usually employed to assess 
the vulnerability of existing buildings which are 
usually considered as the most vulnerable. These 
methods were developed for area-wide data 
collection. Many of them are based on the 
inventory of structural parameters of the design 
collected by visual inspections and related to 
observational data of damage during past 
earthquakes [6]. Generally seismic vulnerability 
evaluation follows three main stages: walk-down, 
preliminary and final evaluations (ozcebe et al, 
2003) The masonry buildings, structures more than 
seven story and those schools that have no 
permanent educational building are excluded from 
this assessment. Most of the data were collected 
data from field visit and structural plan of the 
school and colleges were collected from district 
education office of Sylhet. 
 
3.1. Walk down evaluation: 
The parameters that are surveyed for the walk 
down evaluation are as follows: 
(a) Number of Stories:  
(b) Existence of a soft Story:  
(c) Existence of heavy Overhangs:  
(d) Apparent Building Quality:  
(e) Existence of short Columns:  
(f) Pounding Effect:  
(g) Topographic Effects:  
(h) Local Soil Conditions:  
 
Based on their number of stories and the seismic 
hazard level at the site buildings are assigned 
different base scores as shown in Table 1. 
 
 
3.1.1. Building Seismic Performance: 
Once the vulnerability parameters of a building are 
obtained from walk down surveys and its location is 
determined, the seismic performance score PS can 
be calculated by using Eq. 1. The base scores, BS, 
the vulnerability scores, VS, and the vulnerability 
score multiplies, VSM, to be used in Eq. 1 are 
defined in Tables 4.2 and 4.3, respectively 
 
PS = (BS) - Σ (VSM) × (VS)   (1) 
 
The weight of each building vulnerability parameter 
is evaluated by statistical procedures, based on the 
Duzce database. The results are then smoothed, and 
the weights of the parameters for which there was 
no available data (soft story, pounding, topography) 
are assigned by using engineering judgment. 
 
Table 1: Vulnerability Parameters, (VSM) 
 
Soft story Does not exist = 0; Exists = 1 
Heavy overhangs Does not exist = 0; Exists = 1 
Apparent quality Good =0;Moderate =1;Poor =2 
Short columns Does not exist = 0; Exists = 1 
Pounding effect Does not exist = 0; Exists = 1 
Topographic effects Does not exist = 0; Exists = 1 
 
3.2 Preliminary Assessment 
In many instances statistical analysis based on the 
observed damage and significant building attributes 
would provide reliable and accurate results for 
regional assessments. Yucemen et al. 2004, Ozcebe 
et al. (2003) and Yakut et al. (2003) employed the 
discriminate analysis technique to develop a 
preliminary evaluation methodology for assessing 
seismic vulnerability of existing low- to medium-
rise RC buildings in Turkey. The main objective of 
the procedure is to identify the buildings that are 
highly vulnerable to damage. The procedure is 
applicable to RC frames and frame-wall structures, 
having up to seven stories.  Definition of the 
discriminating parameters and the procedure to be 
followed are introduced below. Further details of 
the proposed method can be reached in the 
references mentioned above. 
 
Evaluated Parameters for preliminary assessment 
are as follows 
The following parameters were chosen as the basic 
estimation parameters. 
 
(a) Number of stories (n): This is the total number 
of individual floor systems above the ground level. 
 
(b) Minimum normalized lateral stiffness index 
(mnlstfi): The mnlstfi parameter shall be computed 
based on the following relationship: 
mnlstfi = min (Ix, Iy)   (2) 
Page 108
 *
 Corresponding Author: K.M.Khaleduzzaman  
E-mail: nayansustcee@yahoo.com 
 
Where; 
( ) ( )
1000×
+
=
∑
∑ ∑
f
xswxcol
nx A
II
I  ,   
( ) ( )
1000×
+
=
∑
∑ ∑
f
yswycol
ny A
II
I
                  
(3) 
   
 
Where, ∑(Icol)x and ∑ (Icol)y are the summation 
of the moment of inertias of all columns about their 
centroidal x and y axes, respectively. ∑ (Isw)x and 
∑ (Isw)y  are the summation of the moment of 
inertias of all structural walls about their centroidal 
x and y axes, respectively. Inx and Iny  are the total 
normalized moment of inertia of all members about 
x and y axes, respectively. ∑Af  is the total floor 
area above ground level. 
 
(c) Minimum normalized lateral strength index 
(mnlsi): The mnlsi parameter shall be calculated by 
using the following equation: 
 
mnlsi = min (Anx,Any )                     (4) 
where:  
( ) ( ) ( )
1000
1.0
×
++
=
∑
∑ ∑ ∑
f
xmwxswxcol
nx A
AAA
A
                                   
Error!  Bookmark not deined.
 
 
( ) ( ) ( )
1000
1.0
×
++
=
∑
∑ ∑ ∑
f
ymwyswycol
ny A
AAA
A
                                      
 
For each column with a cross-sectional area 
denoted by Acol: 
(Acol)x=kx . Acol       ,    (Acol)y=ky . Acol    (5) 
Where; kx=1/2 for square and circular columns; 
kx=2/3 for rectangular columns with bx>by; kx=1/3 
for rectangular columns with bx<by; and ky=1-kx 
For each shear wall with cross-sectional area 
denoted by Asw: 
 (Asw)x=k .Asw       ,   (Asw)y=ky.Asw          (6)      
Where; kx=1 for structural walls in the direction of 
x-axis; kx=0 for structural walls in the direction of 
y-axis; and ky =1-kx. 
For each unreinforced masonry filler wall with no 
window or door opening and having a cross-
sectional area denoted by Amw:
  
 
        
(Amw)x=kx . Amw       ,     (Amw)y=ky . Amw        (7) 
Where; kx=1.0 for masonry walls in the direction of 
x-axis; kx=0 for masonry walls in the direction of 
y-axis; and ky=1-kx. 
 
(d) Normalized redundancy score (nrs): The 
normalized redundancy ratio (nrr) of a frame 
structure is calculated by using the following 
expression: 
( )( )
gf
yxtr
A
nfnfA
nrr
11 −−
=
          
(8)
                                                                  
 
Where; Atr is the tributary area for a typical 
column. Atr shall be taken as 25 m2 if nfx and nfy are 
both greater than and equal to 3. In all other cases, 
Atr shall be taken as 12.5 m2. nfx, nfy are the 
number of continuous frame lines in the critical 
story (usually the ground story) in x and y 
directions, respectively. Agf is the area of the 
ground story, i.e. the footprint area of the building. 
Depending on the value of nrr computed from Eq. 
8, the following discrete values are assigned to the 
normalized redundancy score (nrs): 
nrs = 0 for ≤ 0  
nrs = 1 for 0 < nrr ≤ 0.5 
nrs = 2 for 0.5 < nrr ≤ 1.0 
nrs = 3 for 1.0 < nrr 
 
(e) Soft Story Index (ssi): On the ground story, 
there are usually fewer partition walls than in the 
upper stories. This situation is one of the main 
reasons for the soft story formations.  soft story 
index is defined as the ratio of the height of first 
story (i.e. the ground story), H1, to the height of the 
second story, H2. 
2
1
H
H
ssi =
                                        
(9) 
(f) Overhang ratio (or): The summation of the 
overhang area of each story, Aoverhang, divided by 
the area of the ground story, Agf, is defined as the 
overhang ratio. 
gf
overhang
A
A
or =
                      
             
(10) 
3.2.1 Performance Classification: 
The damage index or the damage score 
corresponding to the life safety performance 
classification (DILS) shall be computed from the 
discriminate function given in Eq. 11. 
 
DILS=0.620n-0.246mnlstfi-0.182mnlsi-
0.699nrs+3.269ssi+2.728or-4.905          (11) 
 
In the case of Immediate Occupancy Performance 
Classification (IOPC), the discriminate function, 
where DIIO is the damage score corresponding to 
IOPC, based on these variables is: 
 
DIIO=0.808n-0.334mnlstfi-0.107mnlsi-
0.687nrs+0.508ssi+3.884or-2.868            (12) 
 
In the proposed classification methodology, 
buildings are evaluated according to both 
Performance levels. The steps to be followed are 
listed below. 
(1) Calculate DILS and DIIO scores by using Eq. 11 
and Eq. 10, respectively. 
 
Page 109
 *
 Corresponding Author: K.M.Khaleduzzaman  
E-mail: nayansustcee@yahoo.com 
 
 
Table 2: Base Scores and Vulnerability Scores for Concrete Buildings 
 
Number 
of 
Stories 
Base Scores (BS) Vulnerability Scores (VS) 
Zone I 
(60<PGV<80) 
Zone II 
(40<PGV<60) 
Zone III 
(20<PGV<40) 
Soft 
Story 
Heavy 
Overhang 
Apparent 
Quality 
Short 
Column 
Pounding Topography 
Effects 
1 or 2 100 130 150 0 -5 -5 -5 0 0 
3 90 120 140 -15 -10 -10 -5 -2 0 
4 75 100 120 -20 -10 -10 -5 -3 -2 
5 65 85 100 -25 -15 -15 -5 -3 -2 
6 or 7 60 80 90 -30 -15 -15 -5 -3 -2 
 
Table-3: Variation of CMC Values with Soil Type and Distance to Fault 
 
Soil 
Type 
Site class description 
 
Shear Wave 
Velocity (m/s) 
Distance to Fault (km) 
0-4 5-8 9-15 16-25 >26 
B Rock >360 0.778 0.824 0.928 1.128 1.538 
C Very dense soil and soft rock 360-760 0.864 1.000 1.240 1.642 2.414 
D Stiff soil 180-360 0.970 1.180 1.530 2.099 3.177 
E Soft soil, profile with>3m of soft 
clay defined as soil with plasticity 
index PI>20,moisture content>40% 
 
<180 1.082 1.360 1.810 2.534 3.900 
 
 (2) Determine the cutoff values for each 
performance classification by using Eq. 13.  
The LSCVR and IOCVR values in Eqs. 11 and 12 shall 
be obtained from Table 4.4 based on the number of 
stories above the ground level. The cutoff 
modification coefficients CMC values are 
adjustment factors, which introduce the spatial 
variation of the ground motion in the evaluation 
process. These values shall be taken from Table-4.5 
based on the building location relative to the fault 
and the soil type at the site. 
CVLS = LSCVR + │LSCVR │× (CMC -1);   
CVIO  = IOCVR  +│IOCVR│×    (CMC-1)           (13) 
 
Table -4: Variation of LSCVR and IOCVR Values 
with Number of Stories 
n LSCVR IOCVR 
3 or less 0.383 -0.425 
4 0.430 -0.609 
5 0.495 -0.001 
6 1.265 0.889 
7 1.791 1.551 
 
(3) By comparing the CV values with associated DI 
value calculate performance grouping of the 
building for life safety performance classification 
(LSPC) and immediate occupancy performance 
classification (IOPC) as follows: 
 
If DILS > CVLS take PGLS=1 
If DILS < CVLS take PGLS=0 
If DIIO > CVIO take PGIO=1 
If DIIO < CVIO take PGIO=0 
 
To decide the probable expected performance level 
of the building the damage scores obtained from 
Eqs. 11 and 12 should be compared with the story 
dependent cutoff values obtained from Eq. 13. In 
each case, the building under evaluation is assigned 
an indicator variable of “0” or “1”. The indicator 
variable “0” corresponds to “none, light or 
moderate damage” in the case of LSPC and “none 
or light damage” in the case of IOPC. Similarly, the 
indicator variable “1” corresponds to “severe 
damage or collapse” in the case of LSPC and 
“moderate or severe damage or collapse” in the 
case of IOPC. In the final stage, the building is 
rated in the “low risk group” if both indicator 
values are zero or in the “high risk group” when 
both indicator values are equal to unity. In all other 
cases buildings are classified as the cases “requiring 
further study.” Further investigations have 
indicated that these buildings generally lie in the 
“moderate risk group.” 
 
4. RESULTS AND DISCUSSION: 
Table-1 represents the result of walk down 
assessment (seismic performance score). Seismic 
performance score below 40, between 41 to 70 and 
between 71 to 100 indicates the high risk group, 
moderate risk group and low risk group 
respectively. Table-6, table-7, table-8, table-9 and 
table-10 represents the number of schools and/or 
Page 110
 *
 Corresponding Author: K.M.Khaleduzzaman  
E-mail: nayansustcee@yahoo.com 
 
colleges laid in these categories when the distance 
to fault is more than 26km, between 16km to 25 
km, 9km to 15km, 5km to 8km and less than 4 km. 
Figute-2 represents the overall scenario quite 
clearly. 
 
Table-5: Calculated performance scores of the 
studied school and colleges 
 
No. of 
Stories 
Performance Score(PS)  
PS≤40 40<PS≤70 70<PS≤100 Total 
1&2 0(0) 1(3.2) 30(96.8) 31(100) 
3 0(0) 3(23.1) 10(76.9) 13(100) 
4 1(11.1) 5(55.6) 3(33.3) 9(100) 
Total 1(1.87) 8(15.1) 44(83.2) 53(100) 
 
Table-6: Results of the Preliminary Assessment 
Method when distance to fault > 26.km. 
No. of 
Stories 
High 
Risk 
Group 
Moderate 
Risk 
Group 
Low 
Risk 
Group Total 
≤2 0(0) 0(0) 31(100) 31(100) 
3 0(0) 1(7.69) 12(92.3) 13(100) 
4 0(0) 2(22.22) 7(77.7) 9(100) 
Total 0(0) 3(5.56) 50(94.3) 53(100) 
 
Table-7: Results of the Preliminary Assessment 
Method when distance to fault is between 16 to 
25km. 
No. of 
Stories 
High 
Risk 
Group 
Moderate 
Risk 
Group 
Low 
Risk 
Group Total 
≤2 0(0) 1(3.23) 30(96.7) 31(100) 
3 0(0) 2(15.38) 11(84.6) 13(100) 
4 0(0) 2(22.22) 7(77.8) 9(100) 
Total 0(0) 5(9.43) 48(90.6) 53(100) 
 
Table-8: Results of the Preliminary Assessment 
Method when distance to fault is between 9 to 
15km. 
No. of 
Stories 
High 
Risk 
Group 
Moderate 
Risk 
Group 
Low 
Risk 
Group Total 
≤2 0(0) 5(16.13) 26(83.8) 31(100) 
3 1(7.69) 3(23.1) 9(69.2) 13(100) 
4 3(33.3) 2(22.2) 4(44.4) 9(100) 
Total 4(7.55) 10(18.9) 39(73.6) 53(100) 
 
Table-9: Results of the Preliminary Assessment 
Method when distance to fault is between 5 to 
8km. 
No. of 
Stories 
High 
Risk 
Group 
Moderate 
Risk 
Group 
Low 
Risk 
Group Total 
≤2 1(3.22) 6(19.3) 24(77.4) 31(100) 
3 1(7.69) 3(23.1) 9(69.2) 13(100) 
4 3(33.3) 3(33.3) 3(33.3) 9(100) 
Total 5(9.43) 14(24.2) 33(62.3) 53(100) 
 
Table-10: Results of the Preliminary Assessment 
Method when distance to fault is <4km 
 
No. of 
Stories 
High 
Risk 
Group 
Moderate 
Risk 
Group 
Low 
Risk 
Group Total 
≤2 2(6.45) 9(29.03) 20(64.5) 31(100) 
3 1(7.69) 6(46.2) 6(46.2) 13(100) 
4 3(33.3) 2(22.2) 4(44.4) 9(100) 
Total 6(11.3) 17(32.1) 30(56.6) 53(100) 
 
 
 
 
Fig-2: Change of vulnerability with distance to fault 
 
 
5. CONCLUSION: 
In Bangladesh, one of the major work tasks consists 
in the identification of the structural seismic 
vulnerability of schools and college. The integrity 
of schools and college buildings during an 
earthquake disaster is of utmost importance. Since 
the sylhet region is located near the Dauki fault 
zone, an earthquake of moderate level may cause a 
heavy damage to life and property. Some 
recommendations which are the outcome of the 
study is given below that should be followed to 
minimize the vulnerability of the school and/or 
college building; 
• Structural assessment should be carried 
out for the schools and college building 
which are in most seismic vulnerable 
group. 
• Rapid measures should be taken to repair 
the buildings which are in low and 
moderate seismic assessment group. 
• Proper earthquake guideline should be 
followed at the time of constructing new 
educational buildings. 
• Some buildings ,which are in very high 
risk as well, should not be used any 
longer 
 
6. REFERENCES 
 
0
10
20
30
40
50
60
High Risk Group
Moderate Risk 
Group
Low Risk Group
Page 111
 *
 Corresponding Author: K.M.Khaleduzzaman  
E-mail: nayansustcee@yahoo.com 
 
1. A New Approach for Earthquake 
Vulnerability and Damage Assessment of a 
Large Group of Existing Residential 
2. Buildings Yaron OFFIR1, David Z. 
YANKELEVSKY2 and Stephan 
SCHWARZ3) 
3. Statistical Pocket Book of Bangladesh, 
Bangladesh Bureau of Statistics. January 
2009. Retrieved on 26 May 2009. 
4. Dennis Bellet, Keeping schools safe in 
earthquake(2006), fundamental concepts 
and principals for assuring acceptable 
performance of school and education 
system 
5. Current Situation - Past and Present - 
Sylhet, Bangladesh Ethnic Community 
Development Organization. Retrieved on 
30 May 2009. 
6. list of school, sylhet msn group 
7. Federal Emergency Management Agency 
(FEMA), “HAZUS : Earthquake loss 
estimation methodology“, 1999 
8. M A Ansary and M Sharfuddin, 
Earthquake hazards scenario in greater 
Sylhet city. 
 
Page 112
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 ar.mujtaba.ahsan@gmail.com : nafiz_h2o@yahoo.com 
ECO‐HOUSING: MATERIAL TECHNOLOGIES FOR A 
SUSTAINABLE BUILT ENVIRONMENT 
 
 
Mujtaba Ahsan and Nafizur Rahman* 
North South University & Housing and Building Research Institute, Dhaka 
 
 
Eco‐Housing is an environmentally and economically optimized designed environment with the objective to 
deliver resource efficient built infrastructure through improved energy and material performance. Material 
efficiency can contribute to the economic, environmental and social benefits of a country. The two most 
common materials used in indigenous construction in Bangladesh are clay and bamboo. However, with 
growing population the availability of these materials, particularly bamboo, is decreasing and their prices are 
increasing. The structures built with clay and bamboo are also proving to be vulnerable to natural damages 
and destruction such as by seasonal flooding, cyclones and time borne decay, leading to short life spans and 
adding to the burden of scarce supply. Currently the trend towards replacing traditional building materials to 
better withstand flood, cyclone and other natural agents of destruction is by the use of CI sheets. But this is 
not a positive development. CI sheets have a much higher embodied energy, their recycle is not very 
convenient and their thermal performance is very poor. The HBRI eco-housing project demonstrates better 
and cheaper material alternatives and technologies that can be replicated all over the country delivering 
much better environmental and economic performance of housing materials. 
 
Key words: Eco‐housing, sustainability, materials, green technology, appropriate technology 
 
1. INTRODUCTION 
 
The United Nations has used the term 
“Eco‐Settlement” since 1972 to define sustainable 
built‐infrastructure. From 2004, the United Nation’s 
Environment Program (UNEP) and UN HABITAT 
have been setting up guidelines to implement 
examples of Eco‐Settlements in the Asia Pacific 
region, identifying it as a flexible, bottoms‐up 
approach that can reduce the negative trends of the 
construction sector and release environmental and 
energy‐saving benefits (UNEP, 2006). With 
emphasis in four key areas: knowledge building, 
educational initiatives, networking and 
demonstration projects, these organizations have 
realized that despite the wide acceptance of the 
concept, a lack of demonstration projects is 
preventing the political decision making process. As 
a result, the UNEP and UN‐HABITAT have 
implemented several eco‐housing demonstration 
projects in countries of Asia, including Indonesia, 
the Maldives, Sri Lanka, Thailand, China and 
Bhutan. As a result of these developments, in 2006, 
the HBRI submitted a proposal to the Government 
of Bangladesh (GOB) for a project titled: Study on 
Eco‐Housing, Ferro‐cement Floating House and 
Polymer in Cement Concrete Using Indigenous 
Materials with a view to create an eco‐housing 
demonstration project in the country which would 
provide an illustrative example of how the building 
sector can contribute to give a relief pressure on the 
material and energy sector (electricity, fuel, and 
other resources) of Bangladesh as well as provide 
large scale environmental benefits. The project was 
approved for the 2007‐2008 financial year – its 
execution started in July 2007 and was completed in 
December 2008. 
 
2. BUILDING MATERIAL – AN 
IMPORTANT COMPONENT OF 
SUSTAINABLE SETTLEMENT 
 
The guidelines of the United Nations Environment 
Program, UNEP (2006, pp.26-27) and UN-
HABITAT on eco‐housing laid emphasis on eight 
key areas, the selection and use of proper building 
materials is one very significant part of them. The 
guidelines, in particular, laid emphasis on using 
natural and rapidly renewable materials as below: 
 
“Use naturally available materials, especially 
organic renewable materials like timber, trees, 
straw, grass, bamboo etc. Even non‐renewable 
inorganic materials like stone and clay are 
useful, since they can be reused or recycled.” 
(UNEP‐IETC, 2004, p.27‐29) 
Page 113ISBN: 978-984-33-2140-4
  
The guidelines of the US Green Building Council 
(USGBC) in its eco‐labeling tool, Leadership in 
Energy and Environmental Design (LEED) has put 
similar emphasis on eight major areas of which the 
selection and use of building materials is one of 
them. According to LEED a green construction 
earns point in the material and resources category 
by following the criteria below: 
 
“Reuse building materials and products to 
reduce demand for virgin materials and reduce 
waste, thereby lessening impacts associated 
with the extraction and processing of virgin 
resources. Increase demand for building 
materials and products that are extracted and 
manufactured within the region, thereby 
supporting the use of indigenous resources and 
reducing the environmental impacts resulting 
from transportation. Reduce the use and 
depletion of finite raw materials and long‐cycle 
renewable materials by replacing them with 
rapidly renewable materials.” (USGBC, 2010, 
pp. 51‐54) 
 
From the above discussion, it is clear that 
eco‐friendly materials are in general characterized 
by those that are locally available, that can be easily 
recycled, reused or rapidly renewed (for short life 
cycle natural materials such as bamboo); in addition 
having properties of low‐embodied energies, low 
emissions and low cost. Some of these building 
materials are mostly made from naturally available 
materials like clay, stone, sand or biomass. 
 
3. HOUSING TYPES & MATERIAL 
USE IN BANGLADESH: 
 
In Bangladesh, 82% households in the rural and 
47% households in the urban areas are made from 
non-permanent (kutcha) building materials (table 1) 
making them vulnerable to flood, cyclone, 
weathering and natural decay. Increasing the 
longevity of these structures could not only provide 
economic benefits, but can also reduce the need for 
new construction materials. 
 
Structure Urban Rural 
Nos. % Nos. % 
Jhupri 420  7.58  1767  9.15  
Kutcha 26.11  47.15  15873  82.19  
Semi-pucca 1288  23.26  1222  6.33  
Pucca 1219  22.01  450  2.33  
Total 5538  100  19312  100  
Table 1. Dwelling households by the type of 
structure (BBS, 2001) 
 
According to general longevity of the construction 
material, traditional houses in Bangladesh are 
popularly classified into four main groups – jhupri 
or informal house, kutcha or impermanent house 
and pucca or permanent house. A sub‐group 
semi‐pucca denotes a combination of permanent 
and impermanent materials. Following is a 
categorization of the main construction materials 
used in traditional house forms in Bangladesh 
(Ahmed, 2005): 
 
Kutcha House  Semi Pucca 
House  
Pucca 
House  
Foundation 
Earthen plinths 
with bamboo and 
sometimes 
timber posts  
Earthen plinths; 
Brick perimeter 
wall with earth 
infill; Brick and 
concrete.  
Brick 
and 
concrete.  
Wall 
Organic 
materials – jute 
stick, catkin 
grass, straw, 
bamboo mats, 
etc. Split bamboo 
framing. Earthen 
walls in some 
areas  
Bamboo mats; 
CI sheet; Timber 
(sometimes split 
bamboo) 
framing. Earthen 
walls in some 
areas. Sometimes 
part or full brick.  
Brick  
Roof 
Thatch rice or 
wheat or maize 
straw, catkin 
grass, etc with 
split bamboo or 
sometimes reed 
stalk framing.   
CI sheet with 
timber framing 
(sometimes split 
bamboo)  
Reinforc
ed 
concrete  
Table 2. Major house building materials in 
Bangladesh (Ahmed, 2005) 
 
According to material used in construction, 
traditional houses in Bangladesh can also be 
categorized as follows (Murshed, 2006): 
 
3.4 Mud Houses: 
One‐third in this country live in mud houses 
because of its widespread availability, relatively 
permanent nature and cheaper construction cost. In 
the Rajshahi region, double storied mud houses are 
common, and in the Jessore single storied mud 
house are predominant. In some regions, houses are 
made with mud blocks mixed with rice husk while 
in others layers of clay are used directly for 
construction. The wall thicknesses typically vary 
from 10" to 24". Mud houses are primarily 
available in the western part and hilly area of less 
flood prone regions of the country. Thatch, clay 
tiles and CI sheeting are typically used in roofing 
these houses. 
Page 114
  
 
Figure 1: Prevalence of Mud Walled Houses in 
Bangladesh (Chowdhury, 1988; 1995) 
 
3.5 CGI Sheet House: 
Corrugated galvanized Iron (CGI) sheet houses are 
available all over the country. Local NGOs provide 
loan of about 10,000/‐ (Taka ten thousand) to 
20,000/‐ (Taka twenty thousand) to use in the 
improvement of the house – a mechanism that has 
rapidly transformed the indigenous house into CGI 
houses. A CGI sheet house carries considerable 
social prestige in the rural areas. Variations in the 
design, size and height of the houses are related to 
the status and wealth of the family. In Faridpur, 
Madaripur, Barisal, Patuakhali and Bhola CI sheet 
houses are also common where the material is used 
for both roofing and wall construction. In the 
central part of the country, as in Dhaka, Comilla 
and Mymensingh CI sheets are mainly used for 
roofing with mud or mud block walls.  
 
 
Figure 2: Prevalence of CI Sheet Houses in 
Bangladesh (Chowdhury, 1988; 1995) 
 
Figure 3: Prevalence of Bamboo Structures in 
Bangladesh (Chowdhury, 1988; 1995) 
 
3.6 Bamboo House: 
Bamboo structures commonly found all over the 
country are relatively richer in the north‐eastern and 
south‐eastern parts. The Tribal house is an excellent 
example of indigenous bamboo house where the 
roof, the walls and even the floors are made with 
bamboo, raised on a platform to keep away wild 
animals, flash flood and landslide. Bamboo 
structures by virtue of flexibility of the material are 
typically more resistant to natural disasters like 
high wind and flood. Besides being low cost, 
bamboo is strong, durable and flexible which can 
sustain the structure under high wind. 
 
3.7 Wooden House: 
Wooden houses are common in the Madhupur 
Tracts and in the Chittagong Region because of the 
nearby forests. Timber houses in Chittagong are 
typically two storied, exceptions being those in the 
south. The houses of the Rakhain and Moghs are 
also of timber, but they are built on stilts. The 
prosperous Moghs have double-storied houses with 
curved balconies and lintels. The timber house in 
Sylhet usually have the floor and sometimes part of 
the lower walls made out of brick, while the walls 
are constructed of reeds called Ikra (Erianthus 
ravaneae) or bamboo matting plastered over with 
cement or mud on both sides and painted white; a 
frame of timber, painted black holds these up. The 
roof is usually of CI sheet, and sometimes of straw. 
 
Houses located in the flood plains of the major 
rivers are subject to various hazards, like riverbank 
erosion, so people are compelled to invest as little 
as possible in housing. In a majority of the cases 
these houses have walls of jute sticks with mud 
dubbed on and thatching of paddy straw. In the 
marshy and low lands (Haor basin, Chalan Beel) 
Page 115
  
and in the islands (char lands), cheap construction 
materials like locally available reeds, long grass, 
jute sticks etc. are widely used both for roofing and 
wall construction. Kitchens, cowsheds, poultry 
coops, etc are typically built separate and usually 
with poorer materials. Except in the north-western 
and central regions where the cowsheds are 
thatched well and stand higher; poor sheds are 
rather more common. 
 
4.0 TRADITIONAL HOUSE – ITS 
VULNERABILITY TO DISASTERS: 
 
4.1 Flood 
Due to its geographical location, natural disasters 
are a common phenomenon in Bangladesh, the 
most significant being flood (Hossain, 2002); 
almost every year the country is flooded once, even 
twice or sometimes more. According to Ahmed 
(2005, p. 3) damage to house forms caused by flood 
are primarily due to: (a) Direct flood hazard: which 
are closely related to (i) Flood depth, (ii) Flood 
duration, (iii) Uplift due to soil saturation and (iv) 
Horizontal force created by flood waves or 
currents; (b) Indirect flood hazard: secondary 
hazards such as high winds or storms, lightning, 
slope instability, ground settlement, etc.; and (c) 
Sustained flood hazard: floodwater can submerge 
buildings and cause various degrees of damage 
from staining of walls to structural collapse 
depending on flood depth and/ or duration and type 
of building. Brick and concrete (pucca) foundations 
are relatively stable under the affects of flood. In 
semi‐pucca houses, the infill earth floor may settle 
and in prolonged flood can become muddy, 
unstable and the mud can escape from below. In 
kutcha houses both low and high intensity flood 
tend to wash off the mud plinth. In kutcha houses 
prolonged or recurring flood tend to rot the base of 
the bamboo or timber posts in saturated soil of the 
plinth. Rotting of the base weakens the entire 
structure making it vulnerable to strong winds, 
differential settlement, sagging of roofing elements 
and doors, windows and wall elements developing 
cracks and losing alignment (Ahmed, 2005).  
 
Organic jute stick and catkin grass walls have a 
lifespan of 2‐3 years and bamboo mat 4‐5 years 
(Ahmed, 2005). Corrugated Iron (CI) sheet on 
timber framing corrodes due to contact with water 
and gets aggravated in flood. If not sufficiently 
above flood level the lower parts of walls are the 
most vulnerable. Monolithic earth wall construction 
can get seriously damaged by flood once the base 
gets affected, the entire structure may collapse. 
Brick walls are relatively durable. Roofs in kutcha 
houses are typically made from catkin grass, rice, 
wheat or maize straw usually on bamboo and 
sometimes reed stalk framing. Normally these have 
to be renewed every 2‐3 years (Ahmed, 2005). 
Decay occurs if thatch comes into contact with 
flood water or gets washed off in strong driving 
rain. Roofs in semi-pucca house are typically made 
from CI sheet with timber or bamboo framing. CI 
sheets are vulnerable to corrosion in damp 
atmosphere. A greater hazard occurs in strong wind 
when CI sheets are crumpled and blown off. 
Reinforced concrete (RC) roof is relatively durable. 
 
4.2 Other Natural Disasters 
Riverbank erosion is most common and a regular 
hazard in Bangladesh and rural housing is directly 
affected by it. About 10,000 hectares of agricultural 
land erodes every year and bank erosion ranges 
from 250‐800 meters every year (BWDB, 2010). 
The three major rivers Padma, Jamuna and Meghna 
bank erosion happen frequently and the most 
vulnerable districts are Sherajgong, Chandpur, 
Faridpur. People become land and homeless and 
take shelter on the sides of major roads and 
highways. 
 
Traditionally cyclones of varying intensity hit parts 
of Bangladesh almost every year and super 
cyclones typically occur after every 10 years; but 
due to global warming and climate change the 
frequency of cyclones has increased. In the last few 
years super cyclones Sidr and Aila hit the coastal 
regions of the country causing large scale death of 
humans and cattle and damage to households and 
crops. Particularly Cyclone Sidr (15‐16 November, 
2008) damaged 565,000 households fully and 
957,000 partly. On the other hand, cyclone Aila 
(25‐ 26 November 2009) damaged 243,000 
households fully and 371,000 households partly 
(CDMP, 2008). 
 
According to Lewis and Chisholm (1996) efforts to 
improve traditional houses to withstand cyclone has 
not gained popularity primarily because: 
• High storm surges accompanying cyclones have 
tended to sweep away kutcha and semi‐pucca 
structures regardless of their quality 
• Poorly maintained or absence of embankments 
have failed to protect households in their places 
• A general tendency to invest little in improved 
construction exists because villagers feel their 
investments would get washed away in the next 
storm  
 
However, improved construction can deliver 
several possible benefits as below: 
• Continued occupation of homes during cyclones 
• Reduction in need of safe heavens (cyclone 
shelters) 
Page 116
  
• Avoidance of dangers of travelling 
homes and safe heavens 
• Reduction of time away from home and attendant 
risk of theft 
• Greater ability to use roofs for both kutcha and 
pucca dwellings as refuge during floods
• Reduction of the recurrent costs of dwelling 
reconstruction/replacement, enabling people to 
stay safely in their own homes, relieve 
over‐crowding in safe heavens 
(Lewis & Chisholm, 1996) 
 
5. HBRI ECO-HOUSING - SOLUTION 
FOR SUSTAINABLE HOUSING
 
Ahmed (1996, p. 39) has shown that contrary to 
popular belief traditional local buildin
are no longer so widely available nor are they 
always cheaper. The standard recommendations of 
“eco‐settlement” guidelines (paragraph 2) therefore, 
need to be revisited in terms of the use of bio
and availability of the most common buildin
material in Bangladesh which is bamboo. 
Bangladesh Bureau of Statistics census of 1981 
indicates that the majority of the houses use 
bamboo in construction whose prices are rising due 
to a growing scarcity (Ahmed I., 1996). Moreover, 
various Non Governmental Organizations (NGOs) 
such as the Grameen Bank and BRAC are 
providing loans to build improved housing which 
can help significantly in overcoming 
cost constraints in selecting house building 
materials.  
 
With a scenario as such the HBRI E
demonstration project has researched and 
developed eight prototype dwelling units 
examples of improved material and 
performance. The project is located within the 
HBRI campus in Mirpur, Dhaka spread over 40 
Kathas of land. It consists of eight rural type units 
each 480 square feet in plan and one urban type 
unit 1230 square feet in floor space. The units are 
for residential use and incorporate renewable 
energy technologies – bio-gas, wind and solar 
power and improved building materials
 
The flood resistant properties of the dwelling units 
have been enhanced by adopting several design 
parameters. These are described below: 
 
Plinth: A brick perimeter wall has been used in the 
construction of the plinth and filled with compacted 
sand to prevent the washing away and damaging 
impacts of recurrent and prolonged flood water. 
Sand fill prevents the seepage of dampness through 
capillary action that rots organic structural 
members – bamboo frames in typical mud plinths.   
between 
 
 
g materials 
‐mass 
g 
technical and 
co‐Housing 
that show 
technological 
. 
 
 
Wall & Roof: the most vulnerable part of 
traditional non-permanent wall construction is the 
lower edge which is recommended to be protected 
from the affects of water. Rural unit 2 made from 
bamboo mat and golpata (nipa palm) thatch roof 
most closely resembles the traditional impermanent 
rural structures. The wall has been protected 
rain by a large overhang of the roof. 
gopata offers additional protection a
its inherent property; it does not easily decay in 
contact with water. Furthermore, to provide 
additional strength, chemically treated bamboo 
frame has been used. The lower parts have been 
dipped in tar and the whole bamboo and thatching 
material have been treated chemically to prevent 
decay. Firm anchoring of the frame has been 
ensured with the plinth, thereby, ensuring that extra 
strength is imparted to the roof and frame to 
withstand cyclonic conditions. 
 
Figure 4: Prototype 4 Ekraw wall construction
 
Similar structural features have been followed in 
rural unit type 4 built with a stabilized brick 
perimeter wall, neat cement finish and compacted 
sand fill construction of the plinth. The wall has 
been constructed using bamboo mat wall,
proofing has been achieved by plastering the wall 
surface – an indigenous construction technique 
called Ikra wall popular in the Sylhet region. The 
plastering process greatly enhances the longevity of 
the structure by keeping out dampness and ma
very much flood resistant.  
 
The structural frame has been made with reinforced 
cement concrete (RCC) pillars of 4” by 4” square 
section supporting a mild steel framing anchored 
firmly on the RCC pillars and covered with 
corrugated iron (CI) sheeting. The strong structural 
frame greatly enhances the flood, cyclone and 
from 
Further, the 
gainst rain by 
 
 
 
 but water 
kes it 
Page 117
  
weathering resistant properties of the materials 
used. Instead of a gabled roof, hipped gabled roof 
has been designed which offers greater protection 
from cyclonic wind (Lewis & Chishol
(Ahmed K. I., 2005). Roof overhand and gutter to 
collect rainwater further prevents dampening of the 
wall material and prevents water borne decay of 
wall material. 
 
The CI roof has been properly ventilated by leaving 
an air gap between the wall and the roof to allow 
convective cooling by air flow. However the hip 
gable traps the hot air which can only escape 
through the leaks, causing a heat build
proposal has been forwarded to provide heat 
insulation by installing styro-foam false cei
which has not been executed yet.  
 
Figure 5: Rural type unit 3
 
Rural type unit 3 uses concrete hollow block walls 
and ferro-cement roof material on a stabilized brick 
walled plinth. Ferro-cement materials have the 
advantage of high crack resistance
impermeability to water. The basic raw materials 
are widely available and construction skills can be 
easily acquired. These also require little 
maintenance and do not involve complex 
equipment in construction (Ahmed K. I., 2005). 
Furthermore, nowadays with micro-credit or loans 
provided by NGOs, these materials have come 
within the affordability of the rural people. The unit 
presents an attractive alternative for building rural 
structures which would be much more resistant to 
flood and cyclonic damages. The dead weight of 
the roof gives the added advantage of being a 
stabilizing agent in strong cyclonic wind.
 
Rural type unit 6 has a similar ground plan and 
layout, with the exception of the wall structure 
which is made with Rat-trap bonding. The bonding
saves the number of bricks required to construct a 
similar area of 10” wall, but gives much better 
thermal insulation and moisture protection. The 
space between two rooms in plan has been provided 
to allow women to engage in income generation 
activities. The gable angle of the roofs has been 
kept from 30 to 40 degrees which has been shown 
by prior research to offer greater resistance to 
m, 1996) 
-up inside. A 
ling 
 
 
 and 
 
 
cyclonic wind (Lewis & Chisholm, 1996). Once 
again, the dead weight of the structure gives 
considerable anchoring. 
 
Figure 6: Rural type unit 2
 
Rural type 2 has four dwelling units and is designed 
to serve as a dwelling in semi-urban areas. The wall 
material has been derived from recycled 
demolished concrete blocks. Demolished concrete 
from a pulled down building in the 
Bhaban) was transported to the site were the blocks 
were crushed using a motor operated crushing 
machine to yield a mixture of coarse and fine 
aggregates. Cement and water was mixed with the 
latter and cast into blocks to create concrete bricks
To allow easy workability, a 10” by 10” square 
block was used as traditional masons are habituated 
to working in brick modules. Any larger size makes 
the blocks too heavy for workability. The use of 
recycled demolished material reduces landfill and 
need for pristine materials, which produces saving 
and useful recycling of construction waste.
of pucca or permanent materials makes the 
dwelling units much more stable under flood and 
cyclone conditions; therefore, they provide 
examples of improved housing solutions for the 
rural areas of Bangladesh.  
 
The two units made from bamboo mat walls and 
traditional roofing also use improved technology of 
plinth construction, strong frame construction, 
treated bamboo, wall and roofing which make them 
much more durable and resistant to common 
flooding and cyclone related damages as compared 
to traditional rural structures made from similar 
materials.  The following tables provide a summary 
the relative advantages of each type of construction 
over similar conventional buildings: 
 
Unit 2: Demolished 
concrete construction  
Conventional
construction
Recycled material  New material
Concrete ratio 1:4:7 in 
which only cement and 
¼ of course sand 
required additionally   
Concrete r
(cement: sand: course 
aggregate). 
materials required
9.5”×9.5”×2.75” block 9.5”×9.5”
 
 
city (Rangs 
. 
 The use 
 concrete 
 
 
atio 1:4:7 
All new 
 
×2.75” block 
Page 118
  
size costing Tk. 23/- 
per block  
size costing Tk. 40 /- 
per block  
Only crushing energy 
required  
Requires manufacturing 
energy of raw materials 
Ferro cement roof  R.C.C. roof 
Pre cast  Cast in situ  
Requires less time in 
construction  
Requires more time in 
construction 
Cost Tk. 150-170/ sft  Tk. 200-250/ sft 
Table 3: Studied benefits in Unit 2 
 
Unit 3: Hollow block  
wall  
Conventional brick 
wall  
7.5”×17”×4” block size 
costing Tk. 25/- per 
piece   
9.5”×4.5”×2.75” bricks 
size costing Tk.5/- per 
piece  
Per cubic feet wall 
construction cost less  
Construction cost more 
No need for plaster  Plaster needed 
Ferro cement roof  R.C.C. roof 
Pre cast  Cast in situ  
Requires less time in 
construction  
Requires more time in 
construction 
Costs Tk. 100/ sft  Costs Tk. 200-250/ sft 
Table 4: Studied benefits of Unit 3 
 
Unit 4: Treated Bamboo 
& Nipa Palm 
Ordinary Bamboo 
Construction   
Treated bamboo pillar 
average life time is about 
10-15 years   
Ordinary bamboo pillar 
life span about 2-3 
years   
Designed to be stable 
under strong wind  
Roof tend to blow 
away in cyclone 
Golpata roof effective 
under  suction wind 
effect (better able to 
withstand cyclone) 
CI sheet roof is 
venerable under  
suction wind effect 
Table 5: Studied benefits of Unit 4 
 
Unit 5: Hollow brick 
wall construction 
Typical 10” thick brick 
wall construction 
10” brick hollow wall 
(Rat-trap bonding) 
10" brick solid wall 
(English/Flemish bond) 
30% brick saving - 
Ferro cement corrugated 
sheet  roof 
Ordinary R.C.C. roof 
  
Pre cast Cast in situ 
Requires less time in 
construction 
Requires more time in 
construction 
Construction cost Tk. 
100/ sft 
Tk. 200-250/ sft 
Table 6: Studied benefits of Unit 5 
 
Unit 6: Ekra wall    Ordinary 5” brick wall  
Economical Less economical 
Durable (life time more Durable  
than 50 years) 
Wall thickness 2"-2.5", 
space saver 
Thickness 5" 
Construction cost 
Tk.52/ sft 
Cost Tk.60-70/ sft 
Table 7: Studied benefits of Unit 6 
 
6. RECOMMENDATIONS 
 
Materials chosen for construction play an important 
role in determining the longevity and hazard 
resistant properties of the overall dwelling unit. 
Bangladesh, due to its geographic location, is 
vulnerable to flood, cyclone, river erosion and other 
water related disasters. Making structures capable 
of withstanding water borne damages is a 
challenge. Even though common wisdom to 
sustainable built structure suggest that fast growing 
organic materials such as bamboo is most 
appropriate for rural home construction, and even 
though it is being used as such, studies suggest that 
such organic materials are increasingly becoming 
scarce and expensive (Ahmed I. , 1996). The 
incentive in disaster prone areas to build more 
robust housing is also less as rural population in 
these areas feel their investments on their housing 
units vulnerable that would be lost in the next flood 
or cyclone (Lewis & Chisholm, 1996). If cyclone 
and flood resistant structures can be shown to 
survive in these areas, the people would be willing 
to spend on building more permanent infrastructure. 
Simple technology such as the construction of brick 
walled plinths and concrete pillars are now 
becoming available in the rural areas. With a little 
training and economic support in terms of micro-
credits and loans that are increasingly becoming 
available through various NGOs and foreign aid 
agencies, the modern structures demonstrated in the 
eco-housing project can become easily replicable 
ones.  
 
The replacement of traditional materials – clay and 
bamboo, is already taking place by CI sheets. 
NGOs and various foreign aid agencies are 
providing CI sheets to disaster affected areas and 
the ability to sell CI sheets during financial 
difficulty is making it a liquid asset. But the 
thermal and material properties (embodied energy, 
recycle value etc.) of CI sheet make it a non-
sustainable building material. If replacements must 
be made of bamboo and clay as base material for 
rural housing, the eco-housing units show several 
much more effective alternatives than CI sheet 
houses. It is desirable that the transition of rural 
housing from traditional materials to modern ones 
be guided towards much more environmentally 
positive and better performing alternatives as 
demonstrated by the eco-housing units. 
Page 119
  
7. REFERENCES 
 
1. Ahmed, I. (1996). Hazard-Resistant 
Construction Technology for Rural Housing in 
Bangladesh: Reinforced Cemement Concrete 
Posts. In R. Hodgson, S. Seraj, & J. 
Chowdhury (Ed.), Implementing Hazard 
Resistant Housing (pp. 39-52). Dhaka: BUET 
and The University of Exeter 
 
2. Ahmed, K. I. (2005). Handbook on Design and 
Construction of Housing for Flood-prone 
Rural Areas of Bangladesh. Dhaka: Asian 
Disaster Preparedness Center. 
 
3. BBS. (2001). Statistical Yearbook . Dhaka: 
Government of Bangladesh. 
 
4. BBS. (2000). Statistical Yearbook. Dhaka: 
Bangladesh Bureau of Statistics. 
 
5. BBS. (2005). Statistical Yearbook 2005. 
Dhaka: Government of Bangladesh. 
 
6. CDMP. (2008). The Comprehensive Disaster 
Management Progrmme (Phase II). Retrieved 
October 30, 2010, from The Comprehensive 
Disaster Management Programme (CDMP): 
http://www.cdmp.org.bd/ 
 
7. Chowdhury, S. I. (1988; 1995). Arthanitik 
Bhugol: Visva O Bangladesh (in Bangla). 
Dhaka: University of Dhaka. 
 
8. Hossain, S. (2002). Human Vulnerability due 
to Natural Disasters in South Asia: A GIS 
Aided Characterization of Arsenic 
Contamination in Bangladesh. Norway: 
NORAGRIC Agriculturl University of 
Norway. 
 
9. Lewis, J., & Chisholm, M. P. (1996). Cyclone 
resistant domestic construction in Bangladesh. 
In R. Hodgson, S. Seraj, & J. Chowdhury 
(Ed.), Implementing Hazard Resistant Housing 
(pp. 29-38). Dhaka: BUET and University of 
Exeter. 
 
10. Murshed, M. M. (2006). Rural House. In S. 
Islam (ed.), Banglapedia. Dhaka: Asiatic 
Society of Bangladesh. 
 
11. UNEP. (2006). Eco-Housing Guidelines for 
Tropical Regions. Bangkok: United Nations 
Environment Programme Regional Resource 
Centre for Asia Pacific (UNEP RRC.AP). 
 
12. USGBC. (2010). LEED 2009 for New 
Construction and Major Renovations. 
Washington: US Green Building Council. 
Page 120
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Kashif Mahmud,  
E-mail: rusho_mahmud@yahoo.com 
EFFECT OF SOFT STOREY IN REINFORCED CONCRETE FRAME 
STRUCTURES 
 
 
Kashif Mahmud* 
Department of Civil and Environmental Engineering 
Islamic University of Technology (IUT) 
Board bazar, Gazipur - 1704, Dhaka, Bangladesh 
E-mail: rusho_mahmud@yahoo.com, rusho@iut-dhaka.edu 
 
Nazmus Sakib 
Department of Civil and Environmental Engineering 
Islamic University of Technology (IUT) 
Board bazar, Gazipur - 1704, Dhaka, Bangladesh  
E-mail: nazm.sakib@gmail.com 
 
Md. Tahmidur Rahman 
Department of Civil and Environmental Engineering 
Islamic University of Technology (IUT) 
Board bazar, Gazipur - 1704, Dhaka, Bangladesh 
E-mail: tr_rafi@yahoo.com, tahmid@iut-dhaka.edu 
 
 
The present study was aimed at findings out the effect of soft storey on frame structures due to lateral 
loading. The masonry infill was modeled by equivalent struts and finite element package ANSYS 5.6 was 
used for the development of the model. Two different theories for modeling the equivalent struts i.e. 
Mainstone and Saneinejad theory were used. Deflections of building frame having soft storey at the ground 
floor were 1.4 to 2.0 times greater than that observed excluding the soft storey effect. The effect of soft story 
was more significant in case of less stiffer Reinforced Concrete (R.C.) frame structures. Storey level had a 
great influence on the deflection of a soft storey building frame due to additional lateral loads on added 
floors. Deflections of R.C. frames with 5 inch wall thickness having soft storey were observed 1.15 times 
greater than that with 10 inch wall thickness. As the beam and column size increases, deflection pattern 
decreases with increased stiffness. Deflections of R.C. frame using Saneinejad Theory of Equivalent Strut 
Modeling were slightly larger than that by Mainstone Theory. 
 
Key words: Infill; Soft Storey; Equivalent Struts; Saneinejad Theory; Mainstone Theory.  
 
1. INTRODUCTION 
 
Usually in structural analysis only the bare 
reinforced concrete (R.C.) frame is modeled 
ignoring the effect of infills with the assumption 
that such modeling is rather conservative and 
computationally more efficient. However such 
assumption may lead to substantial inaccuracy in 
predicting the lateral stiffness, strength and ductility 
of a structure. When an infill frame is subjected to 
lateral loading, the infills behave effectively as strut 
along its compression diagonals to brace the 
frames. The behavior of masonry infilled frame 
structures has been studied in the last four 
decades in attempts to develop a rational 
approach for design of such frames. Present 
code of practice does not include provision of 
taking into consideration the effect of infill. It 
can be understood that if the effect of infill is 
taken into account in the analysis and design of 
frame, the resulting structures may be 
significantly different. Therefore, a study is 
undertaken which will involve the finite element 
analysis of the behavior of High-Rise R.C. 
frame with brick masonry infill. Again when a 
sudden change in stiffness takes place along 
the building height, the storey at which this 
drastic change of stiffness occurs is called a 
Page 121
ISBN: 978-984-33-2140-4
  
soft storey. A soft storey is the one in which the 
lateral stiffness is less than 70% of that in the 
storey above or less than 80% of the average 
stiffness of the three stores above (BNBC, 
1993). The infill components increase the 
lateral stiffness and serve as a transfer medium 
of horizontal inertia forces. From this 
conception the floors that have no infill 
component has less stiffness regarding other 
floors.  
The major objectives of the research work were as 
follows: 
• To find out the influence of masonry infill 
wall panel in Reinforced Concrete framed 
Structures in terms of deformation. 
• To study the behavior of frame with brick 
masonry infill by modeling masonry infill as a 
diagonal strut. The Finite Element package 
ANSYS 5.6 (Manual of ANSYS 5.6) is to be used 
for the development of the model. 
• The present study was aimed at findings out the 
effects of wall thickness on frame structures due to 
horizontal loading. 
• Two different theories (Mainstone and 
Saneinejad theory) of developing equivalent strut 
model were analyzed in this work and comparisons 
of these models were also made. 
 
2. METHODOLOGY OF THE WORK 
 
Finite element technique is a powerful and 
versatile tool for the analysis of problems of 
structural and continuum mechanics. In this 
study a linear finite element analysis was 
performed using the package ANSYS to predict 
the inelastic behavior of R.C. high-rise frame 
with brick masonry infill. The finite element 
analysis of infilled frames includes modeling of 
beams and columns, modeling of masonry infill, 
calculations of wind and earthquake load 
according to BNBC code, generation of finite 
element mesh with infill.  
 
2.1 Finite Element Discretization 
The ultimate purpose of finite element analysis 
is to predict mathematically the behavior of 
actual engineering system. In complete 
modeling, BEAM44 3-D Elastic Beam element 
was used to represent beams and columns. 
LINK10 3-D spar element was used to model 
masonry infill as a diagonal strut against lateral 
load. This model comprises all nodes, elements, 
material properties, geometrical properties, 
boundary conditions and other features that were 
used to represent the physical system. 2-D 
analysis was performed in this study. Since the 
analysis was based on nonlinear elastic 
material response, it provides the information 
about the nature of stress distribution and 
deformation rather than the ultimate behavior of 
the structure. 
For appropriate modeling of R.C member two 
types of elements, one for concrete and other 
for reinforcement are required and two types of 
material properties are also required for both 
these elements but in this analysis, reinforced 
cement concrete frame was assumed as a 
homogeneous and isotropic material. To model 
the R.C frame, Beam44 3-D elastic beam was 
selected from ANSYS element library. For 
Beam44 3-D elastic beam, reinforced concrete 
properties were used. In R.C high-rise frame, 
in addition to the use as partition walls, the 
infill can also be used for increasing stability and 
reducing displacement against lateral load. To 
model brick masonry infill, it was considered 
masonry infill to be act as a diagonal strut 
against lateral load according to the equivalent 
strut method. Since the tensile strength of 
masonry is negligible, only compression 
diagonal strut is liable to resist the lateral load. 
In this analysis the element LINK10 3-D spar 
was used to represent equivalent diagonal strut.  
First to model the equivalent diagonal strut in 
this study, the width of the equivalent strut was 
calculated by taking into accounts the 
formulations developed by Stamfford-Smith and 
Carter (1969) and Mainstone (1971). Also in 
another method of equivalent strut 
formulation, where the area of diagonal strut 
was found 66450 mm2 by Saneinejad and 
Hobbs (1995) formula. In this study a 10 storied 
building frame was analyzed. The cross section of 
columns and beams were taken 305 mm x 305 
mm. For analysis, 3.0 and 2.0 percent 
reinforcement were considered in columns and 
beams respectively. 
 
3. DATA TABULATION 
 
In modeling Plane frame, the following material 
properties and geometrical properties have been 
used for beam, columns, masonry infill. 
 
3.1 Beam and Columns 
3.1.1 Material properties: The following 
material properties of normal weight concrete 
have been provided for finite element analysis of 
building frames: 
• Density, wc = 8.68e-2 lb/in3 
• Compressive strength, fc = 4000 psi 
Page 122
  
• Young’s modulus of elasticity, Ec = 3e6 psi 
• Poisson's ratio, vc  = 0.15 
 
3.1.2 Geometrical properties: The following 
sectional properties have been used for beams and 
columns: 
Column:  Cross-section = 12 in x 12 in 
Beam:  Cross-section = 12 in x 12 in 
 
3.2 Masonry infill: 
3.2.1 Material properties: The following 
material properties have been used for masonry 
infill: 
• Density, wc = 6.94e-2 lb/in3 
• Compressive strength, fc = 1740 psi 
• Young's modulus of elasticity, Ec = 1.2e6 
psi 
• Poisson's ratio, vc  = 0.16 
 
3.2.2 Geometrical properties: Thickness of infill 
= 5 in 
 
3.3 Loads 
In the present investigation, wind load and 
earthquake load has been chosen as the source 
of lateral loading on the building frame as set 
forth by the provision of Bangladesh National 
Building Code (BNBC, 1993). A 10-storied 
building has been selected to carry out this 
study. Fig. 1 shows the plan of the building. 
The structure is 48ft x 36ft in plan dimension 
and per floor storey height of the building has 
considered as 10ft. Loads are shown in Fig. 2 and 
Fig. 3. 
 
 
 
Fig. 1: Plan of the building 
 
 
 
 (a)   (b)           
Fig. 2: Elevation of 10-story building frame 
(F2) with calculated wind load at each floor level 
(a) without soft story effect, (b) with soft story 
effect (Loads are in kips) 
 
 
 
(a)    (b)                                  
Fig. 3: Elevation of 10-story building frame (F2) 
with calculated earthquake load at each floor 
level (a) without soft story effect, (b) with soft 
story effect (Loads are in kips) 
 
4. RESULTS AND DISCUSSIONS 
 
The main objective of this investigation is to study 
the effect of horizontal loading on reinforced 
concrete frame with brick masonry infill for soft 
storey conditions. In this analysis the frame was 
assumed to be restrained at ground floor level. 
Deflections are one of the most important 
parameter to be considered in the design and 
analysis of a tall building. Therefore deflections for 
lateral loads (wind and earthquake loads) was 
studied according to Mainstone theory of 
equivalent strut method for different cases and 
Page 123
  
comparisons were also made. The different cases 
are: deflections for various no. of bay, deflections 
for variable storey frame and deflections for various 
spans of bay. In this study comparison of 
deflections of a 10-storey 3-bay building frame for 
different geometrical properties of beams, columns 
and infill walls were made. Also deflections were 
measured for two different theories of equivalent 
strut method (Mainstone theory and Saneinejad 
theory) and comparisons were also made. 
 
4.1 Effect of Number of Bay 
By using a 10-storey building frame of 12 ft bay 
length analysis was done for both wind and 
earthquake loads. Comparisons of deflections of the 
frame for different soft storey conditions and for 
different no. of bay have been graphically shown in 
Fig. 4. Due to the incorporation of soft storey at 
ground floor, the top deflections of a 10-storey 
building frame turned into 1.6 to 1.8 times than the 
usual deflections having no soft storey in case of 
lateral loads. Also the top deflections became 2.2 to 
2.4 times higher as no. of bay reduces from 8 to 4. 
Because for different no. of bay parallel to wind 
direction, the wind load at every storey level 
remains same but as the no. of bay increases, the 
stiffness of the frame for resisting this load 
increases. As a result, the maximum top deflection 
of the frame decreases as no. of bay increases in 
case of wind load. But for earthquake loading, as 
no. of bay increases both the load and stiffness 
increases; and the rate of increase of stiffness is 
higher than that of load. As a result, similar bar 
chart for the maximum top deflection of the frame 
was found for earthquake loading. 
 
 
Fig. 4: Maximum top deflection of R.C. frame due 
to lateral loads for various no. of bay parallel to 
load direction 
 
4.2 Effect of Number of Storey  
By using a 3-bay building frame of 12 ft bay length 
analysis was done for both wind and earthquake 
loads. Comparisons of deflections of the frame for 
different soft storey conditions and for different no. 
of storey have been graphically shown in Fig. 5. 
Due to the incorporation of soft storey at ground 
floor, the top deflections of the R.C. frame turn into 
1.4 to 2.0 times than the usual deflections having no 
soft storey in case of lateral loads. Also the top 
deflections became 3.2 to 4.4 times higher as no. of 
storey increases from 6 to 10. As the no. of storey 
level increases, there are additional lateral loads 
added for increased storey level. As a result, the 
maximum top deflection of the frame amplifies 
rapidly with increased storey level.  
 
 
Fig. 5: Maximum top deflection of R.C. frame due 
to lateral loads for various no. of storey 
 
4.3 Effect of Various Geometrical 
Properties of Infill Wall 
By using a 10-story 3-bay building frame having 
span of bay 12 ft, analysis was done for both wind 
and earthquake loads and according to Mainstone 
theory of equivalent strut method. Comparisons of 
deflections of the frame for different soft story 
conditions and for different thickness of infill have 
been graphically shown in Fig. 6. Due to the 
incorporation of soft storey, the top deflections of a 
10-storey building frame turn into 1.4 to 1.7 times 
than the usual deflections having no soft storey in 
case of lateral loads. Deflections decrease 10 to 
20% for 10 inch wall thickness than that for 5 inch 
wall thickness.  
 
 
Fig. 6: Maximum top deflection of R.C. frame due 
to lateral loads for various wall thicknesses 
Page 124
  
4.4 Effect of Various Geometrical 
Properties of Beams and Columns 
By using a 10-story 3-bay building frame having 
span of bay 12 ft, analysis was done for both wind 
and earthquake loads. Comparisons of deflections 
of the frame for different soft story conditions and 
for different geometrical properties of beams and 
columns have been graphically shown in Fig. 7. 
With 10 square inch beam and column section, the 
top deflections of a 10-storey building frame 
become 1.7 times for soft storey than the usual 
deflections having no soft storey. But this variation 
reduced to 1.2 times with 16 square inch beam and 
column section due to the stiffer section used in the 
R.C. frame structure. Also with the increasing 
cross-section of beams and columns the deflections 
were also decrease because of increased stiffness of 
the resisting frame.  
 
 
Fig. 7: Maximum top deflection of R.C. frame due 
to lateral loads for various beam and column sizes 
 
4.5 Comparison of Deflections for Two 
Different Theories of Equivalent Strut 
Method 
In this analysis, a 10-story of 3@20 ft bay span 
building frame was used. In this case, two different 
theories of equivalent strut method that is 
Mainstone theory and Saneinejad theory were 
applied. Comparison of deflections of the frame for 
different conditions (without soft story effect/ with 
soft story effect) and for different theories has been 
graphically shown in Fig. 8. The maximum top 
deflections of the frame for these two different 
methods were quite similar.  
 
Fig. 8: Maximum top deflection of R.C. frame due 
to lateral loads for different theories of equivalent 
strut method 
 
5. CONCLUTIONS  
 
The following conclusions may be drawn from the 
current investigation: 
• Deflections for a soft story building frame 
were as much as 1.2~2.0 times greater than 
that observed excluding the soft story effect. 
The lower range was for stiffer frame 
structures. So the effect of soft story was more 
significant in case of less rigid R.C. frames. 
• In both cases of wind and earthquake loads, if 
number of bay increases, then the deflection 
eventually decreases. 
• As the story level of a building frame 
increases, deflection due to lateral loads 
naturally increases due to additional lateral 
loads. 
• Deflections of R.C. frames with 5 inch wall 
thickness having soft storey were observed 
1.15 times greater than that with 10 inch wall 
thickness.  
• As the beam and column cross sectional area 
was increased by 2.54 times, maximum 
deflection of the frame reduced to 3.1 times 
with amplified stiffness of the frame. 
• Deflection for Saneinejad Theory of 
Equivalent Strut Method is slightly larger than 
that for Mainstone Theory. So, the two 
different theories of Equivalent Strut Method 
have little bearing on the variations of results. 
 
REFERENCES 
 
1. BNBC, (1993), “Bangladesh National 
Building Code”, Housing and Building 
Research Institute and Bangladesh Standards 
and Testing Institutions, Dhaka. 
2. Mainstone, R. J. (1971), “On the Stiffness and 
Strengths of Infilled Frames” Proceeding of 
Page 125
  
the Institute of Civil Engineers, Supplement 
IV, 57–90. 
3. Manual of ANSYS 5.6 (1997), Elan Computer 
Group, Inc., USA. 
4. Saneinejad, A. and Hobbs, B. (1995), 
“Inelastic Design of Infilled Frame”, American 
Society of Civil Engineers, (ASCE), Journal of 
Structural Engineering, Vol.121, No.4, pp 634-
643. 
5. Smith, B. S. and Carter, C. (1969), “A Method 
of Analysis for Infilled Frame”, Proceeding of 
the Institute of Civil Engineers 44, Paper No. 
7218, 31–48. 
Page 126
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
1
 Corresponding Author: Ishtiaque Ahmed Tuhin 
E-mail: iatuhin@yahoo.com 
EFFECT OF FINNESS MODULUS OF SAND ON CONCRERTE 
PROPERTIES 
 
Ishtiaque Ahmed Tuhin1, A.S.M.Z. Hasan2 and M. Bashirul Haque3 
 
1
 Lecturer, Department of Civil Engineering, World University of Bangladesh, Dhaka-1205, 
Bangladesh, 2 Lecturer, Department of Civil Engineering, Rajshahi University of Engineering & 
Technology, Bangladesh, 3Lecturer, Department of Civil Engineering, Shahajalal University of 
Science and Technology, Sylhet, Bangladesh 
 
 
The size of aggregates particularly grading is one of the important parameters that affect relative proportions 
in a concrete mix for strength, workability, economy, porosity and shrinkage etc. The main objective of this 
study is to evaluate the effect of fineness modulus (FM) of sand on concrete strength. A series of tests with 
cylindrical specimens were carried out for different FM of sand to investigate the variation of concrete 
compressive strength and other relevant properties of normal weight concrete. Cconcrete has its own 
strength composition according to FM of sand. When these relations are combined, the ultimate strength of 
concrete has great effect due to change of FM of sand. The results indicate that every 10% increase in FM of 
sand from 2.0 to 2.8, compressive strength increases almost from 2% to 8%. The rate of increase of concrete 
strength is faster towards coarser side for FM of sand equivalent to 2.5 or more. The effect of other 
properties such as density, unit weight, modulus of elasticity on concrete properties also reported herein with 
the different FM of sand.  
 
Key words: compressive strength, fineness modulus, workability, modulus of elasticity and density of 
concrete 
 
1. INTRODUCTION 
 
Fineness Modulus is a term used as an index to the 
fineness or coarseness of aggregate. This is the 
summation of cumulative percentage of materials 
retained on the standard sieves divided by 100. It is 
well–known that aggregate plays an important role 
in achieving the desired properties of concrete. 
Though, aggregate constitute 80 to 90% of the total 
volume of concrete, yet very little attention is given 
in controlling the grading and surface texture of 
aggregate to optimize the properties of concrete. 
Improper blend of aggregate influences the cement 
and water demand for a given concrete mix and 
affects workability, compactibility, and cohesion 
characteristics of concrete mix. It also influences 
the compressive strength, flexural strength and 
other properties like permeability & durability of 
concrete.  
 
In general, the grading of aggregates, which do not 
have a deficiency or excess of any size of aggregate 
and give a smooth grading curve, produce the most 
suitable concrete mix. The coarser fine aggregate 
has a smaller surface area and will not compete 
with  the finer binding constituents of concrete, 
such as cement, fly ash  and blast furnace slab, to 
consume water during the hydration stage. 
Meanwhile, it is unanimously understood that fine 
aggregate with a higher fineness modulus is 
beneficial to the workability and strength of 
concrete. 
 
Compressive strength remains the most important 
property of structural concrete, from an engineering 
point of view. The relationship between concrete 
composition and compressive strength has long 
been a matter of interest for researchers. The 
quality and durability of concrete mostly depend on 
the quality and properties of ingredients. Fine 
aggregate affects many concrete properties, 
including workability and finishability. Experience 
has shown that very coarse sand or very fine sand 
produces poor concrete mixes. Coarse sand results 
in harsh concrete mixes prone to bleeding and 
segregation. Fine sand requires a comparatively 
large amount of water to achieve the desired 
concrete workability, is prone to segregation, and 
may require higher cement contents. The 
decreasing FM for sand used in mortar requires 
considerably more cement content when the water-
cement ratio and slump are held constant. However, 
Page 127
ISBN: 978-984-33-2140-4
  
a changing FM has little influence on the cement 
content required in concrete.  Generally, a lower 
FM results in more paste making concrete easier to 
finish. For the high cement contents used in the 
production of high-strength concrete, coarse sand 
with an FM around 3.0 produces concrete with the 
best workability and highest compressive strength. 
In general, manufactured sands require more fines 
than natural sands for equal workability. 
 
Some studies are carried in the literature. Ta-Peng 
Chang, etl. (2001) considered the effect of various 
fineness moduli (FM) of fine aggregate on the 
engineering properties of high – performance 
concrete were studied. Two kinds of coarse 
aggregate and three kinds of fine aggregate were 
used to evaluate the engineering properties of 
concrete. This studies showed that for the same 
concrete mixture, the coarsest fine aggregate 
(FM=3.24) has better positive effects on the 
properties of the fresh and hardened HPC. Kronlof 
(1994) considered the effect of fine aggregate, 
which consists of 63.3% by weight of 0.5 - 6.0 mm 
aggregate particles and 36.7% of 0.0001- 0. 5 mm 
quartz powders, on the water requirement and 
strength evolution of the superplasticized concrete. 
The water requirement for constant workability fell 
sharply with the increasing amount and fineness of 
the very fine aggregate, and the concrete strength 
increased with the increase of quartz powders. 
Ahmed and El Kourd (1989) reported that water 
demand increased rapidly with increase of the very 
fine sand (VFS), which denoted the sand passing a 
No. 200 (75 µm) sieve. But the compressive 
strength of concrete also decreased linearly with the 
increase of VFS at a constant slump of 100 mm. 
 
The present study reports primarily to evaluate the 
effect of concrete compressive for same concrete 
mix using various graded sand as fine aggregate. 
The other properties such as, density, unit weight, 
modulus of elasticity also affects on concrete 
properties due to change of Fineness Modulus of 
sand.  
 
2. REVIEW OF CODE PROVIIONS 
 
ASTM Designation: C33-93- standard specification 
for concrete aggregates”–The fine aggregate shall 
have not more than 45% passing any sieve and 
retained on the next consecutive sieve and its 
fineness modulus will not be less than 2.3 and not 
more than 3.1. Rest is the same as for AASTHO 
M6-93.  
 
U.S.B.R: The code has specified that the fineness 
modulus of sand shall not be less than 2.50 and not 
more 3.0. 
AASTHO Designation: M6-93- “Standard 
Specification for Fine Aggregate For Portland 
Cement Concrete”- It indicates that the fineness 
modulus of sand will not be less than 2.3 and nor 
more than 3.1.  
 
IS 383: “Specifications for Coarse and Fine 
Aggregates from Natural Sources for Concrete.” 
This publication deals with specifications for 
Coarse and Fine aggregates from natural sources 
for Concrete. These specifications do not specify 
any limit for fineness modulus to be used in 
concrete. It divides the sand in four zones i.e. from 
Zone I to Zone IV. Zone I–Sand being very coarse 
and Zone 4 sand is very fine. It is generally 
recommended by code to use sands of zones I to 
Zone III for Structural concrete works.  
 
3. EXPERIMENTAL DETAILS 
 
3.1 Materials and mix proportions 
 
The natural stone were used as coarse aggregate. 
Three different types of natural sand (Two types 
obtained from Sylhet and one type of locally 
available river sand) were used to prepare various 
type of fineness modulus of sand (range of FM 1.2 
– 2.8) in this experiment. Ordinary Portland cement 
(ASTM Type-l) was used as binder in experiment. 
The required material properties, such as specific 
gravity (ASTM C127 and ASTM C128), unit 
weight (ASTM C29), fineness modulus of coarse 
and fine aggregate (ASTM C136) were used to 
design the concrete mix. These properties of the 
coarse and fine aggregates are summarized in Table 
1.1 and 1.2 
 
Table 1.1: Physical characteristics of coarse 
aggregates 
 
Property Stone (¾ in down grade) 
Specific gravity (SSD) 2.63 
Absorption capacity, % 5% 
Unit weight, lb/ft3 98 
Fineness modulus 5.69 
 
 
Table 1.2: Physical characteristics of Sand 
 
Property 
Sand Type 
I II III 
Specific gravity (SSD) 2.47 2.65 2.67 
Absorption capacity, % 2.7 2.8% 3.1% 
Unit weight, lb/ft3 83 90 93 
Fineness modulus 1.20 2.70 2.80 
Page 128
  
 
3.2 Preparation of Cylinder Specimens 
 
Based on predefined mix proportions (weight 
basis), the required quantities of the materials were 
calculated and measured on SSD condition. The 
coarse aggregate, fine aggregate and cement were 
then spread evenly on the mixing surface, mixed 
thoroughly and continuously and water was 
gradually added. At the time of mixing uniform 
quality of concrete were maintained until to prepare 
proper mix. Then, the slump of the every mix 
proportion was measured according to the standard 
method (ASTM C31). This concrete was poured in 
reusable cylindrical moulds (size 6" X 12") and 
compacted properly conforming the ASTM 
procedure.  
 
3.3 Curing and Testing of Cylinder 
 
After casting of concrete, the cylinders were stored 
in moulds for 24 hours in moist condition at room 
temperature and the moulds were carefully 
removed. Then the concrete cylinders were sunk in 
the potable water for 28 days. All the cylinders 
were tested in wet condition at 28 days to determine 
the concrete compressive strength. The top surfaces 
of the cylinders were capped with sulphur mortar in 
accordance with standard specification (ASTM 
C617) before testing.  
 
4. EXPERIMENTAL RESULT 
 
In this study water-cement ratio (W/C) of mix is 
kept constant for all mixes with sand of different 
fineness modulus. Workability of mix is also fixed 
in range of 1.5 inch to 2.5 inch slump. Since mix 
with so different fineness modulus of sand, will 
result in different water demands, so water - cement 
ratio is kept constant and to adjust workability 
slight adjustments in admixture dosages has been 
made. Effect of varying FM of sand is studied on 
concrete density, workability, compressive strength, 
and modulus elasticity of concrete 
 
4.1 Workability of Concrete Mix 
 
The workability of concrete mix was measured with 
the help of 12 inch standard size slump cone. A 
little amount of admixture dose was added to 
concrete mix. Each time concrete mix was 
examined for the behavior in slump, segregation 
and Bleeding etc. Total 18 cylinders were prepared 
to observe slump, segregation and bleeding etc. The 
slump observed was about 2 inch in all cases. No 
segregation or bleeding was observed in the mix. 
The results indicate that with the increase in 
fineness modulus of sand, water demand in the mix 
got affected consequently workability gets affected. 
Since water-cement ratio is kept constant, so to 
keep workability in the same range of 2 inch, 
admixture dosages were varied. The admixture 
dosages reduced considerably as fineness of sand 
increases as. Admixture dosage reduced from 1.0 
percent to 0.2 percent as sand fineness modulus 
increases from 1.2 to 2.8. For Every 5% increase in 
FM of sand, admixture dosage reduced by 0.1%. 
 
4.2 Effect of Fineness of Sand on Density of 
Concrete   
 
After measuring the slump, several 150 mm 
cylinders were filled. These were cured in water 
tank for 28 days. After curing, each cylinder was 
weighed using electronic balance and density of 
concrete was calculated. The variation of density, 
unit weight and slump range with FM of sand is 
shown below for different cases. Since water 
cement fixed, Slumps (range 2-3) were varied due 
to change of fineness modulus of sand. It is evident 
that there is slight increase in density i.e. 1.0 to 2.15 
percent, when fineness modulus increases from 1.2 
to 2.8. According to ACI code requirements, the 
range of normal concrete weight is 90 pcf to 155 
pcf. It is also shown that the range of unit weight of 
concrete is about 142 pcf – 147 pcf. 
 
4.3 Effect of Fineness of Sand on 
Compressive Strength of Concrete   
 
The effect of fineness modulus (FM) of sand on the 
compressive strength of concrete measured at 28 –
days on is shown in Fig 1. From this figure it is 
shown that the compressive strength of concrete is 
increased drastically with the increase of fineness 
modulus of sand. A regression analysis shows the 
following relationship between concrete 
compressive strength and fineness modulus of 
sand- 
 
f'c    =   1128 (FM)2 – 280 (FM) + 5093  
R2  =    0.9841 
 
Where  
f'c = concrete compressive strength at 28 days in psi 
FM = fineness modulus of sand  
 
The experimental investigation indicates that- 
As fineness modulus of sand changes from 1.2 to 
1.8 there is an increase in compressive strength 
from 3236psi to 3743. i.e. strength increases by 
15.7%, Fineness Modulus from 1.8 to 2.4, 
Compressive strength increases from 3743psi to 
4742 resulting in 26.7% increase in strength. On the 
other hand by increasing Fineness Modulus from 
2.4 to 2.8, Compressive strength increases from 
Page 129
  
4742psi to 6380 resulting in 34.5% increase in 
strength. For 10% increase in FM of sand from 2.0 
to 2.8, compressive strength increases almost from 
2% to 8%. The rate of increase of concrete 
compressive strength is faster towards coarser side 
of sand. 
 
f'c  = 1128(FM )2 - 2805(FM) + 5093
2500
3000
3500
4000
4500
5000
5500
6000
6500
7000
1 1.5 2 2.5 3
FM of Sand 
C
o
m
pr
es
siv
e 
St
re
n
gt
h,
 
f'c
 
(p
si)
`
 
 
Fig.1: Relation between concrete compressive 
strength and Fineness Modulus of Sand 
 
 
4.4 Modulus Elasticity of Concrete 
 
There is no doubt that the modulus of elasticity 
increases with an increase in the compressive 
strength of concrete, but there is no agreement on 
the precise form of the relationship. This is not 
surprising, given the fact that the modulus of 
elasticity of concrete is affected by the modulus of 
elasticity of the aggregate and by the volumetric 
proportion of aggregate in the concrete. The former 
is rarely known so that some expressions, for 
example that of ACI 318-95 allow for the modulus 
of elasticity of aggregate by a coefficient which is a 
function of the density of the concrete, usually 
density raised to power 1.5. The figure 2 shows the 
relationship between concrete compressive 
strength, modulus elasticity of concrete and 
fineness modulus of sand. A regression analysis 
shows the following relationship between modulus 
elasticity of concrete and fineness modulus of sand- 
 
Ec = 0.55(FM)2 – 1.38 (FM) + 4.11 
 
Where 
Ec = Modulus Elasticity of Concrete in 106 psi 
FM = fineness modulus of sand  
 
The observed result shows that the static modulus 
of elasticity of concrete has great influence due to 
change of Fineness Modulus of sand on concrete 
compressive strength. As Fineness Modulus of sand 
changes from 1.2 to 1.8 the static modulus of 
elasticity of concrete is increase by 8.2%. Fineness 
Modulus of sand changes from 1.8 to 2.8 the static 
modulus of elasticity of concrete is increase by 
35.2% according to ACI 318-19 
 
Ec = 0.55(FM)2 - 1.38(FM) + 4.11
f'c  = 1128(FM)2 - 2805(FM) + 5093
2
3
4
5
6
7
1 1.5 2 2.5 3
FM of Sand
C
o
m
pr
es
siv
e 
St
re
n
gt
h,
f'c
(k
si)
2
3
4
5
M
o
du
lu
s 
o
f E
la
st
ic
ity
, 
Ec
 
(1
0
6 
 
ps
i)
 
 
Fig.2: Relation between concrete compressive 
strength and Modulus of elasticity with respect to 
Fineness Modulus of Sand 
 
 
4.5 Effect of Sand – Cement Ration on 
Concrete Compressive Strength 
 
Stock et al (1979) published a comprehensive 
review concerning the effect of aggregate volume 
on concrete compressive strength. Most of the cited 
references tend to support the fact that the strength 
decreases when the paste content increases, at least 
in the range of usual structural concrete. Stock et al 
(1979) also performed some original experiments, 
in which they produce a series of concretes having 
different aggregate contents, keeping the same 
grading and matrix and avoiding segregation in 
fluid mixtures by continuously rotating the 
specimens before setting. Note that the aggregate 
volume effect, which is not monotonic, can be 
marked by the increase of entrapped air when 
workability decreases. The obtained result showed 
that lower compressive strength for higher content 
of coarse aggregate - cement ratio in Figure 3. The 
relation between compressive strength and other 
properties of concrete i.e. water – cement ratio, 
aggregate size, aggregate volume, and cement paste 
are observed graphically nearly exponential shape. 
The experimental result showed same behavior like 
as effect of aggregate – cement ratio. The total 
surface area is greater, more mixing water is 
required to produce the desired slump, and for 
given cement contents, the water cement ratio is 
higher for the higher sand content mix of concrete. 
Generally, compressive strength is lower for higher 
water – cement ratio. As sand – cement ratio 
Page 130
  
changes from 0.5 to 2.0 there is decrease in 
compressive strength from 4850psi to 3900. i.e. 
strength increases by 19.6%. Sand – cement ratio 
changes from 2.0 to 4.5 there is decrease in 
compressive strength from 3900psi to 1700. i.e. 
strength increases by 54.6% for fixed fineness 
modulus of sand . 
 
 
f'c = 107(CA/c)3 - 797(CA/c)2 + 751(CA/c) + 5231
1000
2500
4000
5500
7000
0 1 2 3 4 5
Sand/Cement Ratio
C
o
m
pr
es
siv
e 
St
re
n
gt
h,
 
f'c
 
(p
si)
 
 
Fig.3: Relation between concrete compressive 
strength and Sand – cement ratio (coarse aggregate 
– cement ratio is 2 and FM of Sand 2.60)  
 
5. CONCLUSION 
 
Fineness Modulus of Sand affects Compressive as 
well as the other engineering properties of concrete. 
Sand, with higher FM, results in higher strength of 
concrete. The results indicate that with the increase 
in FM, workability gets affected considerably. The 
cement demand also gets modified. Some of the 
concluding observations are given below-  
 
 Fineness Modulus has larger impact on 28 days 
Compressive Strength of Concrete. For every 
10% increase in FM of sand from 2.0 to 2.8, 
compressive strength increases almost from 2% 
to 8% and the rate of increase of concrete 
compressive strength is faster towards coarser 
side of sand. 
 
 Fineness Modulus also affects the density of 
concrete. It increases by about 2.15% as the 
FM increases from 2.0 to 2.8. Optimum value 
of density and other parameters are obtained 
when FM is 2.7. 
 
 The observed result also shows that the static 
modulus of elasticity of concrete has great 
influence due to change of Fineness Modulus 
of sand on concrete compressive strength. As 
Fineness Modulus of sand changes from 1.2 to 
2.8 the static modulus of elasticity of concrete 
is increase by 35.2% according to ACI 318-19 
 The optimum value of strength can be taken 
when workability of concrete is also good. It is 
obtained when Fineness Modulus is about 2.7. 
 
 The sand – cement ration has great impact on 
concrete compressive strength. As sand – 
cement ratio changes from 0.5 to 4.5 there is 
decrease in compressive strength from 4850psi 
to 3900. i.e. strength increases by 54.6%  
 
 
5. REFERENCES  
 
1. AASHTO Designation: M6 – 93, ‘Standard 
Specification for Fine Aggregate for Portland 
Cement Concrete.  
2. ACI 318R-99 (1999), “Building code 
requirements for reinforced concrete and 
commentary”, ACI Committee 318, American 
Concrete Institute, Farmington Hills, 
Michigan, pp.391.  
3. ACI Committee 211.1-91 (1994), “Standard 
Practice for Selecting Proportions for Normal, 
heavyweight and Mass Concrete”, Part 1, ACI 
Manual of Concrete practices.  
4. Ahmed, A. E., and EI - Kourd, A. A., 1989, 
“Properties of Concrete Incorporating Natural 
Crushed Stone and Very Fine Sand,” ACI 
Materials Journal, Vol. 86, No. 4, pp. 417 – 
424 
5. ASTM Designation: C33 – 93, Standard 
Specification for Concrete Aggregates. 
6. BS 8110 (1985), “Structural Use of Concrete: 
Code of Practice for design and Construction”, 
Part 1.  
7. Kronlof, A., 1994, “ Effect of Very Fine 
Aggregate on Concrete Strength,”, Materials 
and structures, No. 27, pp. 15-25 
8. IS: 383-1970, “Specifications for coarse and 
fine aggregate from natural sources for 
concrete”, BIS, New Delhi.  
9. Neville E, A.M, “Properties of concrete”, IV 
edition, Pearson Education Pvt. Ltd. 2005. 
10. Stock, A. F.; Hannant, D. J.; and Williams, R. 
I. T., “The Effect of Aggregate Concentration 
upon the Strength and Modulus of Elasticity of 
Concrete,” Magazine of Concrete Research, V. 
31, No. 109, 1979, pp. 225-234. 
11. Ta-Peng Chang, Shi – Hong Lin, Huang – 
Chin, Ping –Ru Lin, 2001, “ Effect of Various 
fineness modulus of fine aggregate on 
engineering properties of high- performance 
concrete.”, Journal of the Chinese Institute of 
Engineers, Vol. 24, No. 3, pp. 289 – 300 
(2001) 
 
 
Page 131
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
*Corresponding Author: M.B. Haque,  
E mail: bashir-cee@sust.edu, 
 
EFFECT OF AGGREGATE GRADING ON CONCRETE 
COMPRESSIVE STRENGTH 
 
M.B. Haque*  
Shahjalal University of Science and Technology, Sylhet 
 
I. A. Tuhin, M.S.S. Farid 
World University of Bangladesh, Dhaka  
 
 
Compressive strength is the major properties of concrete which depends on mainly aggregate size, shape, 
grading, mix ratio, presence of admixture etc. In this research work, effect of aggregate fineness modulus 
(both fine and coarse) and maximum coarse aggregate size on the compressive strength of aggregate has 
been studied. Others variable like water cement ratio, aggregate cement ratios were kept constant and only 
28 days compressive strength was measured to evaluate the result. Mixture of Sylhet sand and local sand 
was used as fine aggregate to get desired fineness modulus and stone chips were used as coarse aggregate. 
Twelve set of cylinders were crushed in this study with different combination of fine aggregate having 
fineness modulus of 2.0, 2.5 and 3.0 and coarse aggregate having fineness modulus of 6.0, 6.5, 7.0 and7.5. 
Maximum size of coarse aggregate was 1.5 inch. From this study it is observed that compressive strength of 
concrete increases with the increase of both the fine and coarse aggregate fineness modulus. Maximum 
compressive strength was found 3873 psi for concrete having fineness modulus of fine and coarse aggregate 
3.0 and 7.5 respectively with mix ratio 1:2:4. Compressive strength of concrete increases up to the maximum 
aggregate size of 1.5 inch. It is also found that compressive strength has no linear relationship with the 
combine fineness modulus of aggregate. 
 
Key Words: Grading, Fineness Modulus, Aggregate, Compressive Strength, Mix Ratio 
 
1. INTRODUCTION 
 
Compressive strength is the main qualitative 
measure of concrete. The 28 days strength is the 
most common practices employed to determine the 
concrete compressive strength. To ensure the 
strength of hardened concrete testing of 6 in × 12 in 
cylinder is the normal practices since long. It has 
been generally accepted that if the aggregate 
volumes are so chosen that the packing density of 
the combined aggregates is maximum then the 
amount of cementations paste volume required for a 
given amount of workability (i.e. slump) is reduced 
to a minimum. Maximum aggregate packing 
density can be achieved using the well graded 
aggregate 
 
Grading of aggregate means particle size 
distribution of the aggregate Principle of grading is 
that the smaller size particles fill up the voids left in 
larger size particles. By adopting proper 
percentages, of various size aggregates, composite 
aggregate mix can be developed which will be 
thoroughly graded. Properly graded aggregate  
 
produces dense concrete and needs smaller 
quantities of fine aggregate and cement. The 
grading of aggregate is expressed in terms of 
percentages by weight retained on a series of 
sieves, 40 mm,20mm, 10 mm, 4.75 mm ,2.36mm 
coarse are used for grading of coarse aggregate, 
where as 10 mm, 4.75 mm, 2.36 mm, 1.18 mm, 600 
micro, 300 micro, and 150 micro are used for 
aggregate. 
 
2 OBJECTIVES OF THE STUDY:  
 
i) To evaluate the change of concrete compressive 
strength due to changing of aggregate grading. 
ii) To evaluate the response of concrete 
compressive strength due to changing of coarse 
aggregate maximum size. 
iii) To evaluate the change of concrete compressive 
strength due to changing of aggregate combine 
fineness modulus. 
 
 
 
Page 132
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
  
3. PROPERTIES OF CONCRETE 
INGREDIENTS 
 
The ingredients of concrete mix was cement, fine 
aggregate, coarse aggregate and water. No 
admixture was used for this study. 
 
Cement is a binder, a substance which sets and 
hardens independently and can bind other materials 
together. Ordinary Portland cement was used as 
binder materials for the preparation of fresh 
concrete.  
 
The aggregate most of which passes through No. 
4(4.75 mm) sieve is classified as fine aggregate. 
Fine aggregate used in this study is prepared 
artificially to obtain predefine fineness modulus 
and grading. The fine aggregate is washed with 
water and dried in air before use. At the beginning 
of the use of the aggregate, their properties were 
measured in laboratory. Three different samples 
were prepared with fineness modulus 2.0, 2.5 and 
3.0.  
 
The objective of determining the fineness modulus 
was to plot there grading curves, and to use 
assigned combined grading limits to determine the 
amount of each of the aggregate of produce quality 
concrete. Gradations of three samples are given in 
the Table 1. Gradation curve of each sample are 
shown in Fig 1 to 3 and compared with the standard 
gradation curve.  Gradation of sample having 
fineness modulus 2.0 and 3.0 slightly deviated from 
the standard gradation zone. 
 
Table: 1 Gradation of fine aggregate. 
Sieve size Cumulative percent passing 
FM=2.0 FM=2.5 FM=3.0 
#4 100 98 95 
#8 95 92 88 
#16 90 80 75 
#30 75 60 42 
#50 40 20 0 
#100 0 0 0 
 
The aggregate usually occupies about 70 to 75 
percent of the total volume of the mass of concrete, 
in which the coarse aggregate takes the major part. 
As such its selection and proportioning should be 
given carefully attention in order to control the 
quality of the concrete structures.  
 
Different size coarse aggregate was used in this 
study. 1.5 in downgrade, 0.75 in downgrade and 0.5 
in downgrade aggregate was used in this study with 
fineness modulus of 6.0, 6.5, 7.0 and 7.5. Properties 
of these aggregate were determined in the 
laboratory. 
 
Fig 1: Gradation Curve of Sample having FM-2.0 
 
 
Fig 2: Gradation Curve of Sample having FM-2.5 
 
 
Fig 3: Gradation Curve of Sample having FM-3.0 
 
The maximum size of coarse aggregate depends 
upon the nature of work for which the concrete is 
used. From a stand point of minimum void space 
round aggregate are more desirable that irregular. 
0
20
40
60
80
100
0.1 1 10
Pe
rc
en
t p
as
sin
g
Sieve opening (mm)
Sample grading
Lower boundary
Upper boundary
0
20
40
60
80
100
0.1 1 10
Pe
rc
en
t p
as
sin
g
Sieve opening (mm)
Sample grading
Lower boundary
Upper boundary
0
20
40
60
80
100
0.1 1 10
Pe
rc
en
t p
as
sin
g
Sieve opening (mm)
Sample grading
Lower boundary
Upper boundary
Page 133
  
From the stand point of ability to bond with the 
mortar, the rounded aggregate may be inferior, 
however so that in general the shape of the particles 
will be found to be much less important that their 
size and hardness. Thin flat pieces should be 
discarded. 
 
Sample aggregate were prepared artificially to 
obtain the predefine grading. Gradation of these 
samples were given in the Table 2 and 
corresponding gradation curve is given in Figure 4 
to 7 
 
Table: 2 Gradation of coarse aggregate 
Sieve 
size  
                   Cumulative percent passing 
1.5 in 
down 
grade 
1.5 in 
down 
grade 
3/4 in 
down 
grade 
1/2 in 
down 
grade 
FM=7.5 FM=7.0 FM=6.5 FM=6.0 
1.5" 95 100 100 100 
0.75" 40 70 95 100 
3/8" 15 30 50 80 
3/16" 0 0 5 20 
#8 0 0 0 0 
 
 
Fig: 4 Gradation Curve of Sample having FM-6.0 
 
Fig: 5 Gradation Curve of Sample having FM-6.5 
 
Fig: 6 Gradation Curve of Sample having FM-7.0 
 
 
 
Fig: 7 Gradation Curve of Sample having FM-6.0 
 
4 PREPARATION OF CONCRETE 
CYLINDER 
 
Twelve set of Cylinder were cast with different 
grading of aggregate. Water cement ratio was same 
for all the concrete which was 0.5. Cement, sand, 
aggregate ratio was also uniform with ratio of 1:2:4. 
At beginning, aggregate of predefined fineness 
modulus was prepared by sieving of raw aggregate. 
To prepare specific concrete mix, aggregate with 
corresponding fineness modulus was taken then 
concrete mixture was prepared with ratio 1:2:4. All 
mixture was conducted on weight basis. Mixing of 
concrete was done by hand.  
 
5. RESULTS AND DISCUSSION 
 
28 days compressive strength was evaluated in this 
study due to different aggregate grading. 
Laboratory test results were examined and 
explained in both tabular form and graphically 
which is shown below 
 
0
20
40
60
80
100
1 10 100
Pe
rc
en
t p
as
sin
g
Sieve opening (mm)
Sample grading
Lower boundary
Upper boundary
0
20
40
60
80
100
120
1 10 100
Pe
rc
en
t p
as
sin
g
Sieve opening (mm)
Sample grading
Lower boundary
Upper boundary
0
20
40
60
80
100
1 10 100
Pe
rc
en
t p
as
sin
g
Sieve opening (mm)
Sample grading
Lower boundary
Upper boundary
0
20
40
60
80
100
1 10 100
Pe
rc
en
t p
as
sin
g
Sieve opening (mm)
Sample grading
Lower boundary
Upper boundary
Page 134
  
Higher fineness modulus of aggregate represents 
higher aggregate size. Compressive strength of 
aggregate is closely related with the aggregate 
grading as well as size also. Generally concrete 
compressive strength increases with the increase of 
aggregate fineness modulus size of aggregate. If 
aggregate size of concrete increases with reducing 
surface area then quantity of cementing materials 
per unit surface area is  increases which increase 
bond stress with resulting increase of concrete 
compressive strength. 
 
The relation of concrete compressive strength with 
variation of fineness modulus of coarse aggregate is 
shown in Fig 8. From figure it is clear that 
compressive strength increases with the increases 
of coarse aggregate fineness modulus. Concrete 
with lower fineness modulus of both fine aggregate 
and coarse aggregate show comparatively low 
compressive strength. Maximum compressive 
strength was archived when fineness modulus of 
both coarse and fine aggregate was higher and well 
graded. 
 
Fine aggregate having fineness modulus 2.0 is not 
well graded as compared to ASTM grading 
requirement which is shown in Fig 3.1 that’s why it 
gives low compressive strength. 
 
 
Fig 8: Relation of concrete compressive strength 
with the variation of fineness modulus of course 
aggregate 
 
The change of concrete compressive strength with 
variation of fineness modulus of fine aggregate is 
shown in Fig 9. This figure also represent that 
compressive strength increases with the increases 
of fine aggregate fineness modulus.  
 
Coarse aggregate having fineness modulus 6.0 is 
not well graded according to ASTM C 33-93 
grading requirement which is shown in Fig 4 that’s 
why it gives low compressive strength. Maximum 
compressive strength of 3800 psi was archived in 
the concrete having fineness modulus of fine 
aggregate and coarse aggregate 3.0 and 7.5 
respectively.   
 
 
Fig 9: Relation of concrete compressive strength 
with the variation of fineness modulus of fine 
aggregate 
 
Aggregate up to 1.5 in maximum size, concrete 
compressive strength increases. Aggregate above 
1.5 in maximum size the gain in strength due to the 
reduced water requirement is offset by the 
detrimental effect of lower bond area and of 
discontinuities introduced by the very large 
particles [Neville A. M. 1995].  
 
From Fig 10 concrete compressive strength 
increases rapidly due change of maximum 
aggregate size up to 0.75  in. Above 0.75 in 
maximum size, rate of increasing concrete 
compressive strength becomes lower up to 1.5 in 
down grade. 
 
Fig 10: Influence of maximum size of aggregate on 
compressive strength of concrete 
 
Response of concrete compressive strength with 
combined fineness modulus of aggregate is focused 
in the Fig 11. From figure, there is no linear 
2.5
3
3.5
4
5.5 6 6.5 7 7.5 8
Co
m
pr
es
siv
e 
St
re
n
gt
h,
 
ks
i
Fineness Modulus of Coarse Aggregate
FMFA=2.0
FMFA=2.5
FMFA=3.0
2.5
3
3.5
4
1.5 2 2.5 3 3.5
Co
m
pr
es
siv
e 
St
re
n
gt
h,
 
ks
i
Fineness Modulus on Fine Aggregate
CAFM=6.0
CAFM=6.5
CAFM=7.0
CAFM=7.5
2.5
3
3.5
4
0.25 0.75 1.25 1.75
Co
m
pr
es
siv
e 
St
re
n
gt
h,
 
ks
i
Maximum Aggregate Size, inch
FAFM=2.0
FAFM=2.5
FAFM=3.0
Page 135
  
relationship of concrete compressive strength with 
the combine fineness modulus of aggregate.   
 
 
Fig 4.4 : Relation of concrete compressive strength 
with the variation of combine fineness modulus of 
aggregate. 
 
6. CONCLUSION: 
 
The main objectives of the study was to find the 
relation of concrete properties specially 
compressive strength with the both fine and coarse 
aggregate grading, maximum size of coarse 
aggregate and combined fineness modulus of 
aggregate. On the basis of this study following 
conclusions can be drawn: 
• Compressive strength of concrete has been 
greatly influenced by the fine and coarse 
aggregate grading as well as fineness modulus. 
Due to the increase of the fineness modulus of 
aggregate, compressive strength increases 
considerably. Maximum compressive was 
achieved 3873 psi for the concrete with fineness 
modulus of fine and coarse aggregate 3.0 and 
7.5 respectively. Minimum strength was found 
2669 psi for the concrete with fineness modulus 
of fine and coarse aggregate 2.0 and 6.0 
respectively. 
• Compressive strength increases with the 
increases of maximum aggregate size up to 1.5 
inch 
• There is no linear relationship of concrete 
compressive strength with the combined 
fineness modulus of aggregate. 
 
5.2 RECOMMENDATION: 
 
This is a short scale research work due to the 
limitation of time and resource. To get the more 
accurate result large scale research should conduct 
changing various parameters. Few guidelines are 
suggested below for future study on this topic.  
• Mix ratio was constant in this study; this 
research should be revised for different mix 
ratio. 
• With the increases of aggregate size required 
water cement ratio become lower. So this study 
should be conducted with different water 
cement ratio. 
• This study should be performed for brick 
aggregate and it is necessary to prepare 
standard grading requirement for both fine and 
coarse aggregate (brick). 
 
REFERENCES 
 
1. Aziz M.A.[1995], “Engineering Materials” 
First Edition. 
2. Islam M.M. et. al., [2005], “Effect of 
Specimen Size on the Compressive 
Strength of Brick Aggregate Grading” 
B.Sc. Engineering Thesis, Department of 
Civil Engineering, Dhaka University of 
Engineering and Technology, Gazipur, 
Bangladesh.  
3. Kamruzzaman M. el.al,[2004], “Effect of 
Fine Aggregate Size on The Properties of 
Brick Aggregate Concrete” B.Sc. 
Engineering Thesis, Department of Civil 
Engineering, Dhaka University of 
Engineering and Technology, Gazipur, 
Bangladesh.  
4. Neville A.M., [2005], “Properties of 
Concrete” Fourth and Final Edition, 
Pearson Education. 
5. Singh G. and Singh J. [1998], “Building 
Materials”, Third Edition, Standard 
Publishers Distributors  
 
 
 
 
 
 
2.5
3
3.5
4
4 4.5 5 5.5 6 6.5
Co
m
pr
es
siv
e 
St
re
n
gt
h,
 
ks
i
Combined Fineness Modulus
Page 136
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Nazmus Sakib,  
E-mail: nazm.sakib@gmail.com 
FIRE HAZARD SCENARIO IN CHITTAGONG: A CASE STUDY 
 
Sohidul Islam 
Graduate Student, Dept. Geography and Environmental Studies, 
Chittagong University, Chittagong. 
Email:sohidulislam50@yahoo.com 
 
Nazmus Sakib* 
Department of Civil and Environmental Engineering 
Islamic University of Technology (IUT) 
Board bazar, Gazipur - 1704, Dhaka, Bangladesh  
E-mail: nazm.sakib@gmail.com 
 
Zasiah Tafheem 
Dept. of Civil Engineering, Ahsanullah University of Science and Technology,  
Tejgaon, Dhaka. 
Email: zasiah_tafheem@yahoo.com 
 
Tanjina Afrin 
Dept. of Civil Engineering, Stamford University Bangladesh,  
Siddheswary, Dhaka.  
Email: afrintanjina@gmail.com 
 
Abstract: Fire hazard estimation is a daunting task because of the huge number of factors involved in it. 
Such factors are number of vulnerable population, availability of escape ways, accessibility to fire cars, 
active and passive fire suppression equipments etc. In case of high-rise buildings (above 6 storeys) some of 
these parameters are more significant; like accessibility to fire trucks with high-reach ladders and active fire 
suppressing system. To get a realistic picture on the present hazard scenario of the second largest city of 
Bangladesh, Chittagong, a study was undertaken during May, 2010 to September, 2010. Study area was 
Nasirabad Housing Society, Sugandha, Khulshi, Mehedibag and O.R. Nizam Road. Data was collected for 
above mentioned parameters for high-rise buildings and represented and analysed in semi graphical method. 
Some of the major findings include that only 8.7% building has wide enough road for Turntable ladder 
appliances (require 30feet road), about 90% buildings has two or more fire extinguishers but sadly water 
reservoir size (over head and underground) do not comply with required sizes and also they do not keep 50% 
of their reserve for fire fighting according to Bangladesh National Building Code, 2007. 
 
Key words: fire, accessibility, Chittagong, high-rise, BNBC 
 
1. INTRODUCTION 
A fire hazard is any situation in which there is a 
greater than normal risk of harm to people or 
property due to fire. Fire hazards can take the 
form of ways that fires can easily start, such as 
a blocked cooling vent, or overloaded electrical 
system, ways fires can spread rapidly, such as 
an insufficiently protected fuel store or areas 
with high oxygen concentrations, or things 
which, in a fire, pose a hazard to people, such 
as materials that produce toxic fumes when 
heated or blocked fire exits. Fire can cause 
disasters and loss of lives in buildings such as 
residential apartments, offices, hotels, shopping 
centers, hospitals and schools. 
 As with most problems in this country, lack of 
awareness is one of the major impediments in 
making our buildings safe from fire related 
accidents. The difference here is that instead of 
going by the cliché of developing 
consciousness among the public, it is the 
professionals (architects, planners, and 
engineers) who have to first understand the 
emerging and growing need to be 
Page 137
ISBN: 978-984-33-2140-4
  
knowledgeable about fire, its dangers, causes 
and consequences, and then evolve design 
solutions that make a safe living environment. 
Chittagong City has been experiencing high 
rate of urbanization since the last few decades. 
Presently, more than 4 million people are living 
in Chittagong City. The development trend of 
Chittagong City is deliberately shifting vertical 
direction to cope with the extensive population 
pressure. 
High-rise buildings are being constructed in 
every parts of the city but in most cases 
dwellings are being constructed without 
maintaining the planning rules and regulations. 
Fire hazard vulnerability of Chittagong City 
dwellers has been increased due to reckless 
building construction and non conformation of 
Fire Protection Act, 2003.  
Chittagong City has been experiencing many 
fire accidents at present and in most cases lack 
of proper precautionary measures along with 
the institutional inefficiency, insufficient 
equipment support and lack of public 
awareness are causing this situation more 
complex. As most of the dwellers do not know 
how to use the fire fighting equipments, in most 
cases all precautionary measures for combating 
fire generally go into vein. Therefore, 
institutional reform, strengthening of capacity 
at individual and institutional level is needed in 
order to reduce fire hazard risks of Chittagong 
City. 
 
2. Background of the Study 
 
Fire hazards occur frequently in our country 
because of different reasons such as unplanned 
urbanization and lack of public awareness of 
fire, according to the statistics available with 
the Fire Service and Civil Defense. The 
statistics showed the number of fire incidents 
was 6,289 in 2003, 7,140 in 2004, 7,475 in 
2005, 9,542 in 2006, 9,196 in 2007 and 9,310 
in 2008.  Fire causes huge loss of lives and 
properties every year. Although termed as ‘fire 
accident’, most fire events are far from being 
accidental. Indeed, most fires are preventable. 
 
The officials of Fire Service and Civil Defense 
(FSCD) established the number of fire hazards 
and extent of losses in fire incidents are as 
follows: 
 
Table 2.1: Total number of fire hazards and 
extent of losses due to fire hazards in 
Bangladesh  
 
Year Number of 
Fire Hazards 
Extent of Loss 
in Tk (crore) 
2002 5404 112.21 
2003 6289 110.59 
2004 7140 213.78 
2005 7475 272.64 
2006 9542 238.76 
2007 9196 309.00 
2008 9310 231.00 
 
Source: Bangladesh Fire Service and Civil 
Defense, 2009 
 
From the table it is apparent that the fire 
incident and the economic loss is increasing 
gradually. A developing country like us cannot 
afford the huge amount of loss caused by fire 
accidents every year. 
In the port City Chittagong, every year 
devastating fire causes huge loss of property 
and human lives. The number of fire incidents 
is higher than another region of the country. 
This is due to total environment and 
circumstances are not in favor to prevent fire. 
The officials of FSCD established the number 
of fire hazards, death toll and extent of losses 
in fire incidents of Chittagong are as follows: 
 
Table 2.2: Total number of fire hazards, death 
toll and extent of losses due to fire hazards in 
Chittagong Division 
Time 
Period 
No. of 
Fire 
Hazard 
Death 
Toll 
(Human) 
Extent of 
Loss (Tk.) 
2007 778 29 141383600 
2008 836 33 393360066 
2009 1053 11 341671500 
Source: FSCD, Agrabad 2010 
 
From the table it evident that fire hazards and 
economic loss is increasing gradually. Records 
showed that electric short-circuits have topped 
the list of reasons of fire incidents. Burner 
posses second position to generate fire hazard. 
Besides, the poor fire fighting equipments of 
the Fire Service and absence of infrastructure 
supports like street hydrants and construction 
of fire-lanes in busy cities are the reasons that 
tackling such emergency situations. There are 
only 5,000 fire fighters in Bangladesh. There 
are 11 fire stations in the city. Chittagong fire 
fighters are unable to douse flames beyond 
Page 138
  
sixth floor of a high rise building. There is no 
turntable ladder. 
Table 2.3: Total No. of fire disaster and economic 
loss in dwelling-house in Chittagong
Year Total No. of Fire in 
Dwelling House 
Economic 
Loss (Taka)
2007 347 67003200
2008 419 77615400
2009 496 84730400
Source: FSCD, Agrabad 2010 
Table 2.3 reveals that number of fire incidents 
in dwelling-house is increasing in Chittagong 
day by day. Lack of residents’ 
electric wiring and burner fire are also the 
reasons for fire, especially in dwelling
The fire incidents are on an increase due to 
lack of awareness and practicing fire fighting 
drills, violation of building codes and non
compliance with the Fire Checking and 
Extinguishing Law, 2003. 
 
3. Methodology 
 
To carry out the study resourcefully, 
of questionnaire have been developed. Each 
questionnaire has several variables and several 
natures (Table 2). These questionnaires
been developed on the basis of objectives to 
assessing the fire hazard prevention system in 
high-rise apartments of residential areas in 
Chittagong City. Questionnaire on expert 
group mainly higher officials on FSCD, CDA, 
are emphasis on suggestions and 
recommendations for the best approaches of 
fire hazards prevention in high-rise apartments.
A total of 104 samples were collected:
 
Sl. 
No 
Study Area No. of 
Apartment
01 Nasirabad Hosing 
Society 
32
02 Sugandha Housing 
Society 
08
03 Khulshi Residential 
Area 
31
04 O.R Nizam Road 
Residential Area 
18
05 Mehedibag 
Residential Area 
15
 Total 104
 division 
 
 
 
 
awareness of 
-house. 
-
four sets 
 have 
 
 
 
 
 
 
 
 
 
4. RESULTS 
Following results were obtained from the field 
survey: 
4.1 Number of Storey of the Apartments  
A floor is any level part of an apartment that 
has a permanent roof and could be used by 
people (for living, work, storage, recreation, 
etc.). The number of floors of an apartme
been counted by observation technique. In the 
study area 30.8% apartments consist of seven 
floor and second highest 26.9% consist of 
eight floor. The following fig.4.1 represents 
the percentage of apartments consist with 
floor: 
 
Fig 4.1: No of floors with percentage of apartments
 
4.2 Residents of the Apartments
 
It is an important factor to estimate fire safety 
of high-rise apartments because fixed 
installation to safe from fire should be taken on 
the basis of total residents of the apartment. 
According to apartments survey it was found 
that 22.1% apartments resident size was 
around 120 and the second highest 21.2% 
apartments resident size was around 141. In 
the fig 4.2 shows the resident size of the 
apartments.   
  Fig 4.2: Percentage of Resident Size in an 
Apartment Building 
30.8%
26.9%
18.3%
13.5%
6.7%
1.9%0
5
10
15
20
25
30
35
P
e
rc
e
n
ta
g
e
 o
f 
a
p
a
rt
m
e
n
ts
Number of storeys
0
5
10
15
20
25
1
0
0
-1
2
0
1
2
1
-1
4
1
1
4
2
-1
6
2
1
6
3
-1
8
3
1
8
4
-2
0
4
2
0
5
-2
2
5
P
e
rc
e
n
ta
g
e
Resident Size
 
nt has 
 
 
 
 
 
1% 1%
2
2
6
-2
4
6
2
4
7
-2
6
7
2
6
8
-2
8
8
Page 139
  
                 
In the high-rise apartment, if the fire fighting 
factors and escape routes are insufficient in 
compare with population then it has great 
chance to increase the fatality of resi
case of fire accidents. 
 
4.3 Access way 
Access way shall be provided for accessibility 
of site to firefighting appliances. Snorkel 
Turntable Ladder appliances need to 
firefighting and rescue in high-rise apartment. 
To allowing access of that appliances need 30 
feet wide road.  
 
Fig 4.3: Road width below 30 feet
in Nasirabad residential area. 
   
 Accessibility data has been collected through 
field survey. In the study area, above 30 feet 
wide access road has been found only 9.6 % 
apartments. The highest 36.5% apartment’s 
road accessibility has been found above 15 
feet. The access way of the apartm
presented below:   
Fig 4.4: Apartments with Specific Road Width
   
27.9%
36.5%
16.3%
9.7%
0
5
10
15
20
25
30
35
40
P
e
rc
e
n
ta
g
e
 o
f 
a
p
a
rt
m
e
n
ts
Road width in feet
dents in 
or 
 
 
ents is 
 
 
4.4 Emergency Exit and General Stairwell
Emergency exit related information have been 
collected from the apartments of study area by 
the field survey. It has been found that only 
13.5% apartments have emergency
others have no fire escape route except general 
stairwell. In the study area a large number 
apartments (82.7%) are with one stairwell and 
others (17.3%) are with two stairwell.
: 
 
Fig 4.5: Percentage of Apartments with one or 
Two Stairwells 
 
 
Fig 4.6: Percentage of Building vs. Width of 
Stairwell 
According to firefighter expert, six feet wide 
stairwell needs for high-rise apartment to safe 
from fire but in the study area only 2.9% 
apartment’s stairwell wide is near to six feet. 
So in the study area’s apartments are not safe 
from fire.  
 
4.5 Fire Extinguisher 
 A fire extinguisher is an absolute necessity in 
high-rise apartment. At the initial stage of fire 
accidents fire extinguisher used to e
or control fires. According to field survey it 
has been found that 38.5% floors of
apartments are with two fire extinguishers and 
33.7% floors of the apartments are
fire extinguishers. It is notable that 4.8% 
apartments are without fire extinguisher. In the 
following Fig 4.7 shows the number of fire 
9.6%
82.7%
17.3%
24%
52.9%
20.2%
0
20
40
60
P
e
rc
e
n
ta
g
e
Width of stairwell in feet
 
 exit and 
of 
 
 
 
xtinguish 
 the 
 with three 
One
Two
2.9%
Page 140
  
extinguishers numbers in the percentage of 
floors of the apartments: 
 
Fig 4.7: No of Fire extinguisher 
 
Although it is also remarkable that fire 
extinguisher should be laid in different places 
but in the study area where we found the 
extinguishers all are in the corridor and beside 
the door.       
 
4.6 Fire Alarm 
 Fire alarm is a device, such as a siren, use
announcing the outbreak of a fire. This study 
finds out the apartments with and without fire 
alarm. 
 
 In the study area it has been found that 64.4% 
apartments are without fire alarm and rest 
35.6% apartments having fire alarm (Fig 4
 Fig 4.9: Availability of Fire Alarm
4.8%
38.5%33.7%
14.4%
0
5
10
15
20
25
30
35
40
45
o
n
e
tw
o
th
re
e
F
o
u
r
P
e
rc
e
n
ta
g
e
 
Fire extinguisher number
64.4%
35.6%
Apartments 
without fire 
alarm
Apartments 
with fire 
alarm
Fig 4.8: Fire alarm in an apartment of 
Nasirabad residential area. 
 
d in 
9).  
 
 
 
5. Conclusion 
Obvious upgrading is essential in both fire 
safety design and fire fighting. Fire safety 
design can be improved by strict enforcement 
of fixed installation of fire fighting equipments 
and fire escape routes in the apartments. 
Proper fire inspection can reduce the 
vulnerability of high-rise apartments 
considering fire hazard. To improve the fire 
fighting aspect, indiscriminate filling up of 
water bodies must be prevented and adequate 
right- of- ways should be ensured. It is 
particularly important in the new development 
areas. Public awareness campaigns, including 
fire drills, may be conducted. Also careful 
planning of the number and locations of fire 
stations with adequate fire engines and 
equipments are considered necessary.
 
REFERENCES 
 
1. BNBC, (1993), “Bangladesh National 
Building Code”, Housing and Building 
Research Institute and Bangladesh 
Standards and Testing Institutions
Dhaka. 
2. Ahmed, N. (1998): Fire in Residential 
Buildings: A Cause Concern in 
Bangladesh”, EUCSU Technical 
Journal, 1997-98, pp. 94-100. 
3. Federal Emergency Management 
Agency (FEMA) (1997) “Project 
impact: Building a disaster resistant 
community, Government Printing 
Office”, Washington, D.C.
4. REHAB (Real Estate and Housing 
Association of Bangladesh) (2004), 
Annual Report 2002 (Dhaka: 
REHAB). 
5. Chaudhuri, A K, Shami, D K and
Bhagat, O P (2000). Indian Fire 
Service in Retrospect: Vision for next 
millennium- An empirical study, Fire 
Engineer, 34-51. 
 
3.8% 4.8%
F
iv
e
W
it
h
o
u
t 
fi
re
 
e
x
ti
n
g
u
is
h
e
r
 
 
, 
 
 
 
Page 141
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
 
*
 Corresponding Author: Anika Nasra Haque,  
E-mail: shagota@aiub.edu 
INFORMAL SECTOR WATER UTILITY MANAGEMENT: 
POTENTIAL URBAN-SLUM UPGRADATION POLICIES IN 
BANGLADESH 
 
 
Md. Mohataz Hossain 
Department of Architecture, Bangladesh University of Engineering & Technology (BUET), 
Palassy, Dhaka-1000, Bangladesh. 
 
Anika Nasra Haque*  
Department of Architecture, American International University Bangladesh (AIUB), 
Kamal Ataturk Avenue, Banani, Dhaka, Bangladesh, 
 
 
The unplanned water sector of slum settlements in many developing countries has an enormous backlog in 
the provision of reliable water supplies and sanitation services to its population, which is further exacerbated 
by the growing number of informal settlements. Development policy agendas are needed to be reshaped in 
ways that de-emphasize central state control and that shift responsibilities to local government, NGOS and 
the market. With some extensive literature review and using the outcomes of some studies on slum 
upgradation and its infrastructure development, this paper shows a range of practices and policies in 
accessing water and sanitation to urban slum settlements. The paper also summarizes the findings of the 
effectiveness of different policies and also discusses the difficulties and limitations of implementing 
government and private organizations’ initiations. It identifies the changes needed to make slum upgrading 
more effective and capable of reaching a much larger scale. It starts from the observation of supply and 
provision of water and sanitation of slum as well as various upgradation program and policies. This research 
is concluded outlining a conceptual statement of adaptable slum up gradation policies in the context of a 
developing country like Bangladesh. 
 
Key words: Informal sector, water-utility management, urban-slum, adaptable, upgradation policies.  
 
1. INTRODUCTION 
 
As estimated one billion people worldwide live in 
urban slums, the majority of them are in the less 
developed world. These settlements are usually of 
temporary structures and lack upgraded modern 
facilities. These informal sector water utilities in 
developing countries are consistently criticized for 
failing to provide adequate water services to the 
urban poor. The growing recognition of the 
problem of water utility in slums coincides with 
public policy shifts among national governments, 
major supranational institutions and many smaller 
non-governmental, private organizations.  
Development policy agendas are needed to be 
reshaped in ways that de-emphasize central state 
control and that shift responsibilities to local 
government, NGOS and the market. These changes 
are in part needed to democratize development 
through the involvement of local agencies and 
communities. 
This paper focuses on the urban slum and its water-
utilities upgradation policies; questions asked are: 
what new opportunities are offered by the policies? 
What are the constraints imposed by these policies? 
How do these affect local agencies, communities 
and processes in specific slum water utility 
upgradation projects?  
 
2. INFORMAL SECTOR HOUSING: 
URBAN-SLUM AND ITS LIVING 
CONDITION 
 
The world is experiencing an unprecedented rate of 
urbanization. In the path- breaking UN- Habitat 
report Challenge of the slums (2003), Secretary 
General of the UN Kofi Anan warned that: 
“Without concerted action on the part of municipal 
authorities, national governments, civil society 
actors and the international community, the number 
of slum dwellers is likely to increase in most 
Page 142
ISBN: 978-984-33-2140-4
  
developing countries. And if no serious action is 
taken, the number of slum dwellers world-wide is 
projected to rise over the next 30 years to about 2 
billion. The UN – Habitat report is one of numerous 
publications in the past few years alerting us to the 
gravity of the situation (Davis, 2006: Neuwirth, 
2004). If this situation continues along with the 
absence of effective policies, precarious living 
conditions in cities may well become the main 
challenge to human development in future 
decades.” 
 
The planned urban land areas command high land 
price. Therefore, low income families are forced 
into government or private vacant land with 
unplanned accommodation and unhealthy 
condition. Approximately 15 to 20 percent of 
Bangalore’s residents are slum dwellers while it is 
more than 30 percent in Dhaka, Kolkata and 
Mumbai. The government of India defines slums as 
housing that is “unfit for human habitation or 
detrimental to safety, health and morals of the 
inhabitants” (Government of India, 1988). The 
Bangladesh bureau of Statistics defines a slum 
(basti in Bengali) as: “A cluster of compact 
settlements of five or more households that 
generally grow very unsystematically and 
haphazardly in an unhealthy condition and 
atmosphere on government and private vacant 
land”. These seem to be acceptable definitions. The 
bureau used some of the criteria to identify slums, 
which includes predominantly poor housing, poor 
quality or no sewerage and drainage, inadequate 
drinking water supplies and few or no paved streets 
or paths. (CSAFP, 1997) In many of the slums 
covered by this study were found to be located near 
polluted water bodies, swamps or putrid drainage 
canals. These slum dwellers who take the low level 
of jobs continue living under this terrible condition. 
They represent a fundamental transformation of 
physical and social environment of urban life and 
human health. They seldom have access to publicly 
provided services even though the water supply and 
sanitation. In most cases, they build rudimentary 
toilets or use nearby streams and swamps for waste 
disposal. Pollution takes severe due to open 
defecation by the slum dwellers. Waterborne 
diseases are inevitable outcome. Accordingly, 
standard of health is becoming worse due to the 
reduced access to safe water and sanitation. 
 
3. PROVISION OF WATER AND 
UTILITIES IN SLUM AREA 
 
The responsibility of the government organizations 
for water provision in slums is fuzzy; perhaps an 
important contributory factor behind the poor 
quality of water-service levels in slum area is 
inadequate number of government organizations 
involved in water sectors. Generally, the 
intersection of the slum and water sectors has 
created a web of relations among government 
actors that confront a simple version of a public 
utility. Inadequate safe drinking water in slums 
causes many problems. Unsanitary lifestyles, lack 
of domestic water, increased health risks-all are 
interrelated to the water provision of slum area. As 
the slum population is continuously growing 
excessively, demand of water within the service 
area cannot be met through piped network 
connection. So some alternative to piped system 
like buying from informal tankers, rainwater 
collection, own individual wells (for some counties) 
are also options to provide them with water for their 
daily use. But still, long term or short term policies 
are needed to distribute the services to the slum 
dwellers adequately. 
 
4. SLUM UPGRADATION AND 
POLICIES EVOLVED  
 
4.1 Evolutions of slum upgradation policies 
In reference to Mumbai and other places, the slum 
policies are evaluated with the period of time. The 
various trial programs organized by state 
government as well as private agencies are failed in 
the implementing stage for the reasons of 
affordability, service distribution to the actual poor, 
inadequacy of fund, secure cost-recovery and 
maintenance. The role of the government is 
transformed from implementer to facilitator. But 
still it remains the problem of uncertainty to 
identify the truly poor dwellers that need the 
services from the private and governmental 
organizations. The local organizations and banks 
draw changes to the slum improvement policies 
through proper feasibility study and allowing active 
community participation. Now, scaling up the 
financing and implementation procedure from small 
area-based projects to large infrastructure sector of 
slums is the main challenging issue for cities of 
developing countries. 
 
4.2 Common upgradation principles 
In the developing countries, the slum upgradation 
programs are continuously changing according to 
the extensive experiences gathered from small 
projects and studies. But there are some common 
principles that government and private 
organizations follow to develop the water utilities 
and services of slums. 
 
• Development plan by the government to 
redevelop slum infrastructure in situ through 
local structured program,  
• Some agencies start through qualitative research 
methods which include local community 
Page 143
  
development structure, group interviews, 
introspection of the possible stakeholders, 
workshops and develop an action plan for 
longtime development. 
• Some pilot projects initially go through 
feasibility studies which cover poverty matrix, 
SWOT analysis, Micro planning and poor 
community identification. 
• Slum maintenance work is carried out by ward –
level or local engineers, alongside routine works 
for given area. 
• Maintenance divisions are usually like water 
source development, corporate planning by the 
private organizations, capital works, auditing and 
finance.  
• For further extension of the development of water 
utilizes for slum dwellers, local investors and 
developers carry out with Lump sum contracts 
with the government.  
• At the implementation stage the community 
participation is organized through 
communicating with selected community 
representatives to avoid muddle. 
• Ensuring improved services after the connection 
with reliable water supply and consistent billing. 
 
These principles have various implementation and 
maintenance procedure that may vary in different 
context of the cities of developing countries. 
 
4.3 Overview of Institutions and their 
mitigation plans 
Service provision can involve a variety of different 
organizational arrangements in water utility 
upgradation for slum. Among them, state 
governments and government institutions are slum 
rehabilitation authority, Regional development 
authority, municipal organizations, and civil 
societies. Their initiations for developing the 
environment of the slums are slow in progress and 
the staffing of the organizations is not appropriate 
to deliver effective services to the urban poor. In 
support, other coordinating authorities which also 
act as multiple executing agencies  are the    private 
sector developers, private banks, NGOs, 
Cooperative housing societies of slum dwellers, 
foreign agencies etc. Some of these agencies work 
 
  
 
 
 
 
 
 
 
 
 
as financial investor to the slum development pilot 
projects. Their financial interest is the additional 
revenue that is gained from both initial connection 
fees and monthly tariffs paid by the slum dwellers. 
But sometimes there are some unusual funding and 
the opportunities to provide the slum dwellers with 
piped water supply and proper sanitation. Actually 
it varies according to the context. 
The common features of their action plans are to 
improve the delivery of service to the poor 
settlements through an overall improvement of 
performance as well as the provision of 
infrastructure development to the slums.  
 
4.4 Community participation and 
observations 
Self-help practices are sometimes effective while 
undertaking upgrading programs for local area 
slum. Shared water connection and toilet facilities 
are the common approaches that are initiated by 
local slum dwellers. In effect, the potential 
outcomes for slum dwellers can be shared metered 
connections of water, individual metered 
connection, disconnection of illegal supply and 
services or no improvement.  There are always 
choices in community participations which may 
vary with context of the cities. So it is better to 
promote participatory governance with the 
encouraging citizens to get involved with their 
government and hold it to account. The result is 
always observed with improvement of the 
relationships and decision making, user satisfaction 
according to their choices. So the whole process 
can be shown as Figure 1. 
 
4.5 Scaling up the initial financing 
All small local area-based projects are always 
successful as they are easier to manage in 
perspective of financial as well as implementation 
process. It is not important how the pilot projects 
can be scaled up but, rather, how the governance 
process can progress within the public sector 
organizations to generate new forms of governance 
If the continuous development process can be 
formalized with necessary documentation and 
analysis, the initial financing can be scaled up 
according to the improvement of the mitigation 
plans. and adopt new patterns of working with the 
poor. In short, it can be shown as Figure 2. 
 
 
 
 
 
 
 
Figure 1: Overview of the evaluation of 
upgradation policies 
 
Work of active group in 
community level to afford the 
service of investors by sharing. 
Role: Participatory 
governance 
 
Policy changes and unexpected 
Side - effects take place 
Government as 
service provider 
 
Role: Facilitator 
 
Private sector 
organizations and 
their pilot 
projects 
Role: Investor 
 
Page 144
  
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2: Long term mitigation plans 
 
4.6 Limitations of the existing policies 
If it is discussed about the effectiveness of the 
policies and difficulties of implementing 
government and private organizations’ initiations, 
the following common limitations can be 
monitored. 
• In common, low number of social development 
experts work in the government organizations, 
rather these are staffed by engineers which is the 
main cause of limited interaction with slum 
dwellers.  
• Political issues play a big role as the services 
provided by the agencies are misused by the 
powerful political persons who act as the 
community representatives. Public taps were 
provided, either legally by public agencies, or 
illegally by politicians, usually on the eve of 
elections. 
• No consideration of capital investment associated 
with new growing slums and their infrastructure. 
• Poorest people use to have very little 
involvement in community decision making in 
participatory governance. 
 
4. ADAPTABLE UPGRADATION 
POLICIES FOR BANGLADESH 
 
An estimated 3.4 million people live in slum 
(Figure 3) in Dhaka (Source: Sustainable 
Development Networking Program (SDNP) 
website). Some of them are involved in a variety of 
occupations in urban informal sectors. And due to a 
lack of education and employment training they 
usually do not gain entry into the more competitive 
formal sectors of urban employment. As a result 
their income is very low. So affordability of slum 
dwellers to meet the requirement of water and 
sanitation is an important issue. Whatever approach 
is taken for the upgradation of slums, it should be 
based on three simple concepts- “Affordability”, 
“cost recovery” and “replicability”.  
 
 
Figure 3: Slum of Dhaka city (Source: Dhaka 
Satellite Image, Internet) 
 
Affordability means adopting a realistic approach 
to the needed supply in terms of what urban poor 
can really afford. “Cost recovery” is related to the 
concept of “affordability”, providing what can be 
afforded by consumers. “Replicability” means if 
costs are recovered as because they are affordable, 
then the successful repetition becomes likely. This 
would lead to an overall upgradation in slum 
settlements. In context of Bangladesh, the problems 
related to water utilities of urban slum are quite 
similar to other developing counties. But according 
to the available resources and public reactions some 
policies are adaptable for effective results. 
 
5.1. Infrastructure and services 
• House to house service connection is not feasible 
because of the huge gap between service to be 
provided and resource available. Therefore, 
privately supplied communal shared facilities can 
be provided. 
• At the same way, clustered latrines (Figure 4) 
can be an affordable sanitation option since the 
cost is shared by many of the slum dwellers. 
• Consumption of portable water can be reduced 
by providing alternative sources for other 
domestic purposes. 
5.2 Finance 
• Local government should play their subjective 
role because there is a substantial central 
government resource transfer component. 
• Hence direct cost recovery is not feasible for 
slum area; improving land taxation can be a 
source for finance generation. 
• Cost recovery is manageable for many poor 
households, but not for the poorest of the poor. 
In that case, some new cost- sharing 
arrangement is needed to be devised. 
• Government subsidies and favorable loan 
agreements can also be introduced. 
 
Long term policy with scaling up the project 
 
Provision of 
development 
 
Need of 
existing 
slum 
dwellers 
in a local 
area 
Available 
resources 
 
Finance 
 
Communit
y 
participatio
n 
Existing 
constrains 
 
Page 145
  
 
Figure 4: Community Clustered Latrines. (Source: 
Hanchett, S., Akhter, S., Khan, M.H., 2003)
 
5.3 Community participation 
• Upgradation activity in any given slum starts 
with community mobilization. Developments 
have often emerged from the experiences of the 
local communities in trying to upgrade their 
own area, rather than a policy which has been 
superimposed from above 
• In Dhaka city, while undertaking upgrading 
programs, community participation has to be 
ensured at all the strata of decision making and 
implementation as well. 
• Community ownership should be developed 
instead of individual ownership. 
• Communal activities like community 
mobilization and hygiene education can create a 
feeling for need for the infrastructure 
upgradation and their willingness to pay for 
those. It adds to people’s ability to analyze and 
take control of their living environment. The 
local NGOs can play a progressive role here.
• Development and maintenance of infrastructure 
provision can be transferred to semi
autonomous public agencies from the routine 
municipal department, but cannot be to a 
complete autonomous body as it can obstruct 
overall coordination, long term planning and 
routine operational policies. 
 
6. CONCLUDING REMARKS
 
Reviewing all the articles, mentioned in the 
reference, some general conclusion can be drawn 
regarding the upgradation of water utilities and 
services for urban slum. The overall experience of 
the pilot projects in other countries is very positive. 
Through the pilot projects, new wor
relationships are developed between slum dwellers, 
agency staff, NGO workers and others. But 
financial incentives were needed to ensure proper 
upgradation of water utilities and profitable for the 
developers or investors as well. Above all, the 
upgradation of urban slum is a continuous process 
which would be evaluated with the period of time, 
local context, existing needs, future needs and other 
 
 
 
- 
 
king 
factors. So, the collaboration of the government, 
private organizations and community slum dwellers 
is necessary to reduce constrains of slum 
upgradation in Bangladesh. In broader sense the 
most important thing is the sustained reduction in 
vulnerability and poverty of urban poor.
 
REFERENCES 
 
1.  Ahmed, A. (2007), “Urban poor”, 
Star, September 26, 2007. 
2.  Allen, A., Davila, J. D, Hofmann, P. (2006), 
“The peri-urban water poor: citizens or 
consumers?”, Environment & Urbanization
18 No. 2, October 2006, pp. 333-351.
3. Bartlett, S. (2003), “Water, sanitation and urban 
children: the need to go beyond “impr
provision”, Environment & Urbanization
No. 2, October 2003,  pp. 57-70. 
4. Burra, S. (2005), “Towards a pro
framework for slum upgrading in Mumbai, 
India”, Environment & Urbanization
1, April 2005, pp. 67-90. 
5. Census of Slum Areas and Floating Populations 
1997, Volume 1, pages 2-3 
6. Chowdhury, F. J. & Amin, A.T.M. N.
“Environmental assessment in slum improvement 
programs: Some evidence from a study on 
infrastructure projects in two Dhaka slums”,
Environmental Impact Assessment Review
26, Issue 6, August 2006, pp 530-552.
7. Connors, G. (2005), “When utilities muddle 
through: pro-poor governance in Bangalore’s 
public water sector”, Environment & 
Urbanization, V.17 no.1, April 2005, pp.
8. Dove, L. (2004), “Providing environmental urban 
services to the poor in Andhra Pradesh: 
developing strategic decision making”, 
Environment & Urbanization, Vol. 16 No. 1, 
April 2004, pp. 95-106. 
9. Hanchett, S., Akhter, S., Khan, M.H. (2003), 
“Water, sanitation and hygiene in Bangladeshi 
slums: an evaluation of the water Aid
Bangladesh urban programme” Environment & 
Urbanization, Vol. 15 No. 2, October 2003, pp. 
43-55. 
10. Hossain, S., 2007, “Poverty and vulnerability 
in urban Bangladesh: the case of slum 
communities in Dhaka City”, 
Journal of Development Issues, Vol. 06No.1
50-62. 
11. Nabi, A.S.M.M. (2003), “Water supply and 
sanitation facilities for low-income settlements: 
experiences of south-east Asian cities”, 
World Habitat Day 2003. pp. 11-14.
12. Nawaz, T. (2006), “Growing slums of Dhaka: 
Can we not do anything for them?” 
Star, Vol. 5, Num 707, May 26, 2006.
13. Saleheen, M. (2003), “Water for the urban 
poor”, Souvenir: World Habitat Day 2003
71-72. 
 
The Daily 
, Vol. 
 
oved” 
, Vol. 15 
-poor 
, Vol. 17 No. 
, 2006, 
 
, Vol 
 
201-218. 
 - 
International 
, pp. 
Souvenir: 
 
The Daily 
 
. pp. 
Page 146
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
*
 Corresponding Author: sajal chowdhury. Author,  
E-mail: sajal_c@yahoo.com 
 
INTEGRATION OF PERFORMANCE BASED MODELING 
TECHNIQUES WITH BUILDING DESIGN METHOD 
(INDUSTRY/FACTORY) CONSIDERING ENERGY EFFICIENCY IN 
BANGLADESH 
Sajal Chowdhury, Dr. Md. Rabiul Alam 
Dept of Architecture, Chittagong University of engineering & technology (CUET) 
Chittagong-4349 
 
Climate changing has been a debated issue during the last few years. Some institutes in different countries 
have worked on this subject. Several future climate predictions have been generated. Each future climate is 
based on some assumptions and consequently has some uncertainties. These uncertainties are dragged to the 
building simulation results by using the climate data for assessing the future performance of buildings. 
Bangladesh is newly a developing country. Many more construction is going on in full swing now days. This 
rapid construction is changing our earth surface very quickly. So that it increases heat on earth surface, 
energy consumption, decrease the comfort level. The answer to this challenging situation is the adoption of a 
holistic design approach, whereby the different disciplines required is brought together and interacts since 
the first steps of the design process. This study revealed the present implementation status of factory 
building sector energy standards in Bangladesh, implications for sustainable energy efficient designs in 
factory building and increasing demand for sustainable energy efficient industrial building. 
Key words: Building Energy Use; Building Performance Modeling; Industrial Building 
 
1. INTRODUCTION 
 
Factories in Bangladesh have been heavily 
criticized over the last 30 years for the working 
conditions in which employees must labor. High 
internal gains from artificial lighting, poor natural 
lighting system and equipment produce an 
intolerably hot work environment and energy 
consumption is high. Bangladesh is one of the 
largest products exporters in the world. This 
factory building has been expanding rapidly since 
the late 1970s. Many purpose built factories have 
their own compliance to maintain the quality. 
Among the environmental compliances 
recommended Illumination condition, thermal 
comfort and reduce energy consumption are one 
of them that must be ensured. This paper consists 
3 parts such as; 
 (i) The status of energy standards for factory 
buildings in Bangladesh;  
 (ii) Approaches to standards development in 
view of energy efficiency  
 (iii) Implementation and energy simulation.  
 
Energy saving did not happen in industrial sector 
in our country. Extra energy consumption (28.18 
MTOE) in industry sector came from structural 
change (S-effect) and intensity change (I-effect) 
with amount of 16.39 and 11.79 MTOE, 
respectively. 
This paper investigates the implementation status 
of factory building energy standards in 
developing countries and its implications for 
sustainable energy efficient designs in building. 
Important elements of the research that are 
described in the paper are: 
• identifying the role factory building simulation 
can play at the different stages of design; 
• developing a model description that evolves 
through the design process as the factory building 
design becomes more highly specified; 
• simplifying the user interface at the early stage 
of the design where rapid feedback is required 
and where most impact can be made on the 
factory building’s energy and environmental 
performance; 
Page 147ISBN: 978-984-33-2140-4
 *
 Corresponding Author: sajal chowdhury. Author,  
• customizing results presentation to be 
appropriate for the particular stage of design; and 
• implementing these simulation concepts, 
observing their acceptability, and addressing 
quality assurance and training issues. 
In this Fig. 1, we can see the energy demand 
changing rapidly in our industrial sector. From 
1970 to 2020 the energy demand of the industrial 
sector in Bangladesh will be almost 10 times 
increases. 
So what can we do as professional bodies? There 
may have much kind of solutions. Building 
performance modeling while planning or 
designing a building may be one of the solutions 
to get rid of this kind of problem.  
 
 
Fig. 1: energy consumption in the industrial 
sectors in Bangladesh        Source: Research 
Journal of Applied Sciences  
In Fig. 2 we can compare the ratio of energy 
demand increase day by day. And in 2010 it is 
highest. In the long run, we need more energy 
from the limited resources and it will cause a 
tremendous problem for our nation. 
 
Fig.2: Energy demand of industrial sectors in 
Bangladesh            Source: Research Journal of 
Applied Sciences; Year: 2010 | Volume: 5 | Issue: 
2 | Page No.: 85-91 
The overall building behavior will be influenced 
by numerous climate parameters, including sun, 
wind, water, and geotechnical factors.  The sun 
influences shading, orientation, and views of the 
building. Wind introduces concepts of protection, 
shelter, and energy capture. Energy Conservation 
factory Buildings are very effective for restraint 
of global warming, because they can reduce CO2 
emissions in building operation, which account 
for 70% of Life Cycle emissions.  
 
Fig. 3: US co2 emission by sector 
 
Fig. 4: US energy consumption by sector  
 
Fig. 5: US electricity consumption by sector 
sources: architecture 2030, energy international 
administration (2010)  
From fig.3 – 5 we can notice that in US energy 
consumption is 22.7% in industrial sector and the 
whole building effect is almost 49% .the 
electricity consumption rate is about 23% and co2 
emission is almost 19.6%. So now a day it is a 
big deal. 
An essential condition for industrial development 
is uninterrupted supply of energy. Although the 
installed capacity for generation of electricity in 
1960 1980 2000 2020 2040
1
4
1 2 3 4 5 6
Series1 1990 1995 2000 2005 2007 2009
Series2 2.77 3.15 8.83 11.37 13.23 15.18
1960
1980
2000
2020
2040
1 2 3 4 5 6
Y
e
a
rs
Energy saving (MTOE) energy saving 
Page 148
Conference on Engineering Research, Innovation and Education 2011
 
*
 Corresponding Author: sajal chowdhury. Author, 
the country is 2908 megawatt and energy 
consumption is about 25% in the industrial sector 
and takes the second position of energy 
consumption (Fig. 6), the actual production does 
not exceed 2160 megawatt as against the peak 
demand of 2200 megawatt. The average level of 
system loss is still as high as 33.3%. The demand 
for power will increase by 300 MW annually
an investment of about Tk 110 billion up to the 
turn of the century will be needed to meet it.
 
Fig. 6: Bangladesh electricity consumption by 
sector sources: power development authority, 
Bangladesh  
 
2. IMPORTANCE OF ENERGY 
SIMULATION IN ARCHITECTUR
DESIGN  
 
In early design stages, either in new or retrofit 
designs, one can estimate the energy consumption 
of the building being designed by using hand 
calculations. However, an energy simulation 
program can help the designer have more reliable 
predictions because it is able to simulate the 
building, the weather conditions that obviously 
influence the thermal behavior of the building, 
and the operating schedules of the building.
Energy simulations can then help the designer 
validate the preliminary estimation of the 
building's energy consumption and correct some 
of the architectural features of the building, and 
the mechanical systems, to improve the energy 
performance of the building. The building's form 
and thermal characteristics largely run th
of energy consumed by a building. Thus, it is the 
building designer who has the primary control 
0% 20% 40%
INDUSTRY
TRANSPORTATION
AGRICULTURE
COMMERCIAL
RESIDENTIAL
NON ENERGY USERS
Proceedings of the
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh
 
 and 
 
 
AL 
 
e amount 
over the building's energy use. When an architect 
starts to design a building, she or he is 
simultaneously starting the design of the heating, 
cooling, and lighting of the building. To avoid 
major flaws of the design, an architect needs to 
include the evaluation of the building's energy 
consumption in the earlier stages of the design 
process. If energy efficiency is not adequately 
considered during these stages, higher operating 
cost will accrue over the life of the building.
 
3.  IMPACT ON ENVIRONMENT
 
 Building performance modeling will create new 
knowledge and assist in capacity building by 
improving our understanding about energy 
efficiency on climatic adaptation and mitigation. 
This will create more awareness to take more 
effective actions for mitigating climate change,
thereby making sustainable development feasible 
for green industry development in Bangladesh.
also Generate innovative knowledge. 
knowledge will impact on national programs and 
strategies for climate change adaptation and 
mitigation. 
 
4. GAPS FINDING IN DESIGN PROCESS 
(FACTORY BUILDING)  
 
A worker’s ability to do his/her job
working in hot environments. One of the most 
important conditions for productive work is 
maintaining a comfortable temperature inside the 
workplace. Of course the temperature inside the 
factory varies according to the season and several 
methods can be used to address the problem.
Natural cross ventilation is another important 
factor for a factory building. Instead of natural 
cross ventilation extra cooling and heating load is 
needed for a factory building. 
Most of the factory building in our country has no 
or less option of natural ventilation system, use of 
daylight, water efficiency techniques, no 
observation about indoor air quality and energy 
efficiency building envelop. On the other hand 
inside a typical factory, noise may come from
number of different sources such as the sewing 
machines, weaving looms, compressors, radios, 
background noise, etc. The noise, in the form of 
60% 80%
CERIE 262 
 
 
 
 
 
 
 
 
 It 
This 
 is affected by 
 
 a 
Page 149
Conference on Engineering Research, Innovation and Education 2011
 
*
 Corresponding Author: sajal chowdhury. Author, 
sound waves, is transmitted directly through the 
air and reflects off walls and ceilings as well as 
passing through the factory floor. It can be easily 
removed by the way of simulation process. 
 
In Fig. 7 the diagram is presented the basic 3 gap 
of factory building design. In our country there is 
no consideration about local climate, building 
shape, orientation, no consideration about passive 
design process.  
 
Most of the factory building owner want just 
make a floor for production and for this reason 
human being is like a machine nothing else here. 
Health hazardous condition and need extra energy 
for maintaining this factory is a common scenario 
in our country like Bangladesh. 
 
 
Fig. 7: the condition of present factory in 
Bangladesh and gaping element   
 
5.  SIMULATION IN THE DESIGN 
PROCESS 
From Larry O. Degelman, Professor of 
Architecture, Texas A&M University 
know   to establish a holistic design approach 
Proceedings of the
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh
 
 
 
we come to 
with simulation having an input at all stages it 
was necessary to determine the design approach 
of the architecture practice used as a analysis bed. 
The approach developed was also compared with 
related approaches in the published literature. The 
RIBA design plan of work (RIBA 1995) 
identifies three main building design stages:
•Outline Design Stage • Scheme Design Stage • 
Detailed Design Stage. Different design 
objectives and scopes can be observed in 
different factory building design stages. 
At first in outline design stage a concept based on 
feasibility studies is prepared. It shows the design
Analysis and options considered, it can include 
diagrammatic analysis of the requirements on the 
site, solutions to functional and circulation 
problems, relationships of spaces, massing, 
construction and environmental methods and a 
cost appraisal to enable an approximation of 
construction cost. This design stage is extremely 
time constrained. Elevation treatment, materials 
selection, construction and environmental 
analysis then are taken place in out line design 
stage.  
In term of environmental analysis; Simulation 
will focus on problem areas or on typical factory 
building sections. Now the approved Scheme 
Design solution is worked through in detail. 
Detailed design drawings are produced for 
coordinating structure, services and specialist 
installation. Internal spaces may be detailed to 
include fittings, equipment and finishes.
At this design stage the application of simulation 
relates mainly to engineering issues and it will be 
experts using the tool. They will use simulation 
for purposes such as designing a natural 
ventilation strategy (sizing of openings, 
establishing control strategies, confirming 
minimum and maximum air flow) or to model 
other building services applications such as 
chilled construction systems or air conditioning 
systems.  
In Fig. 8 a basic structure is shown for whole 
design evaluation process to see how simulation 
is used in design. 
CERIE 262 
 
 
 
 
 
 
the 
 
 
  
Page 150
CERIE 262 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
 
 
*
 Corresponding Author: sajal chowdhury. Author,  
 
 
Fig. 8: structure of the design evaluation process  
BIM (Building Information Modeling) system 
 
6. PARAMETERS EVALUATED BUILDING 
PERFORMANCE TOOLS 
Simulation parameters also communicate more to 
the factory building envelope (glazing properties, 
ventilation rates) and whole building per year 
energy cost. The designer will be interested in an 
indication of the energy consumption that can be 
expected from the building. Simulation can also 
point out problem areas, identify parameters that 
cause the problem and assess the scale of the 
problem. Various types of simulation engine 
(tools) can be used for these purposes and using 
the same simulation tool throughout the design 
process has additional advantages. It is possible 
to pass a model directly from one design stage to 
the next one. It is easier to tackle environmental 
issues in a holistic approach. Some energy 
simulation engine and their functions 
(applications) are mentioned here such as; 
Ecotect, Energy Plus, Dia lux, E-Spr, Radiance, 
Design Builder, etc. From Table. 1, it is noticed 
that various variables depends on the three design 
stages. And it comes one after another and need 
analysis for every component to make a factory 
green.  
Design stage Parametric consideration 
Out line 
design stage 
Orientation, U-values, Heat 
recovery systems, Air change rate  
Scheme 
design stage 
Detailed analysis, Material 
adjustment in overheating areas, 
Lighting strategy 
Detailed 
design stage 
Different heating systems 
Different cooling systems: 
Mechanical, ventilation 
Table. 1: chart various design stage (Christoph 
Morbitzer, 2001) 
 
7.  MODEL CREATION 
 
A number of key developments are part of the 
user Outline Design Stage (ODS) Interface.The 
program interface is structured to permit a step-
by-step, rapid input procedure for the base case 
model and design options. 3D CAD software is 
used to define the model geometry. Detailed 
support databases are provided that distinguish 
building types, room function and zone location 
with the emphasis on rapid user selection (Joyce 
Carlo, 2003) 
 
Fig. 9: a physical factory building computer 
generated model by Ecotect 
Page 151
CERIE 262 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
 
 
*
 Corresponding Author: sajal chowdhury. Author,  
8. RESULTS ANALYSIS 
 
Presentation of performance data is another vital 
element of building simulation interface design. 
This should help the designer to judge the 
environmental performance of the design and 
point out potential problems in the building. This 
includes the following key components: 
• Ranking of the results against benchmarks. 
• Identifying areas in the building that case poor 
performance. 
• Identification of the reasons for unsatisfactory 
performance. 
 Fig. 10; daylight analysis model by Ecotect 
simulation tool 
After performing the simulation, hourly result 
data is read into the database structure. The 
software then determines annual energy figures 
and compares them against benchmarks. It also 
View the energy flows in the building depending 
on, for example, time of day, external 
temperature, occupancy, only certain zone(s) etc. 
 
 
Fig. 11; win speed analysis l by Energy plus 
simulation tool 
 
9. CONCLUSION 
 
Building simulation is currently not an integrated 
element of the design process. Integrating 
modeling would raise awareness of energy and 
environmental issues and give it an adequate 
status in design decision making. 
Finally it may be noted here Building 
performance simulation modeling has come a 
long way since the early seventies. In other 
developing countries, this type of integration is 
going on in full swing for their betterment of 
environmental aspect and them able to make the 
zero carbon community. We have to think about 
“plus o2 community” development instead of 
“zero carbon community” for our upcoming 
generation so that they can live in green space 
with the help of this kind of prediction 
techniques. 
 
10. REFERENCES 
 
1. Christoph Morbitzer, Paul Strachan, Jim 
Webster, Brian Spires, David Cafferty, 
(2001), integration of building 
simulation into design process of an 
architecture practice,  proceedings of the 
Seventh International IBPSA 
Conference, august 2001, Rio de 
Janeiro, Brazil, pp 697-704.  
2. Joyce Carlo, Enedir Ghisi, and Roberto 
Lamberts, (2003), the use of computer 
simulation to establish energy efficiency 
parameters for a building code of a city 
in Brazil, proceedings of the eighth 
International IBPSA Conference, august 
2003, Eindhoven, Netherlands,pp 133-
138. 
3. Augenbroe G, (1992), Integrated 
building performance evaluation in the 
early design stages, Building and 
Environment, Building and 
Environment, Vol.27, No. 2, pp 149-
161. 
4. Larry O. Degelman, Veronica I. 
Soebarto, (1996), Whole building energy 
performance – simulation and prediction 
for retrofit”dept of of Architecture, 
Veronica I. Soebarto, Texas A&M 
University. 
5. Christoph Andreas Morbitzer Dipl.-Ing., 
M.Sc.(2003) ,Towards the Integration of 
Simulation into the Building Design 
Process, Energy System Research Unit, 
January 2003, Department of 
Mechanical Engineering, University of 
Strathclyde. 
0 304 86 0969 1441 21 9215 24 018 28 821 33 6243 84274 32304 803 352 83 657 63 962 442 67245 7204 87 685 18 165 48 6457 91260 96064 0086 70 567 01 047 31 5276 20 079 24 882 29 68 53 448 83 92
304 8
609 6
914 4
12 19 2
15 24 0
18 28 8
21 33 6
24 38 4
27 43 2
30 48 0
33 52 8
36 57 6
39 62 4
42 67 2
45 72 0
48 76 8
51 81 6
54 86 4
57 91 2
60 96 0
64 00 8
67 05 6
70 10 4
73 15 2
30 7.772 30 .3 326 1.11117 0.14 1 18 2.86230 .06 3 03 .6 0 2 70 .0 8 330 .233 03 .8 63 37 .7 2383 .85 2 87.4 531 7.992 6 .1 81 17 2.892 76 .9 11 170 .502 81 .4 2 26 4.653 01 .4 32 7 .9 12 86 .9 811 99 .0 8
1 175 .202 39 .9 711 62 .7 12 53 .2 04 0.5511 83 .6 01 17 0.30 1 190 .82 11 83 .0 327 1.761 18 7.5431 9. 63 23.7 3294 .1429 6.24 26 4.66 11 62 .0 72 69.7 72 1 .0 11 6 6.2711 75.1 92 86.2 5 1 18 4.6436 2.29 18 45 .7 8
22 3.4311 72.8 3 21 1.051 17 0.5011 83 .5 522 3.22 115 9.4911 85.4 5 116 2.2211 88 .4 11 191 .511 18 0.302 83.4 115 3.8226 3.981 19 3.6426 4.8011 67.4 0 11 82 .2 61 17 2.0611 88 .7 2
25 4.952 12.6 4 11 72 .9 72 07 . 9 11 69 .5 8 11 58 .0 7 2 74 .3 6 2 69 .8 61 16 8.77268 .11 2 59 .7 9 2 46 .2 6
20 1.881 74 .7 520 8.831 16 6.87179 .83116 0.332 26 .2 22.461 16 2.382 41 .9 62 77.3 322 7.482 50 .9 311 88 .7 424 6.68 11 53 .5 31 187 .632 42 .4 51 15 7.2724 3.442 68 .2 82 38.2 40 .9 621 8.97 1 17 9.832 95 .0 911 97 .3 13 62 .4 118 11 .0 7
1 89 .6 02 32.4 8 11 54 .3 11 76.6 611 37 .9 32 06 .9 411 62.3 62 15.7 125 6.65 2 55 .4 81 154 .752 1 .631 4 2.7024 9.462 56 .2 9235 .16 2 88 .6 5 26 9.4422 8.9311 53.8 0 2 53.5 12 24 .2 43 6.3011 69 .1 4
11 87 .7 91 88.1 091 .121 7 1.559 7.982 05 .6 12 18.2 419 8.482 17 .2 920 3.821 15 2.132 14 .4 822 9.13 244 .96 11 56.8 225 6.4860 .1423 6.261 15 7.1023 8.5525 7.471 15 3.97 24 9.832 12 .8 8 11 81 .7 54 02 .3 2
21 9.362 30 .1 611 71 .4 01 82 .9 91 16 1.2120 3.6211 58.3 220 3.321 14 2.4920 3.20 11 56 .7 51 16 3.69 22 5.872 62 .4 9 2 43.8 0234 .022 6 .4 6 2 22.7 11 154 .95228 .7022 1.7321 3.06 1 14 0.2821 8.091 66.3 02 25 .5 211 66.5 4
2 04.4 2192 .472 06 .9 018 .2311 48 .8 3 202 .9120 8.541 90 .1 2 2 13 .9 82 17 .0 22 43.6 1 22 7.842 33 .9 41 174 .731 17 0.382 29 .6 91 13 9.7823 1.131 44.5 622 2.1323 3.211 15 7.3011 63.4 72 15 .3 115 9.4820 8. 311 70 .8 91 15 9.4425 0.69
11 94 .8 11 99 .0 7 1 93 .4 21 14 8.461 80 .2 11 15 2.781 81 .0 719 9.541 15 2.3519 2.73115 0.9419 4.8411 57 .5 4 2 52 .7 223 4.562 42.8 0237 .42 223 .7924 7.842 04 .6 421 5.711 16 0.282 37 .9 522 7.642 27 .1 411 81.1 51 80 .4 93 32 .9 618 06 .9 8
22 1.491 16 0.912 00 .6 5 11 64 .1 1 11 72.4 21 82.9 821 0.35197 .44 2 00 .8 61 166 .452 12 .8 711 77.7 91 146 .94116 2.3323 3.95 1 165 .832 41 .9 3 1 15 6.892 13 .6 621 2.2915.1 91 43 .6 62 23 .5 726 9.361 16 3.7832 4.9811 90.0 0
11 88 .1 0 17 4.43 18 9.071 93 .5 92 01.5 91 .15 1 15 7.6220 7.3124 2.2423 6.152 33.5 3116 2.5723 6.5411 40.3 42 27.0 2 20 3.3811 57.4 91 96.1 511 62.1 51 6 5.061 15 7.161 50.5 8
18 9.15 1 14 6.0817 3.681 15 2.8118 7.651 98 .2 995.4 70 0.801 90 .9 31 15 2.89 23 3.87 1 166 .112 40 .6 011 58 .2 02 31 .9 62 42.6 121 5.72 2 02 .3 822 1.952 13 .5 019 6.822 09.0 92 32 .5 81 16 2.8611 75.9 733 1.29 17 55 .0 3
20 4.2916.5 9115 0.32 178 .99 1 83 .7 81 16 7.6019 1.1796 .2 619 5.7711 65 .2 8 24 7.2180.6 52 2 .29 11 79.3 9 2 44.0 12 56 .9 421 2.002 48 .6 124 5.062 24 .1 61 17 3.9624 4.81
17 8.6511 66.6 411 56 .8 21 77 .4 0 1 93 .1 520 3.62 118 0.95 2 74.8 4 11 71.1 921 1.201 16 4.162 06 .6 920 4.7219 2.902 11 .8 72 53 .7 0
11 45 .1 111 51 .8 518 2.831 13 6.251 96 .0 31 161 .05188 .13 11 69.1 82 24.5 71 1 .32252 .98 1 18 0.39 22 2.0922 9.552 24.7 32 16 .8 11 54 .3 021 4.332 29 .9 2 17 85 .4 0
11 93 .8 418 3.261 76 .4 2 1 93.8 3 17 4.881 4.7 4116 5.39 32 4.53 1 18 7.65116 2.6720 8.582 50 .3 321 2.562 59 .6 1 1 16 3.6911 76.8 230 4.17
178 .24115 3.83 1 130 .9216 8.37 1 141 .9819 6.622 30 .5 9 12 13 .4 31 170 .19 28 0.322 25 .8 71 172 .352 32 .5 01 16 5.042 6. 911 55.2 211 54 .1 0 11 56 .5 311 91 .8 24 12 .3 2
11 66 .0 8 17 5.3118 1.741 73.3 0 18 4.55 191 .9923 4.7323 2.0511 97.1 5 123 0.95 2 83 .0 721 4.492 32.8 92 84 .6 2 1 17 1.0737 0. 712 00.1 6
1 15 1.44 17 6.581 14 3.371 81 .4 218 9.301 15 6.84 22 1.71 5 61 .5 8 2 32 .6 02 39 .8 821 6.9611 76 .4 12 44 .0 028 1.58 3 55 .2 818 03 .1 0
11 60 .5 417 8.901 80 .9 31 71.4 8 18 7.177 .0 219 8.7911 47 .5 6 23 1.382 39 .2 027 .7511 57.7 928 5.3511 51.8 91 17 0.21 12 41 .2 9
1 84.6 01 146 .181 78 .0 01 14 5.67 11 43 .1 4 17 27 .2 9172 7.3817 41.6 117 30.0 617 20 .2 3 37 6.561 156 .2026 0.072 2 .3 0 1 17 9.6035 9.7812 16.8 147 9.70 17 75 .3 4
11 74 .7 21 96 .3 8192 .4918 9.531 72 .3 91 14 8.48115 0.6315 6.81 1 731 .91 1 71 4.481 73 .5717 16.5 91 72 5.6517 00.2 61 72 6.25 1 18 1.2136 0. 73 90 .4 5 1 15 7.9811 9.1 5 6 77 .3 05 49 .2 5
16 5.661 16 6.751 74 .7 61 15 7.62 1 130 .96173 .93 1 88 .4 6 17 02 .8 6172 4.071 71 6.8817 14.3 61 73 .711 70 .31 17 10 .6 2 3 27 .1 337 4.833 1 .7 64 00 .6 011 81.9 4 11 99.3 7
21 9.501 89.0 01 167 .101 5 2.381 70 .2 1184 .301 17 2.9918 7.40 17 22 .5 117 09 .9 4 173 8.96 124 1.1511 71.1 232 6.5343 2.3134 7.283 57.2 211 90 .4 43 70 . 50 4.104 71 .0 512 86.8 55 21 .9 317 93 .8 0
19 9.362 11.2 517 8.17 17 3.17 1 75 1.89 17 35.0 7 4 68.4 811 89.0 03 67 .8 339 1.793 84 .2 411 90 .4 31 19 5.1912 19 .1 6
11 60.4 611 66 .6 91 89 .3 31 16 2.4217 8.5511 45.7 718 4.57142 .151 93 .8 42 03 .5 3 1 733 .07172 0.1817 06.1 117 47.8 4 1 17 2.2436 6.511 17 3.1039 6.28 12 39.9 752 3.32
11 68 .7 61 82.3 9116 0.5518 2.521 7 .0 5 1 75 .7 31 15 1.7518 2.78 121 1.64 17 08 .6 3172 3.28 1 69 3.63173 0.9617 06.2 2 125 1.08 36 7.471 18 1.21 3 84.6 121 1.5745 4.40 59 8.997 21 .9 85 82 .3 71 74 2.95
1 162 .29 17 5.3317 4.70114 8.23 20 5.60 17 10 .7 217 30.5 51 714 .7517 21.7 51 1 2.0817 40.9 2 3 77 .7 3 32 1.854 21 .5 132 4.221 20 5.9312 2.3 412 29 .0 4
190 .781 60 .0 7 1 16 3.32 18 3.781 18 1.05 1 740 .19174 0.2117 30.8 31 71 6.561 746 .571 73 8.6217 09.7 11 71 9.11 1 22 0.604 58 .4 34 02.7 41 187 .841 19 9.293 18 .7 14 59.4 63 95 .0 012 11 .5 449 8.574 83 .4 118 06 .4 3
1 70.7 11 135 .62 1 65 .7 111 61 .5 5 174 0.04 17 44.4 2 4 60.2 139 6.73 11 89.8 0 4 79 .1 56 59 .4 8
23 7.15 184 .581 91 .8 417 3.021 63.6 31 86 .2 617 0.991 74.0 3 3 61 .0 73 37 .7 3 33 1.553 85 .7 942 1.3612 16.8 6
21 4.181 67.4 91 186 .95 1 80.8 41 65 .1 6 2 12.4 3 42 8.641 192 .331 18 3.4744 6.341 17 6.58 1 21 6.1412 70.9 65 31 .2 3
22 1.651 86.2 11 71 .2 71 9.2117 2.60115 0.401 69 .7 91 172 .01198 .972 17 .3 2 303 .51 3 41.0 03 22 .3 82 0.49 11 89 .6 9 42 6.47 17 26 .7 2
2 06.9 5174 .841 89 .0 9 1 66.0 91 144 .03161 .561 6.7817 6.9518 5.9011 89 .2 716 0.582 16 .3 2 3 42 .8 04 59 .3 9 1 19 8.23 1 19 6.2441 8.033 42 .0 412 13 .1 552 0.4012 41 .3 85 12 .9 875 8.59
11 78 .1 516 9.63189 .661 17 0.401 15 2.79 19 9.57 2 16 .8 0 8 76 .0 8 1 013 .30 3 17 .2 011 77 .8 6 11 94.6 243 3.7355 4.95
1 76.6 319 5.771 68 .6 81 70 .4 216 5.731 81 .0 7 186 .472 13 .7 219 1.69 4 05.2 7 253 .1335 7.6428 9.351 204 .39 3 39 .7 64 51.9 1 1 19 6.241 23 0.26
18 5.6817 9.78115 8.5617 0.22 144 .461 0.041 63.6 5195 .68 2 19 .8 0 40 2.30 2 80 .5 83 58 .1 2 32 7.973 88 .0 842 1.884 0.165 62 .1 5
11 73.2 21 161 .94170 .631 17 0.47 1 145 .82 11 64 .4 51 63 .9 419 6.4619 8.6219 3.701 96.3 281 .08 40 3.82 4 12 .9 9 95 3.82315 .73 1 19 1.0136 4.544 82 .8 311 76.0 211 99 .9 1 1 23 9.7112 73.3 4
11 89 .0 918 7.76198 .21 1 62.0 51 77 .8 6 194 .0920 3.251 94 .2 7 3 85.0 84 15 .0 039 9.36 2 85 .7 012 23 .1 71 189 .6731 0.023 61.6 63 80 .4 5 50 7.984 3 .4 617 44 .5 1
174 .491 78 .6 0 1 168 .69 11 52 .8 82 05.3 8120 0.6719 1.5299 2.82 36 0.87 252 .8630 3.422 97.5 93 59 .7 03 9 .6 332 4.7911 94.0 212 04 .0 012 03.8 83 92 .7 9 17 44 .6 7
11 65.1 01 77.5 511 59 .6 517 1.881 75 .9 6 1 17 4.501 57 .9 2 18 6.062 11 .1 62 0 .9 0 3 87.0 2 1 064 .29 3 35 .1 912 11 .5 33 8.2037 5.40
172 .1717 3.701 70 .7 917 4.89161 .45 1 186 .77187 .002 04 .0 9 81 1.53 3 83 .8 7 30 2.7842 1.4733 2.611 22 2.33 44 7.7212 40 .8 05 87 .1 417 53 .9 0
1 69.1 31 171 .81115 9.5416 5.711 85 .0 017 4.741 17 0.70 17 0.47 37 8.573 87 .1 53 5.297 36 .3 1 90 7.843 21 .1 727 5.7112 27 .3 83 83 . 020 2.024 27 .6 4 2 99.7 71 20 3.43 12 97.8 4
191 .9911 42 .5 9 158 .39 11 78.7 918 5.1284 .7 5 1 94.5 4 3 72.0 2 3 00 .0 935 3.8731 1.552 15.8 242 2.233 9 .4 139 8.001 20 0.58 1 20 9.6452 8.86 17 67 .1 8
11 78 .5 416 9.32 11 81 .6 918 2.512 06 .9 374 7.79 3 16.1 2 36 9.81 282 .27 35 5.411 19 8.2936 1.6631 2.80 39 2.74 5 36 .5 3
11 77 .8 2 116 0.361 75 .5 4157 .541 16 8.21 1 90 .0 3 32 9.43 44 0.2442 3.9994 0.0936 9.993 39.4 53 09 .2 03 59 .4 1 3 73 .0 612 17.0 648 1.36 17 59 .4 6
21 2.6517 0.95 16 6.721 73.3 0 15 5.80 214 .502 4.1387 .7 41 052 .92 2 73 .3 27 46.6 626 9.04 2 90 .9 112 25 .3 34 50.4 93 79 .4 91 18 8.483 49.1 71 20 4.971 20 4.0051 4.61 12 54.7 096 .8 0
12 09 .5 6 11 74.1 61 71.9 31 75 .5 916 1.241 68 .3 41 66.3 2185 .69 32 2.26 31 7.711 84 .0 834 7.14 12 03.2 145 5.69
1 82.7 711 74 .0 71 72 .4 5 1 16 5.62 1 19 0.071 65 .5 6217 .33 7 81 .1 9 9 09 .4 46 25.3 92 77 .6 91 25 3.86 3 42 .3 0 3 49.7 411 81 .9 94 09 .5 612 08 .6 54 55 .0 912 54 .1 44 54 .0 61 76 6.22
1 15 7.8011 67.0 616 8.98185 .3616 2.131 70 .1 969.6 5182 .0621 6.652 08.2 671 3.48 87 4.42 32 6.123 68.6 741 5.88 3 44 .4 61 18 6.6432 8.081 18 6.3138 7.7212 19.5 352 6.52 17 74 .1 6
11 72 .4 51 155 .5817 0.91 16 1.001 57 .8 8 212 .32 1 87 .7 8 81 9.67275 .22 13 30.5 430 9.804 66.4 339 5.151 19 7.2311 99.2 281.7 21 18 .4 1 12 34 .6 75 3 .5 6
1 77.8 411 79 .4 7 11 77.4 51 0.7 4 1 67.4 1192 .207 1.98 2 53.9 8 3 29 .1 441 6.953 60 .0 03 43 .6 41 21 6.1636 6.74 4 18 .4 617 2.82 51 7.052 43 .7 55 19 .4 5
21 1.441 165 .801 77 .1 7 1 31 8.561 28 2.3112 80 .9 8 12 79.0 0 26 2.41 1 26 6.84 12 23.3 8 1 21 4.791 23 9.16 17 76 .9 2
12 01 .3 2 182 .18 12 12.3 114 11 .2 412 97 .3 71 292 .921 24 9.121 17 3.67 10 30 .9 91 03 0.8810 67.5 31 06 1.0340 1.761 04.1 913 19.8 83 23 .4 7 4 15 .0 820 5.93 69.1 2 51 3.355 23 .2 21 76 5.2217 27 .1 7
24 5.46 19 8.652 05 .6 2 501 .18 311 .1609 6.8925 1.502 97.0 5269 .11 384 .993 3.26 44 1.901 21 7.364 7.031 22 6.971 25 2.67 7 22 .8 5
12 03.9 0 2 10 .0 512 34.3 621 9.364 00 .0 1 12 54 .1 31 2 5.73 29 9.2911 80 .5 446 . 81 13 0.2811 24.9 2 11 75 .9 25 09 .7 2 4 43 .4 91 24 2.31 4 30 .2 2 12 68.4 2
11 88 .7 72 48.8 51 186 .4527 1.7723 .23 135 1.904 28 .2 01 25 5.943 57 .6 3 26 7.842 73.3 73 22 .2 0 13 55.5 946 3.7247 5.831 23 2.474 71 .1 21 23 6.701 21 2.3650 1.361 25 1.8312 82.6 16 46 .9 0
28 7.481 20 2.2330 8.23 23 3.82 4 44.0 946 .401 24 3.243 73.2 985 .811 94 .8 9 440 .4054 8.24 5 05 .9 612 56 .5 65 71.8 1 6 03 .0 36 6.50 17 73 .6 6
3 16.9 2214 .82393 .76120 9.58 978 .66 4 62 .9 34 82.9 344 0.1312 92 .1 412 74 .7 53 41.9 91 239 .96 32 1.73 12 61.3 7 1 416 .64133 1.935 9. 8 1 25 6.415 84 .6 612 81.3 6 13 05.3 6 17 69 .5 6
28 9.53 18 2.86 4 31.4 48 .03 3 77 .2 6 452 .12 52 4.51 53 5.27 5 46 .0 36 6.766 75 .2 86 7.114 38 .0 118 60 .1 9
17 12 .5 8 1 787 .56 18 09 .9 61 70 9.8117 99 .8 31 71 9.92 1 695 .50 16 98 .3 81 73 1.74 1 79 0.021 74 7.1017 27.6 31 77 2.5316 91.2 61 717 .35 17 51 .0 71 7 8.27 1 73 2.02
1 67 4.94 1 65 8.42 1 69 2.17 16 41.3 3 17 52.7 9 17 78.8 9 1 91 8.31
18 20.0 617 67 .6 3 17 78.5 71 7 6 .271 81 6.28 17 95 .2 717 95 .1 2 18 11 .6 41 75 0.411 77 5.5317 62.6 117 52 .9 61 769 .651 76 8.16 17 52.0 71 75 9.70 19 31 .4 3 lux
 184 0+
16 70
15 00
13 30
11 60
99 0
82 0
65 0
48 0
31 0
14 0
Daylight Analysis
Daylighting Le ve ls
Contour Range: 140 - 1840 lux
In Steps of: 170 lux
©  E C O T E C T  v 5
Visible Nodes: 4096
Above Clip Threshold: 100.0%
Average Value: 625.89 lux
Page 152
Conference on Engineering
*
 Corresponding Author: Md. Mohataz Hossain
LEARNING FROM ISLAMIC HERITAGE: AN ASSESSMENT OF 
CLIMATE CHANGE IMPACTS ON MUGHAL BUILDINGS IN 
Md Mohataz Hossain
Department of Architecture, Bangladesh University
 
 
The Mughal built spaces of 400 years old city named Dhaka abridge the future with its ancient Islamic 
heritage and traditions. Every generation should be obliged to preserve the ancient buildings for lear
But due to impact of climates these Islamic buildings of Mughal times require repair every year. Moreover, 
climate change is becoming a matter of urgency for Bangladesh not only to mitigate the level of future 
change by reducing greenhouse gas emissi
heritage to cope with the climate changes that will occur in future. As Dhaka is one of the most vulnerable to 
climate change effects, ancient heritage buildings must be considered with special 
adaptations. The objective of this paper is to identify and analyze the potential physical impacts of climate 
change on the built environment of the Mughal heritage building and possible mitigation strategies that 
should be considered for them in response to climate change risks in Dhaka city. The results shows that 
many decays of the old buildings is increasing with time due to the adverse effect of climate change and 
some particular means to be taken to sustain the historic he
 
Key words: Islamic Heritage, Climate change impacts, Mughal building, Adaptation, mitigation strategies.
 
1. INTRODUCTION 
 
The traditional architectural heritage and structures 
of Bengal are the reflection of bright and glorious 
past of Bengali nation. Dhaka is an indigenous city 
which was largely confined within Mughal forms 
till now. It is an old city with history of over 400 
years. It has got political importance during Mughal 
Period (1608-1764) when Mughal Emperor 
Jahangir established it as the capital of Bengal 
(Hussain, A.B.M., 2007). But many of these 
Islamic heritages are in lack of maint
Bangladesh is recognized worldwide as one of the 
countries, most vulnerable to the impacts of global 
warming and climate change. The risk of survival 
of a particular building type and region will be 
largely dependent on the nature of that building 
on climate changes (Roaf, S et al, 2005). This paper 
is aimed at all those comprehensive studies of 
climate change and those undertaking impact, risk 
and adaptation studies on heritage of Mughal period 
(figure 1) in Dhaka city. 
  
2. OBJECTIVE 
 
a) To identify and analyze the potential physical
impacts of climate change on the built environment
Proceedings of the
 Research, Innovation and Education
CERIE 2011, 11-13 January 2011, Sylhet
,  
DHAKA 
 
 
* and Nazia Afsoon 
 of Engineering and Technology, 
Dhaka, Bangladesh 
ons, but also to develop exclusive plans to adapt our ancient 
care in respect to risks and 
ritage for future generations. 
enance. 
and 
 
 
 
Figure 1: Development of Dhaka city in various 
Periods (Source: Khan, F. 1997)
 
of the heritage building of Mughal 
suggest possible mitigation strategies that should be 
considered for them in response to climate change 
risks in Dhaka city. 
 
3. METHODOLOGY 
 
Literature related to climate change and other 
aspect together with expert views from climate and 
heritage specialists were extensively reviewed and 
assessed. This integrated and broad methodology 
was made feasible by concentrating the study on the 
risks of Islamic heritage in four selected areas from 
the old and new part of Dhaka city: Lalbag and 
Begum Bazar areas from the Old Dhaka part 
Mughal Period          Bangladesh Period
 
 
i  2011 
, Bangladesh 
 
 
l , 
  it  i t l i  
 i   l rning. 
 i   r. r r, 
 ti t  t  l l f f t r  
 t 
     t  t l r l  t  
l i l i t  f li t  
 t t i  t t 
 it .  r lt  s t t 
  li t    
, ti ti  tr t i s. 
 
 
period. b) To 
  
 
 
t   
  
 
 
  
 
as 
 i  
Page 153ISBN: 978-984-33-2140-4
  
well as University and Mohammadpur areas from 
New Dhaka Part. The names of the Mughal 
structures that are analyzed are shown with figure
2, 3 and 4 as follows: 
 
Figure 2: Mughal Structures of the Old Part of 
Dhaka: Lalbag and Begum Bazar area (Source: 
Photography by the authors)
 
Figure 3: Mughal Structures of the New Part of 
Dhaka: Mohammadpur and Unive
(Source: Photography by the authors)
 
s 
 
 
 
rsity area 
 
4. ISLAMIC HERITAGE IN 
BANGLADESH: MUGHAL 
BUILDINGS 
 
The mughal rule in Bengal is over now, but it’s 
memory still survives in large variety of buildings 
erected through a period of about two hundred 
years. Their expression of building activity through
numerous mosques changes the skyline of Dhaka 
city. In Mughal buildings, there are secular 
buildings (Fort and fortifications, Palaces, 
Hammams, Katras, Bridges) and religious buildings 
(Mosques, Tombs, Qadam Rasuls, Eidgahs). In this 
great creative period rulers were sympathetic 
towards the local context and culture and mosque 
architecture went through extensive elaboration and
perfection. It was recognized as brick-
Figure 4: Surveyed Mughal structures of Old and 
New Dhaka (Source: drawn by the authors, 
Structures Numbers from figure 2 and 3)
 
They also invented chun-surki (lime
brick) to replicate the effect of sand stone. 
example, Sat Gumbag Masjid and Lalbagh Fort
were the most tangible evidence of the past socio 
economic, cultural and religious activities. 
Therefore these heritages should be conserved and 
integrated to the life of contemporary society.
 
5. CLIMATE CHANGE IN CONTEXT 
OF DHAKA CITY 
 
Currently, the most widely accepted climate change 
scenarios predict increases of between 1
3.5°C for the global annual average temperatures 
(Cassar, M. 2005). Bangladesh is one of the worst 
affected among the countries that are facing the 
early impact of climate change. In 
5 
6 
7 
1 
2 
 
 
style  
 
 
 powdered 
For an 
 
 
°C and 
Dhaka, the 
8 
3 
4 
Page 154
  
capital of Bangladesh, the Key climate challenges 
for the historic buildings are: increasing rainfall, 
flooding, more extreme wet/dry cycles of weather 
or environment, coastal erosion and sea level rise. 
The notable direct impacts are: increased decay of 
stonework and organic growth due to higher rainfall 
in the rainy season. Indirect impacts are: increased 
demand for water elsewhere in Bangladesh could 
lead to develop the reservoirs or aqueducts; 
pressure at popular tourist sites due to increased 
tourism in warmer, drier summers; Upgrading of 
flood defences, drainage systems, changing patterns 
of cultivation and woodland expansion affects 
buried archaeology, renewable energy. In 
Bangladesh, average temperature has registered an 
increasing trend of about 1°C in May and 0.5°C in 
November during the 14 year period from 1985 to 
1998. Highest hourly recorded rainfall 162 mm and 
recorded daily rainfall 300 mm. In some hot days of 
summer, temperature goes up to 40ºC in the city 
and surrounding areas. Normally, rainfall cools 
down the weather (figure 5), but it is erratic. 
 
Figure 5: Threads of climate change reported for 
cultural World Heritage properties (Source: 
UNESCO World Heritage Centre, 2007) 
According to IPCC in their recently published 
Fourth Assessment, the following changes have 
been observed in climatic trends, variability and 
extreme events: 
• The annual mean rainfall exhibits increasing 
trends in Bangladesh. Decadal rain anomalies are 
above long term averages, since 1960s. 
• Serious and recurring floods have taken place 
during 2002, 2003, and 2004. Cyclones originating 
from the Bay of Bengal have been noted to 
decrease since 1970 but the intensity has increased.  
• Frequency of monsoon depressions. 
• Water shortages has been attributed to rapid 
urbanization and industrialization, population 
growth and inefficient water use, which are 
aggravated by changing climate and its adverse 
impacts on demand, supply and water quality. 
• The precipitation decline and droughts has 
resulted in the drying up of wetlands and severe 
degradation of ecosystems. 
 
 
Figure 6: Interfered natural drainage system due to 
rapid expansion of the city (2004) and Digital 
Elevation Map of Dhaka City (Source: Internet) 
Due to rapid expansion of the city, the natural 
drainage system was interfered with in some places 
and in some places destroyed (figure 6) and creates 
severe water logging problem. Thus, while 
considering the heritage of Dhaka city, climate 
change  has its direct as well as indirect effect on 
the environment, economy and society and the 
impacts are also interrelated (figure 7) among them. 
 
6. IMPACT ASSESSMENT 
 
6.1 Environmental Impacts 
The hot humid climate of Bangladesh supports 
prolific growth of vegetation and the burnt clay 
products. When the buildings loses its functional or 
economic use, the nature starts its process of 
destruction: vegetation grows, roots penetrate deep 
into the structure, dampness spreads all over the 
place, the wooden members rot, surface peels off 
with all its creative artistic works, roof system 
collapses and soon it turns into as earthen mound. 
The logged water at the site, damages the 
foundation and the building structure. To preserve 
the historical artefacts within Islamic heritage 
building, the indoor temperature should be 21°C, 
and relative humidity (RH) of 35% (dew-point 5°C) 
in the winter and 50% (dew-point 10°C) in the 
summer. It is also desirable that short-term (daily) 
variations in RH are no greater than 5%. But from 
the field survey, while considering all the desire 
situations, it is found that indoor-outdoor thermal 
difference (Table 1) is not so satisfactory. From the 
Damage survey (figure 7), it is found that the wall 
surface in Diwan-i-Am and Bibi Pari’s Tomb 
showed damages due to saltpetre action and rising 
dampness. 
Table 1: Comparative Analysis of the thermal 
condition of Mughal structures (Source: Field 
Survey) 
Name of the 
Islamic heritage 
Average indoor-
outdoor Air 
Temperature 
Difference (deg 
Celsius) 
Average indoor-
outdoor Relative 
Humidity 
Difference (%) 
Average 
indoor-
outdoor Wind 
flow 
Difference 
(m/s) 
Average indoor-
outdoor Dew 
point Difference 
(deg Celsius) 
22%
18%
16%
14%
8%
8%
6%
8%
Hurricane and storm
Sea level rise
Erosion
Floods
Rainfall pattern change
Outdoor painting damage
Droughts
Others
  Surveyed 
Structures 
Page 155
  
Audience Hall 
(museum), 
Lalbagh fort 
3.1 2% 
Tomb of Bibi 
Pari, Lalbag fort 1.1 9% 
Lalbagh Fort 
Mosque 2.1 5% 
Mridha Mosque, 
Lalbagh 0.2 4% 
Kartalab Khan 
Mosque, Begum 
Bazaar 
0.1 3% 
Bara Katra and 
Chhoto Katra 
gateways 
0.6 4% 
Sat Gumbad 
Mosque, 
Mohammadpur 
0.3 6% 
Unknown tomb, 
Mohammadpur 1.9 8% 
Old Eid Gaah, 
Dhanmondi 0.1 1% 
Haji Khawaza 
Shahbaz Mosque 
and Tomb 
2.5 6% 
 
Though this has now been treated, transfusing 
silicon solution above the ground level, but the 
damages occurred again and again and it had to be 
renewed repeatedly. This old structures 
warmer in winter and cooler in summer. Thatch in 
particular has a very high thermal insulation value 
Terraces can also be more energy-
detached houses which lose more heat through their 
larger surface area. Historic building materials are 
also often more durable than their modern 
replacements and can be more cost
energy terms.  
Figure 7: Damage map of the Existing Mughal 
structures (Source: field survey)
 
Wind: Wind driven rain and sand, transported salt, 
can give impacts like penetrative moisture into 
porous cultural heritage materials, structural 
damages, collapses, deterioration of surfaces due to 
erosion (UNESCO World Heritage Centre, 2007). 
Climate and Pollution acting together: pH 
precification, changes in deposition of pollutants 
can make impacts such as brick recession by 
dissolution of carbonates, blackening of materials 
and corrosion of metals (Harris, D.J. 1999).
Changes in rainfall patterns: Increasing levels of 
rainfall pose a threat to semi-ruinous buildings. 
Rain water penetration to wall heads results in 
5 6 
7 
 
3
 
0.2 0.4 
0.2 1.2 
0.5 1.6 
0.4 1.8 
0.1 0.4 
0.2 1.2 
0.1 2.2 
0.7 1.8 
0 0 
0.6 1.9 
can stay 
efficient than 
-effective in 
 
 
 
 
disfiguring and damaging algal growth, staining 
and damage to brickworks. 
Flooding: It presents a significant threa
historic environment and causes irreversible effects 
such as damage to brick work from excessive 
wetting and contamination from flood water. All 
roads become blocked and thus cause 
inaccessibility. 
 
6.1.1 Direct Impacts: Drier, warmer summers 
(more frequent drought conditions): Droughts can 
make risk to organic archaeological preservation, 
increased risk of fire in historic buildings. 
Maintenance of these historic buildings with parks 
and gardens will not be sustainable in water 
shortages (e.g. lawns, herbaceous borders).
Wetter rainy season (more periods of intense rain): 
It may cause flash flooding and ero
archaeology and buildings and flo
river valley especially in old Dhaka part. 
Traditional drainage systems (roof and ground) may 
fail and renovating of rain water disposal system 
(figure 8) can damage the historic fabric or 
character of building.   
 
Figure 8: Impact of wetter rainy season (Source: 
photography by the Author) 
   
Figure 9: Impact of wetter rainy season (Source: 
photography by the Author)
 
Rising temperatures overall: New 
insect pests and invasive plant species
frosts) affect historic parks, gardens,
and landscapes such as the Lalbag fort
requires new installations of air-cond
climate control. 
Low 
 
Moderate 
 
High 
 
t to the 
 
 
sion affecting 
oding of the 
 
 
 
or increased 
 (fewer 
 buildings 
. Thus 
itioning and 
Page 156
  
Figure 10: Impact of heat increasement in Dhaka 
(Source: Ahmed, K. A., 1996, newly drawn by author
   
Increase in storm episodes: Damage
buildings as well as veteran trees may be caused
by extremes of wind and rain. It also cause lo
and damage to ancient woodland. 
 
6.1.2 Indirect Impacts: Switch to renewable 
energy sources or adaptations: Micro
installations adversely affect historic
character.  
Energy measures: Introduction of 
regulations like any changes of building elements 
require unnecessary or inappropriate 
historic buildings. Inherent sustainability  a
embedded energy in historic b
infrastructure either is not reco
contributing to the ‘ carbon economy’ 
pressure to demolish  ‘inefficient’ ol
and infrastructure.  
 
6.2 Economic Impacts 
Tourism, one of the most important and rapidly 
growing service industries, is an important part of 
economic sector in Bangladesh. Climate change has 
the potentiality to radically alter tourism patterns by 
inducing changes in destinations and seasonal 
demand structure (Scott et al., 2008).
are twofold – a) how to integrate the complex 
climate science in economic models and b) how to 
develop economic models that will predict 
economic conditions in future. In order to predict 
the next 100 years, we need economic data from the 
previous 1000 years or so.  
 
6.2.1 Direct Impact:  Among the notable Mughal 
structure of this paper the Lalbagh Fort that have 
already been conserved and opened up for general 
public which is also a source of income for 
Bangladesh. 
Table 2: Economic impacts in mughal structures 
(Source: Scott, D., et al. 2008)
Name Type Location Visito
day
Lalbagh Fort 
(Audience Hall, 
Tomb of Bibi Pari 
and other 
structures) 
Mughal fort 
Complex 
62 no ward, 
Lalbagh,  
Old Dhaka 
6500
(Friday, 
Sat
2000
(Monday
Thursday)Others seven 
mughal structures 
Mughal 
heritage 
Old and New 
Dhaka 
)   
 to Mughal 
 
ss of 
-generation   
 fabric and   
new building 
changes to 
nd 
uildings and 
gnised  as 
increasing 
der buildings 
 The problems 
. 
rs/ 
 
Income 
(tk)/week 
-7000 
urday) 
-2100  
-
 
22,9462.5 
Nil Nil 
 
Here ‘Table 2’ shows that there is 
loss if the heritages are conserved considering 
the climate change. 
 
6.2.2 Indirect Impact: According to 
Stern, from formal economic models, that if we do 
not act, the overall costs and risks of climate change 
will be equivalent to losing at least 5% of global 
GDP each year, now and forever. If a wider range 
of risks and impacts is taken into account, the 
estimates of damage could rise to 20% of GDP or 
more (Stern, 2006) which will be a nightmare for 
the government of Bangladesh to recover the total 
damage due to climate change. So, the historic 
buildings like mughal architectures could have 
negative impact with the economic crisis. 
 
6.3 Social Impacts 
The most obvious social scenarios relate to 
demographic changes, among which, changes in 
population size and distribution are probably the 
most commonly used. Future population changes of 
Dhaka city are likely to have a significant influen
on the natural resources and heritages that are 
managed by local government in this capital city.
 
6.3.1 Direct Impact: Poorly 
inappropriate energy-saving measures can seriously 
detract from the historic character and fabric of 
mughal buildings, whereas well designed measures 
can make considerable savings with little or no 
damage. Mughal Heritage welcomes the 
Government’s commitment to reduce the emissions 
that contribute to global warming, increase fuel 
efficiency and exploit renewable energy sources. 
Nevertheless, policies for adaptation and mitigation 
should be taken into account when policy is being 
formulated. 
 
6.3.2 Indirect Impact 
The informal situation of the whole sale shopping, 
especially at Borokatra and Chotokatra of old 
Dhaka (Hossain, M. S. 2008), may be beneficial to 
commerce both retail and wholesale, and local 
manufacturing. These uses make great demand
service infrastructure, traffic (trucking), dilapidated 
houses (ware-houses), cheap manual labour 
(migrants) etc (Asiatic Society of Bangladesh 
1993). Changes of the historic sites to cope with the 
climate change may cause interruptions
social structures of this part of the city.
 
7. RECOMMENDATIONS 
 
The study of this paper shows that many decays of 
the old mughal buildings is increasing with time 
due to the adverse effect of climate change and 
some particular means to be taken to sustain the 
historic heritage for future generations.
  Surveyed  
Structures 
economic 
Nicholas 
 
ce 
 
designed or 
s on 
 of the 
 
 
Page 157
  
The approach to improve the climatic environment 
in historical buildings in such conditions, was to 
raise the temperature in cooler areas of the building, 
Increasing temperature causes a necessary 
reduction of the RH level. The ideal is to maintain 
RH for the collection environment at less than 70%, 
slightly (5%) less than the threshold RH for 
significantly increased microbial activity (Shin M., 
Franciza T., 2001). Introducing secondary glazing, 
for example, can significantly improve thermal 
performance (English Heritage 2002). Lower 
heating levels could be adopted in some publicly 
accessible historic buildings, such as Lalbag fort or 
Kartalab Khan mosque and the use of humidistat 
controls rather than thermostats may in some cases 
reduce the demand for energy. New additions and 
amendment in Gadget or building construction act 
with considering climate change impact is a 
necessary step to save the mughal structures as well 
as other historic structures. All the mughal building 
should be enlisted with rating climate change 
impact on them.  It is important to work with others 
to protect or, if not feasible, then record these 
significant historic sites that are at risk as a direct 
result of climate change. It is also needed to 
promote further research into the direct impact of 
climate change on the historic environment, 
including the development of impact indicators and 
adaptation strategies. We need to review the 
management of our own city as well as our country 
as a whole in terms of climate change, investigate 
low carbon and alternative energy systems that can 
be used in these historic buildings to reduce carbon 
emissions, ensure that buildings occupied or used 
by Mughal Heritage are maintained and operated to 
optimize their environmental performance and 
ensure that any new buildings constructed on our 
estate achieve ‘excellent’ energy performance 
ratings. Close coordination among BWDB, 
DWASA and DCC is necessary. Adequate human 
and organizational capacity is need to be developed 
with adequate technical, business, management, 
regulatory skills and appropriate enabling 
environment. Also, Participation of all stake holders 
– private actors, public agencies, NGOs, CSOs and 
grassroots organizations, can be the option of 
implementation strategies. 
 
8. CONCLUSION 
 
The rich heritage of old Dhaka, specially the 
mughal heritage, is under great danger and are 
being destroyed (Asiatic Society of Bangladesh, 
1993, p.120).  There are some challenges to 
mitigate the climate change impacts on Mughal 
structures. Identifying vulnerable sites and what to 
prioritize, ‘how to treat old brick and other 
traditional materials affected by increased rainfall’, 
‘are current conservation methods adequate?’, 
increased need for maintenance, ‘where will 
resources be found?’, decisions on the viability of 
certain mughal sites – these all are the possible 
challenges to implement sustainable and adaptable 
strategies for it. The Copenhagen negotiation in 
2009 was focused on separate international funds 
for adaptation and innovation. These funding can be 
a support for mitigating the adaptations of mughal 
structures. In parallel with international 
negotiations initiatives at the domestic level are 
needed for improving the use of financial resources 
and quality of technology transfer (Climate Change 
Cell, 2007). Further research can be conducted on 
various issues of climate change impact upon 
historic building of Dhaka as well as Bangladesh to 
sustain these Islamic heritages with a scope of 
learning from these structures for future generations 
and maintain the presence of the past in the present. 
 
REFERENCES 
 
1.    Ahmed, A.S.M. (2006). Mosque Architecture 
in Bangladesh, UNESCO, Bangladesh. 
2. Alam, M., Rabbani, M.D.G. (2007). 
Vulnerabilities and Responses to Climate Change 
for Dhaka. Environment & Urbanization, Vol. 19: 
81-97. 
3. Asiatic Society of Bangladesh. (1993). 
Architectural conservation Bangladesh. 
Proceedings of the seminar on Architectural 
Conservation on 17 April 1993, Cultural Secretary, 
Asiatic Society of Bangladesh, Dhaka. 
4. Climate Change Cell. (2007). Climate Change 
and Bangladesh. Department of Environment, 
Government of the People’s Republic of 
Bangladesh. 
5. Cassar, M. (2005). Climate Change and the 
Historic Environment. London: University College 
London, Centre for Sustainable Heritage. 
6. Chapman, H. P. (2002). Global warming: The 
implications for sustainable archaeological resource 
management. Conservation and Management of 
Archaeological Sites. 5(4); 241-245. 
7. Harris, D.J. (1999). A qualitative approach to the 
assessment of the environmental impact of building 
materials. Building and Environment. 34: 751-758. 
8. Hossain, M. S. (2008). Preventive Maintenance 
Strategy of Bara Katra, Journal of the Dept. of 
Architecture: Protibesh, Volume 12 No.2. DAERS, 
BUET, Dhaka, July 2008. 
9. Hussain, A.B.M. (2007). Architecture: A History 
Through The Ages, Asiatic Society of Bangladesh, 
Bangladesh. 
10. Karim, A. (1964). Dhaka: The Mughal Capital.  
Dhaka, pp 8-13 
Page 158
  
11. Khan, F. (1997). Conservations Issues of 
Historic Mosques of Dhaka City: Pre-Mughal and 
Mughal Period, unpublished M.Arch thesis paper, 
Department of Architecture, BUET, Dhaka, 
Bangladesh. 
12. Rahman, S. M. (2007). Archaeological 
Heritage, Asiatic Society of Bangladesh, 
Bangladesh 
13. Roaf, S., Crichton, D. & Nicol, F. (2005). 
Adapting Buildings and Cities for Climate Change: 
A 21st Century Survival guide, Architectural Press, 
Oxford, Uk. 
14. Scott, D., et al. (2008). Climate change and 
tourism – Responding to global challenges. United 
Nations World Tourism Organization, Madrid. 
15. Shin M., Franciza T. (2001). Sustainable 
Climate Control for Historic Buildings In Hot And 
Humid Regions, PLEA 2001 - The 18th Conference 
on Passive and Low Energy Architecture, 7-9 
November 2001, Florianópolis – Brazil. 
16. The Aga Khan Trust For Culture. (1990). 
Architectural & Urban Conservation In The Islamic 
World.  Paper In Progress, Volume One, The Aga 
Khan Trust For Culture, Switzerland. 
17. UNESCO World Heritage Centre. (2007). 
Climate Change and World Heritage, Report on 
predicting and managing the impacts of climate 
change on World Heritage and Strategy to assist 
States Parties to implement appropriate 
management responses, Vilnius, Lithuania. 
Page 159
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Sajal K Adhikary 
E-mail: sajaladhikary@yahoo.com 
MODELING GROUNDWATER FLOW AND ADVECTIVE 
TRANSPORT OF SALINITY IN THE UNCONFINED AQUIFER OF 
SOUTHWEST BANGLADESH 
 
 
Sajal K Adhikary*1 and Prof. Ashim Das Gupta2, Mukand S Babel3, Roberto S 
Clemente4 and Sylvain R Perret5  
1Department of Civil Engineering, Khulna University of Engineering & Technology (KUET), 
Bangladesh 
2, 3, 4, 5Division of Water Engineering and Management, Asian Institute of Technology (AIT), 
Thailand 
 
ABSTRACT 
 
The southwest coastal region of Bangladesh is in a very difficult situation compared to other parts of the 
country due to direct interaction of the fresh groundwater with the saline surface water from coastal river and 
sea. A three-dimensional finite-difference groundwater flow model was employed to investigate the variety 
of hydrogeological conditions and to simulate the groundwater flow characteristics and dynamic flow 
exchanges between the rivers and the underlying aquifers in the southwest unconfined aquifer of 
Bangladesh. The MODFLOW modeling package in the framework of Groundwater Modeling System 
(GMS) was applied for this purpose. Stratigraphic modeling results of sub-surface lithology demonstrate that 
the upper unconfined aquifer of the region is extended up to a depth of 150m below the ground surface 
containing two distinct layers. Natural recharge from precipitation formed the main input to the aquifer 
system and abstraction from wells was the main output. The two-layer model was calibrated in two steps 
using observed groundwater levels: a steady state calibration against 1992 data, and a transient calibration 
and validation for 1992-2005 data. The simulation results show that the fluctuations of hydraulic heads are 
dependent on seasonal variation in recharge from precipitation. Advective transport of salinity was assessed 
by coupling the modeling package MT3DMS with MODFLOW in the framework of GMS. The model result 
reveals that the saline front lies close to the sea and has very little effect on groundwater. Also, the dynamic 
interaction simulation depicts that salinity intrusion from coastal rivers, in the form of recharge water, is the 
predominant factor affecting groundwater system rather than the intrusion directly from the sea side. 
 
Keywords: Advective Transport, Conceptual Model, Dynamic Interaction, GMS, Groundwater Flow 
 
1. INTRODUCTION 
 
Worldwide, groundwater is usually the main source 
of freshwater in the coastal region because of 
limited potable freshwater supply, where saltwater 
intrusion is a frequent and widespread problem 
(Werner and Gallagher, 2006). Therefore, its 
development and management on a regional scale is 
essential for a developing country like Bangladesh, 
which often experiences the lack of surface water 
resources having adequate quality to meet the rising 
freshwater demand. But it is recognized that the 
most significant aspect of any water resources 
planning and management strategy is to ensure 
adequate supply of water with acceptable quality 
(Nobi and Das Gupta, 1997). The coastal belt 
surface water systems in the southwest region of 
Bangladesh have already been affected by salinity 
due to the direct interactions of freshwater in the 
tidal rivers and saline water in the sea (Khan, 2002) 
which has direct impacts on the environmental 
sustainability in the region. Salinity concentrations 
in the tidal rivers of coastal belt vary seasonally 
depending on the upstream freshwater flows from 
the Ganges. Adel (2001) reported that the surface 
water availability in Bangladesh is reduced by 50% 
with a corresponding 60% upstream freshwater 
diversion (Farakka Barrage) in the Ganges, which 
causes a proportionate decrease in groundwater 
recharge in the downstream. Thus, salinity is one of 
the major causes of water quality degradation for 
both surface and groundwater resources in the 
region because of its geographical location as well 
as uncontrolled abstraction from underlying 
aquifers (Rahman et al., 2000; Halcrow, 1993).  
Page 160ISBN: 978-984-33-2140-4
  
It is widely accepted that both surface and 
groundwater systems are inherently linked to each 
other. Thus, uncontrolled development or 
contamination of one obviously affects the other 
(Sophocleous, 2002). So, the groundwater systems 
in this region may be affected by salinity intrusion 
from the sea due to over-exploitation from the 
aquifer. Study suggests that the underlying aquifer 
in this region is dynamically linked with the salinity 
affected rivers and surface water bodies (Nobi and 
Das Gupta, 1997; Halcrow, 1993) which may 
further degrades the groundwater quality through 
dynamic interaction mechanisms. In addition, 
further groundwater development and sea level 
changes may aggravate the situation (IPCC, 2007; 
Ranjan et al., 2006). Finding solutions to such 
ubiquitous water resources problems need thorough 
investigations and analysis of the overall system in 
an integrated manner. So, the present study is an 
attempt to investigate the dynamic flow 
characteristics of groundwater systems and 
advective transport of salinity into the aquifer 
system in the southwest coastal region of 
Bangladesh by applying three-dimensional 
groundwater modeling technique. 
 
2. MATERIALS AND METHODS  
 
2.1 Hydrogeological characteristics of 
the study area 
The study area is located in the south-west region 
of Bangladesh lying between 22.200 to 24.120 north 
latitudes and between 88.560 to 89.980 east 
longitudes. The area covers about a total area of 
about 16985 sq. km which is surrounded by the 
Ganges-Padma River in the north, the Gorai-
Madhumati-Haringhata-Baleswar River system in 
the east, the international border between 
Bangladesh and India in the west and the Bay of 
Bengal in the south. The area is enclosed by 20 
hydrological sub-catchments delineated by the 
Institute of Water Modeling (IWM), Bangladesh 
during regional model development phase (Fig. 1). 
The SRTM digital elevation model reveals that the 
area is dominated by flat topography, which varies 
from 18m to 2m above MSL with a gradual drop 
from northwest to southern coastal-belt directions. 
At extreme south, the coastal part has very low and 
flat topography varying between 0m to 2m above 
MSL. The annual average rainfall is 2000 mm of 
which approximately 75% occurs during the 
monsoon season (June to September) and almost 
90% occurs in the wet period (April to September). 
The mean annual temperature is 260C. The relative 
humidity also varies from 70% in March to 89% in 
July. Depending on these parameters, the average 
pan evaporation is also high and generally exceeds 
the rainfall rates in dry season (October to March).  
 
Fig. 1. Location of the Study Area in the Southwest 
Region of Bangladesh 
 
The southwest region of Bangladesh is underlain by 
alluvial sediments of the Bengal Basin, laid down 
by the Ganges-Brahmaputra River system. The 
sediments become progressively older with depth 
and lithologically range from clay and silt, to fine, 
medium and coarse sand, which are unconsolidated 
or lightly compacted. Only those sediments down 
to 300m depth are of interest hydrogeologically. 
Previous studies reported that there are no faults or 
folds within these hydrogeologically significant 
sediments (Halcrow, 1993). In general, the upper 
clay layer is comparatively thick in the coastal part. 
In most of the areas, the composite and deep 
aquifer sequences are found in the 150-300 m depth 
range. The upper surface layer of mainly clay and 
silt characterized by high porosity but low 
permeability, which has poor aquifer properties and 
thus unsuitable for significant groundwater 
development. The intermediate layer has moderate 
to good aquifer properties and capable of producing 
reasonable amount of water. However, the main 
aquifer (lower unit) is the most important source of 
groundwater for irrigation, which is characterized 
by high porosity and moderate to high permeability 
and thus, it can provide large quantities of water to 
shallow and deep tube wells. 
 
2.2 System conceptualization 
The conceptual model helps to simplify the field 
problem and to organize the associated field data so 
that the system can be analyzed more readily 
(Elkrail and Ibrahim, 2008). A total of about 52 
borelogs are available from the groundwater circle 
Page 161
  
of Bangladesh Water Development Board (BWDB) 
covering the whole study area containing individual 
layer lithology along the depth. This allows taking 
the full advantage of GMS® (Groundwater 
Modeling System) to build a conceptual model 
within its framework. GMS® is a graphical user 
interface (GUI) for using MODFLOW and 
MT3DMS and stratigraphic modeling of aquifer 
systems. It has a powerful GIS interface for use in 
different phases of groundwater modeling. 
Interpretations of individual lithology followed by 
semi-automatic preparation of cross-sections and 
automatic fence-diagram reveals that an unconfined 
aquifer exists up to 150 meter below the ground 
surface characterized by two distinct aquifer layers 
(Fig. 2). All sorts of spatially distributed data such 
as location of groundwater level observation well, 
recharge, aquifer hydraulic parameters, top and 
bottom surface of two aquifer layers, bottom of 
riverbed etc. is mapped using GIS by digitizing 
point data, line or polygon features. The topography 
of the upper layer is spatially variable from north to 
south direction and is assigned into the model by 
integrating the digital elevation model (DEM) data 
of the area compiled from SRTM public domain 
database by kriging technique. The surface 
topography has influence on the head pattern of the 
upper aquifer layer and frequently receives rainfall 
recharge. The hydrogeological setting of the study 
area is characterized by large horizontal and 
vertical heterogeneity. Mainly three external 
sources of water influence the recharge conditions 
of the flow system such as rainfall recharge, later 
inflow from west boundary and river bed leakage in 
some sections.  
 
  
 
 
 
Fig. 2. (a) Location of Borelogs (b) Hydrogeological Profile along N-S direction (A-A) (c) Fence Diagram 
(c) 
(b) (a) 
Page 162
  
2.3 Development of numerical model 
The aims of the numerical model were to check and 
assess the validity of various interpretations 
regarding the flow system. These include (i) the 
location and type of flow-system boundaries, (ii) 
the location of recharge areas and (iii) variations in 
interpretation of hydrogeological framework. The 
three-dimensional groundwater flow model 
MODFLOW-2000 and three-dimensional solute 
transport model MT3DMS were used for 
simulating groundwater flow and salinity transport. 
Both models are applied in a two-step flow and 
transport simulation in the framework of GMS®. 
MODFLOW computes the hydraulic heads and 
cell-by-cell fluxes during the flow simulation, 
which is subsequently used by MT3DMS as the 
flow field for executing transport simulation. In 
order to prepare the finite-difference model grid, 
the aquifer system domain was divided into 232 
rows and 162 columns and each cell having 1 km x 
1 km grid size in the horizontal plane. The model 
consists of 2 layers (up to 150m depth) simulating 
the principal hydrostratigraphic units’ presents the 
upper regional unconfined aquifers. The top layer 
(layer #1) is characterized by composite mixtures of 
clay, silt, very fine sand and fine to medium sand 
and lumped into one unit (0-60m). The bottom 
layer (layer #2) is represented by relatively coarser 
materials like fine, medium and coarse sand lumped 
into it (60-150m) (Fig. 2). Thus, both layers are 
hydraulically well-connected to each other (Nobi 
and Das Gupta, 1997). Surface and bottom 
elevations of both layers are interpolated from 
DEM and boreholes data. The model boundaries 
were represented by the available hydrological 
features adjacent to and within the model domain 
(Fig. 1). A time dependent specified head boundary 
is applied along the Ganges River in the north side 
and Gorai-Madhumati-Haringhata-Baleswar River 
systems in the eastern side of the study area using 
water level data of different gauging stations. In the 
south side, the model boundary is extended up to 
Hiron point to establish the sea boundary and a time 
dependent specified head boundary is provided 
using the Hiron Point water level measurement. 
The west boundary of the model domain is located 
along the international border between Bangladesh 
and India and a general head boundary is assigned 
along this side. For this purpose, the known 
hydraulic heads from the observed groundwater 
level of several monitoring wells located along the 
border is used. The river package of MODFLOW 
simulates the effects of flow between aquifer and 
rivers. Water levels in the rivers were used from the 
different gauging stations within it. The recharge 
rates as in (Halcrow, 1993) were assigned on the 
top layer only using the MODFLOW recharge 
package. There was a lack of enough pumping test 
data in the area to be used as aquifer hydraulic 
property. So, the hydraulic conductivity is initially 
distributed on the basis of available pumping test 
data and lithological knowledge. 
 
3. RESULTS AND DISCUSSIONS 
 
3.1 Steady-state simulation and 
calibration of groundwater flow model 
Initially, the developed groundwater flow model is 
simulated and calibrated under steady-state 
condition for the average base condition in 1992. 
The observation data used in the calibration process 
was the water table elevations from observation 
wells. Although, steady-state condition does not 
occur in the practical field situation, but it gives a 
very initial estimates of model parameters. It also 
helps to check the mass balance and to check the 
assigned boundary conditions in the model.  
 
 
Fig. 3. Observed Vs. simulated heads in (a) top 
layer (b) bottom layer 
 
Steady-state simulation was run to estimate the 
initial head distributions to be used in the transient 
simulation. Model calibration in groundwater 
modeling is often required because of the 
(a) 
Obs. well = 71 
RMSE = 1.1 
MAE = 0.9 
ME = - 0.1 
(b) 
Obs. well = 43 
RMSE = 0.9 
MAE = 0.8 
ME = 0.1 
Page 163
  
unavailability of reliable field measured data to 
estimate the aquifer flow characteristics. During 
calibration, traditional trial and error technique is 
followed. GMS® has powerful graphical user 
interface (GUI) with strong GIS linkages for 
assigning model parameters either into cell-by-cell 
or zonal based approach. Parameters are assigned 
into the model by dividing the whole model domain 
into a number of zones for both layers assuming 
similar hydrogeological properties as the cell-by-
cell input is a complicated task especially in a large 
groundwater model. In steady-state calibration, the 
initial values were adjusted within a reasonable 
limit to obtain a good agreement of the computed 
and observed water table in 1992 and quantified by 
statistical means. The calibrated hydraulic 
conductivities (20 zones) vary from 9 to 14 m/day 
for top layer and 18 to 40 m/day for bottom layer. 
To evaluate the calibration performance, scatter 
diagrams are prepared for each layer and a 450 line 
drawn to represent the perfect correspondence 
between observed and simulated values. For this 
model, the estimated RMSE for top and bottom 
layer was 1.1m and 0.9m respectively (Fig. 3), 
which is very small. Once these criteria were 
satisfied, the model was considered calibrated. It 
can be mentioned here that these criteria of 
calibration were met with the residual mean being 
close to zero. 
 
3.2 Transient simulation and calibration 
The transient simulation was run to replicate the 
flow characteristics in the aquifer by introducing 
the pumping well. The discharging through the 
pumping well was simulated as specified flow 
boundary using specified pumping rate. The 
pumping well is considered a sink and is 
represented in the model by a node. Initially, model 
calibration is performed using the available 
observed water table data for a period of 1992 to 
2002. The remaining data from 2003 to 2005 is 
used for validation purpose. The whole simulation 
period is divided into 28 stress periods containing 
two periods (dry and wet) in a year. Recharge is 
assumed to occur only in wet period (May to 
October) and no recharge is considered in dry 
period (November to April) based on rainfall data 
analysis. Each stress periods are further divided 
into 6 time steps with a total of 168 time steps. 
Thus, each time step consists of 30 days with a total 
simulation time of 5113 days. In transient analysis, 
the head distributions or aquifer response at 
different simulation periods under existing stresses 
are found out. Also, the input required by the solute 
transport model (MT3DMS) is generated by 
simulating the flow model in transient condition. 
Transient calibration is carried out using the same 
model parameter structures and initial head 
distributions computed in steady state calibration. 
During transient calibration, storage parameters are 
assigned in the same zone for both layers. The 
observed and simulated heads are then carefully 
compared and parameters are adjusted by trial and 
error method to obtain a good agreement between 
them. Initially, storage parameters are adjusted to 
obtain good match. Also, vertical conductivity is 
adjusted very little. The horizontal hydraulic 
conductivity was not changed. However, only one 
parameter is adjusted at a time because it facilitates 
to understand the effect produced by the change of 
each parameter. After modifying of parameters 
every time, the model is re-run. Several simulations 
have been carried until a good match between 
observed and simulated heads are obtained. From 
transient analysis, it is observed that without 
modifying the horizontal hydraulic conductivity 
values good match between observed and computed 
heads is obtained, which depicts that reasonable 
calibration was achieved in the transient-state. It is 
found that most of the observation wells show good 
agreement with the computed heads and the 
calibrated hydrograph follows the average trend of 
the observed hydrograph. The calibrated values of 
storage coefficient vary from 0.002 to 0.004 for 
both layers. However, there are some monitoring 
wells where poor agreement between observed and 
simulated heads is noticed. The study area 
constitutes a large number of small rivers and water 
bodies which have influence on groundwater level. 
But practically, it is quite impossible to incorporate 
all these in the model domain. It may also be due to 
aquifer anisotropy and heterogeneity. Sensitivity 
analysis shows that the response of the modeled 
system is more sensitive to variation in recharge 
than to hydraulic conductivity and storage 
parameters. 
 
3.3 Simulations of salinity transport 
In the present study, chloride concentration is 
considered as a proxy of salinity. The boundary 
conditions of the saltwater intrusion model depend 
on the boundary conditions used in the flow model. 
In salinity intrusion model, the specified head 
boundary in flow model is changed to specified 
concentration boundary based on the observed 
salinity measurements. As the salinity varies during 
dry and wet season, boundaries are also assigned 
accordingly in both periods. Along the general head 
boundary of flow model along the international 
border, a zero concentration boundary is assigned. 
Any inflow coming from the sea has a specified 
chloride concentration of 24000 mg/L which is 
established by the observed salinity data at Hiron 
point station. For Mongla, Chalna and Khulna 
points in Passur River, time dependent specified 
concentration boundary is established by the 
Page 164
  
observed salinity in those stations. The initial 
salinity concentration is assigned based on the 
groundwater salinity data from the very few 
observed stations. The specified concentration of 
recharge water is taken as 300 mg/L in the coastal 
part of the area where surface water bodies are 
already affected by salinity intrusion. 
 
 
0
5000
10000
15000
20000
25000
0 200 400 600 800 1000
Distance from Sea Boundary (m)
Sa
lin
ity
 
(m
g/
L) 
 
 
 
 
1
 
Fig. 4. Distance of saline front from Hiron Point 
 
As MT3DMS is designed to be used in conjunction 
with any block-centered finite difference flow 
model, it facilitates to couple it with MODFLOW 
to develop solute transport model. Thus, the spatial 
discretization used by solute transport model is 
same as that of flow model. As the transport model 
uses the transient flow model, the stress periods of 
transport model is kept same but each time step 
(one month) of flow model is divided further into 
60 transport steps in transport model. The smaller 
transport steps are taken to ensure the stability 
criteria of salinity intrusion model. Only advective 
transport is considered to simulate salinity transport 
into the groundwater system. In the advection 
process, salinity is transported as the same speed as 
the average linear velocity of groundwater. The 
simulation is carried out for the same period of flow 
model spanning over 1992 to 2005 (5113 days). 
The model results show that the saline front lies 
close to the sea boundary (Hiron Point) and the 
salinity is intruding by recharge water from affected 
surface water bodies through dynamic interaction. 
 
4. CONCLUSIONS 
 
A three-dimensional integrated river-aquifer model 
was developed to investigate the groundwater flow 
characteristics and salinity encroachment 
phenomena into the unconfined aquifer of 
southwest Bangladesh. For this a flow and transport 
model developed by MODFLOW and MT3DMS is 
coupled to develop a saltwater intrusion model. 
Only the advection process is considered for 
simulating saltwater intrusion. The results indicate 
that salinity intrusion from saline surface water 
bodies is found to be the predominant factor in 
affecting the groundwater system through recharge 
water rather than the seawater intrusion directly 
from the sea side. The study conclusively proves 
that in the integrated river-aquifer systems in the 
coastal region, the interactions between the rivers 
and the underlying aquifer systems have significant 
influence on the flow and salinity intrusion into the 
overall system. 
 
5. REFERENCES 
 
1. Adel, M.M. (2001), Effect on water resources 
from upstream water diversion in the Ganges 
basin, Journal of Environmental Quality, 30 
(2), pp. 356-368. 
2. Elkrail, A.B. and Ibrahim, A.E. (2008), 
Regional groundwater flow modeling of Gash 
River basin, Sudan, Journal of Applied 
Sciences in Environmental Sanitation 3(3), pp. 
157–167. 
3. Halcrow (1993), Southwest area water 
resources management project (SWAWRMP) 
Final Report, FAP-4, UNDP/ADB 
(BGD/88/038), Ministry of Irrigation, Water 
Development and Flood Control, Government 
of Bangladesh, Vol. I-XI, August 1993. 
4. IPCC (2007), Climate Change 2007 - Impacts, 
Adaptation and Vulnerability. Working Group 
II contribution to the Fourth Assessment 
Report. Intergovernmental Panel on Climate 
Change (IPCC). 
5. Khan, A.T. (2002), MIKE-11 application for 
salinity intrusion in southwest Bangladesh, 
M.Engg. Thesis, Asian Institute of Technology 
(AIT), Bangkok, Thailand. 
6. Nobi, N. and Das Gupta, A. (1997), Simulation 
of regional flow and salinity intrusion in an 
integrated stream-aquifer system in coastal 
region: southwest region of Bangladesh, 
Ground Water, 35 (5), pp. 786-796. 
7. Rahman, M.M., Hassan, M.Q., Islam, M.S. and 
Shamsad, S.Z.K.M. (2000), Environmental 
impact assessment on water quality 
deterioration caused by the decreased Ganges 
outflow and saline water intrusion in south-
western Bangladesh, Environmental Geology, 
40 (1-2), pp. 31-40. 
8. Ranjan, P., Kazama, S. and Sawamoto, M. 
(2006), Effects of climate change on coastal 
fresh groundwater resources, Global 
Environmental Change, 16, pp. 388-399. 
9. Sophocleous, M. (2002), Interactions between 
groundwater and surface water: the state of the 
science. Hydrogeology Journal, 10, pp. 52-67. 
10. Werner, A.D. and Gallagher, M.R. (2006), 
Characterization of sea-water intrusion in the 
pioneer valley, Australia using hydrochemistry 
and three-dimensional numerical modeling, 
Hydrogeology Journal 14 (8), pp. 1452-1469. 
Page 165
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Christopher Blazo,  
E-mail: christopher_blazo@yahoo.com 
MUNICIPAL WASTEWATER TREATMENT AND HEAVY METAL 
REMOVAL BY CONSTRUCTED WETLANDS 
 
 
Christopher Blazo 
Bangladesh University of Engineering and Technology (BUET), Dhaka 
 
 
In the world where life thrives on water, it is important to have methods that will secure the quality of water 
and provide the nourishment that the environment requires. The study assesses the performance of 
constructed wetlands to treat municipal wastewater and heavy metal removal efficiency for different plant 
species. For this study, ten small beds are constructed with locally available four different plant species and 
soil. Municipal wastewater and the synthetic water are treated by constructed wetlands and the pollution 
removal efficiency is estimated. Also to understand the settling behavior of the effluent water the Routine 
Water Test is performed in undisturbed state. The results of this study show that the constructed wetlands 
can be utilized to remove impurities as well as heavy metals from municipal wastewater and synthetic water 
efficiently. The impurities include Nitrogen (N), Phosphorus (P), Total Suspended Solids (TSS), 
Biochemical Oxygen Demand (BOD), Chemical Oxygen Demand (COD) and Heavy metals such as Arsenic 
(As), Chromium (Cr), Lead (Pb). The values of pH, Color, Turbidity, Hardness, Chloride, Iron, TDS and 
TSS are found satisfactory to be disposed in Inland Surface Water, Public sewer at secondary treatment plant 
and Irrigated land. Particularly, the performance by the plant species Palm (Light palm) and Fern (Pteris 
vittata) are noteworthy. 
 
Key words: Wetland, Wastewater, Heavy Metal, Efficiency, Plant Species 
 
1. INTRODUCTION 
 
Natural wetland systems have often been described 
as the “earth’s kidneys” because they filter 
pollutants from water that flows through on its way 
to receiving lakes, streams and oceans. Constructed 
wetlands are treatment systems that use natural 
processes involving wetland vegetation, soils, and 
their associated microbial assemblages to improve 
water quality. Constructed wetland can be 
considered as wetlands built to fulfill desired 
objectives. White (1998) defines a constructed 
wetland as "purpose built structures, utilizing the 
predominantly natural materials of soil water and 
biota, which perform the desired physical, chemical 
and biological processes and functions of natural 
wetlands to achieve desired objectives". Unlike 
natural wetlands, which are confines by availability 
and proximity of the wastewater source, 
constructed wetlands can be built almost 
everywhere, including lands with limited uses and 
other system components can be managed as 
required include vegetation (Reed et al., 1988).  
 
Wetland plants are an important component in 
constructed wetlands. The roles that they can fulfill 
or to which they can contribute to are numerous. 
Wetland plants have adaptations that allow the 
transportation of oxygen to the roots and rhizomes 
(Brix, 1997). Not all plants are capable of removal 
of contaminants. There are some special plants such 
as Canna lily, Light palm, Pteris vittata, 
Xanthosoma violaceum etc plays important role in 
the removal of pollutants. For experiment local 
plants can be used in the constructed wetland just to 
compare the removal efficiencies. 
 
Constructed wetlands are an innovative, biological 
solution to wastewater treatment. While offering a 
high degree of protection and reliability, they 
eliminate the need for discharging treated effluent 
into surface water that can adversely affect 
environment. Constructed wetlands were first 
initiated in Europe in the 1970s. Since then, the use 
of wetlands has evolved from a research concept to 
an accepted pollution control technology 
worldwide. 
 
2. OBJECTIVES 
 
In this study we observed the effects of pollution on 
a constructed wetland to determine the wetlands’ 
ability to reduce pollution levels. In summary, the 
following objectives are observed: 
Page 166ISBN: 978-984-33-2140-4
  
1. To determine the removal efficiencies of 
selected physical and chemical characteristics of 
Total Suspended Solids (TSS), Biochemical 
Oxygen Demand (BOD), Chemical Oxygen 
Demand (COD), Nitrogen (N), Phosphorus (P) for 
wastewater. 
2. To determine the removal efficiencies of the 
heavy metals such as Arsenic (As), Chromium (Cr) 
and Lead (Pb) for synthetic water.  
3. To compare the removal efficiencies of 
different plant species. 
4. To understand the behavior of the effluent 
water after treatment and when kept undisturbed. 
 
3. RESEARCH METHODS 
 
3.1 Introduction 
 
The removal efficiencies of some locally available 
plants such as Palm (Light palm), Fern (Pteris 
vittata), Kalaboti (Canna lily), Kochu (Xanthosoma 
violaceum) for municipal wastewater and synthetic 
water were observed in this study. When the 
wastewater flows through the system, the 
suspended solids and trace matters are settled and 
filtered. Plants absorb the organic and trace matters 
also. These organic materials and nutrients 
absorbed by the wetland plants on the stems and 
roots are used as food. Plants provide much of the 
oxygen needed by the organisms to live and grow. 
Plant roots keep the rocks or soil loose so that water 
can flow through easily. The whole operation of the 
study was done by: 
 ►Bed preparation 
►Planting and Seeding 
►Wastewater Collection 
►Wastewater Testing 
►Sample Collection 
►Storage and Analysis 
 
3.2 Construction of Wetlands 
 
Constructed wetlands can serve as wastewater 
treatment systems and always consist of shallow 
ponds or channels planted with aquatic 
macrophytes. They can treat a variety of 
wastewaters by the microbial, biological, physical 
and chemical processes (Hamilton, et al., 1997; 
Reed, 2000; USEPA, 2000a; García, et al., 2004; 
Voeks and Rahmatian, 2004). 
 
The pilot scale experiment is of subsurface flow 
system in which eight tubs with four different 
plants and two tubs with soil were used. 
Constructed wetland consists of three layers: 
a) Lower layer of crushed bricks 
b) Middle layer of sand 
c) Upper layer of soils 
3.2.1 Bed Preparation: In total there were ten tubs 
used for the study having the same dimensions. All 
the tubs had the similar side slope of approximately 
1H : 3V. Each plant type was planted in two 
different tubs to understand the standard deviation 
of removals. Only the Horizontal Flow Subsurface 
System was considered in this study. So the total 
removal efficiency of a wetland cannot be predicted 
from this study. 
 
Dimension of the Tubs: 
 
Diameter of the tubs 
 ► Top: 9 inches 
 ► Bottom: 6 inches 
 
Height of the tubs (in total) = 10 inches 
Height of Coarse aggregate (brick chips) = 1 inch 
Height of Fine aggregate (sand) = 1 inch 
Height of Soil = 7 inches 
 
3.2.2 Plantation and Seeding: The two most 
popular methods of vegetating cells are planting 
and seeding. Both methods can be successful 
depending on the procedure undertaken. Prior to 
introducing vegetation to the wetland cells, the 
following preliminary steps should be taken 
(Tousignant et al.1999). 
a) At least 10cm of topsoil (or wetland 
subsurface) should be placed, in an 
uncompacted condition, on the cell 
floor. 
b) The substrate of the wetland should be 
level. 
c) The substrate can be left prepared for 
some time prior to planting and/or 
seeding. 
d) However it should be protected form 
erosion and treated for weeds. 
e) Make sure that the wetland substrate 
is moist (not flooded) just prior to 
planting (or seeding). 
 
Once the vegetation gas started growing, care 
should be taken to ensure that weeds are controlled. 
Due to the lack of dense vegetation at the start of a 
wetland cell, weeds may invade the cell and 
become a major problem. 
 
3.2.3 Tree Plantation: Plants were collected from 
a nursery situated in the Dhaka University area for 
this study. Maturated plants were collected though 
they were taken care for about one month before 
the commencement of the study. There were two 
tubs for each of the plants. 
 
 
 
 
Page 167
  
Plant Species: 
 Palm (Light palm), Fern (Pteris vittata), 
Kalaboti (Canna lily), Kochu (Xanthosoma 
violaceum) 
 
3.3 Raw Wastewater Collection 
 
The removal efficiencies of the plants were studied 
for two different types of water sample. At first the 
raw sewage water was utilized to understand the 
removal behavior and then the synthetic water. The 
raw sewage water was collected from a gutter near 
the Farmgate Residential Area. The synthetic water 
was a mixture of three different effluents of heavy 
metal with the tap water of BUET. The heavy metal 
effluents were: Arsenic (100ppb), Chromium 
(100ppb), Lead (500ppb).  
 
The first requirement for any sampling system is 
that it must provide a representative sample. 
Samples of waste collected from different sources 
fairly represent the whole waste from which they 
were collected. For each experimental time about 
15 liters sample was collected in bucket.  
 
3.4 Wastewater Treatment 
 
After the collection of sample water each time it 
was treated step by step.  
a) At first the opening of the tub was 
closed with plastic papers and clay soil and then the 
water was poured into the tubs for treatment. 
b) The water was contained for about two 
hours in the tub. 
c) Then the clogging materials were 
removed from the opening and the treated water 
was collected in containers. 
d) The treated water was then collected 
and was taken to the laboratory. 
3.5 Methods of Sampling 
 
Water quality parameters measurement may be 
done either in their sources or in their laboratory. 
To measure the parameters in the laboratory 
requires sampling in an appropriate manner. 
Analysis through sophisticated equipment does not 
always ensure correct results because it only 
analyzes the sample that is brought into the 
laboratory. So, the acceptability of any laboratory 
test result depends on the sampling procedure. The 
sample must also be kept in such a manner so that 
the concentrations of different contaminants remain 
unchanged during transportation and storage. The 
analytical techniques to be used will affect the 
sample size taken, the type of sample bottle and 
also the method of storage. 
 
3.6 Preservation and Storage of Samples 
 
Preservation techniques retard chemical and 
biological changes that continue after sample 
collection. Sample preservation is difficult because 
almost all preservatives interfere with some of the 
tests. So the sample should be analyzed as quickly 
as possible without using any chemical 
preservatives.  During storage certain constituents 
could be subjected to loss by adsorption on the 
sides of glass container walls. So, plastic bottles are 
preferred for storage of samples for analysis of 
metal ions as well as other parameters as plastic 
materials are less likely to contaminate the sample 
than glass bottles. Samples of different cells were 
than marked separately. All treated samples were 
kept in the refrigerator on which tests for 
determining different water quality parameters were 
performed. 
 
 
3.7 Sample Analysis 
 
The sample analysis was performed in three 
different stages. At every stage the removal 
efficiency of different parameters were performed. 
The parameters observed in different stages are 
mentioned following: 
 
1st Stage  Nitrogen (N), Phosphorus (P), 
Chromium (Cr), Total 
Suspended Solids (TSS), 
Biochemical Oxygen Demand 
(BOD), Chemical Oxygen 
Demand (COD) 
2nd Stage  Heavy Metal Removal for 
Arsenic (As), Chromium (Cr), 
Lead (Pb) 
3rd Stage   Routine Water Test such as 
pH, Color, Turbidity, Hardness, 
Chloride, Iron, TDS, TSS 
 
4. RESULTS AND DISCUSSION 
 
4.1 Results 
 
The performance observed for the raw wastewater 
treatment and the synthetic water treatment are both 
mentioned in the following pages by form 
histograms. 
 
 
 
 
 
 
 
Page 168
  
38.75 38.33
20.00
31.65
0
10
20
30
40
50
Palm Fer n Kalaboti Kochu
Figure 
4.1: Efficiency of Nitrogen removal 
19.50
85.25
37.50
73.25
0
10
20
30
40
50
60
70
80
90
100
Palm Fer n Kalaboti Kochu
Figure 
4.2: Efficiency of Phosphorus removal 
26.50 35.15
70.25 67.55
0
10
20
30
40
50
60
70
80
90
100
Palm Fer n Kalaboti Kochu
Figure 
4.3: Efficiency of TSS removal 
99.00 93.48
33.48
99.00
0
10
20
30
40
50
60
70
80
90
100
Palm Fer n Kalaboti Kochu
Figure 
4.4: Efficiency of Chromium removal 
82.65 83.15
48.75
68.15
0
10
20
30
40
50
60
70
80
90
100
Palm Fer n Kalaboti Kochu
Figure 
4.5: Efficiency of COD removal 
96.55 88.97 79.41 83.82
0
10
20
30
40
50
60
70
80
90
100
Palm Fer n Kalaboti Kochu
 
Figure 4.6: Efficiency of BOD removal 
 
ARSENIC REMOVAL
79.99 87.74 87.14
65.67
87.61
0
20
40
60
80
100
Soil Palm Fern Kalaboti Kochu
Ef
fic
ie
n
c
y 
(%
)
Figure 
4.7: Average Arsenic Removal Efficiency 
CHROMIUM REMOVAL
64 61.67
53.67 50.33
62
0
10
20
30
40
50
60
70
Soil Palm Fern Kalaboti Kochu
Ef
fic
ie
n
c
y 
(%
)
Figure 
4.8: Average Chromium Removal Efficiency 
LEAD  REMOVAL
98.6 98.38
97.07
94.09
97.27
91
92
93
94
95
96
97
98
99
100
S oil Palm Fern Kalaboti Kochu
Ef
fic
ie
n
cy
 
(%
)
 
Figure 4.9: Average Lead Removal Efficiency 
Col or  S e t t l e me nt
11.59 39.07
75
52.2719.8
0
20
40
60
80
100
Soil Palm Fer n Kalaboti Kochu
T r ees
Figure: 
Color Settlement for undisturbed sample 
Tur bidi t y  S e t t l e me nt
90.11
42.86
94.9 96.63
75.48
0
20
40
60
80
100
Soi l Palm Fer n Kalaboti Kochu
T r ees
 
Figure: Turbidity Settlement for undisturbed sample 
I r on S e t t l e me nt
100
50
88
43
75
0
20
40
60
80
100
Soi l Palm Fer n Kalaboti Kochu
T r ees
 
Figure: Iron Settlement for undisturbed sample 
 
Page 169
  
4.2 Discussions 
 
Table 4.1: Summary of Removal Efficiencies in 
Percent (%) 
Parameters Palm Fern Kalaboti Kochu 
N 38.75 38.33 20.0 31.65 
P 19.5 85.25 37.5 73.25 
Cr 99 93.48 33.48 99 
TSS 26.5 35.15 70.25 67.55 
BOD 96.55 88.97 79.41 83.82 
COD 82.65 83.15 48.75 68.15 
From the results obtained the following decisions 
can be taken: 
 Nitrogen removal is higher by Palm 
 Phosphorus removal is higher by Fern 
 Chromium removal is higher by both 
Palm and Kochu 
 TSS removal is higher by Kalaboti 
 BOD removal is higher by Palm 
 COD removal is higher by both Palm 
and Fern 
 
Table 4.2: Summary of Average Removal 
Efficiency for Heavy Metals (%) 
Parameters Soil Palm Fern Kalaboti Kochu 
As 79.99 87.74 87.14 65.67 87.61 
Cr 64 61.67 53.67 50.33 62 
Pb 98.6 98.38 97.07 94.09 97.27 
From the results obtained the following decisions 
can be taken: 
 Arsenic removal is higher by Palm 
 Chromium removal is similar for Soil, 
Palm and Kochu 
 Lead removal is higher for all the 
plant species and Soil 
 Soil has a very good removal 
capability for Heavy Metals 
 
Table 4.3: Summary of Routine Water Test  
Parameters Soil Palm Fern Kalaboti Kochu 
Chloride 50% 
removed 
50% 
removed 
50% 
removed 
40% 
removed 
30% 
removed 
pH, 
Hardness Unchanged Unchanged Unchanged Unchanged Unchanged 
Color, 
Turbidity, 
Iron, TDS, 
TSS 
Increased Increased Increased Increased Increased 
 
From the results obtained the following decision 
can be taken: 
 Chloride can be removed by the plant 
species and Soil 
 pH and Hardness remain unchanged 
 Color, Turbidity, Iron, TDS, TSS 
values increase due to the presence of 
soil particles in the effluent water 
 
Table 4.12: Summary of Settlement for 
Undisturbed Effluent Undisturbed Effluent 
From the above discussion the following decision 
can be taken: 
 Chloride and Hardness do not settle 
when kept undisturbed 
 Color has a Low to High range of 
settlement for the plant species and 
Soil 
 Iron and Turbidity have a high 
settlement when kept undisturbed for 
the plant species and Soil 
 
5. CONCLUSIONS AND 
RECOMMENDATIONS 
 
5.1 Conclusions 
 
The major findings of the study are mentioned 
briefly stage by stage following: 
At First Stage: 
a) Palm (Light palm) has greater removal 
efficiency for Nitrogen, BOD and COD. 
b) Fern (Pteris vittata) has greater removal 
efficiency for Phosphorus and COD. 
c) TSS and Chromium removal is higher 
for Kalaboti (Canna lily) and Kochu (Xanthosoma 
violaceum) respectively. 
At Second Stage: 
a) Palm (Light palm) has greater removal 
efficiency for Arsenic (As) and Chromium (Cr). 
b) Kochu (Xanthosoma violaceum) has 
greater removal efficiency for Chromium (Cr). 
c) Lead (Pb) removal is higher for all the 
plant species and soil. 
d) Vegetation has the ability to remove 
Arsenic but does not have the ability to remove 
Chromium and Lead. 
At Third Stage: 
a) The chloride concentration is reduced by 
the vegetation and soil. 
b) pH and Iron concentration remain 
unchanged. 
c) Color, Turbidity, Iron, TDS and TSS 
values increase due to the presence of soil particles 
in the effluent water. 
Parame
ters Soil Palm Fern 
Kalab
oti 
Koch
u 
Chlori
de, 
Hardne
ss 
Uncha
nged 
Unch
anged 
Unchan
ged 
Unch
anged 
Unch
anged 
Color Low Low Medium High Medi
um 
Iron, 
Turbidi
ty 
High High High High High 
Page 170
  
d) Chloride and Hardness do not settle 
when kept undisturbed. 
e) Color has a Low to High range of 
settlement for the plant species and Soil. 
f) Iron and Turbidity have a high 
settlement when kept undisturbed for the plant 
species and as well as Soil 
 
5.2 Recommendations 
 
The following recommendations can be made to 
extend the scope of present study: 
 1. The study can be conducted for at least 
one year to obtain seasonal variation in removal 
efficiency. 
 2. The study can be conducted to 
understand the behavior of sunlight and night. 
 3. The heavy metal removal efficiency can 
be further studied for Industrial wastewater. 
 4. Further study is recommended for 
removal of pollutants for flowing wastewater and 
standing wastewater in wetland that are not 
compared in this study. 
 5. This study can be further extended to 
remove pollutants from Industrial, Textile and 
Agricultural liquid waste. 
 6. The aggregate size and type can be 
varied to understand the effect of aggregate in 
removal of pollutants. 
 
6. REFERERENCES 
 
1. Abel-Gawad, S. T. (1991). “Reuse of Drainage 
Water Project: Management in the Eastern Nile 
Delta.” Reuse Report 30, Drainage Research 
Institute. 
2. Alam, Md. J.B.; Islam, M.R.; Muyen, Z. and 
Mamun, M.; Islam, S. (2007). Water quality 
parameters along rivers. Int. J. Environ. Sci. Tech., 
4 (1), 159-167. 
3. Andersson JL, Bastviken SK and Tonderski KS 
(2005) Free water surface wetlands for wastewater 
treatment in Sweden- nitrogen and phosphorus 
removal. Wat. Sci. Tech. 51:39-46 
4. Bachand PAM and Horne AJ (1999) 
Denitrification in constructed free-water surface 
wetlands: I. Very high nitrate removal rates in 
macrocosm study. Ecol. Eng. 14:9-15 
 
5. Bachand PAM and Horne AJ (2000) 
Denitrification in constructed free-water surface 
wetlands: II. Effects of vegetation and temperature. 
Ecol Eng. 14:17-32 
6. Barbosa, A. E. and Hvitved-Jacobsen T. 1999. 
Highway runoff and potential for removal of heavy 
metals in an infiltration pond in Portugal 
7. Boesch D, Hecky R, O'Melia C, Schindler D and 
Seitzinger S (2006) Eutrophication of Swedish seas. 
In. Naturvardsverket (Swedish EPA), Stockholm 
Braskerud BC (2001) The influence of vegetation 
on sedimentation and resuspension of soil particles 
in small constructed wetlands. J. Environ. Qual. 4 
8. Craft CB (1997) Dynamics of nitrogen and 
phosphorus retention during wetland ecosystem 
succession. Wetlands Ecology and management 
4:177-187 
9. Crites, R. W. 1992. Design criteria and practice 
for constructed wetlands. Proceedings IAWQ 
Wetlands Systems Conference, Sydney, Australia. 
10. Crites, R. W. 1992. Design criteria and practice 
for constructed wetlands. Proceedings IAWQ 
Wetlands Systems Conference, Sydney, Australia. 
11. Kadlec RH and Knight RL (1996) Treatment 
wetlands. Wat. Sci. Tech. 44:237-244 
12. Knight RL, Jr VWEP, Borer RE, Jr RAC and 
Pries JH (2000) Constructed wetlands for livestock 
wastewater management. Ecol. Eng. 15:41- 55 
13. Hamilton WA (1987) Biofilms: Microbial 
interactions and metabolic activities. In: Fletcher 
M, Gray TRG, Jones JG (eds) Ecology of microbial 
communities. Cambridge University Press, 
Cambridge, pp 361-385 
14. Kadlec RH and Knight RL (1996) Treatment 
wetlands. Wat. Sci. Tech. 44:237-244 
15. Knight RL, Jr VWEP, Borer RE, Jr RAC and 
Pries JH (2000) Constructed wetlands for livestock 
wastewater management. Ecol. Eng. 15:41- 55 
16. Liehr SK, Anastasiou C, Classen JJ and Rice 
JM (2000) Comparison of design strategies for 
nitrogen removal from animal waste using 
constructed wetlands. In: Wetland systems for 
water pollution control, Florida 
17. Reed, S. C., Crites R. W., and Middlebrooks E. 
J. 1995. Natural Systems for Waste Management 
and Treatment. 2nd ed. McGraw-Hill Inc., New 
York, NY., USA 
18. Tousignant, P.E., Oliver, F. and Sarah, H. 
(1999), “Guidence Manual for the Design, 
Construction and Operation of Constructed 
Wetlands for rural application in Ontario”. Wat. 
Sci. Tech. 32(5):151-168 
19. White, G., Kuginis, L., Beharrel, M. and 
Young, C. (1996), Urban Strom Water 
Management, in water, pp. 48-52: July/August 
Page 171
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Kaish A. B. M. Amrul,  
E-mail: amrul.cuet@gmail.com 
NUMERICAL INVESTIGATION OF THE BEHAVIOR OF 
RETROFITTED FLEXURAL CRACKED BEAM WITH EXTERNAL 
PLATE BONDING  
 
Kaish A. B. M. Amrul*1, Alam Md. Rabiul2, Hassan Md. Kamrul3, Ullah Shah 
Neyamat4  
 
1Research Fellow, Housing and Building Research Institute, Dhaka, Bangladesh. 
2Associate Professor, Department of Civil Engineering, Chittagong University of 
Engineering & Technology, Chittagong, Bangladesh. 
3Graduate Student, Universiti Kebangsaan, Malaysia. 
4Graduate Student, Politecnico di Milano, Lecco, Italy. 
 
 
The aim of this paper is to study the effectiveness of using “External Plate Bonding” in flexural retrofitting 
of reinforced concrete (RC) beam. A simply supported rectangular RC beam is considered for this study. 
The steel plate and the CFRP (Carbon Fiber Reinforced Polymer) sheet are taken into consideration as 
bonded plates for retrofitting of RC beam. General purpose finite element program (ANSYS 11.0) is used to 
carry out non-linear analysis of uncracked, cracked and retrofitted RC beam. Based on the results obtained 
from numerical investigation it is seen that cracking in RC beam reduces the load carrying capacity of the 
beam. When retrofitting technique using steel or CFRP plate bonding externally is applied, stresses at the 
crack tip reduce significantly. Therefore, external plate bonding could be effectively applied in retrofitting of 
RC beam. 
 
Key words: CFRP sheet, Flexural crack, Plate bonding, Non-linear analysis, Retrofitting, Steel plate  
 
1. INTRODUCTION 
 
Reinforced concrete (RC) is one of the most widely 
used construction material in both the developing 
and developed countries since more than a century. 
RC structures are often suffering damage before 
reaching their intended design life. There are 
several factors responsible to this distress of these 
structures, such as improper design, faulty and 
quick construction, change in building usage, 
overloading, natural disasters (like earthquake, 
Tsunami, Cyclone, Flood etc.), various 
environmental effects like corrosion, fire, etc. 
Buildings, which are deteriorated due to such 
factors, need quick attention and scientific approach 
in finding the causes of distress and also need 
suitable remedial action to make the building 
functional. 
Beam is one of the primary elements of the frame 
structure building and is mainly responsible for the 
lateral stiffness of the structure. A beam fails when 
the load acts on it is higher than the load for which 
it is designed (Kaish and Hassan, 2008). It may also 
fail under service load due to loss of its stiffness 
caused by various deteriorating factors discussed 
above. To mitigate the unexpected failure various 
methods are proposed to retrofit the beam. External 
post tensioning, plate bonding, ferro-cement 
laminating and RCC jacketing are among them. 
External plate bonding technique is one of the 
efficient and well-known method of repairing or 
retrofitting of beam (Devid et. al., 1998). Steel plate 
is the traditional material used in the retrofitting of 
flexural beam member. But its low corrosion 
resistance and handling problem forced engineering 
community to look for alternatives (Gorji, 2009). 
Fiber Reinforced Polymer (FRP) emerges as an 
effective alternative of steel plate. It becomes a 
popular material for structural re-strengthening 
because of its high tensile strength, low weight and 
high corrosion resistance properties (Hollaway and 
Leeming, 1999). 
 
Several experimental and analytical investigations 
have been conducted on the use of FRP sheets as 
flexural retrofitting/re-strengthening of RC beams 
Page 172
ISBN: 978-984-33-2140-4
  
(Shahawy et. al., 1996; Saadatmanesh et. al., 1997; 
Sharif et. al., 1994; Chajes et. al., 1995; Khaloo and 
Gharchorlou, 2005 and Panazopoulou et. at., 2001). 
The behavior of re-strengthened beam is also 
available in terms of load-deflection, load-strain, 
failure patterns and structural ductility (Gorji, 
2009).  
 
Laboratory and numerical studies show the efficacy 
of externally bonded FRP plates in enhancing the 
flexural capacity of RC beam. However, there are 
limited studies conducted on the behavior of 
flexural cracked RC beam retrofitted with external 
plate bonding using steel plate or FRP sheet. In this 
paper numerical investigation to the behavior of 
flexural cracked RC beam retrofitted with 
externally bonded steel plate or CFRP sheet are 
reported. 
 
2. FINITE ELEMENT MODELING OF 
RC BEAM 
 
Simply supported reinforced concrete beam of ten 
feet span was considered to carry out numerical 
analysis. Four beams were modeled for this 
purpose. One of which was an un-cracked beam 
(considered as benchmark specimen) denoted as 
UB. A cracked beam (denoted as CB) of crack 
depth of 20% of the full depth of beam was also 
modeled. The two beams were modeled as 
retrofitted cracked beams. One of which was 
retrofitted by steel plate (denoted as RS) and the 
other one was by CFRP sheet (denoted as RF). 
Simulations were carried out by using one of the 
most powerful finite element software ANSYS 
(11.0). Two-dimensional finite element model was 
developed for simplicity in analysis and reducing 
computational effort.  Geometry, loading and 
boundary condition of uncracked, cracked and 
retrofitted beam are shown in Fig. 1.  
 
 
 
Fig. 1: RC beam; (a) Un-cracked beam, (b) Cracked 
beam and (c) Retrofitted beam. 
 
2.1 Element Types 
 
Eight-nodded quadratic plane stress element 
(PLANE82) having two degrees of freedom at each 
node (translation in the nodal x and y directions) 
available in ANSYS finite element program was 
used to model the concrete. This element has 
capability to model plasticity, creep, swelling, 
stress stiffening, large deflection, and large strain 
capabilities. Geometry of node numbering of 
PLANE82 element is shown in Fig. 2. 
 
 
 
Figure 2:  Geometry of PLANE82  
 
One-dimensional (link1, 2-D spar) element was 
used to model the reinforcement. This element is a 
uniaxial tension-compression element with two 
degrees of freedom at each node (translations in the 
nodal x and y directions). Steel plate and CFRP 
sheet were also modeled using PLANE82 element. 
 
 
10′ 
16″ 
Page 173
  
2.2 Material Properties 
 
2.2.1 Concrete: In the present study concrete was 
assumed as a homogeneous material. In usual 
practice, linearly elastic-perfectly plastic model is 
used for concrete crushing though many researchers 
have proposed piece-wise linear model. The 
linearly elastic-perfectly plastic model gives a good 
prediction of ultimate loading and displacement to 
the specimens (Zhang, 2004). Linearly elastic-
perfectly plastic model of normal concrete is shown 
in Fig. 3. 
 
 
 
Fig. 3: Linearly elastic-perfectly plastic stress-strain 
relationship of normal concrete. 
 
In the present study smeared cracking approach was 
used in modeling the concrete. Following properties 
were defined for concrete element: 
 
Elastic modulus (E=3949075 psi), 
Poisson’s ratio (ν=0.2),  
Shear transfer coefficients for an open crack 
(0.3), 
Shear transfer coefficients for a closed crack 
(0.9), 
Uniaxial tensile cracking stress (fr=520 psi), 
Uniaxial crushing stress (f’c=4800 psi).  
 
The shear transfer co-efficient represents the 
condition of cracked face. The shear transfer 
coefficient for a closed crack is widely accepted 
within 0.9 to 1.0. The value of shear transfer 
coefficients for an open crack used in many studies 
of reinforced concrete structures varies between 
0.05 and 0.25 (Bangash, 1989; Huyse et. al., 1994 
and Hemmaty, 1998). Convergence problems were 
encountered with shear transfer coefficients for an 
open crack dropped below 0.2 (Wolanski, 2004). 
Zhang (2004) mentioned that shear transfer value of 
magnitude 0.3 gives a good agreement with the 
change of stiffness of the specimen as well as the 
ultimate loading. Therefore, shear transfer value of 
magnitude 0.3 was taken into consideration in this 
study 
 
2.2.2 Steel Reinforcement and Steel Plate: For 
the finite element modeling, steel reinforcement is 
assumed as linearly elastic-perfectly plastic 
material and identical in both tension and 
compression. Elastic modulus and Poisson’s ratio 
assumed for steel reinforcement were 29 × 106 psi 
and 0.3, respectively. Steel plate used in FEM was 
assumed as linearly elastic material with the same 
elastic modulus and Poisson’s ratio of the steel 
reinforcement. Thickness of the steel plate was 
taken into consideration as 3mm. Linearly elastic-
perfectly plastic model of steel is shown in Fig. 4. 
 
 
 
 
Fig. 4: Linearly elastic-perfectly plastic stress-strain 
relationship of steel. 
 
2.2.3 FRP Sheet: Carbon fiber reinforced polymer 
(CFRP) was used as FRP sheet. A linear elastic 
property was assumed for CFRP. Elastic modulus 
and Poisson’s ratio used for CFRP were 21.75 × 106 
psi and 0.25 respectively. Thickness of CFRP sheet 
was taken 3mm. 
 
2.3 Finite Element Modeling Procedure 
 
The entire beam was modeled first with simply 
supported boundary condition. In case of cracked 
beam, flexural pre-crack was introduced by creating 
a gap (1mm) between elements at the bottom of 
mid-section of beam. The steel reinforcement was 
simplified in the model. Only bottom (flexural) 
reinforcement was modeled for simplicity in 
modeling and analysis. Both the top and shear 
reinforcement was omitted in the model. Perfect 
compatibility between concrete and steel 
reinforcement was assumed in this study. Finite 
element modeling of uncracked beam and closed 
view of crack are shown in Figs. 5(a) and (b).  
0
1000
2000
3000
4000
5000
6000
0 0.002 0.004 0.006
S
tr
e
ss
 (
p
si
)
Strain
Elastic-…
Page 174
  
 
 
(a) 
 
 
 
(b) 
 
Fig. 5: Finite element meshing of beam; (a) Un-
cracked beam and (b) Closed view of crack. 
 
Steel plate and CFRP sheet in retrofitted beam were 
modeled in the same way with consistent thickness 
but with different material properties. Epoxy 
bonding layer was omitted in the model. Usually 
epoxy is much stronger than concrete and therefore 
not a weak link exists in between concrete and steel 
plate or FRP sheet. Perfect bonding (concrete and 
epoxy strength are considered as same) between 
concrete and steel plate (or CFRP sheet) was 
assumed in the analysis. This was done by directly 
joining the nodes of steel plate (or CFRP sheet) 
with concrete elements. Finite element modeling of 
retrofitted beam is shown in Figs. 6(a) and (b). 
 
 
 
(a) 
 
 
 
(b) 
Fig. 6: Finite element meshing of retrofitted beam; 
(a) Retrofitted beam and (b) Close view of crack 
location. 
 
3. RESULTS AND DISCUSSION 
 
Results obtained from the numerical analysis of 
four beams are summarized in Table 1 and 
discussed in the following subsection.  
 
3.1 Load-Deflection Response  
 
The load-deflection response of uncracked (UB), 
cracked (CB) and retrofitted beam (RS and RF) are 
shown in Table 1 and Fig. 7. It is seen that cracked 
beam shows a brittle mode of failure just after the 
yielding of reinforcement. Retrofitted beams show 
significant ductile behavior before failure. 
However, this ductility is not as much as the un-
cracked one. 
 
 
 
Fig. 7: Load-deflection response. 
 
3.2 At the development of first crack 
 
From Fig. 7 it is seen that first crack occurs in the 
cracked beam at higher load than un-cracked beam. 
This may be due to the energy absorbed by the pre-
crack, which allows higher deflection at the same 
load. First crack occurs in both the retrofitted beam 
(Type RS and Type RF) also at slightly higher load 
than un-cracked beam. This is due to additional 
stiffness of steel plate or CFRP sheet. 
 
3.3 At Failure 
 
It is seen from Table 1 that a crack of 20% of full 
depth reduces the ultimate load carrying capacity 
approximately 18%. Pre-cracking also reduces the 
ultimate deflection. Table 1 also shows that, load 
carrying capacity of retrofitted beam increases at a 
0
20
40
60
80
100
120
140
160
0 0.2 0.4 0.6 0.8 1
Lo
a
d 
(k
ip
s)
Deflection (in)
UB CB
Page 175
  
value slightly higher than the un-cracked beam. 
Both the retrofitted beams show a lower value of 
ultimate deflection than the un-cracked beam but 
higher than the cracked beam.  
 
Table 1: Summary of numerical analyses results. 
 
Type 
At First Crack At Failure 
Load 
(kip) 
Deflection 
(in) 
Load 
(kip) 
Deflection 
(in) 
UB 91 0.175 134.42 0.924 
CB 97.9 0.21 114.32 0.35 
RS 92.2 0.16 136.66 0.532 
RF 93 0.16 137.32 0.636 
 
3.4 Stress Response  
 
Table 2 shows the stress responses at different 
locations of beams. All stresses were calculated at a 
load of 91 kips, which was the lowest first cracking 
load (occurred in uncracked beam). It is seen from 
Table 2 that cracking in RC beam causes increased 
stress at crack tip. Stress, σy  (stress in local y-
direction) increases significantly than σx (stress in 
local x-direction) due to crack. However, for 
retrofitted beam stresses at the crack tip effectively 
reduces. At the point of stress transfer, an increased 
stress is noticed due to retrofitting. However this 
increased stress lies within allowable limit. Stress 
contour plot of local stresses (σx and σy) of cracked 
beam is shown in Figs. 8(a) and (b). It is seen that 
stresses concentrate at the tip of crack.  
 
Table 2: Stresses (σx and σy)  
 
Type 
Stress, σx (psi) Stress, σy (psi) 
At 
crack 
tip 
At 
transfer 
At 
crack 
tip 
At 
transfer 
UB 4135 2233 -110.89 0.1824 
CB 4265 2232 1636 0.1808 
RS 4152 2466 386.94 35.14 
RF 4184 2408 438.74 28.103 
 
 
 
 
 
(a) 
 
 
 
(b) 
 
Fig. 8: Stress contour plot of cracked beam, (a) σx, 
(b) σy. 
 
4. CONCLUSION 
 
Based on the results obtained from numerical 
analysis, the following conclusions can be drawn: 
 Cracking in RC beam reduces the load 
carrying capacity of the beam.  
 Significant stress concentration occurs in 
the beam due to cracking. 
 External plate bonding reduces the stress 
concentration at crack tip. 
 External plate bonding causes an increased 
flexural stress in concrete at stress transfer 
zone. However, this increment in flexural 
stress lies within allowable limit.  
 Plate bonding using both the steel plate 
and CFRP sheet could effectively retrofit 
cracked beam by increasing its load 
carrying capacity.  
 
 
REFERENCES 
 
1. Bangash, M. Y. H. (1989). Concrete and 
Concrete Structures: Numerical Modeling and 
Applications, Elsevier Science Publishers Ltd., 
London, England. 
2. Chajes, M.J., Januszka, T.F., Mertz, D.R.,  
Thomson, T.A. and Finch, W.W. (1995), Shear 
strengthening of reinforced concrete beams 
using externally applied composite fabrics. ACI 
Struct. J., 92 (3), pp 295-303. 
3. Devid, E., ------------- (1998), Repair and 
strengthening of reinforced concrete beams 
using composite materials, 2nd Int. PhD 
symposium in Civil Engineering, 1998,  
Budapest. 
4. Gorgi, M.S. (2009), Analysis of FRP 
strengthened reinforced concrete beams using 
Page 176
  
energy method, World Applied Sciences 
Journal 6(1), pp 105-111. 
5. Hemmaty, Y. (1998), Modelling of the Shear 
Force Transferred Between Cracks in 
Reinforced and Fiber Reinforced Concrete 
Structures, Proceedings of the ANSYS 
Conference, Vol. 1, Pittsburgh, Pennsylvania, 
USA. 
6. Hollaway, L.C. (1999), Leeming, M.B., 
Strengthening of reinforced concrete structures 
using externally bonded FRP composites in 
structural and civil engineering, (1999), CRC 
Press, Ehsani, M.R. 
7. Huyse, L., Hemmaty, Y., and Vandewalle, L. 
(1994), Finite Element Modeling of Fiber 
Reinforced Concrete Beams, Proceedings of 
the ANSYS Conference, Vol. 2, May 1994, 
Pittsburgh, Pennsylvania, USA. 
8. Kaish A. B. M. A. and Hassan M. K. (2008), 
Retrofitting of high rise building components, 
B.Sc. Thesis, Department of Civil Engineering, 
Chittagong University of Engineering and 
Technology, Chittagong, Bangladesh. 
9. Khaloo, A.  R. and Gharchorlou A. (2005), 
Finite element analysis of RC beam 
strengthened in flexure by CFRP laminates, 3rd 
Int. Structural Engineering and Construction 
Conference, 2005, Japan. 
10. Panazopoulou, S.,------------------- (2001), 
Repair of corrosion damaged columns with 
FRP wraps, ASCE J Compos Construc 5:3-11. 
11. Shahawy, M. A., Arockiasamy, M., Beitelman, 
T. and Sowrirajan, R. (1996), Reinforced 
concrete rectangular beams strengthened with 
CFRP laminates. Compos Part B: Eng., 27 (3-
4): pp 225-233. 
12. Saadatmanesh, H., Ehsani, M.R. and Jin, L.  
(1997), RC beams strengthened with FRP 
plates II: analysis and parametric study. J. 
Struct. Eng., 117 (11), pp 3434-3455. 
13. Sharif, A., Al-Sulaimani, G.J.,  Basunbul, I.A.,  
Baluch, M.H. and Ghaleb, B.N. (1994), 
Strengthening of initially loaded reinforced 
concrete beams using FRP plates. ACI Struct. 
J., 91 (2), pp 160-167.  
14. Wolanski, A. J. (2004), Flexural behavior of 
Reinforced and prestressed concrete beams 
Using finite element analysis, M. Sc. Thesis, 
Department of Civil Engineering, Marquette 
University, Michigan, USA. 
15. Zhang, Q. (2004), FE application to slab-
column connections reinforced with GFRP 
(2004), M. Eng. Thesis, Faculty of 
Engineering, Memorial University of 
Newfoundland, Canada. 
 
Page 177
 RETHINKING THE FORM OF SUSTAINABLE CYCLONE SHELTER 
Kanu Kumar Das, 
Lecturer, Department of Architecture, Chittagong University of Engineering & Technology 
Md. Rabiul Alam, 
Head, Department of Architecture, Chittagong University of Engineering & Technology 
Smita Rakshit, 
Lecturer, Department of Architecture, Chittagong University of Engineering & Technology 
 
ABSTRACT 
Geographically Bangladesh is a disaster-prone area. Throughout the years, this country has been exposed to 
several hazards such as: cyclone, Gourkee (high water tide) flood, drought, earthquake etc. Cyclone has always 
been a major threat to the coastal area of our country. Severe cyclones have affected this region and have cost 
us wealth and most importantly live. Cyclone cannot be stopped but it is essential to carry out research and 
invent new technologies to protect lives during and after cyclone. It is inherent tendency of human being to look 
for shelter from any natural discomfort or hazard. Therefore, right from beginning of civilization the human 
race have been inventing protection, shelter and technology to adopt a shelter to protect them from above 
calamities. 
This paper is an attempt to derive a form which is sustainable against cyclonic force but yet it is part-and-parcel 
of respective landscape. 
KEYWORDS: Cyclone Shelter, Coastal area of Bangladesh, Architectural Form, Disaster, Landscape,      
Social icon. 
1. INTRODUCTION 
Cyclone is one of the most destructive natural hazards 
in our country. Several cyclones have caused casualties 
and economic loss which had large impact on our 
economy. Therefore, government and private agencies 
have been motivated to construct cyclone shelters. The 
concept for constructing cyclone shelter in the costal 
area of Bangladesh is to give shelter for the local people 
during the cyclone. But what is going to be the 
structure’s use in the remaining days? That means when 
there is no cyclone what is the uses of these structures. 
In this study it has also been tried to rethink the cyclone 
shelters so that they become an icon that gives the 
locality strength and also integrity.  
Bangladesh is situated to the north of Bay of Bengal. Its 
geographical location is between 20 ̊34′ N and 26 ̊38′ N 
latitude, it has 724 km long coast line which is highly 
vulnerable to tropical cyclones and associated storm 
surge (Islam and Peterson, 2008). The south and south-
eastern zone of Bangladesh is more exposed to cyclones 
than the other areas (see Fig. 1). The districts included 
Fig 1: Cyclone affected areas of Bangladesh                               
(http:// banglapedia. search. com. Bd / Maps /       
MN_0131D.GIF/2008)                                              
Page 178ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
in these areas are Chittagong, Cox’s Bazar, Patuakhali, 
Barguna, Jhalkathi, Barisal, Noakhali, Feni, Bhola, 
Satkhira, Khulna, etc.  
Major cyclones that hit to the coast of Bangladesh in 
different times and its number of death are given in 
Table 1. It is seen that lost of human lives in 15th 
November 2007 cyclone’s are much lower than 12th 
November 1970 and 29th April 1991 cyclones’’ 
Preparedness against cyclones is the reason for this. 
Therefore, cyclone shelters like structure are more 
important in the coastal areas of Bangladesh to get 
significant preparedness against cyclone. Its routine 
maintenance is also important to keep it useable form. 
Table 1: Major cyclones that hit Bangladesh in different 
time and their deaths (http: // www.preventionweb.net/ 
english pro      fessional /news / (2010 ). 
DATE YEAR STORM SURGE(ft) DEATHS 
09 May 1961 8-10 11466 
11 May 1965 12 19279 
12 Nov. 1970 20-30 500000 
25 May 1985 10-15 11069 
29-Apr 1991 20-25 138000 
  15 Nov. 2007 20-25  3400 
25-May 2009  - 190 
 
2. OBSERVATION ON EXISTING CYCLONE 
SHELTERS 
Existing cyclone shelters are mostly designed and 
constructed by the Government and NGOs. These 
structures are designed on focusing mainly to protect 
people from cyclone and water-surge. Livestock is an 
important part of our village life. Generally, people are 
not interested to go to the cyclone shelters without their 
important wealth such as livestock. This is our serious 
observation that most of the cyclone shelters have no 
consideration of space for saving live-stocks. In few 
cyclone shelters there is some space for livestock but 
this is not properly designed for that purpose. All 
cyclone shelters are opened in ground floor to allow 
flash flooding during the cyclone (see Figs. 2(a) and 
(b)). This space cannot be used in emergency or in 
general. Besides in the most critical cases appropriate 
access road is not there (see Fig. 2(b)). Most of the 
existing cyclone shelters are designed only as 
structures just to shelters. It is the project of huge 
investment but focused only to protect people from 
cyclone, generally for 4-5 days. Rest of the days in 
a year it is used mostly as a school but not properly 
designed for that purpose. No structure can survive 
if it is meant to be used for only 10 days a year. So 
the structure should be designed for all the year 
considering the social, cultural, educational aspects 
and so on. In this paper it has been discussed how a 
cyclone shelter needs to be designed to get its 
maximum utility during cyclone as well as other 
time of the year. It also covers to protect people as 
well as other wealth such as live stocks.  
 (a) 
(b) 
Figs. 2(a) and (b): Typical Cyclone shelter 
3. DESIGN CONCEPT FOR RETHINKING 
CYCLONE SHELTER 
The form of structure needs to be built in the 
coastal area should have inherent criteria to 
withstand pressure of severe wind as well as to save 
from the storm water surge. The obvious answer is 
a circular shape in broad sense. Circular form is 
able to resist the severe wind pressure and storm 
water surge whenever they occur. On the other 
hand this creates a space for play ground in normal 
Page 179
time. Wind effect on circular form is shown in Fig. 3.   
Fig. 3: Wind effect on circular form 
It is seen that wind force gets component when it acts 
on the surface of circular shaped structure. Inside the 
circular area there will be a fixed space where people 
will live. During emergency definitive space and shape 
are to be provided for people and livestock, 
respectively. People will live in rectangular space and 
livestock will live in circular space. Proposed positions 
for people and livestock inside the circular area are 
shown Fig. 4.  Rectangular shape is achieved from the 
class rooms’ size and shape which is suitable for used as 
school in normal period.  Both shapes together give the 
sense of safety and security.  
 
 
 
 
 
 Fig. 4: Position of people and livestock within the form 
during emergency and the use of the same space in 
normal period 
4. DESIGN CONSIDERATION FOR NEW 
FORM OF CYCLONE SHELTER 
Criteria for the design of new form of cyclone shelter 
should be to provide a sense of safety and security to the 
people and the livestock. Circulation routes for people 
and livestock must be clearly defined to avoid clash and 
confusion during emergency. ‘U’ turn should be 
avoided in the access route of cyclone shelter. Because 
it is difficult for a cow to take a ‘U’ turn in crowded 
situations. Fig. 5 shows a proper circulation route 
for people and livestock. Planning of proper 
circulation route must be taken into consideration 
during design of multipurpose use of cyclone 
shelter. 
 
 
 
 
 
 
 
Fig. 5: Circulation of people and livestock within 
the form of shelter 
The livestock should be visible by their respective 
owners even during emergency shelter. Thereby, 
the people will be more encouraged and willing, 
specially the woman folk, to come to the shelter. It 
is observed that only movable property of the 
coastal people is their livestock. They want to keep 
the property with them till the end of cyclone, if 
one can own one. 
Normal time use of school, play ground, indoor and 
outdoor spaces should be integrated with the 
shelter. Therefore, the design is for a utilitarian 
building that stands boldly to resist cyclones and to 
protect the people and the livestock, but yet being 
functional, simple and free from any decoration.  
5. SITE FOR THE CYCLONE SHELTER 
Site is another factor that must be taken into 
consideration during construction of cyclone 
shelter. Cyclone shelter should be well access of the 
local people of the region where it to be 
constructed. The region must be flat and above the 
sea level of height of cyclone and tidal waves. Low 
flat terrain and funneling coastal part should be 
avoided. 
Page 180
6. WATER SUPLY, SANITATION AND 
ELECTRICITY FACILITIES 
Water Supply and sanitation: Drinking water must be 
supplied from the tube well. Therefore, it has to be 
ensured to install few tube wells near the shelter. 
Facility must exist to store rain water which could be an 
alternate of tube well water. Septic tank and soak pit 
must have to be placed outside the peripheral wall of the 
shelter. Excess water collection inside the peripheral 
wall may be pump out from two swamp located at two 
ends.  
Electricity: It has been observed that supply of 
electricity from national grid is often shutdown during 
cyclone due to damage of electric pole and wire. 
Therefore, an alternate arrangement for electricity must 
be kept in cyclone shelter. Solar energy equipment 
could be an option for this. Lightening arrestor must be 
provided to protect people and livestock from 
thundering. 
7. PROPOSAL FOR NEW CYCLONE SHELTER 
In this study two types of shelter namely DESIGN-01 
and DESIGN-02 are proposed for 2000 people in 
multipurpose uses. However, the scheme can be scaled 
down for community of 1000 people. Cross section of 
these two types is shown in Fig. 6(a) and (b). Structure 
of both these design cases must be R.C.C structures.  
 (a) 
(b)  
 
Figs. 6(a) and (b): Sections showing the wall and      
embankment surrounding the building form    
Basis of DESIGN 01 is considered as at ground 
level and for DESIGN 02 it is considered as on 
Plateau of reclaimed land. 
Figs. 7 and 8 show the use of space for normal and 
emergency periods. Rectangular space could be 
used for the school of children and open space 
could be used as playground in normal time. 
 
 
 
 
 
 
 
Fig. 7: Plan showing the use of space for normal 
period    
 
Fig. 8: Plan showing the use of space for 
emergency period 
Enclosed open space on ground level is to protect 
livestock in emergency. This open space may also 
be used for different socio, cultural, and economic 
activities of the community beyond school hour. 
Page 181
Fig. 9 shows the plan of circulation for ramp and stair. 
Circulation needs to be very well defined for livestock 
and people to avoid chaos and confusion during 
emergency. A ramp climbing up and then down without 
any ‘U’ turn must be there for livestock and a stair must 
be there for people to use during emergency. In normal 
time these elements (ramp, stairs) would be used by all 
students, teachers and community people. Besides, ramp 
must be needed for handicap people during emergency 
and normal time.  
 
 
 
 
 
 
Fig. 9: Plan showing the circulation, ramp for livestock 
and stair for people 
Orientation of the building depends on the climate 
condition, air flow, natural light, etc. Therefore, the 
orientation of the building should be fixed in respect of 
direction of air-movement and the sun path. Rationally, 
east and west sides of the building should be made with 
solid wall and north and south sides of the building 
should be made with enough shaded space and openings 
for natural ventilation. An ideal orientation of the 
building is shown in Fig. 10 
 
 
 
 
 
 
Fig. 10: Plan showing the orientation of the building 
considering climate condition and natural light. 
8. GRAPHICAL PRESENTATION OF 
PROPOSED DESIGN 01 AND DESIGN 02  
Floor plans at different levels, elevations, sections 
and perspective views of proposed design 01 are 
shown in Figs. 11-16. The peripheral wall around 
the shelter region is proposed to make for safety 
and security of the people and their livestock in the 
emergency situation. With the 6m high flood-water 
surge, of temporary stay (say 8 hrs), water may sip 
through the earth inside the ground space bounded 
by peripheral wall. Therefore ground level inside 
the peripheral wall is raised to +1.2 m. 
Fig. 11: Plan at +1.2m level of proposed design 01 
Fig. 12: Plan at +6.0m level of proposed design 01 
Page 182
         
 
 
 
 
 
 
Fig. 13: Plan at +7.2m level of proposed design 01 
 
 
 
 
 
 
 
Fig. 14: Elevations showing the vertical circulation  
Fig. 15: Section showing the vertical circulation, 
ground open space for livestock and upper floor for 
people 
 
 (a) 
 
(b) 
 
Figs. 16(a) and (b): Perspective view of proposed   
design 01 
Details graphical presentation of proposed design 
02 is shown in Figs. 17 to 20. In this proposal of 
design, shelter place is raised from the normal 
ground level of region where shelter to be built. 
Earth filling for killa is done from the digging of 
canal (see Fig. 17) around the base of killa. The 
canal may be used for fishing, ducks cultivation and 
for irrigation purpose. The slope surface around the 
plateau may be used for herbal plantation. 
Cooperative ownership of the canal and the slope 
surface is to be decided by the community. During 
normal time, the rain water inside sunken platform 
will be soaked away by the semi soft surface and 
excess water if any, can be pumped out from the 
two swamps at two ends. This sunken plane at + 4.5 
m level is the major place of activities. Floor plan 
of proposed design 02 at different levels is shown 
Page 183
in Figs. 16 and 17. It is seen that four connects roads 
(conceptual) from different villages and one circular 
circulation around the killa (Plateau) which leads to a 
common entry point at the west site of the killa are 
joined to the shelter. There is a stair for people and a 
ramp for livestock from entry point to the shelter at + 
4.5m level. Here the open space is for live stock and the 
class room is used as shelter for people at emergency. 
 Fig. 17: Floor Plan of proposed design 02                    
at +4.5 level. 
 
Fig. 18: Floor Plan of proposed design 02                    
at +6.0 level 
Section and elevation of Proposed design 02, are given 
in Fig. 19. The sunken space which is party open would 
be used as play ground in normal time. In cyclone 
period it would be used for safety for livestock 
Fig. 19: Section and Elevation of design 02,  
Various perspective views of proposed design 02 
are shown in Figs. 20 (a)-(c). Circular ramp, stair, 
building form and detailing of surrounding 
landscape are shown in these figures. 
 
Fig. 20(a): Perspective view showing ramp and 
stair of proposed design 02 
 
 
Fig. 20(b) (cont’d): Perspective view of proposed   
design 02 showing     entry point 
 
Page 184
Figs. 20(c) (cont’d): Birds eye view of proposed design 
02 showing whole killa with its surrounding 
landscape,  
9. CONCLUSION 
Both of the design proposal discussed above will be 
used all the year as school/ community space. The 
spaces are designed not only as a shelter but also as a 
place for social gathering or meeting place. Surrounding 
environment of the site can be used as agricultural land 
for grains, vegetables or for fishing. At the same time 
the open space can be considered as a playground and 
the whole project would be social icon for a village. 
10. REFERENCES 
(1) Cyclone Shelter preparatory study (1996), http: // 
www.preventionweb.net/ english pro      fessional /news 
/(2010 ). 
(2)  http:// banglapedia. search.com.bd/Maps/       MN 
_0131D.GIF/(2008). 
 (3) Islam, T and Peterson, R., (2008),                                         
A Climatologically Study on the Land Falling Tropical 
cyclones of Bangladesh, Texas Tech University, 
Lubbock, Texas 
Page 185
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Md. Mostafizur Rahman,  
E-mail: mostafiz_t@yahoo.com  mostafiz-arc@sust.edu  
RENEWABLE ENERGY SYSTEMS FOR RESIDENTIAL BUILDINGS IN 
NEW SATELLITE TOWNS OF DHAKA: BARRIERS AND PROBABLE 
SOLUTIONS 
 
Md. Mostafizur Rahman* 
Assistant Professor, Department of Architecture, Shahjalal University of Science and Technology, 
Sylhet-3114, Bangladesh 
 
Iftekhar Rahman 
Assistant Professor, Department of Architecture, Shahjalal University of Science and Technology, 
Sylhet-3114, Bangladesh 
 
Energy is essential to ensure quality of life and to underpin most of the services to our environment. 
Bangladesh faces unprecedented energy crisis due to high-energy demand and poor management. Low 
production results frequent disconnection; load shedding and most of the service sectors in the city are 
interrupted. Surprisingly residential sector consumes 45% electricity of Dhaka and the demand is increasing 
day by day. Another problem is that government introduced new satellite towns to keep pace of development 
and to accommodate people, which will further also increase the demand. Our country relies heavily on 
fossil fuels like natural gas and imported oil for its electricity production. Renewable sources can meet the 
demand only 4% though the zone is favorable for plentiful supply of renewable sources. Therefore the 
objective of the paper is to assess how renewable energy technologies (RETs) can be incorporated in the 
residential buildings of new satellite towns of Dhaka to supplement the existing electricity demand focusing 
more on technical and policy aspect. This paper also tries to find out the main barriers and probable solutions 
to incorporate the technologies in the residential buildings for its sustainability. 
 
Key words: Renewable energy, residential buildings, satellite towns, sustainability, Dhaka. 
 
1. INTRODUCTION 
 
Energy is essential to ensure quality of life and to 
underpin most of the services to our environment. 
Dhaka the capital of Bangladesh faces an 
unprecedented energy crisis due to higher demand, 
country’s small energy infrastructure, poor 
management and system loss. Now Dhaka city 
consumes around1000-1200 MW electricity against 
the demand of 2000 MW, where country can only 
generate 4,162 MW (BPDB, 2010). Surprisingly 
residential buildings sector consumes 45% 
electricity of Dhaka (Rahman and Mallick in Ahsan 
2009). This includes energy for heating, cooling, 
and lighting purpose. Moreover government 
introduced new satellite towns like “purbachal” in 
Dhaka to accommodate people, which will further 
increase the electricity demand.  
 
Now the country’s power is being generated mostly 
with indigenous natural gas (82%), 9% imported 
oil, 5% coal (Kabir at el 2009). Recently a 
remarkable decline of the natural gas takes place, 
which rapidly aggravates electricity generation. The 
initiative of new exploration and development of 
natural gas has almost reduced to zero due to lack 
of capacity. Realizing the fact, government had 
stopped to permit electricity connections for all new 
buildings from April to October 2010 and since 
November they started conditional electricity 
connection like building must use solar energy if 
demand is more than 2 KW (KK, 2010). The 
development of renewable energy is insufficient. 
Renewable energy sources can meet the demand 
only 4%, though the zone is favorable for plentiful 
supply of renewable sources.  
 
Given the city’s power crisis, high energy prices or 
their rather unpredictable development, search for 
alternative source of energy in buildings for new 
satellite towns of Dhaka could be pragmatic to 
supplement existing power demand and to avoid a 
number of social economic and environmental 
problems. Renewable energy systems in buildings 
would be very effective in this regard. 
 
2. OBJECTIVES: 
 
As electricity situation posing the number one 
problem for all service sectors in Dhaka, residential 
Page 186
ISBN: 978-984-33-2140-4
  
buildings could play an important role by 
incorporating RETs to supplement the existing 
demand. This paper focuses on how RETs could be 
incorporated in the urban residential buildings 
focusing on new satellite towns of Dhaka with a 
view to  
• What are the RETs that can be used in 
residential buildings of Dhaka?  
• How different government policies can help to 
promote the RETs around the world? 
• How it could be affordable at local level? 
• What are the barriers and probable solutions 
to promote RETs for buildings in new satellite 
towns of Dhaka? And  
• To prepare a basis for further study about 
RETs use in buildings of Dhaka 
 
3. RESEARCH METHODS 
 
The research consists of three main phases: desk 
study, field research and information analysis. Desk 
study helped to analyze different aspect to promote 
RETs in building sector around the world. Field 
research helped to produce some qualitative and 
quantitative descriptions of some aspects of the 
study area at Dhanmondi in Dhaka that helped to 
make some assumption about new satellite towns. 
The quantitative data from the questions has been 
grouped and put in tables and the results expressed 
in percentages and frequency distribution. 
Qualitative data that were collected through in 
depth interview with key respondents presented in 
graphs. 
 
 
4. ENERGY AS AN URBAN 
ENVIRONMENTAL PROBLEM:  
 
Energy uses are increasing significantly with 
increased supply of fossil fuels to maintain urban 
lifestyles that negatively affect to our environment. 
Realizing the fact ‘Winston Churchill’ expressed 
his emotion (Jowitt, 2009),“We shape our 
buildings, and afterwards our buildings shape us”. 
 
4.1 Energy sources uses in building: As Dhaka 
electric supply authority cannot meet the current 
electricity demand in residential sector at 
dhanmondi shows, most of the building (90%) use 
diesel based generator and IPS as alternative 
sources (Table 1) which contribute to a number of 
social, economic & environmental problems like 
noise and air pollution, global warming etc. They 
spent huge additional cost to operate generators 
each year. Study confirms that people are interested 
about the technology but 70% mentioned it 
expensive.  
Table 1: survey analysis of Dhanmondi 
Questions Answer No. of 
Ans. 
(%) 
What are the 
alternative 
sources you 
currently use  
Generator 9 90 
IPS  1 10 
RE 0 0 
What do you 
prefer as 
alternatives 
Generator 6 60 
IPS  0 0 
RE 4 40 
Why you don’t 
use RET 
Expensive 7 70 
Lack of info. 3 30 
Sources: author 
 
4.2 New satellite towns of Dhaka: Dhaka, the 
capital of Bangladesh, has come to be known as a 
fast growing megacity (13 million) of South Asia in 
recent times. It is expected to grow at a rate of 3.6% 
annually and reach a total of 21.1 million in 2015 
(UN, 1999). To accommodate the growing number 
of population, the city would need at least 10 
million new residential apartments (units/flats) by 
the year 2015. Moreover buildings in new satellite 
towns like “purbachal” will further increase the 
energy demand. This is the right time to think about 
energy choice and sustainable pattern of residential 
building in new satellite towns for our future 
energy security.  
 
4.3 Improving through energy choice and 
buildings design: Buildings are very important for 
our environment because of their lifetime (around 
50-80 years) and most of the energy is used during 
their service life. Through the careful choice of 
environmental friendly energy sources, the use of 
an ecological design approach the building could 
reduce considerably the quantities of pollutants 
entering the environment. CABE (2007) believes 
that: “No building, space or place can be 
considered well designed if it does not contribute to 
environmental social and economic sustainability, 
conversely, no building, space or place can be 
considered sustainable if it is not well designed”.  
 
To improve our environmental and its sustainability 
we need to thing alternative sources of energy for 
buildings. There is an urgent need to transition to 
energy options that are clean, affordable, secure, 
sustainable and peaceable (Kamal, 2010). RETs 
offer the promise of clean, abundant energy. 
 
5. RENEWABLE ENERGY:  
 
Renewable energy may be defined as energy from 
naturally available sources such as wind, solar, rain, 
tides, geothermal heat and biomass etc that can be 
constantly replenished and harnessed for human 
Page 187
  
benefit (IEA, 2009). These resources can be used to 
produce electricity for all economic sectors. 
 
5.1 Renewable energy sources uses in building: 
There is a wide range of renewable energy sources/ 
technologies such as solar photovoltaic (PV), solar 
thermal (ST), wind power, combined heat and 
power (CHP), ground source cooling (GSC), 
ground sources heat pump (GSHP) and biomass 
varying in technical and commercial viability for 
building. It can be used in a number of ways, these 
include: extracted elsewhere and delivered via the 
conventional delivery channels and networks, it can 
be extracted locally, it can be extracted at the site of 
the building(s), or by the building envelop in 
integrated way. Without proper policy interventions 
and technological improvements these patterns of 
energy are not expected to achieve/change in the 
near future (UNEP, 2009).  
 
Table 2: Overview of eight (8) different RE sources 
uses in building worldwide. 
 
Sources Energy 
type 
Co2 
savings 
Cost 
 
Factors 
SPVs Electricity Low Low Solar radiation 
ST H* & C* L*-M* M  Solar radiation 
DHC H & C M-H M Location & 
building type 
CHP H & C M-H M Building type, 
occupation 
GSC Cooling Depend Depend Ground Temp  
GCHP Heating M M Ground Temp  
Wind Electricity L-M M Wind speed 
Biomass  High M Location & 
occupation 
Source: CIBSE, 2006  
H*=Heat, L*=Low, M*=Medium 
 
The application of renewable systems for building 
depends on several determining factors; including 
geophysical (absolute location, global horizontal 
irradiance, temperature, cloud cover, sunshine 
duration, air flow, surface temperature, space 
availability and so on) economic and socio political 
(capital investment, technology support, social 
acceptability, political commitment, institutional 
support etc.) and environmental factors (Green 
house gas emission reduction, climate protection) 
(Kabir at el, 2009). This can substantially meet the 
energy demand for buildings.  
 
6. RENEWABLE ENERGY POLICY 
IN BANGLADESH 2008: 
 
‘Bangladesh's Renewable Energy Policy 2008’ 
approved with a vision for reducing dependence on 
traditional sources of energy and encouraging 
investment in this sector to generate electricity from 
renewable sources. It has been predicted that 5 
percent demand for electricity would be met by 
2015 through utilizing renewable energy while 10 
percent demand by the year 2020 (GOB, 2008). 
According to the policy statement, an independent 
institution, sustainable energy development agency 
(SEDA), in co-operation with local government 
will provide benefits for installation of solar, wind, 
biomass or any other renewable/clean energy 
projects. There is no institution or local policy for 
building sectors in Dhaka to promote RETs yet.  
 
6.1 Major renewable energy sources: RETs 
currently uses building in Dhaka and Bangladesh as 
well are as follows:  
 
6.1.1 Solar Energy: Geographically Dhaka, the 
capital of Bangladesh is situated between 23046’ 
north and 90023’ east latitude. A subtropical region 
that is endowed with a plentiful supply of 
renewable energy sources. The monthly average 
sunshine hour varies 4.1 to 8.7h, which is 
significantly higher than Europe to use solar 
energy. Centre for energy studies (CES), BUET, 
recorded average solar radiation in Dhaka in a year 
4.7 kWhr/m2/day, which offer maximum benefit to 
use solar energy (electricity generation and hot 
water system). In Dhaka  “prime minister office” 
and “Bangladesh bank bhaban” installed solar panel 
to supplement the existing electricity demand. 
Ministry directive also showed all government 
building must use solar energy in Dhaka by 2013.  
 
6.1.2 Wind sources: Wind can be vital sources for 
electricity generation if it can be harness properly. 
Most of the wind speed data of Dhaka available in 
meteorological department are measured at lower 
heights (10m) that lack reliability and accuracy. 
According to Mahfuz at el (2002) above 25 m 
height the average wind speed is in Dhaka is 4.52 
m/s. that could be useful to install a wind turbine 
for high-rise buildings. Vertical axis systems (wind 
turbine) can be installed that require minimum 
speeds of 3.5-5 m/s to operate and is easier to 
integrate with building structure. Currently wind 
energy potential is mainly limited to coastal areas 
and offshore islands with strong wind regimes. 
 
7. DIFFUSION OF RENEWABLE 
ENERGY FOR BUILDING IN THE 
WORLD:  
 
If the aim of the building sector is to make more 
sustainable in the long run, then renewable energies 
will have to play a bigger role. This can be 
achieved through two avenues: first, by substituting 
fossil fuels with renewable energy sources at the 
point of electricity generation; and second, through 
the use of renewable energy technologies at the 
Page 188
  
point of consumption when supported by favorable 
government policies  (UNEP, 2009). Many 
countries are trying to speed up the diffusion of 
renewable energy provision through direct 
regulation. There are number of common policy 
mechanism used worldwide such as target setting, 
regulations, municipal operations, voluntary actions 
and guidance to promote RETs in building sectors 
at local level. 
 
Table 3: Overview of RET’S policy in the world 
Ci
ty
/ 
co
u
n
tr
y 
Ta
rg
et
 
 
R
eg
u
la
tio
n
 
 
M
un
ic
ip
al
 
o
pe
ra
tio
n
 
V
o
lu
n
ta
ry
 
ac
tio
n
s 
 
G
u
id
an
ce
 
 
 U
rb
an
 
 
B
ui
ld
in
g 
Ta
x
es
 
O
th
er
 
Pu
rc
ha
se
 
In
v
es
t 
U
til
ity
 
D
em
o
 
G
ra
n
ts
 
La
n
d 
O
th
er
 
 
K
u
n
m
in
g 
 
Ch
in
a 
X
 
X
 
 X
 
  X
 
  X
 
 X
 
X
 
N
ag
pu
r 
 
In
di
a 
X
 
X
 
X
 
X
 
  X
 
 X
 
   X
 
B
ar
ce
lo
n
a 
Sp
ai
n
 
X
 
X
 
X
 
   X
 
    X
 
X
 
 
7.1 Kunming, China (population 4.7 million): 
Kunming aspires to be a “solar capital” of China. In 
2008, the city adopted a policy framework “advice 
on renewable energy development and use” which 
calls for a 50% share of all buildings in the city to 
have solar hot water and solar PV by 2010. Other 
policies to promote renewable energy include low-
interest loans, tax exemptions, and a special fund to 
encourage private investment. The city has also 
incorporated solar investments into its own 
procurement. And the city is providing support for 
R&D, industry development, university education, 
and a solar hot water equipment-testing center.  
 
7.2 Nagpur, India (population 2.1 million): 
Nagpur participated in a local renewables “model 
communities” program from 2005–2008, paid 
partly through foreign donor assistance. The city 
also issued an ordinance mandating solar water 
heaters for all new residential buildings with more 
than 1500 m2, with a 10% rebate on property tax as 
an incentive. A Renewable Energy Resource Center 
was established to facilitate dialogue with local 
stakeholders, to identify and collect various forms 
of information, and to publish newsletters and 
brochures. Awareness campaigns include a mobile 
van, formation of “energy clubs” in schools, and 
training for students and schoolteachers. The city is 
targeting a 20% reduction in conventional energy 
consumption of municipal buildings and services 
by 2012. 
 
7.3 Barcelona, Spain (population 1.6 million): 
Barcelona enacted a city ordinance in 2000 that 
required solar hot water in all new buildings and 
major renovations above a size threshold (typically 
all commercial buildings, and residential buildings 
of 16 or more households). In 2005, the city 
eliminated the size requirement so the ordinance 
now applies to all construction. The ordinance 
requires 60% of hot water energy to come from 
solar. Barcelona promotes renewable energy 
through its 2002–2010 “Plan for Energy 
Improvement in Barcelona,” which aims to reduce 
CO2 emissions by 20% by 2010 (compared to 
1999). The plan is being implemented and 
monitored by the Energy Agency of Barcelona. 
There are also informational and public awareness 
programs. 
 
8. BARRIERS TO RENEWABLE 
ENERGY DEVELOPMENT:  
 
There are plenty of barriers hindering widespread 
deployment of potential RETs in new satellite 
towns of Dhaka. The major impediments to use 
renewable energy sources in the building sector are 
policy and institutional barriers rather than 
technical problems. Different types of barriers 
experienced are discussed in the subsequent 
headings.  
 
i) Policy Barriers: Lack of renewable energy       
policy in building for local level at Dhaka is 
one of the main barriers. Unfavorable energy 
policies for building sector and unwieldy 
regulatory mechanisms 
ii) Institutional barriers: Absence of a dedicated 
national agency like Renewable Energy 
Development Authority (REDA) to plan, co-
ordinate and finance. 
iii) Technical Barriers: Lack of access to the 
technology. Local manufacturing and/or 
assembly of renewable energy technology 
components and equipment are currently 
limited. 
iv) Market Barriers: Small size of the market, 
limited access to international markets for 
modern RETs, limited involvement of the 
private sector, high upfront cost at the end user 
level. 
v) Economic, Financial and Financing Barriers: 
Unfavorable costs, taxes (local and import), 
subsidies and energy prices. Lack of 
Page 189
  
appropriate financing mechanisms for 
renewable energy in urban sector 
vi) Capacity/ Human Resource Barriers: Lack of 
skilled manpower for system design, 
installation, operation, maintenance and 
training facilities. 
vii) Environmental: Visual pollution, lack of 
valuation of social and environmental benefits 
viii) Information/ Awareness Barriers: Lack of 
information among the public and policy 
makers about renewable energy resources, 
technical/economic information about RETs. 
ix) Social acceptance: Lack of social acceptance 
and local participation. 
 
8.1 FAR (Floor area ratio): RAJUK introduced 
“Dhaka building construction rule 2008” focusing 
more on FAR, creates some barrier to promote RET 
at residential building in Dhaka (figure 1). 
 
Figure 1: FAR analysis 
   
Source: Author 
 
From the above illustration we can see most of the 
buildings at Dhanmondi residential area are typical 
six stories. FAR offers vertical extension (more 
than six) which creates shadow to adjacent lower 
height building, is one of the main barriers to 
promote solar energy in building at Dhaka. 
 
Barriers would not be removed unless government 
takes actions.  
 
9. RESULT AND DISCUSSIONS:  
 
9.1 Technical aspect: On the basis of both the desk 
study and survey analysis we can see geophysical 
factors have been found fully supportive for solar 
energy (solar photovoltaic and solar thermal) 
application in urban residential building in new 
satellite towns of Dhaka to generate electricity and 
hot water system in winter and some cases wind 
speed to harness wind energy, depends on height of 
the buildings. It must be noted that this is the 
theoretical potential real achievements depend on 
the different and specific policy aspect, availability 
of cost–effective technology, affordability, building 
design guidelines, acceptability and effective 
planning and management.  
 
9.2 Policy aspect: From the international energy 
agency IEA (2009) and REN21 (2009), five 
different policy mechanism and activities, namely 
target setting, regulations, municipal operations, 
voluntary actions by government and guidance 
have been identified to promote renewable energy 
at the local level. Different aspects from 
International experiences have been analyzed to 
promote renewable energy in cities including 
Dhaka with the scale value 5  
 
Table 4: values for five policy indicators in four 
different countries. 
 
Ci
ty
/ 
co
u
n
tr
y 
Ta
rg
et
 
 
R
eg
u
la
tio
n
 
 
M
u
n
ic
ip
al
 
o
pe
ra
tio
n
 
V
o
lu
n
ta
ry
 
ac
tio
n
s 
 
G
u
id
an
ce
 
K
u
n
m
in
g 
 
Ch
in
a 
5 4 5 5 5 
N
ag
pu
r 
 
In
di
a 
5 5 5 4 5 
B
ar
ce
lo
n
a 
 
 
Sp
ai
n
 
5 4 5 2 5 
D
ha
ka
 
B
an
gl
ad
es
h 
1 2 5 2 1 
Source: Author 
 
Figure 2: shows the graphical comparison  
 
          
 1. China    2. India      
     
3. Spain    4. Bangladesh 
 
Source: Author 
 
In comparison with the China, India and Spain’s 
renewable energy policy development, from the 
figure we can see Bangladesh clearly lags behind in 
terms of local renewable energy policy in buildings, 
regulations, and proper financing mechanism for 
urban areas. Consequently current government 
Page 190
  
initiative to promote renewable energy technology 
in building sector in Dhaka cannot be called an 
integrated way of system due to absence of clear 
target, regulations like energy efficiency building 
codes. A study on the regulations in the national 
building code of Bangladesh (BNBC) shows that it 
does not address the issues of RETs in any building 
category. RAJUK introduced Dhaka building 
construction rule 2008, there is also no clear 
indication about energy consumption reduction 
from buildings or RE issues.  Moreover FAR (floor 
area ration) creates some barrier to promote RETs 
in building as it casts shadow to adjacent lower 
height buildings due to no restriction on height. It is 
assumed that the introduction of specific renewable 
energy policy in building sector for new satellite 
towns of Dhaka will have a positive aspect to 
implement the government initiative and 
supplement the existing electric energy demand and 
for our future energy security. 
 
9.3 Affordability at local context: Although 
investment costs of RET’s are generally higher 
compared to fossil fuel alternatives, this option 
becomes economically viable when all externalities 
(e.g. environmental cost, health hazards etc.) and 
lower operating cost are taken into consideration 
(GOB, 2008). We can carefully assess the 
following table 5 
 
Energy  Sources Cost  Positive 
aspects 
Negative 
aspects 
Co
n
v
en
tio
n
al
 
Gas 
(82%) 
Low Environment 
friendly 
Not enough 
reserve 
Oil 
(9%) 
  Import 
based/ Emit 
CO2  / 
Operating 
cost high 
Coal 
(5%) 
  Not decided 
yet 
Generator Diesel High   Not 
environment  
Friendly/ 
Emit CO2 
Operating 
cost high 
IPS 
El
ec
tr
ic
ity
 
  
 
Renewable  Solar Very 
high 
Environment 
friendly/ 
No 
operating 
cost 
 
  
Wind  
 Source: Author 
 
According to some experts, 57% said cost could be 
minimized if we use RETs in building an integrated 
way. 29 % mentioned it would be systems would be 
affordable if we can produce it locally. Some of 
them also focused on government incentives. 
 
Fig: 2 expert interview result. 
 
 
Source: Author 
 
In addition building design technique such as 
integrated renewable energy systems could play a 
big role to minimize the cost and system loss if it 
considered at the early stages of a project, before 
factors such as orientation, building form; numbers 
of storey’s, heating and ventilation strategy etc 
have been established (CIBSE, 2006). From the 
Architectural, technical and financial perspectives:  
 
• Reduction of investment costs by replacing 
facade/roof/-shading elements; 
• When grid-connected, avoids the costs of 
batteries. 
• Can be aesthetically appealing;  
• Electricity is generated at the point of use, 
reducing costs of transmission and 
distribution. 
• Suitable for un shaded roofs and facades in 
densely populated areas;  
• No additional land area required, since 
building surfaces used;    
• Can be designed to generate electricity at a 
building’s peak usage times, thus reducing 
the building’s peak grid electricity demand; 
• Can act as shading devices  
• Can form semi transparent elements of 
fenestration  
• PV/T can provide part of the water or space-
heating loads of the building BIPV can form 
part of a grid-failsafe antennae system for 
cellular communications. 
Integrated design requires more emphasis on 
energy efficiency and systems in the early planning 
phase than traditional design that would be ideal for 
new satellite towns of Dhaka. 
 
9.4 Probable solutions: From the above study we 
found barriers would be removed if government 
takes actions on followings. 
 
i) Policy Barriers: Strong policy target and 
regulations for buildings in new satellite towns 
of Dhaka to promote RETs 
Page 191
  
ii) Institutional barriers: Setup strong national 
agency to plan, coordinate and finance to 
implement the policy target 
iii) Technical Barriers: Technology transfer 
mechanisms to make local people informed. 
iv) Market Barriers: Fiscal instruments and 
incentives, Product standards, Economic 
instruments to facilitate the market 
v) Economic, Financial and Financing Barriers: 
Fiscal and economic instruments such as tax 
rebates, Kyoto flexibility mechanisms, 
subsidized loans, regulatory instruments or 
increase energy price, remove energy price 
subsidies 
vi) Capacity/ Human Resource Barriers: Training 
of building professionals those are directly 
involved the building process 
vii) Environmental: Should include environmental 
cost and health issues 
viii) Information/ Awareness Barriers: Awareness 
raising campaigns 
ix) Social acceptance: Voluntary actions such as 
tax incentive, subsidy 
 
FAR should be modified for specific locations like 
new buildings at “ purbachal” in terms of height. 
 
10. CONCLUSIONS: 
 
Geophysical factor fully support solar energy 
development in Dhaka and some cases wind 
sources depends on building height and urban 
design guidelines. Knowing the current fact people 
is also interested to invest for RETs to generate 
electricity in Dhaka. Government has a lead role to 
play in the case of initial investment and there is a 
scope to manage big funds internationally through 
clean development mechanism (CDM). To promote 
RETs we need specific renewable energy policy 
target for building sectors and regulations to 
implement the policy. An integrated energy 
planning approach, and rational policy instrument 
to deal with technical, social, economical and 
political barriers are the prerequisite to promote the 
RETs for building sector in new satellite towns of 
Dhaka. Integrated renewable energy systems could 
play an important role to make it affordable at local 
level especially in new satellite towns of Dhaka. 
 
REFERENCES 
 
1. BPDB (2010), Bangladesh power 
development board. Annual report 2008-
2009. http://www.bpdb.gov.bd/ 
2. CABE, 2007. Comission for architecture 
and built environment. 
http://www.cabe.org.uk/files/sustainable-
design-and-climate-change.pdf 
3. CIBSE, 2006. Renewable energy sources 
for buildings. The Chartered Institution of 
Building Services Engineers. 222 Balham 
High Road, London SW12 9BS. 
4. CES, 2010. Centre for energy studies, 
BUET, Dhaka, Bangladesh. 
http://www.buet.ac.bd/?page_id=41# 
5. EC, 2009. European Commission. Energy, 
http://ec.europa.eu/energy/renewables/inde
x_en.htm  
6. GOB, 2008. Government of Bangladesh: 
renewable energy policy of Bangladesh 
(Final). Power division ministry of power, 
energy and mineral resources. 
7. IEA, 2009. International energy agency. 
Cities, towns & renewable energy.  
8.    Jowitt, P., 2009. Institution of Civil 
Engineers Presidential Address 2009. 
http://www.ice.org.uk/downloads/pjaddres
spresentation.pdf 
9. Kabir, M.H., Endlicher, W. & Jagermeyr, 
J., 2009. Calculation of bright roof-tops 
for solar PV applications in Dhaka 
Megacity, Bangladesh. Renewable Energy 
(2009) 1–5 
10. KK. (2010), kaler kontho. The daily 
bangla newspaper. New electricity 
connection from 1st november. Published 
on October 29, 2010.  
11. Kamal, S. 2010. The untapped energy 
mine. Forum (the daily star) 
http://www.thedailystar.net/forum/2010/m
ay/untapped.htm 
12. Mahfuz, M. U, 2002. Prospect of Hybrid 
Wind System in Bangladesh. Second 
International Conference on Electrical and 
Computer Engineering ICECE 2002, 26-
28 December 2002, Dhaka, Bangladesh. 
13. Rahman, A. and Mallik, D.L, 2010. 
Climate Change Impacts on Cities of 
Developing Countries. 
http://www2.kankyo.metro.tokyo.jp/c40/c
40tokyo/pdf/keynoteLecture_symposium/d
l_mallick.pdf 
14. REN21, 2009.  Renewable Energy Policy 
Network for the 21st Century.  
http://www.ren21.net/pdf/RE_GSR_2009_
Update.pdf 
15. UNEP, 2009. United nations 
environmental programme. Building and 
climate change. Summary for decision 
makers. 
16. UN, 1999. United Nations. Energy 
Efficient Design: A Guide to Energy 
Efficiency and Solar Applications in 
Building Design. ECE Energy Series No. 
9. New York: United Nations. 
 
 
Page 192
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*Corresponding Author: Ram Krishna Mazumder 
E-mail: rkmazumder@gmail.com 
RISK ASSESSMENT OF MASONRY BUILDINGS IN HERITAGE 
AREA: A CASE STUDY FOR THE OLDER PART OF DHAKA CITY 
 
 
R K Mazumder * 
Structural Health Monitoring for RC Bridges in Bangladesh Project, Bangladesh University of 
Engineering and Technology, Dhaka, Bangladesh 
 
M S Hossain  
Trust Alliance Technology Limited, Mohakhali DOHS, Dhaka, Bangladesh. 
 
 
Being very close to the boundary of two active plates: the Indian plate in the west and the Eurasian plate in 
the east and north, earthquake risk of major urban centers including Dhaka are quite substantial. This study 
focuses on the seismic safety evaluation of masonry heritage buildings in Shakhari Bazar in the older part of 
Dhaka City. The major structural parameters in the classification of masonry buildings are considered as the 
number of stories, load-bearing wall material, regularity in plan and the arrangement of walls. It was 
revealed from the study that about 7% of the buildings fall under severe risk category, 36% of the buildings 
fall under high risk category and 41% of the buildings in moderate risk category. 
 
Key words:  assessment, heritage areas, masonry buildings, risk and Shakhari Bazar. 
 
1. INTRODUCTION 
 
The risk is growing with every passing moment 
because of the unabated growth of human 
settlement and industrial and other economic 
activities in and around Dhaka. It is generally 
believed that very high density development and 
existence of very old structures have made the older 
part of the city even more vulnerable to any 
impending earthquake situation. After the death of 
19 people in 2004, due to collapse of an old 
building at Shakhari Bazar in old Dhaka (Observer, 
2004), Town planning department of Dhaka City 
Corporation felt the necessity of undertaking 
initiative to assess the seismic vulnerability of 
buildings at Shakhari Bazar declared as heritage 
areas. Consequently, a consortium of Asian 
Disaster Preparedness Center and a consulting firm 
Datex were assigned to undertake seismic 
vulnerability assessment and prepare separate 
Structural Assessment Reports (SAR) for each of 
these selected buildings (Alam et al., 2010). 
 
SAR also referred to as an Engineer's Report is a 
planning tool used to determine a historic building 
or structure's structural condition by analyzing and 
evaluating foundation, framing, other construction 
systems, and their associated construction details. 
This report also provides recommendations for 
corrective treatments, as applicable. SAR may be 
commissioned for several reasons, including 
determining existing load capacity and 
identification of structural deficiencies that need to 
be addressed for an adaptive use, determining 
causes and the extent of existing or potential 
structural failures, and as documentation and 
justification of the need for demolition. The size 
and degree of detail in a SAR is dependent on the 
condition and complexity of the resource examined 
the amount of information available or attainable, 
and the resource's current or proposed use (Afsana, 
2004). This paper presents the methodology used 
for assessing seismic vulnerability and a summary 
of the assessment being done for selected 82 old 
masonry buildings in Shakhari Bazar. Besides, the 
paper also puts forward some recommendations 
regarding future course action that needs to be 
undertaken for the buildings assessed. 
 
2. STUDY AREA 
 
Shakhari Bazar is located in old town. The old 
urban settlement is one of the high density areas of 
Dhaka city. The selected 82 buildings are situated 
in Shakhari Bazar falls within two wards viz. ward 
72 and 73. The locations of the areas are shown in 
fig. 1.  
 
Page 193ISBN: 978-984-33-2140-4
  
 
 
Fig. 1: Location of Shakhari Bazar 
 
The rich architectural heritage at Shakhari Bazaar is 
also home to the Shakhari community, a 
community that has been living here and practicing 
the same craft of Shakha (conch-made bangles) 
making as their ancestors did over the last 500 
years (Seraj and Alam, 1989). With their habitats, 
lifestyle and craft this community of Shakhari has 
become a living heritage of Old Dhaka. But, as the 
age-worn masonry buildings look dangerously 
close to falling down, it is not just the rich 
architectural heritage that is at risk, the Shakhari 
community and the craft they have carried on 
across centuries also face the threat of extinction. 
Hence, structural assessment of the buildings of 
these areas has been found to be necessary. 
 
 
3. METHODOLOGY ADOPTED FOR 
ASSESSMENT 
 
Several Protocols provided by Federal Emergency 
Management Authority were used for evaluating 
structural vulnerability of the buildings in this study 
(FEMA 310, 1998). First of all building structural 
as well as the architectural types had been 
identified. The load transfer mechanism of the 
buildings had been determined. Level I and level II 
survey of the building were done to identify the 
basic vulnerability factors such as heavy overhang, 
pounding possibility etc. Then with the help of 
Rapid Visual Screening (RVS) method (ATC-21, 
1988) the strength score of the building was 
generated. After that with the help of floor plan, 
structural check was done. From the RVS method 
detailed level of assessment requirements had been 
identified. Among the 82 buildings 74 buildings did 
not satisfy the score; hence most of the buildings 
were undertaken for the detailed assessment. For 
detailed assessment of buildings FEMA 310 and 
several critical structural checks were adopted (Rai, 
2005). 
 
Soil characteristics are one of the major factors to 
analyze earthquake vulnerability of buildings. The 
soil class D was used for seismic vulnerability 
score generation in RVS Method. The Vs30 range 
is 180 to 360 m/sec for class D. It also gave the idea 
for ground base shear wave velocity of the study 
area (CDMP, 2009). 
 
Initially RVS Score was done for the initial 
assessment of the buildings. A detailed survey 
proposed by FEMA 310 was done for each of the 
building for the in depth structural checking of the 
buildings. Fig. 2 shows the outline of the steps 
followed during the study. 
 
Level 1 & 2 Survey  Level 3 
  
IITK- 
GSDMA 
(FEMA 310) 
 
Rapid 
Visual 
Screening 
Score 
 Collection of 
sample from 
sites 
  Material 
Strength 
Determination 
Ground Floor Plan  
  
Defect and 
Extent of 
Damage 
Determination 
 
Structural 
Integrity 
Checks 
 
Literature 
Survey 
   
Decision and Scenario 
Development   
   
Risk Group   
 
Fig. 2: Outline of the Methodology 
 
3.1 Level I and Level II Survey 
A pre set questionnaire was used for building 
survey. Side walk survey and questionnaire survey 
were carried out for each of the 82 buildings. The 
average time required for this survey by a 2-
member team was about 2-3 hours per building. 
Page 194
  
The building attributes considered during level I 
survey were number of stories, occupancy class, 
structural type, number of occupants during the day 
and the night, age of the building, presence of 
heavy overhangs, shape of the building plan, shape 
of the building in elevation view, pounding 
possibility, building in slope land, visible ground 
settlement and visible physical condition . 
 
Moreover, Architectural features which are the 
parameters defining geometry of buildings such as 
story height, span length, presence of open 1st-
story, and etc may act as factors for the 
vulnerability assessment. These parameters 
primarily depend on functioning and aesthetic 
purposes of buildings. For masonry buildings, 
considered attributes were wall thickness, 
maximum unsupported length of wall, corner 
separation, anchorage of wall to floor, anchorage of 
roof with wall, wall to wall anchorage, bracing of 
flexible floor or roof, existence of gable wall, 
horizontal band (Alam et al., 2010). 
 
In level II survey, detail of ground floor of a 
building was surveyed in addition to the features 
considered during level I survey. 
 
3.2 Level III survey 
The direct shear test for masonry load bearing 
buildings with the help of Hydraulic Jack operated 
machines had been conducted. After that some 
laboratory tests were done to determine the 
confined compressive strength of existing brick 
units, confined compressive strength of lime and 
cement mortar and shear strength of the lime mortar 
for the detailed assessment of the buildings. With 
the help of these tests each building was checked 
against the seismic load, height to thickness ratio, 
overhang ratio and old masonry building indices. 
 
3.3 Design Seismic Base Shear 
The design seismic base shear is the total design 
lateral force at the base of a structure. The total 
design lateral force or seismic base shear (VB) 
(BNBC, 1993) along any principal direction shall 
be determined by the following expression: 
 
VB=ZICW/R 
 
Where,  
Z = Seismic Zone Coefficient  
I = Structural Importance Coefficient  
R= Response Modification Coefficient 
W = Seismic weights of building.  
C= Numerical Coefficient given by 
C=1.25S/T2/3 
S= Site coefficient for soil characteristics 
T= Approximate fundamental natural period of 
vibration in second, is estimated by the empirical 
expression: 
T=Ct (hn) 3/4 
Ct=0.049 for masonry building 
hn= Height in metres above base level 
The design base shear (VB) is distributed along the 
height of the building as per the following 
expression: 
Qi = VB (Wi hi / ∑ Wi hi) 
Where, 
Qi = Designed lateral force at floor i, 
Wi = Seismic weight of floor i, 
hi = Height of floor i measured form base, and 
n = Number of storey in the building is the number 
of levels at which the masses are located 
 
3.4 Strength check for diaphragms 
Floor and roof diaphragms should be able to resist 
diaphragm forces Fpx as given below: 
 
 
Where, 
wpx =Weight of roof or floor diaphragm at the level 
x and  
Qi    = wi are lateral loads the i-th floor 
wi   = Seismic weights at the i-th floor 
The force Fpx determined from the above equation 
shall not be more than 0.75 ZIwpx and less than 0.35 
ZIwpx (BNBC, 1993). 
 
3.5 Shear Stress Check 
Shear stress at any level for load bearing wall: 
 
τwall = (Qi/Aw)  
 
Where 
Qi= Storey shear for piers in the grid  
Aw = Area of shear wall in the direction of loading. 
For unreinforced masonry load bearing wall 
building, the average shear stress, τwall shall be less 
than 0.1Mpa (Rai, 2005). 
 
3.6 Old Masonry Building Index 
Following three indexes were used for old masonry 
building indices check (Lourenço and Roque, 
2006): 
 
Index 1: In-plan area ratio 
γ1,i = Awi / S 
 
Index 2: Area to weight ratio  
γ2,i = Awi / G 
Page 195
  
 
Index 3: Base shear ratio 
γ3,i =VRd, i / VSd 
 
Where, 
VSd = Base Shear 
VRd, i= Shear Capacity in i direction 
S = The total Plan area 
Awi = Plan area of earthquake resistant walls in 
direction “i” 
Aw = Total in plan area of earthquake resistant walls 
Table 1:  Minimum recommended values for γ 
Index Allowable Value 
In Plan Area ratio,γ1 5% 
Area to Weight ratio,γ2 1.8 m2/MN 
Base Shear ratio,γ3 1 
 
3.7 Overhang Ratio 
In a typical floor plan, the area beyond the 
outermost lines on all sides is defined as the 
overhang area. The summation of the overhang area 
of each story, Aoverhang, divided by the area of the 
ground story, Agf, is defined as the overhang ratio.  
 
Overhang Ratio = ∑ Aoverhang / Agf  
 
3.8 Parapet Walls 
Non-structural falling hazards such as chimneys, 
parapets, cornices, veneers, and overhangs can pose 
life safety hazards if not adequately anchored to the 
building. The maximum height of unbraced 
unreinforced masonry parapet above the roof 
should not exceed 1.5 times the thickness of parapet 
wall (Rai, 2005). 
 
3.9 Height to Thickness Ratio 
The bearing walls are judged for out-of-plane 
stability based on their height to thickness (h/t) 
ratios. The following allowable ratio must be 
considered for unreinforced masonry bearing wall 
buildings with stiff diaphragms (Rai, 2005). 
Table 2:  h/t ratio for risk zone (Z = 0.15) 
Wall Type Allowable h/t 
Top storey of multi-storey building 14 
First storey of multi-storey building 18 
All other conditions 16 
 
3.10 Direct Shear Test 
Direct shear stress for bearing wall was conducted 
by using calibrated Hi force hydraulic jack, 
Pressure gauge reading = X 
Applied force in Plane, F = 0.0206 X +.169 
Contact surface area= A (2 face for 5 in wall and 3 
face for 10 in wall) 
Ultimate Shear Strength= F/A 
 
 
Fig. 3: Calibration curve for pressure gauge 
 
  
 
Fig. 4: Masonry unit failure (left) and Hydraulic 
Jack 
 
  
 
Damaged Units Deteriorated Mortar 
Vulnerable 
supports 
 
 
 
Inclined 
foundation Crack in lintel Courtyard 
 
 
 
Wooden floor Crack in Wall Corner 
separation 
 
Fig. 5: Defects and extent of damages in Shakhari 
Bazar. 
 
 
 
Page 196
  
3.11 Existing Damage 
For the masonry buildings vulnerability assessment, 
existing damage factors are very important. The 
structural faults those are identified are deteriorated 
mortar, damaged lintel, corner separation, wall 
crack, poor condition of supports etc. These 
structural faults caused structural vulnerability of 
surveyed buildings. Fig. 5 shows different types of 
damage factors in study area. 
 
3.12 Risk Scenario 
Risk Scenario was developed for existing buildings 
considering all importance factors. An engineering 
judgment was applied to classify the buildings in 
different risk group. Fig. 6 shows the way to 
categorize the risk group and Table 3 shows risk 
classification (EMS-98, 1998). 
 
Seismic Zone  Constant Building Importance  
 
Existing 
Damage  
Vulnerability 
Factor  
Structural 
Strength 
 
Risk Group 
Low 
Very 
Low 
 
Moderate 
 
High 
 
Very 
High 
 
 
Fig. 6: Steps of Risk Scenario Development 
 
Table3: Risk Group 
Risk 
Group  
Brief Description 
Very High  Building is in near collapse position  
High  Crack in walls, Corner separation, 
Structural Elements Poor Condition, 
Structural performance low  
Moderate  Cracks in infill, Mortar condition 
Poor, Moderate Structural 
Performance  
Low  Hair Crack in structural elements, 
No severe damage, with some 
vulnerability, Structural 
performance good  
Very Low  Building in good shape, 
Vulnerability very low, Structural 
checks satisfied 
 
4. RESULTS 
 
Most of the buildings in Shakhari Bazar bear the 
symbol of ancient settlement of old Dhaka. About 
20% of the surveyed buildings carry some symbols 
of architecture of 1600 A.D. Although many of 
these symbols have either been decay or modified 
over the time due to different interventions, still 
these holds the heritage of 400 years of Dhaka. 
 
In Shakhari Bazar there is no recent construction 
due to government restriction. This has restricted 
the owners to construct existing house vertically. 
Among the surveyed buildings in Shakhari Bazar 
most of the buildings are 3 storied and above. 
 
1 2 3 4 >=5 
0
5
10
15
20
25
30
35
N
o
.
 
o
f B
u
ild
in
gs
No. of Stories
 
 
Fig.7: Building Storey Distribution 
 
<10  10 - 50  50 - 100 100 - 150 >=150
0
10
20
30
40
50
60
N
o
.
 
o
f B
u
ild
in
gs
Age of Buildings
 
 
Fig.8: Relationship between building age and 
buildings age 
Page 197
  
 
About 61 of the surveyed buildings are more than 
150 years old and owned by individual and these 
buildings are constructed on limited area. 
Moreover, ownership conflicts over the years, 
many of the buildings are not well maintained. As a 
result the apparent quality of buildings was found 
poor during this study. About 62% of the surveyed 
buildings appear to be poor in quality assessment. 
About 31% of the bindings are in average condition 
since these were repaired time to time by the 
owners. 
 
62%
31% 7%
 Good
 Moderate
 Poor
 
 
 
 
Fig.9: Apparent quality of buildings 
 
Building shape and elevation are one of the major 
factors affecting buildings during an earthquake. 
From the experience of different earthquake, it is 
understood that the buildings with irregular shape 
are more damaged then the buildings that are of 
regular shape. Similarly elevation of building is 
also another important factor responsible for 
damages in buildings during an earthquake. Narrow 
tall buildings are more vulnerable during an 
earthquake. About 40% of the buildings have 
‘Setback’ irregularities in elevation and 20% of the 
surveyed builds are of ‘narrow tall’ category. On 
the other hand, 12% buildings are irregular shape in 
building plan. Among the surveyed buildings about 
10% of buildings found with heavy overhangs. 
 
Regular Set back Narrow Tall
0
5
10
15
20
25
30
35
40
Pe
rc
en
ta
ge
 
o
f b
u
ild
in
gs
(T
o
ta
l =
 
82
)
 
 
Fig10: Building Shape in Elevation 
 
Rectangular Narrow Rec. Irregular
0
10
20
30
40
50
Pe
rc
en
ta
ge
 
o
f B
u
ild
in
gs
 
(T
o
ta
l =
 
82
)
 
 
Fig11: Shape in Building Plan  
 
Among the buildings, 89% were found with 
deteriorated mortar, 75% with damaged lintel, 47% 
corner separation, 85% crack in wall, 44% giant 
crack in bearing wall and 49% with poor cornices. 
 
Considering the above stated results and with the 
help of Destructive and Laboratory tests, some 
structural checks had been conducted in the study, 
and the results are depicted in Table 4. 
 
Table 4: Structural checks results 
Structural Check 
No. of Buildings 
Satisfied Not Satisfied 
Shear Stress Check 35 47 
Strength check for  
diaphragms 42 40 
Old Masonry index 43 39 
Overhang Ratio 68 14 
h/t ratio 28 54 
Page 198
  
Parapet Walls 57 25 
 
 
5. CONCLUSIONS 
 
The present study shows that among the surveyed 
buildings, about 36% were found to be in high risk 
category and 7% of the buildings were found to be 
in severe risk category and therefore, in a position 
to be collapsed. Serious lacks in maintenance of 
buildings by the owners were identified. Since 
these old masonry buildings have been declared as 
the heritage building, seismic retrofitting is the 
recommended technique to minimize the 
earthquake effects. Following are key 
recommendations from the study which could be 
taken into consideration for ensuring seismic safety 
of the surveyed buildings; 
• Extra Stories of the building should be 
demolished and the building should be 
restored in original shape and storey. 
• Some recent extensions constructed by the 
owners, such as, the heavy overhangs or 
cantilevers should be demolished. 
• According to the assessment result, height 
to thickness ratio is the most governing 
issue to be addressed if retrofitting is 
opted.   
• In cases when the height to thickness ratio 
of the walls exceeds the limits of stability, 
rehabilitation could be done by reducing 
the span between the walls. 
 
Very Low Low Moderate High Very High
0
5
10
15
20
25
30
35
40
Pe
rp
er
ce
n
ta
ge
 
o
f B
ui
ld
in
gs
(T
o
ta
l =
 
82
)
 
 
Fig. 12: Risk Group Distribution 
 
 
5. REFERENCES 
 
1. Afsana, D. (2004). “Land use Conversion in 
Urban Residential Neighborhoods and Its 
Impact on the Physical Environment: A case 
Study in Dhaka, Bangladesh”, unpublished 
M.Sc. thesis, Dissertation No. UE-04-07, AIT, 
Bangkok, Thailand. 
2. Alam M N, Mashfiq K, Rahman A & Haque S 
M (2010) “Seismic Vulnerability assessment of 
buildings in Heritage and Non-Heritage Areas 
in the older part of Dhaka City”, 3rd 
International Earthquake Symposium, 
Bangladesh, Dhaka.  
3. Arimah, B.C. (2000), “Housing-Sector 
Performance in Global Perspective: A Cross-
city Investigation”; Urban Studies 13: 2551-
2579. 
4. ATC-21, (1988), “Rapid Visual Screening of 
Buildings for Potential Seismic Hazards: A 
Handbook”, Applied Technology Council, 
Redwood city, CA, USA. 
5. BNBC (1993), “Bangladesh National Building 
Code”. 
6. Comprehensive Disaster Management Program 
(2009), “Seismic Hazard & Vulnerability 
Assessment of Dhaka, Chittagong & Sylhet 
City Corporations”, Dhaka, Bangladesh. 
7. EMS-98 (1998), “European Macroseismic 
Scale 1998”. 
8. FEMA 274 (1997), “Guidelines for The 
Seismic Rehabilitation of Buildings”. 
9. FEMA 310. (1998), “Handbook for the 
Seismic Evaluation of Buildings”. 
10. Lourenço, P.B., Roque, J.A., (2006), 
“Simplified indexes for seismic vulnerability of 
ancient masonry buildings, Construction and 
Building Materials”. 
11. Rai Durgesh C. (2005) “Iitk-Gsdma Guidelines 
for Seismic Evaluation and Strengthening of 
Buildings”. 
12. Seraj, T. M. & Alam, M. S. (1989). “Housing 
Problem and Apartment Development in 
Dhaka City, Dhaka: Past Present Future”; 
Dhaka, The Asiatic Society of Bangladesh.  
13. The Daily Bangladesh Observer: “Building 
collapse at Shankhari Bazar” Article, 10th June, 
Dhaka, Bangladesh. (2004). 
 
 
Page 199
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, SUST, Sylhet, Bangladesh  
*
 Corresponding Author: Ram Krishna Mazumder 
E-mail: rkmazumder@gmail.com 
SEISMIC RISK ANALYSIS FOR THE SCHOOLS OF SYLHET CITY, 
BANGLADESH 
 
 
R. K. Mazumder*, M. Ahmed 
Civil and Environmental Engineering, Shah Jalal University of Science and Technology, Sylhet-
3114, Bangladesh 
 
M. R. Raju 
Ahsanullah University of Science and Technology, Dhaka, Bangladesh 
 
 
Bangladesh is one of the most earthquake prone countries in southern part of Asia, where Sylhet is the most 
risky region to an earthquake as it is situated in Dauki fault zone. The main objective of the study was to 
evaluate the structural safety of some renowned schools of Sylhet city due to earthquakes of different 
intensities. Engineering judgment from site visit, questionnaire survey, drawings and prevailing practices of 
building construction in this region was used as the methodology of the study. It was revealed from the study 
that at a probable intensity EMS IX, Damage Grade (DG) will be DG3, DG4 and DG5 with 60%, 26.7% and 
13.3% buildings respectively. It was also found that the masonry schools are in most vulnerable condition 
(40% of the schools have DG5 and 40%- DG4) and the reinforced concrete schools are comparatively in less 
vulnerable condition (80%- DG4). The study also puts forward some recommendations regarding future 
course action that needs to be undertaken for the buildings assessed. 
  
Key words: Schools, Seismic vulnerability, Sylhet city, Intensity, Damage Grade 
 
1. INTRODUCTION 
 
Bangladesh is one of the most earthquake prone 
countries in southern part of Asia. Sylhet, the north- 
eastern region of Bangladesh, is most risky to an 
earthquake as it is situated in Dauki fault zone. The 
schools are the places where hundreds of students, 
the future of the nation, get together every day for 
study purpose. So, school buildings must have 
enough structural safety to avoid mass injury and 
fatality during an earthquake. Unfortunately a 
significant number of the school buildings of the 
city are old and non- structured. So, there should be 
a thorough   investigation to evaluate the 
vulnerability of the school buildings due to a 
probable earthquake and find individual solutions 
for strengthening each of the buildings to ensure its 
structural safety. In this context an attempt was 
taken to evaluate the structural safety of some 
renowned schools of the city due to earthquakes of 
different intensities. 
 
 
2. STUDY AREA 
 
Sylhet City Corporation occupies a total area of 
26.5 sq. km with a population of around 0.5 
million. It is one of the seven divisional cities of 
Bangladesh. There are about seventy schools in the 
city area. From them eight renowned schools were 
selected for the study (Figure 1). Among them there 
are four primary schools: Burhan Uddin Govt. 
Primary School, Durga Kumar Govt. Primary 
School, Ghashitula Govt. Primary School and 
Mendibag Govt. Primary School and four high 
schools: Dakshin Surma Nasiba Khatun Girls High 
School, Syed Hatim Ali Govt. High School, Sylhet 
Govt. Pilot High School and Sylhet Model High 
School. 
 
The existing school buildings are of mainly two 
types: (1) reinforced concrete frame buildings with 
infill brick walls and (2) brick masonry buildings 
with reinforced concrete roofs and using cement 
mortar in most of the cases. These two categories 
fall under engineered construction in which 
assistance from qualified structural engineers are 
sought at each stage in most of the cases. Most of 
the buildings were constructed within last 30 years. 
 
Page 200ISBN: 978-984-33-2140-4
  
 
 
Fig. 1: Location of the Schools in Sylhet City 
Corporation 
 
3. METHODOLOGY 
 
Seismic vulnerability estimation is a complex 
process, which has to take into account not only the 
design of building but also the deterioration of the 
materials and damages of the building, if any. The 
difficulties faced in seismic vulnerability estimation 
of a building are manifold. There is no reliable 
information available for existing building stock, 
construction practices, in-situ strength of material 
and components of the building, and therefore, 
seismic vulnerability estimation mainly relies on set 
of general evaluation statements.  
 
Engineering judgment from site visit, questionnaire 
survey, drawings and prevailing practices of 
building construction in this region was used as the 
methodology of the study. All possible efforts have 
been made to provide accurate and authoritative 
seismic vulnerability assessment of the buildings in 
the given circumstances of information provided by 
school administration. Qualitative and some 
quantitative structural assessment of the buildings 
are done based on visual observation and review of 
drawings, design details observed at site during 
field visit. The evaluation involves a set of checklist 
and identifies areas of potential weakness in the 
building. After analyzed, buildings are classified 
into different damage grades for different 
intensities using European Macroseismic Scale.  
 
3.1 Identification of Vulnerability Factors  
Prior to conducting a FEMA 310 Evaluation, 
All available documents collected and reviewed. 
Different Vulnerability factors associated with the 
particular type of building are checked with a set of 
appropriate checklists from FEMA 310, “Handbook 
for the Seismic Evaluation of Buildings” and Indian 
Standard Guidelines for Seismic Evaluation and 
Strengthening of Existing Buildings. The basic 
vulnerability factors related to Building system, 
Lateral force resisting system, Connections, 
Diaphragms are evaluated based on visual 
inspection and review of drawings. Table 1 shows 
an evaluation form to identify the potential 
vulnerability factors (FEMA 310, 1998). 
Table 1: Influences of Different Vulnerability 
Factors (FEMA 310)  
Vulnerability Factors 
Building system 
Number of storey 
Shape 
Proportion in plan 
Opening in wall 
Position of opening 
Load Path 
Adjacent buildings 
Mezzanines floors 
Deterioration of concrete 
Masonry units 
Masonry joints 
Cracks in infill walls 
Unsupported wall length 
Plan 
irregularities 
Torsion 
Diaphragm continuity 
Vertical 
irregularities 
Weak storey 
Soft storey 
Mass irregularity 
Vertical geometric irregularity 
Vertical discontinuities 
Lateral load 
resisting system 
 
Redundancy 
Height to thickness ratio 
Masonry lay up 
Vertical reinforcement  
Horizontal bands 
Corner stitch 
Gable band 
Diagonal bracing 
 
Diaphragm 
Diaphragm opening at walls 
Plan irregularities 
Page 201
  
Diaphragm reinforcement at 
opening 
Connections 
Wall anchorage 
Transfer to walls 
Lateral restrainers 
Geologic site 
Area history 
Liquefaction 
Slope failure 
Others Non structural components 
 
Vulnerability factors are identified by different 
parameters that may High, Medium, Low, N/A or 
not known. 
  
3.2 Design Seismic Base Shear 
The design seismic base shear is the total design 
lateral force at the base of a structure. The total 
design lateral force or seismic base shear (VB) 
(BNBC, 1993) along any principal direction shall 
be determined by the following expression: 
 
 VB=ZICW/R 
 
Where,  
Z = Seismic Zone Coefficient  
I = Structural Importance Coefficient  
R= Response Modification Coefficient 
W = Seismic weights of building 
C= Numerical Coefficient given by 
C=1.25S/T2/3 
S= Site coefficient for soil characteristics 
The approximate fundamental natural period of 
vibration (T), in second for moment resisting frame 
buildings with brick infill panels may be estimated 
by the empirical expression: 
T=Ct (hn) 3/4 
Ct =0.083 for steel moment resisting frame, 
 =0.073 for reinforced concrete moment 
resisting frames and eccentric braced steel frames, 
 =0.049 for all other structural systems  
hn= Height in metres above base level 
The design base shear (VB) is distributed along the 
height of the building as per the following 
expression: 
Qi = VB (Wi hi / ∑ Wi hi) 
Where, 
Qi = designed lateral force at floor i, 
Wi = seismic weight of floor i, 
hi = height of floor i measured form base, and 
n = number of storey in the building is the number 
of levels at which the masses are located 
 
3.3 Calculation of Shear Stress 
For Masonry; shear stress at any level for load 
bearing wall:  
 
τwall = (Qi/Aw)  
 
Where 
Qi= Storey shear for piers in the grid  
Aw = Area of shear wall in the direction of loading. 
 
For unreinforced masonry load bearing wall 
building, the average shear stress, τwall shall be less 
than 0.1Mpa (Rai, 2005). For Reinforced Concrete 
Structure; average shear stress in columns is given 
as (Rai, 2005): 
 
τcol = (nc/(nc-nf))*(Vi/Ac) < min of 0.4Mpa and 
0.1√ fck  
 
Where 
nc = Total no. of columns resisting lateral forces in 
the direction of loading 
nf  = Total no. of frames in the direction of loading 
Ac = Summation of the cross-section area of all 
columns in the storey under consideration 
Vi = Maximum storey shear at storey level 'i' 
fck= characteristic cube strength of concrete 
 
3.4 Strength Check for Diaphragms 
Floor and roof diaphragms should be able to resist 
diaphragm forces Fpx as given below (Rai, 2005): 
  
 
Where, 
wpx =weight of roof or floor diaphragm at the level 
x  
Qi    = wi are lateral loads the i-th floor 
wi   = seismic weights at the i-th floor 
 
The force Fpx determined from the above equation 
shall not be more than 0.75ZIwpx and less than 
0.35ZIwpx (BNBC, 1993). 
 
3.5 In-Plane Bending in Masonry Piers 
Tension stress:  
 
σ = -P/A+M/Z  
 
Where,  
M= Moment = Distributed Shear in one grid X 
Height of storey 
A= Area = Total area of base of piers in one grid 
P= Load = Total gravity load of piers in one grid 
Z= Section Modulus = Sum of Section modulus of 
piers in one grid 
 
Page 202
  
Permissible tension stress for bending in the 
vertical direction where tension developed is 
normal to bed joints is 0.05 N/mm2 (Rai, 2005). 
 
 
3.6 Out-of-Plane Bending in Masonry Piers  
 
σ = M/Z and M= w X L2/10  
 
Where,  
M= Moment 
w = Uniform dead load of wall 
L = length of wall supported on cross wall 
Z= Section Modulus  
σ = Tension stress  
 
Permissible tension stress for bending in the 
vertical direction where tension developed is 0.10 
N/mm2 (Rai, 2005). 
 
3.7 Axial Stress Check  
The axial stress due to gravity loads in column  
 
σ = Load on column (Fo) / Cross section Area of 
Column (A) 
 
Axial force in columns of moment frames at base 
due to overturning forces, 
 
Fo = (2 VB H) / (3 nf L)  
 
VB = Base shear  
nf = Total no of frames in the direction of loading  
H = Total height in meters  
L = Length of the building in meters  
Permissible axial stress shall be less than 0.25 fck 
(Rai, 2005). 
 
3.8 Masonry Building Index 
Following three indexes were used for old masonry 
building indices check (Lourenço and Roque, 
(2006) : 
 
Index 1: In-plan area ratio 
γ1,i = Awi / S 
 
Index 2: Area to weight ratio  
γ2,i = Awi / G 
 
Index 3: Base shear ratio 
γ3,i =VRd, i / VSd 
 
Where, 
VSd = Base Shear 
VRd, i= Shear Capacity in i direction 
S is the total Plan area 
Awi = Plan area of earthquake resistant walls in 
direction “i” 
Aw = total in plan area of earthquake resistant walls 
 
Table 2:  Minimum recommended values for γ 
Index Allowable Value 
In Plan Area ratio,γ1 5% 
Area to Weight ratio,γ2 1.8 m2/MN 
Base Shear ratio,γ3 1 
 
3.9 Overhang Ratio 
In a typical floor plan, the area beyond the 
outermost frame lines on all sides is defined as the 
overhang area. The summation of the overhang area 
of each story, Aoverhang, divided by the area of the 
ground story, Agf, is defined as the overhang ratio.  
 
Overhang Ratio = ∑ Aoverhang / Agf  
 
3.10 Parapet Walls 
Non-structural falling hazards such as chimneys, 
parapets, cornices, veneers, and overhangs can pose 
life safety hazards if not adequately anchored to the 
building. The maximum height of unbraced 
unreinforced masonry parapet above the roof 
should not exceed 1.5 times the thickness of parapet 
wall (FEMA 310, 1998). 
 
3.11 Height to Thickness Ratio 
The bearing walls are judged for out-of-plane 
stability based on their height to thickness (h/t) 
ratios (Rai, 2005). The following allowable ratio 
must be considered for unreinforced masonry 
bearing wall buildings with stiff diaphragms. 
 
Table 3:  h/t ratio for risk zone (Z = 0.25) 
Wall Type Allowable h/t 
Top storey of multi-storey building 14 
First storey of multi-storey 
building 16 
All other conditions 16 
 
 
3.12 Damage Classification 
The Damage grade of a building is the possible 
consequence to the building due to the probable 
earthquake shaking. The damage grade is expressed 
as the degree of severity of damage in a building 
during different earthquake intensities.  
Classification of damage according to the degree of 
severity is shown in table 4 (EMS-98, 1998). 
Normally, the buildings with similar structural 
systems and properties behave in similar pattern 
during the earthquakes. Hence, generalized fragility 
functions are available for different types of 
building. In Bangladesh case, fragility functions 
Page 203
  
from Nepal, India and Pakistan are utilized and 
verified with “European Macro-seismic Scale 
(EMS-98, 1998)”. Damage grades of different 
building typologies in different intensities of 
earthquakes are extracted from such fragility 
functions. 
 
Table 4: Classification of damage to buildings 
Damage Class Damage Potential 
Grade 1: Negligible to 
slight damage 
Slight non-structural 
damage 
Grade 2: Moderate 
damage 
Slight structural damage 
and moderate non-
structural damage 
Grade 3: Substantial 
to heavy damage 
Moderate structural 
damage and heavy non-
structural damage 
Grade 4: Very heavy 
damage 
Heavy structural damage 
and very heavy non-
structural damage 
Grade 5: Destruction Very heavy structural 
damage or collapse 
 
Damage grades for the identified Masonry 
Buildings and Reinforced Concrete Ordinary 
Moment Resisting Frame Buildings are given 
below in tables 5 and 6 respectively. 
 
The European Macroseismic Scale (EMS) is a unit 
to measure the intensity of earthquake in a 
particular area. The EMS is a qualitative measure of 
the actual shaking at a location during earthquake, 
and is assigned as Roman Capital Numerals. It 
ranges from I (least perceptive) to XII (most 
severe). The intensity scales are based on three 
features of shaking- perception by people and 
animals, performance of buildings, and changes to 
natural surroundings. 
 
Table 5: Fragility of the Masonry Buildings on 
Brick in Cement Mortar 
Shaking Intensity 
(EMS) VII VIII IX 
Damage 
Grades for 
Different 
Classes of 
Buildings 
Weak DG3 DG4 DG5 
Average DG2 DG3 DG4 
Good DG1 DG2 DG3 
 
The table 5 shows that the weaker buildings of this 
category get damage degree of five (DG5) at 
intensity IX where as good buildings of this 
category will suffer damage degree of three (DG3) 
at the same intensity. 
 
The minimum requirement of the building is to 
provide life safety for its occupants. It may not be 
obtain when the performance of building will be 
DG4 or DG5 during earthquake. 
 
The table 6 shows that the weaker buildings of this 
category get damage degree of four (DG4) at 
intensity IX where as good buildings of this 
category will suffer damage degree of two (DG2) at 
the same intensity. 
 
Table 6: Fragility of the Reinforced Concrete 
Ordinary Moment Resisting Frame 
Shaking Intensity 
(EMS) VII VIII IX 
Damage 
Grades for 
Different 
Classes of 
Buildings 
Weak DG2 DG3 DG4 
Average DG1 DG2 DG3 
Good - DG1 DG2 
 
 
4. RESULTS AND DISCUSSION 
 
Figure 2 represents the overall damage risk scenario 
for school buildings with respect to different 
intensity. Based on the assessment done above on 
the basis of the available information about the 
buildings, the architectural and structural 
information obtained from field visit, it is identified 
that the assessed buildings are  is likely to suffer 
moderate to very heavy structural damage at large 
earthquakes of intensity EMS IX. 
 
 
 
Fig. 2: Damage Risk Scenario for School in 
Sylhet 
 
For intensity EMS VII, damage grade will DG1, 
DG2 and DG3 with 40%, 46.7% and 13.3% 
Page 204
  
buildings respectively. At intensity EMS VIII, 
damage grade will DG2, DG3 and DG4 with 60%, 
26.7% and 13.3% buildings respectively. At 
intensity EMS IX, damage grade will DG3, DG4 
and DG5 with 60%, 26.7% and 13.3% buildings 
respectively. Structural check results for 15 
buildings represent in table 7. Table 8 and table 9 
represent the risk percentage for masonry and 
reinforced concrete structure. 
 
Table 7: Structural checks results 
Structural 
Check 
Percentage Total 
Buildings Satisfied Not Satisfied 
Shear Stress 
Check 73.3 26.7 15.0 
Axial Stress 
check  70.0 30.0 10.0 
Strength 
check for  
diaphragms 
60.0 40.0 5.0 
In-Plane 
bending  80.0 20.0 5.0 
Out-of-Plane  
bending  40.0 60.0 5.0 
Masonry 
index 40.0 60.0 3.0 
Overhang 
Ratio 90.0 10.0 10.0 
h/t ratio 60.0 40.0 5.0 
Parapet 
Walls 80.0 20.0 5.0 
 
Table 8: Damage grade for Masonry buildings in 
different Intensity 
Intensity  
(EMS) 
Damage Grade 
DG1 DG2 DG3 DG4 DG5 
VII 20% 40% 40% 0% 0% 
VIII 0% 20% 40% 40% 0% 
IX 0% 0% 20% 40% 40% 
 
Table 9: Damage grade for Reinforced Concrete 
Frame buildings in different Intensity 
Intensity 
(EMS) 
Damage Grade 
DG1 DG2 DG3 DG4 DG5 
VII 50% 50% 0% 0% 0% 
VIII 0% 80% 20% 0% 0% 
IX 0% 0% 20% 80% 0% 
 
5. CONCLUSIONS 
 
From the assessment, it was evident that some 
school buildings in Sylhet fall under high to severe 
risk category. Serious lacks in maintenance of 
buildings were identified. Seismic retrofitting is the 
recommended technique to minimize the 
earthquake effects. Following are key 
recommendations from the study which could be 
taken into consideration for ensuring seismic safety 
of the surveyed buildings; 
• Detail evaluation and retrofit design is 
recommended based on the identified 
weakness in this present study. 
• Retrofitting of this building is feasible. 
However, before taking up any retrofitting 
program, a detailed study of building, its 
structural system and materials is 
recommended.  
• In cases when the height to thickness ratio 
of the walls exceeds the limits of stability, 
rehabilitation could be done by reducing 
the span between the walls. 
• Non-structural elements (partitions, false 
ceiling, furniture, equipment etc.) should 
be fixed properly for restricting their 
movement to prevent from overturning, 
sliding and impacting during an 
earthquake. 
 
REFERENCES 
 
1. ATC-21, (1988), “Rapid Visual Screening of 
Buildings for Potential Seismic Hazards: A 
Handbook”, Applied Technology Council, 
Redwood city, CA, USA. 
2. BNBC, (1993), “Bangladesh National Building 
Code”. 
3. EMS-98, (1998), “European Macroseismic 
Scale 1998”. 
4. Federal Emergency Management Agency, 
(1998). “FEMA 310: Handbook for the 
Seismic Evaluation of Buildings - A Pre 
standard, Washington D.C”. 
5. IS: 1893-2002, (2002), “Criteria for 
Earthquake Resistant Design of Structure”, 
Bureau of Indian Standards, New Delhi. 
6. Lourenço, P.B., Roque, J.A., (2006), 
“Simplified indexes for seismic vulnerability of 
ancient masonry buildings, Construction and 
Building Materials” 
7. Rai D. C., (2005), “IITK-GSDMA Guidelines 
for Seismic Evaluation and Strengthening of 
Buildings” 
Page 205
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Kaish A. B. M. Amrul,  
E-mail: amrul.cuet@gmail.com 
STRENGTHENING OF SQUARE RC COLUMN USING LOW-COST 
SQUARE FERROCEMENT JACKETING TECHNIQUE 
 
 
Kaish A. B. M. Amrul*, Wahed Md. Abdul 
Housing and Building Research Institute, Dhaka, Bangladesh 
 
 
This paper deals about the efficacy of low-cost square Ferrocement Jacketing technique in strengthening of 
square reinforced concrete column. Usually square jacketing technique can not effectively provide lateral 
confinement due to stress concentrations at the corners which results patterns of cracking. The study focuses 
on the limitations and consequent improvement of square jacketing technique. In order to achieve this, 
various square jacketing schemes (SL, RSL, SKSL, and SLTL) are taken into account. It is found from the 
test results that the benchmark specimen developed its design strength but a non-ductile mode of failure 
occurred when the peak load was reached. The jacketed specimen's exhibited an enhanced load carrying 
capacity. But only type SLTL showed excellent ductility performance. All other type of specimens showed a 
brittle mode of failure with enhanced load carrying capacity. 
 
Key words: Strengthening, Column Jacketing, Ferrocement, Lateral confinement, Low-cost 
 
1. INTRODUCTION 
 
Strengthening of reinforced concrete structures are 
needed when their proper function is modified or 
they are used in a different manner than previously 
planned. It is also necessitated due to upgrading the 
seismic provisions of previous code suggesting 
better techniques. New strengthening techniques of 
RC structures have been suggested in recent years. 
 
Strengthening of the reinforced concrete structures 
is one of the most difficult and important tasks to 
perform (Mieczyslaw and Tomasz, 2006). 
Structures must be carefully examined and 
analyzed their technical design in order to 
determine the structural conditions as well as to 
carry out suitable measures. The strengthening 
techniques applied should be effective but also a 
low cost one as cost effectiveness is the main 
concern for developing countries like Bangladesh. 
 
Column is the structural element designed to 
support the vertical loads. It is the most important 
element of a frame-structure building providing a 
great portion of both vertical and lateral stability, 
especially in high rise building. Failure of column 
is very much catastrophic than failure of other 
elements.  It may lead to total collapse of a building 
as it is the only structural element that transfers the 
load of the building to the ground (Kaish and 
Hassan, 2008). 
 
Reinforced concrete columns require lateral 
confinement for enhanced performance against 
axial loads. Lateral confinement in a column is 
provided with lateral ties in the form of individual 
rings or in the form of continuous spirals running 
from top to bottom of the column (Rajasekaran, et. 
al., 2008). Lateral confinement is necessary in order 
to ensure large deformation under load hence 
ductility and provide adequate resistance capacity. 
In the case of a seismic event, energy dissipation 
allowed by a well confined concrete core can often 
save human lives. On the contrary, a poorly 
confined concrete column behaves in a brittle 
manner leading to sudden and catastrophic failures 
(Renato and Antonio). Inadequate axial load 
carrying capacity and axial ductility of column are 
the key factors among many other factors 
responsible for the collapse of many reinforced 
concrete buildings during 1999 Chi-Chi Taiwan 
earthquake (K. Chyuan and M. Lang,  2002). So, it 
is very important to develop low cost but efficient 
techniques to retrofit the columns to increase their 
axial ductility and axial load carrying capacity. 
However, conducted researches have shown, that 
the compressive strength of core concrete, ultimate 
concrete compressive strain and ductility of the 
strengthened column increased significantly if 
proper external confinement by means of jacketing 
were provided (Saadatmanesh, et. al., 1997, 
Masukawa, et. al., 1997, Xiao, et. al., 1999, 
Priestley, et. al., 1994). 
 
Page 206ISBN: 978-984-33-2140-4
  
Ferrocement can be an ideal means of jacketing 
especially in developing countries. Material cost in 
this case is relatively low and thanks to its 
durability it spares the need for any special fire or 
corrosion protection. Its manufacturing is easy and 
needs no advanced techniques (Kazemi and 
Morshed, 2005). It being suitable for both pre-
fabrication and self-help construction could lead 
Ferrocement to become one of the most 
inexpensive and attractive alternative techniques for 
strengthening and rehabilitation of existing and 
damage concrete columns for both axial & shear 
capacity. 
 
Normally three types of jacketing technique is used 
to strengthen a square/rectangular RC column, such 
as: (a) Square/Rectangular Jacketing, (b) Circular 
Jacketing, (c) Octagonal Jacketing, etc. Among 
these types of jacketing technique, first one is the 
most time saving and a low cost solution because of 
its fabrication. Later two requires shape 
modification which is time consuming as well as 
costly with respect to the previous one. But the 
problem behind the square/rectangular type 
jacketing is, it only provides confinement pressure 
at the corner. It relies on arching action for 
confinement; thus, only a portion of the cross 
section is effectively confined. 
 
 
 
Fig. 1: Effectively confined concrete in a 
square/rectangular column. 
 
In recent years researchers are trying both 
experimentally and analytically to overcome the 
drawbacks of square/rectangular jacketing 
technique. Investigations were carried out to reduce 
the stress concentration at the corner of FRP 
strengthened square columns.  Published researches 
shows that, jacketing with rounded corner gives 
certain degrees of confinement by reducing stress 
concentration at corners (Al-Salloum, Y. A. 2006, 
Wang L., 2007). 
 
Limited studies were reported for the similar work 
in case of Ferrocement strengthened RC column.  
This research was carried out to overcome the 
drawbacks of square jacketing technique in case of 
Ferrocement strengthened RC column. 
Investigations were carried out on seventeen square 
columns under monotonic concentric load. Five 
columns were tested without any jacketing 
(considered as Benchmark, denoted as NJ), three 
with Ferrocement jacketing using single layer wire 
mesh (denoted as SL), two with Ferrocement 
jacketing using single layer wire mesh after 
rounding column corners (denoted as RSL), three 
with Ferrocement jacketing  using single layer wire 
mesh with shear keys at the center of each faces 
(denoted as SKSL), three with Ferrocement 
jacketing using single layer wire mesh with two 
extra layer mesh at each corner (denoted as SLTL). 
 
 
 
Fig. 2: Various jacketing schemes (a) SL, (b) RSL, 
(c) SLTL, (d) SKSL. 
 
Experimental results and mode of failure confirms 
that, Type RSL, SLTL and SKSL jacketing scheme 
significantly  reduces the stress concentrations at the 
corner which leads to enhanced carrying capacity.   
 
2. EXPERIMENTAL STUDY 
  
Reinforced concrete column specimens for the 
experimental study were of size 100 mm X 100 mm 
and 600 mm long, reinforced with 4-8 mm Grade 
60 (414 MPa) longitudinal bar. Lateral 
reinforcement was providing by 6 mm Grade 60 
(414 MPa) tie spaced at 100 mm on centre. The mix 
design for the concrete was determined for sand to 
aggregate volume ratio = 0.55, cement content = 
360 kg/m3, air content = 2% and W/C=0.45. Coarse 
aggregate used for making concrete was 12 mm 
downgraded stone chips. The fineness modulus 
(FM) and specific gravity of sand used in this 
investigation were 2.7 and 2.61 respectively. 
Normal tap water was used as mixing water. 
Saturated and surface dry sand and coarse 
aggregate were used for making the concrete. After 
Page 207
  
mixing, the workability of concrete was measured 
by a slump cone. Column specimens were made 
and demoulded after one day of casting. Later the 
specimens were cured continuously under water.  
 
2.1 Ferrocement jacketed specimen 
Ferrocement jacketing was done after 7 days of 
column casting. All strengthened columns were 
jacketed by 12 mm Ferrocement jacket with 20 
gages GI wire mesh of 12 mm opening. To avoid 
direct compressive load on Ferrocement jacket, 5 
mm clear gap was provided at the top and bottom 
of column. Both the jacketed and non-jacketed 
specimens were cured for 28 days from the date of 
casting. Fig. 3 and Table 1 shows the details of both 
non-jacketed and jacketed RC column specimens.  
 
 
 
Fig. 3: Details of column, (a) Long section of non-
jacketed column, (b) Long section of jacketed 
column, (c) Cross-section of non-jacketed column, 
(d) Cross section of jacketed column. 
 
Table 1: Specimen details 
2.2 Test setup 
After curing, all specimens were tested for 
monotonically increasing concentric load by a 
Compression Testing Machine of capacity 2000 
kN. Load was applied to the top of the concrete 
column. The axial deformation of column 
specimens were measured by a strain measurement 
setup with a dial gauge. 
 
3. EXPERIMENTAL RESULTS AND 
DISCUSSION 
 
Experimental results of tested specimens are 
summarized in Table 2. The increment in average 
ultimate load carrying capacity and average axial 
deformation of jacketed specimen are also shown in 
the table. The average load-axial deformation 
responses for the experimental columns are shown 
in Fig. 4. It can be seen from the Fig. 4, all types of 
specimen exhibits a brittle mode of failure except 
type SLTL. The ultimate loads of all the tested 
specimens are shown in Fig. 5. The percent 
increment in ultimate loads and ultimate axial 
deformations are shown in Fig. 6 and Fig. 7 
respectively. The failure modes of the specimens 
after the tests are shown in Fig. 8. 
 
Table 2: Ultimate axial load and deformation of 
tested specimens. 
Sp
ec
im
en
 
A
v
er
ag
e 
U
lti
m
at
e 
Lo
ad
 (k
N
) 
%
 In
cr
em
en
t o
f 
U
lti
m
at
e 
 
Lo
ad
  (k
N
) 
A
v
g.
 
U
lti
m
at
e 
A
x
ia
l 
D
ef
o
rm
at
io
n
 (m
m
) 
%
 In
cr
em
en
t o
f  
U
lti
m
at
e 
A
x
ia
l 
D
ef
o
rm
at
io
n
  
NJ 268.8 0 2.68 0  
SL 337.67 26 3.37 25.75  
RSL 360.5 34 3.85 43.65  
SKSL 304.33 13 3.52 31.34  
SLTL 402 50 5.34 99.25  
 
Sp
ec
im
en
 
H
ei
gh
t 
(m
m
) 
Cr
os
s-
se
ct
io
n
 
(m
m
) 
Lo
n
g 
B
ar
 
Ti
e 
B
ar
 
Ja
ck
et
 
Th
ic
kn
es
s 
(m
m
) 
NJ 
60
0 
10
0 
X
 
10
0 
4-
Φ

8 
6 
m
m
 
@
 
10
0 
m
m
 
- 
1L 12 mm 
R1L 12 mm 
SK1L 12 mm 
3L 12 mm 
Page 208
  
 
Fig. 4: Load-Axial deformation relationship.
 
3.1 Ultimate load response 
The axial load carrying capacity of all jacketed 
specimens is increased than the non
specimens. Type SKSL specimen shows lower 
carrying capacity than type SL specimen though 
both types of specimens contain same layer of wire 
mesh. This may be due to the nailing of shear keys 
into the column that weakens the 
RSL specimen shows higher carrying capacity than 
type SL specimen due to rounding the corners. 
Type SLTL specimen shows the highest carrying 
capacity than all types of specimen
specimen has two extra layer of wire mesh at each 
corner. This specimen shows fifty percent increased 
carrying capacity than the non-jacketed specimen.
 
 
Fig. 5: Ultimate load of specimens
 
 
 
-jacketed 
column. Type 
s as this 
 
 
 
 
Fig. 6: Percent Increment of ultimate load
 
3.2 Axial deformation response
All jacketed specimens show 
deformation, i.e. axial ductility at ultimate load 
level. Type SLTL shows the 
deformation at failure. The increment in axial 
deformation of this type of specimen is 99.25% 
than non-jacketed specimen. This value for type 
SL, RSL and SKSL specimens are 25.75%, 43
and 31.34% respectively. 
 
 
Fig. 7: Percent Increment of ultimate axial 
deformation  
 
3.3 Failure mode 
Failure mode of non-jacketed column (Type NJ) 
does not match with actual building column failure 
mode. Shear failure of concrete occurred at the top 
of the column due to load applied at the top. 
Whereas bursting failure occurs in actual building 
column. Failure mode of all the jacketed column is 
as it was expected.  In type SL specimen, cracking 
of corner occurs due to stress concentration at 
corners. In type RSL specimens, cracking occur
 
  
 
higher axial 
highest axial 
.65% 
 
s at 
Page 209
  
the middle of each face as rounding the corner 
reduces the stress concentration at corners. For type 
SKSL specimen, cracking occurs at both the corner 
and the middle of each face. Shear keys were used 
in this type of specimens make the middle of each 
face effective stress transfer zone. For type SLTL 
specimen, cracking occurs at the middle of each 
face only. No corner cracking is occurred in this 
type of specimen as extra two layer wire mesh 
strengthens the corner. 
 
       
 
   NJ                                         NJ 
       
 
  SL                                          SL 
       
 
  RSL                                     RSL 
        
 
  SKSL                                   SKSL 
     
 
  SLTL                                   SLTL 
 
Fig. 8: Final appearance of tested specimens. 
4. CONCLUSION 
 
This paper investigates the effectiveness of low-
cost square Ferrocement jacketing technique in 
strengthening of square building columns. Results 
Page 210
  
from experimental studies confirm that, square 
Ferrocement jacketing technique could be used 
effectively, if proper jacketing scheme is 
introduced. This is also clear from the experimental 
results that SLTL type jacketing scheme is the most 
effective jacketing scheme among other types used 
in the study. However, further research on full-scale 
columns is needed to warrant their application in 
strengthening of square building columns with high 
axial load risk. 
 
 
REFERENCES 
 
1. A. Rajasekaran, P.N. Raghunath and K. 
Suguna, (2008), Effect of confinement on the 
axial performance of fibre reinforced polymer 
wrapped RC column, American Journal of 
Engineering and Applied Sciences 1 (2): pp. 
110-117, ISSN 1941-7020. 
2. Al-Salloum, Y. A., (2006), Influence of edge 
sharpness on the strength of square concrete. 
columns confined with FRP composite 
laminates, Composites Part B: Engineering, 38, 
pp. 640-650. 
3. Kaish A. B. M. A., Hassan Md. Kamrul, 
(2008), Retrofitting of high rise building 
components, B.Sc. Thesis, Department of Civil 
Engineering, Chittagong University of 
Engineering and Technology, Chittagong, 
Bangladesh. 
4. Keh-Chyuan, Min-Lang Lin, (2002), Seismic 
jacketing of RC columns for enhanced axial 
load carrying performance, Journal of the 
Chinese Institute of Engineers, Vol. 25, No. 4, 
pp. 389-402. 
5. Masukawa J, Akiyama H, Saito H. (1997), 
Retrofitted of existing reinforced concrete piers 
by using carbon fiber sheet and aramid fiber 
sheet, Proceedings of the Third International 
Symposium on Non-Metallic (FRP) 
Reinforcement for Concrete Structures, p. 411–
8, October 1997, Sapporo, Japan. 
6. Mieczyslaw Kaminski, Tomasz Trapko (2006), 
Experimental behaviour of reinforced concrete 
column models strengthened by CFRP 
materials, Journal of Civil Engineering and 
Management, Vol XII, No 2, pp. 109–115.  
7. M. T. Kazemi, R. Morshed, (2005), Seismic 
shear strengthening of R/C columns with 
ferrocement jacket, Elsevier Journal of Cement 
& Concrete Composites, 27, pp. 834–842. 
8. Priestley MJN, Sieble F, Xiao Y, Verma R., 
(1994), Steel jacket retrofitting of reinforced 
concrete bridge columns for enhanced shear 
strength – Part II: Test results and comparison 
with theory. ACI Structural Journal; 
91(5):537–51. 
9. Renato Parretti, Antonio Nanni, Axial testing 
of concrete columns confined with   carbon 
FRP: effect of fiber orientation, 
<http://www.quakewrap.com/frp%20papers/A
xial-Testing-Of-Concrete-Columns-Confined-
With-Carbon-Frp-Effect-Of-Fiber-
Orientation.pdf >. 
10. Saadatmanesh H, Ehsani MR, Jin L., (1997), 
Repair of earthquake damaged RC columns 
with FRP wraps, ACI Structural Journal; 
94(2):206–15. 
11. Wang L., (2007), Effect of corner radius on the 
performance of CFRP-confined square 
concrete column, M. Phil Thesis, Department 
of Building and Construction, City University 
of Hong Kong. 
12. Xiao Y, Wu H, Martin GR., (1999), 
Prefabricated composite jacketing of RC 
columns for enhanced shear strength, ACI 
Structural Journal; 125(3):255–64. 
 
 
Page 211
 TRAND OF URBAN HEAT ISLAND (UHI) IN SYLHET CITY, 
BANGLADESH 
Mohammod Aktarul Islam Chowdhury, A.F.M. Kamal Chowdhury & Salahuddin Ahmmed 
Department of Civil and Environmental Engineering  
Shahjalal University of Science and Technology, Sylhet, Bangladesh 
Abstract 
Until recently, Sylhet City was known as the “green city” of Bangladesh due to its presence of 
green trees and hilly areas. Currently the city is known for its business boom; being one of the 
richest cities in Bangladesh, with new investments of hotels, shopping malls and luxury housing 
estates, brought mainly by expatriates living all over the world. METO (Metropolitan 
Environmental Temperature Observation) system was used to clarify the detailed temporal and 
spatial patterns of Urban Heat Island (UHI) in Sylhet City and meteorological equipments were 
installed on the rooftop of twelve buildings in the city comprising its rural surroundings as 
meteorological data acquisition stations from June to August, 2010. Analyzing the horizontal and 
vertical temperatures recorded in these stations, UHI indices of 1 0-30C has been found for the 
City. The high-rise infrastructures and widespread asphalt roads comprises a wide range of dry 
and dark surfaces which absorbs rather than reflects more sunlight during day time and radiate 
heat after sunset resulting the temperature to rise. During the night, the warmer area has been 
appeared in the highly urbanized centers of the city in compare to its rural surroundings. 
Obviously, unplanned urbanization is the major cause of UHI in Sylhet City. The impact of UHI 
on energy use and public health was also highlighted. Finally the paper suggests some guidelines 
to mitigate the UHI effects in the city. 
 
Keywords 
UHI index, temperature, unplanned urbanization, energy use, green building 
 
 
 
Page 212ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
 1. Introduction 
The urban heat island phenomenon was first 
discovered in the early 1800s in London. As 
urban areas develop, changes occur in their 
landscape. Buildings, roads, and other 
infrastructure replace open land and 
vegetation. Surfaces that were once 
permeable and moist become impermeable 
and dry. These changes cause urban regions 
to become warmer than their rural 
surroundings, forming an "island" of higher 
temperatures in the landscape [Climate 
Change Cell (CCC). (2009a)]. 
So far, most of the Urban Heat Island (UHI) 
phenomena have been detected in high and 
mid-latitude mega cities of the northern 
hemisphere. But many of the cities of 
developing countries are also associated 
with the effects of Urban Heat Island (UHI) 
where the urbanization is in progress.  
This study selected Sylhet City,  being 
urbanized with an alarming rate for one of 
the richest cities in Bangladesh, with new 
investments of hotels, shopping malls and 
luxury housing estates, brought mainly 
by expatriates living all over the world. The 
study aims to explain, first, the relationship 
between land-use changes and surface 
temperature to show clearly the horizontal 
and vertical distribution changes of daily 
temperature which are being altered with 
urbanization in Sylhet City. 
 
 
2. Methodology 
2.1 Horizontal Distribution Change of 
Daily Temperature  
The study has been used METO 
(Metropolitan Environmental Temperature 
Observation) system to clarify the detailed 
temporal and spatial patterns of Urban Heat 
Island (UHI) in Sylhet City.  Meteorological 
equipments were installed on the rooftop of 
12 buildings as meteorological data 
acquisition stations from June to August, 
2010. These 12 stations were installed in and 
out of Sylhet City to show clearly the 
horizontal distribution change of daily 
temperature. Temperature data was collected 
daily at 6 am, 12 pm, 6 pm and 12 am from 
June to August, 2010 in each of the stations. 
 
2.2 Vertical Temperature Profile 
Page 213
 For acquisition of vertical temperature 
profile and surface temperature by different 
land cover 8 high-rise buildings (Station 13 
to Station 20) were selected and air 
temperature in each of 10 feet height was 
recorded at 5pm to 8pm in an interval of 1 
hour. 
2.3 Annual Mean, Maximum and 
Minimum Temperature 
An assessment of annual mean, maximum 
and minimum temperature of Sylhet using 
weather station data operated by Bangladesh 
Meteorological Department (BMD) and 
Climate Change Cell (CCC) shows 
continuous warming of the region since 
1961. 
2.4 Application of Global Information 
System (GIS) and Remote Sensing (RS) 
The difference of surface temperature 
between urban infrastructures (buildings, 
roads) and vegetation area was determined 
using GIS and RS. A thermo-graphic camera 
system can remotely measure the surface 
temperature of the materials through 
infrared radiation. It acquits the distribution 
of surface temperature of the materials, 
easily and instantly. 
 
3. Results 
3.1 Sylhet Climate 
Temperature, rainfall, wind pattern and solar 
radiation mainly characterize the climate 
systems and determine the seasons. 
Brammer (2002) classified Bangladesh into 
four distinct climatic seasons. These are: (1) 
Pre-monsoon (March to May) with high 
temperatures and evaporation rates (2) 
Monsoon (June to September) with high 
intensity of rainfall occurrence (3) Post-
monsoon (October to November) 
characterized as hot and humid period with 
decreasing rainfall (4) Dry or winter season 
(December to February) portrayed as the 
coolest, driest and sunniest period of the 
year. 
The climate of Sylhet is 
tropical monsoon with a predominantly hot 
and humid summer and a relatively cool 
winter. The city is within the monsoon 
climatic zone, with annual average highest 
temperatures of 31°C in June-August and 
average lowest temperature of 10°C in 
January (Tawhidul-2010). Rashid (1991) 
provides detail descriptions about the pattern 
of climate variables of Bangladesh and 
Page 214
 characterizes the Sylhet climate as milder 
summer, heavy rainfall and cloudy cool 
winter. 
3.2 Assessment of Temperature 
Fluctuations 
Assessing meteorological data of 50 years 
(1960-2009), collected from the Sylhet 
Station of Bangladesh Meteorological 
Department (BMD) and Climate Change 
Cell (CCC), the average maximum and 
average minimum temperature from January 
to December has been determined (Figure -
3.1).Furthermore, a climate line has been 
determined by calculating the mean 
temperature for 50 years from 1960 to 2009. 
Then yearly temperature deviations from 
that climate line have been determined. 
 
 
Figure 3.1: Average maxi and average 
min temperature from January to 
December 
Table 3.1: Average maximum and minimum temperature fluctuations from 1960 to 2009 
Season Fluctuations Climate 
Line (0C) 
Warmest Year 
(deviation from 
climate line) (0C) 
Coolest Year 
(deviation from 
climate line) (0C) 
Winter Average Maximum 
(December. to January) 
Increase 25.78 1997 (+1.97) 1964 (-1.08) 
Winter Average Minimum 
(December. to January) 
Increase 13.32 2002 (+1.38) 1962 (-1.27) 
Summer Average Maximum 
(April to May) 
No Change 30.98 1960 (+3.27) 1977 (-3.23) 
Winter Average Minimum 
(April to May) 
Slight 
increase 
22.14 1979 (+1.11) 1986 (-1.89) 
 
Page 215
 However,  International Panel on Climate 
Change (IPCC) states in their Third (2001) 
and Fourth Assessment (2007) Reports that 
by 2030, a 0.70C temperature rise in 
monsoon season and a 1.30C rise in the 
winter season might take place in this 
region. 
3.3 Results of Fixed Points Observation 
Heat islands occur on the surface and in the 
atmosphere. On a hot, sunny summer day, 
the sun can heat dry, exposed urban 
surfaces, such as roofs and pavement, hotter 
than the air while shaded or moist 
surfaces—often in more rural 
surroundings—remain close to air 
temperatures. Surface urban heat islands are 
typically present day and night, but tend to 
be strongest during the day when the sun is 
shining. In contrast, atmospheric urban heat 
islands are often weak during the late 
morning and throughout the day and become 
more pronounced after sunset due to the 
slow release of heat from urban 
infrastructure. 
 
In this study METO (Metropolitan 
Environmental Temperature Observation) 
system was used and meteorological 
equipments were installed on the rooftop of 
twelve buildings in the city (urbanized area) 
comprising its rural surroundings (suburban 
area) as meteorological data acquisition 
stations from June to August, 2010. Station-
01 to Station-05 is located in sub-urban area 
and Station-06 to Station-12 is located in the 
centre of build-up, urbanized area. 
It is found that the Urban Heat Island (UHI) 
phenomena was clearly appeared in the 
urbanized area after sunset and kept through 
the night. Because the potential heat 
capacity in build-up area is larger than sub-
urban, and heat from the building materials 
would be released through the night. Also a 
little or zero Urban Heat Island Intensity 
(UHII) was found in the daytime. The 
diurnal UHII was 0.30C at 17:30 pm, 
because of lower solar radiation of Station -
10 than Station-01 by sky view factor and 
air pollution. The nocturnal UHII was more 
than 2.50C in the midnight. The maximum 
of UHII was 2.50C. The daily extremes, 
3.10C appeared between Station-01 and 
Station-11 on July 14, 2010 at 12:00 am. 
Figure 3.2 illustrates the average maximum 
temperature of 12 stations at different period 
of a day. However, Figure 3.3 shows the 
temperature profile of 12 stations on July 28, 
2010 (summer) after sunset. Figure 3.4 
shows the Urban Heat Island Intensity 
Page 216
 (UHII) of fine day between Station-01 and 
Station-11 in July, 2010. 
 
 
Figure 3.2: Average maximum 
temperature of 12 stations at different 
periods of a day 
 
Figure 3.3: Temperature profile of 12 
stations on July 28, 2010 (summer) after 
sunset 
 
Figure 3.4: Urban Heat Island Intensity 
(UHII) between Station-01 and Station-11  
in July, 2010 after sunset. 
 
Thus, it is very interesting that UHII of 
Sylhet appears larger at night than in the day 
and the daily maximum of UHII was around 
3.00C, diurnal temperature in city center are 
not so much different from suburban by sky 
view factor and air pollution. 
3.5 Thermo Graphic Observations 
With process of urbanization, the city 
growth alters the urban fabric by man-made 
asphalt roads and tar roofs and other features 
substituting forest growth. These surfaces 
absorb-rather than reflect- the sun’s heat, 
causing surface temperatures and overall 
ambient temperatures to rise, resulting the 
Sylhet City as an Urban Heat Island. 
Page 217
 Thermal images detected by thermo-graphic 
camera according to different types of 
surface materials shown in Figure-3.7. The 
surface temperature of roads, buildings were 
more than 350C. Especially, the surface 
temperature of the roofs was more than 
400C. Otherwise, vegetations were around 
280C. 
2 buildings, painted with brown and white 
were observed and it was found the surface 
temperature of these two was 330C (brown) 
and 310C (white). The reason why the 
surface temperature of 2 buildings were 
different was that the albedo of white paint 
is higher than brown. 
4. Discussion 
The study reveals that that the development 
of the Sylhet City is growing at an alarming 
rate without adequate planning. New 
skyscrapers are being built up all over the 
city. Moreover, the asphalt roads are also 
being elongated and expanded with the 
increase in population and development 
pattern. Hence, the city comprises a wide 
range of dry and dark surfaces which absorb 
rather than reflect more sunlight, resulting in 
an Urban Heat Island. 
 
5. Conclusion 
Whoever has experienced the sweltering 
summer days of Sylhet City will agree that 
average temperature of the City has 
increased over the decades. The scorching 
heat during daytime and hot, see thing nights 
coupled with load shedding are the bane of 
the city dweller's life. And it is the unique 
feature of the urban climate known as Urban 
Heat Island (UHI) Effect why the 
temperature is so high in Sylhet. 
Approximately half of the world’s 
population currently lives in cities, and this 
value is expected to increase to 61% by 
2030 (U.S. Environmental Protection 
Agency -2009). The high rate of 
urbanization, in this regards, means that 
increasing numbers of people will be 
exposed to impacts resulting from heat 
islands in the future. Most policymakers and 
environmental activists concerned with the 
threat of global warming urge two strategies 
to combat it; cutting the use of fossil fuels 
and planting trees, which sequester carbon 
dioxide in their wood. The planting of trees 
in cities does both of these, and is far more 
effective than planting trees in forests.  
Page 218
  
6. References 
Bangladesh Meteorological Department 
(BMD) 
Brammer, H. (2002). Land use and Land use 
Planning in Bangladesh, University Press 
Limited, Dhaka. 
Climate Change Cell (CCC). (2009a) 
Characterizing Long-term Changes in 
Bangladesh Climate. 
International Panel on Climate Change 
(IPCC). Third Assessment (2001) and 
Fourth Assessment (2007).  
National Oceanic and Atmospheric 
Administration. Report (2009). 
Rashid, Haroun Er. (1991). Geography of 
Bangladesh, University Press Limited, 
Dhaka. 
Tawhidul Islam, Ananta Neelim. (2010). 
Climate Change in Bangladesh, University 
Press Limited, Dhaka. 
U.S. Environmental Protection Agency. 
Report (2009). 
 
 
Page 219
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Ariful Hasnat,  
E-mail: ariful.hasnat@gmail.com  
ULTIMATE LOAD CAPACITY OF AXIALLY LOADED VERTICAL 
PILES IN MID-SOUTHERN AND MID-NORTHERN DEPOSITS OF 
BANGLADESH 
 
Ariful Hasnat1, Fatin Al Farabee2, A. R. M. Farid Uddin1 and Emtazul Haque2 
1Housing and Building Research Institute (HBRI), Dhaka, Bangladesh. 
  
2Department of Civil Engineering, The University of Asia Pacific, Dhaka, Bangladesh. 
 
 
Accurate evaluation of ultimate load capacity of pile is extremely complex and difficult. Capacity of pile is 
derived from the resistance developed by the soils surrounding the shaft and underneath the tip of the pile. 
Soil, by nature, inherits/exhibits non-homogeneity, anisotropy and in-elasticity. Prediction of accurate 
engineering properties of the surrounding particulate three-phase soil matrix becomes even more complex 
due to installation of piles. Thus, available semi-empirical/empirical methods for determination of ultimate 
resistance of pile pose un-reliability and, thereby, may significantly affect safety and economy of a project. 
Therefore, although expensive, conduction of limited number of full-scale pile load tests becomes inevitable 
prior to commencement of construction. Comparison of the actual capacity determined by load tests with 
predicted one may necessitate revision of pile design. This study aims at bridging this gap between 
prediction and reality. Six pile load tests performed in two different parts of Bangladesh were analyzed and 
compared with the capacities evaluated using static analysis incorporating various empirical methods of 
obtaining pile design parameters. With the aid of the comparative study, the authors’ primary objective is 
carried out towards the estimation of the representative values of design parameters appropriate for local 
conditions within the geo-hydrologic environment of alluvial deposition of the Bengal basin. 
 
Key words: Pile Capacity; Driven Pile; Shaft Friction; End Bearing; Pile Load Test.  
 
1. INTRODUCTION 
 
Piles are relatively long and generally slender 
structural foundation members that transmit 
superstructure loads to deep soil layers. In 
geotechnical engineering, piles usually serve as 
foundations when soil conditions are not suitable 
for the use of shallow foundations. Therefore, 
safety and stability of pile supported structures 
depend on the behavior of piles. Pile behavior is 
significantly dependent on the properties of soils 
surrounding and underlying the shaft and tip/end of 
the pile, respectively. Accurate evaluation of the 
properties of these soils is quite complex. 
Generally, soil is non-homogeneous, inelastic and 
anisotropic. Again, the behavior of these soils 
changes significantly during the driving process, in 
case of driven piles, depending upon the driving 
method, energy required, overburden pressure, pile 
geometry etc. As the dissipation of excess pore 
water pressure generated during the driving process 
is significantly affected by hydro-geologic 
condition and time, the properties of these soils 
become also time and hydro-geology dependent. 
Consequently, determination of the exact capacity 
of pile becomes almost impossible. 
 
The prediction/estimation of load carrying capacity 
of driven pile can be achieved using different 
methods such as pile load test, dynamic analysis 
and static analysis based on soil properties from 
field and laboratory tests, and static analysis 
utilizing the results of in situ tests such as cone 
penetration. Due to the uncertainties associated 
with pile design, available semi-empirical/empirical 
methods for determination of ultimate resistance of 
pile may pose un-reliability and, thereby, may 
significantly affect safety and economy of a project. 
Therefore, although expensive, conduction of 
limited number of full-scale pile load tests becomes 
inevitable prior to commencement of construction.  
However, pile load tests are a verification tool for 
the pile design and they cannot be the substitute for 
the engineering analysis of the pile behavior. 
Comparison of the actual capacity determined by 
load tests with predicted one may necessitate 
revision of pile design. This study aims at bridging 
this gap between prediction and reality. The 
research effort is focused on the applicability of the 
most suitable pile design parameters for predicting 
the axial load carrying capacity of piles driven into 
the geo-hydrologic, cohesive and granulometric 
Page 220
ISBN: 978-984-33-2140-4
  
matrix of dominantly prevailing alluvial deposits of 
the Bengal basin. 
 
This study considers the carrying capacity of driven 
piles only, having same size but different lengths. 
Data acquired includes geotechnical sub-surface 
investigation reports and six pile load test reports 
from three different project sites within the Bengal 
basin. Six pile load tests were performed on test 
piles (PTP1, PTP2, NTP1, NTP2, JTP1 and JTP2), 
two at each site, located at three different sites in 
three districts (Jhalokathi, Pirojpur and Netrokona) 
of Bangladesh. Hunt (1976) grouped various land 
systems of the country into six soils units. 
Accordingly, deposits of Jhalokathi and Pirojpur 
sites located in the mid-southern portion of the 
country are generally of Estuarine and Tidal 
Deposits type, whereas deposits of Netrokona site 
located in the mid-northern portion of the country 
straddles the boundary between Alluvial Floodplain 
Deposits and Depression Deposits type. 
 
Geotechnical subsurface exploration revealed the 
subsurface stratigraphic condition at the site and the 
soils’ parameter to aid in the estimation/evaluation 
of theoretical pile capacity, whereas interpreted 
results from the pile load test reports gave the 
actual (to a greater extent) capacity of the piles. 
This study aims to provide guidelines regarding the 
pile design parameters most appropriate or suitable 
for local conditions and the best procedure for 
estimating ultimate capacity from pile load tests in 
country’s major alluvial deposit. 
 
2. PILE CAPACITY FROM 
THEORETICAL ANALYSIS 
 
Various field and laboratory tests have been carried 
out during the geotechnical investigations for 
evaluation of subsurface conditions and the pile 
design parameters. The subsurface soils of all the 
sites mostly consists of deposition of cohesionless 
non-plastic silts underlain with silty sand except at 
Pirojpur site where a cohesive low to medium 
plastic lean clay layer having thickness varying 
from 2.3 to 8.4 m is underlain with non-plastic silt 
and then silty sand up to the boring termination 
depth. 
 
A site-specific correlation between SPT-N value 
and undrained cohesion has been developed for the 
cohesive deposit encountered at the Pirojpur site 
(Shamima et al, 2010). SPT-N values for 
cohesionless deposits have been corrected for 
overburden pressure according to Lio & Whitman 
(1986). Subsequently, in case of silt and very fine 
sand or silty sand, the overburden-corrected SPT-N 
values have further been corrected for dilatancy. 
The correlation φ = 15 + SQRT(N1’60), is used to 
determine angle of internal friction(φ) for 
cohesionless soils. For shaft friction of pile in 
cohesionless deposit, co-efficient of lateral earth 
pressure, Ks (=1.5) and angle of friction at the pile-
soil interface, δ (= 0.8φ) are used as recommended 
by Broms (1966). 
 
A great deal of variation is found in the values of 
end bearing capacity factor, Nq for deep foundation 
provided by different researches. Theoretical pile 
end bearing capacity is estimated using the Nq-φ 
correlations provided by Terzaghi (1943), 
Berezantzev (1961) and Meyerhof (1953). 
Theoretical pile capacities obtained accordingly are 
summarized in Table 1.     
 
3. PILE CAPACITY FROM LOAD 
TESTS 
 
Six load tests were performed on piles having same 
x-sectional dimensions (300 mm x 300 mm) and 
lengths varying from 12.2 m to 18.3 m. The ASTM 
D 1143 test procedure was followed, in general, for 
pile load tests conducted on test piles designated as 
PTP1, PTP2, NTP1, NTP2, JTP1 and JTP2. The 
results of load tests are summarized in Table 2. 
Load-settlement curves were generated, as shown 
in Figure 1, in order to interpret the ultimate load 
carrying capacity of respective pile. The load test 
data are analyzed using ten interpretation methods 
in order to estimate the ultimate load carrying 
capacity of each pile. The ultimate loads 
determined from pile load tests using different 
interpretation methods are summarized in Table 3. 
This table implies that: 
 
-Ultimate pile capacities obtained using all the 
interpretation methods are close to each other for 
all the test piles.      
-Ultimate pile capacities obtained using Terzaghi 
method, method recommended by the Indian Code 
of Practice, Double Tangent Method on Arithmatic 
Plot, Double Tangent Method on Logarithmic Plot 
and Davisson’s Method are even closer to each 
other for all the test piles. 
-Ultimate pile capacities, having even the least 
length, obtained using all the methods are the 
highest at the Netrokona site that straddles the 
boundary between Alluvial Floodplain Deposits 
and Depression Deposits are the highest of all the 
test piles. 
 
-Ultimate pile capacity (Qu) for a particular load 
test can be estimated as the average of all the 
capacities obtained using all ten interpretation 
methods as mentioned in Table 3 and in this study 
the capacities, thus estimated, of six load tests 
Page 221
  
PTP1, PTP2, NTP1, NTP2, JTP1 and JTP2 are 
estimated as 73, 64, 100, 98, 55 and 70 Ton, 
respectively. 
 
 
Table 1: Summary of theoretical pile capacity (Qu) using different method 
 
Table 2: Summary of pile load test results 
 
     Table 3: Summary of Ultimate loads (Qu) determined from pile load test results using different methods 
 
 
 
Sl. No. Methods PTP1 PTP2 NTP1 NTP2 JTP1 JTP2 
   
Qu(ton) Qu(ton) Qu(ton) Qu(ton) Qu(ton) Qu(ton) 
1 Berezantzeb(1961) 85 75 109 95 57 58 
2 Meyerhof(1953) 164 120 236 184 92 95 
3 Terzaghi(1943) 75 70 92 85 53 54 
Sl. 
No. 
Test Pile 
 No. 
Pile Dimension Applied Load (maximum) 
Total 
Settlement 
Net Settlement 
 Length X-Sectional Dimension 
 
 m mm ton mm mm 
1 PTP1 13.7 300 x 300 68.98 31.9 18.3 
2 PTP2 13.7 300 x 300 79.56 30.175 15.6 
3 NTP1 12.2 300 x 300 102.15 31.425 15.225 
4 NTP2 12.2 300 x 300 102.42 22.37 15.07 
5 JTP1 18.3 300 x 300 60.51 29.835 21.4 
6 JTP2 18.3 300 x 300 79.56 31.3 19.46 
Sl. No. Methods PTP1 PTP2 NTP1 NTP2 JTP1 JTP2 
   
Qu(ton) Qu(ton) Qu(ton) Qu(ton) Qu(ton) Qu(ton) 
1 Terzaghi Method(British Standard Code) 78 66 100 102 58 76 
2 Indian Standard Code of Practice 81 71 118 111 68 68 
3 Double Tangent Method on an Arithmetic Plot 62 58 97 95 47 64 
4 Double Tangent Method on Logarithmic Plot 80 61 88 91 50 69 
5 Maximum Curvature Method 69 61 99 102 50 69 
6 The Hansen 80% Criterion 86 76 103 105 65 80 
7 Davisson's Method 78 68 102 102 57 74 
8 Butler and Hoy's Method 62 56 90 86 50 61 
9 Mzurkiewicz Method 74 66 109 91 52 77 
10 DeBeer et al. (1979) 60 56 98 100 50 63 
Page 222
  
Table 4: Summary of ultimate pile capacity (Qu) from pile load test and theoretical  analysis 
 
Sl. No. Test Pile No. Load test Meyerhof(1953) Berezantzeb(1961) Terzaghi(1943) 
  Qu(avg)(ton) Qu(ton) Qu(ton) Qu(ton) 
1 PTP1 73 164 85 75 
2 PTP2 64 120 75 70 
3 NTP1 100 236 109 92 
4 NTP2 98 184 95 85 
5 JTP1 55 92 57 53 
6 JTP2 70 95 58 54 
 
0
5
10
15
20
25
30
35
0 20 40 60 80 100 120
Load on Pile, ton
Se
ttl
em
en
t, 
m
m
PTP1
PTP2
JTP1
JTP2
NTP1
NTP2
 
 
Fig 1. Load-settlement graphs for six pile load test 
 
4. SUMMARY AND CONCLUSIONS 
 
• Site specific correlation between SPT-N 
value and undrained cohesion can be 
generated to simulate local geological 
conditions in order to evaluate 
representative undrained cohesion for 
cohesive deposits. 
• The ultimate loads determined from 
load/settlement curves of load tests by 
methods mentioned in Table 3 are in 
close compliance with each other.    
• The best method of estimating ultimate 
load from pile load tests results is to use 
the average value of ultimate loads 
obtained from five methods (i.e., 
Terzaghi method, method recommended 
by the Indian Code of Practice, Double 
Tangent Method on Arithmatic Plot, 
Double Tangent Method on Logarithmic 
Plot and Davisson’s Method). 
• Theoretical pile capacities as determined 
using Nq-φ correlations suggested by 
Meyerhof (1953) are much higher than 
the capacities interpreted from pile load 
test results as shown in Table 4. 
Page 223
  
• Theoretical pile capacities as determined 
using Nq-φ correlations suggested by 
Terzaghi (1943) are conservative in 
comparison with the capacities 
interpreted from pile load test results. 
 
• Theoretical pile capacities as determined 
using Nq-φ correlations suggested by 
Berezentzav (1961) are in very close 
compliance with the capacities 
interpreted from pile load test results and 
can be used as most suitable one to 
incorporate local geological conditions. 
 
The above conclusions are based on load test data 
on six test piles only. There is a need to include 
several more pile load tests data in order to 
validate the above conclusions and express them 
in more general terms. 
 
 
REFERENCES 
 
1. Akter,S.,et al. (2010), “Generation of site-
specific idealized model layer for cohesive 
deposits”, Proc. Bangladesh Geotechnical 
Conference 2010, Dhaka, Bangladesh, pp. 
129-132. 
2. American Society for Testing and Materials, 
Method of Testing Piles under Static Axial 
Compressive Load, D1143, Annual Book of 
ASTM Standards, 04.08(1986). 
3. Berezantzev et. Al (1961), “Load bearing 
capacity and deformation of piled 
foundations”, Proc. of 5th international 
conference on SMFE, Vol. 2, pp. 11-15.  
4. Broms, B. B. (1996), “Methods of 
calculating the ultimate bearing capacity of 
pile-a summary”, Journal of Geotechnical 
Engg., Vol. 7, No. 1, pp. 1-33. 
5. Butler, H. D. and Hoy, H. E. (1976),“The 
Texas quick load method for foundation load 
testing”, Users Manual IP77.8, Department 
of Transportation, Federal Highway 
Administration, Washington. 
6. Davisson, M.T. (1973),“High capacity piles”, 
In innovations in Foundation Construction, 
Soil Mechanics Division, Illinois, ASCE, 
Chicago, USA, pp.81-112. 
7. DeBeer, E. E., (1968),“Proefondervindlijke 
bijdrage tot de studie van het grensdraag 
vermogen van zand onder funderingen op 
staal” Tijdshift der oOpenbar Verken van 
Belgie, No. 6, 1967 and No. 4, 5, and 6, 
1968. 
8. Hansen, J.B., 1963.,“Discussion on 
hyperbolic strss-strain response of Cohesive 
soils”, American Society of Civil Engineers, 
ASCE, Journal for Soil Mechanics and 
Foundation Engineering, Vol. 89, SM4, pp. 
241-242. 
9. Hunt, T. (1976), “Some geotechnical aspects 
of road construction  in Bangladesh”, Journal 
Geotechnical Engg., Vol. 7, No.1, pp. 1-33. 
10. Mazurkiewicz, B.K. (1972),“Test loading of 
piles according to Polish Regulations”, 
Preliminary Report No. 35, Commission on 
Pile Reseach, Royal Swedish Academy of  
Engineering Services, Stockholm. 
11. Meyerhof,G.G. and L.J. Mudrdock 
(1953),”An investigation of the bearing 
capacity of some bored and driven piles in 
London clay”Geotechnique, vol.3,pp.267. 
12. Terzaghi (1942),“Discussion of the Progress 
Report of the Committee on the Bearing 
Value of Pile Foundations”, Proceedings of 
the ASCE, Vol.68, pp.311-323. 
13. Terzaghi, K. (1943), Theoretical Soil 
Mechanics, John Wiley and Sons Ltd., p. 
510. 
 
 
 
Page 224
URBAN HEAT ISLAND (UHI) DRIFT IN RAJSHAHI METROPOLITAN 
CITY 
Mohammod Aktarul Islam Chowdhury, A.F.M. Kamal Chowdhury & Salahuddin Ahmmed 
Department of Civil and Environmental Engineering  
Shahjalal University of Science and Technology, Sylhet, Bangladesh 
ABSTRACT 
Rajshahi Metropolitan City is being raised to high due to rural-urban migration and high 
population growth rate where migration is a result of the ‘pull factors’ of urban settlements-such 
as perceived job opportunities, and better infrastructure and housing-in addition to 'push factors' 
from rural areas such as shortage of land and declining returns from agriculture. The process of 
urbanization in Rajshahi Metropolitan City is being done through a much unplanned manner 
when the city growth alters the urban fabric by man-made asphalt roads and tar roofs and other 
features substituting forest growth. These surfaces absorb rather than reflect the sun’s heat, 
causing surface temperatures and overall ambient temperatures to rise in compare to its rural 
surroundings, resulting the city as an Urban Heat Island (UHI). The study clarified the detailed 
temporal and spatial patterns of urban heat islands in Rajshahi Metropolitan City where METOS 
(Metropolitan Environmental Temperature Observation System) was used and installed 
meteorological equipments on the rooftop of twelve buildings in the city comprising its rural 
surroundings as meteorological data acquisition stations from July 01 to August 01, 2010. 
Analyzing the horizontal and vertical temperatures recorded in this stations, UHI indices of 2 0-
30C has been found in Rajshahi Metropolitan City. Finally relevant mitigation measures to get 
rid of the UHI effects in the city is recommended with the subsequent conclusion.  
 
KEYWORDS 
UHI index, settlement, infrastructures, energy use, cooled roof 
 
 
Page 225ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
INTRODUCTION 
 A UHI is a metropolitan area which is 
significantly warmer than its surrounding 
rural areas. Heat islands of cities located in 
the mid latitudes usually are strongest in the 
summer or winter seasons. In tropical 
climates, the dry season may favor large 
heat island magnitudes. The temperature 
difference usually is larger at night than 
during the daytime and larger in winter than 
in summer, and is most apparent when 
winds are weak. The main cause of the 
urban heat island is modification of the land 
surface by urban development; waste heat 
generated by energy usage is a secondary 
contributor. Since we have covered most of 
the land surface of Rajshahi city with 
concrete and asphalt pavements, the city has 
become an oven with millions of people in 
it. Though the UHI air temperature is 
generally most apparent at night, urban heat 
islands exhibit significant and somewhat 
paradoxical diurnal behavior. The UHI air 
temperature is large at night and small 
during the day, while the opposite is true for 
the UHI surface temperature. Throughout 
the daytime, particularly when the skies are 
free of clouds, urban surfaces are warmed by 
the absorption of solar radiation. As 
described above, the surfaces in the urban 
areas tend to warm faster than those of the 
surrounding rural areas. By virtue of their 
high heat capacities, these urban surfaces act 
as a giant reservoir of heat energy. (For 
example, concrete can hold roughly 2000 
times as much heat as an equivalent volume 
of air). This daytime heating creates 
convective winds that minimize the surface 
temperature to a great extent. At night, 
however, the situation reverses. The absence 
of solar heating causes the atmospheric 
convection to decrease. This traps the urban 
air near the surface, and allows it to heat 
from the still-warm urban surfaces, forming 
the nighttime UHI air temperature. 
 
Annual mean temperatures in central 
Rajshahi have increased 2-3 degrees Celsius 
for the last 50 years, which is around five 
times as fast as that of global warming. In 
summer, although daily minimum 
temperatures might be highest in central 
Rajshahi as a typical heat island pattern, 
daily maximum temperatures often appears 
in the southwestern residential area of 
Rajshahi Metropolitan City. We settled 
twelve monitoring station called METOS in 
Rajshahi Metropolitan area since July, 2010 
with own finance. Only collected 
temperature data were acquired and 
analyzed. Here we show some results of 
Page 226
acquired data analysis in the last summer 
season. 
 
SIGNIFICANCE 
 
UHIs have the latent to directly influence 
the health and welfare of the urbanites. 
Compared to rural areas, cities experience 
higher rates of heat-related illness and death. 
The heat island effect is one factor among 
several that can raise summertime 
temperatures to levels that pose a threat to 
public health. The nighttime effect of UHIs 
can be particularly harmful during a heat 
wave, as it deprives urban residents of the 
cool relief found in rural areas during the 
night. Furthermore, the poor air quality that 
results from this increased energy usage can 
affect our health, aggravating asthma and 
other respiratory illnesses. People in Dhaka, 
especially the poor, suffer from various 
acute respiratory diseases during summer. In 
1995, a heat wave in Chicago illustrated 
why excessive temperature and heat islands 
are of concern. This episode of unusually 
hot weather resulted in the deaths of over 
700 people. 
Another consequence of urban heat islands 
is the increased energy required for air 
conditioning and refrigeration in cities that 
are in comparatively hot climates. The Heat 
Island Group, a research and advocacy 
organization that works to educate the public 
and policymakers about the heat island 
effect, estimates that the city of Los Angeles 
spends about $100 million per year in extra 
energy costs to offset its heat island effect. 
Urban heat islands also can impact local 
weather, altering local wind patterns, 
spurring the development of clouds and fog, 
increasing the number of lightning strikes, 
and influencing the rates of precipitation as 
we are experiencing now in Dhaka. 
Sometimes it also affects growth of the 
trees. Using satellite images, researchers 
discovered that plants take more time to 
grow in UHIs than the rural areas.
METHODOLOGY  
There are two parts to this study. The first 
part is data collection system and secondly 
collected data adjustments analysis. The 
study has been used METOS (Metropolitan 
Environmental Temperature Observation 
System) to clarify the detailed temporal and 
spatial patterns of Urban Heat Island (UHI) 
in Rjshahi City.  Meteorological equipments 
were installed on the rooftop of 12 buildings 
as meteorological data acquisition stations 
Page 227
from July 13 to September 9, 2010. There 
are 12 stations (Table-1) whish  are installed 
at Rural and Urban area among the City 
Corporation area to show clearly the 
horizontal distribution change of daily 
temperature. Temperature data was collected 
daily four times as Before Sun rise, Noon, 
After Sun set and Mid Night. Here at the 
Map the YELLOW point has indicate  
 
Suburban Station (SS) and BLUE point 
indicate Urban Station (US).  Table-1 
evaluates the Meteorological Data 
Acquirement Station with global position
 
Fig-1: Twelve METOS station in Rajshahi City Corporation area (YELLOW: Suburban station 
& BLUE: Urban station)
Temperature Data from Bangladesh 
Meteorological Department (BMD): 
An assessment of annual mean, maximum 
and minimum temperature of Rajshahi using 
weather station data operated by Bangladesh 
Meteorological Department (BMD) shows 
continuous warming of the region since 
1964. 
 
Global Information System (GIS) and 
Remote Sensing (RS): 
An application of Global Information 
System (GIS) and Remote Sensing (RS) to  
the difference of surface temperature 
between urban infrastructures (buildings, 
roads) and vegetation area was determined 
using GIS and RS. A thermo-graphic camera 
system can remotely measure the surface 
Page 228
temperature of the materials through 
infrared radiation. It acquits the distribution 
of surface temperature of the materials, 
easily and instantly.  
RESULT & DISCUTION 
Using the data collected from the Rajshahi 
Station of Bangladesh Meteorological 
Department (BMD), a climate line has been 
determined by calculating the Maximum 
temperature for years from 1964 to 2009. 
Then yearly temperature deviations from 
that climate line have been determined; 
distributions of the deviation points were 
plotted in to the graph (figure-2). 
 
Figure-2: Annual Maximum Temperature 
profile for last 50 years. (Source: BMD) 
Fixed Points Observation 
It is clear that the Urban Heat Island (UHI) 
phenomena is undoubtedly appeared after 
sunset and reserved through the night. And 
Urban Heat Island Intensity (UHII) was not 
found in the other times of the day. Station-
1, 4, 5, 9, 10, 12 and Station-2, 3, 6, 7, 8, 
and 11 are located respectively in sub-urban 
area and urbanized area. Figure 4 shows the 
Urban Heat Island Intensity (UHII) at after 
sunset of 12 days between Station-1 and 
Station-6 in 12-23 August, 2010. 
 
 
 
Figure 4: Urban Heat Island Intensity (UHII) 
of station-1 & station -2 for After sunset 
 
Similarly other Urban & Suburban station 
show the UHII as mentioned previously. 
The diurnal UHII was minus, and the 
minimum was -1.20C at 17:30 pm, because 
solar radiation of Station-06 was 15-20% 
lower than Station-01 by sky view factor 
and air pollution. The nocturnal UHII was 
plus, more than 2.00C in the midnight. The 
maximum of UHII was 2.20C. The daily 
0
10
20
30
40
50
1960 1980 2000 2020
Te
m
pe
ra
tu
re
 (0
C)
Year
23
24
25
26
27
28
29
30
31
1 2 3 4 5 6 7 8 9 10 11 12
Page 229
extremes, 2.50C appeared between Station-6 
and Station-1 on August 23, 2010 at 6:00 
pm. The potential heat capacity in build-up 
area is larger than sub-urban, and heat from 
the building materials would be released 
through the night. Thus, it is very interesting 
that UHII of Rajshahi appears larger in 
summerseason.
 
Figure-5: Daily Temperature profile of 
stations-6 in August 17, 2010 
 
 
MITIGATION MEASURES
The heat island effect can be counteracted 
slightly by using white or reflective 
materials to build houses, pavements, and 
roads, thus increasing the overall albedo of 
the city. Using light-colored concrete has 
proven effective in reflecting up to 50% 
more light than asphalt and reducing 
ambient temperature. A low albedo value, 
characteristic of black asphalt, absorbs a 
large percentage of solar heat and 
contributes to the warming of cities. By 
paving with light colored concrete, in 
addition to replacing asphalt with light-
colored concrete, communities can lower 
their average temperature. This is a long 
established practice in many countries. A 
biologically related solution is to use 
vegetation to reduce urban heat. Vegetation 
provides important shading effects as well as 
cooling through evaporation. Some 
examples include:  
 Planting trees around individual 
buildings to shade urban surfaces to 
reduce their temperature, especially 
roofs and south-, east-, and west-
facing walls. The reduction in 
surface temperature also leads to 
substantial reductions in energy use 
for air conditioning.  Trees and green 
spaces are other solutions. 
29
30
30.3
27.9
26.5
27
27.5
28
28.5
29
29.5
30
30.5
Before 
sun rise 
Noon After 
sunset 
Mid night
Page 230
 Trees can also be used to shade roads 
and parking lots, which would 
otherwise become very hot during 
the day and which store heat for later 
release at night. Shading of vehicles 
in parking lots can reduce 
evaporative emissions from gasoline, 
which contributes to increased levels 
of urban ozone.  
 “Green roofs” use living vegetation 
on roofs in order to help reduce heat 
accumulation of buildings. For 
example, the city of Chicago has 
more than 80 municipal and private 
green roofs as of June 2004, 
including the first municipal green 
roof in the country, the City Hall 
rooftop garden. A green roof is much 
cooler than a traditional roof because 
a significant fraction of the absorbed 
energy is used to evaporate water 
rather than to heat the roof and the 
overlying air.  
 Creation of green space such as 
parks can be used to assist in cooling 
of neighborhoods, and an overall 
greening of the city can lead to a 
cooler urban atmosphere. 
In addition, energy demand and costs also 
can be reduced by placing an air-conditioner 
in a shaded window, for example shaded by 
a strategically planted tree. 
COST BENEFITS 
These strategies can provide cost benefits. A 
building owner benefits from reduced 
energy consumption costs. Residents 
downwind of the urban area benefit from air 
quality improvements because: 
 pollutants are deposited on trees  
 greenhouse gas and pollutant 
emissions from air conditioning use are 
reduced  
 emissions of volatile organic 
compounds that contribute to urban smog 
are lessened  
 the rate of ozone formation is 
potentially reduced  
LIMITATIONS & CONCLUTION: 
Luckily, since we know what causes the 
urban heat island effect, we can control it to 
a significant extent. The fact is green trees 
and only trees can help us. Yes, to escape 
the heat island effects, cities need a lot more 
vegetation and a lot fewer dark and hard 
surfaces. But the inconvenient truth is that 
some of our wise guys are plotting to cut 
Page 231
down hundreds of trees. But there must be 
something that we can do to ameliorate the 
existing condition. We cannot be apathetic 
any more regarding the apocalyptic effects 
of climate change. Our governments should 
also contemplate this matter seriously and 
more Environmental Engineers and urban 
planners are needed to attempt the situation.  
 
In this study we used Hydrometer & Room 
Thermometer with required modified figure. 
However in this study are going to make a 
concern about the UHI effects in the 
Rajshahi City. There is no doubt about that 
the high rate of urbanization threats the city 
for rising as an Urban Heat Island. Many 
problems already have beset our adored 
Rashahi City. Let's not contradict the 
situation and make it worse. 
 
REFERANCE: 
  Hansen, J., R. Ruedy, J. Glascoe, 
and M. Sato, 1999: GISS analysis of 
surface temperature change. J. 
Geophys. Res., 104, 30 997– 31 022 
 Akbari, H., L. R. Rose, and H. Taha, 
1999: Charaterizing the fabric of the 
urban environment: A case study of 
Sacramento, CA. Lawrence Berkeley 
National Laboratory, Berkeley, CA, 
Rep. LBNL-44688, 63 pp. 
 Peterson, T. C., and D. R. Easterling, 
1994: Creation of homogeneous 
composite climatological reference 
series. Int. J. Climatol., 14, 671–
679.and R. S. Vose, 1997: An 
overview of the Global Historical 
Climatology Network temperature 
database. Bull. Amer. Meteor. Soc., 
78, 2837–2849. 
 Bangladesh Bureau of Statistics 
(BBS), Statistical yearbook of 
Bangladesh (1998).9.Bangladesh 
Center for Advanced Studies, Guide 
to the Environmental Conservation 
Act 1995 and Environmental 
Conservation Rules 1997 of the 
Govt. of Bangladesh (1999). 
 Defense Meteorological Satellite 
Program (DMSP) 
 Global Historical Climatology 
Network (GHCN) 
 Rajshahi City Corporation (RCC) 
 U.S. Environmental Protection 
Agency 
 Geography & Environment Study 
department, Rajshahi University, 
Rajshahi. 
 Bangladesh Meteorological 
Department (BMD),Agargau, 
Dahaka. 
Page 232
* Corresponding Author: M.A. Hasnat,  
E-mail: mah-che@sust.edu 
 
 
 
A COMPOSITE PHOTOCATALYST FOR METHYLENE BLUE 
DEGRADATION UNDER VISIBLE LIGHT IRRADIATION
M. Afsar Uddin, M. Maria Rahman, A.J.F. Samed,  M. A. Hasnat* 
Department of Chemistry, Graduate School of Physical Sciences, Shahajalal University of Science and 
Technology,Sylhet-3114, Bangladesh. 
 
Abstract 
The photocatalytic degradation of Methylene Blue (MB) under UV irradiation and even under ordinary visible 
light using a new composite photocatalyst Mn1–xCdxS (x =0.18) has been introduced. The order of reactivity, 
irrelevant to the nature of light, followed the order of Mn1–x CdxS (x = 0.18) > TiO2 > ZnO > CdS at neutral pH. 
The lower band gap energy (2.1 eV) of the catalyst Mn1–xCdxS  x = 0.18) and dispersed nature of the photoinduced 
hole within the valence band, comprising the hybridized orbital of S and Cd valence shell orbital-rendering the 
prohibition of the recombination of the photo-induced electron and hole in the mechanistic path of direct photo-
excitation of the catalyst- combined with the self-photosensitized degradation process of the dye molecules were 
identified as the reasons of the higher reactivity under visible light irradiation. 
Key words: Composite catalyst, Degradation, Mineralization, Rate constant, Methylene Blue. 
1. INTRODUCTION 
Dyes are organic colored materials used in textile, 
pharmaceutical, cosmetic and food industries for 
imparting different shades of attractive colors. The 
wastewater discharged from a large number of 
industries, associated with dye stuff activities, contains 
high concentration of reactive dyes which causes a 
serious environmental problem. Some of these dyes 
have detrimental health effects (Neppolian et al., 
2003). Their discharge as wastewater in the ecosystem 
is a dramatic source of esthetic pollution, 
eutrophication, and perturbations in aquatic life. 
Effluents discharged from textile and dyeing industries 
are characterized by low BOD, high COD and 
variation of pH in the range of 2-12 (Amin et al., 2009; 
Babu, et al., 2007). These dyes in water strongly 
absorb sunlight which decreases the intensity of light 
absorbed by water plants and phytoplankton, reducing 
photosynthesis and the oxygenation of water 
reservoirs. The greatest number of the dyes are 
resistant’s to biodegradation and direct photolysis.  
In addition, many N–containing dyes such as 
methylene blue (MB) undergo natural reductive 
anaerobic degradation to yield carcinogenic aromatic 
amines.Therefore, the use of AOPs for effluent water 
treatment has been studied extensively and it has been 
affirmed that UV radiation by lights is expensive. So 
nowadays research is focusing innovative and novel on 
the two AOPs, which can be influenced by solar 
irradiation, i.e. light with a wavelength longer than 300 
nm, homogeneous catalysis with photo-Fenton and 
heterogeneous catalysis with UV/ TiO2 with and 
without accumulation of oxidants and solar radiation is 
as proficient as or even more resourceful than artificial 
radiation that also allows a decline in effluent 
treatment operational expenses. Moreover, in most of 
the industries the phenolic compounds are widely 
utilized and have become ordinary contaminants in 
waste water bodies. The photocatalytic degradation of 
Page 233
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
* Corresponding Author: M.A. Hasnat,  
E-mail: mah-che@sust.edu 
 
 
phenol was found to be more effective under solar 
light in comparison to artificial visible light irradiation. 
There are various physicochemical and biological 
methods for the treatment of reactive dyes in 
wastewater (Neppolian et al., 2003). The conventional 
method of textile effluent water treatment comprises 
chemical coagulation, biological treatment and 
adsorption by activated carbon. However, these 
methods transfer dyes from the liquid to the solid 
phase which causes secondary pollution, requiring 
further treatment. The presence of higher molecular 
weight dyestuffs in wastewater results lower 
degradation efficiency when it is treated by biological 
method.The photocatalytic degradation of dyes is of 
growing interest for environmental remediation. Many 
organic and inorganic pollutants in water and air 
stream have been shown to be fully decomposed by 
means of photocatalysis (Li et al., 2007).  
A large number of studies have been reported in the 
past decades on the photodegradation of organic 
compounds using semiconductor particles as 
photocatalysts. Semiconductor photo catalysts, such as 
TiO2 and ZnO are employed extensively in the 
destruction of organic pollutants owing to their 
relatively high photocatalytic activity, biological and 
chemical stability, low costs, nonpoisonous and long 
life span.The appropriate position of their conduction 
bands allows oxygen to act as acceptor of photo-
generated electrons which is more important in their 
usage (Yu et al., 2002). But several important 
scientific and technologic problems still remain to be 
solved in the application of photocatalysis technology 
of TiO2 semiconductor for the treatment of industrial 
wastewater . 
 In our previous studies (Hasnat et al., 2005; Hasnat et 
al., 2007) have been investigated the photocatalytic 
degradation of several dyes using TiO2 and ZnO 
dispersion under UV light. The main problem of using 
oxide photocatalyst TiO2 and ZnO for dye degradation 
is their pitiable activity under visible light irradiation 
due to their higher band gap energy which hinders 
their photoexcitation. Some dyes could be degraded 
under visible light irradiation over TiO2 or ZnO by a 
self-photosensitized process where the dye is the only 
light absorbing species. A brief of the mechanistic 
pathway is that at the excited state of the dye, an 
electron is injected into the conduction band of TiO2 or 
ZnO where it is captured by the surface adsorbed O2 to 
produce O2• –, and active oxygen species decompose 
subsequently the dye cation radicals.  
However, in such a case photo-efficiency is very low 
due to the much slower interfacial electron transfer to 
the oxidized sensitizer. Solar heterogeneous 
photocatalysis has emerged as a promissory 
technology to destroy toxic and/or bio-recalcitrant 
pollutants in water . Moreover, this technology has 
also shown the strongest potential in order to inactivate 
waterborne pathogen microorganisms To obtain an 
acceptable response to visible light and to investigate 
the potential application of the photocatalytic 
technique under visible light irradiation, a number of 
new photocatalysts, with lower band gap energy 
capable of using visible light, have been developed . 
In the present studies, the efficiency of Mn1–xCdxS (x 
=0.18) in degrading an organic dye Methylene Blue 
(MB)  has been explore under UV and visible light 
irradiation and also to evaluate the relative efficiency 
of three other common photocatalysts(TiO2 , ZnO , 
CdS) for removal of color from effluent water. 
2. EXPERIMENTAL 
2.1. Materials 
TiO2 photocatalyst (P25, 90% anatase, specific surface 
area 50 m2 g–1) ZnO and CdS were supplied by Walko 
Incorp. (Japan). The catalyst Mn1–xCdxS (x=0.18) was 
used as received. The cationic dye methylene blue 
(Fig. 1) was obtained from Waldeck–Gmbh & Co. and 
was used as received. All other chemicals used in the 
experiments were reagent grade and were used without 
further purification. All solutions were prepared by 
using distilled and deionised water. 
 
2.2. Reactor 
      Batch reactors were designed for the 
photodegradation study. For UV light induced 
degradation study three 10 W UV (Mercury) tube 
lights were placed parallel on the top inside of a 
wooden box, kept in a dark room. The walls, inside the 
box, were covered with aluminum foil to ensure the 
maximum light to fall on the reaction vessel by 
reflection. Pyrex glass reactor (200 ml) was used as 
reaction vessel, which along with the reacting solution 
was placed about 15 cm below the tube light on a 
magnetic stirrer. Samples were taken at a regular 
interval by raising the lid of the box. For visible light 
induced degradation study a 500 W crown bulb, the 
visible light source, was hung with a holder and a 
stand over wooden stage in the dark room, about 15 
Page 234
* Corresponding Author: M.A. Hasnat,  
E-mail: mah-che@sust.edu 
 
 
cm apart from the surface of the solution. The 
thermostatic state was maintained using a cooling fan. 
2.3. Methods 
      Energy dispersive X-ray fluorescence (XRF, 
Horiba, MESA-500 W) analysis was used to determine 
chemical composition. The X-ray diffraction patterns 
(XRD) of the powder samples were measured at room 
temperature with a Rigaku powder diffractometer with 
Cu-K radiation. The nitrogen adsorption isotherm at 
77 K was measured using a Belsorp Mini, Japan 
instrument.  
     The UV-visible spectrum of methylene blue was 
obtained for 10 µM solution in the range of 200 nm-
700 nm using a UV-visible spectrophotometer (UV-
1650PC, Shimadzu Corporation, Kyoto, Japan). The 
maximum absorbance was found at 664 nm (λ max = 
664 nm) and photometric measurements were carried 
out at 664 nm. For UV light irradiation assisted 
temporal absorption spectrum changes study a mixture 
of MB (15 µM, 200 ml) was prepared   by taking 0.2 g 
photocatalyst at pH 7.5. The as prepared mixture was 
stirred for 30 minutes in the dark to ensure its 
suspension behavior and then was subjected to UV 
irradiation for 125 minutes. In order to monitor the 
concentration changes, 3 ml of aliquot portions were 
withdrawn at a regular time interval; centrifuged and 
UV-visible spectra were taken. All the photocatalytic 
experiments were carried out under open air condition 
in a dark room.  
3. Results and discussion 
    Fig. 2 shows the XRD pattern of the profiles of MnS 
(curve A) and CdS (curve B) along with composite 
material, prepared from the combination of γMnS and 
CdS (curve C) using hydrothermal method. From these 
profiles, it is clear that γMnS used in this study was a 
mixture cubic (R, rock salt structure) and hexagonal (γ, 
wurtzite structure) phases. However, the cubic phase 
of γMnS was vanished and at the same time signals 
due to cubic phase of CdS along with zincblend type 
structure was noticed as soon as the component CdS 
was hydrothermally combined to the MnS system. The 
newly developed composite material having zinc blend 
type structure was designated as Mn1–xCdxS, where the 
value of x using XRF technique was determined to be 
0.18. Using the as prepared material, photocatalytic 
degradation experiments of Methylene blue (MB) have 
been performed both under UV and visible light 
irradiation. Fig. 3 shows the spectral changes of MB 
2
0 10 20 30 40 50 60 70
In
te
ns
ity
 
A
B
C
  
Fig.2. XRD patterns of (A) γ MnS (B) CdS and (C) 
Mn1–xCdxS (x=0.18). 
Wavelength/nm
200 300 400 500 600 700
Ab
so
rb
an
ce
0.0
0.5
1.0
1.5
2.0
 
Fig.3.The temporal absorption spectrum changes of 
MB taking place under visible light irradiation. The 
lines indicate the change of decolorization 
/degradation every 25 min intervals. Initial 
concentration of MB: 15 µM (200 ml), Mn1–x CdxS 
(x = 0.18):  0.2 g, pH:  7.5.  
 
Fig. 1. The molecular structure of Methylene blue. 
 
 
N 
 
N – CH3 
CH3 
  H3C– N 
CH3 
S+ 
Cl– 
Page 235
* Corresponding Author: M.A. Hasnat,  
E-mail: mah-che@sust.edu 
 
 
Catalyst  Rate constant at  
UV light 
Rate constant at 
Visible light 
 k664 nm 
/10–3 
min–1 
k292 nm 
/10–3 
min–1 
k664 nm 
/10–3 
min–1 
k292 nm 
/10–3 
min–1 
TiO2 19.2 18.1 7.8 6.5 
ZnO 10.9 8.2 2.1 1.9 
CdS 4.1 2.3 1.6 1.0 
Mn1–xCdxS 
(x=0.18) 
22.3 19.1 15.1 13.3 
molecules recorded at 25 min regular intervals under 
visible light condition. The absorption spectrum of MB 
shows two major peaks, one at 664 nm due to 
substitution of >N(CH3)2 group to heteroaromatic ring 
(responsible for color) and another at 292 nm 
associated with localized bands of the unsaturated 
heteroaromatic  system (Wellington et al., 2006) . 
These peaks were decreased markedly in intensity and 
were almost completely disappeared after 125min 
irradiation. The disappearance of the peak at 664 nm 
indicates decolorization (either due to functional 
groups removal or due to mineralization or due to both 
reasons). Meanwhile, the disappearance of the peak at 
292 nm indicates the mineralization of MB molecules. 
Since the intensity of the peaks was decreased 
exponentially and so estimated the relative 
photocatalytic performances by evaluating first order 
rate constant (k) at both 664 nm and 292 nm. The 
linear form of the first order decolorization has been 
shown in Fig. 4 measured at 664 nm both in presence 
of visible and UV light.   It has been found that the 
value of k at 664 was 15.1  10-3 min-1, slightly higher 
than 13.3  10-3 min-1 which was observed at 292nm. 
This results indicate that minerlization of MB 
molecules took place followed by decolorization 
provably due to N-deethylation as was also observed 
by other researchers using oxide photocatalysts (Li et 
al., 2007, Hu et al., 2006) . In order to confirm the 
mineralization, TOC was determined as bellow 
detection limit (< 0.1%) after 150 min irradiation. 
 The main attractive feature to point out is the relative 
activity of the as prepared catalyst under visible light 
irradiation. In order to compare the relative activities, 
experiments were performed under same condition 
using TiO2, ZnO, most familiar semiconductor 
photocatalysts, CdS and as prepared Mn1–xCdxS 
catalyst. 
Though the catalysts TiO2 and ZnO were relatively 
active under UV light irradiation but they are deemed 
under visible light condition as is reported in Table 1. 
Table-1: The temporal absorption spectrum change 
kinetic results of MB under UV and visible light 
irradiation 
The activity of the as prepared Mn1–xCdxS under 
visible light irradiation was found to be higher than 
that for TiO2 and almost closer to that observed for 
TiO2 under UV irradiation. In case of both peaks 
decolorization / mineralization followed the order of 
Time / min
0 25 50 75 100 125 150
-L
n 
[M
B]
t/[
M
B]
o
0.0
0.1
0.2
0.3
0.4 a
b
c
d
(A)
  
Time / m in
0 20 40 60 80 100 120 140
-L
n 
[M
B]
t/[
M
B
] o
0.0
0.2
0.4
0.6
0.8
1.0
1.2 a
b
c
d
(B)
 
Fig. 4.  Linear form of first order decolorization at 
664 nm of Methylene Blue (200 ml, 15 µM) in 
presence of  (A) Visible light irradiation and in 
presence of (B) UV light irradiation.  The lines a, b, c 
and d indicate the presence of 0.2 g Mn1–xCdxS (x = 
0.18), TiO2, ZnO and CdS photocatalysts, 
respectively. 
Page 236
* Corresponding Author: M.A. Hasnat,  
E-mail: mah-che@sust.edu 
 
 
Mn1–xCdxS > TiO2 > ZnO > CdS, irrelevant to light 
used for photolysis.  The reasons of such high activity 
of the as prepared Mn1–xCdxS catalyst might be 
because either due to its larger surface area and or due 
to reasonable smaller band gap energy. Therefore, it is 
essential to investigate the surface area and band gap 
energy of the as prepared catalysts. 
     Fig. 5 shows the N2 adsorption isotherm for Mn1–
xCdxS (x =0.18). This is similar to type II isotherm 
defined in the IUPAC classification, indicating 
relatively strong interaction between sample surface 
and adsorbate. Adsoprtion isotherm is typical for non 
porous material. It starts up taking N2 homogeneously 
from relative pressure (p/po) zero then decreases 
apparently at higher pressure until at relative pressure 
0.4. This signifies that adsorption in this nonporous 
material is generally accompanied by the formation of 
a monolayer followed by a multilayer and thereby 
lacking of capillary condensation.  
The specific surface area was determined using BET 
method and found 31 m2g–1 with high correlation 
coefficient of the BET straight line, which is quite low 
compared to TiO2 (50 m2/g) and ZnO (100 m2/g) ( 
Hasnat et al., 2007). Therefore, the measurements of 
surface area did not support the noble activity of the 
composite Mn1–x CdxS catalyst. 
 Finally, the band gap energy has been estimated by 
measuring the reflectance spectra of the composite 
catalyst. The diffused reflectance spectrum of the 
composite material Mn1–xCdxS (x = 0.18) is shown in 
Fig 6. As can be seen from figure, the band gap energy 
of the catalyst Mn1–xCdxS (x = 0.18) was estimated to 
be 2.2 eV. This value is significantly smaller than 
oxide photocatalysts anatase TiO2 (3.2 eV) and ZnO 
(3.4 eV) and also slightly lower than the sulfide 
photocatalyst CdS (2.4 eV). Therefore, lower band gap 
energy of the composite catalyst Mn1–xCdxS (x=0.18) 
might be a consistent reason of the activated 
photocatalytic performance MB molecules degradation 
under visible light condition. But, CdS show lower 
photodegradation efficiency than TiO2, despite of 
having lower band gap energy (2.4 eV) than that of 
TiO2 (3.2 eV). Lower band gap energy of the 
composite catalyst is therefore not the only reason for 
its higher catalytic activity but also the photocatalytic 
oxidation of organic compounds is mainly considered 
to be controlled by the following processes: (1) the 
photoabsorption of the semiconductor catalyst, (2) the 
generation of photogenerated electron and hole, (3) the 
transfer of charge carriers and (4) the utilization of the 
charge carriers by the reactants. In the photocatalytic 
processes using TiO2, ZnO or CdS, the recombination 
of the photogenerated electron and hole limits their 
degradation efficiency under UV irradiation. The 
lower band gap energy enabled the catalyst to be 
photoexcited resulting in the formation of 
photogenerated e- and h+.  Moreover, the hybridization 
of the S and Cd valence levels makes the VB largely 
dispersed, which favors the mobility of photoholes in 
the VB- preventing the recombination of e- and h+ and 
is beneficial to the oxidation reaction. In addition, the 
self-photosensitized degradation process of the dye 
p/po
0.0 0.1 0.2 0.3 0.4 0.5
V
ol
um
e 
of
 N
2 a
ds
or
be
d 
/c
m
3  g
-1
2.0
2.5
3.0
3.5
4.0
4.5
5.0
5.5
 
Fig. 5. BET isotherm of as prepared Mn1–xCdxS 
(x=0.18) catalyst. 
 
Wavelength, / nm
300 400 500 600 700 800
R
ef
le
ct
an
ce
0
10
20
30
40
50
60
70
80
 
 Fig. 6. The reflectance spectra of the as prepared 
Mn1–xCdxS (x=0.18). 
Page 237
* Corresponding Author: M.A. Hasnat,  
E-mail: mah-che@sust.edu 
 
 
molecules occurs concurrently, which is the main 
mechanism of degradation using oxide or sulfide 
catalyst, with the direct photocatalytic (e- and h+ 
generation) process. Therefore, superior 
photodegradation ability of the newly presented 
photocatalyst under visible light irradiation could be 
attributed to the combination of two process, namely, 
the enhanced direct e- and h+ generation process with 
increased lifetime of the photoproduced e- and h+ pairs 
and the self photosensitized degradation process of the 
dye molecules. 
4.  CONCLUSION 
The new catalyst more efficiently degraded Methylene 
blue molecules compared to the broadly used TiO2 or 
ZnO photocatalysts both under UV and visible light 
irradiation. Although, it showed slightly higher 
photocatalytic efficiency than TiO2 under UV light 
irradiation, a considerably greater activity than that 
was found for it under visible light irradiation. The 
results of the present study suggest that the 
photocatalytic degradation of dye pollutants using the 
composite phocatalyst Mn1–xCdxS (x = 0.18) could be 
an efficient way of the remediation for substantial 
harmful effect created by these pollutants. Since the 
catalyst showed considerably higher photocatalytic 
performance under visible light irradiation, it could 
further be recommended that the cost effective visible 
light irradiation based dye treatment technology, 
utilizing Mn1–xCdxS (x = 0.18) should be preferred. 
5. ACKNOWLEDGEMENTS 
The authors express great gratitude to Prof. Masato 
Machida and Mr. Satoshi Shiba of Kumamoto 
University, Graduate School of Nano Science and 
Technology, Japan for supplying necessary 
photocatalysts to perform the experiments for this 
research paper. 
6.  REFERENCES 
 
Amin, N. K., 2009, Removal of direct blue-106 dye 
from aqueous solution using new activated                     
carbons developed from pomegranate peel: Adsorption 
equilibrium and Kinetics, J. Hazard. Mater. 165, 52–
62. 
  
Babu, B. R., Parande, A. K., Raghu, S., Kumar, T. 
P.,2007. Cotton textile processing: waste generation 
and effluent treatment. J. Cot. Sci. 11, 141-153.  
 
Chen, S., Cao, G., 2002. Photocatalytic oxidation of 
nitrite by sunlight using TiO2 supported on hollow 
glass microbeads. Solar Energy 73, 15–21. 
 
Hasnat, M. A., Siddiquey, I. A., Nuruddin, A., 2005. 
Comparative photocatalytic studies of degradation of a 
cationic and an anionic dye, Dyes Pigments 66,185–
188. 
 
Hasnat, M. A., Uddin, M. M., Samed, A. J. F.,  Alam, 
S. S., Hossain, S., 2007.Adsorption and photocatalytic 
decolorization of a synthetic dye erythrosine on 
anatase TiO2 and ZnO  surfaces . J. Hazard. 
Mater.147, 471–477. 
Hu,X., Mohamood, T., Ma, W., Chen, C., Zhao, J., 
2006. Oxidative decomposition of  Rhodamine B dye 
in the presence of VO2+ and/or Pt(IV) under visible 
light irradiation:N-deethylation, chromophore 
cleavage, and mineralization. J. Phys. Chem. B 
110,26012–26018. 
 
Li,X., Ye, J., 2007. Photocatalytic Degradation of 
Rhodamine B over Pb3Nb4O13/fumed SiO2  composite 
under visible light irradiation. J. Phys. Chem. C. 111, 
13109–13116. 
 
Neppolian, B.,  Kanel, S. R.,  Choi, H. C.,  Shankar, M. 
V.,Arabindoo,B.,2003.Photocatalytic degradation of 
reactive yellow 17 dye in aqueous solution in the 
presence of TiO2 with  cement binder. Int. J. 
Photoener. 05, 45–49.  
 
Wellington, S., Pereira, S., Renato, S., Freire, S., 2006. 
Azo dye degradation by recycled waste   zero-
valent  iron powder.  J. Braz. Chem. Soc. 17, 832–838. 
 
Yu, J.C., Yu, J., Zhao, J., 2002. Enhanced 
photocatalytic activity of mesoporous and ordinary 
TiO2 thin films by sulfuric acid treatment. Appl. Catal. 
B: Environ. 36, 31–43. 
 
 
 
Page 238
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Sohrab Rohani,  
E-mail: srohani@uwo.ca 
A MULTIVARIATE ANALYSIS OF BIODIESEL PRODUCTION 
FROM THE LIPID OF WASTEWATER SLUDGE 
 
 
Muhammad N Siddiquee and Sohrab Rohani* 
Department of Chemical and Biochemical Engineering, the University of Western Ontario,      
1151 Richmond Street North, London, ON, N6A5B9 Canada  
 
 
 
Biodiesel is the most promising environment friendly green fuel produced from various renewable lipid 
sources. Wastewater sludge is a potential source of lipids that can be extracted using organic solvents and 
converted to biodiesel. A statistical multivariate analysis is a fast, economic, and effective way to 
systematically investigate the effect of several variables simultaneously. In this study, a half fraction 25 
Plackett-Burman factorial design was used to investigate the influence of five different variables on the 
biodiesel production from the methanol extracted lipid.  An empirical model was developed. The interaction 
of methanol to lipid ratio and reaction time was turned out to be the most significant factor.  Reaction time, 
amount of natural zeolite, concentration of acid catalyst, methanol to lipid ratio and the some interactions 
among the variables were also found to be statistically significant. The maximum biodiesel yield of the 
H2SO4 catalyzed esterification-transesterification was 57.12% (on the basis of lipid) at the centre point run.  
The effect of reaction time and temperature were also studied for the biodiesel production from the lipid of 
wastewater sludge. The yield and quality of the FAME were determined by GC.  
 
Keywords: Lipid, biodiesel, factorial design, wastewater sludge, fatty acid methyl ester (FAME) 
 
 
1. INTRODUCTION 
Biodiesel has worldwide attraction and growing 
interest as a renewable, biodegradable, clean fuel. It 
provides similar energy density to petro-diesel and 
can be used in most diesel engines in pure form 
(B100) or may be blended with petroleum diesel at 
any concentration. (Revellame et al., 2010; Knothe 
et al., 2005; Vyas et al., 2010; Siddiquee and 
Rohani, 2010; Xue et al., 2006]. However, the 
biodiesel production from pure vegetable oil is a 
major economic challenge as 70% and 85% of the 
overall biodiesel production cost is associated with 
the raw-materials (Revellame et al., 2010; Haas and 
Foglia, 2005; Mondala et al., 2009).  Moreover, 
these raw-materials for biodiesel production 
compete with food materials. Extensive research is 
being conducted all over the world to produce 
biodiesel from alternative raw-materials like algae, 
waste cooking oil, non-edible oil like jatropha, 
castor, neem, karanja,  pongamia, etc. But these are 
not the unique solution as cultivation of some of 
these requires huge lands. So the biodiesel 
production from a raw material that is readily 
available in large quantities without any cost is very 
important. 
Wastewater sludge generated after primary and 
secondary treatment processes is a source of 
various lipids which are being considered as 
potential feedstock for biodiesel production 
(Pokoo-Aikins et al., 2010; Uggetti et al., 2009; 
Jarde et al. 2005). Municipal wastewater treatment 
facilities produce large quantities of sludge that is 
available without any cost or even with an 
incentive. Wastewater treatment plant facilities in 
USA alone produced over 6.2 million metric tons of 
dry sludge every year (Dufreche et al., 2007). In 
2008, six wastewater treatment plants in London, 
Canada produced 3.8x105 m3 wastewater sludge 
(http://www.london.ca/d.aspx?s=/Sewer_and_Wast
ewater/Sewagetreatment_index.htm). The 
generation of wastewater sludge is expected to 
increase in the future due to increasing urbanization 
and industrialization. The sludge management and 
disposal is a great challenge for any wastewater 
treatment facilities. Biodiesel production from 
sludge will reduce the costly disposal as well as 
management challenge and will promote the energy 
recovery from the waste. Lipids are usually 
Page 239ISBN: 978-984-33-2140-4
  
extracted from the sludge with organic solvents to 
avoid the interference and subsequently, biodiesel 
is produced from the extracted lipid.  
Approximately 17– 18 wt % lipids (on the basis of 
dry sludge) were extracted from dried sewage 
sludge by boiling solvent extraction using 
chloroform and toluene as solvents  of which 65 wt 
% of the extracts were found to be free fatty acids 
and 7 wt % were glyceride fatty acids  and 28 wt% 
were  unsaponifiable material (Boocock et al., 
1992).  Pokoo-Aikins et al. separated the free fatty 
acids (FFA), triglycerides (oils) and the solvent 
from extracted lipids from sewage sludge by using 
toluene, hexane, ethanol, and methanol and found 
the yield of FFA was 24.8 wt%, 24.9 wt%, 25.5 
wt%, 25.5 wt%, respectively. The maximum yield 
of triglyceride was 3.4 w% for all four solvents 
(Pokoo-Aikins et al., 2010). 
Biodiesel, chemically known as fatty acid methyl 
ester (FAME), is produced via esterification and/or 
transesterification reaction (Fig. 1) of various lipid 
sources with alcohol in the presence of a base, acid, 
enzyme or heterogeneous catalyst. Base catalyst 
transesterification is widely used commercially due 
to very fast reaction rate compared to other 
catalysts. But, base catalyzed process is highly 
sensitive to the presence free fatty acids (FFA) as 
FFA reacts with catalyst and form soap that 
consume catalyst, inhibits glycerol separation and 
facilitate emulsion formation during washing step 
(Siddiquee and Rohani, 2010) . 
 
Acid catalyzed transterification is slower than base 
catalyzed transesterification and requires high lipid 
to alcohol ratio (Demirbas, 2005). However, the 
main advantage of acid catalyst is the ability to 
catalyze both the esterification and 
transesterification to produce more biodiesel. As 
the presence of water can stop the reaction (Fig. 2), 
this approach requires a water management 
technique.  
Few researchers used acid-catalyzed in-situ 
transesterification process to produce biodiesel 
from freeze dried primary and secondary sludge 
process (Revellame et al., 2010; Mondala et al., 
2009; Dufreche et al., 2007). However, the solvent 
and acid catalyst requirements were high. 
Moreover, freeze drying process to remove water 
from sludges was energy and time consuming. 
Additionally, water produced by in-situ 
esterification made the reaction rate slow. The use 
of commercial zeolite was reported in biodiesel 
production to absorb water produced by 
esterification reaction (Cao et. al., 2008). However, 
there was no report about the use of natural zeolite 
as a dehydrating agent for the production of 
biodiesel. In this study, we used natural zeolite to 
absorb water produced during the esterification 
reaction of FFA.  
The yield of biodiesel production depends on 
several factors including the type of catalyst (base, 
acid, enzyme or heterogeneous), alcohol/lipid ratio, 
temperature, and reaction time, water and free fatty 
acid content. Although several researchers have 
demonstrated biodiesel production from the lipid of 
wastewater sludge, the effects of various 
parameters have not investigated.
Fig. 1: Acid-catalyzed transesterification of triglycerides and esterification of fatty acids 
Fig. 2: Acid-catalyzed hydrolysis of FAME. 
Page 240
  
A statistical experimental design is a fast, 
economic, and effective way to investigate the 
effect of several variables simultaneously 
(multivariate data analysis). The objective of the 
multivariate data analysis is to develop an empirical 
model to describe the relation between a variable 
space (X) and response variable (Y) as well as 
possible (Jalbani et al., 2006; Karami and Rohani, 
2009). In this study, a half fraction 25 Plackett-
Burman factorial design was applied to study the 
effects of five factors  namely methanol to lipid 
ratio (X1), Reaction time (X2), temperature  (X3), 
amount of acid catalyst (X4), and amount of natural 
zeolite (X5). Stirring rate was kept constant during 
the experiments. 
 
2. MATERIALS AND METHODS 
 
2.1. Materials 
SuplecoTM standard 37component FAME mix- a 
37 component reference mixture of fatty acid 
methyl ester in the range of C4 to C24 including 
saturated, mono-unsaturated and poly unsaturated 
FAME were purchased from Supleco (Bellefonte, 
PA, USA) and used to calibrate the GC for FAME 
analysis. HPLC- grade methanol and hexane were 
purchased from Caledon Laboratories Ltd. 
(Georgetown, ON, Canada), sodium bicarbonate 
was purchased from Sigma-Aldrich Inc. (St. 
Louise, MO, USA), Sodium Chloride was 
purchased from EM Science       (Gibbstone, NJ, 
USA), anhydrous sodium sulphate was purchased 
from BDH Inc. (Toronto, ON, Canada). All the 
chemicals were used without any treatment. 
 
2.2 Sample Preparation 
Natural zeolite was crushed, desalted and calcinated 
at 300 oC temperature using a Lindberg/Blue 
Mendel (Model: Box Furnace, Thermo Scientific, 
USA) prior to use as a dehydrating agents. The 
wastewater sludge was collected from Adelaide 
Pollution Control Plant, London, ON, Canada. 
After settling for 24 hours at 0oC  and discarding 
the supernatant liquid, the resulting sludge was then 
centrifuged using IEC Centra-HN centrifuge 
(International Equipment Company, Needham 
Heights, USA) for further dewatering. Dewatered 
sludge was spread on tray and put in a fume hood to 
dry under vacuum at ambient temperature. Dried 
sludge was crushed in a mortar and pestle, 
homogenized and then stored in a freezer prior to 
use. 
 2.3 Extraction of lipid from sludge 
The lipid was extracted from dried sludge by using 
methanol as a solvent. The dried sludge was 
weighed into a round bottom flask and methanol 
was added and then the resulting mixture was 
heated to the 70oC temperature at ambient pressure.  
A magnetic stirring bar was used for mixing and the 
loss of methanol due to evaporation was minimized 
by using a condenser with water at 20 oC. After 
assigned extraction time, the resulting slurry was 
immediately filtered using VWR filter paper (size 
5.5 cm) and a Buchner funnel attached to vacuum. 
Any residual particles were removed by 
centrifuging the lipid solution. The methanol was 
removed from the resulting supernatants under 
vacuum using a Büchi Rotavapor R-200 (Büchi 
Labotechnik, Switzerland) at 45oC and then flask 
was flushed with air to remove any remaining 
methanol in the gas phase. The resulting lipid was 
stored in refrigerator prior to use.   
 
2.4 Experimental Design of Biodiesel 
Production 
Five variables under investigation and their high 
and low experimental levels and center points are 
given in Table 1. Two replicates were done for all 
treatment combinations. The biodiesel productions 
from extracted lipid were performed according to 
the scheme stated in Minitab Software using the 
modified version of Christie’s method in presence 
of an acid catalyst (H2SO4) (Christie, 2003). 
Table 1.  The experimental parameters and their 
high and low levels and center points 
Factors Low 
level 
(-1) 
High 
Level 
(+1) 
Centre 
Point 
(0) 
A: Methanol to 
lipid ratio (ml/g) 
50 200 125 
B: Reaction time 
(h) 
4 24 14 
C: Temperature    
            (oC) 
45 75 60 
D: % Acid catalyst  
           (ml/ml) 
1 5 3 
E: Natural Zeolite 
(mg) 
25 75 50 
Two hundred milligram of extracted lipid was 
dissolved in 10 ml of hexane and transferred to a 
round bottom flask. Assigned amount of natural 
zeolite, H2SO4 and methanol were added to the 
flask and the resulting mixture was heated at 
assigned temperature for the time mentioned in 
Table 1. A magnetic stirring bar was used for 
mixing. The loss of methanol due to evaporation 
was minimized by using a condenser with water. 
After stopping the reaction, the mixture was 
allowed to cool and then centrifuged using IEC 
Centra-HN centrifuge (International Equipment 
Company, Needham Heights, USA) for 5 minutes 
to remove the natural zeolite.  The supernatants 
Page 241
  
were transferred to a separatory funnel and then 
10ml aliquot of 5% NaCl in water was added. 
Twenty ml of hexane was added to the separatory 
funnel and shaken for 3 minutes to extract 
biodiesel. Extraction procedure was repeated 3 
times. Hexane layer was washed with 10 ml of 2 % 
NaHCO3 followed by 10 ml of warm water and 
dried by passing through a Whatman filter paper 
(110 mm dia) containing anhydrous sodium 
sulphate and collected into a measuring flask. A 1.5 
ml aliquot of hexane phase was pipetted into 2.0 ml 
Supelco PTFE lined capped vial (Supelco, 
Bellefonte, PA) for FAME analysis using GC 
equipped with FID (Flame Ionization Detector). 
The remaining hexane phase was transferred to a 
round bottom flask and the solvent was removed 
under vacuum using a Büchi R205 Rotary 
Evaporator (Büchi Labotechnik, Switzerland) at 40 
oC to get biodiesel. The yield of FAME was 
determined from FAME analysis using GC.  
2.5 FAME analysis 
Varian CP-3800 gas chromatograph (Varian Inc., 
Lake Forest, CA) equipped with FID, and a 50m x 
0.25 mm x 0.2 µm Varian CP-Wax 58 (FFAP) CB 
capillary Column (Varian Inc., Lake Forest, CA) 
was used to analyzed the FAME. Helium was used 
as a carrier gas and the sample injection volume 
was 1.0 µl with a split ratio of 80:1. The column 
flow was constant at 1.2 ml/min and column oven 
temperature was programmed to maintain at 100 oC 
for 1.0 min, increase from 100 oC to 200 oC at 15 
oC /min, then increased from 200 oC to 240 oC at 5 
oC /min, and finally maintained at 240 oC for 24 
min. The detector and injector temperature were set 
at 260 oC for the duration of the analysis.  
 
3. RESULTS AND DISCUSSION 
 
3.1 Statistical Analysis  
Minitab software version15 (Minitab Inc, State 
College PA, USA) was used for the statistical 
analyses. The normal probability plot for effects of 
biodiesel production from extracted lipid is shown 
in Fig. 3. The response for the model is the amount 
of biodiesel Y expressed in terms of wt/wt% (on the 
basis of lipid). The underlying model for a half 
fraction 25 Plackett-Burman factorial design is 
given by   
 




54
43423251
4131215
4321
19.1
82.031.055.112.1
87.08.186.168.0
48.020.099.094.131.45
XX
XXXXXXXX
XXXXXXX
XXXXY
 
Here, Xi is the factors  influencing the biodiesel 
production namely methanol to lipid ratio (X1), 
reaction time (X2), temperature  (X3), amount of acid 
catalyst (X4), and amount of natural zeolite (X5); Xi 
Xj is the interaction between the factors,  and  is the 
random error term having a normal distribution with 
mean zero and variance σ2 (Montgomery and Runger, 
2003). In the model, positive coefficients indicate 
that the high level of the variables increase the 
biodiesel yield. The interaction of methanol to lipid 
ratio(X1) and reaction time (X2) was turned out to be 
the most significant for the model. Reaction time, 
Temperature, amount of natural zeolite, concentration 
of acid catalyst, methanol to lipid ratio and the some 
interactions among the variables were also found to 
be statistically significant. 
20100-10-20
99
95
90
80
70
60
50
40
30
20
10
5
1
Standardized Effect
Pe
rc
en
t
A A
B B
C C
D D
E E
Factor Name
Not Significant
Significant
Effect Type
DE
CE
CD
BD
BC
AE
AD
AC
AB
E
D
C
B
A
Normal Plot of the Standardized Effects
(response is Biodiesel Yield, Alpha = 0.05)
 
 
Fig. 3: The normal plot of standardized effects of 
various factors and their interaction.  
3.2 FAME Analysis 
 
 
 
Fig. 4: FAME analysis of biodiesel obtained via 
acid catalyzed esterification-transesterification of 
lipid of the wastewater sludge. 
0
10
20
30
40
50
%
 F
A
M
E 
yi
el
d
Page 242
  
The maximum FAME yield of half fraction 25 
Plackett-Burman factorial design was 57.12% 
(wt/wt) (on the basis of lipid). This yield was 
obtained for centre point run. As shown in Fig. 4, 
biodiesel contain mainly the methyl ester of 
myristic acid (C 14:0), palmitic acid (C16:0), 
palmitoleic acid (C 16:1) stearic acid (C18:0), oleic 
acid (C18:1) and linoleic acid (C 18:2). Methyl 
ester of palmitic acid (C 16:0) is present in greatest 
amount in the biodiesel produced from the 
extracted lipid.  These results are found to be in 
agreement with the findings of Mondala et. al. by 
the in-situ transesterification of primary and 
secondary sludge (Mondala et. al., 2009).  
3.3 Effect of time on biodiesel production  
The effect of reactime time is shown in Fig. 5. The 
reaction was fast initally due to the esterification of 
the free fatty acid present in the lipid.  However, 
the reaction was slow after 12 h that may be due to 
the slow acid catalyzed transesterification of  lipid. 
 
 
Fig. 5: The effect of time on biodiesel production 
via H2SO4 catalyzed esterification-
transesterification of lipid of the wastewater sludge. 
3.3 Effect of temperature on biodiesel 
production  
The effect of temperature is shown in Fig. 6. The 
four temperature levels 40oC, 50oC , 60oC, and 70o 
were used for the 24h reaction time. The yield of 
biodiesel production was  increased with 
temperature upto 60oC. The maximum yield was 
obtained at 600C that was approximately 60 wt/wt% 
(on the basis of extracted lipid) . However, 
significant polymerization of unsaturated fatty acids 
and their derivatives might have caused the 
decrease of biodiesel yield at temperature above 
60oC. Another, possible reason is the loss of 
methanol at higher temperature. 
 
 
 
 
Fig. 6: The effect of temperature on biodiesel 
production via H2SO4 catalyzed esterification-
transesterification of lipid of the wastewater sludge. 
 
 
4. CONCLUSIONS 
 
A model was developed for biodiesel production 
from the lipid of wastewater sludge. The interaction 
of methanol to lipid ratio(X1) and reaction time (X2) 
was turned out to be the most significant for the 
model. All the five factors and the some 
interactions among the variables were also found to 
be statistically significant. The maximum FAME 
yield of half fraction 25 Plackett-Burman factorial 
design was 57.12% (wt/wt) (on the basis of lipid). 
The use natural zeolite as a dehydrating agent was 
increased the biodiesel yield. The biodiesel yield 
above 60oC was significantly decreased. This may 
be due to the acid catalyzed polymerization of 
unsaturated fatty acids and/ or their ester. Biodiesel 
produced from the lipid of wastewater sludge 
contain mainly the methyl ester of myristic acid (C 
14:0), palmitic acid (C16:0), palmitoleic acid (C 
16:1) stearic acid (C18:0), oleic acid (C18:1) and 
linoleic acid (C 18:2). 
 
 
REFERENCES 
1. Boocock DGB, Konar SK, Leung A, Ly LD, 
Fuels and chemicals from sewage sludge: 1. 
The solvent extraction and composition of a 
lipid from raw sewage sludge. Fuel 1992; 71 
(11):  1283–1289. 
2. Cao F., Chen Y., Zhai F., Li J., Wang J., Wang 
X., Wang S., Zhu W., Biodiesel production 
from high acid value waste frying oil catalyzed 
by superacid heteropolyacid, Biotech and 
Bioengg. 2008, 101(1), 93-100. 
3. Christie W., Lipid Analysis, Bridgwater:   The 
Oily Press; 2003. 
0
10
20
30
40
50
60
70
0 20 40 60
B
io
di
es
el
 yi
el
d,
 %
 w
t/w
t
Time, h
0
10
20
30
40
50
60
70
0 20 40 60 80
B
io
di
es
el
 y
ie
ld
 ,%
 w
t/w
t
Temperature, oC
Page 243
  
4. Demirbas A. Biodiesel production from 
vegetable oils via catalytic and non-catalytic  
supercritical methanol transesterification 
methods. Progress in Ener and Combus Sci 
2005; 31: 466–487. 
5. Dufreche S, Hernandez R, French T, Sparks D, 
Zappi M, Alley E. Extraction of lipids from 
municipal wastewater plant micro-organisms 
for production of biodiesel. J of the Am Oil   
Chem Soc 2007; 81: 181-187. 
6. Haas MJ, Foglia TA, Alternate feed stocks and 
technologies for biodiesel production. In: 
Knothe G, Krahl  J, Gerpen JV, editors. 
Biodiesel Handbook,   Champaign, IL: AOCS 
Press; 2005, p.42–61. 
7. Jalbani N., Kazi T. G., Arain B. M., Jamali 
M.K., Afridi H. I., Sarfraz R.A.; Application 
of factorial design in optimization of 
ultrasonic-assisted extraction of aluminium in 
juices and soft drinks, Talanta 2006; 70: 307-
314.  
8. Jarde E, Mansuy L, Faure P. Organic markers   
in the lipidic fraction of sewage sludges. 
Water Research 2005; 39:1215-1232.  
9. Karami D., Rohani S., Synthesis of pure  
zeolite Y using soluble silicate, a two-level 
factorial experimental design, Chem. Engg. 
and Processing 2009; 48: 1288-1292. 
10. Knothe G. What is biodiesel? In: Knothe G, 
Krahl  J, Gerpen JV, editors. Biodiesel 
Handbook,   Champaign, IL: AOCS Press; 
2005, p. 1–3. 
11. http://www.london.ca/d.aspx?s=/Sewer_and_
Wastewater/Sewagetreatment_index.htm   
[accessed on  March 11, 2010] 
12. Mondala A, Liang K, Toghiani H, Hernandez 
R, French T. Biodiesel production by in-situ  
transesterification of municipal primary and 
secondary sludges. Biores Tech 2009; 100: 
1203-1210. 
13. Montgomery DC, Runger GC, Applied 
Statistics and Probability for Engineers, 3rd 
edn, New York: John Wiley & Sons, Inc.; 
2003.   
14. Pokoo-Aikins G, Heath A, Mentzer RA, 
Mannan MS, Rogers WJ, El-Halwagi MM. A 
multi-criteria approach to screening 
alternatives for converting sewage sludge to 
biodiesel,  J of Loss Preven in the Process 
Indus 2010; 23: 412-420. 
15. Revellame E, Hernandez R, French W, Holmes 
W, Alley E. Biodiesel from activated sludge 
through in-situ transesterification. J Chem 
Tech Biotech 2010; 85: 614-620. 
16. Siddiquee M.N, Rohani S; Lipid Extraction 
and Biodiesel Production from Municipal 
Sewage Sludges- A Review, Journal of 
Renewable and Sustainable Energy Review, 
June 2010 (Accepted). 
17. Uggetti E., Llorens E.,  Pedescoll A., Ferrer I., 
Castellnou R., Garcia J., Sludge dewatering 
and stabilization in drying reed beds: 
Characterization of three full-scale systems in 
Catalonia, Spain, Bioresource Technology, 
2009,100, 3882–3890 . 
18. Vyas AP, Verma JL, Subrahmanyam N. A 
review on FAME production processes. Fuel   
2010; 89(1):1-9. 
19. Xue F, Zhang X, Luo H, Tan T. A new method 
for preparing raw material for biodiesel 
production. Process Biochemistry 2006; 41: 
1699–1702. 
 
 
Page 244
 Biogas from municipal solid waste 
Department of Chemical Engineering and Polymer Science,                                                           
Salma A. Iqbal, M. Suhel Hawlader, M. Nazim-Ul-Goni, M. Asraful Islam, S. Ded Mukta, M. 
Shamim, S. Islam Khan, M. Monir Hossein                                                                                  
Shahjalal University of Science and Technology, Sylhet-3114,Bangladesh E-mail: 
emma_promi@yahoo.co.uk 
Abstract 
Energy crisis and environmental pollution is the best concerned of today’s world. So that, 
research for renewable energy and getting friendly environment is middle task of all 
countries .Due to urbanization, many solid wastes are generated and the disposal of 
municipal solid waste is a great concern now a days . Municipal solid waste contains lot 
of organic composition which is one of the sources of biogas that’s biogas can help to 
remove the energy crisis and keep environment friendly. In this work can represent the 
reactant preparation, reactor design, biogas production from municipal solid waste, 
component of biogas, CO2 removing process, final component of biogas (in percentage), 
why needed to remove CO2, how public can benefited from this biogas and how it can 
save the environment from environmental pollution 
Keywords are: Solid waste, biogas, Absorption, co 2 removal. 
Introduction 
Energy is a vital input for economic growth 
in agriculture and industry. Fossil fuel are 
depleting fast due to over exploitation, 
besides increasing the environment al 
protection cost. Search for renewable energy 
source and their technology development is 
of paramount importance to have a balance 
and buoyant environment for better quality 
of life. Energy supply from renewable 
source is therefore an essential part of every 
country’s strategy, especially when there is a 
serious threat of environment degradation 
and challenge for maintaining sustainability 
of fossil fuels. [D.P. Kothari , K.C. Singal, 
Rakesh Ranjan, Renewable energy 
sources,2008, Preface xvll]                         
Biogas can be digestion of animal, plant and 
human waste. Digestion is a biological 
process that takes place in a digester with 
anaerobic organism in absence of oxygen at 
a temperature of 35 0 to 700c. [D.P. Kothari , 
K.C. Singal, Rakesh Ranjan, Renewable energy 
sources,2008, PP-287 ] 
Municipal solid waste (MSW), also called 
urban solid waste, is a waste type that 
includes 
     
          
Fig 1: Municipal Solid waste (Lalmaiya) 
Corresponding Author:                   
Salma A. Iqbal                              
Email: emma_promi@yahoo.co.uk 
Page 245
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
predominantly household waste (domestic 
waste) with sometimes the addition of 
commercial waste collected by a 
municipality within a given area. They are in 
either solid or semisolid form and generally 
exclude industrial hazards wastes. The term 
residual waste relates to waste left from 
household sources containing materials that 
have not been separated out or sent for 
reprocessing. Solid waste creates not only 
ground water pollution and soil pollution but 
is also play a vital role in urban air pollution. 
Due to the population growth and economic 
development, MSW generated is increasing 
with dramatically. the quantity of MSW in 
Sylhet is up to 120 tons/day. Among them 
maximum are disposed by landfill method. 
[Data From Sylhet City Corporation] 
 
Material and Methodology- Biogas 
production from solid waste: 
Waste Collection: 
1. Municipal Solid waste from Lalmatia 
2. From Police Line,  Rekabibazar 
3. From Electric Supply Road, 
Amborkhana 
In the batch reactor there take place the 
anaerobic digestion process of the waste 
material for 60 days. After the digestion 
process completed we collected the Biogas 
to gas collector through the Brine Replacing 
method. Then in the Orchid apparatus we 
measure the percentage of CO2. After that 
we have done water absorption of the 
collected gas. And again we measure the 
percentage of CO2 at the same process. 
Comparing the measurement of  carbon-di-
oxide in between before and after 
absorption process we seen that carbon-di-
oxide is reduced in great amount  
 
Fig 2: Mechanism of organism 
Pressure Swing Adsorption - PSA 
Adsorption“ refers to the exit of molecules 
from fluids and their subsequent attachment 
to solid surfaces . This process is used in 
PSA to remove the CO2 and any remaining 
traces of other gases from raw biogas. 
Before adsorption, sulfur and water vapor 
must be removed from the raw biogas, since 
these substances can damage the active 
carbon required in the process. As a rule, 
water separation succeeds when raw biogas 
is cooled nearly to the point of freezing. For 
the separation of sulfure from biogas, 
various other processes may be used.  
Pressurized Water Scrubbing (PWS) 
Pressure water washing is a matter of 
physical adsorption processes. Raw biogas is 
routed through a water-filled pressure tank, 
in which the gases present in the biogas are 
absorbed by the water through the 
application of physical force. Besides CO2, 
this process can also remove some of the 
hydrogen sulfide (H2S) and ammonia (NH3) 
present in raw biogas. When biogas contains 
more hydrogen sulfide than can be removed 
through pressure water washing, this is an 
indication that an additional sulfur removal 
process should be implemented “upstream” 
of the pressure water wash. Following the 
completion of the pressure water wash, the 
gas must be dried and dehumidified before 
being fed into the natural gas grid. 
Page 246
      
Fig 3: setup for the process. 
 
 
 
 
 
 
 
Fig 4: Schematic view of reactor 
 
 
Fig 5: Reactor with agitator 
 
 
 
 
 
 
 
 
 
  
         
 
 
 
 
 
 
 
 
Page 247
 Fig 6:Burning of bigas 
 
 
 
Fig 7: Gas collector
Table 1: Solid waste composition from Lalmatiya,Sylhet 
Basis: 20 kg weight municipal solid waste 
Element 1.Sample 
Weight(kg) 
1. 
Sample(%) 
 
2.Sample 
Weight(kg) 
2. 
Sample(%) 
 
3.Sample 
Weight(kg) 
3. 
Sample(%) 
 
Paper  1.00 5.00 1.00 5.00 1.50 7.50 
Can 0.00 0.00 0.00 0.00 0.00 0.00 
Plastic 1.50 7.50 2.00 10.00 1.50 7.50 
Organic 16.80 84.00 16.90 84.50 16.85 84.25 
Wire 0.20 1.00 0.00 0.00 0.00 0.00 
Others 0.50 2.50 0.10 0.50 0.15 0.75 
 
Table 2: Solid waste composition from Rikabibazar , Sylhet 
Basis: 30 kg weight municipal solid waste 
Element 1.Sample 
Weight(kg) 
1. 
Sample(%) 
 
2.Sample 
Weight(kg) 
2. 
Sample(%) 
 
3.Sample 
Weight(kg) 
3. 
Sample(%) 
 
Paper 1.50 5.00 2.00 6.6 1.00 3.33 
Can 0.10 0.33 0.10 0.33 0.15 0.50 
Plastic 2.00 6.60 2.00 3.33 2.00 6.60 
Organic 25.9 86.47 25.4 88.14 25.75 85.83 
Page 248
Wire 0.00 0.00 0.00 0.00 0.10 0.33 
Others 0.50 1.60 0.50 1.6 1.00 3.33 
 
Table 4:Typical chemical composition of MSW which collect from the Sylhet City Corporation 
Component Carbon Hydrogen Oxygen Nitrogen Sulfur Ash 
Food waste 48.0 6.4 37.6 2.6 0.4 5.0 
Paper 43.5 6.0 44.0 0.3 0.2 6.0 
Cardboard 44.0 5.9 44.6 0.3 0.2 5.0 
Plastic 60.0 7.2 22.8 - - 10.0 
Textile 55.0 6.6 31.2 4.6 0.15 2.5 
Rubber 78.0 10.0 - 2.0 - 10.0 
Leather 60.0 8.0 11.6 10.0 0.4 10.0 
Garden 
trimming 
47.8 6.0 38.0 3.4 0.3 4.5 
Wood 49.5 6.0 42.7 0.2 0.1 1.5 
Misc. 
organics 
48.5 6.5 37.5 2.2 0.3 5.0 
Dirt, ashes, 
brick etc 
26.3 3.0 2.0 0.5 0.2 68.0 
 
Theoretical Biogas yield 
 
The exact expectation of the producible biogas 
amount and its methane content is One of the 
most important aspects of an anaerobic digester. 
The chemical Compositions of a feedstock 
determine the potential biogas yields, as well as 
the gas composition. The results of elemental 
analyses showed the chemical composition of 
feed used in this study to be 
C14.25H28.80O4.43NS0.03. An empirical 
equation, Eq. (1), was used to calculate the 
biogas production in the anaerobic digestion. As 
a result, the theoretical biogas and methane 
yields of feed fresh leachate at standard 
temperature and pressure (STP, i.e., 0°C, 760 
mmHg) were 1.116 L biogas /g VSS destroyed 
and 0.72 L CH4/g VSS destroyed, respectively. 
The theoretical methane was estimated to be 
65%. 
CnHaObNcSd+ [A]H2O → [B]CO2 + [C]CH4 + 
[D]H2S……………. (1) 
 
Where 
[A] = n – a/4 – b/2 + 3c/4 + d/2 
[B] = n/2 – a/8 + b/4 +3c/8 + d/4 
[C] = n/2 + a/8 – b/4 – 3c/8 – b/4 
 
[Muhammad Alamgir,Chris McDonald,Karl 
Ernst Roehl , Aminul Ashan. 2005,”Integrated 
Management and Safe Disposal of Municipal 
Solid Waste in Least Developed Asian 
Countries” Department of Civil 
Engineering,KUET,Khulna,Bangladesh ] 
 
Page 249
Percentage of Methane: 
                                  
Measured by the Orchid apparatus: 
 Before the absorption (Approximate) 
 
Carbon dioxide (%) Methane (%)  
36 63 
38 61 
39 60 
 
2. After the Absorption   
   
Carbon dioxide (%) Methane (%) 
11 87 
13 85 
12 86 
 
 
 
Fig 8: Overall setup for CO2 absorption 
process. 
 
Conclusion:  
 
Solid wastes from domestic sources contribute 
to the processing environmental problems of the 
country like Bangladesh. In this paper attention 
has shifted to using organic waste material 
(Solid Waste) in the production of methane gas 
using a batch reactor production of biogas and 
the biogas contains around 60% of methane used 
as cooking, heating and lighting and as a source 
of electricity. 
 
Reference 
 
• D.P. Kothari , K.C. Singal, Rakesh 
Ranjan, Renewable energy 
sources,2008, Preface xvll, PP-287 
• O.S Data Table From Md. Albab 
Ahmed Choudory(C.I), Sylhet City 
Corporation,Date-2010. 
• RON ISAACSON,Senior project 
Manager,Enviromental 
Technology,Gas Research   
Institute,Chicago,Illions,USA,”Methan
e from community wastes” 
• Muhammad Alamgir,Chris 
McDonald,Karl Ernst Roehl , Aminul 
Ashan. 2005,”Integrated Management 
and Safe Disposal of Municipal Solid 
Waste in Least Developed Asian 
Countries” Department of Civil 
Engineering,KUET,Khulna,Banglades
h 
• M.S.K.A Sarker , B.K.Banik , M.A.I. 
Chowdhury , M.S. Islam and M.S 
Muntaha ,”Practice of Open Dumping 
in Sylhet City Corporation of 
Bangladesh”, Department of Civil and 
Environmental Engineering ,Shahjalal 
University of Science and 
Technology,Sylhet-3114 pp 227 & 228 
Page 250
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
 
* Corresponding Author E-mail: ikbal87@yahoo.com 
 
                                   
 
 
                           Clinical Waste Management in Sylhet City 
              
                  Husne Ara Moriom, Md. Ikbal Mahmud* ,  Salma A. Iqbal 
Department of Chemical Engineering & Polymer Science, Shahjalal University of science & Technology 
                                                                    Sylhet, Bangladesh 
 
Abstract: 
The scenario of clinical waste disposal system is simply threatening to our environment. Due to increasing 
health facility, production of clinical waste is also increasing. It is therefore, becoming a matter of great 
concern to manage this waste properly. Here we studied the clinical waste management system of Sylhet 
City Corporation (SCC). The objective of our study is the analysis of current disposal system of clinical 
waste and provide some recommendation for the improvement of existing healthcare situation as well as 
reduction of environmental pollution. The existing system of waste disposal is to dump all types of wastes 
in low lying areas adjacent to the town. Mass people are not aware of the hazards of infectious clinical 
waste. The wastes are not categorically segregated. As a result, mixing of municipal solid wastes with 
hazardous clinical wastes led to high risk of public health and environment. Our study also identify the risk 
associated with health hazards of general people and people engaged in the existing management system. 
We also give guidelines to SCC for sustainable management of clinical wastes. 
 
Key words : Waste, Clinical waste, Management, Health hazard. 
 
Introduction:  
Waste is defined as anything that you discard, 
intend to discard or are required to discard. This 
covers more than just objects and substances you 
have decided to dispose of. Material being 
recovered -  eg. sent for recycling or prepared for 
reuse - also counts as waste. Waste includes all 
items that people no longer have any use for, 
which they either intend to get rid of or have 
already discarded. Additionally, wastes are such 
items which people are require to discard, for 
example by lay because of their hazardous 
properties. 
Clinical waste is any waste which poses a threat 
of infection to humans. The term also includes 
drugs or other pharmaceutical products. 
Clinical waste is mainly produced by hospitals, 
health clinics, doctors' surgeries and veterinary 
practices, but also arises from residential homes, 
nursing homes and private households. 
Examples of clinical waste are human or animal 
tissue, blood or other bodily fluids, excretions, 
drugs or other pharmaceutical products, swabs or 
dressings, syringes, needles or other sharp 
instruments. 
 
One estimate shows that some 5.2 million people 
(including 4 million children) die each year from 
waste-related diseases. Concerned with this 
situation Agenda 21, adopted in the United 
Nations Conference on Environment and 
Development (UNCED) in Rio de Janerio in 
June, 1992, set the following goals and targets 
with regard to waste management in cities: 
 All countries must establish waste 
treatment and disposal criteria and 
develop the ability to monitor the 
environmental impact of waste by the 
year 2000. 
 By 2025, developing countries should 
ensure that at least half of the sewage, 
wastewater and solid waste are disposed 
according to national and international 
guidelines. 
 By 2025, all countries shall dispose of 
all waste according to international 
quality guidelines (Nasima, 2000). 
The unsafe disposal of health-care waste (for 
example, contaminated syringes and needles) 
poses public health risks. Contaminated needles 
and syringes represent a particular threat as the 
failure to dispose of them safely may lead to 
Page 251ISBN: 978-984-33-2140-4
dangerous recycling and repackaging which lead 
to unsafe reuse. Contaminated injection 
equipment may be scavenged from waste areas 
and dumpsites and either be reused or sold to be 
used again. WHO estimated that, in 2000, 
contaminated injections with contaminated 
syringes caused:  
21 million hepatitis  B virus (HBV) infections 
(32% of all new infections); two million hepatitis 
C virus (HCV) infections (40% of all new 
infections); and at least 260 000 HIV infections 
(5% of all new infections)(WHO, 2000). 
In 2002, the results of a WHO assessment 
conducted in 22 developing countries showed 
that the proportion of health-care facilities that 
do not use proper waste disposal methods ranges 
from 18% to 64%. 
In addition to the public health risks, if not 
managed, direct reuse of contaminated injection 
equipment results in occupational hazards to 
health workers, waste handlers and scavengers. 
Where waste is dumped into areas without 
restricted access, children may come into contact 
with contaminated waste and play with used 
needles and syringes. Epidemiological studies 
indicate that a person who experiences one 
needle stick injury from a needle used on an 
infected source patient has risks of 30%, 1.8%, 
and 0.3% respectively of becoming infected with 
HBV, HCV and HIV (Nasima, 2000). 
 
Sylhet, the northeastern divisional city of 
Bangladesh, is located at 24º53′N latitude and 
91º52′E longitude stands on the banks of river 
Surma. Considering the demand of huge 
increasing population, rapid and mushrooming 
growth of private clinics/hospitals is observed in 
the recent years in Sylhet city. And most of 
private clinics are housed in renovated 
residential building and do not have the facilities 
for adequate waste management systems. So 
clinical waste generated from government 
hospitals, private clinics, diagnostic centers and 
many other sources is a big problem in Sylhet 
City as there exists a very poor and unhygienic 
disposal system of that waste. Our study took an 
attempt to find out comparative analysis of 
clinical waste management in Sylhet City and to 
make some environmentally safe alternatives for 
better management.  
 
Objectives: 
• to categorize various types of clinical wastes in 
Sylhet City 
• to see the total amount of clinical waste 
generated from different hospitals and clinics of 
Sylhet city. 
• to note the existing management and discarding 
system of the clinical waste. 
• to provide some guidelines for improved 
management and dumping system of this clinical 
waste. 
 
Materials & Methods : 
Our study is intended to focus on the 
mismanagement and possible threats of clinical 
waste in Sylhet City. Among 136 different health 
care centers available in Sylhet city we studied 
around 40 facility center. The study was 
conducted for the period of six month from 
March 2010 to August 2010.Both primary and 
secondary data have been collected for this 
study. Primary data collection involves  
preliminary survey, questionnaire survey, 
physical observation and survey for finding 
waste generation rates. The primary data have 
been collected mainly on the basis of 
questionnaire through formal interview of the 
manager, matrons, cleaners, ward master and 
patients. The relevant secondary data for our 
study were mainly collected from the published 
and unpublished papers, journals etc. The 
collected data and information were critically 
analyzed to assess existing waste management 
system, its limitation and impacts. An integrated 
management plan was recommended for efficient 
disposal of clinical waste. 
 
Result and Discussion : 
To find out the generation rate of different 
categories of wastes, a weeklong survey at 
different hospitals, clinics, diagnostic center and 
outdoors clinics of SCC area has been carried 
out. The wastes were collected, weighed and 
recorded three times a day from each health care 
center(HCC). The timing was morning, noon and 
evening. The data collection survey for each 
HCC was a continuous program i.e. without 
break for weekend and general holidays. In this 
Page 252
survey we found clinical wastes such as gauge; 
bandage, cotton, saline bag, chemical reagent, 
blood, urine, stools, test tube etc from 
pathological lab, plasters , foil or packet of 
medicine, any part of human body amputed in 
Operation Theater, abortion ambrio, syringes and 
needles, stool, urine, cough, spit, blood etc. We 
categorize these wastes as Infectious and General 
waste, Sharp waste, Recyclable waste, Chemical 
and Radioactive waste. The average amount of 
generated waste in different categories from 
different clinics and hospitals, diagnostic centers 
is tabulated below.  
                               Table : Amount of clinical waste generated in studied health care center 
 
 
 
Sl. 
No 
 
 
                       Name 
 
 
No. of 
beds 
No. of 
people 
involve
d in 
waste 
manage
-ment 
                
             
            Daily generated waste(in Kg)/Day 
Infectious 
& general 
Sharp Recycla-
ble  
Chemical & 
radioactive 
1 Sylhet Osmani Medical College Hospital       
    900 
    
   130 
 
     400 
 
 10 
 
  20 
 
    04 
2 Jalalabad Ragib Rabeya Medical College 
Hospital  
     
    500 
 
   110 
 
     150 
 
  8 
 
  10 
 
    2.5 
3 North East Medical College Hospital      400     90      100   5    7     1.5 
4 Sylhet Shahid Shamsuddin Hospital      100     24       25   2    5     0.5 
5 General Shisu Hospital        75     20       18   1    5     0.5 
6 T.B.Hospital        56      8       15   2    3     0.4 
7 Noorjahan Hospital        60     25       15   2    4     0.3 
8 Niramoy Poly Clinic        40     16       10   1    2     0.2 
9 City Poly Clinic        50     20       12   1    2     0.4 
10 Ayesha Medicare       35     15       10   1    2     0.5 
11 Central Hospital        25     10       08   1             1     0.2 
12 Mother care Clinic       18       8       06  0.5    2      - 
13 Jalalabad Clinic       20     12       08   1    1      - 
14 Al-Raiyan Hospital       24     04       07   1    3     0.2 
15 Arroggy Poly Clinic       26     06       08   -    2      - 
16 Friends Eye Hospital       20     04       06   -    -      - 
17 Shahjalal Mental Health Hospital       50     10       10  0.5    2     0.5 
18 Marie Stopes Clinic       14      06       08   -    2      - 
19 United Poly Clinic       40      18       10   1    2      1 
20 Royal Hospital       70      45       18   1    3      1 
21 Metropolitan Hospital       25      14       08   -    2      - 
22 Al-Banna General Hospital       24      07       06  0.5    2      - 
23 Popular General Hospital       20      04       06   -    2      - 
24 Fair Health Hospital       26      06       08  0.5    1     0.5 
25 Ideal Clinic       24      06       06  0.5    2     0.2 
26 Medinova Medical Services       04       04   1    2       2 
27 Popular Medical Center       15       05   1    3       3 
28 Medi Aid       03       03   1    1       1 
29 Medi Lab       02       02  0.5    1       1 
30 Marie Stopes       04       04  0.5    -     0.5 
31 Lab Aid Diagnostic Center       08       04    1    2       1 
32 Malik Compath       04       02  0.5    1     0.5 
33 National Diagnostic Center       04       03  0.5    1      0.5 
34 Family Health Clinics       03       02  0.8    1     0.4 
                               Total 2642    665     907  47.3   99    24.3 
Page 253
 
 
 
      
 
 
                
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                                        Figure: Photograph showing collection & dumping of clinical waste 
 
 
 
The rate of waste generation differs due to 
geographical location, season of the year, 
collection frequency, availability of different 
treatment facilities, social status of the patient 
(i.e. income, living standard, awareness about 
diseases), hospital management, legislation etc. 
Clinical waste generated from the daily activities 
of patients, cleaners, sweepers, nurses, doctors, 
Page 254
and administrators etc that are discarded as 
useless. Medical wastes are generated from 
wards, cabins, Operation Theater. Volume of 
waste mainly depends upon Number of beds and 
outdoor patients that represents the waste 
generation sources. It is observed that existing 
clinical waste collection, handling and disposal 
practices of all the clinics and hospitals of SCC 
involved transport of wastes by ward boys, maid 
nurses and other employees from the point of 
generation to initial storage points in each unit. 
Wastes are normally collected from small bowl 
or plastic bin provided for each bed in hospital 
and stored either in a large size plastic bag or 
bucket. These plastic bags or wastes from 
buckets are then put in a pushcart and carried to 
the nearest municipal bins for dumping without 
any segregation or treatment. The municipal bins 
are normally placed either in hospital premises or 
outside the hospital. Wastes from operation 
theater, laboratory and hospital kitchen are also 
dumped into municipal bins. SCC trucks carried 
these wastes three times daily to the landfill area 
for final dumping. Following pie diagram 
categorically shows the amount of waste in 
percentage. 
 
 
                      
84%
4%
10%
2%
Infectious &
General
Sharp
Recyclable
Chemical &
Radioactive
 
 
                                        Figure: Percentage of different type of clinical waste 
 
 
Risk associated with clinical waste  : 
 
Clinical waste is a reservoir of potentially 
harmful micro-organisms which can infect 
hospital patients, health-care workers and the 
general public. Other potential infectious risks 
include the spread of, sometimes resistant, 
micro-organisms from health-care establishments 
into the environment. These risks have so far 
been only poorly investigated. Wastes and by-
products can also cause injuries, for example 
radiation burns or sharps-inflicted injuries; 
poisoning and pollution, whether through the 
release of pharmaceutical products, in particular, 
antibiotics and cytotoxic drugs, through the 
waste water or by toxic elements or compounds 
such as mercury or dioxins.  
Throughout the world every year an estimated 12 
000 million injections are administered. And not 
all needles and syringes are properly disposed of, 
generating a considerable risk for injury and 
infection and opportunities for re-use. 
Worldwide, 8-16 million hepatitis B, 2.3 to 4.7 
million hepatitis C and 80 000 to 160 000 HIV 
infections are estimated to occur yearly from re-
use of  syringe needles without sterilization2.  
Many of these infections could be avoided if 
syringes were disposed of safely. The re-use of 
disposable syringes and needles for injections is 
particularly common in certain African, Asian 
and Central and Eastern European countries. 
In developing countries, additional hazards occur 
from scavenging on waste disposal sites and 
manual sorting of the waste recuperated at the 
back doors of health-care establishments. These 
practices are common in many regions of the 
world. The waste handlers are at immediate risk 
of needle-stick injuries and other exposures to 
toxic or infectious materials. 
Page 255
The use of radiation sources in medical and other 
applications is widespread throughout the world. 
Occasionally, the public is exposed to 
radioactive waste, usually originating from 
radiotherapy treatments, that has not been 
properly disposed of. Serious accidents have 
been documented in Goiânia, Brazil in 1988 in 
which four people died from acute radiation 
syndrome and 28 suffered serious radiation 
burns. Similar accidents happened in Mexico 
City in 1962, Algeria in 1978, Morocco in 1983 
and Ciudad Juárez in Mexico in 1983. 
Risks associated with other fractions of health-
care wastes, in particular blood waste and 
chemicals, have been relatively poorly assessed, 
and need to be strengthened. 
 
Recommendation :  
 
Clinical waste management is one of the most 
neglected parts of the managerial process in 
Bangladesh. Neither the government nor the 
hospital authorities pay proper attention to this 
matter. There are no well-defined rules and 
regulations of clinical waste management in 
Sylhet City Corporation. That means no specific 
definition of clinical waste and no specific and 
separate regulation for disposal of clinical waste 
and also there is less priority for proper disposal 
of waste by the authorities and lack of 
accountability of concerned authorities. Since the 
existing solid waste management system of 
Sylhet City is neither satisfactory nor adequate 
and has been failed to keep pace with the vast 
amount of solid waste produced, the clinical 
waste doesn’t get proper attention. Having this 
reality, some recommendations from us- 
 The build-up of a comprehensive 
system, addressing responsibilities, 
resource allocation, handling and 
disposal. This is a long-term process, 
sustained by gradual improvements; 
 Segregation and identification (color 
coding) of hazardous waste from non-
risk clinical waste. 
 Non-biodegradable portion of clinical 
waste should be separately collected 
and recycled. 
  SCC should start a separate collection 
and disposal system for clinical waste. 
 
 
 
Conclusion : 
 
At present, clinical waste management has 
become a decisive issue around the world. For its 
hazardous nature it is very much harmful for the 
environment. Lately, the management of clinical 
wastes has received little attention despite their 
potential environmental hazards and public 
health risks. Using both the quantitative and 
qualitative approach, the report has attempted to 
put a figure on the mismanagement of clinical 
waste and the health hazard accompanying with 
it. The study reveals that medical wastes are not 
properly managed in almost all the clinics and 
hospitals, in the study area. It can be concluded 
that the existing system of clinical waste 
management of studied health care centers is 
neither satisfactory nor adequate. Human 
resource development, adequate logistic and 
technological support and above all political 
commitment are the basic needs for the 
development in the sector. 
 
References: 
 
1. Rahman, M. H., Ahmed, S. N. and Ullah, M. 
S. 1999. A study on hospital waste management 
in Dhaka City. 25th WEDC conference, Addis 
Ababa, Ethiopia. 
 
2. Rahman, M. T., Sarkar, M. S. K. A., 
Chowdhury, M. A. I., Haque, K. E. and Hasan, 
M. M. 2003. Solid waste pollution in Sylhet 
City, Bangladesh Journal of Environmental 
Science. 
 
3. Nasima, A. 2000. Medical waste management: 
A review. Environmental Engineering Program. 
School of Environmental resources and 
development, Asian Institute of Technology, 
Khlogluang, Pathumthani, Thailand. 
 
4. World Health Organisation (WHO) 2000. 
Waste from Health-Care-Activities. WHO 
information, fact Sheet No 253, October 2000. 
 
5. Alamgir M., Chowdhury K.H., Hossain Q.S., 
Glawe U. & Roehl K.E. 2003. Management of 
clinical wastes in Khulna city. Proc. of 
SRRAESND 2003, 19-20 Dec., Khulna.  
 
Page 256
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*Corresponding Author: Kaniz Ferdous 
E-mail: engr_kaniz@yahoo.com 
COMPERATIVE STUDY OF BIODIESEL PREPARATION 
METHODS 
 
 
Kaniz Ferdous*1, 2, M. Rakib Uddin1, Maksudur R. Khan1, 2, 3, M. A. Islam1, 2 
1Department of Chemical Engineering and Polymer Science, Shahjalal University of Science and 
Technology, Sylhet, Bangladesh 
2Centre for Environmental Process Engineering, Shahjalal University of Science and Technology, 
Sylhet, Bangladesh 
3Faculty of Chemical and Natural Resources Engineering, Universiti Malaysia Pahang, Lebuhraya 
Tun Razak, 26030 Gambang, Kuantan, Pahang, Malaysia 
 
 
Biodiesel, which is a new, renewable and biological origin alternative diesel fuel, has been receiving more 
attention all over the world due to the energy needs and environmental consciousness. Biodiesel is usually 
produced from food-grade vegetable oils using transesterification process. Base catalyzed transesterification 
reaction is widely used for biodiesel production from vegetable oil due to its faster kinetics than that of acid 
catalyzed process. But if free fatty acid (FFA) content in the oil is more than 2%, the base catalyzed process 
is not feasible. Using food-grade vegetable oils is not economically feasible since they are more expensive 
than diesel fuel. Therefore, it is said that the main obstacle for commercialization of biodiesel is its high cost. 
Nonedible feed stocks are being studied in recent years for biodiesel production. The main problem for the 
nonedible sources is its high FFA content which limits the use of single step transesterification reaction. A 
two-step and three-step processes are developed recently for the biodiesel production from oil. In the present 
paper biodiesel is prepared from nonedible oils, such as rubber seed oil and nahor oil by different methods. 
The difficulties of each processes are discussed and the biodiesel properties are measured and compared. 
 
Keywords: Biodiesel; Transesterification; Esterification; Saponification. 
 
1. INTRODUCTION 
 
The vast majority of motor vehicles used around 
the world rely on four-stroke internal combustion 
engines run on petroleum-based fuel or biodiesel. 
In comparison with petro-diesel, vegetable oils 
have their own advantages: first of all, they are 
renewable as the vegetables which produce oil 
seeds can be planted year after year; secondly, they 
are available everywhere in the world; thirdly, they 
are “greener” to the environment, as they seldom 
contain sulfur element in them. (Balat et. al., 2008).  
Use of biodiesel is catching up all over the world 
especially in the developed countries. Most 
developed countries are moving from voluntarily to 
obligatory legislations to increase the market share 
of biofuels within the transport sector (e.g. set up of 
a mandatory biofuel target of 10% by the European 
Commission for the European transport sector in 
2020 (Directive 2009/28/EC of the Parliament and 
of the Council on the promotion of the use of 
energy from renewable sources and amending and 
subsequently repealing Directives 2001/77/EC and 
2003/30/EC, Brussels, 23 April 2009.)) 
The end cost of the biodiesel mainly depends on the 
price of feedstock.  Although biodiesel is currently 
produced from high quality food-grade vegetable 
oils (in the USA, soybean oil; in Europe, rapeseed 
oil) using methanol and an alkaline catalyst, but it 
can be made from any plant oils with over 350 oil-
bearing crops being identified for the production of 
biodiesel (Demirbas et. al., 2007). The predominant 
feedstock in the Europe is rapeseed, while soybean 
is the most widely used feedstock in the United 
States (US). Feedstocks such as palm, jatropha and 
coconut are common in Malaysia, India and the 
Philippines, respectively. (Demirbas, 2007). Gui et 
al made a thorough analysis on the production of 
biodiesel from edible and nonedible oils. Generally 
the cost of raw materials accounts about 70-80% of 
the total production cost of biodiesel.  
Four major techniques (dilution, microemulsion, 
pyrolysis, and transesterification modification 
techniques) are used for biodiesel production, 
among them transesterification process has been 
widely used to reduce the high viscosity of the oil. 
Transesterification reaction can be catalyzed by 
both homogeneous (alkalies and acids) and 
Page 257ISBN: 978-984-33-2140-4
 
 
 
 
heterogeneous catalysts. The most commonly used 
alkali catalysts are NaOH, CH3ONa, and KOH  
(Gemma et. al., 2004). It has been found that the 
alkaline-catalyzed transesterification process is not 
suitable to produce esters from unrefined oils 
(Ramadhas et. al., 2005)  where the FFA content is 
higher. In order to prevent saponification during the 
reaction, FFA and water content of the feed must be 
below 0.5 wt.% and 0.05 wt.%, respectively. 
Because of these limitations, only pure vegetable 
oil feeds are appropriate for alkali-catalyzed 
Transesterification without extensive pre-treatment 
(Freedman et. al., 1984).  Homogeneous acid-
catalyzed reaction is about 4000 times slower than 
the homogeneous base-catalyzed reaction and 
hence is not popular for industrial production of 
biodiesel.  
A two-step process is developed recently for the 
biodiesel production from oil, where in the first step 
acid-catalyzed esterification is conducted to convert 
the FFA to FAME followed by the base catalyzed 
transesterification to convert the TG to FAME. 
Another approach was reported, where FFA was 
produced from oil by saponification-acidification 
reaction and FAME is produced by acid catalyzed 
esterification (Islam et. al., 2008).  In the present 
paper biodiesel is prepared from nonedible oils, 
such as rubber seed oil and nahor oil by different 
methods. The difficulties of each processes are 
discussed and the biodiesel properties are measured 
and compared. 
 
2.  MATERIALS AND METHODS 
 
2.1. Chemicals 
Methanol (99-100%), ethanol (99-100%), sodium 
hydroxide pellets (96%),  potassium hydroxide 
pellets (>84%), phenolphthalein (pH 8.2 - 9.8), 
starch,  acetone (99%), n-Hexane(96%), 
hydrochloric acid(37%) , isopropanol, iodine, 
sodium iodide, glacial acetic acid, bromine, carbon 
tetrachloride, s-Diphenylcarbazide, Potassium 
Dichromate etc. were purchased from Merck. All 
the chemicals used were analytical reagent grade.  
 
2.2 Extraction of oil 
Different methods were used to extract oil from the 
seed (Morshed et. al., 2008). For mechanical press, 
a vertical, manual operated, cylindrical (4.3 cm ID) 
mechanical press spiral screw was used. For cold 
percolation processa, hexane was used as a solvent. 
A Soxhlet Extraction unit was used for oil 
extraction where hexane was refluxed for 6 h for a 
given amount of karnel mass.  
 
2.3.    Biodiesel preparation from oil 
2.3.1 Acid catalysed transesterification 
Biodiesel from non-edible oil  was prepared 
by acid catalyzed transesterification reaction (De 
B.K. and Bhattacharyya, 1999). The reaction was 
carried out at 70 0C and atmospheric pressure under 
reflux for 18 hours with vigorous stirring. Typically 
50 gm of oil sample were placed in a three-necked 
250 ml round bottom flask equipped with a reflux 
condenser. The flask was placed in an electric 
heater with a temperature controller and magnetic 
stirrer. Concentrated sulfuric acid (2 wt % of oil) 
was mixed in required amount of methanol. 
Methanol was used 9:1 molar ratio to oil. The 
methanesulfonic acid solution was transferred into 
the reaction flask. After 18 hours, the contents were 
cooled to room temperature. After the reaction 
period, the reaction product was allowed to stand 2-
3 hours in a separatory funnel. Two separate layers 
were observed. Upper layer was methyl ester 
(Biodiesel) and lower layer were a mixture of crude 
glycerin  and lye catalyst. The Biodiesel layer was 
separated and this layer was opaque as it contained 
some catalyst, methanol and triglyceride. For 
purification of the biodiesel given water wash. For 
this purpose hot water and biodiesel mixed together 
in separatory funnel and shaking. Then allow stand 
for phase separation. Water is heavier than 
biodiesel and absorbs the excess alcohol, catalyst 
and impurities. After washing and settling, the 
water and the impurities in the water are drained 
from the bottom of the separatory funnel. Several 
wash cycle are generally needed. The first washed 
water drained from funnel will be milky, and the 
final washed water drained off will be clear. The 
washed biodiesel was then dried at 80-100 0C under 
vacuum. 
 
2.3.2 Two step method 
A two-step acid-catalyzed methanolysis of higher 
FFA containing oil was adopted for the conversion 
of FFA and TG to fatty acid methyl esters 
(Zullaikah et al 2005). In brief, in the first step 
esterification was carried out at 60 0C and 
atmospheric pressure with a molar ratio of 
methanol/FFA as  5/1. Sulfuric acid (2 wt% of oil) 
was used as catalyst and reaction was carried out 
for 2 h. After 2 h the contents were cooled to room 
temperature and reaction product was washed with 
hot water in a seperatory funnel until clear water 
found  and dried under vacuum at 100 0C for 20 
min. In the second step acid catalyzed 
transesterification (2 wt% sulfuric acid ) with 
oil/methanol molar ratio of 1/9. The methanolysis 
was performed under vigorous stirring at 100 0C. 
After 6 h the contents were cooled to room 
temperature, and reaction product was washed with 
hot water until clear water found. The organic 
phase was collected and dried under vacuum at 100 
0C for 30 min. 
 
 
Page 258
 
 
 
 
2.3.3 Three-step method 
In this method the raw seed oil was saponified, 
acidified and esterified sequentially. Saponification 
was carried out for 30 min with different 
stoichiometric amount of alcoholic sodium 
hydroxide solution at 60 0C (Islam et. al., 2008). In 
further study saponification of oil was done by 
aqueous calcium oxide solution. The reaction time 
and molar ratio of oil to calcium oxide were 
optimized. 
After saponification, the soap solution were treated 
with different stoichiometric amount of 
concentrated hydrochloric acid at a temperature of 
60 -70 0C with vigorous stirring. After dissolving 
the soap the fatty acid contents were separated in 
separatory funnel. The fatty acid content was 
determined by titrimetric method.  
Esterification of FFA was carried out as similar the 
first step of the two-step method. The molar ratio of 
FFA to methanol, catalyst concentration and 
reaction temperature were optimised. The biodiesel 
was washed and dried under vacuum. 
 
2.4. Analytical Methods for Oil and 
Biodiesel 
FFA in the oil and biodiesel samples was analyzed 
by the method described in AOCS Aa 6-38. 
Saponification value (SV) was determined by the 
method described by Jeffery et al. .  The iodine 
value (IV) were determined by titrating 0.01 N 
sodium thiosulfate to the mixture of tested fuel and 
chemical reagents until the disappearance of the 
blue color based on the analysis methods of 
American Oil Chemist’s Society.  
Physical properties such as color, moisture content, 
density and calorific value of the oil were 
determined by following ASTM D 1500, ASTM D 
1744 (Karl fisher method), ASTM D 1480/81 and 
ASTM D 240 respectively. Boiling point was 
determined by using the variable heating 
instrument, Gallanclamp, Germany. Viscosity, flash 
point, pour point and cloud point were determined 
by standards ASTM D445, ASTM D 93 (Pensky- 
Martens Flashpoint Apparatus, Lazer Scientific Inc, 
Germany), ASTM D 2500 and ASTM D 97 
respectively.  
 
3. RESULT AND DISCUSSION: 
 
3.1: Extraction of oil and Characterization:  
The oil was extracted from the seed by 
different  methods and the oil content in the 
seed presented in Table 1. 
Table 1: Oil contents in nahor and rubber seed by 
different methods 
Seed Press  Cold 
percol
ation  
Press 
with 
solvent 
Sohxl
ett  
 wt.% wt.% wt.% wt.% 
Nahor Seed 39 44 52 54 
Rubber 
Seed 
5 42 49 52 
Properties of raw oil are given in Table 2. 
 
Table 2: Properties of raw oil. 
Properties  Nahor 
seed oil 
Rubber 
seed oil 
Physical state Liquid  Liquid 
Color Brown  Brown 
Specific gravity at 250C 0.926 0.88 
Viscosity, mm2/s at 250C 58.06 33 
FFA wt. % 12.17 45 
Average molecular weight of 
FFA (gm/mol) 
275.5 278.12 
Molecular weight of oil 
(gm/mol) 
864.5 875.36 
Saponification value (mg of 
KOH/gm of oil) 
249.33 213 
Iodine value, g I2/100 g oil 77 132.6 
Cetane Index 50.87 45.25 
Moisture content, wt. % 0.51-0.52 0.93-0.98 
 
3.2. Preparation of biodiesel: 
 
3.2.1. Biodiesel preparation by single step 
(transesterification) and two-step medods: 
The properties of biodiesel for acid catalyzed 
transesterification reaction and two-step method are 
presented in Table 3. The final viscosity of the 
biodiesel by  two-step method is lower than the 
single step acid catalyzed process. RSO yields poor 
results than the Nahor oil due to its high FFA 
content in the oil. The acid catalyzed single step 
process is time consuming and even after 18 h the 
viscosity of the biodiesel is not comparable with the 
standard biodiesel viscosity. However, there are 
some drawbacks in two-step process also. The 
second step, transesterification requires 6 h instead 
of 2 h reported by Zullaikh et al. And the final 
biodiesel viscosity is higher than the standard value 
(Table 3) 
Table 3: Properties of Acid catalyzed 
transesterification and two-step method products 
Property  Trannsesterificati
on 
Two-step 
NSO RSO NSO RSO 
Color  Black Dark 
brown 
Blac
k 
Dark 
brown 
Viscosity 
(mm2/s) at 
22 0C 
14.5 17.8 9.6 14.5 
Page 259
 
 
 
 
Saponificati
on value (mg 
KOH/gm 
oil) 
211 203 212 202 
FFA (wt%) 2.12 14.5 0.65 6.2 
Specific 
gravity  
0.89 0.86 0.89 0.9 
 
3.2.2. Three-step method for biodiesel 
Preparation: 
FFA was prepared from oil by Saponification of oil 
followed by acidification mentioned above. The 
results are represented in Fig. 1. From Fig. 1, it can 
be seen that the optimum molar ratio of sodium 
hydroxide to oil was 1:6 for both nahor oil and 
RSO. Further increase in the molar ratio of NaOH 
to oil the conversion of oil to soap remain 
unchanged. 
3 4 5 6 7
60
70
80
90
100
FF
A
, w
t.%
NaOH/Oil (mol ratio)
 Nahor Oil
 RSO
Fig.1: Preparation of Free Fatty Acid (FFA) from 
oil through saponification and acidification by 
different stoichiometric molar ratio of alcoholic 
NaOH solution [T = 60 0C, Time=30 min]. 
 
In further study, saponification was carried out by 
aqueous calcium oxide solution and FFA prepared 
from nahor oil. The results are shown in Fig 2.  
As shown in Fig. 2, the optimum molar ratio of oil 
to calcium oxide was 1:2 for nahor oil and time was 
1 hour.   
FFA obtained from oil was subjected to 
esterification to convert biodiesel. The reaction was 
carried out with different FFA/methanol molar ratio 
in presence of catalyst (HCl). Effect of 
FFA/Methanol molar ratio was investigated at 60 C 
and 5 wt% of catalyst. The results are presented in 
Fig. 3. The maximum conversion of FFA to methyl 
ester was found for FFA/ methanol molar ratio of 
1:6 after 120 minutes for both oil and for nahor oil 
conversions were 97.2% and 98.15% for nahor oil 
and RSO respectively. Further increase in molar 
ratio of alcohol to FFA the conversion of FFA and 
viscosity remain unchanged. 
 
0 50 100 150 200 250
45
50
55
60
65
70
75
80
85
90
95
100
P
er
ce
nt
 F
FA
Time (min.)
 Oil:CaO=1:3
 Oil:CaO=1:2
 Oil:CaO=1:1
Fig 2: Preparation of FFA from nahor oil through 
saponification and acidification by different 
stoichiometric molar ratio of calcium oxide to oil in 
aqueous solution [T = 1000C, under reflux with 
vigorous stirring]. 
 
0 2 4 6 8 10
65
70
75
80
85
90
95
100
C
on
ve
rs
io
n,
 %
methanol/FFA, mol ratio
 FFA feom Nahor Oil
 FFA from RSO
Fig. 3 : Conversion of FFA to biodiesel at different 
FFA/ methanol molar ratio for nahor oil derived 
FFA and RSO derived FFA [Reaction temp. 60C, 
Catalyst concentration 5.0% wt of FFA, vigorous 
stirring, Reaction time 120 min]. 
 
Effect of Catalyst Concentration was studied at 
FFA/methanol molar ratio of 1:6 at 60 C and the 
results are presented in Fig. 4 a and b. 
 
Fig 4 shows that around 98 % conversion of FFA 
can be achieved by 5 wt% catalyst concentration. 
Further increase in catalyst concentration has no 
impact on FFA conversion.   
 
Page 260
 
 
 
 
0 10 20 30 40 50 60 70 80 90 100 110 120
0
20
40
60
80
100
a) Nahor Oil
FF
A 
w
t%
Time (min)
 7 wt% HCl Catalyst
 5 wt% HCl Catalyst
 3 wt% HCl Catalyst
 
0 20 40 60 80 100 120
0
20
40
60
80
100
b) Rubber seed oil
FF
A,
 w
t.%
time, min
 Catalyst concentration = 3 wt.% of FFA
 Catalyst concentration = 5 wt.% of FFA
 Catalyst concentration = 7 wt.% of FFA
 
Fig 4: Effect of catalyst concentration on 
esterification reaction [T = 60C,  FFA / methanol 
ratio 1:6, vigorous stirring, Reaction time 120 min]. 
 
 
Effect of Temperature on esterification reaction was 
studied with Nahor oil derived FFA. The results are 
presented in Fig 5. It can be seen that the 
temperature has a significant effect on the 
conversion of esterification reaction. As the 
temperature increased, the conversion was also 
increased.. 
 
3.4 Properties of biodiesel: 
 
Some of the important quality parameters of 
biodiesel (viscosity, density, flash point, cloud 
point, pour point, calorific value, FFA content, 
copper strip corrosion etc.) are shown in Table 4. 
Physical properties of biodiesel were compared 
with standard biodiesel properties. All of the 
measured values were in the range of standard 
biodiesel values except the FFA content which was 
found higher in the biodiesel prepared by three-step 
method. But as the copper strip corrosion test 
showed non corrosive nature of the biodiesel, it can 
be safely used in the diesel engine. 
 
0 20 40 60 80 100 120
0
20
40
60
80
100
FF
A 
w
t%
T ime (min)
 60 0C 
 50 0C 
 40 0C 
 30 0C 
 
Fig. 3.5: Effect of tTemperature on esterification 
reaction for nahor oil [FFA / methanol ratio 1:6, 
Catalyst (HCl) 5.0% wt of FFA, vigorous stirring, 
Reaction time 120 min] 
 
 
4.     CONCLUSION: 
 
Biodiesel has been prepared from nahor oil and 
rubber seed oil by acid catalyzed transesterification 
reaction, two-step method and three-step methods. 
Among these methods tranesterification is best 
because it requires fewer amounts of equipment and 
investment. But base catalyzed tranesterification is 
not used for the preparation of biodiesel from 
Nahor and Rubber seed oil because of their high 
FFA content. Acid catalysed transesterification 
reaction was done for the preparation  of biodiesel 
from both nahor oil and Rubber Seed oil. The 
viscosity of oil reduces from 58.06 mm2/s to 14.55 
mm2/s and FFA reduces 12.17% to 2.12%  for 
Nahor Oil and 33 mm2/s to 12.00 mm2/s and FFA 
45% to 8.5%  for Rubber Seed Oil after 18 h of 
reaction. The product was not used as biodiesel 
because of its higher viscosity and FFA and the 
process was time consuming. Acid catalysed two-
step method was performed for the preparation of 
biodiesel   from both oil. The viscosity of Nahor oil 
reduces from 58.06 mm2/s to 9.64 mm2/s which was 
slightly higher than biodiesel standard. FFA of the 
oil reduces from 12.17% to 0.64% and for Rubber 
Seed oil Viscosity changes from 33 mm2/s to 14.5 
mm2/s and FFA 45% to 6.2% . 
Three-step method, where FFA was produced by 
saponification and acidification of oil and threafter 
Biodiesel was produced by esterification of FFA, 
showed comparable biodiesel properties and similar 
optimum conditions for both oil. Hence three-step 
method can be used for biodiesel production from 
nonedible mixed feed stocks. 
Biodiesel properties was measured by standard 
methods and compared with the standard biodiesel 
properties. 
Page 261
 
 
 
 
 
Table 4: Properties of biodiesel produced by three- 
step method 
 
5. ACKNOWLEDGEMENT 
 
The financial support from the research grant of 
University Grants Commission (UGC) of 
Bangladesh for conducting this research work and 
ERL for providing their facility for biodiesel 
properties measurement.  
 
5. REFERENCES: 
 
1. De B.K. and Bhattacharyya, Biodiesel from 
minor vegetable oils like karanja oil and nahor 
oil, Wiley-VCH Verlag GmbH, D-69451 
Weinheim, 1999 pp. 404-406. 
2.  Demirbas A (2007b) Importance of biodiesel as 
transportation fuel. Energy Policy 35:4661–
4670 
3. Directive 2009/28/EC of the Parliament and of 
the Council on the promotion of the use of 
energy from renewable sources and amending 
and subsequently repealing Directives 
2001/77/EC and 2003/30/EC, Brussels, 23 April 
2009. 
4. Freedman B, Pryde EH, Mounts TL. Variables 
affecting the yields of fatty esters from 
transesterified vegetable oils. JAOCS 
1984;61(10):1638–43. 
5.  Islam Md. Wahidul, Islam Mohammed 
Rafiquel, Khan Maksudur R., Islam M. A., 
Mozumder M. S. I., Siddiqee M N., Rahman 
Mustafizur, A three-step process for biodiesel 
production from vegetable oil, Proceedings of 
the international conference on chemical 
engineering 2008; 130-134. 
6. Jeffery GH, Bassett J, Mendham J, Denney RC, 
Vogel’s Textbook of Quantitative Chemical 
Analysis, 5th ed., Longman Scientific and 
Technical; UK 1991: 308-309. 
7. Ma, F., Hanna, M.A., 1999. Biodiesel 
production: a review. Bioresource Technology 
70, 1–15. 
8. M. Balat, Havva Balat, A critical review of 
biodiesel as a vehicular fuel. Energy Conv Mgmt 
2008; 49: 2727-41.]. 
9. M.M. Gui, K.T. Lee, S. Bhatia, Feasibility of 
edible oil vs. non-edible oil vs. waste edible oil 
as biodiesel feedstock, Energy 33 (2008) 1646– 
1653 
10. Morshed Mahbub, Khan Maksudur R., Islam M. 
A., Mazumder Salatul I., Uddin Md. T., Hossain 
Md. Z., Rubber seed oil as a potential source for 
biodiesel production: Bangladesh perspective, 
Proceedings of the international conference on 
chemical engineering 2008; 193-197. 
11. Official Methods and Recommended Practices 
of the American Oil Chemists’ Society, 5th ed, , 
AOCS Press, Champaign; 1998. 
12. Ramadhas AS, Jayaraj S, Muraleedharan C. 
Biodiesel production from high FFA rubber 
seed oil. Fuel 2005;84:335–40 
13. Vicente Gemma, Martinez Mercedes, Aracil 
Jose. Integrated biodiesel production: a 
comparison of different homogeneous catalysts 
systems. Bioresour Technology 2004;92:297–
305 
14. Zullaikah Siti, Lai Chao-Chin, Vali Shaik 
Ramjan, Ju Yi-Hsu, A two-step acid-catalyzed 
process for the production of biodiesel from rice 
bran oil, Bioresource Technology 96 (2005) 
1889–1896, pp. 1889-1896 
 
Properties Biodiesel 
from 
Nahor 
oil 
Biodiesel 
from 
Rubber 
seed oil 
Biodiesel 
Standard 
Value 
(Balat et. 
al) 
Density at 15 
0C (Kg/L) 
0.89 0.85 0.878 
Cetane Index 
(Calculated) 
45.4 46.5 - 
Pour point 
(C) 
9 6 -15 to 10 
Copper Strip 
Corrosion ( 3 
hours at 100 
0C) 
Non 
corrosive 
Non 
corrosive 
Non 
corrosive 
Flash point 
(C) 
162 120 100-170 
Fire point 
(C) 
200 180 - 
Kinematic 
Viscosity 
(mm2/s) at 
38C 
6.64 4.5 1.9-6.0 
FFA wt% 2.80 1.85 Trace 
Water 
content, % 
vol. 
0.10 0.08 0.05 
Calorific 
value (Gross 
Kcal/Kg) 
9364 8520 10156 
Saponification 
value (mg 
KOH/gm oil) 
204.7 202.3 - 
Iodiene value 81.29 75.2 - 
Free glycerol, 
% wt. 
Nil Nil 0.02 
max. 
Total 
glycerol, % 
wt. 
Nil Nil 0.24 
max. 
Page 262
* Corresponding Author: Rafiad Islam 
E-mail: rafiadbmb06@yahoo.com 
CRISPR MAY GIVE IMPORTANT INFORMATON WHICH CAN BE 
BENEFICIAL   IN   MOLECULAR   BIOLOGY AND 
BIOTECHNOLOGY STUDY. 
 
       
Rafiad Islam* 
University of Dhaka, Bangladesh 
 
 
CRISPRs (Clustered Regularly Interspaced Short Palindromic Repeats) are sites containing multiple short 
direct repeats found in the genomes of approximately 40% of bacteria and 90% of archaea.CRISPR 
functions as a prokaryotic immune system, in that it confers resistance to exogenous genetic elements, such 
as plasmids and phage. Here I found some interesting and important information by searching the CRISPR 
database (http://crispr.u-psud.fr/crispr/).I found high CRISPR ratio in thermo stable bacteria which may 
confer resistance from heat by these CRISPRs and some CRISPR found in plasmid DNA of bacteria which 
confer transformation to other bacteria, we can use these as a medium of transfer resistance to other bacteria 
which is needed in different biological process. I also found some info about different species of bacteria 
which have high CRISPRs is pathogenic in nature. 
 
Keywords: CRISPR, Thermopile, Plasmid, Immune System, Phage 
 
1. INTRODUCTION 
 
The clusters of regularly interspaced short 
palindromic repeat (CRISPR)–based defense 
System protects many bacteria and archaea against 
invading conjugative plasmids transposable 
elements and viruses. Resistance is acquired by 
incorporating short stretches of invading DNA 
sequences in genomic CRISPR loci. These 
integrated sequences are thought to function as a 
genetic memory that prevents the host from being 
infected by viruses containing this recognition 
sequence (Fig 1). 
 
 
 
Fig 1: CRISPR possible mechanism. 
 
 
CRISPR may give some important information 
about the bacteria and archaea. How this work  
against other organism. Here different CRISPR 
related info is analyzed. 
 
This information can be used for further research 
on CRISPR and may be used in different purpose 
biotechnology. 
 
2. METHODS AND MATERIALS 
 
I access CRISPR database to do this work. The 
Web address is (http://crispr.u-psud.fr/crispr/). 
Then analyze my data. 
 
3. RESULTS 
 
I found some interesting information from CRISPR 
database. 
 
3.1 CRISPR in Clostridium genus 
Clostridium is a genus of Gram-positive bacteria, 
belonging to the Firmicutes. 
Clostridium consists of around 100 species ,Which 
include common free-living bacteria as well as 
important pathogens; there are four main species 
responsible for disease in humans: 
Page 263
ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
  
C. botulinum, an organism producing a toxin in 
food/wound that causes botulism. (Baron S et al., 
eds1996) 
 C. difficile, can overgrow other bacteria in 
the gut during antibiotic therapy and cause 
pseudomembranous colitis.( Baron S et al., 
eds.1996) 
 C. perfringens, formerly called C. welchii, 
causes a wide range of symptoms, from 
food poisoning to gas gangrene 
 C. tetani, the causative organism of 
tetanus(Baron S et al., eds,1996). The 
name derives from "of a tension", referring 
to the tension (caused by tetanus) in the 
muscles 
 C. sordellii has been linked to the deaths 
of more than a dozen women after 
childbirth 
I found almost every organism belongs to this 
genus in database have CRISPR (Fig 2). 
 
Fig 2: Different clostridium spp. is presented with 
its CRISPR 
3.2 CRISPR in plasmids: 
Mainly CRISPR is situated in chromosomal DNA 
but there are some bacteria whose plasmids have 
CRISPR in it (Table 1). 
 
 
Table 1: CRISPR in plasmid 
 
3.3 High CRISPR: 
There are different bacteria which have high 
CRISPR.Here is some description about some 
bacteria and archaea which have high CRISPR. 
1. Methanocaldococcus is a genus of the 
Methanocaldococcaceae-mesophile 
2. Pyrococcus-Pyrococcus has similar 
characteristics of other archaea such as 
Archaeoglobus, Thermoautotrophican, and 
Methanococcus in the respect that they are all 
thermopile and anaerobic. Pyrococcus differs, 
however, because it's optimal growth temperature is 
nearly 100 oC and dwells at a greater sea depth than 
the other archaea. Studying Pyrococcus helps give 
insight to possible mechanisms used to endure 
extreme environmental conditions like high 
temperatures and high pressure. 
Plasmid CRISPRs 
Rhodothermus marinus DSM 
4252     (plasmid pRMAR01) 
7 
Aquifex aeolicus VF5                               
(plasmid ece1) 
1
Azoarcus sp. EbN1                                   
(plasmid 1) 
2 
Clostridium botulinum B1 str. 
Okra  (plasmid pCLD) 
4 
Clostridium botulinum Ba4 str. 
657  (plasmid pCLJ) 
1 
Thermus thermophilus HB27                   
(plasmid pTT27) 
8
Clostridium botulinum A3 str. 
Loch Maree(plasmid pCLK) 
5 
Thermus thermophilus HB8                     
(plasmid pTT27) 
9
Clostridium botulinum B1 str. 
Okra (plasmid pCLD) 
4 
Clostridium botulinum Ba4 str. 
657  (plasmid pCLJ) 
1 
Thioalkalivibrio sp. K90mix                
(plasmid pTK9001) 
1
0
2
4
6
8
10
12
14
C.
bo
tu
lin
um
 A
 …
C
. b
ot
ul
in
um
 B
1 … C
. …
C.
kl
uy
ve
ri 
D
SM
 …
C
. p
er
fri
ng
en
s …
C
. b
ot
ul
in
um
 A
2 …
C
. b
ot
ul
in
um
 …
C.
 d
iff
ic
ile
 6
30
C.
 k
lu
yv
er
i …
C.
 te
ta
ni
 E
88
No. of CRISPR in Clostridium
Page 264
  
3. Thermobifida-Thermobifida fusca, formerly 
known as Thermomonaspora fusca, is a rod shaped; 
thermophilic organism found in decaying organic 
matter and is a major degrader of plant cell wall. 
4. Thermotogales: Thermotogales are extremely 
thermostable and therefore useful for many 
industrial processes such as in chemical and food 
industries (R. Huber et al., 2004).Thermotoga 
enzymes are known for being active at high 
temperatures.  
Table 2: High CRISPR in different bacteria and 
archaea 
 
Bacteria No  of 
CRISPR 
Methanocaldococcus:  
Methanocaldococcus fervens AG86 8  
Methanocaldococcus infernus ME 14  
Methanocaldococcus jannaschii 
DSM 2661 
20  
Methanocaldococcus sp. FS406-22 23  
Methanocaldococcus vulcanius M7  20  
Pyrococcus:  
Pyrococcus abyssi GE5 4  
Pyrococcus furiosus DSM 3638 7  
Pyrococcus horikoshii OT3 6  
Thermobifida  
Thermobifida fusca YX 14  
Thermotoga  
Thermotoga maritima MSB8 8  
Thermotoga naphthophila RKU-10 8  
Thermotoga neapolitana DSM 4359 8  
Thermotoga petrophila 8  
Thermotoga sp. RQ2 8  
 
. 
 
 
Here is a graphical representation of 
Methanocaldococcus spp and it’s CRISPR (Fig 3). 
 
 
 
Fig 3: Some Methanocaldococcus spp. is shown 
with its CRISPR 
3.4 Thermo stable bacteria also have 
CRISPRs in there sequence: 
 
The bacteria states below are thermo stable bacteria 
and all have CRISPR on its sequence (Table 3). 
 
Table 3: Thermo stable bacteria with its CRISPR 
 
Bacteria CRISPRs 
Thermincola sp. JR 7  
Thermoanaerobacter italicus Ab9 4  
Thermoanaerobacter mathranii subsp. 
mathranii str. A3 
3  
Thermoanaerobacter pseudethanolicus 
ATCC 33223 
7  
Thermoanaerobacter sp. X514 4  
Thermoanaerobacter tengcongensis 
MB4 
3  
Thermoanaerobacterium 
thermosaccharolyticum DSM 571 
5 
Thermobaculum terrenum ATCC BAA-
798 
5  
Thermobispora bispora DSM 43833 6  
Thermobifida fusca YX 14  
0
5
10
15
20
25
Page 265
  
 
 
 
 
4. DISCUSSION 
 
Clostridium is a genus of Gram-positive bacteria. 
They are obligate anaerobes capable of producing 
endospores. Here I see this highly pathogenic 
bacteria have CRISPR which may give the 
organism much protection from being attack by 
other organism. This may confer the 
pathogenicity. 
Here there are different bacteria which have 
CRISPR in their plasmid, which may use as a 
biotechnology tool. Because we can transfer this 
plasmid from one bacterium from another and 
can construct a novel bacteria which may give 
different function along with resistance against 
different phage. 
High CRISPR level gives high versatility in 
bacteria. Here seen that the bacterium gives 
protection to itself by CRISPR.  
The specific type of bacteria listed here which 
have high CRISPR mainly thermo stable. So we 
can use these bacteria in different important 
purpose where temperature does harm. 
 
 
5. CONCLUTION 
 
In conclusion it can be said that CRISPR is an 
important bioinformatics tool which can be used 
in different biotechnological application. 
 
 
REFERENCES 
 
1. Wells CL, Wilkins TD (1996). Botulism 
and Clostridium botulinum in: Baron's 
Medical Microbiology (Baron S et al., 
eds.) (4th ed.). Univ of Texas Medical 
Branch.ISBN 0-9631172-1-1. 
http://www.ncbi.nlm.nih.gov/books/bv.f
cgi?rid=mmed.section.1108 
2. Wells CL, Wilkins TD (1996). 
Antibiotic-Associated Diarrhea, 
Pseudomembranous Colitis, and 
Clostridium difficile in: Baron's Medical 
Microbiology (Baron S et al., eds.) (4th 
ed.). Univ of Texas Medical Branch. 
ISBN 0-9631172-1-1. 
3. Wells CL, Wilkins TD (1996). Tetanus 
and Clostribium tetani in: Baron's 
Medical Microbiology (Baron S et al., 
eds.) (4th ed.). Univ of Texas Medical 
Branch. ISBN 0-9631172-1-1. 
http://www.ncbi.nlm.nih.gov/books/bv.f
cgi?rid=mmed.section.1099. 
4. Huber, R., K. O. Stetter, The 
Prokaryotes: An Evolving Electronic 
Resource for the Mircobiological 
Community. 2004. Springer-Verlag New 
York, LLC. 
5. Kawarabayasi et al. 1998. Complete 
Sequence and Gene Organization of the 
Genome of a Hyper-thermophilic 
Archaebacterium, Pyrococcus horikoshii 
OT3. DNA Research 5: 55-76 
6. Valli, Eric and Diane Summers (January 
1990). "The Nest Gatherers of Tiger 
Cave" in National Geographi 
7. R. Barrangou et al., Science 315, 1709 
(2007).  
8. F. J. Mojica, C. Diez-Villasenor, J. 
Garcia-Martinez, 
9. E. Soria, J. Mol. Evol. 60, 174 (2005). 
10. C. Pourcel, G. Salvignol, G. Vergnaud, 
Microbiology 151,653 (2005). 
11. Bolotin, B. Quinquis, A. Sorokin, S. D. 
Ehrlich,Microbiology 151, 2551 (2005). 
12. J. S. Godde, A. Bickerton, J. Mol. Evol. 
62, 718 (2006). 
Bacteria CRISPRs 
Thermodesulfovibrio yellowstonii 
DSM 11347 
5  
Thermocrinis albus DSM 14484 5  
Thermomonospora curvata DSM 
43183 
15   
Thermosediminibacter oceani DSM 
16646 
6  
Thermosipho africanus TCF52B 12  
Thermosipho melanesiensis BI429 5  
Thermotoga maritima MSB8 8  
Thermotoga naphthophila RKU-10 8  
Thermotoga neapolitana DSM 4359 8  
Thermotoga petrophila 8  
Thermotoga sp. RQ2 8  
Thermus thermophilus HB27 10  
Thermus thermophilus HB8 11  
Page 266
  
13. G. W. Tyson, J. F. Banfield, Environ. 
Microbiol. 10, 200(2008). 
14. R. K. Lillestøl, P. Redder, R. A. Garrett, 
K. Brügger,Archaea 2, 59 (2006). 
15. R. Sorek, V. Kunin, P. Hugenholtz, Nat. 
Rev. Microbiol. 6,008). 
16. P. Horvath et al., J. Bacteriol. 190, 1401 
(2008). 
17. H. Deveau et al., J. Bacteriol. 190, 1390 
(2008)
 
 
 
 
 
 
 
 
 
 
Page 267
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Syeda S. Razia,  
E-mail: syedasrazia@che.buet.ac.bd 
DETERMINATION OF MASS TRANSFER COEFFICIENT: A 
LABORATORY DEMONSTRATION 
 
 
Syeda S. Razia *, B.M. S. Arifin,  Md. M. Islam and Anup Kumar 
Department of Chemical Engineering, Bangladesh University of Engineering and Technology 
(BUET), Dhaka 1000, Bangladesh 
 
A laboratory demonstration of determination of mass transfer coefficient was developed using aeration of 
water. The demonstration was designed to provide both conceptual and practical insight of the mass transfer 
process. A bubble column fitted with a sieve tray was used to carry out the experiment. The air flow rate and 
hole size of the sieve tray were varied.  Mass transfer coefficient was obtained from the initial and final 
oxygen concentrations of the aerated water. A dimensionless correlation for mass transfer coefficient in 
terms of the experimental variables was developed by dimensional analysis and regression of the 
experimental data. 
 
Key words: Mass transfer coefficient; aeration; bubble column; dimensional analysis; Stanton number 
 
1. INTRODUCTION 
 
Although diffusional mass transfer is of common 
interest in physics, physical chemistry, biology 
etc., the concept of mass transfer coefficient is 
developed explicitly in chemical engineering. A 
chemical engineering graduate is expected not 
only to have clear understanding of the concept 
but also to be comfortable in applying it in 
diversified fields. Several mass transfer 
experiments are currently used in the unit 
operations laboratories of chemical engineering 
departments in different universities. It is 
unfortunate that undergraduate laboratories of 
chemical engineering all over the world is 
generally lacking in experimental facilities that 
demonstrates the concept of mass transfer 
coefficient adequately. A typical chemical 
engineering laboratory has either a distillation or 
an absorption column and a diffusion cell with 
membrane separator. The distillation/absorption 
column is used to demonstrate tray or packing 
efficiency and at times to exercise the column 
control. The diffusion cell, on the other hand, 
demonstrates diffusion phenomenon and 
measurement of diffusivity. The notion of mass 
transfer coefficient is missing from these 
experimental demonstrations.  
 
Therefore, efforts to build customized 
experimental set-up are going on to meet the 
requirement. A number of inexpensive and simple 
experiments in mass transfer are reported in 
articles published in Chemical Engineering 
Education.  Nirdosh and Baird (1996-2001) 
described a series of low cost experiments in 
mass transfer exploring phenomena of liquid-
liquid extraction, gas absorption, vapor diffusion 
and natural convection. Kwon et al (2002) and 
Mohammad (2000) have developed experiment to 
measure binary molecular diffusion and 
molecular diffusivity. Chawla and Pourhashemi 
(2004) reported an experimental set-up using both 
de-oxygenation and aeration to demonstrate the 
mass transfer phenomenon. 
 
In the present paper our target is to set up a 
tailored experiment for undergraduate laboratory 
that can enable students to comprehend both 
theoretical and applied side of inter-phase mass 
transfer and mass transfer coefficient. This 
involves building a simple and easy to maintain 
experimental rig for demonstrating measurement 
of mass transfer co-efficient and effect of 
different parameters on it. A basic mass transfer 
correlation is also developed using the measured 
values and a method called dimensional analysis 
as an essential part of the experiment. The 
formulation of the experiment is inspired by the 
aeration set-up suggested by Cussler (1997). 
Aeration is a frequently used industrial processe, 
particularly as fermentors and in sewage 
treatment; and is directly relevant to chemical 
engineering jobs. 
 
This paper describes the experimental set-up, 
procedure and development of the dimensionless 
correlation in detail. It also discusses the 
limitations of the demonstration. 
 
Page 268
ISBN: 978-984-33-2140-4
  
2. EXPERIMENTAL SET-UP AND 
MEASUREMENT OF MASS 
TRANSFER COEFFICIENTS 
 
The aeration process was studied by injecting air 
into water for a certain period of time and 
measuring the oxygen concentration of the water 
before and after the aeration.  A glass column of 
50.8 mm diameter and 600 mm height was built 
to carry out the aeration experiment. The column 
was fitted with a sieve tray at the bottom. A 
manometer was attached to one of the holes of the 
sieve tray to measure the clear liquid height on 
the tray. The schematic of the setup is shown in 
figure 1. At first, the column was filled with 500 
ml water. Prior to the experiment, the dissolved 
oxygen of the feed water, denoted by c10, was 
measured by a DO meter. 
 
 
 
Fig. 1: Experimental arrangement for aeration 
 
Air from a compressor was passed into the water 
through the sieve tray acting as a sparger. There is 
a 30 mm gap between the air inlet and the sieve 
tray to allow uniform distribution of air over the 
column cross sectional area. A Rota-meter was 
used to measure the air flow rate. The flow time 
was 5 minutes for each experiment. At the end of 
experiment the aerated water was collected by the 
drainage valve and concentration of dissolved 
oxygen of the water, denoted by c1f, was 
measured. The experiments were carried out at 
atmospheric condition (at 290C and 1 atm).  Table 
1 summarizes different parameters of the 
experiment. 
 
A mass balance on the aerated water was done to 
get the expression for mass transfer coefficient; 
 1,111 cckANdt
dVc
sat      (1) 
   1,11,11 cckaccV
Ak
dt
dc
satsat                (1a) 
Here, A is the interfacial area of mass transfer i.e. 
total bubble ares, z is the clear liquid height, k is 
the mass transfer coefficient, a is the total bubble 
area per unit volume of liquid, c1 is the 
concentration of the dissolved oxygen in water 
and c1,sat  is the saturated concentration of the 
dissolved oxygen in water at atmospheric 
temperature.  
 
The boundary conditions for equation (1) are  
at t = 0 c1=c10 and  
at t = 5 min c1=c1f                
         
By integrating equation (1) between the 
boundaries we get 
 








fc
c sat
cc
dcdtka
1
10
1,1
1
5
0
      (2) 












10,1
1,1ln
5
1
cc
cc
ka
sat
fsat      (3) 
In present study different air velocities and sieve 
trays with different hole sizes were used and 
corresponding ka were calculated from c10 and c1f 
data using equation (3). 
 
Table 1.  Experimental conditions for aeration 
 
Diameter of the bubble 
column 
50.8 mm 
Volume of each solution 500 ml 
Diameter of single orifice 3, 3.5 and 4 mm 
Number of orifices 20 
Air flow rate 4,6,8,10 and 12 
lit/min 
Aeration time 5 min 
Initial oxygen content of  the 
feed water 
2.85 mg/lit at 
250C 
Oxygen content of saturated 
water 
8.38 mg/lit at 
250C 
 
 
For better result, k and a should be measured 
independently. The product of ka is measured to 
avoid the uncertainty and difficulties arise in 
individual measurement of k and a. 
 
3.   DEVELOPMENT OF 
DIMENSIONLESS CORRELATION 
 
The method dimensional analysis is frequently 
used in describing transport phenomena, i.e. mass 
transfer, momentum transfer, heat transfer etc and 
a useful tool for engineers in general.  Mass 
transfer modeling is traditionally done by 
Page 269
  
dimensional analysis. The accuracy of a 
dimensional analysis is dependent on proper 
identification of the factors affecting the 
phenomenon. In this demonstration the main 
experimental variables are bubble velocity, v, 
bubble diameter, d, liquid density, ρ, liquid 
height, z and viscosity, µ. Thus, ka can be 
expressed as a function of five factors  
 
           ka= ka (v, ρ, µ, d, z)                                (4) 
The function is assumed to have the following 
form 
          ka =  C vα ρβ µγ dδ z                               (5) 
 
Here, the constant C and the exponents α, β, γ, δ 
and   are dimensionless.   
 
From dimensionless analysis the following 
equation is obtained  
   
 

















d
zdvC
v
kad
               (6)   
The left hand side of equation (6) is a type of 
Stanton number whereas the first term in 
parentheses on the right hand side is Reynolds 
number and the second term is a measure of 
column’s depth. The next step of the correlation 
development is to determine the constant C and 
the exponents γ and  . By taking ln on both sides 
of equation (6) we get  
 


















d
zdvC
v
kad lnlnlnln 


     (7) 
 
In this demonstration the bubble diameter is 
considered to be independent of velocity. 
Therefore, if the sieve tray is kept fixed and air 
flow rates were varied, the plot of 





v
kadln vs







dvln  will produce a straight line with slope -
γ and intercept 












d
zC lnln  .   
Furthermore, equation (7) can be rearranged to 
get the value of   as follows 
 



























d
zCdv
v
kad lnlnln 



      (8) 
 
According to equation (8), a plot of 






















dv
v
kadln  against 





d
zln will form a 
straight line with slope   and intercept lnC. 
4. DETERMINATION OF THE 
EXPONENTS AND THE CONSTANT 
 
In order to determine the exponents and constant 
C, aeration was done with sieve trays of three 
hole sizes and five air flow rates. The ka values 
were estimated with the initial and final 
concentrations of oxygen of the aerated water 
using equation (1). Table 2 presents the calculated 
values of ka for different runs.   
 
Table 2. ka values for different operating 
conditions 
 
Hole 
diameter 
(mm) 
Air flow rate 
(lit/min) 
ka (s-1) 
3 
4 2.0833×10
-3 
6 2.1631×10
-3 
8 2.3045×10
-3 
10 2.5028×10
-3 
12 2.0721×10
-3 
3.3 
4 1.1812×10
-3 
6 1.5439×10
-3 
8 1.5824×10
-3 
10 1.8866×10
-3 
12 1.6509×10
-3 
4 
4 1.1385×10
-3 
6 1.2506×10
-3 
8 1.3215×10
-3 
10 1.3667×10
-3 
12 1.2859×10
-3 
 
The bubble diameter, d and bubble velocity, v 
were estimated by the following equations; 
 
 
3/1
27.1










gl
H
g
D
d


      (9)  
 v = 25 V1/6 + Us                                  (10) 
 
Here, Us is the superficial velocity of air, DH is 
the hole diameter of the sieve tray, V is the bubble 
Page 270
  
volume and σ is the surface tension of water. The 
parameters 





v
kad
, 






dv  were calculated 
using the ka, d and v values. Figure 2 and 3 
present the plot of 





v
kadln versus 






dvln and 























dv
v
kadln  versus 





d
zln , respectively.  
 
The linear regression lines are also shown in the 
figures. The constant and exponents of equation 
(6) obtained from the slope and intercepts of the 
regression lines are shown in Table 3. 
 
ln(dv
6.4 6.5 6.6 6.7 6.8 6.9 7.0
ln
(k
ad
/v
)
-10.70
-10.65
-10.60
-10.55
-10.50
-10.45
-10.40 lnC+ln(z/d)=-7.1601
--0.4998
Fig. 2: Plot of 





v
kadln versus 






dvln  
ln(z/d)
4.12 4.14 4.16 4.18 4.20 4.22 4.24 4.26
ln
[(k
ad
/v
)(
dv




-7.30
-7.25
-7.20
-7.15
-7.10
-7.05
-7.00
lnC = -8.3009
0.2724
 
Fig. 3: Plot of 






















dv
v
kadln versus 





d
zln  
 
 
Table 3. Exponents and constant obtained from 
regression analysis  
 
γ   C 
0.4998 0.2724 2.5×10-4 
 
 
 
5. RESULTS & DISCUSSION 
 
The experimental values of ka varied from 
1.1385×10-3 to 2.5×10-3 per sec, which are 
within the typical range of mass transfer 
coefficient in liquids. The correlation gives ka as 
a function v0.5, which is also within the 
acceptable range as the exponent to v in the 
existing correlations of ka varies from 0.2 to 0.6 
for liquid system (Cussler, 1997).  
 
In this demonstration it is also important to 
appreciate the sources of error in the 
measurement as well as the shortcomings of 
dimensional analysis. For example, low airflow 
rate leads to weeping through the sieve tray. This 
affects the measurement of liquid height, z and 
dissolved oxygen of the aerated liquid, c1f. 
Furthermore, fluctuation in air flow introduces 
error in measurement by affecting the bubble 
diameter and bubble velocity. These can be 
minimized by keeping the flow rate high enough 
to avoid weeping and by introducing an 
intermediate storage tank between the compressor 
and the air inlet to the column to stabilize the 
fluctuation of air flow. 
 
Furthermore, the variables considered in the 
dimensional analysis are not exhaustive. ka may 
vary with tank diameter, sparger shape or surface 
tension of the liquid. This will change the form of 
the correlation developed as equation (6). In this 
demonstration, the clear liquid height, z was kept 
fixed and z/d were varied by varying the hole 
diameter of the sieve tray. A better estimation 
may be obtained by varying the liquid height, z. 
Besides, equation (9) does not include effects of 
hole velocity on bubble diameter, which is not 
always the fact. Bubble diameter may be directly 
obtained by image processing instead of 
calculating from other parameters. 
 
6. CONCLUSIONS 
 
In this work, aeration of water was studied to 
demonstrate mass transfer coefficient 
measurement in the undergraduate laboratory of 
chemical engineering. The product of mass 
transfer coefficient and total bubble area per 
column volume, ka were measured 
experimentally. A correlation was developed by 
dimensional analysis to express ka in terms of the 
experimental variables. This demonstration is 
Page 271
  
unique as it offers a simple and easy to maintain 
experimental procedure at the same time provides 
both conceptual and practical understanding of 
mass transfer coefficient, its measurement and 
prediction. Lastly, the developed correlation i.e. 
equation (6a) may be used to optimize design and   
operating parameters of industrial aeration 
process. 
 
NOMENCLATURE 
 
a total bubble area per liquid volume, 
cm2/cm3 
A cross sectional area of the column, cm2 
c1 oxygen concentration  of the aerated 
water mg/cc  
c1(sat) saturation oxygen concentration of the 
water, mg/cc 
C Constant in equation (6) 
d bubble diameter, cm 
DH sieve diameter, m 
k mass transfer coefficient, cm/s 
Us superficial velocity, cm/s 
v superficial velocity of air, cm/s 
V volume of bubbles, cm3 
z clear liquid height, cm 
 
Symbols 
γ,   exponents in equation (6)  
µ viscosity, g/cm-s 
ρg density of air, g/cc 
ρl density of water, g/cc 
σ surface tension of water, g/m-s 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
REFERENCES 
 
1. Chawla, R. C. and Pourhashemi, A., (2004), 
“Mass Transfer Experiment Using 
Deoxygenation and Aeration of Water”, 
Proceedings of the 2004 American Society 
for Engineering Education Annual 
Conference & Exposition. 
2. Cussler, E. L., Diffusion Mass Transfer in 
Fluid Systems(1997), 2nd edition, Cambridge 
University Press, 248-249. 
3. Kwon, K.C., Ibrahim, T.H., Park, Y. K. and 
Simmons, C. M. (2002), Inexpensive and 
Simple Binary Molecular Diffusion 
Experiments, Chemical Engineering 
Education, Vol. 36, No.1. 
4. Mohammad, A. W.(2000),  Simple Mass 
Transfer Experiment Using Nanofiltration 
Membranes, Chemical Engineering 
Education, Vol. 34, No.3. 
5. Nirdosh, I. and Baird, M. (1996 – 2001),  
Low-Cost Experiments in Mass Transfer, 
Parts 1-8, Chemical Engineering Education, 
Vol. 30, No.1 to Vol. 35, No.3. 
 
 
 
 
 
 
 
 
Page 272
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Sohrab Rohani,  
E-mail: srohani@uwo.ca 
DEVELOPMENT OF ACIDIC MESOPOROUS HETEROGENEOUS 
CATALYST FOR THE BIODIESEL PRODUCTION FROM THE 
LIPID OF WASTEWATER SLUDGE 
 
 
Muhammad N Siddiquee, Hossein Kazemian, Sohrab Rohani* 
Department of Chemical and Biochemical Engineering, the University of Western Ontario 1151 
Richmond Street North, London, ON, N6A5B9 Canada  
 
Biodiesel, an attractive alternative to diesel fuel, is produced from renewable lipid sources via catalytic 
transesterification and/or esterification reaction. Heterogeneous acid catalysts are promising for the 
esterification-transesterification reaction to produce biodiesel from high free fatty acid containing lipid 
sources. Unlike homogeneous catalyst, these catalysts are environmentally propitious and can be easily 
recovered, regenerated and reused.  In this study, the production of biodiesel from the lipid of wastewater 
sludge was studied through usage of a mesoporous heterogeneous catalyst; namely a mesoporous ordered 
silica, SBA-15, impregnated with heteropolyacid H3PO4.12WO3.xH2O (PW12). The mesoporous material 
was synthesized following a similar procedure reported in literature (Speybroeck et al, 2009); however, a 
different silica source was used. Upon synthesizing, calcining and impregnating the SBA-15 with different 
percentage of the heteropolyacid, different analytical techniques including X-RD, BET surface analysis and 
scanning electron microscopy (SEM) were applied to characterize the prepared catalysts. Catalytic 
performances of the prepared catalysts were evaluated in a micro-reactor setup (Autoclave Engineers, 
division of Snap-tite, Inc., USA) under several different experimental conditions. The biodiesel yield for 
sample impregnated with 25% PW12 was 10.63 wt/wt% (on the basis of lipid) at temperature of 135°C, and 
pressure of 135psi for 3hours of reaction. Gas chromatograph was used to determine the yield and the 
quality of biodiesel.  
 
Keywords: Biodiesel, mesoporous heterogeneous catalyst, nano materials, zeolitic materials 
 
 
1. INTRODUCTION 
Energy is an integral part of the society and plays a 
pivotal role in its socio-economic development by 
raising the standard of living and the quality of life. 
However, the majority of energy consumed 
worldwide comes from fossil fuel sources. Fossil 
fuel sources are non-renewable, and will be 
exhausted in the near future (Shafiee et al., 2009).   
Presently, there is an urgent need for alternative 
cheap and renewable energy resources with little or 
no environmental impact.   
Extensive research is being conducted all over the 
world to produce fuels from renewable biomass. 
Biodiesel, a renewable liquid fuel produced from 
lipid sources, is one of the most attractive among 
the options explored for alternative energy sources. 
Biodiesel is a renewable, biodegradable, clean fuel. 
It provides similar energy density to petro-diesel 
and can be used in most diesel engines in pure form 
(B100) or may be blended with petroleum diesel at 
any concentration. (Revellame et al. 2010; Knothe 
et al., 2005; Vyas et al. 2010; Siddiquee and 
Rohani, 2010; Xue et al., 2006]. However, the 
biodiesel production from pure vegetable oil is a 
major economic challenge as 70% and 85% of the 
overall biodiesel production cost is associated with 
the raw-materials (Revellame et al., 2010; Haas and 
Foglia, 2005; Mondala et al., 2009).  Moreover, 
these raw-materials for biodiesel production 
compete with food materials. Alternative raw-
materials like algae, waste cooking oil, wastewater 
sludge, non-edible oil like jatropha, castor, neem, 
karanja, etc are also being used for biodiesel 
production. However, presence of large amount of 
free fatty acid (FFA) is an obstacle for biodiesel 
production from non-edible sources. 
Page 273ISBN: 978-984-33-2140-4
  
 
 
 
Fig. 1: Biodiesel production via transesterification of triglycerides  
 
Chemically, biodiesel is fatty acid alkyl ester 
commonly known as fatty acid methyl ester 
(FAME), is mainly produced transesterification 
reaction (Fig. 1) of various lipid sources with 
alcohol in the presence of a base, acid, enzyme or 
heterogeneous catalyst. Base catalyst 
transesterification is very fast compared to other 
catalysts and widely used commercially. But, base 
catalyzed process is highly sensitive to the presence 
free fatty acids (FFA) as FFA reacts with catalyst 
and form soap that consume catalyst, inhibits 
glycerol separation and facilitate emulsion 
formation during washing step (Siddiquee and 
Rohani, 2010). Acid catalyzed transterification 
requires high lipid to alcohol ratio and is slower 
than base catalyzed transesterification and 
(Demirbas, 2005). However, the main advantage of 
acid catalyst is the ability to catalyze both the 
esterification and transesterification to produce 
more biodiesel. As the presence of water can stop 
the reaction, this approach requires a water 
management technique.  
Heterogeneous catalysts have shown greater 
promise toward transesterification to obtain 
biodiesel. The commonly used heterogeneous 
catalysts are Mg/La mixed oxide, S-ZrO2 sulfated 
zirconia, KOH/Nax zeolite, Li/CaO, CaO, 
KI/Al2O3, (ZS/Si) zinc stearate immobilized on 
silicagel, KNO3/ Al2O3, SO42-/TiO2-SiO2, etc. 
Heterogeneous catalysts can be recovered 
conveniently from reaction products (Vyas et al., 
2010; Serio et al., 2008). The undesired 
saponification reactions can be avoided by using 
heterogeneous acid catalysts. This catalyst enables 
the transesterification of vegetable oils or animal 
fats with high contents of free fatty acid (FFA) 
(Garcia et al., 2008). Solid catalyst can be reused 
and provides the possibility for carrying out both 
transesterification and esterification reactions 
simultaneously (Lopez et al., 2005).  
Wastewater sludge is being considered as potential 
feedstock for biodiesel production (Pokoo-Aikins et 
al., 2010; Uggetti et al., 2009; Jarde et al. 2005). 
Lipids are usually extracted from the sludge with 
organic solvents to avoid the interference and 
subsequently, biodiesel is produced from the 
extracted lipid.  Approximately 17– 18 wt % lipids 
(on the basis of dry sludge) were extracted from 
dried sewage sludge by boiling solvent extraction 
using chloroform and toluene as solvents  of which 
65 wt % of the extracts were found to be free fatty 
acids and 7 wt % were glyceride fatty acids  and 28 
wt% were  unsaponifiable material (Boocock et al., 
1992).  Pokoo-Aikins et al. separated the free fatty 
acids (FFA), triglycerides (oils) and the solvent 
from extracted lipids from sewage sludge by using 
toluene, hexane, ethanol, and methanol and found 
the yield of FFA was 24.8 wt%, 24.9 wt%, 25.5 
wt%, 25.5 wt%, respectively. The maximum yield 
of triglyceride was 3.4 w% for all four solvents 
(Pokoo-Aikins et al., 2010). 
In this study, the production of biodiesel from the 
lipid of wastewater sludge was studied through 
usage of a mesoporous heterogeneous catalyst; 
namely a mesoporous ordered silica, SBA-15, 
impregnated with different percentage of 
heteropolyacid H3PO4.12WO3.xH2O.  
2. MATERIALS AND METHODS 
 
2.1. Materials 
P-123 and sodium bicarbonate were purchased 
from Sigma-Aldrich Inc. (St. Louise, MO, USA), 
sodium silicate was purchased from The PQ 
Corporation, USA. SuplecoTM standard 
37component FAME mix- a 37 component 
reference mixture of fatty acid methyl ester in the 
range of C4 to C24 including saturated, mono-
unsaturated and poly unsaturated FAME were 
purchased from Supleco (Bellefonte, PA, USA) and 
used to calibrate the GC for FAME analysis. 
HPLC- grade methanol and hexane were purchased 
from Caledon Laboratories Ltd. (Georgetown, ON, 
Page 274
  
Canada); sodium chloride was purchased from EM 
Science       (Gibbstone, NJ, USA); anhydrous 
sodium sulphate was purchased from BDH Inc. 
(Toronto, ON, Canada). All the chemicals were 
used without any treatment. 
 
2.2 Catalyst Preparation  
Highly ordered mesoporous silica SBA-15, which 
was used as the catalyst substrate, was synthesized 
according to the procedure described in the 
literature (Speybroeck et al., 2009) with minor 
changes of the procedure.  Briefly, 6 gram of 
triblock copolymer of Poly (ethylene glycol)-block-
poly (propylene glycol)-block-poly(ethylene 
glycol) (i.e. PEG-PPG-PEG; P-123) with average 
molecular weight of  ~5,800  was added to 180 ml 
of 2M HCl solution in a conical beaker. The 
mixture was vigorously mixed using a magnet 
stirrer at 35°C until all of the P-123 was dissolved 
(i.e. solution A). In another beaker, 15.5 g of 
sodium silicate solution (>27 wt.-% SiO2) was 
diluted to 45 ml of deionized water (i.e. solution B). 
Then, solution B was added drop-wise to the 
solution A under vigorous stirring. Mixing of the 
resultant milky mixture was continued for 10 more 
minutes before switching to the static synthesis 
conditions of ageing at 35°C for 24 h. The SBA-
15mesoporous was crystallized at 100°C for 24 h 
under static condition. The SBA-15 product was 
then cooled to ambient temperature and separated 
from supernatant by means of vacuum filter using 
appropriate filter paper, rinsed with extra amount of 
deionized water to remove unreacted silicon 
precursor, dried at 60°C in an electrical oven for 5 
h. In order to remove the organic molecules of the 
p-13 surfactant from the SBA-15 pores, the product 
was calcined at 500°C for 5 h under a controlled 
heating and cooling rate.  Schematic diagram of 
SBA-15 synthesis is illustrated in Fig. 2.  
To prepare the solid acid as heterogeneous catalysts 
for biodiesel synthesis purposes, the mesoporous 
SBA-15 was loaded with different percentage of 
dodeca-tungstophosphoric acid (i.e. 
H3PO4.12WO3.xH2O) as a super-acid (i.e. 
heteropolyacid; HPA) by means of an “incipient 
wetness” impregnation method.  To do this,  
appropriate amount of HPA (wt/wt%), which was  
corresponded to 5%, 15% and 25 % of  HPA 
loading with respect to SBA-15 support,  was 
dissolved in methanol to form a homogeneous 
solution. The HPA solution was then added the 
measured quantity of mesoporous substrate, while it 
was mixing using a magnet stirrer for 30 min. 
Later, the formed slurry was dried at 60°C and 
calcined at 170°C for 5 h under air atmosphere with 
controlled rate of heating and cooling. 
Fig. 2: General synthesis scheme for the ordered mesoporous silica SBA-15.
Page 275
  
2.3 Extraction of lipid from sludge 
The wastewater sludge, collected from Adelaide 
Pollution Control Plant, London, ON, Canada, was 
allowed to settle for 24 hours at 0°C and the 
supernatant liquid was discarded. The resulting 
sludge was then centrifuged using IEC Centra-HN 
centrifuge (International Equipment Company, 
Needham Heights, USA) for further dewatering. 
Dewatered sludge was spread on tray and put in a 
fume hood to dry under vacuum at ambient 
temperature. Dried sludge was crushed in a mortar 
and pestle, homogenized and then stored in a 
freezer prior to use. 
The lipid was extracted from dried sludge by using 
methanol as a solvent. The dried sludge was 
weighed into a round bottom flask and methanol 
was added and then the resulting mixture was 
heated to the 70°C temperature at ambient pressure.  
A magnetic stirring bar was used for mixing and the 
loss of methanol due to evaporation was minimized 
by using a condenser with water at 20°C. After 
assigned extraction time (1 h), the resulting slurry 
was immediately filtered using VWR filter paper 
(size 5.5 cm) and a Buchner funnel attached to 
vacuum. Any residual particles were removed by 
centrifuging the lipid solution. The methanol was 
removed from the resulting supernatants under 
vacuum using a Büchi Rotavapor R-200 (Büchi 
Labotechnik, Switzerland) at 45°C and then flask 
was flushed with air to remove any remaining 
methanol in the gas phase. The resulting lipid was 
stored in refrigerator prior to use.   
 
2.4 Biodiesel Production 
Biodiesel was produced by using a micro-reactor 
(Autoclave Engineers, division of Snap-tite, Inc., 
USA) facilitated with a high temperature oil 
circulator (Julabo Labortechnik GMBH, D-77960, 
and Germany). Five hundred milligram of extracted 
lipid was mixed with 100 mLof methanol and 
assigned amount of acidic mesoporous 
heterogeneous catalyst namely, SBA-15 
impregnated with different percentage of 
heteropolyacid. The resulting mixture was 
introduced into reactor and heated at 135°C 
pressure was 135 psi) and allowed to react for 3h. 
After the reaction time, the mixture was allowed to 
cool and then centrifuged using IEC Centra-HN 
centrifuge (International Equipment Company, 
Needham Heights, USA) for 10 minutes at 3000 
rpm to remove the solid materials. The supernatants 
were transferred to a separatory funnel and 50 ml of 
hexane was added to the separatory funnel and 
shaken to extract biodiesel. Extraction procedure 
was repeated 2 times. Hexane layer was passed 
through a Whatman filter paper (110 mm dia) 
containing anhydrous sodium sulphate and 
collected into a measuring flask. A 1.5 ml aliquot of 
hexane phase was pipetted into 2.0 ml Supelco 
PTFE lined capped vial (Supelco, Bellefonte, PA) 
for FAME analysis using GC. The remaining 
hexane phase was transferred to a round bottom 
flask and the solvent was removed under vacuum 
using a Büchi R205 Rotary Evaporator (Büchi 
Labotechnik, Switzerland) at 40 °C to get biodiesel. 
The yield of FAME was determined from FAME 
analysis using GC.  
2.5 FAME analysis 
Varian CP-3800 gas chromatograph (Varian Inc., 
Lake Forest, CA) equipped with FID, and a 50m x 
0.25 mm x 0.2 µm Varian CP-Wax 58 (FFAP) CB 
capillary Column (Varian Inc., Lake Forest, CA) 
was used to analyzed the FAME. Helium was used 
as a carrier gas and the sample injection volume 
was 1.0 µl with a split ratio of 80:1. The column 
flow was constant at 1.2 ml/min and column oven 
temperature was programmed to maintain at 100 °C 
for 1.0 min, increase from 100 °C to 200 °C at 15 
°C /min, then increased from 200 °C to 240 °C at 5 
°C /min, and finally maintained at 240 °C for 24 
min. The detector and injector temperature were set 
at 260 °C for the duration of the analysis.  
 
3. RESULTS AND DISCUSSION 
 
3.1Catalyst Characterization 
The as-synthesized SBA-15 was then characterized 
by means of various instrumental techniques. The 
SEM image, which is shown in Fig. 3, was taken by 
means of JSM 600F model, Joel, Japan operating at 
10 keV of acceleration voltage. SEM image of the 
fabricated mesoporous SBA-15 exhibits hexagonal 
cylinder-like morphologies, which is one of the 
typical morphologies known for this type of highly 
ordered mesoporous silica materials.  
 
Fig. 3: SEM micrograph of a calcined SBA-15 
sample 
Page 276
  
Surface area of the as-synthesized mesoporous was 
measured using a BET surface area and pore size 
analyzer (Micromeritics ASAP 2010) instrument. 
Prior to measurement of nitrogen adsorption-
desorption isotherms, the sample was degassed 
under vacuum (10-5 Torr) at 125 °C for 6 h.  BET 
surface area results for the calcined sample was 
higher than 605.2408m2/g, external surface area 
was 529.5621m²/g, and BET adsorption average 
pore diameter was 52.7748A, which are in close 
agreement with those reported in the relevant 
literatures (Speybroeck et al., 2009). 
 
3.2 FAME Analysis 
A typical GC chromatogram of biodiesel produced 
from the lipid of wastewater sludge is shown in Fig. 
4. According to the chromatogram, biodiesel 
contain mainly the methyl ester of myristic acid (C 
14:0), palmitic acid (C16:0), palmitoleic acid (C 
16:1) stearic acid (C18:0), oleic acid (C18:1) and 
linoleic acid (C 18:2). Methyl ester of palmitic acid 
(C 16:0) is present in greatest amount in the 
biodiesel produced from the extracted lipid.  These 
results are found to be in agreement with the 
findings of Mondala et. al. by the in-situ 
transesterification of primary (Mondala et al., 
2009). 
 
 
 
Fig. 4: GC chromatogram of FAME produced from 
the lipid of the wastewater sludge. 
 
Based on the chromatogram, the maximum FAME 
yield was 10.63 % (wt/wt) (on the basis of lipid) 
that was obtained for 25% PW12 at 135°C. The 
effect of PW12 loading on the lipid conversion is 
illustrated in Fig. 5. As shown in Fig. 5, biodiesel 
yield was increased by increasung the loading of 
PW12.  
 
Fig.-5: The effect of PW12 loading on biodiesel 
production from the lipid of wastewater sludge  
 
4. CONCLUSIONS 
 
The conversion of the wastewater sludge lipid to 
biodiesel was studied through usage of a 
mesoporous ordered silica, SBA-15, impregnated 
with heteropolyacid H3PO4.12WO3.xH2O (PW12). 
Different analytical techniques including scanning 
electron microscopy (SEM) and BET surface 
analysis were applied to characterize the prepared 
catalysts. The highest biodiesel yield at the 
examined conditions was 10.63 wt/wt% (on the 
basis of lipid) for the mesoporous catalyst 
impregnated with 25% PW12. Biodiesel produced 
from the lipid of wastewater sludge contain mainly 
the methyl ester of myristic acid (C 14:0), palmitic 
acid (C16:0), palmitoleic acid (C 16:1) stearic acid 
(C18:0), oleic acid (C18:1) and linoleic acid (C 
18:2). 
 
 
REFERENCES 
1. Boocok DGB, Konar SK, Leung A, Ly LD, 
Fuels and chemicals from sewage sludge: 1. 
The solvent extraction and composition of a 
lipid from raw sewage sludge. Fuel 1992; 71 
(11):  1283–1289. 
2. Cao F., Chen Y., Zhai F., Li J., Wang J., Wang 
X., Wang S., Zhu W., Biodiesel production 
from high acid value waste frying oil catalyzed 
by superacid heteropolyacid, Biotech and 
Bioengg. 2008, 101(1), 93-100. 
3. Christie W., Lipid Analysis, Bridgwater:   The 
Oily Press; 2003. 
4. Demirbas A. Biodiesel production from 
vegetable oils via catalytic and non-catalytic  
supercritical methanol transesterification 
methods. Progress in Ener and Combus Sci 
2005; 31: 466–487. 
Page 277
  
5. Dufreche S, Hernandez R, French T, Sparks D, 
Zappi M, Alley E. Extraction of lipids from 
municipal wastewater plant micro-organisms 
for production of biodiesel. J of the Am Oil   
Chem SOC 2007; 81: 181-187. 
6.  Garcia CM, Teixeira S, Marciniuk LL, 
Schuchardt U. Transesterification of soybean 
oil  catalyzed by sulfated zirconia. Biores 
Tech 2008; 99: 6608–6613. 
7. Haas MJ, Foglia TA, Alternate feed stocks and 
technologies for biodiesel production. In: 
Knothe G, Krahl  J, Gerpen JV, editors. 
Biodiesel Handbook,   Champaign, IL: A°CS 
Press; 2005, p.42–61. 
8. Jarde E, Mansuy L, Faure P. Organic markers   
in the lipidic fraction of sewage sludges. 
Water Research 2005; 39:1215-1232.  
9. Knothe G. What is biodiesel? In: Knothe G, 
Krahl J, Gerpen JV, editors. Biodiesel 
Handbook,   Champaign, IL: AOCS Press; 
2005, p. 1–3. 
10. Lopez DE, Goodwin JJG, Bruce DA, Lotero 
E.Transesterification of triacetin with 
methanol  on solid acid and base catalysts. 
App Cat A: Gen 2005; 295(2):97–105. 
11. Mondala A, Liang K, Toghiani H, Hernandez 
R, French T. Biodiesel production by in-situ  
transesterification of municipal primary and 
secondary sludges. Biores Tech 2009; 100: 
1203-1210. 
12. Montgomery DC, Runger GC, Applied 
Statistics and Probability for Engineers, 3rd 
edn, New York: John Wiley & Sons, Inc.; 
2003.   
13. Pokoo-Aikins G, Heath A, Mentzer RA, 
Mannan MS, Rogers WJ, El-Halwagi MM. A 
multi-criteria approach to screening 
alternatives for converting sewage sludge to 
biodiesel,  J of Loss Preven in the Pr°Cess 
Indus 2010; 23: 412-420. 
14. Revellame E, Hernandez R, French W, Holmes 
W, Alley E. Biodiesel from activated sludge 
through in-situ transesterification. J Chem 
Tech Biotech 2010; 85: 614-620. 
15. Serio MD, Tesser R, Pengmei L, Santacesaria 
E. Heterogeneous catalysts for biodiesel 
production. Ener Fuel 2008; 22: 207–217. 
16. Shafiee S, Topal E. When will fossil fuel 
reserves be diminished? Ener Pol 2009; 37 
(1): 181- 189. 
17. Siddiquee M.N, Rohani S; Lipid Extraction 
and Biodiesel Production from Municipal 
Sewage Sludges- A Review, Journal of 
Renewable and Sustainable Energy Review, 
June 2010 (Accepted). 
18. Speybroeck  et.al., Ordered Mesoporous Silica 
Material SBA-15: A Broad-Spectrum 
Formulation Platform for Poorly Soluble 
Drugs , Journal of Pharmaceutical Sciences, 
98(8), 2009, 2648-2658. 
19. Uggetti E., Llorens E.,  Pedescoll A., Ferrer I., 
Castellnou R., Garcia J., Sludge dewatering 
and stabilization in drying reed beds: 
Characterization of three full-scale systems in 
Catalonia, Spain, Bioresource Technology, 
2009,100, 3882–3890 . 
20. Vyas AP, Verma JL, Subrahmanyam N. A 
review on FAME production processes. Fuel   
2010; 89(1):1-9. 
21. Xue F, Zhang X, Luo H, Tan T. A new 
method for preparing raw material for 
biodiesel production. Process Biochemistry 
2006; 41: 1699–1702. 
 
 
Page 278
Dissimilar behavior of Ag modified Pt and Pd cathodes on the reduction 
mechanism of NO3– at H+–conducting solid polymer electrolyte reactor 
 
M.A. Hasnat a,*, M. Saiful Alam a  , M.A. Rashed a  , M. R. Karim a, M. H. Mahbub-ul Karim a,  
M. Machida b  
a Department of Chemistry, Graduate School of Physical Sciences, Shahajalal University of 
Science and Technology, Sylhet–3114, Bangladesh. 
b Department of Applied Chemistry and Biochemistry, Graduate School of Science and 
Technology, Kumamoto University,  2–39–1 Kurokami, Kumamoto 860–8555, Japan. 
 
*Corresponding author (M.A. Hasnat ) 
Department of Chemistry, Shahajalal University of Science and Technology, Sylhet–3114, 
Bangladesh. 
Email: mahtazim@yahoo.com, mah–che@sust.edu 
Phone/Fax (b): 88–0821–715752 
Abstract 
In this paper, the relative electrochemical and catalytic hydrogenation responses of Ag modified 
Pt and Pd cathodes, deposited on H+ conducting Nafion membrane for  NO 3– reduction, have 
been reported. Electrochemical investigation showed the order of reactivity as; Ag–Pt > Ag–Pt–
Pd > Ag–Pd. Conversely, the catalytic hydrogenation reaction showed the reactivity sequence as; 
Ag– Pd > Ag–Pt–Pd > Ag–Pt. While both of these two processes were combined in the 
electrolyte reactor, the order of reactivity was turned out to be; Ag–Pt–Pd > Ag–Pt > Ag–Pd in 
Page 279
ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
reducing nitrate ions. In the present study, reasons of such dissimilar trends of cathodic reactivity 
have been discussed. 
Key words: Nitrate reduction, Catalytic activity, Voltammetry, Electrolysis, Rate constant 
Corresponding author ( M.A. Hasnat) E–mail:   mahtazim@yahoo.com, mah–che@sust.edu 
Phone/Fax: 880–715752–251 
 
Page 280
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
 
* Corresponding Author: Maksudur R. Khan  
E-mail: mrkhancep@yahoo.com 
 
 
DOUBLE CHAMBER MICROBIAL FUEL CELL (MFC) FOR 
ELECTRICITY GENERATION 
 
 
Kallol Talukdar1, M. S. A. Amin1, Maksudur R. Khan*1, 2 
1Department of Chemical Engineering and Polymer Science, Shahjalal University of Science and 
Technology, Sylhet-3114, Bangladesh. 
2Faculty of Chemical & Natural Resources, Universiti of Malaysia Pahang,  
26300 Gambang, Kuantan, Pahang, Malaysia. 
 
E-mail: kallol.talukdar@yahoo.com; Phone No.: +8801717846205 
 
Application of Microbial Fuel Cell (MFC) as a renewable source of energy for electricity generation is a 
promising technology. In this process, electricity generation from biodegradable organic substrate is 
accompanied by wastewater treatment, which reduces the cost of industrial effluent treatment. Current 
generation in laboratory scale mediated double chamber MFC has been studied in batch mode. The MFC 
was designed and fabricated using available local materials. The main objective was to investigate the 
current generation of MFC in different operating conditions, such as – initial substrate concentration, initial 
mediator concentration, initial pH and external load. Glucose was used as substrate, an azo dye (Cibacron 
Yellow – 2G) as mediator and potassium permanganate solution as oxidant. Domestic waste water was used 
as source inoculums. Current generation, current density, change in pH, change in COD and effect of 
polarization was studied. Polarization experiments were conducted to find the maximum power density. The 
study documented a maximum power density of 2.76mW/m2 at current density of 8.17mA/m2. A maximum 
72% removal of COD is observed at optimized operating conditions.  
 
 
Key Words: Microbial Fuel Cell, Mediated MFC, Wastewater treatment, Electricity generation, COD. 
 
1. INTRODUCTION 
 
Energy conversion and environment are 
interrelated. Environmental degradation has 
become a serious problem with the increase in 
electric power generation by conventional way of 
burning fossil fuel. The recent energy crisis and 
alarming environmental pollution has reinvigorated 
interests in MFCs among academic researchers as a 
way to generate electric power or hydrogen from 
biomass without a net carbon emission into the 
ecosystem. A microbial fuel cell (MFC) is a 
bioreactor that converts chemical energy in the 
chemical bonds in organic compounds to electrical 
energy through catalytic reactions of 
microorganisms under anaerobic conditions (Z. Du 
et al., 2007). MFCs can also be used in wastewater 
treatment facilities to break down organic matters 
(Liu et al., 2003). The real interest in MFCs has 
tremendously grown in recent years, both in terms 
of number of researchers as well as the applications 
for these systems (Pant, D., et al., 2009). Moreover, 
the reported electric current output from the MFCs 
has also increased tremendously over the recent 
years. In this study, MFC has been constructed for  
 
simultaneous power generation and wastewater 
treatment. In the present study, Glucose has been 
used as substrate, an azo dye (Cibacron Yellow–
2G) as mediator and potassium permanganate 
solution as oxidant. Different experiments have 
been done to find the optimum condition for current 
generation and COD removal. Polarization 
experiments were conducted to find the maximum 
power density. 
 
2. MATERIALS & METHODS  
 
2.1. Chemicals Used in Experiments  
 
 
i. Yellow Cibacron-2G (an industrial dye which 
was supplied from a local industry) was used 
as the mediator. The IUPAC Name is 
trisodium 4-[[4-chloro-6-[(4-sulphonatophenyl) 
amino]-1,3,5-triazin-2-yl]amino]-2-[[1-(2,5-
dichloro-4-sulphonatophenyl)-4,5-dihydro-3-
methyl-5-oxo-1H-pyrazol-4-yl] azo] 
benzenesulphonate. 
ii. Anhydrous dextrose purified (MERCK, 
Germany) was used as the substrate. 
iii. Potassium Permanganate (MERCK, Germany) 
was used as the oxidant. 
Page 281
ISBN: 978-984-33-2140-4
2.2 MFC Construction & Inoculation  
 
 
Dual-chambered MFC was designed and fabricated 
in the laboratory using available local material. 
Total volume of both anode and cathode 
compartment was the same (0.5 L) and each 
chamber was provided with sample port, wire point 
inputs (top), inlet and outlet ports. 
 
A Proton Exchange Membrane (PEM) membrane 
between two straight conduits was used to connect 
the two chambers. Two 1 cm long and 0.75 cm 
diameter plastic tubes were used.   
 
Fig 1. Schematic diagram of dual-chambered 
microbial fuel cell with schematic details. 
 
 
The Proton Exchange Membrane used in the 
experiments was Nafion-212 (DuPont, Germany). 
 
Both anode and cathode electrodes were made of 
graphite Rod (length 11 cm; diameter 0.8 cm) 
obtained from local dry cell factory and were 
positioned at a distance of 2 cm on either side of the 
membrane. Each electrode had a surface area of 
28.65 sq. cm (both anode and cathode). Prior to use, 
the electrodes were soaked in de-ionized water for a 
period of 24 h. Contact between electrodes and 
copper wires was sealed with epoxy material. 
 
Yellow Cebicron-2G (YC) was used as mediator 
and Glucose as substrate in the anodic chamber of 
the MFC. The mixture of substrate, mediator and 
sludge was stored in a jar with air bubbling. 
Glucose was the nutrient for microorganism. This 
mixture was used as the original anodic inoculums. 
The sludge was collected from Sylhet City 
Corporation’s waste water drainage system. Before 
inoculation, the sludge was filtered through a sieve 
of 0.25 mm pore size to remove the impurities. The 
cells were operated in batch mode at constant 
operating temperature (30 ± 2°C) and at dark 
environment.  
 
 
2.3 MFC Operation 
 
 
 
The performance of MFC with respect to electricity 
generation from organic carbon source was 
investigated by a series of experiments. The first 
experiment was conducted to investigate the steady 
current production of the MFC. The second 
experiment was conducted to investigate the effect 
of initial substrate concentration on electricity 
generation. To do so, solution of three different 
substrate (glucose) concentrations of 300, 600 and 
900mg/L were taken with a fixed mediator (YC) 
concentration of 300mg/L. The anode chambers of 
three MFC were charged with the mixtures. The 
third experiment was conducted to investigate the 
effect of initial mediator concentration. In this 
experiment, anode chambers of three MFCs were 
filled with the mixtures of fixed concentration 
substrate (300mg/L glucose solution) and three 
different concentrations of mediator (300, 600 and 
1200mg/L YC solution). All the results were 
plotted as current density vs. time. The change in 
pH with time was also recorded. In the fourth 
experiment, voltage vs. current density and power 
density vs. current density data were recorded for 
three MFCs running with three different substrate 
and mediator concentrations. Power density curves 
were used to obtain the maximum power density by 
varying the external resistance using a resistor box. 
The fifth experiment was done to investigate the 
water treatment performance of the MFCs. The 
anode chambers were charged with different 
substrate and mediator concentrations and the 
results were expressed as % COD removal vs. time. 
In all the experiments, the oxidant and the oxidant 
concentration were kept same (200mg/L KMnO4 
solution). All the experiments were done in closed 
circuit and the current generated was expressed as 
current density vs. time. 106 external resistance 
was used in the first experiment and 10 external 
resistances were used in the second, third and 
fourth experiment. Every experiment was 
conducted at least in duplicate at constant room 
temperature (30 ± 2 oC) and the average value was 
reported for all the data. The anode chambers were 
inoculated with 15mL of sludge each time. The 
decolorization of mediator was observed regularly 
to investigate if the mediator was decomposing due 
to microbial action. 
  
 
 
Sampling 
Port 
Page 282
2.4 Analysis and Calculations  
 
2.4.1 Current density: Current was recorded with 
a fixed resistance by a precise digital multimeter. 
Then the current density (A/m2) was calculated by 
the following equation (1). 
 
 
Current Density, 
        J = I/A      (1) 
Here, I= current and A= Projected cross sectional 
area of anode 
 
2.4.2 Power Density: The voltage difference (V) 
between two points of a resistor connected with the 
anode & cathode was recorded using a precise 
multi-meter. Power density (mW/m2) was 
calculated according to the following equation (2). 
 
 
Power Density,  
              P = IV/A         (2) 
Where, I= current, V= voltage difference and A= 
projected cross-sectional area of the anode. 
 
2.4.3 COD calculation: COD of a sample can be 
calculated by the following equation: 
   
COD (as mg O2 /L) = 
଼଴଴଴(௕ି௦)௡
௦௔௠௣௟௘ ௩௢௟௨௠௘ X dilution factor 
 
Where,   b = ml FAS solution required for blank 
               s = ml FAS solution required for sample 
               n = norlarity of FAS solution 
 
 
3. RESULTS AND DISCUSSION 
 
3.1 Study the Performance of MFC 
0 20 40 60 80 100 120 140
0
4
8
12
16
20
24
Cu
rr
en
t (
m
ic
ro
A)
Time (hour)
 Fig. 2.   Performance of a MFC. Anode chamber 
contains a mixture of 300mg/L glucose and 
300mg/L YC. 200mg/L KMnO4 is used in the 
cathode chamber. Current was measured in closed 
circuit with an external resistance of 100. 
 
Performance of the MFC at an external resistance 
of 100Ω was investigated at a substrate (glucose) 
concentration of 300mg/L and mediator (YC) 
concentration of 300mg/L. 200mg/L KMnO4 is 
used in the cathode chamber. 
 
Initially current and voltage were very low which 
was observed in Fig.2., but with respect of time, it 
increased. After some time, the current started 
increasing. The current gained a highest value of 21 
µA, and it decreased with the further increment of 
time (not showed in the plot). The current showed a 
nearly steady response from 99th hour to 140th 
hour. Current production increases as the bacteria 
grows exponentially. Current production decreases 
when bacterial growth reaches stationary/decay 
phase. Other reasons may be – ohmic losses, 
metabolic losses, concentration losses, activation 
losses. 
 
 
3.2 Effect of initial Substrate (Glucose) 
concentration in MFC  
 
To explore the effect of initial substrate 
concentration in the current production of MFC, 
anode chambers of three MFCs were charged with 
three different solutions having a fixed 
concentration of mediator and variable substrate 
concentrations.  The mediator (YC) concentration 
was kept fixed at 300mg/L and the variable 
substrate (glucose) concentrations were 300, 600 
and 900mg/L. The oxidant used in the all three cells  
 
0 10 20 30 40 50 60 70 80
0.000
0.001
0.002
0.003
0.004
0.005
0.006
0.007
0.008
0.009
0.010
Time (hour)
Cu
rr
en
t D
en
si
ty
 (A
/m
2 )
 300ppm YC & 300ppm Glucose
 300ppm YC & 600ppm Glucose
 300ppm YC & 900ppm Glucose
 Fig. 3. Effect of the initial substrate concentration 
(mg/L) on the current production of MFC. 10 
external resistances were used in each cells. 
 
 
were KMnO4 and the concentrations of the oxidant 
were kept constant at 200mg/L. All the currents 
Page 283
were measured in closed circuit and the cells were 
connected with external resistance of 10. The 
cells were run for about 56hours and the 
corresponding currents were recorded with respect 
to time. The results are shown as current density vs. 
time in the Fig.3.   
 
The result shows that, the cell using 300mg/L YC 
and 300mg/L glucose at the anode chamber gave 
better current production then other two. Initially 
the current density of the 300, 600 and 900mg/L 
glucose cells were 0.0039, 0.00351 and 0.00468 
A/m2 respectively. As the time proceeds, the 
current density of the 600 and 900mg/L glucose 
cells were unsteady and showed a decreasing trend. 
But the 300mg/L glucose cell showed a steady 
current production with the increment of time.  
 
At the end of 75 hours, the current density for the 
cells containing 300, 600 and 900mg/L glucose 
were 0.00741, 0.00387 and 0.00488 A/m2 
respectively. This clearly showed that, for a fix 
mediator concentration, there is a maximum level 
of substrate concentration that can be used to 
deliver maximum current density. Beyond that 
level, the production of current falls.  
 
 
3.3 Effect of Initial Mediator (YC) 
Concentration in MFC 
 
 
 
 
 
To investigate the effect of initial mediator 
concentration in the current production of MFC, 
anode chambers of three MFCs were charged with 
three different solutions having a fixed 
concentration of substrate and variable 
concentrations of mediator.  The substrate (glucose) 
concentration was kept fixed at 300mg/L and the 
variable mediator (YC) concentrations were 300, 
600 and 1200mg/L. The oxidant used in the all 
three cells was KMnO4 and the concentrations of 
the oxidant were kept constant at 200mg/L. All the 
currents were measured in closed circuit and the 
cells were connected with external resistance of 
10. The cells were run for about 120 hours and 
the corresponding currents were recorded with 
respect to time. The results are shown as current 
density vs. time in the Fig.4.   
 
From the data it can be seen that, initial current 
density of the cells containing 300, 600 and 
1200mg/L YC were 0.0039, 0.00585 and 0.00702 
A/m2. From 80th hour, all the cells were producing 
nearly steady current. At the end of the 120 hours, 
the current densities of the three cells were 
0.00819, 0.013 and 0.01755 A/m2 respectively. 
Throughout the time of the experiment, the cell 
contained 1200mg/L YC showed better result than 
both the cell contained 300mg/L and 600mg/L YC. 
The graph clearly indicates that, for a fixed initial 
substrate concentration, the increment of mediator 
concentration increases the current production.  
 
0 20 40 60 80 100 120
0.000
0.002
0.004
0.006
0.008
0.010
0.012
0.014
0.016
0.018
0.020
Cu
rr
en
t D
en
si
ty
 (A
/m
2 )
Time (hour)
 300ppm Glucose & 300ppmYC
 300ppm Glucose & 600ppmYC
 300ppm Glucose & 1200ppmYC
 Fig.4.  Effect of the initial mediator concentration 
(mg/L) on the current production of MFC. 10 
external resistances were used in each cell. 
 
 
The reason for this behavior can be explained by 
this: the metabolic processes in microbial cells 
generate reductive species which are isolated by a 
microbial membrane. Therefore, electron transfer 
between the cells and electrode are diminutive as 
they are separated by the membrane of the cells 
(David A. Katz, 2004). The electro-active groups 
which are required for the microbial redox activity 
of enzymes are kept deep inside their prosthetic 
groups which make electrical communication 
between electrode surface and microbial cells poor. 
The poor electrical communication can be solved 
by wiring the microbial cells to the electrode 
surface using mediators. There are different ways 
for a mediator to be coupled to the microbial 
(Rabaey, K. and Verstraete, W., 2005; J.H. 
Hirschenhofer et al., 1998). The mediators are used 
to shuttle electrons between the electrode and 
intracellular bacterial space. Thus, as the 
concentration of the mediator increased, the current 
production also increased. 
 
 
3.4 Effect of Initial pH and Change in pH 
During MFC Operation  
 
The pH of feed chamber (anode chamber) affects 
both anodic microbial activities and cathodic 
reaction, and thus is a very important factor (Z. He 
et al., 2008). Fig.5. shows the change of pH at 
anode chamber with time. Three MFCs were used 
in this experiment which had a fixed concentration 
Page 284
of substrate (300mg/L glucose) and variable 
concentration of mediator (300, 600 and 1200mg/L 
YC). 200mg/L KMnO4 solution was used as 
oxidant in all three cells. The initial pH of the cells 
were 6.2, 6.0 and 5.7 respectively. The variation in 
initial pH is due to the different concentrations of 
mediator.  
0 20 40 60 80 100 120 140
4.0
4.5
5.0
5.5
6.0
6.5
7.0
pH
Time (hour)
 300ppm Glucose & 300ppm YC
 300ppm Glucose & 600ppm YC
 300ppm Glucose & 1200ppm YC
Fig.5.  Change of pH in the anode chamber with 
time. The variation of the initial pH is due to the 
different mediator concentration. 10 external 
resistances were used in each cell. 
 
 
The biological and electrochemical reactions in the 
double-chambered MFC had changed the pH of the 
anode chamber. From the plot, it can be observed 
that, the pH of the cells initially tend to decrease. 
But after reaching a lowest value, the pH of all 
three cells increased with time. Bacterial 
metabolism constantly produces weak acid 
compounds and maintains their intracellular pH (H. 
G. Schlegel, 1993), which explains the decreasing 
of pH in the first stage of the experiment. The 
increase of pH is due to proton consumption by the 
cathodic reactions (F. Zhao et al., 2006). Both 
proton consumption and generation occur at the 
same time, but a balance was established based on 
the initial pH.  
 
Comparing this pH plot with Fig.4. , it can be seen 
that, lower initial pH of the feed results higher 
current. The advantages of operating an MFC at 
low pH are the availability of protons at the cathode 
and the proton transfer process across the proton 
exchange membrane (PEM) separating the anode 
and cathode. Because of a higher driving force, the 
use of low pH at the anode side is expected to result 
in higher proton transfer rates and can alleviate 
proton limitations at the cathode. It should be noted 
that the present MFC is a batch-operated system. In 
a continuously operated MFC, the buffering effect 
via bacterial metabolism may not be as important as 
that in a batch system, because a constant flux of 
high pH solution may overwhelm the proton 
generation. 
 
 
3.5  Polarization Curve 
 
The performance of the anode, cathode, cell and 
membrane were analyzed by E-j curves. The 
voltages and potentials in an open circuit (j=0 
A/m2) indicate the maximum voltage or potential 
which is feasible under the existing experimental 
conditions. After connecting the resistor, thus 
allowing an electrical current through the system, it 
can be seen to what extent this maximum voltage or 
potential is reached. Operation at peak power 
density can cause instability in control because the 
system will have a tendency to oscillate between 
lower and higher current densities at peak. 
Operation at the higher power densities will mean 
operation at lower cell voltages or lower cell 
efficiency. 
 
In this experiment, the electrodes potential were 
measured at various current densities to investigate 
the effect of polarization on MFC operation. From 
the Fig.6., it is observed that, when the current 
density of the cells increased potential decreased. It 
can be also seen that, potential energy decreased 
with the concentration of the mediator used.  
 
Fig.7. shows the polarization curve as a function of 
current density. Power densities were measured at 
variable external resistances. Current generation in 
different resistors was observed once the maximum 
voltage was attained. From the Fig.7., maximum 
power density was recorded 2.76mW/m2 at the 
current density 8.17 mA/m2 for the cell containing 
0.000 0.004 0.008 0.012 0.016 0.020
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
V 
(v
ol
t)
Current Density (A/m2)
 300ppm Glucose & 300ppm YC
 300ppm Glucose & 600ppm YC
 300ppm Glucose & 1200ppm YC
 
Fig. 6. Polarization curve for three MFCs using 
solution of fix conc. of substrate (300 mg/L glucose) 
and different conc. of mediator (300, 600 & 
1200mg/L YC) in anode chamber and 200mg/L 
KMnO4 solution in cathode 
Page 285
 0 4 8 12 16 20
0.0
0.4
0.8
1.2
1.6
2.0
2.4
2.8
3.2
Po
w
er
 D
en
si
ty
 (m
W
/m
2 )
Current Density (mA/m2)
 300ppm Glucose & 300ppm YC
 300ppm Glucose & 600ppm YC
 300ppm Glucose & 1200ppm YC
Fig. 7. Power Density vs. current density 
polarization curve for three MFCs using solution of 
fix conc. of substrate (300 mg/L glucose) and 
different conc. of mediator (300, 600 & 1200mg/L 
YC) in anode chamber and 200mg/L KMnO4 
solution in cathode 
 
 
1200mg/L YC and 300mg/L glucose at the anode 
chamber. For 300mg/L and 600mg/L of YC, the 
maximum power densities were found to be 
2.09mW/m2 and 1.18mW/m2 for current densities 
of 7.11mA/m2 and 5.33mA/m2 respectively. 
 
At first, the power densities showed an incremental 
trend with increasing external resistance. But after 
reaching a peak value, the power densities begin to 
fall down with increasing resistance and current 
density. Current generation showed decreasing 
trend with increase in resistance and is consistent 
with the reported literature (Venkata Mohan et al, 
2006., Min et al, 2004.), which indicated a typical 
fuel cell behavior. At higher resistance used, 
relatively less power density was observed. 
Relatively less voltage drop was observed at lower 
resistance indicating less potential drop. Voltage 
stabilization was comparatively rapid at higher 
resistances studied. Effective electron discharge 
observed at lower resistances might be the probable 
reason for further potential drop and slow 
stabilization of the voltage at lower resistances. 
Oxidation of substrates by microbes was observed 
to be more at lower resistance than at higher 
resistance, where microbes donated electrons to the 
anode as the electrons were discharged in a closed 
circuit (Britannica, Liu et al. 2005.). Relatively 
lower power observed in this study might be 
because of using graphite electrode without any 
coating. 
 
 
 
3.6  Removal of COD in MFC  
 
It has been reported that microorganisms can 
convert organic matter into electricity using MFCs 
0 20 40 60 80 100 120
0
10
20
30
40
50
60
70
80
90
100
 300ppm Glucose & 300ppm YC
 300ppm Glucose & 600ppm YC
 300ppm Glucose & 1200ppm YC
%
 C
O
D 
R
em
ov
al
Time (hour)
 Fig. 8. Percent removal of COD in terms of time 
for three MFCs using solution of fix conc. of 
substrate (300 mg/L glucose) and different conc. of 
mediator (300, 600 & 1200mg/L YC) in anode 
chamber and 200mg/L KMnO4 solution in cathode 
 
 
while simultaneously accomplishing wastewater 
treatment (Venkata Mohan et al., 2008; Liu et al., 
2004). During operation, fuel cells’ anode 
chambers were continuously monitored for COD 
removal to enumerate the potential of fuel cell to 
act as wastewater treatment unit. In 120 hour 
operation, the cells showed a COD removal 
efficiency of 52%, 60% and 72% for the cells 
containing 300, 600 and 1200mg/L YC and 
300mg/L glucose respectively. So, the removal of 
COD is found to be higher for the cell which 
showed higher current density. 
 
 
4. CONCLUSION 
 Microbial Fuel cell was fabricated and 
constructed with local materials. 
 Effect of initial mediator and initial 
substrate concentration was investigated.  
 It has been found that, current generation 
of a MFC increases for a given 
concentration substrate with the increment 
of mediator concentration. 
 Effect of initial substrate concentration on 
electricity generation has been investigated 
and no specific trend was found. 
 The polarization curve was plotted for 
particular MFC. Due to the ohmic 
resistances, sharp drop in the voltage was 
Page 286
observed with the increase of the current 
density. This indicates the external 
resistances in electrode, connecting weir, 
circuit etc were dominated in the MFC 
efficiency.  
 The removal of COD is found to be higher 
for the cell which showed higher current 
density. The highest COD removal was 
found 72% for the cell containing 
1200mg/L YC and 300mg/L glucose at the 
anode chamber. 
 Maximum power density was recorded 
2.76mW/m2 at the current density 8.17 
mA/m2 for the cell containing 1200mg/L 
YC and 300mg/L glucose at the anode 
chamber. 
 Further studies are necessary for the 
implementation of MFC in practical 
uses. 
 
 
 
REFERENCES  
 
1. BritannicaOnline:  
http://www.search.eb.com/eb/article?idxref=51
245 (accessed on 01/11/2009) 
2. Dadiv A. Katz, Construction of Microscal Fuel 
Cell, 2004 
3. F. Zhao, F. Hamisch, U. Schroder, F. Scholz, 
P. Bogdanoff, I. Hermann, Challenges and 
constraints of using oxygen cathodes in 
microbial fuel cells, Environ. Sci. Technol. 40 
(2006) 5193–5199. 
4. H.G. Schlegel, General Microbiology, 7th 
ed.Cambridge University Press, Great Britain, 
1993. 
5. J.H. Hirschenhofer, D.B. Stauffer, R.R. 
Engleman, and M.G. Klett, Fuel Cell 
Handbook (Fourth Edition) 
6. Liu, H., Cheng, S. and Logan, B. E., 
Production of electricity from acetate or 
butyrate using a single-chamber microbial fuel 
cell. Environ. Sci. Technol., 2005, (39), pp-
658–662. 
7. Liu, H., Ramanarayanan, R. and Logan, B. E., 
Production of electricity during wastewater 
treatment using a single chamber microbial 
fuel cell. Environ. Sci. Technol.,2004, (38), pp-
2281-2285. 
8. Pant, D., et al. A review of the substrates used         
in microbial fuel cells (MFCs) for sustainable 
energy production. Bioresour. Technol. (2009), 
doi:10.1016/j.biortech.2009.10.017 
9. Rabaey, K. and Verstraete, W., Microbial fuel      
cells: Novel biotechnology for energy 
generation. Trends Biotechnol., 2005, 23, 291–
298. 
10. Sani, R.K., Banerjee, U.C,. Decolorization of 
triphenylmethane dyes and textile and dye-stuff 
effluent by Kurthia sp.. Enzyme Microb. 
Technol. 1999, 24, pp-433– 437. 
11. Sung Taek Oh, Trends in Microbial Fuel Cells 
for the Environmental Energy Refinery from 
Waste/Water- Journal of Department of Civil 
Engineering, University of Glasgow, UK. 
12. Venkata Mohan, S., Saravanan, R., Veer 
Raghavulu, S., Mohanakrishna, G. and Sarma, 
P. N., Bioelectricity production from 
wastewater treatment in dual chambered 
microbial fuel cell (MFC) using selectively 
enriched mixed microflora: Effect of catholyte. 
Bioresour. Technol., doi: 10-1016/j.biotech 
2006.12.026. 
13. Zhuwei Du, Haoran Li, Tingyue Gu. A state of 
the art review on microbial fuel cells: A 
promising technology for wastewater treatment 
and bioenergy, Biotechnology Advances 25 
(2007) 464–482 
14. Zhen He, Yuelong Huang, Aswin K. Manohar, 
Florian Mansfeld, 2008. Effect of electrolyte 
pH on the rate of the anodic and cathodic 
reactions in an air-cathode microbial fuel cell. 
ELESEVIER, Bioelectrochemistry 74 (2008) 
78–82 
 
Page 287
 * Corresponding Author: M.A. Hasnat,  
E-mail: mah-che@sust.edu 
 
 
EFFICIENT HYDROGEN PEROXIDE DECOMPOSITION ON 
BIMETALLIC Pt–Pd SURFACE 
 
M. Maria Rahman , M. Afsar Uddin, M.R. Karim , M.A. Hasnat 
 
Department of Chemistry, Graduate School of Physical Sciences, Shahajalal University of Science 
and Technology, Sylhet–3114, Bangladesh. 
 
ABSTRACT 
Hydrogen peroxide was efficiently decomposed on Pt–Pd surface deposited on Nafion membrane. Comparing 
the activities for the different materials, the activity for the decomposition of hydrogen peroxide was found to 
decrease in the order of Pt–Pd surface > MnO2> K2Cr2O7 > Au > Polycrstalline Pt plate. It was observed that the 
decomposition process followed bimolecular first order kinetics, which was well fitted with Eley–Rideal (L–R) 
model. The first order decomposition rate constant was 4.5×10–4s–1 and 5.4×10–4s–1 for A1 and A2 surfaces, 
respectively. The free energy of activation was evaluated as 34.0 kJmol–1over Pt–Nafion and 36.3 kJmol–1for Pd 
Nafion systems, respectively. In this paper, reason of efficient catalytic decomposition of hydrogen peroxide 
over bi-metallic Pt-Pd surface has been discussed. 
 
Key words:  Metal film, decomposition, hydrogen peroxide, efficiency, Nafion membrane. 
 
1. INTRODUCTION 
 
Hydrogen peroxide (H2O2) is a light blue liquid, to 
some extent more viscous than water and its dilute 
solution is almost colorless. It is a weak acid, has 
strong oxidizing properties and is a powerful 
bleaching agent. It is used as a disinfectant, 
antiseptic, oxidizer and in rocket as a propellant. The 
oxidizing capacity of hydrogen peroxide is so strong 
that it is considered as a highly reactive oxygen 
donating species. Its most recent intended use include 
as a fuel/propellant instead of carcinogenic 
hydrazines( Hurlbert et al.,). Hydrogen peroxide is a 
well–established source of the hydroxyl radical (•OH) 
in the so called oxidative destruction of organic 
wastes (Kwan et al.,). Many efforts have been 
directed to destroy toxic organic compounds using 
H2O2 in presence of UV and visible light (Sedlak et 
al., and Hasnat et al.,) . In the previous report, we 
discussed the role of Fenton’s reagent (Fe(II)/Fe(III) 
+H2O2), for attaining  rapid degradation of some 
organic compounds . Although nearly all of the H2O2 
was decomposed during the degradation process, 
nevertheless, it was necessary to remove the residual 
peroxide in the digest to avoid the secondary 
pollution. If the waste containing Fenton’s reagent is 
discharged to the natural aquatic systems, it may 
cause harm to the living beings due to the action of  
 
 
 
•OH radicals. By contrast, when analytical samples 
containing such oxidative materials are employed into 
sophisticated techniques like chromatography, the 
column materials might be degraded or damaged. It 
has been found that the self decomposition of 
hydrogen peroxide is fairly very slow. Therefore, 
prior to inserting the test samples through the column, 
it is necessary to remove all of the residual hydrogen 
peroxide. On top of showing destructive effects, 
hydrogen peroxide is a source of artificial oxygen. It 
is possible to be used for emergency patients and 
aquatic lives in the aquarium if a steady peroxide 
decomposing catalyst could be developed.  
Concerning the above facts, there are so many metal 
oxides have been reported in the literature for 
hydrogen peroxide decomposition (H. Zhou et al., 
Baldi et al.,) . Among them, Fe2O3, MnO2 and 
K2Cr2O7 are frequently used. Some reports have also 
been published based on noble metal (Pt and Pd) 
catalyzed decomposition of hydrogen peroxide. In 
addition, the Gold nanoparticles (Au NPs) were also 
used for, deposited directly on polymer beads, for 
H2O2 decomposition. However, because of chemical 
reactions; metal oxides are consumed proportional to 
the extent of hydrogen peroxide. This means that the 
metal oxides cannot spontaneously be regenerated 
and moreover, additional treatment is required to 
Page 288
ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
 * Corresponding Author: M.A. Hasnat,  
E-mail: mah-che@sust.edu 
 
 
avoid the secondary pollution caused by the toxic 
metal ions. Conversely, noble metals seem to show 
pitiable catalytic performance. Recently, bi–metallic 
catalysts, originated from Pt and Pd, have been 
attracted by the researchers due to their robust 
catalytic properties for numerous reactions. 
 In this report, the effects of bi–metallic catalytic 
surfaces, consists of Pt and Pd particles, on catalytic 
hydrogen peroxide decomposition have discussed. In 
order to prove the validity of using such catalyst, the 
relative decomposition efficiencies have been 
compared with other conventional peroxide 
decomposing materials.  
 
2. EXPERIMENTAL   
2.1. Preparation of catalysts  
 
The noble metal films were prepared by following the 
procedures described in the references [30-33]. Pt and 
Pd were chemically deposited on the each surface of 
the Nafion–117 membrane (DuPont, Inc.). The 
Nafion membrane was first sand blasted and dried at 
110 °C then was immersed into 200 mL water 
containing 5mg of H2[PtCl6] supplied by Walko 
Icorp. A mixed solution of 2.0 M NaBH4 and 4.0 M 
NaOH was added to the membrane–containing 
system at rate of 2.0 mL·h−1.  Meanwhile, the reaction 
mixture was heated from 35 °C at a rate of 5 °C·h−1.  
The Pt plating with an area of 2  3 cm2 per side of 
the Nafion membrane was completed within 12 h. 
Using the same procedure, Pd coated membrane was 
prepared from 10.0 mg PdCl2. Meanwhile, Gold 
particles with a 2 nm core surrounded by a 
decanethiolate monolayer shell (DT–Au2nm 
nanoparticles) were synthesized by a conventional 
synthesis protocol [34]. The Au particles (4.2 mg) 
were than deposited on a plastic formed Carbon plate 
(6 cm2) using the technique mentioned in the 
reference [35]. In the text, this catalyst has been 
designated as Au–CP. In the present research, we will 
be show the efficiency of mixed catalytic surfaces 
consisting of Pt and Pd particles. In this connection, 
two catalytic surfaces A1 (76 mol % Pt + 24 mol % 
Pd) and A2 (59 mol % Pt+ 41 mol % Pd) have been 
used for decomposition of H2O2.The deposited 
amount of metallic particles for A1 and A2 surfaces 
were 2.1 mg and 3.3 mg respectively. The 
composition of surfaces was determined by the X–ray 
florescence technique. 
 
2.2. H2O2 decomposition 
 
Standard H2O2 solution was prepared by dilution and 
its concentrations was standardized by standard 
potassium dichromate solution. The catalytic 
competence of Pt–Pd film deposited on Nafion –117 
membranes were measured with respect to H2O2 
decomposition. The reactions of H2O2 decomposition 
was carried out at room temperature and at 
atmospheric pressure. Decomposition of H2O2 by 
A1/Nafion or A2/Nafion assembly and O2 production 
were performed in a 250 ml Gas jar filled with 250 
ml volume of solution. A graduated glass burette was 
used to measure the volume of O2 at STP. Light was 
excluded by wrapping the Gas jar with aluminum 
foil. Similar, procedure was also maintained for the 
decomposition process studied by the other materials 
(MnO2 and K2Cr2O7). In each case 5.0 mg fine 
powder materials were added to the reactor to start 
the process. 
3. RESULTS AND DISCUSSION 
3.1. Surface Characterization  
 
Before applying to the catalytic reaction process, it 
was necessary to ensure the deposition of the Pt. Fig. 
1 shows the SEM (Scanning electron microscopy) 
micrograph of the Nafion surface after deposition of 
the Pt particles. 
 The relative view of the images indicates the 
deposition of Pt particles over the Nafion membrane. 
The depositions of the Pt particles were further 
confirmed by the electron probe micro analysis 
(EPMA) of the Pt–Nafion cross–section as shown in 
Fig. 2.  
The dotted colored points clearly indicate the 
deposition of Pt particles over the Nafion surface. 
The average thickness of the metal deposits was 
estimated to be ca. 2 µm over the Nafion membrane. 
An ordinary Pt surface has several crystalline phases 
(100,110, 111 etc).  Fig. 3 shows the XRD pattern of 
the as prepared A1–Nafion assembly. The clear peaks 
at 2 values 39.1 and 48 indicate 110 and 200 planes 
caused due to the formation of Pt–Pd film over 
Nafion surface. Estimating the intensity of the peaks, 
                        
                               
 
Fig.1. SEM (Scannaing electron 
microscopic) image of the after deposition 
of Pt–Pd particles. 
Page 289
 * Corresponding Author: M.A. Hasnat,  
E-mail: mah-che@sust.edu 
 
 
it is apparent that the Pt–Pd particles, in A1, showed 
110 planes as the major component on the surface.  
 
3.2. Catalytic efficiency  
 
Fig. 4 shows the evolved O2 versus time profile due 
to decomposition of H2O2 using conventional 
materials and using the as prepared Pt–Pd (A1 and A2 
surfaces) and Au films. From the tangents of the 
curves, the normalized initial reaction rates were 
evaluated, which are reported  
in Table 1. The decomposition efficiency of different 
materials for hydrogen peroxide destruction followed 
the order of A1 > A2 > MnO2> K2Cr2O7 > Au–PC > 
commercial Pt plate.  
It is clear from the trends of the O2 evolution curves 
that the as prepared A1/ A2 assembly was prolific by 
several times for hydrogen peroxide decomposition 
compared to MnO2 and K2Cr2O7, which in turn is 
more efficient than Au–PC plate and an ordinary Pt 
plate. The reason of such elevated performance of the 
as prepared Pt – Pd films on Nafion could be 
explained by the decomposition mechanism and 
properties of the bi–metallic Pt–Pd surfaces.  
Mededovic´ et al., proposed the decomposition 
mechanism of H2O2 on Pt surface(. Mededovic et 
al.,) . 
/deg
30 40 50 60 70
In
te
ns
ity
 Fig. 3. X–ray diffraction pattern of the as 
prepared A1 (Pt–Pd) surface recorded by 2KW 
Multiflex diffractometer . 
Time,t/ 103s
0.0 2.0 4.0 6.0
Ev
ol
ve
d 
O
2 
/ 1
0-
3  
m
M
0.0
20.0
40.0
60.0
80.0
A1
A2
MnO2
K2Cr2O7
Au-PC
Pt
Fig.4. Comparisons of catalytic decomposition of 
H2O2 solution over A1(Pt–Pd; 2.1 mg)/Nafion 
assembly, A2(Pt–Pd; 3.3 mg) / Nafion assembly, 
MnO2 (50 mg), K2Cr2O7 (50 mg), Au–PC (4.2 mg) 
and Pt plate.  [H2O2] = 0.50M; Volume of the 
reactor 250 ml. Geometric surface area of catalyst 
2  
 
Fig.2. Electron probe micro analysis photograph of 
the Pt–Nafion cross–section. The upper black part 
indicates the Nafion membrane; the lower black 
part indicates the epoxy resin of the sample holder. 
The middle colored part indicates the deposited Pt 
particles. 
Table 1: Normalized decomposition rate using 
various catalysts 
 
Catalyst KMnO2 K2Cr2O7   Au-
PC 
Pt  
plate 
A1 A2 
O2 
Evolution 
rate/10–9 
mol L–1g–
1s–1 
2.8 2.1 1.2 0.91 10.0 5.4 
Rate 
constant/ 
k,10–4 s–1 
2.3 1.2 0.5 0.3 5.4 4.5 
Page 290
 * Corresponding Author: M.A. Hasnat,  
E-mail: mah-che@sust.edu 
 
 
H2 + 2Pt 2Pt–H                                               (1)               
ଵ
ଶ
O2 + Pt  Pt–O            (2) 
Pt + OH–   Pt–(OH)ads + e–          (3) 
Pt–(OH)ads + H2O2  Pt–(OOH)ads + H2O      (4) 
Pt–H + H2O2 + e–           Pt + H2O + OH –           (5) 
Pt–(OOH)ads + Pt–(H)ads         2Pt + O2 + H2      (6) 
Pt–O + 2Pt – H          Pt–H2O + 2Pt          (7) 
Pt–H2O        Pt + H2O                                        (8) 
  
The first steps in the surface catalyzed hydrogen 
peroxide decomposition are the adsorption of 
molecular hydrogen, molecular oxygen and hydroxyl 
ions. Hydrogen and oxygen are adsorbed through 
dissociative adsorption in which hydrogen and 
oxygen atoms are directly bonded to the platinum. 
Hydroxyl ions are involved in a simple charge 
transfer reaction. The surface bound species further 
react with hydrogen peroxide to form oxygen and 
water. By writing the species balance on hydrogen 
peroxide it is obvious that Pt–(OH) and Pt–(H) are 
directly involved in its decomposition kinetics. The 
concentrations of these two species are 
interdependent since both bind to free catalytic sites 
on the platinum surface. However, it has been 
reported that Pt and Pd particles become negatively 
and positively charged, respectively, when they are 
combined . Therefore, in the present case, presence of 
excessive negatively charged Pt particles in the 
assemblies of A1, A2 probably increased the 
negatively charged region within the whole surface 
area. Hence the creation of excessive negative surface 
area might have stimulated the reactions (3–5) by 
increasing the decomposition activity.  
According to Nørskov’s study the characteristics of 
d–bands of the surface metal, predominantly the 
weighted center of the d–band (εd), play a key 
function in determining surface reactivity. A higher 
lying d–band center tends to bind adsorbates more 
strongly, forming M–OH bond more easily, but it is 
unfavorable to OH formation by breaking the M–OH 
bond. On the other hand, a lower lying d–band tends 
to make easy O–H bond formation, but it binds the 
adsorbates more weakly . Therefore, the most active 
catalytic surface should have a εd with an 
intermediate value. The density functional theory 
(DFT) studies have shown that for pure Pt surface, 
Pt–OH is easily formed on the surface of Pt because 
of the higher εd of Pt. This means that a pure surface 
is favorable to accomplish reaction (3) but at the 
same time unfavorable for the reactions (4) and (5). 
But an efficient decomposition, all of these reactions 
should be taken place efficiently. 
Several studies have reported that the existence of Pd 
in the Pd–Pt catalyst could lower the εd of Pt to a 
moderate εd value. Therefore, in comparison with that 
on pure Pt surface, all the reactions (3–5) were 
probably facilitated by the bimetallic A1 and A2 
surfaces, ultimately increasing the decomposition rate 
of hydrogen peroxide. In addition of the surface 
activation, as described above, the increased surface 
area, which could be inferred from the SEM image 
(Fig. 1) of the catalytic surfaces, might be another 
reason of efficient decomposition rates by the A1 and 
A2 surfaces.  
 
3.3. Reaction Kinetics 
 
From the dependency of decomposition rate on the 
initial H2O2 concentration, the kinetics was 
investigated. Fig.5 shows the dependency of the 
oxygen evolution rate on the initial hydrogen 
peroxide concentration within the range of 0.05–
10.0M over A1–Nafion system. Up to 5.0M, the 
decomposition rate was increased linearly. Above this 
limit, constructive deviation is observed from the 
normal trend. This means that above this 
concentration limit, the number of oxygen molecules 
evolved were unexpectedly high. This can be 
explained by the enthalpy change (ΔHo) of the 
decomposition reaction. The decomposition of 
peroxide is an exothermic process over the noble 
metal surfaces although the change in temperature 
rise during the process was not significant until the 
peroxide concentration was used as higher as 3.0M. 
By measuring the temperature rise at 5.0M H2O2 
concentration, the change in ΔHo was determined to 
be – 12.45 kJmol–1 in the present case. 
 At higher temperatures, hydrogen peroxide tends to 
show auto decomposition reaction and as the 
solubility of produced oxygen gas is very low at 
higher temperature, the reaction equilibrium shifts to 
forward direction. Hence, an excessive rise in the 
reaction rate is noticed at higher temperature. 
[H2O2] / M
0.0 2.0 4.0 6.0 8.0 10.0 12.0
O
2 e
vo
lu
tio
n 
ra
te
 / 
10
-9
 m
ol
 s
-1
0.0
20.0
40.0
60.0
80.0
 
Fig.5. Dependency of O2 evolution rate on 
initial peroxide concentration (0.05 M–10 
M).Volume of the reactor 250 ml.  Geometric 
surface area of the catalyst (A1) was 12.0 cm2. 
Page 291
 * Corresponding Author: M.A. Hasnat,  
E-mail: mah-che@sust.edu 
 
 
However, the reaction rate was always proportional to 
the initial peroxide concentration indicating that Pt–
Pd surface had copious numbers of sites to 
decompose hydrogen peroxide. Since no restraining 
rate was observed within the mentioned concentration 
range, it is, therefore, suggested that the 
decomposition of H2O2 was occurred according to 
Eley–Rideal (E–R) model of surface, which was 
consistent with the reference . The rate law used for 
E–R model may be written for the decomposition of 
H2O2 as (9). 
 
                      
ݒ = ௞௄ೌ[ுమைమ]మ
ଵାଶ௄ೌ [ுమைమ]                                            (9) 
 
Where, v is the reaction rate, k the rate constant and 
Ka the adsorption equilibrium constant of H2O2 on Pt. 
At sufficiently high concentration of H2O2, 
Ka[H2O2]>>1. Therefore, equation (9) can be written 
as  
ν = 
ଵ
ଶ
 k [H2O2]               (10) 
This assumption was firmly matched with 
experimental data as shown in Fig.5. In our 
experiments, the decomposition rate was increased 
proportionally with the peroxide concentration. 
However, from the dependency of H2O2 
decomposition on concentration, it was possible to 
determine the actual reaction kinetics. The evolution 
rate of O2 is related to the initial concentration of 
H2O2 as the following rate law (eqn. (11)).  
–݀[ܪଶ ଶܱ]
݀ݐ
= ݇[ܪଶ ଶܱ]                            (11) 
where, k is the rate constant and α is the order of 
reaction. Since one molecule of H2O2 is decomposed 
into one molecule of H2O and one–half molecule of 
O2 (H2O2→ H2O+1/2 O2), equation (11) may be 
written as:  
 
݀[ ଶܱ]
݀ݐ
= 12݇[ܪଶ ଶܱ]                                            (12) 
Taking logarithm, the equation (6) may be linearized 
in the form of equation (13). 
 
݈݃݋
݀[ ଶܱ]
݀ݐ
= log൬12 ݇൰+ ݈ܪ]݃݋ଶ ଶܱ]                 (13) 
 
 From the slope of log ௗ[ைమ]
ௗ௧
 vs. ݈ܪ]݃݋ଶ ଶܱ] (Fig.6), 
order (α) of the reaction was determined as 0.91 and 
0.95 over A1 and A2 surfaces, respectively. The above 
discussion therefore, exhorts that H2O2 was 
decomposed over the noble metal films using first 
order kinetics. This conclusion is compatible with the 
nature of the evolution of the amount of O2 evolution 
as is shown in Fig. 4. The oxygen molecules evolved 
exponentially indicating that H2O2 also decayed 
exponentially as like as first order reaction. In the 
present case, the exponential relation (equation 14) 
between H2O2 concentration and time t can be 
evaluated by integrating the differential equation 
(11).  
 [ܪଶ ଶܱ] = [ܪଶ ଶܱ]௢݁ି௞௧                                  (14) 
Applying equation (14), observed rate constant k was 
estimated as 5.410–3 s–1 using A1 and 4.510–3 s–1 
using A2 surfaces.  Finally, from the dependency of 
the rate constants on temperature (Fig. 7), energy of 
the activation, Ea was calculated by applying so 
called Ahrenius equation (15).  
 
lnk = lnA–Ea/RT                                         (15) 
 
where, A = (kT /h), here k is Boltzman constant and 
h is Plank’s constant.  
log[H2O2]
-0.6 -0.4 -0.2 0.0 0.2 0.4 0.6
lo
g 
(r
at
e)
-2.3
-2.2
-2.1
-2.0
-1.9
-1.8
-1.7
-1.6
-1.5
 
Fig.6. log (rate) vs. log [H2O2] curves for 
peroxide decomposition over (●) A1 surface and 
over A2 surface (■).  
Reciprocal of Temperature /1/T x 103(K-1)
3.2 3.3 3.4 3.5 3.6 3.7
ln
(k
 /s
-1
)
-9.5
-9.0
-8.5
-8.0
-7.5
-7.0
-6.5
 
Fig.7. Arrhenius plot of lnk vs. 1/T for 
peroxide decomposition over (●) A1surface 
and over A2 surface (■). [H2O2] = 50 µM, 
volume of the reactor 250 ml. Geometric area 
of the catalytic surface 12.0 cm2.  
Page 292
 * Corresponding Author: M.A. Hasnat,  
E-mail: mah-che@sust.edu 
 
 
From this dependency Ea was calculated as 34.0 kJ 
mol–1 for A1 and 36.3 kJmol–1for A2 surfaces, 
respectively. The lower activation energy shown by 
the A1 surface indicates that Pt content determined 
the activation of the surface. 
 
3.4. Stability of the catalytic surfaces 
 
The stability of the catalytic surface is very important 
prior to its use for the realistic purposes. In order to 
check the stability, in tern of  longevity of the 
catalytic surfaces of as prepared A1 and A2 films, 10 
separate experiments (each was 2h long) were 
conducted out under same condition.  Fig.8 shows the 
O2 evolution rate for H2O2 decomposition reaction in 
presence of A1 and A2 surfaces. The first order 
decomposition rate constant was 4.5×10–4s–1 and 
5.4×10–4s–1 for A1 and A2 surfaces, respectively. In 
order to check the reproducibility, ten experiments 
were repeated. It is evident from Fig.8 that 
performance of the peroxide destruction rate constant 
was persistently invariable. In the first three 
experiments, the slight increase of the reaction rates 
might be because of surface cleaning effect due to 
removal of potential surface blocking particles 
(hydroxide, micro organics etc.). The constancy of 
the rates consequently proves that the novel metal 
films fabricated on the Nafion membrane were 
exclusively stable to decompose hydrogen peroxide 
and suitable for long term use.  
 
4. CONCLUSION 
 
Novel Pt–Pd catalyst was developed, which 
successfully could decompose H2O2 without adding 
any foreign materials. This catalyst is several times 
effective than an ordinary polycrystalline Pt surface. 
The altered electronic property and or enlarged 
surface area were the reason of enhanced catalytic 
ability. The decomposition mechanism followed 
Eley–Rideal model. Because of reproducible catalytic 
nature, the Pt–Pd catalytic surface may be used 
repeatedly for long time. Since Pt and Pd are highly 
expensive metal so considering the cost, MnO2 and 
K2Cr2O7 have to be preferred, however, 
permanganate and dichromate themselves are toxic. 
Thus, secondary contamination cannot be ignored 
after decomposition of hydrogen peroxide. But incase 
of platinum and palladium, the active form is metal 
itself, which provides active sites rather than entering 
into an oxidation–reduction scheme. Therefore, Pt–Pd 
surfaces are environmentally friendly for peroxide 
destruction.   
 
4. ACKNOWLEDGEMENT 
The authors acknowledge Prof. Masato Machida, 
Department of Nano Science and Technology, 
Kumamoto University, Japan for supplying required 
materials to prepare Pt films on Nafion membrane. 
6. REFERENCES 
Baldi, M., Finocchio, E., Pistarino, C., Busca, G., 
1998. Evaluation of the mechanism of the oxy-
dehydrogenation of propane over manganese oxide. 
Appl. Catal. A: Gen.173, 61–74. 
 
Hurlbert, E., Applewhite, J.,Nguyen, T., Reed, B., 
Baojiong, Z.,Yue,W.,1998. Nontoxic Orbital 
Maneuvering and Reaction Control Systems for 
Reusable Spacecraft.J.Propul,.Power.14(5), 676-687 . 
Hasnat, M.A., Uddin, M.M., Samed, A.J.F.,  Alam, 
S.S., Hossain, S., 2007.Adsorption and photocatalytic 
decolarization of a synthetic dye erythrosine on 
anatase TiO2 and ZnO surfaces.  J. Hazard. Mater. 
147,471–477.  
Kwan, W.P., Voelker, B.M., 2003. Rates of hydroxyl 
radical generation and organic compound oxidation in 
mineral-catalyzed Fenton-like systems. Environ. 
Sci.Technol. 37, 1150–1158. 
 
Sedlak, D.L., Andren, A.W., 1994. The effect of 
sorption on the oxidation of polychlorinated 
biphynyls (PCBs) by hydroxyl radical. Wat. Res. 28, 
1207-1215 
Zhou, H., Shen, Y.F., Wang, J.Y., Chen, X., 
O’Young, Chi-Lin, Suib, Steven L., 1998.Studies of 
decomposition of H2O2 over manganese oxide 
octahedral molecular sieve materials. J. Catal. 176, 
321–328.  
Experiment number
1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0
R
at
e 
co
ns
ta
nt
, k
 / 
10
- 4
 s
- 1
0.0
1.0
2.0
3.0
4.0
5.0
6.0
 
Fig.8. Catalytic efficiency of decomposition of 
H2O2 solution over A1 assembly (black) and A2 
assembly (grey). [H2O2] = 50 µM; Geometric 
surface area of the catalyst was 12.0 
cm2.Volume of the reactor 250 ml.  
Page 293
 
 
ELECTROCATALYTIC NO2
–
   REDUCTION USING Gc-Pt 
ELECTRODE 
M.A. Rahsed 
a
, M. Saiful Alam 
a
, M.H.M. Karim
a
, M.A.  Hasnat 
a*
 
a 
Department of Chemistry, Graduate School of Physical Sciences, Shahjalal University of Science 
and Technology, Sylhet 3114, Bangladesh. 
 
S. Hossain 
b
 
b 
Institute of Nuclear Science & Technology, Bangladesh Atomic  Energy Commission, Ganak 
Bari, Savar, GPO Box-3787, Dhaka-1000, Bangladesh. 
 
ABSTRACT 
 
Platinum particles were electrochemically deposited over glassy carbon (GC) to prepare GC –Pt electrodes. 
The electrocatalytic behaviors of this electrode have been compared with that of an ordinary 
polycrystalline(OPC) Pt and GC electrode in reducing NO2
– at neutral medium . The as prepared GC –Pt 
electrode reduced NO2
–, exhibiting double–peak reduction waves. The reduction performance of this 
electrode was noticed at least 7.8 times higher than that of an OPC Pt electrode. The sensitivity of the GC –Pt 
electrode was found to be enhanced by the temperature rise. A consecutive mechanism, NO 2
–→NO→NH4
+, 
over the as prepared GC–Pt electrode has been investigated. 
Keywords: Glassy carbon, Platinum, Nitrite, Mechanism, Efficiency. 
 
1. INTRODUCTION 
 
Drinking water, containing NO3
− > 50 ppm, is 
deleterious for health and environment (Gray, 
1994). Nitrite ions are essential precursors in the 
formation of nitrosamines, many of which have 
been recognized to be carcinogens and detrimental 
for our environment. Nitrite ions are usually used as 
food preservatives and are highly malicious to 
living bodies. Therefore, the elimination of nitrite 
from the liquid waste, foods and drinking water has 
received continued attention over the last couple of 
years (Hasnat et.al., 2009, Hasnat et. al. 2010). On 
the other hand, reduction of nitrite ions might be a 
route to synthesize numerous useful chemicals 
namely NH4
+, N2, NO, N2O, HNO2, NH2OH 
(Heckner, 1973). Direct electroreduction of nitrite 
ions requires high overpotential at most bare 
electrode surfaces (Lin and Li, 2007) . Noble metal 
nanoparticles have been extensively utilized owing 
to their extraordinary catalytic activities 
(Bonnemann et.al.,2002, El-Deab et.al., 2003) . 
Particularly, Pt nanoparticles have been attracted as 
an intensive research subject to fabrication of 
electrodes (Bard and Faulkner, 2001).  It has been  
 
 
reported by Dima et al., that the activity of a 
polycrystalline Pt electrode in reducing nitrite  
ions is very poor (Dima et al, 2003) The 
mesoporous materials, prepared by the surfactant 
template technique, have the large surface area 
(Hasnat et. al.,2008). Attard et al., reported that 
mesoporous Pt films, electro –deposited on Au from 
the mixture of octaethylene glycol monohexadecyl 
ether (C16EO8) and hexachloro platonic aci d 
H2[PtCl6],  have large surface area (Attard et. al., 
1997). Another surfactant, sodium dodecyl sulphate 
(SDS), has been proved to be an efficient 
templating reagent in chemical synthesis of large 
capacity oxygen storage mesoporous materials 
(Machida et. al., 2006). Recently, Ojani et al., 
reported a carbon paste electrode to reduce NO 2
– 
under acidic condition (Ojani et al, 2008).M. Duca 
et al., recently reported pH dependant dissimilar 
nitrite reduction mechanism at Pt electrode (Duca et 
al., 2010).  In this study, Pt modified glassy carbon 
(GC–Pt) electrode was prepared by electro –
deposition of Pt films, from a mixture of sodium 
dodecyl sulphate (C 12H25OSO3Na) and H2[PtCl6]. 
The as prepared GC–Pt electrode has been 
employed for electrocatalytic NO 2
– reduction under 
neutral pH condition.
 
Corresponding Author: M.A.Hasnat 
E-mail: mahtazim@yahoo.com
Page 294
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
CERIE-101                                                                                                                        Water pollution 
2. EXPERIMENTAL 
 
All the glassware was boiled with deionized water 
and was sonicated to remove organic and inorganic 
contaminants. Solutions were prepared with 
analytical grade chemicals (Merck, Germany.) and 
Millipore Milli–Q water (resistivity > 18 MΩcm–1 
and micro organic concentration ≤3 ppb).  The 
volumes of the solutions to be examined in each 
independent experiment were 10mL. All the 
electrochemical experiments were performed three 
times with a Metrohm 797VA automatic 
electrochemical polarization system. A KCl 
saturated Ag/AgCl electrode was used as a 
reference electrode. The auxiliary electrode was a 
4–cm2 ordinary polycrystalline (OPC) Pt plate and 
the working electrode was primarily a glassy 
carbon (GC) electrode having a geometric area of 
0.28cm2, which was then modified by depositing Pt 
particles. Prior to the surface modification, GC 
surface was cleaned smoothly by washing with 
deionized water followed by rubbing with alumina. 
Finally, the electrode was cleaned by cycling for 
10–15 times in 0.5 M sulfuric acid solution between 
0.6 and –0.6 V at 50mV s–1 scan rate. The cyclic 
voltammogram of 30 gL–1 SDS and 20gL–1 
H2[PtCl6] over GC showed Pt deposition wave at –
0.75V and 25mVs–1 scan rate (Fig. 1) . Therefore, 
the electroplating of the GC surface with Pt films 
was carried out at –0.7V for 300s using the same 
reaction mixture. The total deposition charge was 
determined to be 825 mC. This leaded formation of 
Pt films over GC surface. Before use, the as 
prepared GC–Pt electrode was rinsed with boiled 
water for several times to remove the residual SDS.  
In order to avoid interference of O2, all the 
voltammetric experiments were carried out under 
N2 atmosphere condition. The cathodic electrolysis 
was performed using a conventional cell divided by 
Nafion membrane (Walko Incorp. Japan).  The 
concentration changes of NO2
– and NH4
+ ions as a 
function of time were evaluated by ion 
chromatographic technique.  The XRD data was 
recorded using a multiflex 2KW diffractometer. 
The scanning electron microscope (SEM) image of 
the surface was taken with a JEOL model JSM–
6060LV instrument. 
 
3. RESULTS AND DISCUSSION 
 
3.1. Cyclic Voltammetry 
 
Figure 2 exhibits the comparison of the linear 
sweep voltammograms (LSVs, at a scan rate of 
10mVs–1) of 0.1M KNO2 in 0.5M KCl recorded 
using a fresh GC electrode (Fig. 2A), OPC Pt 
electrode (Fig not shown) and as prepared GC–Pt 
electrode (Fig. 2C) at 293K. No characteristic 
feature for NO2
– reduction is seen over the GC 
surface as shown in Fig. 2A. By contrast, the OPC 
Pt electrode shows a reductive wave (E1) at –0.80V 
having current density of –2.6 mAcm–2. 
Meanwhile, E1 peak is shown to be appeared at –
0.83V using the as prepared GC–Pt electrode 
having a current density of –8.1 mAcm–2. The 
experiments were repeated using variable nitrite 
concentrations. Throughout the concentration range 
(0.01–0.1M), the peak current ratio  ( JE1( GC–Pt)/ 
JE1( ord.Pt) ) was 3.0 at 293K. This observation truly 
implied that the as prepared GC–Pt electrode was 
indigenously much reactive, compared to an OPC 
Pt electrode to reduce nitrite ions.  
 
However, in order to evaluate the order of NO2
–  
 
E, V vs. Ag/AgCl
-1.0 -0.8 -0.6 -0.4 -0.2
C
u
rr
e
n
t 
d
e
n
s
it
y
, 
j 
/ 
m
A
c
m
-2
-15.0
-12.0
-9.0
-6.0
-3.0
 
Fig.1. Cyclic voltammogram of Pt deposition over 
glassy carbon from a solution of 30 gL–1 SDS + 
20gL–1 H2[PtCl6] at a scan rate of 25mVs
–1. 
 
E, V vs. Ag /AgCl
-1.4 -1.2 -1.0 -0.8 -0.6 -0.4
C
u
rr
e
n
t 
d
e
n
s
it
y
, 
j 
/ 
m
A
c
m
-2
-4.0
-3.0
-2.0
-1.0
0.0 A
 
Page 295
CERIE-101  Water pollution 
 
 
 
 
reduction at peak potential (E1), log j was plotted 
against log[NO2
–] in the concentration range as 
mentioned above. The slopes of the regression lines 
correspond to the respective order of reaction, 
which was 0.45 for OPC Pt electrode and 0.30 for 
the as prepared GC–Pt electrode, respectively. An 
interesting trait to underline is that the polarization 
curve of the GC–Pt electrode exhibited a second 
peak (E2) at –1.1V with a current density of –13.0 
mAcm–2  (Fig. 2B). This observation indicates that 
NO2
– was reduced to an electro active intermediate 
(X) at E1, which was next converted into end 
product/s (P) at E2 wave following a consecutive 
reaction pathway (1).  
 
NO2
– → X → P    (1) 
 
Figure 3 illustrates how the E1 and E2 peaks, using 
GC–Pt electrode, were dependent on the scan rate 
at 293K. The E1 peak became saturated at scan the 
rate of 50mVs–1; by contrast, the cathodic current 
associated to E2 peak was increased almost linearly 
as a function of scan rate. At all scan rates, E2 
currents were larger than that of E1. Since either of 
the GC or OPC Pt electrode did not exhibit E2 peak 
(Fig. 2), it can be inferred that E2 peak was 
originated from the synergistic influence of GC and 
Pt particles.  However, if the electro–active reactant 
was gaseous, the effect of temperature on the 
reduction wave should be less important because of 
decreased solubility. In order to elucidate the nature 
of the intermediate (X) using GC–Pt electrode, 
temperature dependant experiments were next 
carried out between 290K and 333K. The OPC Pt 
electrode increased the current density of E1 wave 
having a rate of 0.12±0.005 mAcm–2K–1 without 
affecting the position of E1 (Fig. 4A). On the 
contrary, in case of GC–Pt electrode, E1 wave was 
shifted to negative potentials as the temperature 
was raised as shown in Figure 4B. At the same 
time, the current ratio ( ) at E1 wave was amplified 
from 3.0±0.15 ( at 290K) to 9.2±0.52 (at 333K), 
confirming  the stimulated performance of GC–Pt 
at higher temperatures. Here, it is to be noted that 
the E1 wave was distinctly influenced compared to 
the E2 wave with the temperature rise. At 290K, 
current associated to E1 was lower than that of E2; 
however, after 298K, current at E1 surmounted that 
of E2. Analytically, the E1 current density was 
boosted at a rate of 1.26±0.035 mAcm–2K–1; 
conversely, E2 current density was elevated at a 
rate of 0.76±0.015 mAcm–2K–1. This fact can be 
explained by the relative mass transfer rates of the 
electro-active species. The mass transfer rate of the 
ionic species NO2
–, from the bulk to electrode 
surface, was positively influenced with the rise of  
temperature as has been reflected in the case of 
wave E1. At lower temperatures (<298K), JE1 < JE2 
implies that the intermediate X was strongly 
bonded to the electrode surface. The reverse effect 
(JE1>JE2), at higher temperatures (> 298K), suggests 
that the intermediate generated at E1 was provably 
gaseous molecules, part of which was desorbed at 
the elevated temperatures exhibiting less 
momentous increase of current density at E2. 
E, V vs. Ag/AgCl
-1.2 -1.0 -0.8 -0.6 -0.4
C
u
rr
e
n
t 
d
e
n
si
ty
, 
j 
/ 
m
A
cm
-2
-15.0
-12.0
-9.0
-6.0
-3.0
0.0
E1
E2
B
 
Fig. 2. LSV curves of 0.1M KNO2 + 0.5M KCl over 
(A) Glassy carbon electrode and (B) Nano–
structured GC–Pt electrode at  10mVs–1 and 293K. 
 
E, V vs. Ag,AgCl
-1.6 -1.4 -1.2 -1.0 -0.8 -0.6 -0.4
C
u
rr
e
n
t 
d
e
n
si
ty
, 
j /
 m
A
cm
-2
-35.0
-30.0
-25.0
-20.0
-15.0
-10.0
-5.0
0.0
E1
E2 10mVs
-1
225mVs
-1
 
Fig. 3. Dependency of peak current and peaks 
positions of 0.1M KNO2 reduction in 0.5MKCl on 
scan rate using as prepared GC–Pt electrode at 293K.  
 
Page 296
CERIE-101  Water pollution 
 
 
The appearance of E2 peak only by the GC-Pt 
electrode suggests that the gaseous intermediate (X) 
generated at E1, was most likely strongly adsorbed 
by the Pt particles in involvement of GC, which 
was consequently reduced at E2 potential. 
Meanwhile, the capability of Pt particles (on OPC 
surface) to adsorb the gaseous intermediates was 
not provably sufficient which ultimately can be 
reduced further on the same surface. This was 
might be the reason of the no-exhibition of the E2 
wave by the OPC Pt electrode. 
3.2. Rotating disk electrode 
In order to identify the electron transfer reaction at 
peak E1, we employed Pt modified GC rotating 
disk electrode. The reciprocal of peak current, i at 
E1, versus reciprocal of square root of angular 
velocity, w of the disk electrode yielded a straight 
line (Fig. 5) as per Koutecky–Levich equation (2) 
[16].  
 
 +                       (2) 
 
Where, n is the number of electron transfer, Do 
(2.0×10–5cm2s–1) the diffusion co–efficient of nitrite 
ions, ω the rotation frequency (rad/s), A the 
electrode area, F the faraday constant, iK the current 
in absence of mass transfer and Co the nitrite 
concentration. From the slope, the value of n was 
obtained to be 0.83, which indicates that single 
electron transfer reaction might have taken place at 
E1. Therefore, this observation fairly suggests that 
NO was generated at E1 due to the following 
reaction (3). 
 
NO2
– + H2O + e
– → NO + 2OH–                    (3) 
 
 
E, V vs. Ag/AgCl
-1.0 -0.9 -0.8 -0.7 -0.6 -0.5
C
u
rr
e
n
t 
d
e
n
si
ty
, 
j /
 m
A
cm
-2
-7.0
-6.0
-5.0
-4.0
-3.0
-2.0
-1.0
0.0
333K
293K
303K
313K
323K
A
 
E, V vs. Ag/AgCl
-1.4 -1.2 -1.0 -0.8 -0.6 -0.4
C
u
rr
e
n
t 
d
e
n
s
it
y
, 
j 
/ 
m
A
c
m
-2
-60.0
-50.0
-40.0
-30.0
-20.0
10.0
0.0
290K
298K
303K
309K
315K
321K
328K
333K
B
 
Fig. 4. Dependency of peak current on 
temperature for the reduction of 0.1M KNO2 in 
0.5M KCl over (A) ordinary Pt electrode and (B) 
GC– Pt electrode, at 25 mVs–1 scan rate.  
 
w
-1/2
 (rpm)
-1/2
0.005 0.010 0.015 0.020 0.025 0.030 0.035 0.040
1
/i
 (
 m
A
)-
1
0.4
0.8
1.2
1.6
2.0
2.4
 
Fig. 5. Kouteky–Levich plot for NO2
– reduction 
over GC–Pt rotating disk electrode at –
0.85V.[NO2
–] = 1.0x 10–3M, supporting 
electrolyte: 0.5M KCl, electrode area: 0.2826 cm2, 
room temperature 
Page 297
CERIE-101  Water pollution 
 
 
The literatures also support this observation. Many 
researchers reported that Pt electrode can generate 
NO adlayers during NO2
– reduction (Hasnat et.al., 
2008).  
 
3.3. Chronoamperometry 
 
Double peak chronoamperometry were next 
employed to investigate electrochemical process by 
setting the electrode potential –0.85V and –1.15V 
respectively using GC–Pt electrode. Figure 6 
represents the current transients of 0.5M KCl both 
in absence (a) and in presence (b) of 0.1M KNO2. 
In the second step, the net current due to reduction 
was larger than that was observed in the first step. 
This assessment is purely consistent with the CV 
results at room temperature as shown in Fig.2C.       
However, for an electroactive material, 
electrochemical reaction (under diffusion control) is 
described by Cottrell’s equation (4) (Bard and 
Faulkner, 2001). 
I= nFADo
–1/2C π t–1/2       (4) 
Where, C is the bulk concentration (mol cm–3), Do 
the diffusion co–efficient, n the number of electron 
transfer, F the Faraday constant, A the electrode 
area. From the plots of I vs. t–1/2 vs. t–1/2 the values 
of n was determined to be 0.91 at –0.85V, which 
literally validated the reaction (3). The value of n 
was also estimated at –1.15V assuming that all the 
NO species generated at –0.85V was electro–active 
at –1.15V. The value of n (3.8), determined for the 
second step, suggests that either NH2OH or NH3 
might be the potential end product. According to 
the method describe in literature (Galus, 1976), the 
catalytic rate constant (ko) due to heterogeneous 
electron transfer may be calculated using the 
following equation: 
 
Icat/Id = π 
1/2(ko Cot)
1/2      (5) 
 
Where, Icat is the catalytic current in presence of 
nitrite, Id is the diffusion limited current in absence 
of nitrite and t the time.  From the slopes of the 
Icat/Id vs. t
1/2 plot, the catalytic rate constant (ko) was 
calculated as 1.0×102 M–1s–1 for the process took 
place in the first step, which was raised to 4.4×102 
M–1s–1 in the second step. As mentioned previously, 
in the first step single electron transfer reaction (3) 
was identified by applying Koutecky–Levich and 
Cottrel’s equations. Therefore, the 4.4 fold charge 
transfer in the second step compared to first step, 
points that around 4–electron transfer reaction was 
involved in the second step. This means that either 
of the following reactions (6 and or 7) might have 
taken place in the second step. 
 
NO + 4H2O +5e
–→ NH3 + 5OH
–  (6) 
NO + 3H2O +3e
–→ NH2OH + 3OH
– (7) 
 
 
4. CONCLUSION 
 
The present study unveils the higher reduction 
capability of SDS templated GC–Pt electrode for 
nitrite ions. This electrode showed an apparent 
view of consecutive mechanism; NO2
–
→NO→NH4
+.  This electrode might be used for 
ammonia synthesis as well as NO2
– detection. 
 
ACKNOWLEDGEMENT 
 
The authors acknowledge the helps from Prof. I. 
Taniguchi, Prof. M. Machida and Dr. D.J. Zhang, 
Department of Nano Science and Technology, 
Kumamoto University, Japan. A special thanks to 
Dr. Rezwan Miah of Department of Chemistry, 
Shahjalal University of Science and Technology, 
Sylhet, Bangladesh for important counseling.  
 
5. REFERENCES 
 
[1]   Attard, G.S.,Bartlett, P.N., Coleman, 
N.R.B., Elliott, J.M.,  Owen, J.R. and 
Wang, J.H. (1997)  Science (weekly 
science journal),278 PP.838–840. 
[2]   Bonnemann,H.,Waldofner,N., Haubold, 
H.G., T.Vad,T., (2002), Preparation and 
Characterization of Three-Dimensional Pt 
Nanoparticle Networks, J.Chem.Mater. 14, 
PP.1115–1120. 
time, t /s
0.0 4.0 8.0 12.0 16.0 20.0 24.0 28.0 32.0
C
u
rr
e
n
t 
d
e
n
s
it
y
, 
j 
/ 
m
A
c
m
-2
-20.0
-16.0
-12.0
-8.0
-4.0
0.0
(-0.85V) (-1.15V)
(a)
(b)
 
Fig. 6. Double step chronoampergrams of 0.5M 
KCl (a) and 0.5MKCl +0.1M KNO2 at 
300K..Sampling pulse: 1ms; First and second steps 
were –0.85V and –1.15V vs. Ag/AgCl respectively.  
 
Page 298
 
 
 
[3] Bard, A.J., Faulkner, L.R.  
Electrochemical Methods (Fundamentals 
and Applications),  
Jhon Wiley and sons,  (2001), 2nd edition, 
PP.339–341 
 
[4]  Cui, H.F., Ye, J.S., Zhang, J. Wang, W.D. 
and Sheu, F.S. (2005), Electrocatalytic 
reduction of oxygen by a platinum 
nanoparticle/carbon nanotube composite 
electrode, J. Elect roanal. Chem.577 
,PP.295–302. 
 
[5] Duca,M.,  Kavvadia, V., Rodriguez, P., 
Lai,S.C.S.,  Hoogenboom, T., and  Koper, 
M.T.M.,(2010) New insights into the 
mechanism of nitrite reduction on a 
platinum electrode  J. Electroanal. Chem. 
       649, PP. 59-68. 
 
[6]  Dimia, G.E., de Vooys, A.C.E., and 
Koper, V J. (2003) Electrocatalytic 
reduction of nitrate at low concentration 
on coinage and transition-metal electrodes 
in acids   solutions. J. Electroanal. Chem. 
554–555,PP.15–23. 
 
[7]  El–Deab, M.S.,  Ohsaka, T.,(2003), 
Electrocatalysis by nanoparticles: oxygen 
reduction on gold nanoparticles-
electrodeposited platinum electrodes, J.  
Electroanal. Chem. 553, PP.107–115. 
 
 [8] Gray, N.F. Drinking Water Quality: 
Problems and Solutions’, Wiley and Sons 
Ltd (1994), Chichester pp 21 
 
[9] Galus, Z.  Fundamentals of 
Electrochemical Analysis, (1976)  Ellis 
Horwood, New York, 10 PP.3131 
 
[10] Hasnat, M.A.,  Agui, R., Hinokuma, S.,  
Yamaguchi, T., and Machida, M.(2009). 
Different reaction routes in electrolytic 
nitrate/nitrite reduction using an H+- 
conducting   solidpolymer electrolyte. 
J. Catal. Commun. 10, PP.1132–1135. 
 
[11] Hasnat, M.A.,  Ishibashi, I.,  Sato, K., 
 Yamaguchi, T.,  Ikeue, K. and  Machida, 
 M. (2008)  Electrocatalytic reduction of 
 nitrate using Cu-Pd and Cu-Pt 
 cathodes/H+- conducting solid 
 polymer electrolyte membrane  assemblies. 
 Bull. Chem. Soc. Jpn. 81, PP.1675–1680. 
 
[12]  Hasnat, M.A., Amirul Islam, M.,  
Borhanuddin, S.M.,  Ullah Chowdhury, 
M.R. and Machida, M. (2010), Influence 
of  Rh on electrocatalytic reduction 
of NO3
-  and  NO2
- over Pt and Pd 
films.J. Mol.  Catal.A 317 PP. 61–67. 
 
[13] Heckner, H.N. (1973), Potentiostatic 
switching experiments for the cathodic 
reduction of nitrous acid in perchloric acid 
with the addition of nitric acid, J. 
Electroanal. Chem., 44, PP. 9–20. 
 
[14] Lin, J. Li, X. (2007), Electrocatalytic 
 reduction of nitrite at polypyrrole 
 nanowire–platinum nanocluster modified 
 glassy carbon electrode Microchem. J. 87,   
        PP.41–46 
[15]  Machida, M., Kawamura, K.,  Kawano, T.,  
Zhang, D. and  Ikeue, K. (2006), Layered 
Pr-dodecyl sulfate mesophases as 
precursors of Pr2O2SO4 having a large 
oxygen-storage capacity,J. Mater. Chem. 
16, PP. 3084–3090 
[16]        Ojani, R.,  Raoof, J.B. and Zarei, E. 
 (2008), The effect of ultra-low  proton 
 concentration on the  electrocatalytic 
 reduction of nitrate over  platinum, J. 
 Electroanalysis , 20,PP. 379 – 385. 
. 
 
 
. 
 
 
Page 299
  
 
1
    
ENTREPRENEURIAL MANAGEMENT: AN INTERNATIONAL STUDY 
 
Dr. Mohammad Abul Hasan 
Deputy Secretary 
Additional Deputy Commissioner (Revenue), Sylhet 
Administrator, The Sylhet Chamber of Commerce & Industry, Sylhet  
  
Key words: entrepreneur, management, industry 
INTRODUCTION 
 
Entrepreneurship 
 
The word entrepreneur originates from the French word, 
entreprendre, which means "to undertake." In a business 
context, it means to start a business. The Merriam-Webster 
Dictionary presents the definition of an entrepreneur as one 
who organizes, manages, and assumes the risks of a business or 
enterprise. 
Entrepreneurship is the act of being an entrepreneur, which can 
be defined as "one who undertakes innovations, finance and 
business acumen in an effort to transform innovations into 
economic goods". This may result in new organizations or may 
be part of revitalizing mature organizations in response to a 
perceived opportunity. The most obvious form of 
entrepreneurship is that of starting new businesses however, in 
recent years, the term has been extended to include social and 
political forms of entrepreneurial activity. When 
entrepreneurship is describing activities within a firm or large 
organization it is referred to as intra-preneurship and may 
include corporate venturing, when large entities spin-off 
organizations. Entrepreneurial activities are substantially 
different depending on the type of organization that is being 
started.  
Corresponding Author: Dr. Mohammad Abul Hasan 
 E-mail: hasan1090@gmail.com 
 
Austrian economist Joseph Schumpeter’s definition of 
entrepreneurship placed an emphasis on innovation, such as: 
 new products 
 new production methods 
 new markets 
 new forms of organization 
Any entrepreneurial manager is charged with the difficult 
task of turning a business idea into reality, either through 
starting a new business or injecting new life into an existing 
one. To help them along each step of the journey – from finding 
the idea in the first place through to its planning and 
implementation – the manager can draw inspiration from the 
experiences of others who have been on similar journeys before 
them. 
As a means of entrepreneurship development, the footsteps 
of others can be followed and the entrepreneur can benefit from 
the wisdom of those who have found a route to success. 
Entrepreneurship management demands innovation, as well 
as the marriage of profitability and growth. 
History of Entrepreneurship 
The entrepreneur is a factor in microeconomics, and the study 
of entrepreneurship reaches back to the work of Richard 
Cantillon and Adam Smith in the late 17th and early 18th 
centuries, but was largely ignored theoretically until the late 
Page 300ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
  
 
2
19th and early 20th centuries and empirically until a profound 
resurgence in business and economics in the last 40 years. 
In the 20th century, the understanding of entrepreneurship owes 
much to the work of economist Joseph Schumpeter in the 1930s 
and other Austrian economists such as Carl Menger, Ludwig 
von Mises and Friedrich von Hayek. In Schumpeter, an 
entrepreneur is a person who is willing and able to convert a 
new idea or invention into a successful innovation. 
Entrepreneurship employs what Schumpeter called "the gale of 
creative destruction" to replace in whole or in part inferior 
innovations across markets and industries, simultaneously 
creating new products including new business models. In this 
way, creative destruction is largely responsible for the 
dynamism of industries and long-run economic growth.  
For Schumpeter, entrepreneurship resulted in new industries but 
also in new combinations of currently existing inputs. 
Schumpeter's initial example of this was the combination of a 
steam engine and then current wagon making technologies to 
produce the horseless carriage. In this case the innovation, the 
car, was transformational but did not require the development 
of a new technology, merely the application of existing 
technologies in a novel manner. Despite Schumpeter's early 
20th-century contributions, traditional microeconomic theory 
did not formally consider the entrepreneur in its theoretical 
frameworks (instead assuming that resources would find each 
other through a price system). In this treatment the entrepreneur 
was an implied but unspecified actor, but it is consistent with 
the concept of the entrepreneur being the agent of x-efficiency. 
Different scholars have described entrepreneurs as, among 
other things, bearing risk. For Schumpeter, the entrepreneur did 
not bear risk the capitalist did. 
For Frank H. Knight  (1921) and Peter Drucker (1970) 
entrepreneurship is about taking risk. The behavior of the 
entrepreneur reflects a kind of person willing to put his or her 
career and financial security on the line and take risks in the 
name of an idea, spending much time as well as capital on an 
uncertain venture. Knight classified three types of uncertainty. 
 Risk, which is measurable statistically (such as the 
probability of drawing a red color ball from a jar 
containing 5 red balls and 5 white balls). 
 Ambiguity, which is hard to measure statistically (such 
as the probability of drawing a red ball from a jar 
containing 5 red balls but with an unknown number of 
white balls). 
 True Uncertainty or Knightian Uncertainty, which is 
impossible to estimate or predict statistically (such as 
the probability of drawing a red ball from a jar whose 
number of red balls is unknown as well as the number 
of other colored balls). 
Management 
 
Management in all business and organizational activities is the 
act of getting people together to accomplish desired goals and 
objectives efficiently and effectively. Management comprises 
planning, organizing, staffing, leading or directing and 
controlling an organization (a group of one or more people or 
entities) or effort for the purpose of accomplishing a goal. 
Resourcing encompasses the deployment and manipulation of 
human resources, financial resources, technological resources 
and natural resources 
 Basic functions/Roles-Management operates through various 
functions, often classified as planning, organizing, staffing, 
leading/directing, and controlling/monitoring.i.e 
 Planning: Deciding what needs to happen in the future 
(today, next week, next month, next year, over the next 
5 years, etc.) and generating plans for action. 
 Organizing: (Implementation) making optimum use 
of the resources required to enable the successful 
carrying out of plans. 
 Staffing: Job analyzing, recruitment, and hiring 
individuals for appropriate jobs. 
Page 301
  
 
3
 Leading/Directing: Determining what needs to be 
done in a situation and getting people to do it. 
 Controlling/Monitoring: Checking progress against 
plans. 
 Motivation: Motivation is also a kind of basic 
function of management, because without motivation, 
employees cannot work effectively. If motivation 
doesn't take place in an organization, then employees 
may not contribute to the other functions (which are 
usually set by top level management). 
Managers vs. Entrepreneurs 
A manager is someone who directs a team and an entrepreneur 
is someone who organizes, manages, and assumes the risks of a 
business or enterprise. An entrepreneur can be a manager but a 
manager cannot be an entrepreneur. A manager is someone who 
is what is known as a micro-manager. They like to control all 
aspects of their workplace. Each person is given their assigned 
tasks and a manager will look over your shoulder until you 
finish it. An entrepreneur is generally considered a leader 
versus a manager. They will give people tasks and a deadline 
and generally leave them alone until it is completed. They will 
trust people to get the job done without having to constantly 
look over their shoulder. 
Entrepreneurship and Economic Development 
Entrepreneurship plays an important role in the economic 
development of a country. Entrepreneurship creates the forces 
of change and ultimately accelerates the pace of economic 
development. An entrepreneur introduces new ideas, 
technology and methodology for performing works and jobs in 
the country. As total production increases so as a whole, 
economic development is achieved. 
The proper utilization of human and non-human resources is 
important for economic development. Entrepreneurs extend 
help in this regard by accumulating the scattered resources and 
make them productive through new ventures. Consequently, 
industrialization boosts up both vertically and horizontally 
which ensures proper utilization of natural and other 
supplementary resources. 
Creation of employment is another important aspect of 
economic development. Entrepreneurship contributes 
substantially to employment generation. Entrepreneurs also 
promote a better skilled workforce through institutional training 
and introducing them with new technologies. 
Entrepreneurs also bring attitudinal changes. Economic 
advancement greatly depends on the level and degree of use of 
technology in production. The traditional outlooks, attitudes, 
values and behavior of the people sometimes hinder economic 
development. Entrepreneurs in any country help in this regard 
by introducing new methods and technologies in the society 
and generating them to remove narrow outlooks and attitudes of 
people. In fact, developing entrepreneurship can remove the 
narrow social outlooks and attitudes of people. 
Moreover, where entrepreneurship contributes to increase 
national income, create environment for innovation, change 
personal consumption, develop infrastructure, increase savings 
propensity and above all, change the standard of living of the 
people. 
Women Entrepreneurship and Women Development 
Women’s development all over the world is, now a day, a 
zenith of the common realization. The attainment of any 
sustainable development activities cannot be achieved without 
the full participation and integration of women in all spheres of 
life. Therefore, the institutions can play a prudential role in 
promoting women’s development through entrepreneurship. 
Considering women as an important ingredient of human 
development, a proliferation of policies, programmes and 
projects designed to help women has been evolved over the last 
couple of decades. The conceptual frame work and the 
institutionalization process of modern times “Women in 
Development (WID)” approach were familiarized from 
Page 302
  
 
4
“welfare” to “equity” (1950-1970); “equity” to “anti-poverty” 
(1970-1980); “anti-poverty” to “efficiency” (post 1980s): and 
to “empowerment” (1990 onwards). 
Since independence, Bangladesh has emphasized on women 
empowerment. Significant increase of women participation can 
be found in economic activities though it is not up to the 
optimum level. Government agencies, economists, policy 
makers, financial executives, political leaders and 
administrators now think of women empowerment in any 
development activities. It is also realized that Bangladesh needs 
to exploit economic potentialities of women as entrepreneurs. 
Now socio-economic development of Bangladesh and Women 
Entrepreneurship Development (WED) are co-existed.  
At present women are entering into trades and industries. They 
are contributing to increase their family income and playing 
important role in the family. In a modern society, women’s 
roles are not limited to the family alone. Now they are being 
essentially considered as a potential part of the work force and 
their roles in the economic development of the country cannot 
be ignored from the framework of socio-economic 
development. Their roles in this regard have enhanced their 
economic independence, ensured their empowerment in any 
field of development, and established their social status. After 
realizing this matter, the government is therefore, making 
policies and implementing various plans and programmes. 
The development efforts by GOs and NGOs could not bring any 
significant change in the quality of women’s life. There are many 
reasons behind the failure of the various ISs to WED in 
Bangladesh. This thing frustrates WEs to set up their enterprises. 
Though the supports to women by different institutions in 
developing entrepreneurship may be visualized insufficient and 
less effective, it is positive to find that women are participating in 
the labour market of Bangladesh, which is contributing to socio-
economic development, (and that) provide some qualitative 
changes in urban and rural areas. From these mentioned views, 
position of women and entrepreneurship and the relationship 
with socio-economic development could be evaluated. 
Model of Entrepreneurship 
There are different models of entrepreneurship. Those  are- 
 Behavioural Model of Entrepreneurship  
 Push’ and `Pull’ Theoretical Model of 
Entrepreneurship 
 Model of Strategic Management  
 Model of Variables Affecting the Performance of 
Entrepreneurship 
 Entrepreneurial Economic Success Index (EESI)  
 Gibb’s Small Enterprise Development Model  
 Model developed for the analysis Effectiveness of 
NGO supported Micro-enterprises  
 
Proposed Model for Assessment of Effectiveness of ISs in 
WED 
 
This model is developed focusing on the examination of the 
supports provided by the institutions for the development of 
WEs. The study was confined on particular businesses where 
the institutions supported WEs to develop.  Again, the study is 
developed that ISs should have out the performance of WEs in 
market for specific businesses. That is why WEs, ISs and SMEs 
kept in the middle of the model surrounding the development 
wheel where market performance is prime to evaluate. The 
heart of this model ‘Assessment of effectiveness of ISs in 
WED’ designated by ‘A’ is placed in a circle in the centre. The 
size and characteristics of the SMEs, WEs and ISs are shown in 
the right box (marked- B) of the centre. For the development of 
WEs, they require ISs. The requirement might be common for 
all businesses and some requirements might be business 
specific. It is discussed earlier that the position of women in 
society suggests ISs for the development of WEs obviously.  As 
the research examines the effectiveness of ISs for WED that is 
why, on the left hand side box (marked-C) ISs are placed. The 
concept of institution also has been described in the framework 
section of this chapter. Institutions provide financial and non-
financial, software and hardware supports for WEs. These 
supports need to be examined. The box (marked- D) below the 
oval, structured to examine if ISs meet the requirement for the 
Page 303
  
 
5
sustainability of WEs, if institutions’ delivery mechanism is 
designed accordingly. This examination of effectiveness will 
include the appropriateness, adequateness, proper delivery and 
finally the external and internal performance of the SMEs. 
Therefore, for the appropriateness, adequateness and delivery 
mechanisms concerned with this model aim at examining 
whether the types of ISs delivered at various stages of 
development were appropriate and adequate. The SMEs 
performance will be examined based on their past trends, 
experience and potentials for various growth and 
farsightedness. Using qualitative quantitative and   measures 
the effectiveness of SMEs is to be examined.           
A feedback system also has been developed to have the effect 
on the supply and demand of ISs as well as on the measures of 
the effectiveness of ISs. The model also focuses on the 
measurement of the effectiveness (Marked-E) of ISs. 
Institution’s objectives for choosing such programme, 
development of the people concerned, the structure of ISs, the 
process of the delivery of supports and the process of receiving 
the same by SMEs and other sectors such as strength and 
weaknesses of the SMEs for particular businesses as shown in 
the top of the oval, are considered while measuring the 
effectiveness. The feedback system works here for influencing 
or adjusting demand and supply of both parties, i.e., institutions
and WEs. That feedback system was designed to find out the 
gap between demand and supply. It is also worked out to 
examine the process and by suggesting appropriate measures, 
delivery of supports and actions to be taken by WEs. The model 
incorporates all possible elements in its greater environment 
those thought to have influence on the delivery of various and 
the need and operational activities of the SMEs.  
The development of WEs in selected businesses has been 
thought to the product of effectiveness of the design of ISs at 
market environment, the performance of supported WEs at 
market environment with in the greater external environment of 
the as well as WEs in the internal environment of the 
institutions and SMEs. 
 
The output of the SMEs is thought to be the combined effect of 
both ISs and WEs. WEs access in the market environment with 
product or services of the SMEs supported by institutions 
develops the entrepreneurship. This happens in each business 
where feedback from specific market environment for specific 
business develops WEs.  
The quantitative and qualitative measures have been 
accommodated for examination of the effectiveness of ISs. The 
overall effectiveness, the focus of the model, thought to have 
interactive effect on both the design and delivery of ISs and the 
entrepreneurial capability of WEs for specific SMEs in market 
environment.  
Proposed Model for Assessment of Effectiveness of ISs in 
WED 
 
 
 
 
 
 
Page 304
  
 
6
 
 
Entrepreneurship in Bangladesh 
Page 305
  
 
7
Bangladesh is among the most densely populated countries in 
the world with the seventh large population of the world. Half 
of the GDP comes from service sector although two-thirds of 
Bangladeshis are farmers. More than three quarters of 
Bangladesh’s export earnings come from the garment industry. 
Cheap labor and low conversion cost attracted huge foreign 
investment in this sector. The huge population and frequent 
natural calamity are two severe obstacle in economic countries 
economic growth. Also poor governance and weak public 
institutions, inefficient use of energy resources, insufficient 
power supplies, slow implementation of economic reforms, 
political infighting and corruption are significant obstacles too. 
Even though According to world bank despite of all these 
obstacles Bangladesh has shown steady economic growth of 4-
5% annually (6.5% in 2006-2007), relatively low inflation and 
fairly stable domestic debt, interest, and exchange rates. 
 Bangladesh deserves acclamation for introducing microcredit. 
It covers a wide area of rural households as a means of poverty 
reduction. Few example- Grameen Bank, ASA, BRAC, Karitas, 
Proshika. 
Grameen Bank  helps to 
 extend banking facilities to poor men and women 
 eliminate the exploitation of the poor by money 
lenders 
 create opportunities for self-employment for the vast 
multitude of unemployed people in rural Bangladesh 
 bring the disadvantaged, mostly the women from the 
poorest households, 
 reverse the age-old vicious circle of "low income, low 
saving & low investment", into virtuous circle of "low 
income, injection of credit, investment, more income, 
more savings, more investment, more income". 
  
The Association for Social Advancement (ASA) helps to  
 empowering women for poverty alleviation  
 entrepreneurship development  
 Capacity building  
 
It introduced a small entrepreneur-lending (SEL) programme  
 
In RMG Sector currently, there are 4490 manufacturing units. 
The sector contributes significantly to the GDP provides 
employment to around 4.2 million of whom 90% are women 
generates about $5 billion worth of products each year by 
exporting garment. 
 
Entrepreneurship in India 
India is ninth in the Global Entrepreneurship Monitor (GEM) 
survey of entrepreneurial countries.  It is highest among 28 
countries in Necessity based entrepreneurship, while 5th from 
the lowest in opportunity based entrepreneurship. The 
liberalization, which was started in 1991 and the Information 
Technology boom of the mid-late 90’s, have been significant 
factors, leading to a wave of entrepreneurship sweeping 
through the country. Indians have entrepreneurial capacity. 
Moreover, in India, the post-liberalization and globalization era 
has brought with it a growing middle class - roughly estimated 
to be 250 million - and rising disposable incomes. This presents 
a huge potential, which if tapped can be a veritable gold mine. 
Entrepreneurs can make the best of this by catering to various 
demands of this segment. India, with its abundant supply of 
talent in IT, management, and R&D, has become the 
hot bed of outsourcing of services from all parts of the 
globe where companies can reduce their costs, but not their 
quality [If the foreign company chooses the right Indian 
partner]. 
 Indian entrepreneurship is second to none and activity 
levels are at an all time high 
 Entrepreneurs are driving the growth of the Indian 
economy 
 One in every ten Indians is engaged in some 
entrepreneurial activity or the other. 
 Ambani’s Reliance Communications made mobile 
telephony affordable to the common man.  
 Tata Motors with their $2,000 car promise to do the 
same to the auto sector.  
Page 306
  
 
8
 Captain Gopinath’s Air Deccan made air travel as 
commonplace as travel by train  
 Biyani’s Big Bazaar changed the face of retail in India 
 Ambani’s Reliance Communications made mobile 
telephony affordable to the common man.  
 Tata Motors with their $2,000 car promise to do the 
same to the auto sector.  
 Captain Gopinath’s Air Deccan made air travel as 
commonplace as travel by train  
 Biyani’s Big Bazaar changed the face of retail in India 
 
Entrepreneurship In China 
China has emerged as a world economic super power, forcing 
all players to consider new economic models. The growing 
significance of small and medium-sized enterprises (SMEs) in 
China's economy is hard to ignore. Chinese and foreign experts 
estimate that SMEs are now responsible for about 60% of 
China's industrial output and employ about 75% of the 
workforce in China's cities and towns. Private business is the 
fastest-growing sector of China's economy, expanding at an 
annual rate of 20 percent, far above the 9.5 percent average 
growth of the national economy over the past two decades. 
China has the highest number of the world's richest people 
under age 40 outside of the United States, according to Fortune 
magazine. The Chinese government is providing the "enabling 
environment" for small and medium-sized enterprises (SMEs). 
 
 Industry produced 53.7 percent of China’s gross 
domestic product (GDP) in 2009 
 Industry (including mining, manufacturing, 
construction, and power) contributed 52.9 percent of 
GDP in 2009 and occupied 2.5 percent of the 
workforce. 
 China is the world’s leading manufacturer of chemical 
fertilizers, cement, and steel.  
 SMEs are now responsible for about 60% of China's 
industrial output and employ about 75% of the 
workforce in China's cities and towns. 
 Chinese entrepreneurs bid on antique Rolls-Royces 
and pay cash for the latest BMWs. 
 Measured on a purchasing power parity (PPP) basis, 
China in 2006 stood as the second largest economy in 
the world after the US, although in per capita terms the 
country is still lower middle-income.  130 million 
Chinese fall below international poverty lines.  While 
overall income is rising, wealth is not equally 
distributed. 
 
Entrepreneurship in Thailand 
Entrepreneurship has long been the main vehicle of Thai 
economic growth. The government and other related agencies 
initiated several projects and activities to help strengthen and 
promote entrepreneurship in the country. Private enterprises in 
Thailand can be divided legally into four categories: unlimited 
partnership, limited partnership, limited company and public 
company. During the decade of economic boom in Thailand, 
entrepreneurial activity expanded at a very rapid rate. 
Entrepreneurship Development Program in Thailand helps the 
entrepreneurs think systematically and help them make right 
decisions before investing in and expanding their business. The 
financial constraints play an important role in shaping the 
pattern of entrepreneurship in Thailand, especially in the 
Northeast compared to the Central region. 
Thailand is one of the highest rates of women entrepreneurship 
activity among GEM countries. It stood at 18.5% in 2002. High 
levels of necessity based rather than opportunity based 
entrepreneurs. There is a direct correlation between the rates of 
economic growth with the intensity of entrepreneurial activity 
in Thailand. Since the 1960s, the private sector has played a 
critical role in the country’s economic growth. A Buddhist 
belief system has also contributed to tolerance of failures with 
regards to entrepreneurship. 
The Thai Board of Investment (BOI) was set up to facilitate 
new business ventures. The Thai commercial class is mostly 
made up of Thais of Chinese origin. This group is characterized 
has having a greater entrepreneurial drive (a result of their 
Page 307
  
 
9
Confucian belief system). This group has contributed 
significantly to the economic development of Thailand and is 
also largely responsible for moving the Thai economy from an 
agriculture-based economy to a more service-based economy. 
 
CONCLUSION 
 
 Entrepreneurial activities are substantially different depending 
on the type of organization that is being started. 
Entrepreneurship is a challenging and rewarding profession. It 
needs to concentrate on market analysis, financial resources, 
and technology management. Recently Bangladesh has seen a 
dramatic increase in foreign direct investment. 
Telecommunications have shown remarkable improvements 
after the sector was opened for private investment. A number of 
multinational corporations, including Unocal Corporation and 
TATA have made major investments, with the natural gas 
sector being a priority. Goldman Sachs referred Bangladesh as 
one of the next eleven emerging country and emphasis on the 
potential of future economical growth. Bureaucracy and red 
tape is still part of the investment problem but huge local 
market cheap labor and more export focused government 
policies encouraging more pro business environment. 
 
REFERENCES 
 
 
 
Page 308
 
 
 
 
Fabrication of 2D plasmonic super lattice of silver nanocubes for molecular sensing 
using surface enhanced Raman spectroscopy. 
   
Nur Ahamad and Anatoli Ianoul1 
 
Department of Chemistry, Carleton University 
1125 Colonel By Dr. Ottawa ON Canada 
Phone : (613)-520-2600 x 6043 
Fax: (613)-520-3749 
 
1Corresponding author (e-mail: anatoli_ianoul@carleton.ca). 
  
 
 
 
 
 
 
 
 
Page 309
 Abstract: Colloidal solution of silver nanocubes was prepared by polyol method 
and 2D structure of nanocubes was fabricated by Langmuir-Blodgett technique. The as 
prepared 2D organization of silver nanocubes exhibited Plasmonic property and was 
employed to detect Rhodamine 6G molecules at different solution concentrations. 
Fluorescence and Raman signals were detected at 1pM and 1nM concentrations of 
Rhodamine 6G respectively. Such plasmonic materials can be used to develop chemical 
and biosensors platforms. 
 
 
 
Keywords: Silver nanocubes, plasmonic material, Langmuir-Blodgett technique, 
Surface Enhanced Raman Scattering. 
 
Page 310
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Syeda S. Razia,  
E-mail: syedasrazia@che.buet.ac.bd 
Formation of 1,1,1 trifluoroethane (143a) in HCFC-22 Reactor  
 
 
Sultana R Syeda *, Markéta Bláhová#   
*Department of Chemical Engineering, Bangladesh University of Engineering and Technology 
(BUET), Dhaka 1000, Bangladesh 
#State Office for Nuclear Safety, Department of Non-Proliferation Division of Chemical Weapons 
Prohibition, Prague 2 120 00, Czech Republic 
 
HCFC-22 is used as a precursor to produce tetrfluorethane (TFE) monomer, which is further polymerized to 
manufacture different fluoropolymers. The presence of 1,1,1 trifluoroethane (143a) in HCFC-22, even at 
ppm level, is potentially detrimental to the quality of fluoropolymers manufactured from TFE. The objective 
of the present investigation is to track the source and the reaction mechanism of 143a formation in the 
HCFC-22 reactor. The investigation started with a careful survey on the possible pollutants in the raw 
materials of a HCFC-22 plant followed by a critical review of the chemistry of catalyst HF/SbCl5 as well as 
patented manufacturing processes of fluoro products. The probable source and chemistry towards formation 
of 143a were examined. It was revealed that both 1,1 dichloroethane and cis 1,2 dichloroethene present as 
contaminants in the raw materials are the potential sources of 143a, with cis 1,2 dichloroethene being the 
most likely source. It was also suggested that facilitating chlorination of the 1,1 dichloroethane and cis 1,2 
dichloroethene inside the reactor would decrease the amount of 143a formed. 
 
Key words: HCFC-22, 143a, HF/SbCl5, cis-1,2-dicloroethene, 1,1-dichloroethane, Chloroform, Hydrogen 
fluoride 
 
1. INTRODUCTION 
 
HCFC-22, also known as R-22, is a refrigerant 
used for residential and commercial air 
conditioning and for medium- and low-
temperature commercial refrigeration 
applications. Although HCFC-22 is subject to 
Montreal Protocol and phase out as a refrigerant, 
it is still in use as a precursor for manufacturing 
the monomer tetrafluoroethane (TFE), which is 
later polymerized into different fluoropolymer 
products. HCFC-22 is produced by the 
continuous, liquid phase reaction of chloroform 
and hydrogen fluoride in presence of a partially 
fluorinated antimony pentachloride catalyst. The 
reaction is carried out in a simple, steam heated, 
tank type reactor. The overall process for HCFC-
22 and by product HCl is as follows; 
 
HClCHClFHFCHCl FSbCl 22 23 4    
 
A very small amount of HCFC-23 is also 
produced in this process. Table 1 summarizes the 
reaction temperature and pressure maintained 
inside the HCFC-22 reactor. 
 
Among the impurities present in HCFC-22, 1,1,1 
triflouroethane  (143a) is of particular concern as 
it is potentially detrimental to the quality of 
fluropolymers, although the chemistry and extent 
of the effects are not well understood. 
 
Table 1: Temperature and pressure limits of 
HCFC-22 reactor 
 
HCFC-22 
Reactor 
Max Min Typical Units 
System 
pressure 
240 140 225 psig 
Reactor 
temperature 
90 65/70 80 0C 
 
Laboratory analyses show that 143a is generally 
present at 1 ppm level in HCFC-22. Two to 3ppm 
143a, however, is not uncommon. On some 
occasion it may go up to as high as 10 ppm. It is 
postulated that 143a in HCFC-22 has a link with 
the impurities present at ppm level in the raw 
materials. The characteristics and chemistry of 
these impurities are, however, not very clear. It is, 
nevertheless, imperative to track the source and 
reaction mechanism of 143a formation in HCFC-
22 reactor in order to keep 143a at an acceptable 
level. 
 
The objective of the present investigation is to 
identify the source(s) of 143a and to understand 
Page 311
ISBN: 978-984-33-2140-4
  
the chemistry towards its formation in the HCFC-
22 reactor. The objective is realized by the 
following steps; 
 
i) Survey of related literature   
a. to obtain a list of possible 
contaminants in the raw materials, i. e. 
Chloroform and HF 
b. to understand flouro-chloro chemistry 
of hydrocarbons in presence of SbCl5 
catalyst 
ii) Identification of the possible sources and 
reaction mechanisms of 143a formation 
iii) Suggestion of possible measures to be 
taken for reduction of 143a formation 
 
2. CONTAMINANTS IN THE RAW 
MATERIALS 
 
In order to short list the potential contaminants 
present in the reactor, industrial production 
processes of the raw materials along with the 
impurities in commercially available raw 
materials were reviewed.  
 
Table 4 Potential Contaminants in Raw Materials 
Impurities in 
Chloroform 
Impurities in HF 
Bromo-chloromethane 
Methyl Chloride 
Methylene Chloride 
1,1 dichloroethane 
Carbon tetrachloride 
Acidity as HCl 
Water 
Free Halogens 
Nonvolatile matter 
Amylene content 
Cis 1,2 dichloroethene 
Trans 1,2 dichloroethene 
2-methyl-2-butene 
Benzene 
Toluene 
Chlorobenzene 
Ethylbenzene 
m & p-Xylene 
o-Xylene 
1,3,5 trimethylbenzene 
1,2,4 trimethylbenzene 
1,4 dichlorobenzene 
1,2 dichlorobenzene 
1,2,4,5 
tetramethylbenzene 
Biphenyl 
Hexachlorobenzene 
Arsenic 
Flourosilicic acid 
Nonvolatile acid 
Sulphur dioxide 
Water 
 
The list was compared with the list of potential 
contaminants in raw materials provided by the 
raw material suppliers (table 4). It was found that 
the list provided by the raw material suppliers is 
comprehensive. One may consider the possibility 
of presence of two more contaminants in 
chloroform (b.p.61.20C), namely, 1,1,1 tri-
chloroethane (b.p.740C),  and 1,1 dichloroethene 
(b.p.320C). The boiling point differences between 
Chloroform and these two compounds make their 
existence very slim in the raw materials. This is 
also true for trans 1,2 dichloroethene 
(b.p.47.50C), which most of the time does not 
exist in chloroform.  
 
3. CHEMISTRY OF THE 
CATALYST SbCl5 
  
In presence of HF the catalyst SbCl5 undergoes 
the following fluorination reaction [2] 
HClFSbClFSbClHSbClHF   445  
 
The SbCl4F takes part in two types of fluorination 
reaction:  
 
i) Substitution reactions 
The first type is the substitution reactions, in 
which fluorination of chlorocarbon takes place 
through the successive replacement of the 
chlorine atoms by fluorine. The rate and extent of 
the overall reaction depend on the fluorine 
content of antimony halide as well as the relative 
reactivity of the C-Cl bonds. Some groups i.e. 
allyl, benzyl and methyl group in CH3-CCl3 are 
very active and the target Cl atom can be replaced 
easily. By contrast, molecules like in CCl3-CCl3 
and CCl2=CCl2 are less reactive and requires 
pentavalent catalyst with a fluorine content 
greater than SbCl4F. 
 
ii) Disproportionation reactions 
The second type is disproportionation reaction in 
which the substituents of the organic molecules 
rearrange themselves into thermodynamically 
more stable configuration. In an intermolecular 
disproportionation the groups are exchanged 
between individual molecules; 
422
)/(
33
5 CClFCClFCClFCCl FClSb    
 
One the other hand, in the intramolecular 
disproportionation the redistribution is internal; 
23
)/(
22
5 CClFCClFCClFCCl FClSb    
It is to be noted that thermodynamically the most 
stable configuration is the one possessing the 
least symmetry. 
 
Page 312
  
4. TRACKING THE SOURCES AND 
RESPECTIVE CHEMISTRY OF 143a 
FORMATION 
 
The identification of the source of 143a started 
with the list of hydrocarbons provided by the raw 
material suppliers. The elimination of the unlikely 
hydrocarbons forming 143a was done next. Two 
types of hydrocarbon were excluded from the list 
based on the following considerations;  
 As 143a is an aliphatic compound the 
aromatic impurities are excluded 
 As 143a is a bi carbon compound and 
the catalyst (SbCl5) does not take part in 
addition reaction the mono-carbon 
impurities are excluded  
The following three compounds are left in the list 
for further consideration 
1. 1,1- dichloroethane  
2. cis and trans 1,2 –dichloroethylene  
3. 2-methly-2-butene 
 
A literature survey on fluorochemistry shows that 
almost all contemporary research works deal with 
the reduction of Freon production or finding 
alternatives to it rather than the impurities HCFC-
22 may contain. Much of the information referred 
in this investigation is obtained from different 
patents describing manufacturing conditions and 
yields of different fluorohydrocarbons. During the 
investigation, the focus was made on the type of 
catalyst used and the reaction temperature. The 
references used in explaining the reaction 
mechanism are mostly for HF/SbCl5 system. In 
absence of any reference with HF/SbCl5, 
references of similar system, such as HF/SnCl5 or 
HF/Cr-Mg are used to approximate the reaction 
thermodynamics. In the following sections the 
chemistry of three probable contaminants as 
possible sources of 143a are discussed under the 
conditions prevailing in the HCFC-22 reactor. 
 
i)  Chemistry of 1,1 dichloroethane  
 
Investigation on the mechanism of formation of 
143a from 1,1 dichloroethane leads to two 
possible routes (figure 1).  
 
1. The first route 123 involves fluorination 
of 1,1 dichloroethane to 1,1 difluoroethane in 
presence of HF/SbCl5 system and at a 
favourable temperature i.e. 50-1200C[1]. 
Formation of 143a, however, requires further 
fluorination, which necessitates replacement 
of one hydrogen atom. This can only be done 
by free fluorine[2], not by HF. The list of 
impurities provided by the suppliers show the 
presence of free halogen in raw materials. 
This free halogen, if F2, may contribute to the 
formation of 143a. It is to be noted the free 
chlorine does chlorinate hydrocarbons at the 
temperature maintained in the reactor [3]. 
 
2. The second route 123 involves    
chlorination of 1,1 dichloroethane to 
trichloro-ethane (HCFC-140a). The 
trichloro-ethane further reacts with HF to 
form 143a. As mentioned earlier the methyl 
group in trichloethane is a highly potent 
activator for replacement of Cl by SbCl5 
catalyst. The reaction temperatures 70 to 
1000C., and reaction pressures 50 to 100 
psig, are adequate to fluorinate HCFC-140a 
to form HFC-143a [4]. The presence of free 
fluorine, again provides another route to the 
formation of 143a from tri-chloroethane. 
 
All fluorination reactions, however, have to 
compete with highly probable chlorination of 1,1 
dichloroethane and formation of CHCl2-CHCl2 
and higher chlorinated compounds with high 
boiling points that build up in the reactor. 
 
 
HFCHCFHClCHCHFHFCHCHCl FpsigCSnCl    3332
40040,12050@
32
2
0
52
 
 
                                        
 
       HClCHCFCHCCl psigCSbClHF    33
10050,10070@,2
33
0
5  
 
 
 
22 CHClCHCl   
 
+F2 
+HCl/SbCl5 
2 3 
+HCl/SbCl5 
1 2 3 
Figure 1 Formation of 143a from 1,1 dichloroethane 
 
Page 313
  
ii)  Chemistry of 1,2 dichloroethylene or 
1,2 dichloroethene 
 
Manufacturing 143a from 1,1 dichloroethene 
(also known as vinylidene chloride) is a standard 
practice in the industry. The presence of 1,2 
dichloroethene gives rise to the possibility of  
presence of 1,1 dichloroethene  in the reactor as 
an intermediate product produced from intra-
molecular redistribution of 1,2 dichloroethene. 
The reaction route in figure 2 shows that 
fluorination of 1,1 dichloroethene to 143a 
requires temperature 60-2000C. The same is true 
for the production of 143a directly from 1,2 
dichloroethene[5],[6].However, in presence of an 
intermediate product 1, fluoro-1,1 dichloroethane, 
1,1 dichloroethene can be converted to 143a at a 
much lower temperature, i.e. more favourably[7]. 
 
Like 1,1 dichloroethane, 1,2 dichloroethene is 
subject to further chlorination and formation of 
high boiling chlorinated ethane which remain in 
the HCFC-22 reactor. 
  
 
 
 
22 CHClCHCl   
 
 
 
33
1,20060@/ 05 CHCFCHClClCH atmCHFSbCl     
   
 
 
33
1,20060@/
22
0
5 CHCFCClCH atmCHFSbCl     
 
 
 
 
     33
15015,12040@/,
23
0
522 CHCFCFClCH psigCHFSbClCClCH     
 
 
Figure 2 Formation of 143a from 1,2 DCE 
 
 
 
    22323
/
323
25 CHFCHFCHFCHCHCHCHCHCCH FHFSbCl     
 
 
 
 
 22
/
22
5 CHFCHFCHClCHCl HFSbCl    
 
 
Figure 3 Fluorination of 2-methyl-2-butene 
 
 
 
iii) Chemistry of 2-methly-2-butene  
+SbCl5/HF 
@600C,17.5bars 
+ SbCl5/HF 
+HCl/ SbCl5 
+HCl/ SbCl5 
Page 314
  
Figure 3 shows that fluorination of 2-methly-2-
butene eventually leads to the formation of 
difluoroethane, not 143a. Thus, 2-methly-2-
butene may be excluded from the potential source 
of 143a formed in the HCFC-22 reactor. 
 
From above discussions it is clear that 
fluorination of 1,1 dichloroethane to 143a 
requires two step reaction involving two different 
fluorinating agents i.e. either HF and F2 or HCl 
and F2. On the other hand, fluorination of 1,2 
dichloroethene to 143a is an one step reaction 
with two more favourable routes. Thus, from 
reaction mechanism and thermodynamic point of 
view, 1,2 dichloroethene is a more probable 
source of 143a than 1,1 dichloroethane.  
 
It is to be noted that both 1,1 dichloroethane and 
1,2 dichloroethene are subject to chlorination 
under the reactor conditions and they only 
fluorinate partially to form 143a. 
 
5. POSSIBLE MEASURES FOR 
REDUCTION OF 143a  
 
Following are the two possible options for 
reduction of 143a formation in HCFC-22 reactor  
 
1. Using raw materials with lower 
contaminants than those of the currently 
used raw materials 
2. Applying reactor conditions towards lower 
selectivity of 143a formation  
 
The first option would result in major increase in 
the cost of raw materials, which is not desirable. 
The second option, on the other hand, has the 
potential to affect the purity of HCFC-22 if 
reactor conditions are to be changed beyond the 
operation limits. One way of implementing the 
second option is by promoting chlorination of the 
1,1 dichloroethane and 1,2 dichloroethene 
towards formation of higher chlorinated 
compounds with high boiling point. As it is 
mentioned earlier, both of these compounds are 
prone to further chlorination. Reported data on 
HCl/SbCl5 show [2] that up to 300 psia, the system 
pressure does not have much effect on the 
Henry’s constant,  of HCl, whereas increase in 
temperature from 60 to 1200C increases H from 
88 to 138. Thus running the reactor at a lower 
temperature within the process limits may 
facilitate the chlorination reaction and production 
of high boiling point chlorohydrocarbons. 
However, as the effect of decreasing temperature 
on reaction equilibrium of chlorination is not 
known the above mentioned proposition for 
reduction of 143a is subject to the result of trial 
run of the HCFC-22 reactor. 
 
6. CONCLUSIONS  
 
The investigation on the identification of the 
source of 143a in HCFC-22 reactor leads to the 
following conclusions: 
 
a) 1,1 dichloroethane and 1,2 dichloroethene are 
the two possible sources of 143a in HCFC-22 
with 1,2 dichloroethene to be the most likely 
source 
b) Only part of 1,1 dichloroethane and 1,2 
dichloroethene form 143a and the rest 
undergoes chlorination reaction  
c) One way of reducing 143a without disturbing 
the production of HCFC-22 is to favour 
chlorination reactions in the reactor. 
 
ACKNOWLEDGEMENT 
We gratefully acknowledge the support and fund 
provided by the Organization of the Prohibition 
of Chemical Weapon (OPCW), the Hague, the 
Netherlands. 
 
REFERENCES 
 
1. United States Patent 5672788: Two-step 
process for manufacturing 1,1-
difluoroethane 
2. Kaiser, E. W., (1993) Relative Rate 
Constants for Reactions of HFC 152a, 143, 
143a, 134a, and HCFC 124 with F or Cl 
Atoms and for CF2CH3, CF2HCH2, and 
CF3CFH Radicals with F2, Cl2 and O2, Int J 
Chemical Kinetics, 25, 667-680. 
3. US patent 6,339,178: Synthesis of 1,1,1-
trifluoroethane by fluorination of 1-chloro-
1, 1-difluoroethane 
4. US patent 6,630,610: Method of producing 
fluorinated organic compounds 
5. WIPO Patent Application 
WO/2005/097716: Method of making 
difluoromethane, 1,1,1-trifluoroethane and 
1,2-difluoroethane 
6. US patent 7,112,708:  Method of making 
difluoromethane, 1,1,1-trifluoroethane and 
1,1-difluoroethane 
7. United States Patent 7071368:  Method of 
making 1,1,1-trifluoroethane 
Page 315
Proceedings of the 
    Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*Corresponding Author: M.S.A. Mamun 
E-mail: shameembtri@yahoo.com  
 
 
INFLUENCE OF WEATHER PARAMETERS ON RED SPIDER 
MITE- A MAJOR PEST OF TEA IN BANGLADESH  
 
M. Ahmed and M.S.A. Mamun* 
Entomology Division, Bangladesh Tea Research Institute, Srimangal, Moulvibazar, Bangladesh 
 
M.M. Hoque and R.S. Chowdhury 
Department of Food Engineering and Tea Technology, Shahjalal University of Science and 
Technology, Sylhet, Bangladesh 
 
Abstract 
 
An investigation was carried out at the main farm of Bangladesh Tea Research Institute (BTRI), Srimangal, 
Moulvibazar, Bangladesh during 2005-2009 to find out the influence of weather parameters on the 
infestation of red spider mite in Bangladesh tea Monthly data on mite population and infestation were 
recorded from the experimental plots with systematic sampling method. Five years meteorological data of 
the experimental area under the Srimangal Meteorology Station were also collected for the study from the 
Meteorological Department, Dhaka. The weather factors such as temperature, relative humidity, rainfall, 
sunshine hours etc. are very important for the productivity of tea as well as out break of pests in tea. Pest 
population have a tendency to fluctuate with the environmental factors. The weather factors exercise a 
dominating effect on the fecundity, incubation period, reproductive capacity, longevity and development of 
mite pests. Climatic factors such as temperature, relative humidity and sunshine hours showed positive 
relationship with the infestation of red spider mite. All the parameters except rainfall were found highly 
correlated (r = 0.91, 0.92 & 0.91 respectively) with the field infestation of mite. On the other hand, heavy 
rainfall & cloud coverage and water requirement of crop were found to be negatively correlated (r = -0.89 & 
r = -0.49) with the infestation of mite. Correlation coefficients are statistically significant at 5% level of 
significance. This study may be helpful in rescheduling the use of miticides and modifications of some 
available control options to minimize the infestation of red spider mite of tea in Bangladesh.   
 
Key words: Tea, Red spider mite, Weather, Infestation  
 
INTRODUCTION 
 
Tea is a long established plantation crop of 
enormous economic importance to Bangladesh 
meeting the entire domestic demand of this 
cheapest health beverage. Tea plant is subjected to 
the attack of several insects, mites, fungal 
pathogens and weeds. Obviously the intensive 
monoculture of a perennial crop like tea over an 
intensive cultivated area during last 160 years had 
formed a stable tea ecosystem apparently at isolated 
ecological zone of greater Sylhet and Chittagong 
districts in Bangladesh for widely divergent 
endemic or introduced pests (Alam, 1999). Each tea 
growing country has its own distinctive pests, 
diseases and weeds. In the world tea, 1034 species 
of arthropods and 82 species of nematodes are 
associated with tea plants (Chen and Chen, 1989). 
Among them, 25 species of insects, 4 species of 
mites and 12 species of nematodes are recorded 
from Bangladesh (Ahmed, 2005). Red spider 
mite, Oligonychus coffeae Nietner is one of the 
major pests of tea in Bangladesh. It belongs to the 
order Acarina. Of course, they are not spiders at 
all although they are related to them. Hundreds of 
spider mites are found on the upper and 
undersurface of every tea leaf, together with 
thousands of eggs and the white skin casts by the 
mites as they grow. Red spider mites are of major 
economic importance in tea industry of 
Bangladesh and are responsible for depredation 
of yield and debilitation of tea plants. The red 
spider mite normally attacks the upper surface of 
mature leaves. But in severe cases young leaves 
are also attacked. The larvae, nymphs and adult 
mites cause the damage. When large numbers of 
mites are present, sucking one leaf cell after 
another and sucking out the contents, the whole 
leaf eventually changes to a bronze colour, dries 
up and drops- especially in hot and dry weather. 
Page 316ISBN: 978-984-33-2140-4
When the conditions are favourable, during spring 
and summer the eggs produced by the females 
without fertilization. Crop loss due to the attack of 
red spider mite in Bangladesh tea is 9.57% (Ali et 
al. 1994). The eggs are laid singly at intervals on 
the surface of the leaves, mostly along the mid-rib 
and veins. During the cropping season (March-
October), red spider mite shows the maximum 
fecundity (60-77 eggs), minimum incubation period 
(3-5 days), minimum life cycle (7-9 days) and 
maximum female population (1:1.2) (Ahmed and 
Sana, 1990). Most of the valley circles reported 
severe infestation of red spider mites which are 
more prevalent and alarming round the year for the 
tea industry. It is noticed for the information of the 
tea estate that severe damage is apprehended in tea 
plantations during drought period. Infestation of 
Red spider mites was high during last decade 
because of higher temperature and humidity, 
uneven rainfall and intermittent sunlight. The 
climatic factors such as temperature, relative 
humidity, rainfall, sunshine hours etc. are very 
important for the productivity of tea as well as out 
break of pests in tea (Ahmed and Uddin, 2001). 
Pest population have a tendency to fluctuate with 
the environmental factors. The degree of 
influencing factors determined the magnitude of 
increase or decrease in number of mite population. 
The climatic factors exercise a dominating effect on 
the fecundity, incubation period, reproductive 
capacity, longevity and development of mite pests.  
 
No work has been done on the population dynamics 
and the infestation of red spider mite in Bangladesh 
tea in relation to weather parameters (temperature, 
relative humidity, sunshine hours and rainfall). So, 
an attempt has been made to correlate red spider 
mite infestation with the weather parameters in 
general and temperature, relative humidity, 
sunshine hour and rainfall in particular. 
 
MATERIALS AND METHODS 
 
A detailed investigation was carried out at the main 
farm of Bangladesh Tea Research Institute (BTRI), 
Srimangal, Moulvibazar, Bangladesh during 2005-
2009 in order to find out the influence of weather 
parameters on red spider mite, a major pest of tea in 
Bangladesh. Five years meteorological data of 
maximum and minimum temperature, sunshine 
hours, relative humidity and rainfall of the 
experimental area were collected from the 
Meteorological Department, Dhaka. Monthly data 
on the mite infestation were recorded from the 
clonal tea plants in the experimental plot with 
systematic sampling method. Ten mature leaves per 
bush were plucked randomly, mites were brushed 
by mite brushing machine and calculated under a 
compound microscope. The percentage of 
infestation per plot was calculated by Lubischev’s 
analytical method. The monthly percentage of 
infestations was compared with the weather 
parameters, such as temperature, relative 
humidity, sunshine hours, rainfall and water 
requirement of the crop and correlation analysis 
was done between these parameters and red 
spider mite infestation. Mean monthly values 
were computed from five years of meteorological 
data (2005-2009). For the computation of mean 
temperature, average value of maximum and 
minimum temperature was taken. The water 
requirement of the crop was calculated by using 
Penman (1956) equation:                             
 
Rn = Eo/L --------------------------(i) 
 
Where, 
Rn = net solar radiation  
L = latent heat of evaporation= 590 cal/gm 
Eo = potential evaporation in mm (calculated 
below) 
Rn was calculated from total radiation at the top 
of the atmosphere (Ra), given in the Table-1. 
(MacDonald & Partners, 1967) using Glover and 
McCulloch (1958) equation which reads as: 
            Rn=Ra[ 0.29 cos + 0.52 n/N ] 
 
Net solar radiation is around 55 percent of total 
solar radiation and varies only little with season 
(Monteith, 1965).  
Hence, Eo may be written as  
           Eo =  0.55Ra[ 0.29 cos + 0.52 n/N ]/L   
 
                                                                                
                                      0.29 cos +0.52 n/N 
Therefore Eo=0.55Ra                                        cm 
 
                                                590 
 
                                         
                                      0.29 cos +0.52 n/N 
            or, Eo=5.5Ra                                        mm 
                                                590 
 
Where, 
n = actual sunshine hrs recorded 
N=maximum possible sunshine hrs (= day length) 
 = latitude 
Monthly values of Ra (cal cm-2 day-1) and N (hr) 
for Srimangal (latitude 24.3º N) and the equation 
for the daily estimation of water requirement of 
the crop Etw= 0.85Eo are given in Table 1.  
 
Table 1. Monthly values of solar radiation at the 
top of the atmosphere (Ra) in cal cm-2 day-1, 
Maximum possible sunshine hrs (N) for 
Srimangal (latitude 24.3º N) and the 
corresponding equation for estimating daily water 
requirement of the crop  (Etw = 0.85Eo). 
Page 317
 
Month Solar radiation   
Cal / cm2  / day 
Maximum possible 
sunshine N (hrs/day) 
Equation for water requirement, 
Etw=0.85 Eo (mm) 
January 603 10.9 1.2609 + 0.2279 n 
February 705 11.4 1.4741 + 0.2548 n 
March 822 12.0 1.7188 + 0.2822 n 
April 918 12.8 1.9195 + 0.2955 n 
May 969 13.3  2.0260  + 0.3002 n 
June 984 13.6 2.0575 + 0.2981 n 
July  973 13.5 2.0345 + 0.2969 n 
August 934 13.0 1.9529 + 0.2960 n 
September 856 12.3 1.7898 + 0.2867 n 
October 745 11.6 1.5578 + 0.2646 n 
November 631 11.0 1.3294 + 0.2363 n 
December 572 10.7 1.1196 + 0.2202 n 
 
Eo   = potential evaporation in mm 
Etw  = water requirement of crop in mm  
 
The significance test of the Coefficient of 
Correlation (r) was carried out by using Student’s t- 
distribution (Alder and Roessler, 1964): 
     
tcal = r/ {(1-r2)/ (n-2)}1/2  -----------------------(ii) 
 
Where r is the Correlation Coefficient, n is the 
number of data and (n-2) is the degree of freedom. 
If the tcal > t0.05, the coefficient is significant. 
Relationship between each of the parameters and 
the infestation were plotted in 5 different graphs. 
Correlation co-efficient were calculated in each 
case to see the significant relationship. 
 
RESULTS AND DISCUSSIONS       
 
The influence of weather factors such as 
temperature, relative humidity, sunshine hours, 
rainfall and water requirement of crop are very 
important and played vital effect on red spider mite 
infestation. Carr (1972), Kandiah and Thevadasan, 
(1980) and Devanathan (1975), correlate climatic 
requirements of tea plant with the yield of tea crop. 
A prolong drought during early part of the season 
hinders normal growth of the bushes and the 
severity of mite attack gradually increases with 
their quick multiplication. Drought is related to 
temperature, humidity, light duration, wind effect, 
shade status, soil type and drainage condition etc. 
which have the positive effect on red spider mite 
incidence. The influence of weather parameters on 
the infestation of red spider mite in Bangladesh tea 
is shown in the following sub heading: 
 
Temperature 
 
Temperature is an important unique meteorological 
parameter that influences the growth and 
development of tea as well as pest infestation. High 
temperature influences the infestation of red spider 
mite in tea. Multiplication rate is greatly increased 
in higher temperature. In low temperature, 
population is reduced during winter season but 
unreasonable low temperature followed by wind 
during spring leads to high mortality. Potential 
progeny output increases exponentially i.e. 20 
individual at 15.50 C; 12,000 individual at 210 C; 
13,000,000 individual at 26.50 C (Ahmed and Haq, 
2007). Infestation increases with the increase of 
temperature and vice-versa.  
 
 
From April to September monthly average 
temperature was higher than that of the rest of the 
months and accordingly the infestation percentage 
was also observed higher during this period than 
the other period of the year (Fig. 1). The correlation 
co-efficient between the percentage of infestation 
and the temperature is r = 0.91. The values are 
statistically significant at 5% level of significance.  
 
Relative Humidity 
 
Humidity is an important climatic factor that 
influences the growth and development of tea plant. 
It interferes with the population build-up of red 
spider mite. Hot and dry weather with low humidity 
lead to high infestation of red spider mites. It 
encourages less feeding, slower egg laying and 
shorter life span. Like temperature, relative 
Fig.1 Relatio ns hip betwe en te mpe rature  and infe s ta tio n o f red 
s pide r m ite  in Banglades h tea
0
10
20
30
40
50
60
70
80
90
Jan Feb M ar Apr M ay Jun Jul Aug Sep Oct Nov Dec
M onth
Te mpe ra t ure
% inf e st a t ion
r = 0.91 
Page 318
humidity was also found to be positively related 
with the infestation of red spider mites in tea. 
Infestation increases with the increase of relative 
humidity and vice-versa.  
 
From April to September monthly average 
humidity was higher than that of the rest of the 
months and accordingly the infestation percentage 
was also observed higher during this period than 
the other period of the year (Fig. 2). The correlation 
co-efficient between the percentage of infestation 
and relative humidity is r = 0.92 and the values are 
statistically significant at 5% level of significance. 
 
Rainfall 
 
Rainfall is one of the major climatic factors that 
affect the growth, development and yield of tea as 
well as outbreak of red spider mite. The minimum 
annual rainfall of 1150–1400 mm is generally 
considered necessary for successful cultivation of 
tea (Eden, 1965; Hasan et al., 1965; Harler, 1966). 
Too much water can be devastating for some pests. 
Raindrops can physically dislodge them from their 
host plant and behaviour patterns can be disrupted. 
Prolonged or heavy rain with big rain drop washes 
off mites from host. Mites move to underside of the 
leaf. It leads to high mortality of mites. It also 
escorts to less breeding of mites. Eggs of red spider 
mite is least affected. The droplet size of rain has 
reduced in a small i.e. drizzling. So, light rain with 
intermittent sunlight increase the populations of red 
spider mites in tea. Monthly average rainfall and 
percentage of infestations of mites are shown in 
Fig. 3.  
 
In the figure it is conspicuous that infestation 
increased with rainfall, but the rate was not same in 
all the rainy months (May-October). In June rainfall 
was the maximum but infestation percentage was 
the maximum having less rainfall in March-May 
than June. Heavy rainfall might have washed out 
the mite population from the leaves. At the onset of 
first rain during February or early March, tea begins 
to flush and pest continues its life process on tea 
(Sana, 1989). However, the correlation between 
rainfall and the percent infestation was found 
insignificant at 5% level of significance with r = -
0.89. 
 
Sunshine hours 
 
Sunshine hour is a major weather parameter. Red 
spider mite is a positively phototropic pest. Light 
duration (sun light intensity and penetration) in 
daytime influences the build up of mite population. 
Light has the positive response in the upper surface 
of the leaves. It influences egg laying, oviposition 
rhythm, with the maximum oviposition at dawn and 
dusk when there is a rapid change in light intensity. 
Changes in light regime i.e. light to dark leads to 
peak oviposition. Egg hatching is the maximum at 
red light. Light penetration within the canopy 
regulates the distribution of mites. Sunshine hours 
were found to be positively related with the 
infestation of red spider mite in tea; the higher 
sunshine hours, the higher was the percentage of 
infestation (Fig 4).  
 
From October to April, the length of sunshine hours 
remained maximum due to minimum cloud 
coverage and the percentage of infestation was 
found to be high. It indicates that the length of 
sunny period has a great influence on the activity of 
pest attack (Sana, 1989). The correlation co-
efficient was found to be r = 0.91 which is 
significant at 5% level of significance. 
 
 
 
 
 
 
 
Fig. 2 Rela tio ns hip betwe en rela tive  humidity and infes tatio n 
o f re d s pider mite in Bangla des h te a
0
10
20
30
40
50
60
70
80
90
100
Jan Feb Mar Ap r May Jun Jul Aug Sep Oct Nov Dec
Mont h
Re la t ive Humidit y 
infe st a t ion
Fig. 3  Re la tio ns hip be tween mo nthly  ra infa ll and 
infes ta tio n o f re d s pider mite  in B anglades h tea  
0
50
10 0
150
20 0
250
30 0
350
40 0
450
50 0
Jan Feb Mar Apr May Jun J ul Aug Sep Oct Nov Dec
Month
0
10
2 0
3 0
4 0
50
6 0
70
8 0
9 0
Rainfall
Infe sta t ion
Fig. 4 R ela tio ns hip betwee n s uns hine  ho urs  a nd infes tatio n 
o f re d s pide r mite in B anglades h te a
0
10
2 0
3 0
4 0
50
6 0
70
8 0
9 0
Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
Mo nth
S unshine  hours
infe st a t ion
r = 0.92 
r = 0.91 
r = - 0.89 
Page 319
Water requirement of crop 
 
Water requirement of crop generally plays a 
negative role on infestation during the production 
period of tea (April - October).  
 
It reveals from Fig. 5, that while water requirement 
was high, infestation percentage was observed low 
(March, April & May) and vice-versa during June, 
July, August &   September. The correlation co-
efficient (r = -0.49) shows that the relationship (-ve) 
between the two factors is not significant.  
 
CONCLUSION 
 
The literature on pest outbreaks of red spider mites 
gives us some indications of the impacts of extreme 
climatic conditions. Although the climatic factors 
are beyond control in nature, some of these 
situations interfere with the spray fluids and also 
might have influenced resistance or tolerance of the 
pest due to exposer to inadequate toxicity from the 
applied chemical. Thus knowing the behaviour of 
this particular pest under variable climatic factors, 
this study may be helpful in rescheduling the 
miticides use and modifications of some available 
control options to reduce the infestation of red 
spider mites in Bangladesh tea. Planters should 
keep in mind that climate change is likely to be a 
gradual process that will give them some 
opportunity to adapt. Planters who closely monitor 
the occurrence of pests in their fields and keep 
records of the severity, frequency, and cost of 
managing pests over time will be in a better 
position to make decisions about whether it remains 
economical to continue to grow a particular crop or 
use a certain pest management technique. Those 
Planters who make the best use of the basics of 
integrated pest management (IPM) such as field 
monitoring, pest forecasting, recordkeeping, and 
choosing economically and environmentally sound 
control measures will be most likely to be 
successful in dealing with the effects of climatic 
factors. 
 
 
 
 
REFERENCES 
  
1. A.F.M.B. Alam. (1999). Profile of tea industry 
in Bangladesh. Global advances in tea science. 
Aravali Books International (P) ltd. New Delhi. 
P. 1-22. 
2. Ahmed, M. (2005). Tea Pest Management. 
Evergreen Printing and Packaging, Dhaka, pp.1-
29. 
3. Ahmed, M. and Haq, M. (2007). Biological 
attributes of Red Spider Mites (RSM) and their 
integrated control approaches in tea. Circular 
No.128. Bangladesh Tea Research Institute. 1-
8pp. 
4. Ahmed, M. and M. J. Uddin (2001). Effect of 
some climatic factors on Helopeltis infestation 
of tea. Tea J. Bangladesh. 37(1&2): 8-17. 
5. Ahmed, M. and Sana, D.L. (1990). Biological 
aspects of red spider mite, Oligonychus coffeae 
N. in tea. Bangladesh J. Zool. 18:75-78. 
6. Alder and Roessler. (1964). Report on recent 
climatic changes in Bangladesh. SAARC 
Meteorological Research Center (SMRC), 
September, 2001, 1-14.   
7. Ali, M.A., Ahmed, M. and Haq, M.I. (1994). 
Crop loss by Red Spider mites in tea. 
Bangladesh J. Zool. 22 (2): 197-202. 
8. Carr, M.K.V. (1972). The climatic requirements 
of the tea plant: A review. Expl. Agric. 8: 1-14. 
9. Chen, Z.M. and Chen, X.F. (1989). An analysis 
of world tea pest fauna. J. Tea Sci. 9: 13-22. 
10. Devanathan, M.A.V. (1975). The quantification 
of climatic constraints on plant growth. Tea Q. 
45(3 & 4): 43-72. 
11. Eden, T. (1965). Tea (2nd Ed.). Longmans; 
London, P. 205 
12. Glover, J. and McCulloch, J.S.G. (1958). Quart. 
Royal  Met. Soc. 84: 172. 
13. Harler, C.R. (1966). Tea growing: Oxford 
University Press. London. P. 162 
14. Hasan, K.A., Chaudhury, S.H. and  Halim, M.A. 
(1965). Effect of climatic factors on the yield of 
tea (Camellia sinensis). Tea J. Pakistan, 3: 4-13.  
15. Kandiah, S. and Thevadasan, T. (1980). 
Quantification of weather parameters to predict 
tea yields. Tea Q. 49 (1): 25-33.   
16. MacDonald, M. and Partners. (1967). Report on 
investigation into irrigating tea in Sylhet and 
Chittagong districts. Vol. II. Appendix-I , 
climatic data and the calculation  of 
evaporation. 127-146.         
17. Monteith, J.L. (1965). Radiation and crops.  
Expl. Agric., 1: 241-251. 
18. Penman, H.L. (1956). The movement and 
availability of soil water. Soils and Fertilizer. 
29: 221-225.  
19. Sana, D.L. (1989). Tea Science, Asrafia 
Boighar, Dhaka, Bangladesh, P. 90-198. 
Fig. 5 Re la tio ns hip between water requirem ent o f cro p a nd 
infes ta tio n o f red s pider m ite  in Banglade s h tea
0
2 0
4 0
6 0
8 0
10 0
12 0
14 0
Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
Mont h
Wa t er  r equire me nt  of  c rop
% inf est
r = - 0.49 
Page 320
 
Laser Action in Polyfluorene and Fluorene-based Co-
Polymers 
  
Md. Amdadul Huq Chowdury1, Andrew P. Monkman2 and Nazia 
Chawdhury1 
1Department of Physics, Shahjalal University of Science and Technology, Sylhet-3114, Bangladesh, 
Email: emdaad20015@yahoo.com , nc-phy@sust.edu 
2OEM Research Group, Department of Physics, Durham University, Durham DH1 3LE, U.K. Email: 
a.p.monkman@durham.ac.uk 
 
 
 
Abstract: 
We have investigated optical absorption, steady state and time resolved 
photoluminescence spectroscopy at room temperature and at low temperature of 
polyflourene and 9,9–dyoctylefluorene-2,7-diyl-dibenzothiophene-s,-s-dioxide-3,7-
diyl co-polymers p(F-S)y. Dual phosphorescence is observed for p(F-S)50 that are 
originated from different monomer units. Drop cast film of polyfluorene and p(F-
S)50 show amplified spontaneous emission (ASE) effect peaking at 2.66 eV for 
later with FWHM at 5 nm . 
   
Keywords: Time resolved emission, spectral narrowing, delayed fluorescence and 
polyfluorene copolymer. 
Page 321ISBN: 978-984-33-2140-4
  
 
 
 
 
 
 
 
This Page is Intentionally Blank 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Page 322
  
 
 
 
 
 
 
 
 
 
 
This Page is Intentionally Blank 
 
 
 
 
 
 
 
 
 
 
 
 
Page 323
  
 
 
 
 
 
 
 
 
 
 
This Page is Intentionally Blank 
 
 
 
 
 
 
 
 
 
 
 
 
Page 324
  
 
 
 
 
 
 
 
 
 
 
 
This Page is Intentionally Blank 
 
 
 
 
 
 
 
 
 
 
 
Page 325
  
 
 
 
 
 
 
 
 
 
 
This Page is Intentionally Blank 
 
 
 
 
 
 
 
 
 
 
 
 
Page 326
  
 
 
 
 
 
 
 
 
 
 
 
This Page is Intentionally Blank 
 
 
Page 327
* Corresponding Author: Prof. Dr. Md. Maksudur Rahman Khan  
E-mail: mrkhancep@yahoo.com 
PERFORMANCE of THE TWO-CHAMBER MICROBIAL FUEL 
CELL 
 
M. R. Khan, M. S. A. Amin, K. Ferdaus, M. A. Islam  
Department of Chemical Engineering and Polymer Science,  
Shahjalal University of Science and Technology, Sylhet 3114, Bangladesh 
 
 
Microbial fuel cell (MFC) is a promising technology for the wastewater treatment with production of 
sustainable clean energy. Proton exchange membranes (PEM) are often used in the microbial fuel cells to 
separate the liquid in the two-chamber (one is act as anode and another is cathode) while allowing protons to 
pass between the chambers. Using Nafion as proton exchange membrane simultaneous power (electricity) 
generation from readily biodegradable organic substrates was investigated in this study. Biodegradation was 
the dominant mechanism of the Yellow Cibacron-2G (YC) dye removal in association with glucose 
substrate. Effect of catholytes in cathode, substrate concentration in anode on power generation was studied. 
This system demonstrates the performance of the two-chamber MFC, corresponding to the highest power 
generation of 54µA and around removal of chemical oxygen demand (COD) is 50%. 
 
Key words: Microbial Fuel Cell; Wastewater treatment; De-colorization; Electricity generation;  
 
1. INTRODUCTION 
 
As we head into the future, large portion of energy 
produced and used in the world will be from 
sustainable sources due to the world’s limited supply 
of fossil fuels and their impact on environmental and 
economic changes. Microbial Fuel Cell (MFC), a 
source sustainable energy uses either of low or 
negative economic value such as wastewater. This 
technology is recently gaining a great attraction due 
to their ability to generate electricity directly while 
accomplishing wastewater treatment. MFCs have 
been mostly used for converting a variety of 
carbohydrates such as acetate, butyrate, glucose, or 
even complex organics in wastewater [Venkata 
Mohan et al., 2008; Liu et al., 2003].  
MFC is a biochemically catalyzed system, which 
generates electricity by oxidizing biodegradable 
organic matter in the presence of either fermentative 
bacteria or enzymes [9-11]. The biocatalyst present in 
the anode chamber of MFC generates electrons (e–) 
and protons (H+) through anaerobic respiration of 
organic substrates. Electron transfer occurs through 
the electrode (anode) integrated with an external 
circuit to the cathode. Protons diffuse through the 
proton exchange membrane or salt bridge (which 
separates the cathode and anode chamber) into the 
cathode chamber, where they combine with the 
electron acceptor. The potential difference between 
the respiratory system and electron acceptor 
generates the current and voltage needed to generate 
electricity [Chaudhuri SK, Lovely DR et al 2003; Oh 
SE and Logan BE et al, 2005]. 
 
 Azo dyes which constitute the largest chemical class 
of synthetic dyes are extensively contained in effluent 
discharged from dye-manufacturing industries and 
dye-consuming industries. The intense color of        
 
 
 
 
dye-containing wastewater leads to severe aesthetic 
problems and obstructs light penetration and oxygen  
transfer into water bodies, thus affecting aquatic life. 
Treatment of dye-containing wastewater still presents 
a technical challenge. Most physicochemical methods 
can remove dye efficiently but are not feasible due to 
their expensive cost, limited versatility and sensitivity 
to other wastewater constituents. Alternatively, 
biological treatment may present a relatively 
inexpensive way to remove dyes from wastewater 
[Dos Santos et al., 2007; Pandey et al., 2007]. De-
colorization of azo dyes is usually achieved under 
anaerobic (methanogenic) or anoxic conditions. In 
the past few years several bacterial strains that can 
aerobically decolorize azo dyes have been isolated. 
 
In this paper, MFC has been constructed for 
simultaneous power generation and removal of COD. 
Glucose (substrate) and YC (mediator) has been used 
in anode chamber. Potassium permanganate 
electrolyte solution was used in cathode. Some 
effective parameters such as effect of catholyte, 
initial substrate concentration and wastewater 
treatment   have been investigated to evaluate the 
MFC performance.  
 
2. MATERIALS AND METHODS  
 
YC -2G was used in this experiment, supplied from 
local textile industry. The IUPAC Name is trisodium 
4-[[4-chloro-6-[(4-sulphonatophenyl)amino]-1,3,5-
triazin-2-yl] amino]-2-[[1-(2,5-dichloro-
4sulphonatophenyl)-4,5-dihydro-3-methyl-5-oxo-1H-
pyrazol-4-yl]azo]benzenesulphonate. 
 
 
Page 328ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
` 
2.2 MFC CONFIGURATION AND OPERATION 
 
The two-chambered MFC was designed and 
fabricated in the laboratory using PET bottle (Figure 
1; Table 2.1). Total volume of both anode and 
cathode compartment was the same (0.5 L) and each 
chamber was provided with sample port, wire point 
inputs (top), inlet and outlet ports. 
 
Figure1: Schematic diagram of Two-chamber 
microbial fuel cell with schematic details 
 
A membrane between two straight conduits was used 
to connect the two chambers. 9.5 cm long and 0.75cm 
diameter plastic tube was used. Both anode and 
cathode electrodes were made of graphite Rod (6 cm; 
0.8 cm diameter) obtain from dry cell battery and 
were positioned at a distance of 2 cm on either side of 
the membrane. Electrodes had a surface area of 16.08 
sq. cm. prior to use, the electrodes were soaked in de-
ionized water for a period of 24 h. Contact between 
electrodes and copper wires was sealed with epoxy 
material.   
Substrate was individually implemented as carbon 
source for the electricity production and also 
mediator was used in the anodic chamber of the two-
chamber MFC.  The anodic inoculums were prepared 
by using sludge, collected from local waste water 
drainage system. Before inoculation, the sludge was 
filtered through a 0.25 mm pore size sieve to remove 
the impurities. 
Constant removal COD and current generation were 
considered as indicators for satisfactory formation of 
the bio-film and stable operating conditions. Open 
circuit voltage (OCV) was measured by connecting 
multimeter in parallel with the MFC. Note that 
Sludge containing cell is anode. The current was 
measured with the help of a ammeter connecting in 
series with resistance. One end of a resistance 
connected with Anode terminal (+ve) of the MFC 
other end will connect with the +ve terminal of the 
ammeter. Negative terminal of the Ammeter will 
connect with the Cathode of the MFC.  
 
A series of experiments was conducted to investigate 
the performance of the two-chamber MFC. Whereas, 
OCV and current generation vs time, decolorization 
of YC vs time and removal of COD as a function of 
time were observed. All experiments were conducted 
at least in duplicate, in a constant temperature room 
(30 ± 2 0C), and the average value was reported for 
all data.  
 
Table 1: MFC component and inoculation condition 
 
Reactor configuration  Dual chamber  
 
Anode chamber    Suspended growth  
Anode inoculums  Mixed anaerobic       
consortia  
Mediator-anode    Yellow Cibacron 
Oxidant-cathode                 KMnO4  
Volume of anode and  0.5L 
cathode chamber 
Anode and cathode  Graphite plate 
material   
Surface area of electrodes 16.08 (sq. cm)  
Membrane  Proton exchange          
membrane (Nafion) 
Feeding nature (l/cycle)  Batch  
Operating temperature 30 ± 2 (0C)    
pH    6.5 (anode), 7.5 (cathode) 
 
 
 
2.3 ANALYTICAL METHODS 
 
2.4.1 COD CALCULATION METHOD:  
 
COD of sample was determined by taking 2.5 ml of 
sample , 2.5 ml distilled water, 1.5 ml 0.1M K2Cr2O7 
and 3.5 ml H2SO4 reagent in a 10 ml COD ampule.  
The ampule was heated at 150o-160o C for 2 hours. 
Then the ampule was shaken and allowed to cool at 
room temperature. The solution was then taken in a 
conical flask and added with 1, 10-Phenophthroline 
indicator which makes its color blue. Then the 
solution was titrated with 0.1 M Mohr’s salt (FAS) 
until the color changes to red. The same procedure 
was conducted with a distilled water sample. 
 
By using the following equation COD of a sample 
can be calculated  
 
                                     (1)  
 
where, b is the volume of FAS used in the blank 
sample, s is the volume of FAS in the original 
sample, V is the sample volume and n is the 
normality of FAS. If milliliters are used consistently 
for volume measurements, the result of the COD 
calculation is given in mg/L. 
Page 329
` 
2.4.2 DE-COLORIZATION OF YC 
 
Decolorization of YC was determined by monitoring 
the decrease in absorbance at the maximum 
wavelength of 425 nm. UV-visible spectrophotometer 
(Shimadzu, Model -1650) was used for this purpose. 
For the 48-hr decolorization experiment, test samples 
(5ml) where withdrawn from the reactor at 0, 2, 4, 6, 
8, 10,12, 24, 30, 36 and 48 hr. samples where 
centrifuged at 5,000 rpm for 5 min to remove 
suspended biomass from the liquid media and 
absorbance was measured. Decolorization activity 
was calculated as the following:  % ݊݋݅ݐܽݖ݅ݎ݋݈݋ܿ݁ܦ ݂݋ = (஺ି஻)×ଵ଴଴
஺
                  (2) 
 
A is the initial absorbance; B is the observed 
absorbance. 
 
3. RESULT AND DISCUSSION 
 
3.1 EFFECT OF CATHOLYTE ON MFC 
PERFORMANCE 
 
The effect catholytes in two-chamber MFC three 
cells having glucose concentration of 50ppm and 
600ppm concentration of YC in anode chamber was 
operated. Anode wastewater was inculcated with 
250mL of wastewater.  Cathode chambers were run 
with the three different electrolyte solutions of 200 
ppm KMnO4, 200ppm K2Cr2O and saline water. The 
experiments were done for both open and close 
circuit. In closed circuit cells were connected with 
external resistance of 22.5. 
0 10 20 30 40 50 60 70 80
0
3
6
9
12
15
18
C
B
Cu
rre
nt
, 

Time, hr
A
 
Figure2:  Effect of catholyte on the MFC 
performance (600 ppm of YC in anode; A: 200 ppm 
KMnO4, B: 200 ppm K2Cr2O7, C: saline water in 
cathode; temperature T: 30± 2 0C by using 22.5 Ω 
resistance; OCV: ±0.56V for A, ±0.30V for B, 
±0.13V for C) 
Figure2 shows that the current generated for each 
case as a function of time. During 3.5 days (80 hr) of 
this experiment at first 10hr the current increased 
rapidly for KMnO4 and K2Cr2O7 electrolyte solution 
and reached a maximum value of 16µA for the cell 
operating with KMnO4 solution. No pH decreasing 
adjustment was made as it was reported by Li et al, 
2009 that low pH values lead to an increase of 
cathode potential. According to the following 
Equations, MnO4 has a much higher oxidation 
potential than in alkaline conditions: 
V 1.33 = E; O7H + 2Cr6e + 14H OCr
59.0;432
7.1;234
0
2
32
72
0
224
0
224






VEOHMnOeOHMnO
VEOHMnOeHMnO
  
In comparison reactive catholytes the saline water as 
catholyte showed very poor performance because of 
low consumption of electron in anodic reaction. As a 
result for further experiments,   KMnO4 solution was 
used as an electron acceptor in this study. 
 
3.3 EFFECT OF SUBSTRATE CONCENTRATION 
ON MFC PERFORMANCE  
 
To explore the effect of glucose (C6H12O6) 
concentration in MFC three cells having glucose 
(C6H12O6) concentrations of 50, 300, 600 and 900 
ppm in the anode chamber was operated. The anode 
wastewater was inoculated with 250 mL of 
wastewater (anode COD = 224ppm). In the cathode 
chamber was operated with saline water. The 
experiments were done for both open and close 
circuit. In closed circuit cells were connected with 
external resistance of 22.  
0 10 20 30 40 50 60 70 80 90 100
0
10
20
30
40
50
60
B
D
C
C
ur
re
nt
, 

Time, hr
A
 
Figure3:  Effect of glucose concentration on 
electricity generation (A: 50, B: 300, C: 600 and D: 
900ppm glucose along with 300 ppm YC in each 
anode; 200 ppm KMnO4 in cathode; temperature T: 
30± 2; OCV: ±0.14V for A, ±1.1V for B, ±0.66V for 
C, ±0.61V for D) 
 
Page 330
` 
 
Figure3 shows the current generated for each case as 
a function of time. The duration of this experiment 
was nearly 4 days (92 h). During the first 3h the 
voltage and current increased rapidly for all cases and 
reached a maximum value of 0.35V and 13 µA 
respectively after 55 h for the cell operating with 
0ppm glucose concentration in anode chamber. 
 
When micro-organisms consume a substrate such as 
glucose in aerobic conditions they produce carbon 
dioxide and water. However when oxygen is not 
present they produce carbon dioxide, protons and 
electrons as described below ( Bennetto et al, 1990; 
logan BE et al 2007) 
 
ܥ଺ܪଵଶ ଺ܱ +ܪଶܱ → 6ܥ ଶܱ + 24ܪା +  24݁ି 
 
According to Hideki Sakai et, all the current 
increased with the increase in the glucose 
concentration. For high glucose concentration this 
may cause the increase of the proton concentration 
within the immobilized layer by the following 
glucose oxidation reaction which leads to suppression 
of the enzymatic activities. 
 
݁ݏ݋ܿݑ݈ܩ → ݁݊݋ݐ݈ܿܽ݋݊݋ܿݑ݈ܩ + 2ܪା +  2݁ି 
 
In comparison with various glucose concentrations in 
anode higher glucose concentration exhibited lower 
current generation.  
 
3.4 PERFORMANCE   OF MFC IN WASTEWATER 
TREATMENT  
 
Two-Chamber MFC were continuously monitored for 
the removal COD to enumerate the potential of fuel 
cell to act as wastewater treatment unit. During 
operation, three cells having glucose concentrations 
of 300, 600 and 600ppm along with 300ppm YC 
concentration was operated. The anode wastewater 
was inoculated with 250 mL of wastewater (initial 
anode COD = 224ppm).  In the cathode chamber was 
operated with 200ppm KMnO4 solution. 
 
Figure4 (a) shows the percentage of COD removal 
increases as a function of time for all cases and 
reaches a maximum 48% COD removal for the cell 
operation with 300ppm glucose concentration in 
anode. The duration of this experiment was nearly 3.5 
days (78 h). 
 
In this study de-colorization of azo dye was not so 
high (figure: 4.b). About 25% of de-colorization was 
achieved. De-colorization of azo dye by bacteria 
could be due to adsorption by microbial cells or to 
biodegradation was reported by Sani & Banerjee et 
al. 
 
0 10 20 30 40 50 60 70 80
0
10
20
30
40
50
C
B
Re
m
ov
al
 o
f C
O
D
Time, hr
A
 
 
Figure 4(a):  % of COD removal in MFC (300,600 
and 900 ppm glucose along with 300 ppm of YC in 
anode; 200 ppm of KMnO4 cathode; temperature T: 
30± 2 0C; % of COD removal: 48.9% for A, 37.2% 
for 8, 3% for A) 
 
 
 
 
0 10 20 30 40 50 60 70 80
0
5
10
15
20
25
C
B
%
 o
f D
ec
ol
or
iz
at
io
n
Time, hr
A
 
 
Figure5:  % of De-colorization in MFC (300,600 and 
900 ppm glucose along with A: 300ppm, B: 600ppm 
and C: 900ppm glucose in anode; 200 ppm KMnO4 
in cathode; temperature T: 30± 2 0C; % of de-
colorization: 24.57% for A, 11.87% for B, 12.3% for 
C) 
 
 
De-colorization rate may be lowered due to the 
adsorption of azo dye on the microorganism surface. 
In adsorption, cells may become deeply colored 
because of adsorbing dyes, whereas those retaining 
their original color are accompanied by the 
occurrence of the biodegradation. The microbial 
consortium does not remain at its original color after 
batch de-colorization in this study, indicating that the 
color removal was actually primarily incurred   due to 
biosorption rather than biodegradation by the living 
cells.  
Page 331
` 
 
3.2 STUDY THE PERFORMANCE ON MFC  
 
To investigate the overall Performance of the Two-
Chamber MFC having glucose (C6H12O6) 
concentrations of 300ppm along with 300ppm of YC 
in the anode chamber was operated. The anode 
wastewater was inoculated with 250mL of 
wastewater (anode COD = 224ppm). In the cathode 
chamber was operated with 200ppm KMnO4 
solution. The experiments were done for both open 
and close circuit. For closed circuit resistance of 22.5 
 was used.  
 
0 10 20 30 40 50 60 70 80 90 100
500
600
700
800
900
1000
1100
1200
Equlibrium State (voltage)
Equlibrium State (Current)
Rising State
 Voltage (mV)
 Current (µA)
Time, hr
V
ol
ta
ge
, m
V
0
10
20
30
40
50
60
C
u
rren
t, µ
A
 
Figure 5(a):  Performance of electricity generation in 
MFC (300 ppm glucose and 300 ppm YC in anode; 
200 ppm of KMnO4 in cathode; temperature T: 30± 2 
0C by using 22.5 Ω resistances; Equilibrium current 
and voltage: ±54µA and 1.16V) 
 
Figure 5(a) shows the voltage and current generated 
as a function of time. The duration of this experiment 
was nearly 4 days (92h). During the first 44h the 
voltage and current increased rapidly and reached a 
maximum value of 1.2V and 54 µA respectively after 
45h of the cell operation.  
 
Generally, voltage and Current increases as the 
bacteria grows exponentially and decreases when the 
bacterial growth reaches stationary phase. More 
precisely voltage and current generation can also be 
decreases due to limited mass transfer of chemical 
species by diffusion to the electrode surface or the 
metabolic losses. To generate metabolic energy, 
bacteria transport electrons through MFC membrane 
at a higher potential. The higher the difference 
between the redox potential of the substrate and the 
anode potential, the higher the possible metabolic 
energy gain for the bacteria, but the lower the 
maximum attainable MFC voltage. To maximize the 
MFC voltage, therefore, the potential of the anode 
should be kept as low (negative) as possible (logan et 
al, 2006). However, if the anode potential becomes 
too low, electron transport will be inhibited and 
fermentation of the substrate (if possible) may 
provide greater energy for the microorganisms.  
 
 
 
Two-Chamber MFC was continuously monitored for 
the change of pH in anode chamber. Whereas, the 
cell was operating with glucose concentrations of 300 
ppm and 300ppm concentration of YC in the anode 
chamber and 200ppm KMnO4 in cathode chamber.     
  
0 20 40 60 80 100
0
10
20
30
40
50
60
Time, hr
C
ur
re
nt
, 

5
6
7
8
9
10
pH
 
Figure 5(b):  pH change in MFC (300,600 and 900 
ppm glucose along with 300 ppm YC in anode; 200 
ppm KMnO4 in cathode; temperature T: 30± 2 0C by 
using 22.5 Ω resistances, pH range: 6.5-7.8 for 
Maximum current generation) 
 
Figure 5(b) shows the change in pH during the 
current generation as a function of Time. Initial pH at 
anode chamber was decreases due to the proton 
generation. Mainly pH value in anode chamber is 
inversely proton generation. Generated protons are 
then diffuse through the proton exchange membrane 
(which separates the cathode and anode chamber) 
into the cathode chamber and increase the pH value 
again. Optimum pH value of 7.2 is obtained form this 
experiment.  
 
Usually Nafion as MFC membrane is typically 
slower than the other cations such as Na+, K+, Ca2+ 
and Mg2+. Therefore pH of the cathode chamber will 
increased by leakage of proton, if there is no pH 
control by using cathode buffer solution.(R A 
Rozendal et all, Trinh et al 2010). Rozendal et all 
reported that MFC potential mainly affected bye the 
insufficient supply of the protons at the cathode 
chamber.  Maximum current was obtained when the 
pH of anode was around 7. Optimum pH for MFC 
operation using activated sludge in anode chamber is 
7-8(Gil et al), with lower current generation is being 
achieved at pH below 6 and over 9.   
 
Page 332
` 
 
4. CONCLUSION 
Microbial Fuel cell was fabricated and constructed 
with the locally available materials. Effect of 
KMnO4, K2Cr2O7 and saline water as catholyte 
concentration on electricity generation has been 
investigated and KMnO4 solution exhibited higher 
voltage and current than K2Cr2O7. Effect of glucose 
concentration was studied. Optimum glucose 
concentration should be used in order to generating 
the higher electricity. De-colorization rate may be 
lowered due to the adsorption of azo dye on the 
microorganism surface. This system is capable for  
simultaneous electricity generation of about 54µA 
and also reduced nearly 50% of COD from the 
wastewater.    
 
REFERENCES  
 
1. Britannica Online:                  
http://www.search.eb.com/eb/article?idxref=512
45  
2. Wikipedia Online: 
  http://en.wikipedia.org/wiki/Microbial_fuel_cell  
3. http://www.microbialfuelcell.org   
4. Logan BE, Microbial Fuel Cell, Published by 
John Wiley & Sons, Inc., Hoboken, New Jersey, 
2008.   
5. Shijie You, Qingliang Zhao, Jinna Zhang, Junqiu 
Jiang, Shiqi Zhao, A microbial fuel cell using 
permanganate as the cathodic electron acceptor, 
2009. 
6. Bennetto, Electricity generation by 
microorganisms, Biotechnology Education, Vol-
1, No-4, pp 163-168, 1990.   
7. Y. Mohan, S. Manoj Muthu Kumar and D. Das, 
Electricity generation using microbial fuel cells. 
International Journal of Hydrogen Energy 
Volume 33, Issue 1, pp 423-426, 2008,  
 
8. Trinh NT, Park JH, Kim SS, Generation 
behavior of electricity in a microbial fuel cell, 
Korean J. Chem. Eng. 27(2), pp546-550, 2010. 
 
9. Gil, G.C., Chang, I.S., Kim, B.H., Kim, M., 
Jang, J.K., Park, H.S., Kim, H.J.,. Operational 
parameters affecting the performance of a 
mediator-less microbial fuel cell. Biosensor 
Bioelectron. 2003 , (18), pp-327–338. 
 
10. Chaudhuri SK, Lovely DR Electricity generation 
by direct oxidation of glucose in mediatorless 
microbial fuel cells. Nat Biotechnology 
21:1229–1232, 2003 
11. Oh SE, Logan BE Hydrogen and electricity 
production from a food processing wastewater 
using fermentation and microbial fuel cell 
technologies. Water Res 39:4673–4682, 2005. 
12. Rozendal, A. R., Hamelers, M. V. H. and 
Buisman, N. C., Effects of membrane cation 
transport on pH and microbial fuel cell 
performance. Environ. Sci. Technol., 40, 5206–
5211, 2006. 
13. Pandey, A., Singh, P., Iyengar, L.,. Bacterial 
decolorization and degradation of azo dyes. Int. 
Biodeterior. Biodegrad. 2007, (59), pp-73–84.   
14. Dos Santos, A.B., Cervantes, F.J., Van Lier, J.B., 
2007. Review paper on current technologies for 
decolourisation of textile wastewaters: 
perspectives for anaerobic biotechnology. 
15. Sani, R.K., Banerjee, U.C,. Decolorization of 
triphenylmethane dyes and textile and dye-stuff 
effluent by Kurthia sp.. Enzyme Microb. 
Technol. 1999, 24, pp-433– 437. 
 
Page 333
  
Photocatalytic activities of TiO2 nanoparticles synthesized using sol-gel 
method with presence of nanoporous polystyrene. 
 
Sharmin Rahman Snigdha, Mohammed Jasim Uddin, A.F.M. Al-Mukit, Sudip Shaha, M. Akhtarul Islam 
Department of chemical engineering and polymer science, Shahjalal University of Science and 
Technology, 
Sylhet3114, Bangladesh . 
Phone: +8801715880574, Email:sharmin_ceps@yahoo.com, Fax: 715257 
 
Nanotechnology is one of the extensively high advanced technologies of the world & emerging in haste 
with its entire span & has a diversified use. Following this advancement TiO ₂ is playing a vital role in this 
era & is one of the most important photocatalyst that is used in many purposes like fog proof & self 
cleaning glass, antibacterial, antiviral, anti soling, self cleaning, air pollution water treatment,  including 
dye removal from the industrial waste i.  Nanostructured TiO ₂ was synthesized using sol-gel method 
with presence of nanoporous polymer . Photocatalytic efficiency of TiO ₂ increases with the escalation of 
surface area of the TiO₂ nanoparticles. Here TiO ₂ is synthesized with and without the presence of polymer 
(polystyrene) and calcinated at 450 0C, 5500C, 6500C and compared the photo catalytic performance with 
that of commercial/standard TiO ₂. The samples have been characterized by several techniques (SEM, 
HRTEM, FTIR, Raman, UV–Spectroscopy and XRD). These 3 types of TiO ₂ calcinated at 550 are also 
applied in industrial dye and the results are compared, which indicate that this photocatalytic process 
might be effective to remove this color and minimize the cost of an effluent treatment plant. This 
comparison shows that TiO₂ with polystyrene is much more effective in photodegradation than that of 
bare TiO₂ sample which is calcinated at temperature of 550 0C. The photocatalytic efficiency of the 
synthesized samples was decreased in case of the samples calcinated at 450 and 650 0C. 
 
 Keyword: Nanotechnology, sol-gel method, photocatalyst, Polymer, Efficiency.  
 
 
1. Introduction: 
 
Natural water environment in the present day is 
endangered by a variety of hazardous chemical 
substances derived from man made products. 
Various contaminants such as azo dyes and 
organochlorine and aromatic hydrocarbons have 
been detected that affect the environment very 
tremendously. Various methods have been 
developed to remove organic substance from water, 
such as biological methodii,iii,iv, chemical 
oxidationv,vi, electrochemical oxidationvii, and a 
photo catalytic methodviii,ix,x. Among them, the 
photo catalytic oxidation is one of the most 
promising technologies for the eradication of 
organic micro pollutants because it is highly 
efficient in mineralization and can utilize sunlight 
as energy sourcexi. In particular, the photocatalytic 
oxidation of organic pollutants by titanium dioxide 
(TiO2) has grown much more attention as a 
promising chemical procedure for environmental 
cleanup, and organic substance degradation. TiO2 
nanoparticles are effective for the photocatalytic 
degradation of various organic contaminants in 
water; however, its practical use in aqueous media 
is limited because of the difficulty of filtration and 
recovery of infinitesimally small TiO2 particles. xii  
Photocatalytic materials, TiO2 has been extensively used 
in sterilization, xiii, xiv sanitation, and remediation 
Page 334
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
  
applications,xv as well as air purification and water 
treatment. TiO2 has proven to be an excellent 
photocatalyst material by which undergoes complete 
mineralization under UV exposure.xvi 
Off late, Titanium dioxide (TiO2) has been 
extensively studied as a photocatalyst for 
applications such as water and air remedy, because 
of its relatively high photocatalytic activity, robust 
chemical stability, relatively low production costs, 
and nontoxicity. Redox reactions of environmental 
interest are initiated on the TiO2 surface with 
trapped electron-hole after band gap excitation. 
However, TiO2 is active only under near-ultraviolet 
irradiation due to its wide band gap energy of 3.0-
3.2 eV. Therefore, significant efforts have been 
made over the last 20 years to develop modified 
TiO2 particles that are active under visible light 
irradiation (λ > 400 nm).xvii 
Titanium dioxide has been extensively used, either 
as thin films or as submicron powders, in a wide 
application range in electronic or optical devices as 
well as pigment or catalyst. In many processes, 
titanium alkoxide are used as precursors in order to 
get oxide with controlled purity and morphology. 
The involved reactions are essentially hydrolysis 
when we follow sol-gel process. 
We have synthesized TiO2 powders from titanium 
isopropoxide, Ti (O-iC3H7)4 (referred to hereafter 
as TTIP), in the presence of a solvent alcohol, at 
room temperature and Atmospheric presser. In such 
conditions, narrow-sized particles (20-60 nm) partly 
crystallized in the anatase structure are obtained. 
Similar reactions conducted in supercritical. 
In powder synthesis, pure dry particles can be 
recovered, without further washing and drying 
steps, by removing the solvent and byproducts, 
simply decompressing the system at a temperature 
above the alcohol’s critical point. 
We have recently developed a simplest process for 
TiO2 powder production at a laboratory scale. 
However the aim of the study is to increase the 
surface area of photocatalyst and for this purpose, 
polymer is added to prepare TiO2 powder using sol-
gel process that we developed. Expectation is to 
enlarge the surface area of TiO2 particle, by using 
the simplest sol-gel method and to determine 
efficiency of TiO2 that we synthesized in laboratory   
under same conditions.  
 
 
 
 
2. Experiment: 
 
Preparation of Photocatalyst and Apparatus: 
2.1. Material: 
Titanium isopropoxide, Ti (O-iC3H7)4 
Photocatalyst TiO2 (Degussa P-25, MERCK, 
GERMANY) 
DYE, Methylene Blue (MERCK, GERMANY) 
 
2.2. Synthesis of TiO2 with the presence of 
polystyrene in sol-gel process: 
 For the preparation of TiO2 powder in a new and 
simplest sol-gel process that we tried here to 
produce, 25lml TIP is taken to two round 
battle.51.19 ml isopropanol and 12.24ml distilled 
water in each bottle is added and stirred in magnetic 
stirrer (BDH) for 30 min. After adding TIP, 
isopropanol and water in a given amount in each 
bottle, 2 gm polystyrene is added to a round bottle 
and leaves them for 24 hours. After 24 hour we get 
titanic acid in each bottle; one is only titanic acid 
and another is titanic acid with the presence of 
polystyrene. 
 
 2.3Calcination: 
These 2 samples in the same amount are calcinated 
at a temperature of 450⁰C, 550⁰C, and 650 ⁰C in an 
Electric Muffle furnace (JSMT-30T, KOREA), 
Standard TiO₂ is also calcinated at these 
temperature to compare the efficiency of the 
synthesized TiO₂ and with the presence of 
polystyrene. 
 
2.4Preparation of bed: 
After completion of calcinations .25 gm synthesized 
TiO₂ with polystyrene, synthesized TiO₂ and 
standard TiO₂ is measured. Each of samples is taken 
to a 100 ml beaker and added a little amount of 
distilled water to prepare paste bed in each beaker. 
 
2.5. Preparation of 5 ppm Methylene Blue:  
At first 100ppm methylene blue is prepared in 1 
liter volumetric flux. Then 1ppm, 2ppm, 3ppm, 
4ppm, 5ppm, 6ppm, 8ppm, 10ppm of methylene 
blue solution is prepared from mother solution and 
made a calibration curve in UV-Spectrophotometer 
(UV-1650, SHIMADZU).  
Page 335
  
In UV–Spectrophotometer, the wavelength is taken 
from 200-800nm. And the highest pick is achieved 
for MB is 664 nm that we fixed. 
 
 
2.6. Operation procedure for the photocatalytic 
Bed: 
We mainly do our job in the basis of spectra that 
gives a graphical representation of absorbance vs. 
wavelength. Now 50ml of 5ppm methylene blue 
dye is pour in each bed that is being prepared. 
Taken 6ml from each beaker and centrifuged 
(Centrifuger-Effendrop) up to 10 minute. Then 
centrifuged solution was taken to a plastic cell. 
After correction of sample baseline, cell is placed in 
UV-spectrophotometer and measured the sample 
concentration and the spectrum for each sample at 
t=0. Then the sample solution is backed to their 
main solution & placed these bed under a UV-light 
(100 watt) .To protect the eyes carbon paper and 
gloves are used. In this way, spectrum and the 
concentration of the samples are determined in 
equal time interval and when the data is taken the 
beaker must be placed in a dark condition. 
 
Here we take data in a time interval of 15 minutes 
for all sample calcinated at 450⁰C, 550⁰C, 650⁰C 
and try to maintain the same condition for all the 
experiment. 
 
3. Result and Discussion:  
 
3.1Adsorption Kinetics of Methylene Blue for the 
synthesized Tio2 and Synthesized TiO2 with the 
presence of polymer Polystyrene: 
For our Discussion we named the bed prepared for 
our experiment by synthesized TiO2 as only TiO2 , 
standard Tio2 as Com. TiO2and synthesized TiO2 
with the presence of polystyrene as PS bed only 
here after.  
We know that adsorption is depending upon the 
surface area of the photo catalyst. There are 2 
spectra showed the decrement of curvature area that 
means the concentration of Methylene Blue is 
decreasing with time. The area of each spectrum is 
measured and from here the C/Co vs. time is 
prepared. 
 
 
                             Fig: 01(a)          
 
 
                                 Fig: 01(b) 
 
The comparison of TiO2 and polystyrene at 450⁰C 
shows that the 1st order curve of TiO2 is below the 
polystyrene curve in Fig: 01(a) & 1(b). That means 
the required time for degradation of same amount of 
Methylene Blue is less for TiO2 that synthesized the 
polystyrene in Fig: 02. 
 
 
   Fig: 02 
400 500 600 700 800
0.0
0.2
0.4
0.6
0.8
1.0
1.2
 
 TiO2 at 450
A
bs
or
bn
ce
Wavelength
 B
 C
 D
 E
 F
 G
 H
 I
 J
 K
 L
 M
 N
 O
 P
 Q
500 600 700 800
0.0
0.2
0.4
0.6
0.8
1.0
1.2
 
 ps at 450
A
bs
or
be
nc
e
Wavelength
 t=0
 t=15
 t=-30
 t=45
 t=60
 t=75
 t=90
 t=105
 t=120
 t=135
 t=165
 t=200
 t=230
 t=260
 t=300
 t=360
0 50 100 150 200 250 300 350
0.0
0.2
0.4
0.6
0.8
1.0
 
 
C
/C
o
Time
 C/Co vs Time For Tio2 450
 C/Co vs Time For PS450
Page 336
  
 
3.2. Adsorption Kinetics of Methylene Blue for the 
synthesized Tio2 and Synthesized tio2 with the 
presence of polymer Polystyrene at temperature of 
550⁰C: 
 
Here 2 spectra also showed the decrease of 
curvature area that means the concentration of 
Methylene Blue is decreasing with time. The area of 
each spectrum is measured and from here the C/Co 
vs. time is prepared. 
 
 
 
                             Fig: 03(a) 
                            
                                 Fig: 03(b) 
     The comparison of TiO2and polystyrene at 550⁰C 
shows totally different behavior than the experiment 
made for the calcinations temperature of 450⁰C 
using same conditions shown in Fig: 03(a) & 1(b) 
and this is a matter of concern that the 1st order 
curve of TiO2 with polystyrene which is indicated by 
the red curve is below the black curve indicating 
TiO2 means the required time for degradation of 
same amount of Methylene Blue is less for TiO2 
with polystyrene than synthesized TiO2 shown in 
Fig: 04. 
. 
 
                                  Fig: 04 
 
3.3. Adsorption Kinetics of Methylen Blue for the 
synthesized Tio2 and Synthesized tio2 with the 
presence of polymer Polystyrene at temperature of 
650⁰C: 
 
2 spectra also showed the decrement of curvature 
area that means the concentration of Methylene 
Blue is decreasing with time. The area of each 
spectrum is measured and from here the C/Co vs. 
time is prepared. 
 
                                         Fig: 05(a) 
400 500 600 700 800
0.0
0.2
0.4
0.6
0.8
1.0
1.2
 
 
WAVELENGTH VS ABSORBENCE at ps 550
AB
SO
R
BE
N
C
E
WAVELNGTH
 B
 C
 D
 E
 F
 G
 H
 I
 J
 K
 L
 M
 N
 O
 P
 Q
 R
 S
400 500 600 700 800
0.0
0.2
0.4
0.6
0.8
1.0
 
 TiO2 at 550
Ab
so
rb
en
ce
 
wavelength
 t=0
 t=15
 t=30
 T=40
 T=50
 t=70
 t=90
 t=100
 t=120
 t=135
 t=150
 t=160
 t=180
 t=195
 t=210
0 50 100 150 200 250
0.0
0.2
0.4
0.6
0.8
1.0
 
C
/C
o
Time
 C/Co vs Time For Tio2 550 ()
 C/Co vs Time For PS 550
400 500 600 700 800
0.0
0.2
0.4
0.6
0.8
1.0
 
 ps at 6500C
A
bs
or
be
nc
e
wave length
 t=0
 t=15
 t=30
 t=45
 t=60
 t=75
 t=90
 t=105
 t=120
 t=135
 t=150
 t=165
 t=180
 t=195
 t=210
 225
 t=265
Page 337
  
 
                                  Fig: 05(b) 
 The graph of C/Co vs. time of both of Synthesized 
TiO2 and synthesized TiO2 with polystyrene at 
temperature 650⁰C shows below is indicating that 
the black curve is much below than the red curve. 
That means at 650⁰C the activity of polystyrene is 
decreased in the TiO2 bed depicted in Fig: 05 & 
Fig: 06. 
.                                                                                         
                                   Fig: 06 
Now the comparison of TiO2 at 3 calcinations 
temperature of 450⁰C, 550⁰C, 650⁰C is shown in 
the same graph. In this graph, blue sign 
indicates the kinetics of TiO2 at 450⁰C, red sign 
at 550⁰C, green sign at 650⁰C and the black 
color is for the standard TiO2 calcinated at 
550⁰C. The graph depicts that the TiO2 at 
550⁰C is less active than standard TiO2 but it’s 
more effective than the TiO2 synthesized at 
450⁰C and 650⁰C in Fig: 07. 
Again the com TiO2 is just near about the 
synthesized TiO2 at 550⁰C.  
Similarly the comparison of synthesized TiO2 
with polystyrene at 3 calcinations temperature of 
450⁰C, 550⁰C, 650⁰C is shown below.
  
                                      Fig: 07 
In this graph, black sign indicates kinetics of 
synthesized TiO2 with polystyrene at 450⁰C, red 
sign at 550⁰C, green sign at 650⁰C and the blue 
sign is for the standard TiO2 calcinated at 
550⁰C. Again, the graph shows that the 
synthesized TiO2 with polystyrene at 550⁰C is 
less active than standard TiO2 but it is also 
more effective than the TiO2 synthesized at 
450⁰C, 550⁰C and 650⁰C in Fig: 08.
                              
                                  Fig: 08 
400 500 600 700 800
0.0
0.2
0.4
0.6
0.8
1.0
 
TiO2 at 650
0C
 
A
bs
or
be
nc
e
Wavelenth
 t=0
 t=15
 t=30
 t=45
 t=60
 t=75
 t=90
 t=105
 t=120
 t=135
 t=150
 t=165
 t=180
 t=195
 t=210
 t=225
 t=265
0 50 100 150 200 250 300
0.0
0.2
0.4
0.6
0.8
1.0
 
C
/C
0
Time
 C/Co vs Time  For Tio2 650
 C/Co vs Time for ps at 650
0 50 100 150 200 250 300 350 400
0.0
0.2
0.4
0.6
0.8
1.0
 
C
/C
o
Time
 C/Co vs Time For Tio2 450
 C/Co vs Time For Tio2 550 ()
 C/Co vs Time  For Tio2 650
 C/Co vs time for com tio2
0 50 100 150 200 250 300
0.0
0.2
0.4
0.6
0.8
1.0
 
 
C
/C
0
Time
 C/Co vs Time For PS450
 C/Co vs Time For PS 550
 time vs C/Co at 650
 C/Co vs time for com tio2
Page 338
  
 
Conclusion: 
The data and graph experimentally demonstrate that 
the sol-gel process which is developed here is the 
simplest way that can be used not only for the 
laboratory work but also for the industrial purpose 
which behave just like the standard TiO2. 
Apart from this, we also add polymer in this method to 
enhance the efficiency of TiO2 that can remove color 
from the industrial effluent. The experiment says that 
the surface area of this sample is increased in 
reasonable extent than the synthesized TiO2 at same 
procedure which is calcinated at a temperature of 
550⁰C. So, we can use TiO2 with the presence of 
polystyrene at 550⁰C that can be applied instead of 
standard TiO2 and minimize the time that is required 
in any application of photo catalyst. This research 
work opens the possibilities of availability of 
photocatalyst in laboratory work and so for the 
industrial purpose like water treatment, effluent 
treatment; which could be useful eminently to save the 
environment. 
Reference:       
                                                             
iTitaniumart.com,photocatalysis application of titanium 
dioxide 
ii Kang, J. H.; Kondo, F. Bisphenol a degradation by bacteria 
isolated from river water. Arch. Environ. Contam. Toxicol. 
2002, 
43 (3), 265–269. 
iii Fukuda, T.; Uchida, H.; Takashima, Y.; Uwajima, T.; 
Kawabata, 
T.; Suzuki, M. Degradation of bisphenol a by purified laccase 
from Trametes villosa. Biochem. Biophys. Res. Commun. 
2001, 
284 (3), 704–706. 
iv Fent, G.; Hein, W. J.; Moendel, M. J.; Kubiak, R. Fate of C-
14- 
bisphenol A in soils. Chemosphere 2003, 51 (8), 735–746. 
v Sajiki, J. Decomposition of bisphenol-A (BPA) by radical 
oxygen. 
Environ Int. 2001, 27 (4), 315–320. 
vi Belfroid, A.; van Velzen, M.; van der Horst, B.; Vethaak, D. 
Occurrence of bisphenol A in surface water and uptake in fish: 
evaluation of field measurements. Chemosphere 2002, 49 (1), 
97–103. 
                                                                                                          
vii Boscolo Boscoletto, A.; Gottardi, F.; Milan, L.; Pannocchia, 
P.; 
Tartari, V.; Tavan, M.; Amadelli, R.; Battisti, A.; Barbieri, A.; 
Patracchini, D.; Battaglin, G. Electrochemical treatment of 
bisphenol-A containing wastewaters. J. Appl. Electrochem. 
1994, 
24 (10), 1052–1058 
viii Watanabe, N.; Horikoshi, S.; Kawabe, H.; Sugie, Y.; Zhao, 
J. C.; 
Hidaka, H. Photodegradation mechanism for bisphenol A at 
the TiO2/H2O interfaces. Chemosphere 2003, 52 (5), 851–
859. 
ix Fukahori, S.; Ichiura, H.; Kitaoka, T.; Tanaka, H. Capturing 
of 
bisphenol A photodecomposition intermediates by composite 
TiO2-zeolite sheets. Appl. Catal., B 2003, 46 (3), 453–462. 
 
xKaneco, S.; Rahman, M. A.; Suzuki, T.; Katsumata, H.; Ohta, 
K. 
Optimization of solar photocatalytic degradation conditions of 
bisphenol A in water using titanium dioxide. J. Photochem. 
Photobiol., A 2004, 163 (3), 419–424 
xiOllis, D. F.; Pelizzetti, E.; Serpone, N. Photocatalyzed 
destruction 
of water contaminants. Environ. Sci. Technol. 1991, 25 (9), 
1522– 
1529. 
 
xii CHANGSHENGGUO, † MINGGE, ‡ 
LULIU , * , ‡ GUANDAOGAO,† 
YINCHANGFENG,*,‡ ANDY UQIUWANG*, Directed 
Synthesis of Mesoporous 
TiO2 Microspheres: Catalysts and 
Their Photocatalysis for Bisphenol A 
Degradation,  November 10, 2009 
xiii Fujishima, A.; Rao, T.N.; Tryk, D.A. Titanium Dioxide 
Photocatalysis. 
J. Photochem. Photobiol., C: Photochem. ReV. 2001, 1, 1. 
xiv (3) Winkler, J. Nano-scaled titanium dioxidesProperties and 
use in 
coatings with special functionality. Macromol. Symp. 2002, 
187, 317. 
 
xv Fujishima, A.; Hashimoto; Watanabe, T. Fundamentals of 
TiO2 
photocatalysis, first ed.; BKC, Inc.: Herndon, VA, May 1999. 
coatings with special functionality. Macromol. Symp. 2002, 
187, 317. 
xvi Fox, M. A.; Dulay, M. T. Heterogeneous Photocatalysis. 
Chem. ReV. 
1993, 93, 341 
xvii Jina Choi, Hyunwoong Park, and Michael R. Hoffmann* 
Effects of Single Metal-Ion Doping on the Visible-Light 
Photoreactivity of TiO2, ,November 10, 2009 
Page 339
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: M. Mohibul Alam   
E-mail: mmalam-cep@sust.edu  
Photocatalytic degradation of reactive dye in batch and continuous 
modes 
M.Mohibul Alam*, S.Uddin,M.R.Khan,Kaniz Ferdous,M.A.Islam 
Department of Chemical Engineering and Polymer Science 
Shahjalal University of Science and Technology, Sylhet-3114, Bangladesh. 
 
 
Organic dyes are one of the largest pollutants released in wastewater from textiles and other industrial 
processes. Because of potential toxicity of the dye and their visibility in surface waters, removal and 
degradation of organic dyes have been a matter of considerable interest. A wide range of methods have been 
developed, amongst which the heterogeneous photocatalysis involving titanium dioxide(TiO2) appears to be 
the most promising technology. In the present work, titanium dioxide(TiO2) has been used as photocatalyst 
for the degradation of methylene blue(MB) and reactive yellow(RY) in batch and continuous modes. 
Titanium dioxide(TiO2) was immobilized onto the ceramic plate using cement as binder. The absorption 
capacities of TiO2 in bulk and in immobilized form have been investigated. It was found that the maximum 
absorption capacity of titanium dioxide(TiO2) decreased only three times due to immobilization. Effect of 
initial concentration and solution thickness has been studied for photocatalytic degradation of the dye.it was 
found that the degradation rate decreases sharply due to the increase in the solution depth. Effect of 
residence time on photocatalytic degradationin continuous mode has been investigated. 
 
Key words: Photocatalysis; Immobilized TiO2; Methylene Blue (MB); Reactive Yellow(RY); UV activation 
of TiO2 
 
 
 
Page 340ISBN: 978-984-33-2140-4
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Maksudur Rahman Khan, 
E-mail: smrkhancep@yahoo.com, mrkhan@sust.edu 
 
PREPARATION OF BIODIESEL FROM WASTE COOK OIL BY 
USING THREE STEP METHOD 
 
 
Kaniz Ferdous1, 2, Md. Rahim Uddin1, Rehnuma Islam1, Md. Maksudur Rahman 
Khan1, 2, 3*, Md. Akhtarul Islam1, 2 
1Department of Chemical Engineering and Polymer Science, Shahjalal University of Science and 
Technology, Sylhet 3114, Bangladesh 
2Centre for Environmental Process Engineering,, Shahjalal  University of Science  and 
Technology, Sylhet 3114 ,  Bangladesh 
3Faculty of Chemical and Natural Resources, University Malaysia Pahang, 26300 Gambang, 
Kuantan, Pahang, Malaysia 
 
 
Waste cook oil was collected from local restaurants for the preparation of biodiesel. The free fatty acid 
(FFA) of the oil was found as 1.83 wt. %. Biodiesel was prepared by three-step method where in the first 
step, the oil was saponified by  aqueous Ca(OH)2 solutions, in the second step the soap was converted to 
FFA by acidification and in the final step the FFA was converted to fatty acid methyl ester by acid catalyzed 
esterification reaction. The process of preparation of FFA from oil was optimized. Esterification reaction 
was conducted by reacting FFA with methanol at different methanol/FFA molar ratio in presence of 2-6 
wt.% HCl of FFA as catalyst at 60-65° C. The biodiesel properties such as density, viscosity, FFA content, 
moisture content, pour point, cloud point, Saponification value, iodine value, specific gravity and cetane 
index were measured and compared with the standard biodiesel properties. The yield of biodiesel from raw 
oil by this method was found as 67%.    
 
Key words: Waste Cook  Oil, Saponification, Acidification, Esterification,  Biodiesel. 
 
1. INTRODUCTION 
 
A great quantity of Petroleum based fuel or fossil 
fuel is used all over the world but its reservation is 
limited. For reducing the dependence of fossil fuel 
alternative fuels are introduced. One of the most 
commonly mentioned alternative fuel is 
“Biodiesel”.  Biodiesel is defined as “a substitute or 
an additive to diesel fuel that is derived from the 
oils and fats of plants and animals or mono-alkyl 
esters of long chain fatty acids derived from a 
renewable lipid feedstock such as vegetable oil or 
animal fat (Wang Yong et al. 2006) and (Atlin R et. 
al. 2001). The most common oil sources are waste 
cook oil (WCO), sunflower oil, corn oil, canola oil, 
soybean oil, castor oil, rapeseed oil, soybean 
soapstock, koroch seed oil, Sclerocarya birrea oil 
(SCO), melon bug oil (MBO), sorghum bug oil 
(SBO), cardoon (Cynara cardunculus L.), Gum 
copal (kauri resin), frying oil (a mixture of olive oil 
and sunflower oil), Karanja (Pongamia pinnata), 
Jatropha (Jatropha Curcas), Neem (Azadirachta 
indica), Mahua (Madhuca indica),Simarouba 
(Simarouba indica), Jojoba (Simmondsia chinensis 
Link Schneider) etc. Some of these sources are now 
used for the commercial production of biodiesel. 
Such as our neighboring country India is producing 
biodiesel from Jatropha seeds. Isonox bioenergy 
has started operations at the  Ambad area of MIDC. 
The unit will manufacture biodiesel from jatropha 
seeds (  Barnwal B.K.  et  .al.  2004). The main 
ingredient for biodiesel preparation is WCO and 
Ca(OH)2 which are collected  from local  markets. 
Nowadays a comparative study on preparation of 
biodiesel from the WCO by three step method was 
investigated. The conversion of pure triglyceride 
(TG) to fatty acid methyl ester (FAME) is high. 
From the view of chemical reaction refined 
vegetable oil is the best start material to produce 
biodiesel. At first free fatty acid (FFA) was 
prepared from WCO reacting with of Ca(OH)2. 
FAME was prepared by esterification of FFA with 
methanol at different molar ratio. Effect of different 
parameters such as FFA/methanol molar ratio, 
catalyst concentration has been studied and 
optimum parameters are found. 
 
 
Page 341ISBN: 978-984-33-2140-4
  
2. MATERIALS AND METHODS 
 
2.1. Chemicals 
 
Methanol (99-100%), ethanol (99-100%), calcium 
oxide (CaO)or “dry lime”, sodium hydroxide 
pellets (96%), potassium  hydroxide pellets 
(>84%), phenolphthalein (PH 8.2-9.8), acetone 
(99%), diethyl ether , hydrochloric acid (37%), 
sulfuric acid (98%), iodine , sodium iodide, 
bromine, carbon tetrachloride, glacial acetic acid, 
potassium dichromate etc. All the chemicals were 
used as analytical reagent grade. 
 
2.2. Waste Cook Oil 
 
Waste cook oil (palm oil) was collected from local 
restaurants located in Sylhet city in Bangladesh . 
The oil was filtered and its properties were 
measured. 
 
2.3. Biodiesel preparation by Three- step 
method 
 
2.3.1. Saponification 
 
For saponification process required amount of 
WCO was taken in a three necked flask and mixed 
with different stoichiometric amount of aqueous 
calcium oxide solution. The mixture was heated 
with vigorous stirring at temperature of 100 0C for 
2-3 hours. The reaction was stopped by cooling the 
reaction mixture. Aqueous calcium hydroxide 
solution was prepared by dissolving required 
amount of dry calcium oxide (CaO) in 60-90 ml 
water. The reaction time and molar ratio of oil to 
calcium oxide were optimized. 
The Saponification reaction: 
 
CaO + H2O                  Ca(OH)2  
 
CH2OOCR                       CH2OH 
CHOOCR +
ଷ
ଶ
Ca(OH)2↔CHOH + ଷଶ(RCOO)2Ca 
 CH2OOCR                      CH2OH 
   (TG)                              (Glycerin)   (Soap) 
R-COOH + ଵ
ଶ
Ca(OH)2 ↔ ଵଶ(R-COO)2Ca + H2O 
(FFA)                                     (Soap) 
 
Where R denoted any hydrocarbon chain 
 
2.3.2. Acidification or Free fatty acid (FFA) 
preparation 
 
After saponification reaction, produced calcium 
soap solution was treated with different 
stoichiometric amount of concentrated hydrochloric 
acid at a temperature of 65 -70 0C with vigorous 
stirring. After dissolving the soap, the fatty acid 
contents were separated in separatory funnel. After 
separation, hot water wash was given for removing 
mineral acid from the fatty acid. The fatty acid 
content was determined by titration method. The 
different molar ratio of soap to hydrochloric acid 
was given and optimized. 
 
In acidification step following reaction was occur 
for calcium soap: 
 
(R-COO)2Ca + 2HCl          2R-COOH      +   CaCl2 
  (Soap)                                 (FFA) 
 
2.3.3. Esterification of Free fatty acid (FFA) 
 
When acidification was completed produced FFA 
was reacted with different stoichiometric amount of 
methanol with vigorous stirring and heated under 
reflux at a temperature of 60-65 0C in presence of 
hydrochloric acid as a catalyst for 2-2.5 hrs. In the 
esterification reaction, molar ratio of FFA to 
Methanol and Catalyst concentration were 
optimized. 
 
During Esterification the following reaction occurs: 
R-COOH + CH3OH ↔ R-COOCH3 + H2O 
 (FFA)      (Alcohol)        (FAME) 
 
After preparing the biodiesel from WCO various 
physico-chemical properties was measured and 
compared with the standard biodiesel. 
 
The yield of biodiesel was calculated by the 
following equation:  
 
Yield =     
୛ ୠ୧୭ୢ୧ୣୱୣ୪
୛ ୓୧୪    
 
Where, Wbiodiesel  = Weight of biodiesel and  
WOil = Weight of Oil 
 
2.4. Analytical methods for Oil and 
Biodiesel 
  
FFA in the oil and biodiesel samples was analyzed 
by the method described in AOCS Aa 6-38. To 
determine FFA of sample and biodiesel, 1ml of oil  
and biodiesel were weighed in gm then dispersed in 
5ml diethyl-ether solution followed by titration 
against 0.1 M KOH. Saponification value (SV) was 
determined by method described by Jeffery et al. 2 
gm sample is taken in 50 ml alcoholic KOH then 
heated with vigorous stirring at 65 °C for 30 
minutes and titrated with the 0.5 M hydrochloric 
acid. The iodine value was determined by titrating 
Page 342
  
the sample with 0.01 N sodium thiosulfate and 
chemical reagents until the disappearance of blue 
color. Iodine value is calculated by following 
equation: 
 
 Iodine value (IV) = (V1-V2) *S*0.1269*100/ W 
 
V1 and V2 are the volume of sodium thiosulfate 
(ml) required for titration with sample and blank 
titration, S is the concentration of Na2S2O3 in 
Normality, W is the weight of oil sample in gm. 
Physical properties color, moisture content and 
density of the sample were by the following ASTM 
D 1500, ASTM D 1744 (karl fisher method), 
ASTM D 1480/81 and ASTM D 240. Viscosity, 
cloud point, pour point were determined by 
standards ASTM D445 respectively. 
 
3. RESULT AND DISCUSSION 
 
3.1. Characterization of waste cook oil 
 
The properties of WCO such as viscosity, 
density, moisture content, saponification value, 
pour point, cloud point etc were measured and 
represented in Table 1. 
 
Table1: properties of WCO 
 
3.2. Effect of molar ratio of Ca(OH)2 on 
FFA preparation 
 
 Saponification of  WCO was done at different 
molar ratio (1:2, 1:3) with aqueous calcium oxide 
solution.  After saponification, acidification was 
conduct to produce FFA. Percent (%FFA) 
conversion was observed at different time interval 
and reaction time was optimized. The results is 
represent in Fig. 1.  
 
  Fig.1: Time vs. % conversion of FFA at different 
oil/aq. CaO molar ratio [1:3, 1:2 molar ratio of Oil 
to CaO, reaction time 2-3 hours at 100 oC 
temperature under reflux with vigorous stirring] 
 
From the Fig.1 it is seen that, at 1:3 oil/CaO (molar 
ratio) 100% FFA was formed in 100 min, whereas 
at 1:2 oil/ CaO (molar ratio) 100% FFA was 
obtained after 130 min. In further experiments FFA 
was produced using 1:3 oil/CaO molar ratio. 
 
3.3. Fatty acid methyl ester (FAME) 
preparation by esterification of FFA 
 
3.3.1. Effect of FFA/ methanol molar ratio 
 
The FFA/methanol   molar ratio is one of the 
important factors that affecting the FFA conversion 
to methyl ester. From the reaction stoichiometry 1 
mole alcohol is required per mole of FFA to 
convert in methyl ester. FFA react with different 
stoichiometric amount of methanol and the results 
is represent in Fig. 2. 
0
20
40
60
80
100
120
0 100 200
Pe
rc
en
ta
ge
  F
FA
 
Time (min)
FFA TG : 
aq.CaO=1:3
FFA TG 
:aq.CaO=1:2
Properties Experimental  
Value 
Color Yellowish 
Density(kg/m3),  at  25 
oC 
902 
Specific gravity, at 25 oC 0.902 
Kinematic viscosity 
(mm2/s), at 40oC 
47.60 
Free fatty acid content 
(%FFA) 
1.83 
Moisture content (%) 0.40 
Saponification value(mg 
KOH/mg oil) 
238 
Clod point(oC) 12 
Pour  point (oC) 6 
  
Page 343
  
 
 
 
Fig. 2: % conversion of FFA vs.  FFA/methanol 
molar ratio [temperature  65 0C, 5 weight% HCl to 
FFA as catalyst and molar ratio of FFA to methanol 
1:6 under reflux with vigorous stirring]. 
 
From the Fig.2,  it is observed that the FFA 
conversion increases as the ratio of Methanol/FFA 
increases. The conversion is 99.5 % at the molar 
ratio of FFA to methanol 1:6. Further increase in 
FFA to methanol molar ratio conversion does not 
increase. The optimum molar ratio of FFA to 
methanol is 1:6. 
 
 
3.3.2. Effect of catalyst concentration on 
esterification (HCl) 
 
Catalyst concentration has a significant role on 
conversion of FFA to methyl ester. Increase of 
catalyst concentration increases the %FFA   
conversion. The results are shown in Fig. 3. At a 
certain catalyst concentration the conversion is 
high.  
 
From the Fig.3,  it is shown that, the FFA 
conversion increases as the catalyst concentration 
increases and the conversion is 99.5% at the 
catalyst concentration is 5 wt% of HCl to FFA. 
Further increase in catalyst wt% conversion does 
not increase. The optimum catalyst concentration is 
5 wt% of HCl to FFA.  
 
                      
 
 Fig. 3: Catalyst concentration vs.  %FFA reduction 
[Temperature 650C, Molar ratio of FFA to methanol 
1:6 and Reaction time 2.0 hr, under reflux with 
vigorous stirring]. 
 
 
3.3.3. Effect of time on %FFA conversion 
 
Time has a significant effect on the conversion of 
esterification reaction. Increase time increases the 
reaction conversion. After a certain time interval 
the conversion become maximum.                
 Figure 4: Time vs. %FFA reduction [Reaction 
temperature 650C, FFA/Methanol molar ratio 1:6, 
Catalyst concentration 5 wt% of under reflux with 
vigorous stirring] 
 
 Fig.4 shows the FFA conversion with time 
respectively. Highest conversion is found after two 
hours at 650C temperature. Further increase in time 
the conversion does not increase. The optimum 
time is two hours. 
 
3.4. Properties of biodiesel 
 
Properties of produced biodiesel was measured  and 
comparison with biodiesel standard are given in 
Table 2.The quality of biodiesel is determined by 
0
20
40
60
80
100
120
1:00 1:03 1:06 1:09
%
 C
on
ve
rs
io
n 
 F
FA
FFA/methanol molar ratio
0
20
40
60
80
100
120
0 2 4 6 8
%
 F
FA
 c
on
ve
rs
io
n
wt % catalyst
0
20
40
60
80
100
120
0 50 100 150 200
%
FF
A
  →
Time (min)→
Page 344
  
measuring some properties such as cetane index 
which indicates ignition characteristic.  
 
Table 2: Properties of biodiesel produced from 
WCO and comparison with standard value 
\ 
 Cetane index of  biodiesel  is slightly higher  than 
standard  value of biodiesel. Other  prpperties such 
as  density, viscosity, FFA content, moisture 
content, pour point, cloud point, saponification 
value, iodine value, specific gravity  were measured 
. 
4. CONCLUSION  
 
  
Biodiesel has been synthesized from waste cook oil 
by three step method with aqueous calcium oxide  
solution. Three-step method for biodiesel 
preparation comprises with saponification of oil, 
acidification of soap to produce FFA and 
esterification of FFA to biodiesel. Saponification 
was done by aqueous calcium oxide solution at 
different molar ratio of oil to CaO and optimized. 
The optimum molar ratio for saponification by 
aqueous calcium oxide was 1:3 oil to CaO and 
reaction time 120  minutes at 100 0C. In 
acidification the molar ratio of soap to hydrochloric 
acid was 1:2.5 for calcium soap. In Esterification 
the optimum molar ratio of FFA to methanol was 
1:6, the catalyst concentration was 5 wt% of HCl to 
FFA, the reaction temperature was 650C and the 
reaction time is 2 hour. So the properties of 
biodiesel such as density, viscosity, specific 
gravity, cloud point, pour point, cetane number are 
nearest to the petrodiesel. The present experimental 
results support that produced biodiesel from waste 
cook oil can be successfully used as diesel. 
 
5. ACKNOWLEDGEMENT 
 
The financial support from the research grant of 
University Grants Commission (UGC) of 
Bangladesh for conducting this research work and 
ERL for providing their facility for biodiesel 
properties measurement.  
 
6.  REFERENCES 
 
1. M. Encinar  Jose ,´* F. Gonza Juan ´ Lez, And 
Rodrı´Guez-Reinares Antonio  (Biodiesel From 
Used Frying Oil. Variables Affecting The Yields 
And Characteristics Of The Biodiesel) 
Departamento De Ingenierı´A Quı´Mica Y 
Energe´Tica, Universidad De Extremadura, 
Avenida De Elvas S/N, 06071 Badajoz, Spain 
 
2. Wang Yong  , Ou Shivi, Liu Pengzhan , Xue 
Feng, Tang Shuze (Comparison Of Two Different 
Processes To Synthesize Biodiesel By Waste 
Cooking Oil)  
Department Of Food Science And Engineering, 
Jinan University, Guangzhou 510632, China 
Received 17 November 2005; Received In Revised 
Form 12 February 2006; Accepted 15 February 
2006. 
3. Knothe Gerhard *, Dunn  Robert O. And Bagby 
Marvin O. ( Biodiesel: The Use Of Vegetable Oils 
And Their Derivatives As Alternative Diesel Fuels) 
Oil Chemical Research, National Center For 
Agricultural Utilization Research,  
Agricultural Research Service, U.S. Department Of 
Agriculture,  
Peoria, Il 61604 
4. Barnwal B.K. *, Sharma M.P.  (Prospects Of 
Biodiesel Production From Vegetable Oils In India) 
Alternate Hydro Energy Centre, Indian Institute Of 
Technology, Roorkee 247667, Uttaranchal, India 
Received 7 April 2004; Accepted 7 May 2004. 
 
5.  Atlin R., Cetinkaya S., Yucusu Hs; The 
Potential Of Using Vegetable Oil Fuels As Fuel 
Foe Diesel                   Engines;  Energy Converse 
Manage 2001, 42,Pp. 529-538. 
6. Gui M.M., Lee K.T. , Bhatia S., Feasibility Of 
Edible Oil Vs. Non-Edible Oil Vs. Waste Edible 
Oil As Biodiesel Feedstock, Energy 33 (2008), 
Pp.1646-1653. 
7 . Atlin R., Cetinkaya S., Yucusu Hs; The 
Potential Of Using Vegetable Oil Fuels As Fuel 
Foe Diesel Engines. Energy Converse Manage 
2001, 42,Pp. 529-538. 
8 . Knothe G., Gerpen J.V. And Krahl J. , (2005), 
The Biodiesel Handbook, Aocs Press, Illinois. 
Properties Produced 
biodiesel 
value 
Standard 
value 
Density(kg/m3),  at  
25 oC 
821 805-895 
Specific gravity, at 
25 oC 
0.821 0.805-
0.895 
Kinematic viscosity 
(mm2/s), at 40oC 
4.168 3.85-6.0 
Free fatty acid 
content (%FFA) 
0.97 0.65-2.50 
Moisture content 
(%) 
0.12 0.09-0.25 
Saponification 
value 
199 175-210 
Iodine value 89 72-95 
Cloud point (oC) -1 (-1)-(-7) 
Pour  point (oC) -3 (-3)-(-26) 
Cetane Index 53 38-50 
Page 345
  
9 . B.K Sharma, Industrial Chemistry; Twelfth 
Ed.;Karishna Prakashan Media Ltd.; Meerut, India, 
2001,Pp.1159 
10.  Y. Watanabe, Y. Shimada, A. Sugihara, Y. 
Tominaga, J. Am. Oil Chem. 
Soc. 78 (2001) 703. 
 
11 . Y. Watanabe, Y. Shimada, A. Sugihara, Y. 
Tominaga, J. Mol. Catal. 
B-Enzym. 17 (2002) 151. 
 
 
Page 346
                                                           Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
 
 
*
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
 
Recovery of Chromium from Tannery Effluent 
 
1Hazzaz – Bin – Yousuf, 2Sudipa Ghosh, and 3Dr. A.K.M.A. Quader,  
1
, Department of Petroleum and  Georesources Engineering; Shahjalal University of Science and 
Technology, Sylhet 3114, Bangladesh, email: hazzaz-pge@sust.edu; 2National University of 
Singapore, Singapore;  
3Department of Chemical Engineering, Bangladesh University Engineering & Technology, 
Dhaka, email: quader@che.buet.ac.bd 
 
 
This paper describes the effectiveness of recovering chromium from tannery waste to met 
existing environmental regulation. The treatment involves reaction between Magnesium 
Oxide slurry with chrome bearing tannery effluent. Chromium removal is more effective 
with dilute tannery effluent. 
 
Keywords: Chromium, ETP, Tannery, Chemical engineering, Waste management.  
 
 
 
 
 
INTRODUCTION 
 
Environment is a matter of general concern 
at present times due to the higher degree of 
pollution. Lather processing is one of those 
technologies documented by the 
environmentalists for their pollution 
prospective [5, 8, 10]. Leather and leather 
products are the most commonly used 
commodities in the world. The tannery 
industries are considered pioneers in the 
export sector of Bangladesh because of their 
annual revenue of taka 1500-1600 crore [7]. 
Therefore it is not possible to terminate the 
tannery industries because of there 
contribution to the economy of the country. 
However appropriate steps can be taken in 
order to reduce the pollution from the 
tannery industries. The 207 tanneries located 
in Hazaribagh and Kalurghat of Bangladesh 
involves with US$ 43 billion of formal 
trade. There are about 176 tanneries in 
Hazaribagh on 25 hectors of land where 
90% of them do not equipped with any kind 
of waste treatment facility. The solid and 
liquid effluents discharging from these 
tanneries are directly thrown into the 
Buriganga River resulting severe 
contamination problem. Effluent discharging 
from the tanneries containing chromium 
compound causes an adverse affect on the 
aquatic life and human health. In addition, 
chromium is too expensive to be allowed to 
go freely in the drainage system. Therefore 
Page 347ISBN: 978-984-33-2140-4
  
*
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
 
an effluent treatment (ETP) plant is 
necessary for each tannery to sanitize the 
waste water and to recover and reuse the 
chromium discharging into the environment. 
 
Due to the constant movement of 
environmental and human rights 
organizations, all the 176 tanneries of 
Hazaribagh are relocating in a 200 acre 
industrial area of Savar. According to the 
environmental regulation of Bangladesh, 
each tannery must be equipped with an ETP 
to treat the effluents discharging from it. 
However, construction of ETP for each of 
the plant requires lot of time and money. 
This problem can be solved by building a 
Common Effluent Treatment Plant (CETP) 
for all the tanneries about to be relocated in 
Savar. In this case, the effluents from the 
tanneries will be discharge into the central 
drainage system that leads to the ETP. 
Rather than being a part of a tannery the 
ETP will operate as a single plant. The 
prime objective of the suggested plant will 
involve treating the wastewater as well as 
recovering expensive chromium, which can 
be reused in the tannery.  However, a 
technical study is required in order to 
examine the possibility of constructing such 
type of ETP capable of treating the 
wastewater from the central drainage system 
as well as recover chromium from it. Among 
the two different methods used to recover 
chromium from tannery waste, Magnesium 
Oxide treatment method will be used in this 
project due to its simplicity and extensive 
usage [2, 18]. A medium scale Effluent 
Treatment Pilot Plant has been constructed 
in order to execute the experiments on the 
tannery effluent. The effluents will be 
collected from the central drainage system 
of Hazaribagh where all the wastes from the 
tanneries mixing and flowing towards 
Buriganga. The effluents will be analyzed 
first at the lab and then feed to pilot plant 
where they will be treated by Magnesium 
Oxide. After the treatment, the discharging 
water from the ETP will be analyzed again 
to compute the amount of chromium 
recovered from the effluent. In addition, the 
experiments will be performed at different 
operating condition to optimize the recovery 
and to improve the quality of the effluent 
discharging from the ETP.      
 
 
EXPERIMENTAL SETUP 
 
Recovery of chromium from spent tanning 
after precipitation constitutes an indirect 
means of recycling and reusing the chrome 
in processing. By adopting indirect chrome 
reuse after precipitating the residual tanning 
floats, the tanner can avoid the problem of 
increasing float volume. The principal is 
based on recovering the chrome from floats 
containing residual chrome by means of 
precipitation, separation, and subsequent re-
dissolution in acid for reuse. There are two 
methods to precipitate the chrome [1]. The 
first method involves rapid precipitation 
with sodium hydroxide and Sodium 
carbonate, enhancing coagulation with 
polyelectrolyte, thickening and finally 
dewatering the voluminous sludge by 
filtration. There is another process which 
involves slow precipitation with Magnesium 
Oxide, settling of the suspension, 
decantation of the supernatant and 
subsequent acidification of the relatively 
dense precipitate.  
 
 
In the selected process Magnesium Oxide 
(MgO) is used to separate Chromium from 
the effluent. Because of its low reactivity 
Page 348
  
*
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
 
and solubility Magnesium Oxide (MgO) 
causes chromium to settle as a compact 
sludge. This compact sludge of chromium 
can be separated easily. The settlement of 
chromium depends on pH. Chromium 
Hydroxide is insoluble in the pH range of 8 
to 12. Optimum pH range is from 8.5 to 9 
for better precipitation.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1   Block diagram of the chrome 
recovery process by precipitation with 
Magnesium Oxide (MgO) 
 
 
Almost 30-50% of basic chrome sulfate 
comes with waste chrome liquor after 
tanning. The volume of exhaust chrome 
liquor is 4-6% of total volume of discharged 
wastewater. Its pH is about 3.5-4. 
Chromium (total) content in the wastewater 
is about 500 mg/l from main chrome tanning 
drums [4]. At the beginning Magnesium 
Oxide reacts with the basic chrome sulfate 
and as a result of this reaction hydrated 
Chromium oxide precipitate forming a 
compact sludge. The following reaction 
occurs here. 
 
 
Cr(OH)SO4 + MgO + H2O =Cr(OH)3     + MgSO4 
 
 
From tanning drums, waste liquor moves to 
the discharge drain. From here it is collected 
and placed into the reactor according to the 
capacity of the reactor. After reaction, it 
enters into the settling tank where after 
complete settlement chromium is expected 
to be recovered.   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Sieve 
Holding 
Tank 
Precipitation 
and Settling 
Tank 
Treatement 
Tank 
Storage tank 
NaOH + 
Polyelectrolite 
Treated 
 Effluent 
Recovered 
Cr 
Effluent 
Filter Plant 
H2SO4 
Sieve 
Holding 
Tank 
Precipitation 
and Settling 
Tank 
MgO 
Treatement 
Tank 
Storage 
tank 
H2SO4 Treated 
 Effluent 
Recovered 
Cr 
Effluent 
Page 349
 *
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
 
 
Figure 2   Block diagram of the chrome 
recovery process by precipitation with 
Sodium Hydroxide / carbonate  
 
 
The pilot ETP plant used for the experiment 
consists of three parts; magnesium oxide 
tank, main reactor and settling tank. The 
Magnesium Oxide tank is a 10 liters 
capacity mild steel tank used for MgO 
solution preparation. A polypropylene valve 
has been fixed at the bottom outlet. A 
support structure with top opening for 
stirring/ manual mixing and cleaning (so that 
MgO can flow by gravity into the main 
reactor) is used in this experiment. The main 
chrome precipitation reactor is of a capacity 
of 100 liter is made of flat sheet mild steel 
with fabric reinforced plastic linings using 
bisphenol resin and one layer FRP as surface 
mat outside. The bottom slope is in the 
range of 5-15o. The reactor is equipped with 
a stirrer. The shaft of the stirrer is in 
stainless steel for a length of about 78 
meters with sets of stainless steel blades. 
The stirrer is driven by a 0.37 KW motor, 
which provides constant rotation of 2800-
2900 rpm. Here Magnesium Oxide mixes 
with the basic chrome sulfate and requires 
stirring due to the low reactivity of 
Magnesium Oxide. Afterwards, the liquids 
are transferred to a 100-liter capacity carbon 
steel tank known as settling tank. Here the 
liquid is kept for a day to let the hydrated 
chromium oxide settled. The treated 
effluents are drained through the bottom 
valve and chromium oxide is collected. The 
effluents are treated with sulfuric acid to 
regenerate magnesium oxide. Thus, 
Magnesium oxide can be recycled where the 
remaining effluents are fine enough to be 
discharged into the river. 
 
In the laboratory, experiments were carried 
out three times using the same procedure. 
Samples of three different concentrations 
were treated. First sample contains 30 liter 
of waste liquor. It was diluted to 90 liters. 
Second sample contained 30 liters of waste 
liquor and it was diluted to 60 liters. Third 
sample contains 60 liters of waste liquor in 
absence of any kind of dilution. Before and 
after the reaction following parameters were 
measured for the effluents: pH, total 
dissolved solid (TDS), total suspended 
solid(TSS) and total chromium content.  
 
Alkaline Hypobromite Oxidation method of 
HACH was used to determine Chromium 
(total). Spectrophotometer was set at 540 nm 
wave length. The range of possible 
measurement here is 0-0.700 mg/liter. So, 
dilution was necessary here. 
 
The wastewater was collected from the 
central drainage system of Hazaribagh by 
the roadside where effluents from all the 
tanneries are mixes with each other and 
discharges into the river. After obtaining the 
parameters mentioned above for the 
effluents, amount of Magnesium Oxide 
required for test run was calculated. Because 
of the low solubility of MgO, it is better to 
be used as slurry. When Magnesium Oxide 
solution mixed with the waste liquor 
contained in the reactor, they are stirred for 
10-15 minutes and then transferred into the 
setting tank and left to settle for a day.     
              
RESULT & DISCUSSION 
 
The study was related to the existing chrome 
recovery process in tannery sector. To 
estimate the amount of chemicals required in 
the recovery process, pH measurement in 
Page 350
  
*
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
 
regular basis and periodical Chromium and 
basicity estimations are necessary. On an 
average ratio of the fresh basic chromium 
sulfate and recovered chromium is almost 
7:1.  
 
Run 1 
(300% 
dilution) 
2 
(100% 
dilution) 
3 
(no dilution) 
Inp
ut
 
 
O
utp
ut
 
Inp
ut
 
 
O
utp
ut
 
 
Inp
ut
 
 
O
utp
ut
 
pH 9.65 9.86 7.55 7.76 7.79 7.59 
TDS, 
gm/lit 2.45 2.47 3.28 3.20 7.93 7.98 
TSS, 
gm/lit 0.44 0.60 0.98 0.52 0.63 0.323 
TS, 
gm/lit 2.89 3.06 4.26 3.72 8.56 8.303 
Cr 
(total), 
gm/lit 
1.00 0.19 1.80 0.50 3.40 1.20 
 
Figure 3   Data generated before and after 
the experiments.  
 
Time required for achieving the desired pH 
is comparatively more. Because Magnesium 
Oxide is a slow reacting alkali and pH 
increases slowly after the addition of 
Magnesium Oxide for chromium 
precipitation. Considering the initial 
indication of pH and because of the slow 
reaction of Magnesium Oxide, excess 
amount of Magnesium Oxide is added 
sometimes. This might increase the 
reactivity between chromium and 
Magnesium Oxide but it does not have any 
noticeable effect on the reaction rate. 
The reaction carried out at three different 
dilutions. This will determine the effect of 
the dilution on the extent of chromium 
recovery from the effluent. The reactions are 
also carried out at different stirring and 
settling time. Therefore, it was possible to 
observe and study the rate of reaction in 
terms of three different parameters. 
 
 
Figure 4   Extant of recovery with 
wastewater dilution during the experiment. 
Data shows that the recovery increases with 
dilution.  
 
 
The results determined from the lab tests 
indicates that the amount of chromium 
detected in the output stream of the ETP is 
less than the amount enters in it. Therefore, 
it can be affirmed that, it is possible to 
recover chromium from the central drainage 
system wastewater using the Magnesium 
oxide treatment method. It is also proved 
from the experimental data that the pilot 
ETP designed for the purpose is capable of 
accomplishing the task.        
 
Analyzing the results indicate that the 
amount of chromium recovery significantly 
depends on the extent of dilution. The 
amount of chromium recovery increases 
with dilution (figure - 4). That means that to 
increase the recovery the wastewater must 
be mixed with a stream of water. Increase in 
recovery with dilution is not surprising 
because normally reaction rate increases 
with dilution. However, the collected 
wastewater is already diluted enough as 
water from different other sources are 
0
100
0 200 400
C
r 
R
ec
o
v
er
y 
(%
)
Dilution
Effect of Dilution on 
Recovery
Page 351
  
*
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
 
mixing with the chrome liquor.  Therefore, 
chrome recovery will be high even if diluted 
water will not be mixed during the 
operation. 
 
 
 
Figure 5   Variation of pH with Dilution. 
Experimental results indicate that dilution 
has no significant effect on the pH of the 
effluent. 
 
 
 
 
 
Figure 6   Variations of TDS, TSS and TS 
with Dilution. Experimental results indicates 
that dilution  
 
The pH of the tannery wastewater recorded 
in the laboratory was 8-10 (figure - 4), 
which matches with the international 
benchmark standard of wastewater regarding 
pH. Therefore, dilution is necessary to adjust 
the pH of the discharged wastewater. It is 
also evident from the results that the amount 
of total dissolved solid (TDS) increases and 
total suspended solid (TSS) decreases after 
the ETP treatment. The increase in TDS 
value was observed because the discharged 
effluents were tested before the sulfuric acid 
treatment. Therefore, the effluents contain 
Magnesium sulfate dissolved in it.            
 
 
CONCLUSION 
 
Characterization of the tanning process 
revealed that, on a mass basis, a majority of 
the Chromium, which is lost from the 
process, is lost in the liquid fraction as 
soluble Chromium. Chrome recovery is an 
indirect way if recycling chrome in the 
lather production as it enables the tanner to 
avoid problems attributed to the 
accumulation of the float volume. Adopting 
this method of chrome recovery and 
employing it to treat the wastewater of the 
0
20
0 100 200 300 400
p
H
Dilution
Variation in pH with 
dilution
01
0 100 200 300 400
T
D
S
 (
g
m
/l
it
)
Dilution
Effect of Dilution on 
TDS of Effluent
01
0 100 200 300 400T
S
S
Dilution
Effect of Dilution on 
TSS of Effluent
01
0 100 200 300 400
T
S
 (
g
m
/l
it
)
Dilution
Effect of Dilution on 
TS of Effluent
Page 352
 *
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
 
central drainage system of the tannery 
complex was the prime objective of the 
project. The laboratory data generated 
during the experiment suggests that the 
Magnesium oxide method is suitable for 
recovering chromium from the wastewater. 
Experimental data are also suggests that the 
process do not need any kind of dilution. 
Therefore, it can be concluded that building 
a CETP that can treat the wastewater and 
recover chromium is technically possible 
and it can be implemented at the industrial 
area of Savar where the tanneries are going 
to be relocated. 
 
In this study, the recovery process is 
optimized only in context of the dilution, 
stirring time and settling time. However, 
there are other parameters involve that 
contains a significant effect on the recovery 
of chromium. Therefore, these parameters 
need to be investigated in order to optimize 
the recovery of chromium as well as tannery 
waste management.  
 
In addition, the economical feasibility of 
building a CETP also needs to be 
investigated. According to DoE, about three 
thousand tons of tannery waste has been 
discharged into the river daily [6]. 
Therefore, it needs to be observed whether a 
CETP is capable of treating this much 
amount of wastewater. A study should also 
be performed on other chrome recovery and 
waste treatment process to determine the 
most suitable process to recover chromium 
from tannery wastewater in terms of both 
technical and economical point of view.               
 
 
AKNOWLEDGEMENT 
 
The authors wish to thank all the operators 
and officers of Bay Tannery for their 
technical support in accomplishing the task. 
The authors also would also like to 
acknowledge with gratitude the service 
rendered by the technicians and staffs of 
Mass Transfer Laboratory and 
Environmental Laboratory of Chemical 
Engineering Department of BUET. 
Furthermore the HACH is thanked for 
supporting this work. 
 
 
REFERENCE 
 
[1]  Abass, E., Masdaghinia, A. and 
Reza, V., “Chromium (III) 
removal and recovery from 
tannery wastewater by 
precipitation process,” American 
Journal of Applied Sciences 2 
(10): 1471-1473, 2005. 
[2] Awan, M. A. , Baig, M.A., Aslam, 
M.R. and Ijaz, N., “Recovery of 
Chromate from tannery 
wastewater”. 
[3] Black, J.A., Water Pollution 
Technology, Restone Publishing 
Company (1977). 
[4] Bosnic, M., Bulijan, J. and 
Daniels, R.P., “Pollutions in 
Tannery Effluents” 
[5] Chakroborti, S., “Chromium-the 
killer” , journal of Indian lather 
trade association. 
[6] CP fact sheet, Chromium 
Recovery from Spent Chrome 
Liquor. 
[7] Environmental Quality Standards 
(EQS) for Bangladesh, 
Department of Environment, 
Government of People’s Republic 
of Bangladesh (1991). 
Page 353
 *
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
 
[8] Devnath, A., Tannery Troubles, 
Star Weekend Magazine (2000). 
[9] Dutta, S.S., An introduction to 
Principles of Lather Manufacturer, 
3rd Edition, Indian Leather 
Technologists Association (1985). 
[10] Environmental, Health, and Safety 
Guidelines in Tanning and Lather 
Industry. 
[11] Huda, M.N., Farouk, A., Ahmed, 
F. and Islam, A.B.M.M.A., The 
Leather Goods Manufacturing 
Industry, Bureau of Economic 
Research (1962). 
[12] Kundu, S.K., Ghosh, A.K., Waster 
Chrome liquor Treatment and 
Regeneration in Tannery. 
[13] Ludvik, L., Chrome Balance in 
Leather Processing. 
[14] Ludvik, J., Chrome Management 
in the Tanyard. 
[15] Ludvik, L., The Scope of 
Decreasing Pollution Load in 
Leather Processing. 
[16] Othmer, Donald and Kirk, F., 
Encyclopedia of Chemical 
Technology, Volume 14, 3rd 
Edition, John Willy & Sons. 
[17] Pao, P.G., and Others, Clean 
Technology, Leather – The 
International Journal (1997). 
[18] Rajmoni, S., “A System for 
Recovery and Reuse of Chromium 
from Spent Tanning Liquor using 
Magnesium Oxide and Sulfuric 
acid”. 
[19] Rajmoni, S., Environmental 
Management in Indian Tanneries, 
Journal of Indian Leather Trade 
Association, (1994).    
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Page 354
 *
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
 
        
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Page 355
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Second B. Author,  
E-mail: somebody@somewhere.com 
Rule of Mixture for Predicting the Elastic Modulus of polymer-fiber and 
polymer-fiber-particle Composites: A discussion 
 
M. A. Islam1 and K. Begum2 
Department of Chemical Engineering and Polymer Science, Shahjalal University of Science 
and Technology (SUST), Sylhet 3114, Bangladesh 
E-mail: mislam@sust.edu1, china@sust.edu2 
 
Abstract 
An analysis has been done on the models proposed in Literature for predicting the elastic modulus of fiber 
reinforced polymer composites (FRPC). These models have been applied for polymer-fiber as well as for 
polymer-fiber particle composites system. For polymer-fiber composites Rule of Mixture ( RoM) and for 
polymer-fiber-particle composites Rule of Hybrid Mixture (RoHM) models have been analyzed in this 
article. RoM can be divided into two forms, depending on the direction of the applied stress on the fiber in 
the composite material, parallel and series models. RoHM is parallel model for more than two components 
system. The experimental data reported in different specialized research journals regarding elastic modulus 
of different FRPC has been fitted to the models. The probable variation in the averaged value of the modulus 
of elasticity of the polymer and the fiber has been taken into consideration and the validity of the Parallel, 
Series model has been tested with an acceptable deviation range of the prediction value.   It is found the 
parallel and series models, by no means, predict the modulus within an acceptable deviation factor of 0.1. 
But RoHM model satisfactorily fits the experimental data.  
 
Keywords: Fibers, Polymer-matrix composites (PMCs), Short-fiber composites, Mechanical properties, 
Prediction model 
 
 Introduction 
Fibers are introduced in polymer compositions in 
order to improve their mechanical properties. Both 
synthetic and natural fibers are used for the 
purpose; although in recent years, polymer-matrix 
composites with natural fibers have received 
considerable attention both in the literature and in 
industrial applications due to their improved 
mechanical properties, significant processing 
advantages, low cost and low density [1]. 
Literature data on fiber-reinforced polymer 
composites (FRPCs) have been accumulating, but 
reports on theoretical modeling of 
composition/property relation of these composites 
are scarce [2-5].  
The modulus of elasticity can be considered as one 
of the most significant mechanical properties of 
materials for engineering design of structure.  
The elastic properties of fiber reinforced 
composites can be experimentally determined or 
derived from a variety of mathematical models.  
A number of models are available in the Literature 
[6-11] for the prediction the Young’s modulus of 
the polymer-fiber composites as well as for 
polymer-fiber-particle (hybrid composite) 
composites. For polymer-fiber composites the  most 
frequently discussed ones are  (i) Rule of Mixture 
(RoM) (ii) Halpin-Tsai (HT), (iii) Modified Halpin-
Tsai (MHT) (iv) Nairn (v) Mendel (vi) Hirsch (vii) 
Cox and (viii) Bowyer-Bader (BB) model [2,3] and 
for polymer-fiber-particle composites (i) laminate 
analogy approach (LAA), (ii) Rule of hybrid 
mixtures model [10-11] are frequently used. 
Among all the models of polymer-fiber composites 
the RoM model has the simplest mathematical 
relation that does not have any adjustable 
parameter. The modulus of elasticity of the 
polymer, Ep, and of the fiber, Ef, should be known 
and then the modulus of elasticity of the composite, 
Ec, can be calculated for any volume fraction of the 
fiber in the composition by this model. But those 
experienced in the field shall admit that this model, 
in most cases, do not predict the modulus of 
elasticity of the composites satisfactorily. The 
experimental observations and analysis of Facca et 
al [2] and Kalaprasad  et al [3] provide evidence for 
that. The experimentally observed value of the 
modulus of elasticity of the composites always lies 
in between those predicted by the parallel and 
series  models.  
Recently Mirbagheri et al [10] conducted intensive 
research on hybrid composites consisting of ternary 
mixture of wood flour, kenaf fiber and 
polypropylene, and found that the Rule of Hybrid 
Mixture (RoHM) could successfully describe the 
modulus of elasticity of the polymer composites. 
Page 356ISBN: 978-984-33-2140-4
 The RoHM in elaborate form practically is reduced 
to the Parallel model for a three-component system. 
Rule of mixture (RoM)  
The simplest available model to predict the elastic 
modulus of polymer-fiber composite is the rule of 
mixtures (RoM). Depending on the direction of the 
applied stress on the fiber of the composite 
materials (Figure 1) RoM can be divided into two 
forms: parallel model and series model. 
 
Parallel Model [6] 
In this case the load (equivalent to stress z), 
applied parallel to the direction of the fibers, tends 
to stretch the fiber and the polymer to the same 
extent. Therefore, by assuming that fiber, polymer 
and composite experience equal strains, we can 
write 
 
1with   
  


pf
ffppc EEE


 
(1) 
 
 
where the subscripts c,   f  and  p stand for 
composite, fiber and polymer matrix respectively,   
Ec ,  Ef  and Ep, are the elastic moduli, and f  and  
p , are the volume fractions.  
The Eq. (1) can be theoretically derived for a 
composite system, in which the fibers are aligned 
along z-axis and propagate through the whole 
length of the body as shown in Figure (1). A force 
(equivalent to stress z) is acting along the z-axis. 
Then the modulus of elasticity along z-axis is given 
by Eq. (1) [12]. This equation is very attractive with 
superficially interesting features: a) This equation is 
apparently valid for f (0, 1) and b) for f =0, 
Ec =Ep, and for f =1,   Ec =Ef.  
The Eq. (1) is derived for long fibers (The fiber 
length is equal to the height of the object), but in 
most cases, attempts are made to apply it for 
composites with short-fibers distributed randomly. 
It is also ignored that beyond certain value of f  
(far below unity), the composite loses its integrity 
and the eq. (1) can not be applied for high value 
of f . 
There is a popular perception that the Eq. (1) is a 
theoretical model as it can be derived for the 
distribution of fibers along the axis of elongation. 
For short-fiber reinforced composites, the equation 
is not valid at all. The concept ‘Modulus of 
Elasticity’ can not be considered similar to mass or 
energy that some sort of law of conservation will be 
validated for it and also whatever short the fibers 
may be, the composite is not a homogeneous 
solution to expect the additivity of the some of the 
property of the components.  Therefore, it is not 
unusual that the experimental data on modulus of 
elasticity vs. volume fraction is not described by the 
model represented by Eq. (1) as reported in the 
literature [2, 3]. 
 
Series Model [6] 
In this case, the fiber, polymer and composite 
experience the equal stress but the produced strains 
for each are different. The elastic modulus, Ec, of 
the composite is given as:  
 
p
f
f
f
c
EE
E
 


1
1
 
 
(2) 
One could expect that the equation (2) would be 
derived if the load (equivalent to the stress x or y) 
is applied to the object in Figure (1) along x or y 
axis. This is, however, not the case. For the 
derivation of the Eq. (2), the fiber and polymer 
material are arranged in a manner as shown in 
Figure (2), and a load is applied along y- direction 
and then the Eq. (2) is derived [12]. If the load is 
applied to the object Figure (2) along x- or z- axis, 
the parallel model or the Eq. (1) will be obtained.  
Such an arrangement, however, is not realistic for a 
composite, as this does not ensure adhesion 
between the polymer and the fiber. This is not a 
composite; rather separate elements arranged in 
series.  Thus, the Eq. (2) is not a theoretical model 
for short-fiber reinforced polymer composites. The 
series model (Eq. 2) also fails to describe the 
experimental data on modulus of elasticity of 
polymer-fiber composites vs. volume fraction of the 
fibers [2, 3]. 
 
 
RoHM Model [11]  
In a hybrid composite more than one type of fibers 
are used in a single polymer. A hybrid 
particle/short-fiber/polymer composite consisting of 
two single composite systems, namely 
particle/polymer and short-fiber/polymer systems 
and the two systems then form the hybrid 
composite. Here it is assumed that there is no 
interaction between the two single systems and the 
iso-strain condition is applied to the two single 
systems. 
Then the elastic modulus, cE , of the hybrid 
particle/short-fiber/polymer composite system can 
be evaluated from the RoHM by the following 
equation: 
2211 ccccc EEE    (3) 
Page 357
 Where 1c  and 2c  are, respectively, the relative 
hybrid volume fraction of the particle/polymer 
system and the short-fiber/polymer system, and  
121  cc   
and 
fp
p
c 



1  and 
fp
f
c 



2 , where 
( fp   ) is the total reinforcement volume 
fraction and should be used as reinforcement 
volume fraction for calculation the elastic modulus 
(Ec1 and Ec2) of both single composites. 
Therefore 
)(1 fppmmc EEE    
and 
)(2 fpfmmc EEE    
Now from Eq. (3) it can be written 
 
ffppmmc
fp
f
fpfmm
fp
p
fppmmc
EEEE
EE
EEE













)]([
)]([
 
 
 
 
 
 
 
 
(4) 
 
Eq (4) is also a RoM model for hybrid composite 
system. 
 
Illustration of the model prediction 
Before going for validation of the models, one has 
to be very cautious about the quality of data being 
used. For the validation of the models, the first two 
parameters that are essential to be known are the 
modulus of elasticity of the polymer and the fibers. 
It is a well-known fact that the polymer properties 
vary in a wide range depending on the chemical 
composition, chain-branching, molecular mass 
distribution and the processing parameters. 
Therefore, any value of Ep found in literature could, 
by no means, be considered an acceptable one 
without reservations. The properties of natural 
fibers also vary in a wide range. The variation is 
caused by the fluctuation in environmental 
conditions (moisture, soil, temperature etc) in the 
regions, in which the fibers grow and also on the 
processing methods. Even in the same batch, the 
properties of fibers have statistical distribution. For 
this reason, it must be defined first in what range 
the prediction would satisfy the requirements to the 
design of structural material.  
 
Tolerable deviation from the values predicted by 
the models 
Let’s assume that the coefficient of deviation in the 
value of the parameters Ep and Ef are respectively p 
and f; i.e.  p= Ep/Ep and f = Ef/Ef. The deviation 
in the value of the parameters Ep and Ef will 
definitely reflect in the deviation of the estimated 
value of Ec. 
Equation for error calculation in  parallel model 
[13]: 
Following the Eq. (1), we have  
           ppffc dEvdEvdE   (5) 
Then the deviation in the elastic modulus of the 
composite, Ec, is given by 
           ppffc EvEvE   (6). 
Substituting Ef  and Ep with their equivalents, the 
Eq. (6) is converted into eq. (7).  
           pppfffc EvEvE    (7) 
For every volume fraction vf, the error Ec in the 
estimation of Ec will be determined from the Eq. 
(7).  
 
Equation for error calculation in Series model [13]: 
Following the Eq. (2), we have 









p
p
p
p
f
f
f
f
c
c
c
E
dE
E
v
E
dE
E
v
E
E
dE
..  
(8) 
Then the deviation in the elastic modulus of the 
composite, Ec, is given by 







 




p
p
p
p
f
f
f
f
c
c
c
E
E
E
v
E
E
E
v
E
E
E
..  
(9) 
Substituting Ep and Ef  with their equivalents, the 
Eq. (9) is converted into Eq. (10).  










p
p
p
f
f
fc
c
c
E
v
E
v
E
E
E
  
(10) 
For every volume fraction vf, the error in the 
estimation of Ec will be determined from the Eq. 
(10).  
For simplicity, let’s assume that p= f= 0.1. Then 
for both the Eq. (7) and the Eq. (10) (corresponding 
to parallel and series model), Ec= 0.1Ec. This 
would mean that if the experimentally obtained 
value of the modulus of elasticity of the composite, 
Eexp, with a given composition lies within the range 
of (1.00.1) Ec, the prediction may be considered 
satisfactory. 
Validation of parallel and Series model 
These two models do not have any adjustable 
parameter. If the experimental value of modulus of 
elasticity Eexp vs. fiber volume fraction data is 
plotted and the curve lies in the area surrounded by 
the prediction curves 0.9Ec and 1.1Ec, then the 
Page 358
 prediction might be considered satisfactory. This 
procedure of validation is applied to some polymer 
fiber composites such as High density 
polyethylene (HDPE)-E-glass, (HDPE) -Hardwood 
A, HDPE -Hardwood B, HDPE –Hemp, HDPE -
Rice hulls, Low density polyethylene (LDPE)-
Sisal and Polypropylene (PP)-Flax system. The 
data were collected from the Literature [2, 3, 4, 
14]. The Figures were drawn (For the economy of 
space, only four of the mentioned figures are 
presented in this paper) and it was found that in all 
cases, the experimental curve, Eexp, lay far apart 
from the area surrounded by the curves 0.9Ec and 
1.1Ec as predicted by the parallel and series model. 
Such was the picture with the prediction by the 
parallel and series model on all mentioned 
systems..  
Thus, it is hard to rely on the parallel and series 
model to predict the modulus of elasticity of a 
polymer-fiber composite. Facca et al [2] have also 
excellently demonstrated these failures. 
Validation of RoHM Model 
For the validation of the RoHM, Mirbagheri et al. 
[10] accepted as the modulus of elasticity of wood 
flour and kenaf fiber those values, which were 
obtained by back-calculation from the experimental 
data of the binary composition of polymer-fiber and 
polymer-particles. Such approach seems logical as 
the fibers have anisotropic structure and their 
modulus can not be considered equal in all 
directions.  
Conclusions 
1. To analyze the Young’s modulus of 
polymer-fiber composites, parallel and 
series models (RoM) were applied to 
previous  experimental  result. 
2. The analysis was done by assuming a 
tolerable deviation of 10% from the 
calculated  value. 
3. It was found that  for all compositions, the 
experimental curve lay far apart  from the 
area surrounded by the curves 0.9Ec and 
1.1Ec. 
4. Finally, this suggests   that Parallel, Series 
models totally fail to predict the Young’s 
modulus of polymer-fiber  composites. 
5. But surprisingly it was found that RoHM  
model satisfactorily predicted the elastic 
modulus of particle/short- fiber/polymer 
composites. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1   Distribution of the fibers oriented along 
z-axis and propagating through the whole length of 
the cube. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 2 Three-dimensional view of a 
‘hypothetical’/model arrangement of fibers and 
polymer matrix: parallel arrangement as viewed 
along z- and x-axis, and   series arrangement as 
viewed along  y-axis. 
 
 
 
y 
 x 
z 
x 
z 
y 
z 
y 
  x 
Page 359
  
 
30
25
20
15
10
5
0
Y
ou
ng
's 
M
od
ul
us
,  
 E c
  ,
  (
G
Pa
)
0.40.30.20.10.0
Volume fraction E-glass fibers, f
Parallel1.1
Parallel0.9
 
 
 
Figure 3    Young’s modulus Ec vs. volume fraction 
of the fiber, f , in HDPE-E-glass composite. The 
symbol   represents the experimental data 
collected from Facca et al [2]. The interpretation of 
the symbols is given in the text. 
 
 
20
15
10
5
0
Y
ou
ng
's 
 m
od
ul
us
,   E
c  
(G
Pa
)
0.50.40.30.20.10.0
Volume fraction of flax fibers, f
Parallel1.1
Parallel0.9
 
 
 
Figure 4    Young’s modulus Ec vs. volume fraction 
of the fiber, f , in PP-flax composite. The symbol 
  represents the experimental data collected from 
Peponi et al [4]. The interpretation of the symbols 
is given in the text. 
 
 
 
 
 
14
12
10
8
6
4
2
0
Y
ou
ng
's 
M
od
ul
us
,  
 E c
  ,
 (G
Pa
)
0.40.30.20.10.0
Volume fraction E-glass fibers, f
Series1.1
Series0.9
 
 
 
 Figure 5    Young’s modulus Ec vs. volume 
fraction of the fiber, f , in HDPE-E-glass 
composite. The symbol   represents the 
experimental data collected from Facca et al [2]. 
The interpretation of the symbols is given in the 
text. 
 
2.0
1.5
1.0
0.5
0.0
Y
ou
ng
's 
 m
od
ul
us
,  
 E c
 , 
  (
G
Pa
)
0.50.40.30.20.10.0
Volume fraction of flax fibers, f
Series1.1
Series0.9
 
 
 
Figure 6    Young’s modulus Ec vs. volume 
fraction of the fiber, f , in PP-flax  composite. 
The symbol   represents the experimental data 
collected from Peponi et al [4]. The interpretation 
of the symbols is given in the text. 
 
 
 
 
 
 
Page 360
 References 
[1] Joseph PV et al., (1999), Composites Science 
and Technology, 59,  pp. 1625-1640.    
[2] Facca AG  et  al., (2006), Composites: Part A,  
37, pp. 1660.-1671. 
[3] Kalaprasad G et al., (1999),  Journal of 
Materials Science, 32, pp. 4261-4267. 
[4] Peponi L et al., (2008),  Polymer Composites, 
29,  pp. 321-325.  
[5] Xue Y et al., (2007), Composites Part B: 
Engineering, 3, pp. 152-158.  
[6] Sih GC et al., (1995), Advanced   Technology 
for Design and Fabrication of composite Materials 
and Structures. Kluwer Academi publishers. 
[7] Jones RM., (1975), Mechanics of composite 
material. United States: Hemisphere Publishing 
Corporation. 
[8] Halpin JC and Tai SW., (1969), Effects of 
environmental factors on composite materials. 
AFML-TR 7-423 J. 
[9] Halpin JC and  Kardos JI., (1976), Polym Eng 
Sci , 16(5), pp. 344-352. 
[10] Jamal M et al., (2007), Iranian Polymer 
Journal, 16(4),  pp.  271-278. 
[11] Fu  S. Y. et al., (2002), Composites: Part B, 
33, pp. 291-299. 
[12] Matthews FL and Rawlings RD., (1994), 
Composite Materials: Engineering and Science. 
London: Chapman & Hall,  pp. 19. 
[13] Akhnazarova S and Kafarov V., (1982), 
Experiment optimization in Chemistry and 
Chemical  Engineering. Moscow:  Mir Publishers. 
[14] Joseph K. et al., (1999),  Revista Brasileria de   
Engenharia Agricola e Ambiental,  3,  pp. 367-379.   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Page 361
 
 
 
 
STUDIES ON THE PROPERTIES OF EPOXY-BASED POLYMER 
MODIFIED MORTAR   
Md. Mostafizur Rahman1,*, Md. Akhtarul Islam2 and Mainuddin Ahmed 3 
2 Department of Chemical Engineering and Polymer Science, Shahjalal University of Science and 
Technology (SUST), Sylhet- 3114, Bangladesh. Tel: +880 (0)821 713491, Fax: +880 (0)821 713491 
E-mail: mislam@sust.edu 
 1,3Housing and Building Research Institute (HBRI), Darus-salam, Mirpur, Dhaka-1216, Bangladesh 
Tel: +880 (0)2 8060989, Fax: +880 (0)2 8060773 E-mail: mostafizur_cep@yahoo.com 
 
 
The main objective of the study is to improve the physical, chemical and mechanical properties of conventional 
mortar using epoxy based polymer as a binding material. The authors have conducted a series of tests on epoxy 
resin modified mortar with view to compare their performance with conventional Portland cement mortar. 
Naturally occurring local fine aggregate obtained from Sylhet has been characterized and used as fine aggregate. 
Specimens were prepared with varying polymer contents keeping the remaining variables of the composition 
constant. The properties under control are compressive strength, flexural strength, tensile strength, water uptake, 
porosity, resistance to chloride ion penetration and chemical resistance to acid and salts. The result of this study 
shows that the addition of polymer to mortar improves mechanical strength (Compressive strength, Flexural 
strength and Tensile strength), resistance to chloride ion penetration, chemical resistance to acid and salts and 
decreases water absorption and porosity. The variation of concentration of the polymer materials is found to be 
key factor determining the mortar properties. The effects of other variables on the properties of polymer 
modified mortar have also been discussed. It is concluded that owing to the exceptionally high resistance to 
water permeability, salt and acid, polymer modified mortar can be used in hydraulic structures in coastal area, 
drainage systems, canal networks, chemical plants etc, and hence it has high perspective in Bangladesh.  
 
Keywords: Mortar, Polymer, Strength, Porosity, Chemical resistance 
 
1. INTRODUCTION 
Masonry mortar can be defined as a mixture of 
Portland cement, mineral aggregates (sand) with 
water, which presents hardening capacity and 
adherence. Masonry mortar functions are: (i) 
bond units of masonry; (ii) distribute loads; (iii) 
absorb deformations; (iv) seal joints. Masonry 
mortars can be employed for joining 
bricks/blocks, rendering and grouting [ACI 
548.3R-95, 2000]. The incorporation of 
polymers greatly improves strength, adhesion, 
resilience, impermeability, chemical resistance 
and durability properties of mortars and concrete 
[Ohama, 1987, Mirza et al, 2002 and Mehta & 
Monteiro, 1993]. These properties make Polymer 
modified mortar (PMM) a suitable material for 
making various structural and non-structural pre-
cast products, repair of structural members, 
waterproofing, anticorrosive and decorative 
finishes, overlay of pavements, bridges and 
industrial floors]. In modern concrete 
construction and repair works the, role of 
polymers is increasing day by day. Polymers are 
either incorporated in a cement–aggregate mix or 
used as a single binder. The composites made by 
using polymer along with cement and aggregates are 
called polymer-cement mortars (PCM), while 
composites made with polymer and aggregates are 
called polymer mortar (PM). A number of 
thermoplastic or thermosetting polymers are used in 
modifying mortars and concrete. These are used in 
various forms like: liquid resins, latexes, 
redispersible powders and water-soluble 
homopolymers or copolymers [Ohama, 1987]. 
Several studies have been carried out to evaluate 
different properties of polymer mortars with various 
thermoplastic and thermo setting polymers. 
Aggarwal et al. (2007) studied the properties of 
polymer modified mortars using epoxy and acrylic 
emulsion, and found that these materials have 
superior strength properties and better resistance to 
the penetration of chloride ions and carbon dioxide 
than those PMCs based on vinyl acetate, copolymers 
of vinyl acetate–ethylene, styrene–butadiene, 
Corresponding Author:  
Md. Mostafizur Rahman 
E-mail: mostafizur_cep@yahoo.com 
Page 362
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
 
 
 
styrene–acrylic, and acrylic-styrene-butadiene 
rubber emulsions. 
Kim et al. (1999) studied the properties of 
poly(vinyl alcohol) (PVA) modified mortar and 
concrete with up to 2 wt% polymer (calculated 
based on cement) and compared the structure and 
properties of polymer modified mortar/concrete 
with those without poly(vinyl alcohol). The 
authors observed that poly (vinyl alcohol) 
modified mortar showed merely unchanged 
compressive strength and slower absorption of 
water as compared to the unmodified mortar, 
which was an indication of lower permeability of 
the polymer-modified mortar. 
Mandel and Said (1990) studied the effect of an 
acrylic polymer on the mechanical properties of 
mortar and found that the mechanical properties 
of mortar and the adhesion between mortar and a 
steel fiber would improve substantially with the 
addition of an acrylic polymer in the system. 
Ohama et al. (1991) investigated the effect of the 
monomer ratio on the typical properties of the 
polymer-modified mortars with styrene-butyl 
acrylate latexes. The author found that the 
properties (pore-size distribution, flexural and 
compressive strengths, water absorption, and 
drying shrinkage) are affected to a great extent 
by both monomer ratio and polymer-cement 
ratio. Neelamegam and Ohama (1983) conducted 
a series of tests on various types of polymer and 
resin mortar composites and observed superior 
properties of polymer modified mortar (PMM) 
than those of ordinary cement mortar. Jain 
(1992) made a study on the applications of 
polymer cement mortar and found that the 
adhesion of mortar and concrete to the old 
surface could be increased with the addition of 
suitable polymer. The use of polymer mortars for 
rehabilitation of distressed reinforced concrete 
structures, providing seamless flooring in large 
areas and construction of specialized jobs was 
also reported in the paper. Limaye and Kamat 
(1992) studied the effect of six types of polymers 
in cement mortar and found significant 
improvement in energy absorption capacity of 
these polymer modified systems. 
But in Bangladesh, however, systematic research 
in the field of this structural material has merely 
initiated only few years back (Rahman et.al, 
2010). Following these studies, an experimental 
observation on the properties of polymer 
modified mortar materials based on epoxy resin 
has been reported in this paper. Mechanical 
strength (compressive strength, tensile strength 
and flexural strength)  physical properties 
including water absorption, chloride ion penetration 
and porosity and chemical properties (chemical 
resistance to acid and salts) of polymer modified 
mortar formed with different compositions are 
studied and compared with those of unmodified 
Portland cement mortar in this investigation. 
 
2. EXPERIMENTAL 
 
2.1 Materials 
Technical grade epoxy resin based on 
Epichlorohydrin and bisphenol-A was collected from 
local market. Epoxy resin used in the experiment had 
a viscosity of 3600cps at 300C, density of 
1.15gm/cm3 and pH value of 7.72. Naturally 
occurring silica sand collected from Sylhet, 
Bangladesh was washed, dried and sieved. The 
particle sizes of Sylhet sand was ranged from 
0.15mm to 2.36mm. Ordinary Portland cement was 
used in the experiment. The properties of the cement 
are described in The Table 1. 
 
Table-1: Properties of Portland cement used in the 
experiment 
          
Test performed  Result 
1. Fineness test  0.068% 
2. Setting time    
 Initial  2 hours 
      Final  3 hours 
3. Compressive strength  
 7 day  15 MPa 
 28 day  19 MPa 
 
2.2 Preparation of mortar specimens 
Composition of conventional mortar was mixed 
following ASTM C305 standard method and 
technique. Compositions of different types of mortar 
specimens are detailed in Table-2. Addition of 
polymer in the composition required some 
modification of the method as pretreatment of 
polymer and sequence of addition of the components. 
The epoxy resin, being in liquid state added without 
pre-treatment.  
 
2.2.1 Polymer cement mortar 
Cement, sand and water were first mixed using 
ASTM C305 procedure, and then polymer emulsion 
was mixed with the pre-wetted composition. The 
fresh composition was cast into a steel mould on a 
vibrating table. For compression test, a cube size 
steel mould with dimensions 50.8mmX50.8mm 
X50.8mm was used. These specimens were used for 
porosity measurement, water absorption and 
chemical resistance test as well. For the test of tensile 
Page 363
 
 
 
strength, briquettes (dumbbell shaped specimen) 
were prepared following the procedure as 
prescribed by ASTM, C190 of mortar specimen. 
For the determination of the coefficient of 
thermal expansion and chloride ion penetration, 
bar type mortar specimen were prepared with 
dimensions 304.8mmX25.4mm X25.4mm.  
 
2.2.2 Polymer mortar 
Polymer mortar was prepared by mixing silica 
sand with epoxy-based polymer. No Portland 
cement was added. The mixing procedure and 
the size of the specimen were the same as those 
of conventional mortar. The mixing procedure 
and the size of the specimen were the same as 
those of conventional mortar. 
The mortar specimens were demolded after 24 
hour of molding and then stored in water in case 
of conventional mortar and polymer cement 
mortar but curing under water is not required for 
polymer mortar since there is no Portland cement 
in the specimen. Infact, Polymer mortar 
specimens were cured in atmosphere until tested 
(either 7 or 28 days).  
 
Table -2: Ratio of ingredients used in mortar 
 
2.3 Methods 
 
2.3.1 Determination of Water absorption 
kinetics and equilibrium uptake and porosity 
of mortars 
The 50.8mm cube size mortar samples were 
dried at 110o C in an oven and then taken in 
desiccators to cool down to room temperature. 
The process was repeated until a constant weight 
W0 of the specimen is attained. Then the dried 
sample was put under water in a beaker at room 
temperature. At a predefined time of interval, the 
samples were taken out, the water adhered to the 
surfaced were wiped by cloth and weighed. Then 
the sample is returned in the beaker. In the 
beginning, the measurement was done at an 
interval of 1 hour and at the end- at an interval of 
6 hours.  
Water absorption at a given time t and equilibrium 
water uptake A at t  are calculated by the 
following formulae: 
1/ 0  WWA tt  (1) 
and 
 Where Wt is the weight of the wet sample at time t 
and W is the weight at equilibrium.  
 
00 /VWa   (3) 
w
T WWV
W


/)( 00
0


  
(4) 
and 
Ta  /1  
(5) 
 
Where a, T and  are respectively apparent 
density, true density and porosity; V0 is the bulk 
volume of the sample, W is the weight of the wet 
sample at equilibrium and w is the density of water. 
 
2.3.2 Chemical Resistance tests 
The cured specimens were tested for chemical 
resistance at room temperature in accordance with 
standard RILEM PC-12 “Method of test for chemical 
resistance of polymer concrete and mortar” [RILEM 
PC-12]. The types of test solutions used were as 
follows: 10% sulphuric acid (H2SO4) and 10% 
sodium chloride (NaCl). The test specimens after 
record of their weight were soaked in solutions for 
periods of time of 7 days. After immersion period, 
the appearance of test specimens was visually 
checked, cleaned by running tap water and dried in 
oven at 1100 C temperatures in an oven until constant 
weight and weight was measured.  
After that, compressive strength was performed on 
the specimens according to ASTM C109. Test results 
were compared with those obtained from 
compressive strength test of specimens untreated in 
solutions. Mass change and compressive strength 
change of the specimens was calculated by the 
following equation: 
 
Mass change = [(Mr-Mi)/Mi]* 100 
 
Where Mi is the mass (gm) of the specimens before 
immersion and Mr is the mass (gm) after test period. 
 
Compressive strength change = [(Cf-Ci)Ci]*100 
 
Where, Ci is the compressive strength (MPa) of 
untreated specimens and Cf is the compressive 
strength (MPa) of test specimens treated solutions for 
7 days. 
Mortar/t
ype 
Ceme
nt 
Sand W/C Polymer 
Normal 
Mortar 
1 2.75 0.45 - 
Polymer 
cement 
mortar 
1 2.75 0.45 0.04-
0.26 
Polymer 
mortar 
- 10 - 1-1.5 
1/ 0   WWA  (2) 
Page 364
 
 
 
 
2.3.3 Measurement of compressive and tensile 
strength  
The compressive strength of the specimens was 
measured by Universal Testing Machine (Model 
No. TIB/M. C; Capacity-300 Ton). 
 
3. RESULTS and DISCUSSION 
 
3.1 Compression tests of mortar 
specimens 
It is important to measure the mortar 
compressive strength since this test gives a good 
overall indication of the quality of the mortar or 
concrete and its mechanical properties. Also, to 
increase the abrasion-erosion resistance, the 
compressive strength must be higher to enable 
the mortar to successfully handle the repeated 
impact. The ultimate compressive strength of the 
polymer cement mortar and polymer mortar are 
shown in the Figs. 1 and 2 respectively. 
 
 
Figure 1. Dependence of the compressive strength on 
epoxy content for polymer cement mortars water-
cured for 7 () and 28 () days 
 
The Fig.1 shows that the compressive strength of 
unmodified water cured Portland cement mortar 
specimen is 17 MPa at 28 days. The compressive 
strength of polymer cement mortar increases 
with the addition of polymer and maximum 50 
MPa strength was indicated by 5 wt.% epoxy 
content (based on sum of the weight of sand and 
Portland cement) polymer cement mortar 
specimen at 28 days curing The point indicated 
by 0 (wt %) in the curve actually denotes the 
result of conventional Portland cement mortar.  
The Fig. 2 shows that the strength gain rate of 
polymer mortar is higher than that of polymer 
cement mortar and unmodified mortar. Polymer 
cement mortar gains about 55% of ultimate 
strength at 7 days curing while, polymer mortar 
gains 85% of that strength at same curing 
interval. 
 
Figure 2. Dependence of the compressive Strength on 
epoxy content for polymer mortars air cured for 7 () days 
and 28 () days 
 
Finally, Polymer mortar prepared with the addition 
of 16 wt.% epoxy (based on weight of sand) provides 
maximum 70 MPa at 28 days atmospheric curing.  
 
3.2 Properties of different types of mortar 
specimens 
Percentage of porosity, apparent density, true 
density, tensile strength and flexural strength are 
determined for unmodified and polymer modified 
different types of mortar specimens. The obtained 
result is summarized in table-3. 
 
Table 3. Porosity, tensile strength and flexural 
strength of different types of mortar specimens 
 
 
The result shows that the addition of polymer 
reduces the porosity and density. It can be explained 
by; the additions of polymer in mortar fill up the 
voids inside the mortar which results the decrease in 
porosity. In case of normal cement–sand mortar, 
water occupied some space in mortar during casting. 
After casting extra water dried out, this causes voids. 
In case of resin modified mortar no cement was 
added so there was not required to add any water. 
This is why in case of polymer mortar porosity was 
not observed. Result shows the porosity of polymer 
mortar is 0.54% which may be an experimental error.  
Tensile strength on the other hand increases with the 
increasing polymer content. Polymer mortar with the 
addition of 16 wt% epoxy (based on weight of sand) 
provides maximum 8.48 MPa tensile strength. 
0
5
10
15
20
25
30
35
40
45
50
0 1 2 3 4 5 6
Epoxy content (w t%)
C
om
pr
es
si
ve
 s
tr
en
gt
h 
(M
Pa
)
0
10
20
30
40
50
60
70
80
8 10 12 14 16 18
Epoxy content (wt%)
Co
m
pr
es
si
ve
 s
tre
ng
th
 (M
P
a)
Types of mortar Poro
sity 
(%) 
T.S 
(MPa) 
F.S 
(MPa) 
Conventional mortar 7.50 2.44 7.50 
5 wt.% Epoxy  
modified PCM 
5.07 5.76 8.60 
16 wt.% Epoxy base 
PM 
0.54 8.48 9.50 
Page 365
 
 
 
Flexural strength increases with the increasing 
polymer content and maximum 9.50 MPa 
Flexural strength of polymer mortar with 
addition of 16 wt% epoxy (based on weight of 
sand) found after 28 days curing.  
 
3.3 Water absorption and chloride ion 
penetration of different types of mortar 
specimens 
Figure 3 shows water absorption by different 
PMM as a function of soaking time t.  The 
Figure shows that initially the absorption rate is 
very fast and then gradually the water uptake 
attains an equilibrium value A - the value being 
highest for normal mortar followed by mortars 
modified by PVA and epoxy resin. The water 
sorption is a result of combined effect of porosity 
and mortar composition. The mortar modified 
with shows higher water sorption than those 
modified with epoxy. It can be explained by the 
hydrophilic nature of PVA. The polymer mortar 
made with epoxy resin shows the lowest water 
uptake. All the experimental results, however, 
categorically show that the mortar modified by 
any of the polymers under investigation 
possesses water resistance higher than normal 
mortar. 
 
 
Fig.3 4. Water absorption kinetics of different mortars. 
() Normal, modified with () 2% PVA, (() 5% 
Epoxy and  (×) 14% Epoxy Polymer mortar 
  
Porosity, apparent density and true density are 
calculated by Eqs. (3-5), and the tensile strength 
measured by Universal Testing Machine are 
presented in Table 3. As shown in the Table, the 
mortar modified by epoxy resin shows lowest 
porosity and highest tensile strength 
demonstrating the superiority among the 
composition studied.  
Similar to water absorption, chloride ion 
penetration also decreases with the addition of 
polymer (Fig.5). In the present investigation, 
reduction of chloride ion penetration is up to five 
times of polymer mortar using 16 wt.% epoxy (based 
on weight of sand) comparative to conventional 
cement mortar. While, reduction in chloride ion 
penetration is up to 50% of polymer cement mortar 
using 5 wt.% epoxy (based on weight of sand and 
cement) comparative to conventional cement mortar. 
This indicates that epoxy modified mortar should 
have more resistant towards chloride ion attack. The 
increased resistance to chloride ion penetration 
makes PMM very useful in application in corrosion 
prone (Saline zone) area. 
 
 
Fig. 5. Effect of polymer addition on chloride ion 
penetration 
 
3.4 Chemical Resistance of different types of 
mortar specimens 
The test results, mass change and compressive strength 
change for 10% Sulphuric acid (H2SO4) solutions after 7 
days immersion period are shown in table-4.  
 
Table 4. Chemical resistance of different types of 
mortar specimens 
 
Types of mortar Mass 
Change 
(%) 
Compressive 
strength 
Change (%)  
Conventional mortar 7.48 33.00 
10 wt.% Epoxy 
polymer mortar  
1.00 3.00 
12 wt.% Epoxy 
polymer mortar 
0 1.00 
14 wt.% Epoxy 
polymer mortar 
0 0.00 
16 wt.% Epoxy 
polymer mortar  
0 0.00 
 
In 10% sulphuric acid (H2SO4) solutions, the weight 
change of epoxy polymer mortar specimens was very 
small compared to conventional Portland cement mortar. 
The average mass change of epoxy polymer mortar was 
00008%, while the average mass change of normal 
Portland cement mortar specimens was as high as 8%. 
For 10% sulphuric acid (H2SO4) solutions, the 
compressive strength change was clearly smaller for the 
0
0.5
1
1.5
2
2.5
3
3.5
4
0 10 20 30 40 50 60Time (Hour)
%
 o
f w
at
er
 a
bs
or
pt
io
n
0
2
4
6
8
10
12
14
16
18
20
0 5 10 15
polymer content (wt%)
C
l i
on
 p
en
et
ra
tio
n,
 c
m
PCM PM
Page 366
 
 
 
epoxy polymer mortar specimens than conventional 
Portland cement mortar. It can be explained by the 
higher chemical resistance of epoxy based polymer 
mortar specimens.  
 
4. CONCLUSION 
 
The results of this study show that the addition 
of polymer causes several changes in the 
microstructure and properties of mortar. For 
example, the addition of epoxy to cement 
mortars improves compressive strength, tensile 
strength and decreases porosity, density and 
chemical resistance. Among different types of 
polymer modified mortar, polymer mortar 
showed higher ultimate compressive strength at 
higher strength gain rate compared to polymer 
cement mortar or unmodified mortar at same 
mortar composition.  Thus, epoxy based polymer 
mortar can be used for repair and retrofitting 
works. 
 
5. ACKNOWLEDGEMENT 
 
The authors are thankful to Razia Begum, Md. 
Mirza Shahjahan and Md. Shahidullah khan of 
housing and building research institute for their 
helpful suggestions, consultations and 
continuous inspiration. 
 
6. REFERENCES 
 
1. ACI 548.3R-95. State of the art report on 
polymer-modified concrete. In: ACI Manual 
of Concrete Practice, Part-5. Famington 
Hills, USA: American Concrete Institute; 
2000. p. 548.3R-1–548.3R-47. 
2. Aggarwal, L. K., Thapliyal, P.C. and 
Karade, S. R., Properties of Polymer 
modified mortars using epoxy and acrylic 
emulsion, Journal of Construction and 
Building Materials, 2007,Vol-21, No. 2, pp. 
379-383 
3. Jain, V. K., Polymer cement mortar, Indian 
Concrete Journal, March 1992, Vol-66, pp. 
139-144 
4. Kim, J.-H., Robertson, R. E. and Naaman, 
A. E., Structure and properties of poly (vinyl 
alcohol)-modified mortar and concrete, 
Journal of Cement and Concrete research, 
Vol-29, 1999,  pp.  407-415. 
5. Ohama Y. Principle of latex modification 
and some typical properties of latex 
modified mortar and concrete. ACI Mater J 
1987;86(Nov–Dec):511–8. 
6. Mirza J, Mirza MS, Lapointe R. Laboratory and 
field performance of polymer-modified cement-
based repair mortars in cold climates. Constr 
Build Mater 2002;16:365–74. 
7. Mehta PK, Monteiro PJM. Concrete: structure, 
properties and materials. 2nd ed. Englewood 
Cliffs, NJ: Prentice Hall; 1993. p. 418–23. 
8. Ohama Y. Polymer-based admixtures. Cement 
Concrete Compos 1998;20:189–212. 
9. Mandel, J. A. and Said, S., Effect of the addition 
of an acrylic polymer on the mechanical 
properties of mortar, ACI Materials journal, 
January 1990 ,Volume-87, Issue-1, pp.54-61 
10. Ohama, Y., Demura, K., Hamatsu, M. and 
Kakegawa, M., “Properties of the polymer-
modified mortars with styrene-butyl acrylate 
latexes with the monomer ratios” ACI Materials 
Journal, 1991,  Volume-88, Issue-1, pp.55-61 
11. Neelamegam, M. and Ohama, Y., Comparison 
of properties of polymer mortar composite,  The 
Indian Concrete Journal, December 1983, Vol-
57(1), pp. 313-318 
12. Limaye, R. G. and Kamat, M.K., Experimental 
studies on polymer modification of cement 
mortar, The Indian Concrete Journal, March 
1992, Vol-66, pp. 156-158 
13. Rahman, M.M., Islam, M.A. and Ahmed, M., 
Perspective of polymer modified 
concrete/mortar in Bangladesh, Proceedings of 
2nd Internatinal Conference on Chemical 
Engineering, Bangladesh University of 
Enginnering and Technology (BUET), Dhaka, 
December 2008, pp. 225-229 
14. Rahman, M.M., Islam, M.A. and Ahmed, M., 
Studies on the development of polymer-concrete 
composites for structural uses, Proceedings of 
3rd International Conference on Structure, 
Processing and Properties of Materials, BUET, 
Dhaka, February 2010, pp. E-13 
15. Rahman, M.M., Islam, M.A. and Ahmed, M., 
Studies on polymer modified mortar and 
concrete using epoxy resin, Proceedings of 
International Conference on Engineering 
Research, Innovation and Education, SUST,  
2010, pp. 187-190 
16. RILEM PC-12 “Method of test for chemical 
resistance of polymer concrete and mortar”, 
Technical Committee TC-113, Symposium on 
Properties and Test Methods for Concrete-
Polymer Composites. 
 
Page 367
Tailoring MgH2 with Mg-Nb-O Towards 
Hydrogen Storage 
 
M.W. Rahmana,, S. Livraghia, S. Enzob, E. Giamelloa, M. Bariccoa 
aDipartimento di Chimica IFM, NIS Centre of Excellence, Università di Torino, 
Via Pietro Giuria 9, 10125, Torino, Italy 
bDipartimento di Chimica, Università di Sassari, 07100, Sassari, Italy 
 
Abstract 
 
A breakthrough in H2 absorption and desorption kinetics of MgH2 was achieved by ball-milling 
with 1 mol% MgNb2O6, Mg4Nb2O9 and Mg3Nb6O11. The presence of Mg-Nb oxides remarkably 
increases the H2 absorption and desorption kinetics of nano-structured MgH2, were examined by a 
volumetric Sievert apparatus. Prior to this experiment, the ternary Mg-Nb-O compounds were 
investigated by Mass Spectrometry (MS) in order to understand their interaction with H2 in mild 
conditions. Among the various ternary oxides, Mg3Nb6O11 compound showed remarkable uptake 
and release of H2, may be due to the presence of octahedral niobium clusters in the oxide structure. 
The results obtained from pressure-composition-isotherms (PCI) measurements, pointed out that the 
H2 desorption rate increases with increasing temperature from 593 to 673 K and in the same 
conditions absorption rate decreases. The most promising results obtained for Mg3Nb6O11 doped 
MgH2 nano-particle, even compared to MgH2 promoted with Nb2O5, the best additive reported so 
far. The MgH2/Mg3Nb6O11 system completely dehydrogenated (3.93 wt%) within 5 mins at 673 K 
under 0.1 MPa H2 and the activated sample takes only 3 mins for fully rehydrogenation (3.20 wt%) 
at 613 K under 2.5 MPa H2. The H2 content of the nano-structured materials is lower than the 
stoichiometric capacity may be due to the presence of a non-reactive MgO layer on the surface or at 
the grain boundaries. Structural analysis of the solid-state materials was carried out by X-ray 
diffraction (XRD) and solid-state phases were analysed by Rietveld method. Desorption curves 
were constructed and analysed by the Johnson-Mehl-Avrami formalism in order to derive reaction 
rate constants at different temperatures. Activation energy was estimated by Arrhenius plot and the 
values obtained for MgH2/Mg3Nb6O11 mixture and bare MgH2 to be 106 and 142 kJ/mol, 
respectively. All desorption data were verified with that obtained from differential scanning 
calorimeter (DSC), connected to a H2 detector. The role of ternary Mg-Nb oxides on H2 absorption 
and desorption properties of MgH2 nano-powder will be discussed on the basis of kinetic model, 
explains by the formation of reactive pathways of ternary oxide species with easier splitting  of H2 
that facilitate the H2 transport into the solid structure, proposed in this context. 
 
Keywords: hydrogen storage, MgH2, Mg-Nb oxides, absorption and desorption kinetics, activation 
energy. 
 
                                               
 Corresponding author: Md. Wasikur Rahman (M.W. Rahman) 
E-mail: rmd.wasikur@unito.it  
Tel: + 39 011 670 7573  Fax: + 39 011 670 7855 
 
Page 368ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
 The Effect of percentage of hollow lumen on the mechanical 
properties of Bangla White Grade B jute fiber 
Md. Rashnal Hossaina,b
 
, Subhankar Biswasb , Qumrul Ahsanb, Md. Aminul Islamb 
Aart Van Vuurea, Ignaas Verpoesta 
aDepartment of Metallurgy and Materials Engineering, Katholieke Universiteit Leuven, Kasteelpark Arenberg 44 
bus 2450, 3001 Heverlee, Belgium 
bDepartment of Materials & Metallurgical Engineering, Bangladesh University of Engineering and Technology, 
Dhaka-1000, Bangladesh 
 
Abstract:  
Composite industries now a days has focused on the natural resources available because of the environmental 
concern and lowering the weight and cost of the reinforced composite products, and so the emphasis on the 
natural fiber. Bangla white grade B Fiber diameter was measured using optical method and was cross checked 
with the weight measuring method and comparative discussions were made. The single Bangla White grade B 
jute fiber tensile test data showed a large scatter since natural fibers show their strength within a range rather a 
fixed value. Test data was corrected for machine compliance. Tensile properties of Bangla white grade B were 
analyzed with normal and Weibull statistics. Afterwards these tensile test data was corrected for the average 
percentage of hollow lumen present in BWB jute. It was observed that the hollow space inside is not uniform and 
defects are probable there but Weibull Statistics shape and scale parameter remains unchanged.  
 
Keywords: Jute Fiber, Single fiber tensile test, fiber diameter.  
 
Introduction: 
With the demand of high performance materials the entire composite industries has focused its goal not only 
towards this single value but an integration of the application needs performance, process ability and 
environment. While the environmental concern comes as a prime target now a days and so the reinforcement 
choice is natural fiber as reinforcement and bio compatible polymer as matrix materials other than glass, carbon, 
auramid, kevlar and other artificial fibers and high cost resin system. Although the natural fiber reinforced 
polymer composite is far more below to that of the properties of the artificial fiber reinforced polymer composite, 
but with the context of specific strength value natural fiber well compete the artificial fiber. There fore to 
evaluate the mechanical a property of the natural fiber is necessary.  
Mwaikambo L. Y. (2009) measured the tensile properties of both untreated and alkali treated jute fiber. He also 
studied the surface morphology of the treated and untreated fiber. In this paper he showed that the tensile strength 
and Young’s modulus of jute fiber bundles depends on the physical characteristics of internal structure such as 
the cellulose content, changes in the crystallinity index. The study demonstrated the brittle failure of jute fiber 
and dependence of tensile properties on the changes in fiber structure [1].  
Chawla N. et. al. (2008) studied monotonic tensile behavior of a sisal fiber and performed micro-force testing 
system using different gage length. The measured tensile strength was corrected for the machine compliance and 
Page 369
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
 implemented Weibull statistics to quantify the degree of variability in fiber strength and different gage length. He 
also discussed the failure mode and mechanism in terms of fiber microstructure [2].  
Almeida J. R. M. d’ et. Al. (2005) while working with piassava fiber showed that the chemical composition, 
mechanical behavior and morphological characteristics are comparable with the coir fiber [3]. 
Defoirdt N. et. al. (2010) in her work “Assessment of the tensile properties of coir, bamboo and jute fiber” 
studied the mean strength and standard deviation of these fibers by normal and Weibull distribution. She also 
discussed the applicability of Weibull statistics and studied the correction method that assesses the real fiber 
elongation from the clamp displacement [4]. 
Andersons J. (2009), studied the mechanical properties of flax fibers and showed that the mechanical property is 
affected by the natural variability in plant as well as the damage accumulated during processing, and thus have 
considerable variability that necessitates statistical treatment of fiber characteristics. He tried to correlate the 
presence of kink bands with the mechanical properties of flax [5]. 
Cichocki F.R. Jr (2002) in his study employed dynamic mechanical and thermal mechanical techniques to 
measure the elastic and thermal expansion characteristics of a model composite system containing jute fibers 
over a broad temperature range. The jute fibers investigated in this study exhibited considerable elastic and 
thermal expansion anisotropy. The longitudinal Young’s modulus of the fibers has been determined. Also the 
fibers exhibit negative thermal expansion coefficients along their lengths. However, large positive thermal 
expansion coefficients, similar in magnitude to many polymeric materials, in the transverse directions were also 
estimated by the researcher [6].  
Yu J.Y. (2008) showed that the two-parameter Weibull distribution does not always adequately describe the 
experimental bast fibre strength at different gauge lengths. For this reason, he modified the test data by 
incorporating the diameter variation of jute fibres in his paper. The fibre diameter was measured with an optical 
microscope. It was found that as the fibre diameter variation increased the tensile strength of the jute fibre 
decreased. In addition, he showed the breaking strength of jute fibre was less sensitive to gauge length than that 
of cotton fibre because the breaking of jute filament involves ultimate cells breaking repeatedly and matrix 
cracking [7] 
Although all the works of the researchers has comprehended the mechanical properties of these natural fibers 
well within the previously measured range but more discussion and study is required to characterize these fibers. 
Regarding this the measurement procedure of fiber diameter should be more precise; this is since the tensile 
strength is depended on the cross-sectional area of the fiber under test. Also since natural fibers show a wide 
scatter in their mechanical properties with respect to the testing equipment so more work is required to clearly 
understand the machine compliance with respect to a particular fiber. These natural fibers are so irregular in 
shape and also contain a large number of defects at the microscopic level; regarding this the applicability of 
Weibull statistics could be discussed for the validity of the tensile test data. 
 
Experimental Methods: 
Materials:  
Bangla white grade B, Jute was kindly supplied by Bangladesh Jute Research Institute. The fiber falls within the 
genus Corchorus Olitorious. The jute fiber was supplied with only retted condition and bottom cut and has an 
average length of 2.5 meters. 
Page 370
  
Fiber preparation: 
Fibers were chosen randomly from the supplied Bangla white grade B jute, washed in distill water at room 
temperature and dried at 70°C in oven for 2 days.  
 
Tensile testing of jute fiber: 
Jute fiber diameter measurement: 
The jute fiber diameter like other natural fiber is irregular in nature along the length of individual fiber, which 
may be due to the inhomogeneous distribution of pectic and gummy materials along the fiber bundle, fiber 
entanglement and various kinds of defects that may be of natural or artificial origin. For each test specimen fiber 
diameter were measured with optical method and also using mass and length measurement considering the 
density of the fiber for calculating the diameter, and both methods are then cross checked. The density of the jute 
fiber was taken from the literature value. 
Bangla White grade B jute fiber diameter was measured using the following methodology; those are 
• Optical root 
• Weight measurement root 
Before continuing to measure the diameter optically, some jute fibers were first embedded in a mounting mold 
consist of liquid epoxy polymer mixed with curing agent and fibers were hold vertical with the help of clamps 
within the mold. The cured epoxy polymer inside vertically mounted jute was then polished to get a mirror like 
appearance. And then it was observed under the Leica CMD stereo optical microscope equipped with Nikkon 
coolpix digital camera with zooming capability as shown in Figure 1. a) 
 
a)       b) 
Figure 1: Optical microscopes, a) Leica CMD sterio microscope, b) Leica MZ8 image processing software 
based sterio optical microscope 
 
Assuming the jute fiber to have uniform diameter along the length the width of the single fiber filament were 
measured with computer interfaced and Leica MZ8 image processing software based stereo optical microscope 
with high precision image processing facility as shown in Figure 1.b). While measuring the width under this 
microscope the magnification was set constant for all measurement. A large number of width data were taken to 
opt out the effect of irregularity of jute fiber and get an average value. 
Page 371
 Also assuming the jute fiber to be quasi circular a 60mm long fiber were taken and was cut 3mm apart with a 
very sharp blade and then it was vertically observed under the PHILIPS
to get some idea about the variation of the 
was set similar for all images and the machine was set to nullify any effect of fiber tilt and get the ac
the cut surface. The images were then processed with Leica MZ8 image processing software.
To cross check the optical method of diameter measurement of jute fiber weight of similar group of individual 
fibers were taken and weight measured with
literature value of fiber density the diameter was calculated. 
compared graphically with the obtained diameter value from the weight measurement procedure.
The defects that are most probable for jute fibers and fib
electron microscope XL30 FEG; this was discussed in detail in the context of 
distribution and its applicability for natural fiber 
Figure 2: Paper 
 
To get an average tensile strength property of Bangla white grade B jute more than 
taken of a jute fiber bundle for each span length. The span lengths were 5, 10, 20 and 35mm. The sin
were glued on a paper frame using cyanoacrylate glue shown in 
Figure 3: Mini tensile 
Single fiber tension test were carried out in the Metallurgy and Materials Engineering Department of K
Universiteit Leuven in a mini tensile/compression machine. The machine was calibrated and it registers the 
displacement of the clamps and the force applied on the fiber.  The paper frame was cut just before the start of the 
tensile test as shown in Figure 2. A load cell of 20N and strain rate of 0.1mm/min and screwed clamps were used. 
Samples that broke near the edge of the clamps were excluded from the analysis.
 
Weibull statistics: 
 scanning electron microscope XL30 FEG
fiber diameter (perimeter) with preceding length. The magnification 
tual image of 
 
 Mettler AT261 DeltaRange weighing machine. Then from 
The optically measured diameter value was 
 
er morphology were studied with PHILIPS scanning 
the assumptions of 
system 
 
frame for single jute fiber tensile test 
50 single fiber filaments were 
Figure 2.  
 
compression machine 
 
 
the 
Weibull 
gle fibers 
atholieke 
Page 372
 Natural fibers are very fine filaments in the microscopic scale and their properties can vary considerably 
according to the local fiber compositional and morphological characteristics. So a statistical knowledge about 
these fibers strength distribution is necessary since, it’s not possible to state a single value for the strength of a 
fiber since they show considerable scatter in the mean strength decreases with fiber length. Both scatter and 
length dependence is due to the distribution of defects in the fiber and the longer the fiber the greater the chance 
of containing sizeable defects. 
 
The assumptions for the Weibull distribution statistics for natural fiber are as follows;  
1. The stress field in each link is considered as being uniform 
2. The failure stress of one link is independent of that of other link. 
3. All links have the same failure probability for a given applied stress. 
The first assumption implies that local modification of stress field around and the defect are negligible, so each 
link can be considered as being subjected to uniform stress field. The second assumption implies that there is no 
interaction between defects. The third assumption implies that the defect distribution inside materials must be 
homogeneous and isotropic. 
The equation for Weibull Statistics are given as follows  
Fx,m, λ  1 
 eλ           (1) 
Where  
“m” = Shape factor 
“λ” = Scale factor 
The Mean and the variance of this distribution is given by equation (2) and (3) respectively 
µ   λΓ 1            (2) 
σ  λΓ 1   
 µ         (3) 
To apply the distribution we will need the following equation. According to Weibull distribution a fiber of 
volume V can have N parts, where V0 is the volume of individual parts, then the relation between V, N and V0 is 
as follows 
V   V  N     Where V  π  !  L#$%&'%()*   (4) 
V0 can be calculated from the known literature value of length and diameter of ultimate or elementary fiber cell. 
The chance that a fiber of N parts will survive or fail at a certain load is given by 
Fσ  1 
 +1 
 Fσ,N          (5) 
Where F1 (σ) is the probability of fiber failure at stress σ and probability of sustaining at that stress [1 - F1 (σ)] 
For very big values of N equation (5) becomes 
Fσ  1 
 e- ./ σ           (6) 
According to Weibull  
Fσ   σσ0

            (7) 
Where σ0 is the average value of the property 
Page 373
 And the final Weibull distribution is  
F  1 
 e- σσ0           (8) 
And the form or shape factor “m” is related with scale factor “λ” as indicated in equation (9) 
λ  σ0- /           (9) 
The mean and the variance of this distribution may be rewritten as 
µ  σ0- / Γ 1 

          (10) 
And  
σ   σ0- /*

Γ 1  
 
 µ        (11) 
To determine the Weibull parameter the Weibull distribution can be rewritten as  
Ln Ln  .*  mLnσmLn2-
/
σ0 3        (12) 
Equation (12) is of the form y = mx + b. By using the median rank approximation for estimating cumulative 
probability of failure 
F  4'56.8'94'5:(;.<          (13) 
And using equation (12) to make plot between Ln Ln  .* VS Lnσ Weibull parameter and its standard 
deviation and mean can be determined. 
Tensile strength was calculated by using equation (14): 
 
      A
FMax
=σ               (14) 
 
      Where, 
                 σ    ═  tensile strength 
                 FMax = maximum force 
                 A     = cross-sectional area 
 
Cross-sectional area was measured by using equation (15) and (16)  ( )22dA pi=            (15)     
and 
L
mA ×= ρ            (16) 
 
where,   
              m = mass 
              V = volume 
              L = length 
              ρ = density 
              d = diameter           
    
The Young’s modulus was measured from the linear portion of the stress/strain curve. 
 
Page 374
 Correction of Tensile Properties 
 
 Total machine displacement (“α”) can be calculated by using the following equations: 
 
GripFiberTotal LLL ∆+∆=∆          (17) 
 
)(
0
σα
σ
××=
∆×
×∆ A
LE
SpanL
Grip
Fiber          (18) 
 
σ
α
×
∆−∆
=
A
LL FiberTotal
           (19) 
 
 Corrected Young’s modulus and strain to failure can be calculated by using the following steps: 
 
i
Total
i AE
L
F
L
×
−
∆
=
0
0α
     
        (20)
  
ii
Total
A
L
EA
L
F
L 00 1 ×=
×
×
=
∆
σ
ε
         (21)
                              
 
00 L
A
L
L iiGrip σα ××
=
∆
          (22) 
  
000 L
L
L
LCorrected
L
L GripTotalFiber ∆
−
∆
=〉〈
∆
        (23) 
 
 
 
Where, 
“α” =  machine displacement for each fiber 
L0  =  original span length 
E   =  Young’s modulus for each fiber 
E0  =  extrapolated Young’s modulus 
Ai   =  cross-sectional area for each fiber 
F   =   force   
ε =   strain 
“α” =    stress 
 
Results and Discussion: 
Probable fiber failure criterion and interaction with defects: 
 
Figure 4: Chain like natural fiber structure [Courtesy Defoirdt N. et. al. (2010) [4]]  
 
Page 375
 Figure 4 shows the illustration of chain like structure of natural fiber l
linked smaller parts that consists of the whole of the technical fiber. This kind of 
weakest link and for longer fiber there is greater chance of having large number of flaw a
can fail at a certain applied load [1].  
 
Figure 5: Jute fiber interior and exterior structure
lumen; c) Node like structure on the exterior of j
 
But jute like fiber is called the extra xylery fiber
to facilitate the water and nutrients transportation for the entire plant. Although the lumen of this kind elementary 
fiber is 2 – 5mm long and is tube like but this tubular structure
is not uniform as indicated in Figure 5.a throughout the entire length of the elementary fiber
this interior tubular structure is not continuous but separated by a micron level thin membrane like structure 
called sieve plate as indicated in Figure 5.b. From Figure 5.b the irregularity of lumen size is clearly understood.
Figure 5.c shows the exterior of jute fiber. The exterior of 
like and peak of each of these waves are termed as node
At this point a detailed discussion could be made. It is true that the technical fiber such as jute is like a chain of 
linked smaller fiber but the linking points may
materials and a techical jute fiber consists of 8 
embedded in irregularly distributed non fibrous 
fiber length; therefore the jute fiber and other natural fibers are 
ike jute. Jute fiber is supposed as a chain of 
fiber is supposed to break at the 
nd therefore
  
 
 a) Lumen interior; b) Membrane like entity inside 
ute fiber. 
 [8], which means its fiber forming xylem tissue is long enough 
 with a diameter range between 5 and 20
 [9][10][11]
this kind of fiber also has irregular shape and the wave 
 [12].  
 not be the fibrous materials but some could be some kin
– 12 lumens of different shape and these lumens are again 
pectic, waxy and lignocellulosic materials throughout the entire 
natural composites itself [1][8]. 
 the fiber 
 
µm and it 
. Also 
 
d of pectic 
Page 376
 Although jute fiber contains cellulose and other pectic, waxy and lignocellulosic materials but only “α” – 
cellulose is considered as the strength contributory part during single fiber tensile test and also when the fiber is 
put inside a polymeric matrix as reinforcement. But obviously there could be some shear force between the 
cellulosic and non-cellulosic materials that can occur at the microscopic level that may contribute or nullify some 
of the fiber strength.  
Accordingly since there are amorphous region and crystallite region within “α” – cellulose itself [2][8] so 
regarding the weakest link theory the fiber failure at the narrow portion may not be fully acceptable fact. This is 
since in all single fiber tensile test there is always some strain value. This strain value could be the contribution of 
the amorphous zone to elongate other than the narrow crystallite zone and this microscopic elongation is possible 
everywhere within the fiber under tension. The amorphous zone that elongates and becomes narrower than the 
narrowest crystallite region can fail immediately as the load is increased farther and this kind of failure is seen as 
brittle failure. Along with this the applied load could insist the micro fibrils of jute to align with the loading 
direction at the expense of microscopic elongation of fiber. 
Also it is not clear that how defects interact each other while conducting single fiber tensile test but if the larger 
microscopic defect has more crystallite portion of “α” – cellulose rather than its neighboring smaller defect with 
less strength contributor then the latter portion has a greater chance of failure than the former. Additionally from 
the morphological study it can be said that the defects are not uniformly distributed. Some defects originated 
naturally that like leaf growth point (Figure 6; a), some fiber also could have some delaminated lumens (Figure 6; 
b, c), also the fibers could be very irregular shaped along the length (Figure 6; d), some portion could be very 
intensely rich in pectic materials (Figure 6; e). Other than these there is always some process assisted defects 
such as kink bands is always possible (Figure 6; f). There could be more types of defect within the natural fiber 
but that discussion is beyond the scope this paper.  
From the above discussion it may be hypothesized that the fiber failure under certain stress may occur in some 
sequence. That is a single jute fiber under tensile force will build up stress concentration at some weak defect 
point or at the narrowest portion of the fiber. But if that weak defect point  or narrowest portion is mostly 
crystallite than its neighboring portion then deformation will start there allowing the fiber to deform under 
tension and in the successive stage stress concentration point may shift to some new point on the fiber other than 
the neighboring narrowest portion and fail immediately as the failure stress is reached. This may be one other 
reason of large standard deviation of fiber strength of natural fiber.  So it is not beyond question, which 
methodology should be appropriate for measuring the cross sectional areas of the thinner natural fiber like jute. 
So regarding this fact it may be said that the tensile strength, modulus and strain value of jute or other natural 
fiber always remain within a certain range other than a particular value, and so the translated mechanical 
properties of natural fiber reinforced polymer composite always show discrepancy with the theoretical value. 
Although there are lot of other explanation regarding strength of composites but these natural fiber mechanical 
properties also has influential affect.   
Page 377
  
Figure 6: Some natural defects of BWB jute fiber 
 
 
Determination of fiber diameter: 
Regarding diameter determination it was observed that the individual fiber has different perimeter for a same 
population of fiber as shown in Figure 7. The Figure also shows that the cross sectional view of lumen and has 
got little resemblance in shape and size to its neighboring lumen, which is also mentioned in Figure 5.b. 
The length wise diameter or cross sectional perimeter is not the same when the jute fibers were cut 3mm apart 
and put under SEM observation and plotted in a graph. From Figure 8 it is clear that although the jute fiber is 
assumed to quasi circular along its length but this observation clearly show that there is rare resemblance 
regarding this fact i.e. jute fiber is not circular and the fiber diameter varies widely irrespective of its length. This 
Page 378
 could be due to the irregular shape of the lumens and irregular distribution of the non-fibrous binders throughout 
the entire length of the fiber. 
 
 
Figure 7: Cross sectional view of BWB jute fiber under a) Leica CMD polarized stereo microscope, b) 
SEM 
 
 
 
Figure 8: Variation of fiber perimeter of BWB Jute with preceding 3mm length of a 54mm long fiber 
   
Another question may arise regarding the validity of fiber cross sectional area measuring methodology, since jute 
fiber is very thin and irregular shaped. Some researcher follow optical root to measure fiber diameter, some 
follow measurement of weight of fiber and then calculate diameter of fiber from known density and fiber length 
value. Although the latter procedure seem to be convincing but for thinner fiber like jute there is always need of a 
high accuracy of wt measurement.  
251.05
273.23
253.51
273.5
211.54
278.61
225.54
202.07
163.07
173.38 168
225.54
199.74
213.79
227.01
211.94
224.87
215.64
0
50
100
150
200
250
300
0 3 6 9 12 15 18 21 24 27 30 33 36 39 42 45 48 51 54
Cu
rc
u
m
fe
re
n
ce
 
(M
ic
ro
n
)
Distance (mm)
Variation of curcumference of BWB Jute fiber relative to 
Fiber length
Perimeter of Jute fiber in 
each preciding 3mm length
Average perimeter
Page 379
 Figure 9: Area calculation using Image [
 
The drawback of the optical procedure of fiber diameter measurement is that the cross sectional circumference of 
the fiber is considered as circle to calculate fiber diameter, but the hollow spaces 
excluded. Chawla N. et. al. (2008) tried optical procedure while working with sisal fiber and used java software 
to calculate the fiber cross section [2] as shown in 
sisal fiber is also irregular throughout its length. So regarding 
excluding the average empty hollow spaces of the lumen. 
of irregularities act at the microscopic level and cou
natural fiber, which is translated into the fiber reinforced polymer composites.
 
Figure 10: Width measurement of Bangla
 
 
 
Courtesy Chawla N. et. al. (2008) / Composites Science and 
Technology 68][2] 
within the lumens are not 
Figure 9. It is also clear from the Figure 9 that the shape of the 
the fact this procedure may be used more
This kind of measure may be necessary since the
ld have influential affect on the mechanical properties of 
 
 white grade B jute with Leica MZ8 software based sterio optical 
microscope 
 precisely 
 kind 
 
Page 380
  
Figure 11: Comparison of diameter value of Bangla white jute fiber diameter value measured by optical 
and fiber weight measurement method 
 
Figure 10 shows the optical method to measure the width of jute fiber which is taken as diameter assuming that 
the fibers are completely circular through the entire length. The arrow indicates how it was measured by drawing 
a line along the width of the fiber and immediately the width value is transformed in to micron value by the 
software by counting the pixel that has been occupied by the drawn line on the computer screen. Leica MZ8 
image processing software based sterio optical microscope keeping the magnification at fixed value of 5 where 
each pixel value is calibrated as 2.7micron with the software itself. Some 20 fibers of same 50mm length were 
taken from the same bunch of fiber from which single fiber tensile test specimens were made. At least 60 width 
data were randomly taken for each fiber through the entire length like it is shown in Figure 11. Accordingly, to 
crosscheck the optically obtained average width value of these fibers the weight of individual fiber was measured 
and the average diameter were calculated from the length and density value of jute fiber.  
Figure 11 shows that weather the diameter measurement method is either weight measurement based or optical 
based there could be always some discrepancy. For jute like thin fiber the weight measurement is possible with 
high precision micro gram range weighing machine and the measured diameter value will be the average of the 
whole length additionally some moisture may be absorbed by the jute fiber itself, which may increase the weight, 
volume and the diameter value. The advantage of weight measuring to get the fiber diameter is that the hollow 
spaces of the fiber are always excluded from the weight value since empty space has no weight although human 
error is never zero. In accordance with this for any single fiber of any types of shape through the length, if a large 
number of values of fiber width are taken and the average may closely resemble to the diameter measured via 
weight measurement method as shown in Figure 11. Larger scatter may be possible or moderately less scatter for 
another set of fibers if similar procedure is followed.  
Table 1: Single fiber tensile testing data summary of 5, 10, 20 and 35 mm span length of BWB jute 
Span 
Length 
(mm) 
Fiber 
diameter 
(µm) 
Max 
force 
(N) 
Ttensile 
strength 
(Mpa) 
Strain To 
failure 
(%) 
Strain To 
failure 
(%) Corr 
Modulus 
of 
elasticity  
Gpa 
Modulus 
of 
elasticity  
Gpa Corr 
5 ± 0 64.41 ±  11.36 2.16 ± 0.68 712.87 ± 288.23 3.07% ± 0.65% 1.70% ± 0.59% 25.92 ± 13.03 45.15 ± 6.58 
10 ± 0 70.86 ± 14.82 2.17 ± 1.04 524.84 ± 138.86 1.88% ± 0.45% 1.26% ± 0.38% 29.02 ± 7.58 43.14 ± 2.00 
20 ± 0 83.47 ± 8.89 2.81 ± 0.77 507.86 ± 93.03 1.46% ± 0.31% 1.19% ± 0.24% 35.62 ± 7.19 42.79 ± 2.64 
35 ± 0 69.25 ± 6.57 1.67 ± 0.27  452.27 ± 102.55 1.00% ± 0.14% 0.98% ± 0.13% 45.71 ± 10.15 46.32 ± 9.40 
 
Comparison of BWB jute fiber diameter measurement via Weight measurement and Optical 
measurement route
0.00
10.00
20.00
30.00
40.00
50.00
60.00
70.00
80.00
Number of Fiber
D
ia
/ w
id
th
 
(M
ic
ro
n
)
Wt-Diameter
Optical Width
Wt-Diameter 46.8741.5445.1653.1446.8750.1074.1051.6450.1070.8553.1448.5156.0148.5145.1654.6053.1458.7548.5150.10
Optical Width 66.0154.6959.1958.3656.7860.8558.4362.6465.4154.5640.2641.6136.4745.3242.6956.8039.9159.7744.3546.76
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20
Page 381
 Table 1 indicates the data summary of the tensile test of Bangla white jute fiber. From Figure 12 the tensile 
strength shows a decreasing trend with increasing span length and the standard deviation is higher for the lower 
span length. Strain to failure shows decreasing trend with increasing span for the uncorrected and corrected value 
and again the lower span shows the highest standard deviation for both cases as indicated in Figure 14. From 
Figure 13 the modulus of elasticity for uncorrected data shows the increasing trend with increasing span length 
and the corrected data shows the no dependency over span length, but whatever trend may be the standard 
deviation is always higher for the lowest span length.  
y = -6.9767x + 671.55
R² = 0.664
0.00
200.00
400.00
600.00
800.00
1000.00
1200.00
1400.00
1600.00
0 5 10 15 20 25 30 35 40
Te
n
si
le
 
St
re
n
gt
h 
(M
Pa
)
Span Length (mm)
Variation of Tensile Strength of BWB raw jute  relative to span length
5mm
10mm
20mm
35mm
Average Tensile Strength
Linear (Average Tensile 
Strength)
 
Figure 12: Variation of tensile strength of Bangla white grade B jute fiber relative to span length 
y = -98.571x + 43.396
R² = 0.7395
y = 1.004x + 44.252
R² = 0.0021
0.00
10.00
20.00
30.00
40.00
50.00
60.00
70.00
0 0.05 0.1 0.15 0.2 0.25
E-
M
o
du
lu
s
 
(G
P
a)
(1/Span length) (1/mm)
Variation of  E-Modulus of BWB Jute fiber w.r.t. span length  
5mm
10mm
20mm
35mm
5mmC
10mmC
20mmC
35mmC
UnCorrected
Corrected
Linear (UnCorrected)
Linear (Corrected)
 
Figure 13: Variation of extrapolated E - modulus of Bangla white grade B jute fiber relative to span 
length 
y = -0.0006x + 0.029
R² = 0.7942
y = -0.0002x + 0.0164
R² = 0.7713
0.00%
0.50%
1.00%
1.50%
2.00%
2.50%
3.00%
3.50%
4.00%
4.50%
5.00%
0 5 10 15 20 25 30 35 40
%
 
St
ra
in
Spam Length (mm)
Strain Variation of BWB Jute fiber with respect to span length 
5mm
10mm
20mm
35mm
Average Uncorrected 
strain
5mmc
10mmc
20mmc
35mmc
Average corrected strain
Uncorrected strain
Corrected strain
 
Figure 14: Variation of tensile Strain of Bangla white grade B jute fiber relative to span length 
Page 382
 For lumen percentage correction the tensile strength, apparent and corrected e modulus and strain to failure 
shows similar pattern as Figure 12, Figure 13 and Figure 14, this is shown in Figure 15 – 17. 
y = -8.7757x + 844.72
R² = 0.664
0.00
200.00
400.00
600.00
800.00
1000.00
1200.00
1400.00
1600.00
1800.00
2000.00
0 5 10 15 20 25 30 35 40
Te
n
s
ile
 
St
re
n
gt
h 
(M
Pa
)
Span Length (mm)
Variation of Tensile Strength of BWB raw jute  relative to span length
5mm
10mm
20mm
35mm
Average
Linear (Average)
 
Figure 15: Variation of tensile strength of Bangla white grade B jute fiber relative to span length including 
% lumen Correction 
 
y = -123.99x + 54.586
R² = 0.7395
y = 1.2623x + 55.663
R² = 0.0021
0.00
10.00
20.00
30.00
40.00
50.00
60.00
70.00
80.00
90.00
0 0.05 0.1 0.15 0.2 0.25
E-
M
o
du
lu
s
 
(G
Pa
)
(1/Span length) (1/mm)
Variation of E-Modulus of BWB Jute fiber w.r.t. span length including lumen % correncton
5mm 
10mm
20mm
35mm
5mmC
10mmC
20mmC
35mmC
UnCorrected
Corrected
Linear (UnCorrected)
Linear (Corrected)
 
Figure 16: Variation of extrapolated E - modulus of Bangla white grade B jute fiber relative to span 
length including Lumen % Correction 
 
y = -0.0006x + 0.029
R² = 0.7942
y = -0.0002x + 0.0164
R² = 0.7705
0.00%
0.50%
1.00%
1.50%
2.00%
2.50%
3.00%
3.50%
4.00%
4.50%
5.00%
0 5 10 15 20 25 30 35 40
%
 
St
ra
in
Spam Length (mm)
Strain Variation of BWB Jute fiber with respect to span length including % lumen 
correction 
5mm
10mm
20mm
35mm
Average uncorrected
5mmC
10mmC
20mmC
35mmC
Average Corrected
Linear (Average uncorrected)
Linear (Average Corrected)
 
Figure 17: Variation of tensile Strain of Bangla white grade B jute fiber relative to span length including 
% Lumen correction 
If we consider Figure 14 and Figure 17 we can see that the strain to failure remains uneffected by % lumen 
correction although the strength and stiffness value has incresed to a certain percentage. This may be attrebuted to 
Page 383
 the fact that empty space like lumen which is a hollow space never have any contribution to fiber elongation but 
it is the solid portion which contributes this strain value.  
y = -0.0013x + 0.0432
y = -0.0013x + 0.0432
-0.0100000
-0.0050000
0.0000000
0.0050000
0.0100000
0.0150000
0.0200000
0.0250000
0.0300000
0.0350000
0.0400000
0 10 20 30 40
α
 (
m
m
/N
)
Span Length "mm"
Variation of average "α" values in relation to span length 
without and with % Lumen correction
Without % lumen Correction With % Lumen correction
Linear (Without % lumen Correction) Linear (With % Lumen correction)
 
Figure 18: Variation of “α” values with span length without % Lumen and with %  Lumen correction. 
 
The “α” value for each test length were calculated for ind ividual specimen since natual fiber has irregular shape 
through out entire length and along the length the compositional variation is also irregular. The average of each 
calculated “α” for each span were taken and plot was made as shown in Figure 18. The calculated alpha values 
for each test length were used for correcting the measured strains and corrections of the E-modulus as indicated 
in Figure 13&16. From Figure 18 it is clear that the average “α” value is larger at shorter test lengths, which 
means that for shorter test lengths more slippage in the clamps dominates the strain value. Another remarkable 
observation from the experiment was that % lumen correction doesn’t have any effect on the failure strain. This is 
logical since lumen is a hollow empty space and with no fiber forming materials although it is an integrated part 
of the fiber itself, which is mostly of natural origin.   
y = -7.1008x + 674.51
R² = 0.6611
y = -8.7757x + 844.72
R² = 0.664
y = -6.9767x + 671.55
R² = 0.664
0.00
200.00
400.00
600.00
800.00
1000.00
1200.00
0 5 10 15 20 25 30 35 40
T
e
n
si
le
 S
tr
e
n
g
th
 M
P
a
Span Length mm
Comparison of tensile strength of BWB jute fiber by Normal correction (including % Lumen) and 
Weibull Calculation method
Mean Tensile Strength Calculated from Weibull Distribution
Mean tensile strength calculated from normal distribution including % lumen correction
Mean Tensile strength Calculated from normal correction
Linear (Mean Tensile Strength Calculated from Weibull Distribution)
Linear (Mean tensile strength calculated from normal distribution including % lumen correction)
Linear (Mean Tensile strength Calculated from normal correction)
 
Figure 19: Tensile strength as a function of the test length according to a normal (standard deviation) with 
and without % lumen correction and Weibull (standard deviation) distribution and for BWB jute Fiber 
 
Figure 19 shows the comparison of the tensile strength of BWB jute calculated from normal correction (standard 
deviation) and Weibull Distribution method. The data points for both the method are seen to superimpose on each 
other.  Therefore it can be said that whatever may be the diameter (cross sectional area) measuring procedure for 
Page 384
 jute like fiber there will always be some scatter in the test result but it will follow some trend which can be 
predicted by normal and Weibull distribution method to some extent.  
Table 2: Weibull parameters calculated for different test length and effect of % lumen correction 
Span length 
(mm) 
 
Ultimate Cell Dimension 
[8][10][11][12] 
Weibull 
Shape 
parameter 
“m” a 
Weibull Scale 
Parameter (MPa) a 
λ  σ= > 
Calculated Tensile Strength from individual method 
Normal 
Distribution 
without  % 
Lumen correction 
Weibull 
Distribution 
without  % 
Lumen correction 
Normal 
Distribution  with 
% Lumen 
correction 
5 ± 0 Length 2.5973 807.44 712.87 ± 288.23 717.16 ± 296.57 896.70 ± 362.55 
10 ± 0 2 – 5.5mm 3.6989 582.17 524.84 ± 138.86 525.37 ± 158.18 660.17 ± 180.89 
20 ± 0 Diameter 5.3279 549.52 507.86 ± 93.03 506.40 ± 109.45 638.81 ± 123.61 
35 ± 0 5 - 20µm 4.6110 494.65 452.27 ± 102.55 452.05 ± 111.48 568.90 ± 128.99 
“a”
 Without and with % lumen correction. 
Table 2 shows the Weibull parameters for different test length. All the shape factor (m) are larger than two, 
which is an indication of increase in failure rate as the applied load raises. Furthermore the shape factor indicates 
the variation in the data the bigger the value for the shape factor “m”, the smaller the variation in the data. It was 
observed that the estimated value of shape factor ‘m’ for the tensile strength data without % lumen correction 
remains the same as the value of shape factor ‘m’ obtained from the calculated tensile strength obtained from % 
lumen correction. We used the literature value of the jute ultimate cell length and diameter value to calculate the 
number of segments “N” present in each average volume of test length and the ultimate cell diameter value is 
includes the hollow space of lumen. This seems logical since the average of % lumen is excluded and solid fiber 
body is only solid portion of fiber is considered as the strength contributory part. Manmade fibers usually have 
shape factors between 5 and 20, while natural fibers have shape parameter, which mostly remain between 1 and 
6 [4]. In our case the shape parameter is in between 2.5 – 4.7 and different for individual test lengths.  
The above discussion implies that if we exclude the % lumen (hollow space) from the optically measured 
diameter for jute like fiber the strength, stiffness values increases to a certain percentage. But the strain to failure 
remains the same since “α” value remains the same, which may be an indication of either insensetiveness of the 
Weibull parameter to wards the % lumen present in the jute fiber or the Weibull parameters includes the 
irregularly shaped empty spaces of the fiber interior in addition with the exterior and shows an overall shape and 
scale parameter value.  In our case the strength, stiffness and strain to failure values remains well within the 
literature value of mechanical properties of jute fiber [Ref], but mean strength at infinite fiber length calculated 
from normal and Weibull distribution is far more below the value obtained from the incorporation of % lumen 
correction. 
Defoirdt N. et. al. (2010) in her work tried to see correlation between the fiber diameter and the “α” value for 
bamboo, coir (brown and white) and jute fiber and proposed that the “α” value seem to be inversely proportional 
to the fiber diameter. The study showed that after applying all the correction method the systematic standard 
deviations are not eliminated. Slippage during the single fiber tensile test is not because of the fiber diameter 
alone but it is a contribution of the whole fiber volume [4]. This is since some fiber failure seems to be just from 
the slippage or sliding of elementary fibers within the gage length. It was observed in previous study of Defoirdt 
N. et. al. (2010) the thicker fiber like bamboo, coir showed less slippage with existing clamping procedure [4]. 
Along with this since we cannot say the fiber diameter will increase with increasing span length but we can say 
the fiber volume will increase with increasing span length so it could be better to find a precise relationship 
Page 385
 between the “α” value and fiber diameter if we incorporate the mea n fiber volume instead of the mean fiber 
diameter for each span length and make a plot.  
y = -7.289x + 0.0418
y = -7.289x + 0.0418
-0.0100000
-0.0050000
0.0000000
0.0050000
0.0100000
0.0150000
0.0200000
0.0250000
0.0300000
0.0350000
0.0400000
0 0.001 0.002 0.003 0.004 0.005 0.006
α
 (
m
m
/N
)
Mean Fiber Volume (Cubic mm)
Variation of "α" value with mean fiber volume With and without % 
Lumen correction
Alpha Value Without % Lumen correction Alpha Value with % lumen correction
Linear (Alpha Value Without % Lumen correction) Linear (Alpha Value with % lumen correction)
 
Figure 20: Dependency of "α" value on fiber volume with and without % Lumen correction. 
 
Figure 20 shows the relation between the “α” value and fiber volume. From the curve we observed  the inversely 
proportional relationship between these two factors. Along with this we see the average “α” value for highest 
span length is negative which is physically impossible, but the information from this point is that higher the span 
length the lesser the slippage. From the curve it can be said that the strain to failure for BWB jute fiber is not free 
from slippage after all these correction. Another observation is that the % lumen within fiber does not have any 
influence on “α” value, since it’s an empty space.  
Discussion: 
Fiber diameter measurement has been discussed in detail and for jute like fiber a comparison between the wt. 
measuring method and optical method has been discussed. Many researchers [2] has followed optical route for 
diameter measurement for single fiber tensile strength. Weight measurement procedure is more appropriate for 
the thicker fiber. But whatever the method we follow to measure diameter of natural fiber the mechanical test 
data will always show some degree of scatter, since the fiber forming material composition is non-uniform 
through entire length. Along with this the crystallite percentage of cellulose within micro fibril is irregular and 
amount of defect within the fiber during processing has detrimental effect on fiber mechanical properties. 
After the completion of tensile test of single jute fiber it was corrected for the with normal correction method for 
slippage [4][5][7][13]. Weibull statistics is normally employed for brittle fiber. Although jute as a natural fiber 
has some plastic deformation although not extremely notable but it seem interesting to make a comparison of the 
normal and Weibull distribution for the tensile properties of jute. It was observed that the standard deviation of 
the tensile strength obtained from normal and Weibull distribution are mostly equal. But when we incorporate the 
% lumen correction in the tensile test data Weibull statistics didn’t match the standard deviation value for each 
span length. 
As the chance of defect and weak links increase in larger span length so it is obvious that for larger span length 
the strength and strain to failure should decrease. The fact is reflected in Figure 12, 14, 15 and 17, and we clearly 
see from these figures the strength value for each span length has increased after % lumen correction but it did 
not affect the strain to failure.  
Page 386
 The stiffness value as indicated in Figure 13 and 16 showed span length dependency before correction of test data 
for slippage but after correction the stiffness value shows very small or no dependency on span length for both 
the case of with and without % lumen correction. As indicated we see the apparent and corrected stiffness value 
has been increased to certain extent as the percentage of lumen excluded from fiber.  
The Weibull shape and scale parameter remained unchanged after % lumen correction. Although lumen is a 
hollow empty space but its interior is not entirely uniform, so unchanged value of Weibull shape and scale 
parameter before and after % lumen correction hypothesized with the fact that the failure rate behavior of jute 
fiber will remain unchanged although the strength and stiffness value has increased and Weibull Statistics 
prediction is not beyond question at this point. Since jute fiber is one type of fiber so its shape parameter should 
be one unique value, but we see 4 different values for 4 different test lengths, which is an indication of common 
natural fiber behavior [4][13].  
The decrease in average “α” value for higher span seem to correlate strain to failure is less dependent on the 
slippage behavior at higher span length, which is indicated in Figure 18, and once again we see there is no 
contribution to the “α” value for % lumen correction. For jute fiber this “α” value should be only one for all span 
length, but we see a decreasing trend, which indicates strain to failure is not entirely free from slippage. For 
35mm test length we find the average “α” value is negative which is not possible but obtain ed from calculation, 
although 60% test data showed positive “α” value. This is since slippage can never be negativ e. It is irrelevant to 
say the increase or decrease in test length will result in increase or decrease in fiber diameter. The previous work 
of Defoirdt N. et. al. (2010) to correlate fiber diameter with “α” value, she stated an inversely proportional 
relation between fiber diameter and “α” value.  So it was hypothesized that the “α” value for jute is not only 
related with the span length but the “α” value is cumulatively related to the entire averag e test volume, since 
slippage may occur along the entire volume of test length of jute like natural fiber and since a single technical 
jute fiber is not entirely regular as one another jute fibers in the same bunch so there must be different “α” value 
for individual specimen [4][14].  
Conclusion: 
Bangla white jute can be a great alternative for the fiber reinforced polymer composite industries. From the 
environmental point of view and natural abundance this can be a valuable alternative to manmade fiber for 
various uses of fiber reinforced polymer composite. Normal distribution along with % lumen correction showed 
increased strength and stiffness value but strain to failure remained unchanged.  Weibull statistics showed similar 
standard deviation as normal distribution and showed same shape and scale parameter and remained insensitive 
to % lumen correction.  
Acknowledgement: 
The author cordially acknowledges the full support of VLIR authority, Metallurgy and Materials Engineering 
Department of Katholieke Universiteit Leuven and Materials and Metallurgical Engineering Department of 
Bangladesh University of Engineering and Technology and Bangladesh Jute Research Institute.  
References: 
[1] Mwaikambo L. Y. (2009), “Tensile properties of alkalized jute”, Bio Resources, 4(2), 566 -588 
[2] Chawla N., Silva F.de A., Toledo Filho de R. D., “Tensile behavior of high performance natural (sisal) 
fibers”, Composites Science and Technology 68 (2008) 3438–3443 
Page 387
 [3] Almeida J. R. M. d’, R.C.M.P. Aquino, S.N. Monteiro, “Tensile mechanical properties, morphological 
aspects and chemical characterization of piassava (Attalea funifera) fibers”, Composites: Part A 37 (2006) 1473–
1479 
[4] Defoirdt N., Biswas S., Vriese De L.e, Ngoc Tran L. Q., Van Acker J., Ahsan Q., Gorbatikh L., Van Vuure 
A., Verpoest I., “Assessment of the tensile properties of coir, bamboo and jute fibre”, Composites: Part A 41 
(2010) 588–595 
[5] Andersons J., Porik E., Sparninš E.,  “The effect of mechanical defects on the strength distribution of 
elementary flax fibres”, Composites Science and Technology 69 (2009) 2152–2157 
[6] Cichocki F.R. Jr., Thomason J.L., “Thermoelastic anisotropy of a natural fiber”, Composites Science and 
Technology 62 (2002) 669–678 
 [7] Yu J.Y., Xia Z.P., Cheng L.D., Liu L.F., Wang W.M., “Study on the breaking strength of jute fibres using 
modified Weibull distribution”, Composites: Part A 40 (2009) 54–59 
[8] Rowell R. M. and Stout H. P., “Chapter 7; Jute and Kenaf, Handbook of Fiber Chemistry”, International fiber 
science and technology series; 16, 3rd ed. by Taylor S Francis Group 2007 (405 – 450)  
[9] Oksman K., Mathew A. P., Långström R., Nyström B., Joseph K., “The influence of fibre microstructure on 
fibre breakage and mechanical properties of natural fibre reinforced polypropylene”, Composites Science and 
Technology 69 (2009) 1847–1853 
[10] A. Majumder, S. Samajpati, P.K. Ganguly, D. Sardar and P.C. Das Gupta, “Swelling of Jute: Heterogeneity 
of Crimp Formation”, Textile Research Journal 1980 50: 575 
[11] Guha Roy T.K., Mukhopadhyay A.K. and Mukherjee A.K., “Surface Features of Jute Fiber Using Scanning 
Electron Microscopy” Textile Research Journal 1984 54: 874, 
[12] Mukhopadhyay A. K., Bandyopadhyay S. K., and Mukhopadhyay U., “Jute Fibers Under Scanning Electron 
Microscopy” Textile Research Journal 1985 55: 733 
[13] Hu W., Ton-That M.T., Perrin-Sarazin F., Denault J. “An Improved Method for Single Fiber Tensile Test 
of Natural Fibers” National Science and Engineering Research Council Canada, VVC  Society of Plastics 
Engineers 2009, DOI 10.1002/pen.21593 
[14] Sakostschikoff A. P., Novotscherkassk, The structure of bast fibers, The Melliand, 2002, Vol. 1, No. 1 Page 
716 – 718. 
 
 
 
 
 
    
Page 388
                                                           Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
*
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
Use of Waste Plastics with Bitumen for Road Construction 
 
1Hazzaz – Bin – Yousuf, 2Dr. Md. Mizanur Rahman, and 3Dr. A.K.M.A. Quader.   
 
1Department of Petroleum & Georesources Engineering, Shahjalal University of Science & 
Technology, Sylhet, email: hazzaz-pge@sust.edu;  
2Department of Civil Engineering, Bangladesh University of Engineering & Technology, Dhaka, 
email: mizanur@ce.buet.ac.bd 
3Department of Chemical Engineering, Bangladesh University of Engineering & Technology, 
Dhaka, email: quader@che.buet.ac.bd 
 
 
 
This paper deals with an investigation on potential use of waste plastics with bitumen for 
road construction. This provides an understanding of the application of waste plastics for 
making modified bitumen for use in bituminous pavement construction and repair. The 
modified bituminous mix with waste plastics was prepared by using bitumen 
manufactured by ERL. The modified bitumen mix contained shredded LDPE and PP 
films (LDPE: PP = 3:1) as 8% by weight of the bitumen in the mix. Laboratory data 
generated after the test on bitumen material indicates that addition of waste plastics 
substantially improves the stability, fatigue life, indirect tensile strength, and reduced 
rutting and water damage of bituminous mixes under adverse water logging condition. 
 
 
Keywords: Bitumen, Waste, Plastic, Transportation, Chemical  
 
 
 
 
INTRODUCTION 
 
Plastics are engineering materials and used 
extensively for a wide range of applications. 
Plastics products at the end of useful life are 
thrown away as municipal garbage. Mixing 
of different kinds of plastic wastes with 
other degradable and non-degradable wastes 
in the garbage has led to limit the use of thin 
plastic bags for packing and other 
convenient applications. Collection and 
reuse of these plastic bags, sheets, films, 
bottles, cans etc. are considered a reasonable 
option to reduce its impact as a nuisance in 
municipal garbage. Reuse is possible 
through recycle to plastics industry for lower 
grade products or use in other applications 
not yet recognized.  
 
All the polymers used in Bangladesh are 
imported. Major polymers used include 
Polyethylene (PE), Polypropylene (PP), 
Polyvinyl Chloride (PVC), Polyethylene 
Terephthalate (PET), Polystyrene (PS), 
Page 389ISBN: 978-984-33-2140-4
 *
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
Polyurethane (PU) etc. The estimated import 
of polymers in FY 2006-07 and 2005-06 
were 288,464 and 273,874 tons respectively. 
Table 3 provides some data about types of 
polymer imported and category of import 
where Figure 3 provides the import of PE 
and PP for FYs 1988-89 thru 1998-99. A 
recent study reports that per capita plastic 
consumption per year in Dhaka city is 9 kg 
while the national average is 3.36 kg which 
is significantly lower then the global 
average. It also reports that solid wastes 
disposed by Dhaka City Corporation (DCC) 
contained about 4.15% by weight plastic 
materials in 2005. This represents 10.43% 
annual increase between 1992 and 2005 for 
plastic materials in solid waste. During the 
year 2004-2005, the plastic waste increased 
by 28.13%. The same study reported that 
about 91 ton/day of soiled and unsoiled 
plastics wastes are collected and recycled 
from DCC dump sites. The quantities of PE 
and PP dumped in the landfill are estimated 
to be 31.26 ton and 32.89 ton per day 
respectively. In order to appreciate the costs 
of recycled plastics it is worthwhile to 
examine the recycled chain as shown in 
Figure 1. The costs data re based on the 
reports by Waste Concern [12] and are for 
the year 2005, Figure 4. However, the costs 
of recycled PE/PP resins today can be 
excess of Tk. 60/kg depending on the quality 
ordered.  
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1   Steps involved in recycling of 
waste plastics.  
 
 
The above statistics indicate that every day a 
considerable amount of waste plastics are 
land filled in different dump sites around 
Dhaka city. The primary goal of this project 
is to study the application of waste plastics 
for making modified bitumen for use in 
bituminous pavement construction and 
repair.  
 
 
PREVIOUS STUDY 
 
Some of the studies on bitumen modification 
suggested that, recycled polyethylene from 
grocery bags might be useful in bituminous 
pavements leading to reduced permanent 
deformation in the form of rutting and 
reduced low temperature cracking of 
pavement surface [1]. It was also reported 
that asphalt concretes that employ 
polyethylene modified binders are more 
resistant to rutting during elevated seasonal 
temperatures [2]. Zorrob [3] and Zorrob et al 
[4] have shown that recycled plastics 
consisting predominantly of PP and LDPE 
can be incorporated into conventional 
bituminous road surfacing mixtures resulting 
in greater durability and fatigue life. Some 
other studies reported that adding LDPE in 
bitumen would increase the resistance to 
deformation [5], increase strength [7], and 
improve temperature susceptibility [6]. Jasto 
and Veeragavan [11] conducted a study on 
the use of processed plastic bags as an 
additive in bituminous mix. The modified 
bituminous concrete mixes in the surfacing 
of road pavement has shown improved 
stability and strength, fatigue life and other 
desirable properties even under water 
logging condition. A similar type of study 
reported that waste plastics being stable in 
the temperature range 220-230 oC were used 
as modifier of the mix results in 
improvement in stability, fatigue life, 
indirect tensile strength, and reduced rutting 
Collection 
Cleaning & 
Drying 
Shredding 
Extrusion 
Palletizing 
Sorting 
Page 390
 *
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
and water damage of bituminous mixes 
under adverse water-logging conditions [8]. 
In 1997, a patent was issued in USA with 
title: Plastics Asphalt Paving Material and 
Method of Making Same, by incorporating 
waste plastics which are not sorted [15]. The 
plastic wastes being unsorted are subject to 
plasma surface treatment. An experimental 
study was carried out in the Department of 
Civil Engineering at BUET dealing with 
polymer blending with bitumen using virgin 
polymers that include LDPE, PP, EVA and 
PVC [19]. All these polymers were 
compatible for blending with bitumen 
except that PVC required vigorous stirring 
during blending. The results indicate that 
optimum performances were observed with 
LDPE content around 8% by weight in the 
bitumen. LDPE modified bitumen mix 
showed decrease in penetration, ductility, 
specific gravity and increase in softening 
temperature when compared with 
unmodified bitumen. According to Punith 
and Verraragavan [22], a polyethylene 
content of 5% by weight of asphalt is 
recommended for improved performance of 
asphalt concrete mixtures. In addition, it was 
reported that higher percentage of polymers 
in modified bitumen is not favorable [23]. 
Therefore, it is evident from all the previous 
studies that the plastic content should be 
between 5-8% to improve performance of 
asphalt concrete mixtures.  
 
 
EXPERIMENT 
 
The first step of the experiment involves 
investigation of the plastic waste 
management produce applied in different 
sector of the country and property evaluation 
of different types of waste plastic material. 
Several visits were made to the sites where 
plastic wastes are dumped. Shops and areas 
where plastics are sorted, process and sold 
were visited. Field survey indicates that the 
waste plastics to be used would be a mixture 
of PP and PE (HDPE and LDPE) as the 
sorting practice does not assure strict 
separation of PP and PE. Therefore, it was 
decided to use shredded LDPE and PP for 
this study.  Preparation of plastic modified 
bitumen mix at bench scale with 50 to 100 
gm of bitumen was made while the 
preparation of modified bitumen mix with 
plastic wastes for road surfacing required the 
construction/fabrication of a gas fired 
furnace, containers and agitator system in 
another laboratory.  
 
To understand the behavior of plastics in 
bitumen melt, LDPE, HDPE and PP have 
been selected for this study considering the 
melting point, Table 1. 
 
Table 1 Some Properties of Different 
Polymer and Bitumen. (For polymers, the 
molecular weight being varying, the values 
mentioned against properties lie within a 
range value.)   
 
 P
rop
erties
 
  Sp
.
 G
r
.
 
 M
elting
 
 
P
oint
,
 oC
 
 Flash
 
P
oint
,
 oC
 
Th
erm
al
 
 
D
eco
m
p
o
sitio
n
,
 
oC
 
LDPE 
 
0.918-0.93 100-120 >231 >270 
HDPE 0.94-0.96 130-140 >360 270-350 
 
PP 0.91-0.97 
 
120-170 400 270-300 
PS 
 
1.35-1.39 235-250  >300 
PVC 
 
1.35-1.39 130-190 >388  
PET 
 
1.45-1.50 265-310   
Bitumen 
80/100 
grade 
1.01-1.06 54-173 >220 >300 
 
Virgin polymers are used at the initial stage 
of the experiments to formulate the modified 
bitumen. These polymers are available in 
Page 391
 *
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
granular forms. Later waste plastics, mainly 
LDPE, HDPE and PP films were purchased 
from the relevant shops. By noting the 
melting point of these waste plastics, the 
plastic types were identified.  
 
The bitumen was tested for determining its 
grade. The penetration test reveals that the 
value is 73/74 and the bitumen is not 80/100 
grade. It was decided to continue work with 
it, because this grade is also used for road 
surfacing in Bangladesh. 
 
Blending of shredded waste LDPE and PE 
with this bitumen at bench scale using 50 to 
100 gm of bitumen sample was carried out 
for various proportion of LDPE and PP 
separately in the temperature range 250-
300oC. Time required for blending depended 
on the percentage of plastics added and the 
range was 60-120 minutes. Blending was 
carried by stirring the mix manually on and 
off. Completion of blending was on the basis 
of visual observation of the mix surface and 
consistency of the mix melt.  
 
The mix for actual pavement was prepared 
by using cylindrical containers (38 cm ID 
and 51 cm height). A separate stand 
arranged over the container on the gas fired 
furnace carried the variable speed motorized 
agitator for mixing the bitumen and plastic 
mix in molten condition.  
 
The container containing the measured 
amount of bitumen was placed on the gas 
fired furnace that has been constructed 
specifically for this purpose. When the 
molten bitumen was heated to 240-260oC, 
the shredded plastics was slowly added by 
agitating manually. The heating was 
continued until the mix reached 300-320oC 
when the gas burner was shut. The agitator 
was turned on when the plastics appear to be 
dispersed in the bitumen and not floating as 
entangled molten mass. The agitation was 
turned off when the mix reached 240-250oC. 
 
Six batches of modified bituminous mix 
with shredded LDPE and PP were prepared 
and these were used for road surfacing 
covering an area about 240 sq. ft. The road 
surfacing was carried out using graded stone 
aggregates. The bituminous mix constituted 
5% by weight of the concrete bituminous 
mix employed for road surfacing. The 
quantity of bitumen mix used for making 
bituminous aggregate mix was based on 
Marshal Test.    
 
 
 
RESULTS AND DISCUSSION 
 
Initial laboratory tests for modifying 
bitumen with virgin plastics and waste 
plastics in proportions 2 to 12% by wt 
showed that they can be mixed with 
bitumen. Literature review reveals that 
waste plastics (both PE and PP) when mixed 
with the bitumen (at 8% wt of bitumen) 
gives the best performance as bituminous 
concrete mix. 
 
The mix that was prepared by using bitumen 
manufactured by ERL has been modified in 
the laboratory using two different mixtures 
of PE and PP. The results are shown in table 
2,  
 
Table 2 Comparison of different properties 
between usual and modified bitumen.  
 
 Bitumen 
(80/100) 
Modified 
Bitumen 
(LDPE:PE 
= 3:1) 
8% by wt. 
plastics 
Modified 
Bitumen 
(LDPE:PE 
= 1:1) 
8% by wt. 
plastics 
Penetration 74 43 37 
Page 392
 *
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
Softening 
Point 
55oC 78oC 82.5oC 
Ductility 118 5 cm 7 cm 
 
Table 2 indicates that, modifying bitumen 
by waste plastic material significantly 
changes some parameters of the original 
bitumen. The penetration rate of the bitumen 
decreased significantly implying that the 
modified bitumen is more appropriate for 
the type of road subjected to excessive water 
logging. The results also indicate that the 
softening point of the modified bitumen 
increased where ductility decrease. 
Therefore, the modified bitumen is of high 
strength and less flexible at the same time.        
 
The road surfacing was carried out using 
graded stone aggregates. The bituminous 
mix constitutes 5% by weight of the 
aggregate bituminous mix employed for 
road surfacing. The quantity of bitumen mix 
used for making bituminous aggregate mix 
was based on Marshall Test. The test results 
on Marshall Specimens shown in Figure 2 
indicate that at 4% of air voids, the bitumen 
content is 4.9%. At this 4.9% bitumen 
content the Marshall parameters from the 
experiment are,  
 
Marshall Stability, kg = 1680  
Marshall Flow, mm  =   3.2 
VFA, %  =   73 
VMA, %  =   14.2 
 
Marshall Design Criteria for medium traffic 
satisfies all the above values. Therefore, the 
design or optimum bitumen content is found 
to be 4.9 percent. 
 
 
 
Figure 2   Bitumen Content Vs Marshall 
Stability Chart  
 
The time for conducting this study was 
short. Based on the information provided in 
the literature some decisions were made 
without repeating works already done. 
However, this has exposed the difficulties 
and problems of carrying out the work both 
on laboratory scale and pilot scale. The 
chemistry aspects of waste plastic films 
were not examined. 
 
 
Right method of road paving with modified 
bituminous mix (i.e. methodology of road 
surfacing) could not be employed for lack of 
equipment. In view of the higher softening 
temperature of the modified bitumen mix 
(>78oC), good paving should employ hot 
rolled technique. 
  
CONCLUSION AND RECOMENDATION    
   
The percentage of waste plastic material 
required to provide optimum performance 
by the modified bitumen is determined 8% 
by wt of bitumen in the laboratory. LDPE 
and PP were used in the ratio 3:1. At current 
level of sale price of the shredded waste PE 
and PP films (about Tk. 60 / kg) against the 
price of bitumen (Tk. 29/kg), the potential 
for its use in bituminous mix appears not 
promising. A life cycle analysis would 
probably be a better way of judging the 
Bitumen Content Vs Marshall stability
1000
1100
1200
1300
1400
1500
1600
1700
1800
1900
3 3.5 4 4.5 5 5.5 6 6.5 7
Bitumen Conntent, %
M
ar
sh
al
l S
ta
bi
lit
y,
 
kg
Page 393
 *
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
potential of using waste plastics in 
bituminous mix. 
 
However, an in-depth study is desirable to 
assess the potential of using waste plastics 
films for making modified bituminous mix 
for road surfacing and other specific 
applications in Bangladesh. More studies are 
required to establish the optimum 
temperature and time for blending plastics in 
bitumen including type of bending system 
with agitator in order to avoid 
decomposition/degradation of both plastics 
and bitumen. A longer stretch of road, say 5 
km, is to be surfaced with modified 
bituminous aggregate mix to assess its 
beneficial and improved properties in 
different regions of Bangladesh 
encompassing regional characters in respect 
of weather, flood, and traffic. The road 
measuring about 240 sq ft paved with 
modified bituminous mix inside BUET 
campus even after more then two years 
(paved on 31.3.2008) is in excellent 
condition. 
 
AKNOWLEDGEMENT 
 
The authors express their gratitude to 
Intermediate Technology Development 
Group, Practical Action (Bangladesh) for 
providing the fund required for the study.  
 
 
REFERENCES 
 
[1] Larry Flynn, Recycled Plastic finds 
home is Asphalt Binder, J. Roads 
and Bridges, Col 31, No. 3, pp 41-
47 (March 1993) 
[2] Denning, J.H. and J. Carswell, 
“Assessment of Novophalt as a 
Binder for Rolled Asphalt Wearing 
Course”, TRRI Report 1101, 
Transport & Road Research 
Laboratory, Crowthrome, UK, 
(1983). 
[3] Zoorrob, S.E., “Laboratory Design 
and Performance improved 
bituminous composites Utilizing 
Plastics Packaging Waste”, 
Conference on Technology Watch 
and Innovation in Construction 
Industry, Belgium Building 
Research Institute, Brussels, 
Belgium, April 2000 
[4] Zoorrob, S.E., and Suparma, L.B., 
“Laboratory Design of Investigation 
of Proportion of Bituminous 
Composite Containing Waste 
Recycled Plastics Aggregate 
Replacement (Plastiphalt)”, CIB 
Symposium on Construction and 
Environment Theory into Practice, 
Sao Paulo, Brazil (November 2000) 
[5] Dallas, N. L, “Enhancement of 
Asphalt Concrete Mixtures to meet 
structural Requirements through the 
addition of Recycled Polyethylene”, 
ASTM STP 1193, (1993). 
[6] Felsinger, R., “Effect of Co-
Mingled Polymer on Rheology of 
LDPE Modified Asphalt ”, 
Unpublished Report, (1993) 
[7] Mahabir Panda and Mayajit 
Mazumder, Development and 
Evaluations of a Bituminous Paving 
Binder Containing Reclaimed 
Polyethylene India Highways, 
Indian Road Congress, New Delhi, 
pp 11-20, vol. 25, No. 5 (May 1997)   
[8] “Use of Waste Plastic for Improving 
Quality and Life of Road 
Construction”- Submission of Best 
Practices for Dubai International 
Award 2006 by Bangalore City 
Corporation and K.K. Plastic Waste 
Management Pvt. Ltd., Bangalore, 
India (2006). 
[9]  Sridhar, R., Bose, S., Kumar, G., 
and Sharma, G., “Performance 
Characteristics of Bituminous Mixes 
modified by Waste Plastic Bags”, 
Central Road Research Institute 
Page 394
 *
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
(CRRI), New Delhi, India 
(Unpublished). 
[10] Schroeder, R.L., The Use of 
Recycled Materials in Highway 
Construction, J. Public Roads, vol 58, 
No.2 (1994). 
[11] Justo,C. E. G. and Veeraragavan, 
A., Utilization of Waste Plastic Bags 
in Bituminous mix for Improved 
Performance of Road, Centre for 
Transportation Engineering 
Bangalore University, Bangalore, 
India (April 2002, Unpublished). 
[12] Composition of Plastic Waste and 
Market Assessment of the Plastic 
Recycling Sector in Bangladesh – 
Study conducted by Waste Concern, 
document available at 
www.wasteconcern.org (2006). 
[13] Strategies to Improve Plastic 
Recycling in Bangladesh, Final 
Report for Waste Concern (2007). 
[14] Islam, M.S., “Recycling of Plastic 
Bottles: Bangladesh Perspective”, 
Presented in ChE Division Seminer, 
IEB, Dhaka, Sept. 25 (2002). 
[15] Winkler, U., “Waste Plastics in 
Road Construction”, Chemical 
Abstract, vol. 20, p540, 142202n 
(1994). 
[16] Tuuji, H., “Asphalt Concentration 
for Paving and Waterproofing”, vol 
120, 166575 t (1993). 
[17] Polakovic, L., et al, “Utilization of 
Plastic Waste in Asphalt Mixtures 
[18]  Used in Road Construction”, 
Chemical Abstracts, vol 116, p350, 
199880 d (1992). 
[19] US Patent 5702199: Plastic Asphalt 
Paving materials and method of 
making same, issued on Dec. 30, 
1997. 
[20] Islam, M.S., A Study on the 
prospects of using polymers in 
Bituminous Binder and Mixes, M.Sc. 
Thesis, Civil Engineering 
Department, BUET, Dhaka, (2003). 
[21] Ahmed, G. U., Utilization of 
Plastics as Packeging, Souvenir: 5 th 
Dhaka International Plastics 
packaging & Printing Industrial fair, 
28-31, January (2008). 
[22] Enayetuallah, I. and Sinha, 
A.H.M.M., Plastic Waste Recycling 
and Its Opportunities in Bangladesh, 
Souvenir: 5th Dhaka International 
Plastics packaging & Printing 
Industrial fair, 28-31, January (2008). 
[23] Punith, V.S. and Veeraragavan, A., 
Behaviors of Asphalt Concrete 
Mixtures with Reclaimed 
Polyethylene as Additives, J. Mat. in 
Civ. Engineering, Vol. 19, issue 6, 
p500-507 (June 2007) 
[24] Vasudevan, R., Nigam, S.K., 
Velkennedy, R., Sekar, A.R.C., and 
Sundarakanan, B., “Utilization of 
Waste Polymers for Flexible 
Pavement and Easy Disposal of 
Waste Polymers”, Proc. Int. Conf. on 
Sustainable Solid Waste 
Management, pp.105 – 111, Chennai, 
India, 5-7 September (2007). 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Page 395
*
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
 
Page 396
*
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
Table 3    Types of Polymer imported and category of import for two financial years. 
  
FY Total Import 
(ton) 
Polymer Type (% of 
total) 
Category (t) Export (t) 
PE PP In-Bond Non In-
Bond 
In Bond Non In-
Bond 
2005-06 273,874 26.31 25.10 80,628 192,246 80,628 192,246 
2006-07 288,864 28.73 29.62 103,853 184,611 103,853 184,611 
 
 
 
 
 
Figure 3   Import of Polyethylene and polypropylene for financial years 1988-89 thru 1998-99.  
  
0 20000 40000 60000 80000 100000 120000
88-89
89-90
90-91
91-92
92-93
93-94
94-95
95-96
96-97
97-98
98-99
Import (Ton)
F
in
a
n
ci
a
l 
Y
e
a
r
Total of 
PE, PP, PVC, PET
pp(ton)
PE (ton)
Page 397
 *
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
 
 
   
  
 
 
 
 
       
 
 
   
 
   
 
 
       
 
 
 
 
 
 
Figure 4   Recycling Chain of different types of waste plastic material via two different routes.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Waste Plastic Sources 
Dustbins/Street (Tk 0) Household (Tk 10-12/kg) 
Feriwala (Tk 16/kg) Tokai (Tk 5/kg) 
Vangriwala (Tk 20/kg) Vangriwala (Tk 12/kg) 
Recycled Resin for Sale (Tk 
40/kg) 
Recycled Resin for Sale (Tk 
40/kg) 
Wholesale Dealer (Tk 25/kg) 
Mechanical Processing 
Wholesale Dealer (Tk 18/kg) 
Mechanical Processing 
Page 398
 *
 Corresponding Author: Hazzaz – Bin - Yousuf,  
E-mail: hazzaz_bin@yahoo.com 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Page 399
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Zakia Sultana. Author,  
E-mail: zzaakkiiaa@yahoo.com 
An Effort to improve software teaching in Engineering Education 
 
Zakia Sultana * and Farhan Isteaq Akhanda  
United International University, Dhaka 
 
Hasan Sarwar United International University, Dhaka 
 
 
Bangladesh is now going through the growth stage of IT industry. There are over 400 software companies at 
present.  Every year, over 6000 graduates come out from more than 80 universities and 700 colleges. The 
emerging software companies in Bangladesh, however, feel the necessity of more skilled and competent 
fresh graduates. An obvious gap between fresh graduates’ capability and industry requirement is felt by both 
the academy and industry. It is found that there are little discrepancies between the BSC curriculum of 
Bangladesh and universities from abroad. But there is a necessity to improve the teaching method. In order 
to improve software teaching in engineering education, a case study is performed on a group of mediocre 
students to evaluate themselves on their own as well as the teaching methodology. Further work is necessary 
to design an evaluation method of software teaching in our country. 
 
Key words: Skilled software engineer; Education; Curriculum; Teaching methodology; IT industry  
 
1. INTRODUCTION 
 
The demand of producing more skilled software 
engineers according to market need is growing now-
a-days in our country. Recent studies show that, in 
terms of export, software development can play a 
major role that really adds to the revenue of the 
country. A software specialist must go through 
rigorous course works and practices of software 
engineering and project management. In general, 
most of the universities in our country are offering 
graduation courses on Computer Science and 
Engineering. The curriculum consists of courses 
taken from different areas of computer science. 
These include computer network, database, software 
engineering mainly. Growth of IT industry requires 
people having skills in any of these areas.  
However,  “It is also being observed in Bangladesh 
that there is a widening gap between the supply and 
demand sides of software professionals. Both the 
two sides of this vital industry have been expressing 
dissatisfaction about this most important ingredient. 
Although more than 50 universities and numerous 
colleges under national university have been 
offering related programs, both the quality of fresh 
graduates having computer science and ICT related 
education appear to be discouraging. Some of the 
common concerns from the demand side are 
shortage of supply of competent professionals; fresh 
graduates need too much training time, value 
creation ability of graduates is low and employee 
turnovers as well as its impact are high. The supply 
side has also some important issues such as fresh 
graduates are not finding attractive jobs resulting in 
lower admission in CSE, career path in the software 
industry is not encouraging, limited on-job learning 
and growth opportunity, and long term opportunity 
cost is high. There is no doubt that these burning 
issues must be addresses to reduce the gap between 
the industry and the academia for addressing human 
resource readiness issue for realizing such an 
important opportunity of nation building” 
(M.Rokonuzzaman, BASIS Soft expo 2010. 
Bangladesh) [17].  
Understanding the fact that Bangladesh is still 
growing in IT, the industry requires fresher having 
basic knowledge on all the areas of computer 
science.  There are other logical reasons why 
universities facing difficulties in focusing only on 
software engineering teaching. A software engineer 
must merge formal knowledge, good decision and 
taste, understanding, and ability to interact with and 
understand the needs of clients. It is not easy to 
teach all of this, undoubtedly not in one or two 
courses on software engineering in the universities 
[1]. 
 
2. ASSESSMENT METHODOLOGY 
 
Considering the aspects of the problem argued 
between two groups namely the academy and 
industry, in this work it is followed the steps given 
below to perform a comparative study on the 
inclusion of software engineering courses contained 
Page 400ISBN: 978-984-33-2140-4
  
in the curriculum of our country and foreign 
universities.  The procedure is 
1. Collect courses included in the curriculum 
of different Bangladeshi and foreign 
universities  
2. Arrangement of the courses topic wise into 
respective major areas. The major areas 
considered, are Software engineering, 
Intelligent System Engineering, 
Mathematics, Computer Network and 
System, Telecommunication engineering 
and Core/general courses. 
3. Prepare an average analysis and comment 
on the practices followed by the 
universities 
The course materials collected from both Private 
universities such as Ahsanullah University of 
Science & Technology, BRAC University, East 
West University, United International University, 
North South University, American International 
University-Bangladesh and public Universities such 
as Bangladesh University of Engineering and 
Technology, Dhaka University. The foreign 
universities course materials are from Australian 
National University, Indian Institute of Technology 
Bombay, Nan yang Technological University, 
Stanford University (California), University of 
Bradford [12-16].  
2.1 CSE program offered in our country: 
All the course details have been collected from 
websites. The courses were classified according to 
major areas [5-12]. Eight universities have 
considered offering Computer Science and 
Engineering.  
A graphical representation of concentration wise 
course distribution is shown in Fig.1. This diagram 
reflects the curriculum structure practiced in our 
country. 
 
Figure 1: Average courses covered in software 
engineering trail of CSE program offered in our 
country 
2.2 CSE program offered elsewhere: 
Similar classification method as above has been 
applied on course curriculum followed in several 
foreign universities. Five engineering universities 
have been chosen [12-16].       
A graphical representation of concentration wise 
course distribution is shown in Fig.2. This diagram 
reflects the curriculum structure practiced in 5 
different universities. 
 
Figure 2: Average courses covered in software 
engineering trail of CSE program offered elsewhere 
 
 
3. CLARIFICATION 
 
Our objective is to find out the constraints 
hindering the development of good software 
engineers from mediocre students for our local and 
international job market. Through this study result 
It can be summarized that our course structure 
maintains the international standard.    
In Fig.1 & Fig.2, it is seen that 12% software 
engineering courses covered in CSE program 
offered in our country and 13% covered in CSE 
program offered elsewhere. And differences 
between these two categories are bare minimum. 
There is only 1% deviation between these two 
categories. The set of curriculum structure of CSE 
program offered in our country and foreign 
universities are almost same. So it is assumed that it 
is a minor problem to produce skilled fresh 
software engineers. Perhaps more software 
engineering courses can be added in our course 
curriculum for betterment of our curriculum 
structure or introduce improved teaching 
methodology.  
With the assessment result it can be said that, rather 
than course curriculum more concentration is 
needed on our teaching method. This is the crucial 
point for our (Bangladesh) software engineering 
education. 
 
 
4. SOME SUGGESTIONS 
 
Teaching software engineering has never been 
easy and no compromise has emerged from the 
many debates about how best to do it. At the base 
of the problem lies the fact that the complexity of 
software engineering comes from the complexity 
Page 401
  
of problems and it is impossible to teach this 
complexity in a traditional classroom setting [2]. 
In Bangladeshi university course curriculum, 
there is no active division of Computer Science. 
Software Engineering, Network, and Database 
courses are mainly focused here. In some of the 
universities elsewhere, more specialized degrees 
are offered as Internet Computing, Mobile 
Computing, Multimedia Computing, Software 
Engineering, Business Computing, Computer 
Systems Administration, Robotics with Artificial 
Intelligence, Information and Communication 
Technologies (ICT) [16]. Bangladeshi 
Universities can have some specialized areas in 
Computer Science faculty.   
Practical courses like java, php, C language 
cannot be taught as theory courses only, Lab 
based practices should be emphasized. There 
should be some pre-defined set of criteria for the 
teachers about how should a course be offered. 
More emphasis on lab classes needs to be given 
by the universities. Theory classes are of course 
needed but for a programming language course, 
80% of the course needs to be practical oriented 
with problem solving approach. 
A practical way of teaching method like 
“Learning by doing” can be followed by the 
universities so that the problem of too much 
dependency on theory can be avoided. “Learning 
by doing” is a model of teaching which aims to 
strengthen practical ability and project awareness 
of engineering students. This model was 
addressed by Dr. Roger Schank, firstly proposed 
in Carnegie Mellon University in USA. “Learning 
by doing”, is a way to let students learn through 
practice, knowledge acquirement, induction and 
summary. In this teaching model, teachers convey 
less theoretical knowledge and students needn’t 
take part in classroom activities or have 
examinations. Here, teachers teach students by 
particular project or product, students completely 
take part in development and business activities, 
finally the knowledge they learned become useful 
and market- oriented [18]. 
 
4.1 Improved Teaching methodology 
To improve teaching methodology, many 
researches and studies has been done 
internationally. It is known that new ideas are not 
easily welcomed. The socio-economical structure 
and language also puts barrier to implement new 
methods.  A literature review and some analysis 
based on Bangladeshi context it is found that 
some of these methods can easily be followed to 
improve teaching SE in our universities. So it is  
proposed to implement these methods in several 
phases so it will not be a pressure or impossible to 
implement. 
Phase 1 
In phase1 a different method of evaluation 
namely, student evaluation of module (SEM) 
questionnaire can be used to obtain students’ 
input and feedback on modules with a view to 
improving teaching and learning. Usually 
universities are taking feedback from students to 
evaluate teachers, but in this method a module is 
evaluated not a teacher 
By any usual SEM several aspects are being 
overlooked: 
• the existing SEM can’t reflect problems 
encountered by students in their learning 
process 
• the existing SEM can’t identify modules in 
which the majority of students are 
challenged and unable to cope 
• the existing SEM can’s provide adequate 
module-related information to lecturers in 
order to further understand the needs of 
students 
 
The proposed SEM must be able to identify 
“difficult” modules and the associated reasons for 
this perception. In part, the questionnaires should 
recognize why students are struggling with these 
modules, as well as whether they have been 
appropriately equipped with sufficient 
background knowledge for the current level of 
studies. Also of interest were ways to aid students 
in overcoming these difficulties and to increase 
their interest in learning. As the emphasis of 
modern engineering education has shifted to what 
is being learned instead of what is being taught, 
the new SEM has to focus on learning outcomes. 
Lastly, this SEM should provide students with a 
platform for feedback on supporting facilities 
such as libraries, computing provision and 
experimental laboratories [22].  
 
Phase 2 
In the second phase, a new method of teaching 
"bottom up" approach can be followed. This 
approach utilizes an intensive regimen of 
laboratory exercises, which require students to 
add a new feature to an existing corpus of 
software. To add the new feature, a student must 
first understand and then redesign (or refactor) the 
existing code, which is designed for the purpose 
of illustrating the complexities that arise in large 
software. Each of these lab exercises gives 
students a basis in experience for understanding 
the lecture material, which presents a pattern or 
solution to address the complexity that was 
motivated in the lab. Thus, unlike in traditional 
courses, which begin with a requirements 
specification followed by design and 
implementation, SE course begins with directed 
Page 402
  
implementation and maintenance tasks, which 
motivate design strategies and techniques.[21] 
Bottom up approach actually evolved from a 
process called continuous quality improvement 
(CQI). In our study it is identified that the 
curricula of our local universities are of 
international standard but there is no end of 
improvement. So, a curriculum must be subjected 
to a process of continuous quality improvement 
(CQI), CQI is a general framework for 
systematically improving the products that flow 
out of a production process. To successfully apply 
CQI to a curriculum requires: 
1. specifying learning outcomes at a granularity 
that is sufficient for improving specific 
components of instruction, 
2. developing assessment methods to measure 
these fine-grain learning outcomes and 
3. Improving the transparency of instruction, so 
that variations in outcomes can be traced 
back to events within the course or its 
prerequisites [21]. 
Phase 3 
The method is to help students by providing a TA 
who will help them handson. Here students are as 
apprentices. This method can be followed by the 
faculty very easily by just providing an eligible 
TA to the students. 
A significant improvement in students' software 
engineering skills can be achieved via the 
following elements: 
• challenging students to build four or five 
applications over a 13-week semester 
(note that these applications can be sub 
modules in a single online learning 
community) 
• drawing on the alumni to bring 
professional software engineers onto the 
campus to coach students 
• a terminal room where students can work 
together on a scheduled basis 
• projects with real clients 
• an emphasis on oral and written 
presentation of results [20]. 
 
 
5. CASE STUDY 
 
Teaching programming language C is initially 
undertaken in Computer Science studies. To 
improve the teaching method of C programming, a 
case study is performed on a batch of students 
doing C programming course following the 
guidelines of SEM in phase 1. The sample of 
students taken for this study has a background 
which is less than average. First, a questionnaire is 
made for the students. Students were asked to 
answer the questionnaire. There were 9 questions 
regarding their depth of understanding on 9 
different topics of programming. Each question has 
4 different answers like Excellent, very well, well, 
and not well as mentioned in Table 1. Students 
chose only one answer per question. Later, the 
filled up forms were collected. The 4 categories of 
Remarks were marked as 4 (Excellent), 3 (very 
well), 2 (well), and 1 (not well) also shown in Table 
1. As per these weights, each student’s total was 
counted. Table 2 shows the GPA that is followed in 
result processing. Estimated total number (the 
expected one) and the grade based on this 
evaluation are shown in Table 3. Afterward, when 
the original exam was over, the original grade is 
given in Table 3 again. 
 
 
 
 
 
 
                                                
 
 
 
Table 1: Mark allocation for questions 
  
                   
 
 
 
 
 
 
 
 
 
Table 2: GPA calculation basis  
 
 
Table 3:  Result Chart of student evaluation sheet 
 Remark  Mark 
Highest 
Mark 
Excellent 4 36 
very well 3 27 
Well 2 18 
Not Well 1 9 
80 A 
70 B+ 
60 B 
50 C+ 
40 C 
30 D 
ID Excellent 
very 
well Well 
Not 
Well Total 
GPA 
(%) 
Grade 
based on 
Evaluation 
Grade 
Based 
on 
Exam 
1   2 1   8 67 B B- 
2 3       12 100 A B+ 
3   1 1 1 6 50 C+ B- 
4   1 2   7 58 C+ B+ 
5   2 1   8 67 B C+ 
6     2 1 5 42 C B- 
7     3   6 50 C+ B 
8   1 2   7 58 C+ D 
9       3 3 25 D D+ 
10     1 2 4 33 D B 
11     2 1 5 42 C C+ 
12 2 1     11 92 A A- 
13 2 1     11 92 A A 
14   1 2   7 58 C+ C+ 
15   2 1   8 67 B A 
16   2 1   8 67 B B 
17 2 1     11 92 A A 
Page 403
  
Then the questionnaire evaluation grade and the 
actual exam grade has compared. It is found that 
47.06% of the actual result is better than the self 
evaluation, 29.41% of the actual result is less than 
the self evaluation and 23.53% of the actual result 
is similar to the self evaluation. Comparison result 
is given in Table 4. 
 
 
Table 4: Comparison of Grade based on Evaluation and 
Grade Based on Exam 
 
Though it is found 29.41% of student got less mark 
than evaluation but the difference is minimal. i.e., 
Grade based on Evaluation is B and Grade Based 
on Exam is B- (please see Table 3).  
 
 
6. CONCLUSIONS 
 
In this paper, our own view of the difficulties of 
educating a software engineer is presented. Though 
the analysis of the CSE program offered in our 
country and CSE program offered elsewhere has 
shown very little difference, it is understood that 
the outcome of the teaching is not so similar.  
A study based on Student Evaluation Module 
(SEM) is made and found out that our students are 
capable enough to self-estimate themselves.  
So, in order to prepare themselves to learn and 
understand more in a fixed time period of a 
semester, some more measures need to be taken and 
continuously assess the strengths of those measures 
toward achieving a better learning outcome. 
Options like more practical oriented projects which 
are related to different companies of local market 
can enhance the chance of practical experience to 
the students. The direct relation of universities and 
business companies can be made so that the 
students can work in the companies for a limited 
time for experience. Furthermore, more 
collaboration is needed between universities and 
local companies to understand and identify each 
other’s problem to minimize the gap by doing 
seminars, fairs.  
In order to institutionalize the educational 
experience, It is needed to focus on devising a 
better and more practical teaching methodology 
with the objective to help enable students learn 
more within the stipulated period of a semester. 
 
REFERENCES 
 
1. The Education of a Software Engineer, Mehdi 
Jazayeri, Technical University of Vienna 
2. The International Journal of Engineering 
Education, Volume 24, Part II Contributions 
in: Engineering Education Research. 
3. Guide to Software Engineering Body of 
Knowledge, SWEBOK, version 0.7, 
http://www.swebok.org 
4.  Curriculum of Ahsanullah University of 
Science & Technology. 
www.aust.edu/cse/cse_admission_req.htm#syl 
5. Curriculum of BRAC University. 
www.bracuniversity.net/academics/dept/  
6. Curriculum of East West University.  
www.ewubd.edu/ewu/ 
7. Curriculum of United International University. 
www.uiubd.com 
8. Curriculum of North South University. 
http://www.northsouth.edu/ 
9. Curriculum of American International 
University-Bangladesh. http://www.aiub.edu/ 
10. Curriculum of Bangladesh University of 
Engineering and Technology. 
http://www.buet.ac.bd/cse/undergrad/ 
11. Curriculum of Dhaka University. 
http://www.cse.univdhaka.edu/ 
12. Curriculum of Australian National University. 
http://cecs.anu.edu.au/future_students/undergra
duate 
13. Curriculum of Indian Institute of Technology 
Bombay. http://www.cse.iitb.ac.in/ 
14. Curriculum of Nan yang Technological 
University. http://www.ntu.edu.sg/ 
15. Curriculum of Stanford University (California). 
http://cs.stanford.edu 
16. Curriculum of University of Bradford. 
http://computing.brad.ac.uk/courses/ug/  
17. ICT Innovation Ecosystem for Improving 
Human Resource Readiness for Software 
Industry: - M.Rokonuzzaman, BASIS Soft 
expo 2010. Bangladesh     
18. Learning by doing: Software project 
management course education, HUANG Long-
jun, DAI Li-pin, GUO Bin, LEI Gang (Jiangxi 
Normal University, Nanchang Jiangxi 330022, 
China) Sep. 2009, Volume 6, No.9 (Serial 
No.58), Journal of Communication and 
Computer, ISSN 1548-7709, USA 
 
19. BASIS Soft expo 2010. Bangladesh 
20. Teaching Software Engineering-- lessons from 
MIT by Hal Abelson 
(http://www.swiss.ai.mit.edu/~hal/) and Philip 
Greenspun (http://philip.greenspun.com )  
21. Teaching Software Engineering Bottom Up R. 
E. K. Stirewalt ,Software Engineering and 
Network Systems Laboratory,Department of 
Computer Science and Engineering,Michigan 
State University 
Total result 17 % 
Accurate 4 23.53 
Better than evaluation 8 47.06 
less than evaluation 5 29.41 
Page 404
  
 
22. Student evaluation of engineering modules for 
improved teaching-learning effectiveness Poay 
Hoon Lim School of Computer Science, The 
University of Nottingham, UK.Email: 
phl@cs.nott.ac.uk 
23. Suyin Gan (Corresponding author), Faculty of 
Engineering, The University of Nottingham 
Malaysia Campus, Malaysia. Email: 
suyin.gan@nottingham.edu.my 
24. Hoon Kiat Ng Faculty of Engineering, The 
University of Nottingham Malaysia Campus, 
Malaysia.Email:hoonkiat.ng@nottingham.edu.
my 
 
Page 405
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Sonia Afrin  
E-mail: afrin.ju@gmail.com  
DESIGN A SIMPLE DATA STRUCTURE USING MULTILEVEL 
STACK 
 
Sonia Afrin* and Shima Chakraborty 
Department of Computer Science and Engineering 
Dhaka International University, 66 Green Road, Dhaka – 1205, Bangladesh 
 
Saiful Islam 
Department of Electrical, Electronic & Telecommunication Engineering 
Dhaka International University, 66 Green Road, Dhaka – 1205, Bangladesh 
 
Data structure plays an important role in conventional computer. In this paper a simple but effective process 
to design a simple data structure of multilevel stack is described. Many kinds of data, including 
observational data collected in the human and biological sciences, have a hierarchical or clustered structure. 
Multilevel data structures also arise in longitudinal studies where an individual’s responses over time are 
correlated with each other. To determine if data sets is suitable for multilevel analysis firstly identify the 
levels in the multilevel structure. This paper aims to give a Pictionary of basic structures and classifications 
that underlie multilevel stack. In this process a unique id for each element is assigned. The parent id of that 
data is also assigned to indicate the level of that data. The stack has three identifier named id, Pid and data. 
The id is assigned in ascending order. Binary search is possible to search that data. For searching an element 
in a data structure, using multilevel stack will be easier and efficient than other data structure.    
 
Key words: Multilevel Stack, Clustered Structure, id, Pid, Binary Search. 
 
 
1. INTRODUCTION 
In computer science, a stack is a last in, first out 
(LIFO) abstract data type and data structure. A 
stack can have any abstract data type as an element, 
but is characterized by only two fundamental 
operations: push and pop. The push operation adds 
to the top of the list, hiding any items already on 
the stack, or initializing the stack if it is empty. The 
pop operation removes an item from the top of the 
list, and returns this value to the caller. A pop either 
reveals previously concealed items, or results in an 
empty list. 
 
When a model of an object to be designed, or more 
generally a set of data interrelated in an intricate 
way, is to be created in the computer, a suitable 
data structure must be built up in the machine 
memory. This paper deals with the problem of 
representing objects composed of other objects, 
hierarchically organized and linked together by 
connection relations. A careful analysis of these 
objects, which are encountered in several 
applications, has provided the base for designing a 
flexible, systematic, expandable and relatively 
compact data structure for their computer 
representation. It was viewed as The characteristics 
which are common to several parts of the object are 
stored without duplication. An implementation of 
the structure based on the ring technique, which 
gives the structure its flexibility, is also described in 
detail (Browne, 2009). 
 
 
 
 
                 Fig 1: Multilevel Stack 
 
 
Page 406ISBN: 978-984-33-2140-4
  
2. MULTILEVEL MODELING 
 
Multilevel modelling is realistically a complex 
modelling that generates dependent data. 
Multivariate responses arise when there are 
measurements on more than one variable for 
individuals, leading to a two-level hierarchical 
structure with responses at level 1 nested within 
individuals at level 2, this type of modeling is 
known as hierarchical or multivariate response 
model.  If the responses may be viewed as 
indicators of one or more unobserved (latent) 
construct, a factor model is usually more 
appropriate.  In a factor model, the correlation 
between responses is assumed to be due to their 
common dependence on one or more latent variable 
or factor.  A structural equation model is a 
generalization of a factor model in which each 
factor may depend on explanatory variables and 
possibly other factors.  
 
The figure is an example of hierarchical structure 
where all level is represented simultaneously: 
people nested within households within places in a 
three level model. 
 
Fig 2: Hierarchical Structure  
 
3. METHODOLOGY 
 
In data structure array is an arrangement of items at 
equally spaced addresses in computer memory.It is 
used in a programming language to specify a 
variable that can be indexed. Although array 
representation of stack is very easy and convenient  
But it allows only representing fixed size stack. 
Single linked list structure is sufficient to represent 
a stack. In computer science, a linked list is a data 
structure that consists of a sequence of data records 
such that in each record there is a field that contains 
a reference to the next record in the sequence. 
Linked lists are useful to study for two reasons. 
Most obviously, linked lists are a data structure 
which you may want to use in real programs. 
 
 
 
 
Fig 3: Two ways of representing a stack 
 
The index structures that we have studied involve a 
sorted index file. A binary search is applied to the 
index to locate pointers to a block containing a 
record the file with a specified indexing field value. 
A multilevel index considers the index file, which 
was discussed as single-level ordered indexes and 
will now be referred to as the first (or base) level of 
the multilevel structure, as a sorted file with a 
distinct value. We mentioned that an index file is 
effectively a special type of data file with two fields 
as pid & value. Thus, we can build a primary index 
for an index file itself. This new index to the first 
level is called the second level of the multilevel 
index. The above process can be repeated and a 
third-level index can be created on top of the 
second-level one. The third level, which is a 
primary index for the second level, has an entry for 
each second-level block. We can continue the 
index-building process until all the entries of some 
index level fit in a single block. 
 
The multilevel structure can be used on any type of 
index, whether it is a primary, a clustering, or a 
secondary index, as long as the first-level index has 
distinct values for and fixed-length entries. The 
figure below depicts a multilevel index built on top 
of a primary index. 
 
We can represent multilevel structure as a complex 
structure, heterogeneity, dependent data and 
contextually. A large range of structures that ML 
can handle routinely is termed as complex 
structure; e.g. houses nested in neighbourhoods. 
Standard regression models ‘averages’, i.e. the 
general relationship ML additionally models 
variances is known as heterogeneity; e.g. individual 
house prices vary from neighbourhoods to 
neighbourhood. A potentially complex dependency 
in the outcome over time, over space, over context 
is known as dependent data; e.g. houses within a 
neighbourhood tend to have similar prices.   
 
Page 407
  
 
 
 
 
Fig 4: Multilevel Index using Binary Search 
 
Multilevel indexes are used to improve the 
performance in terms of the number of block 
accesses needed when searching for a record based 
on an indexing field value. It should be noted that 
we could also have a multilevel primary index 
which could be sparse. In this case, we must access 
the data block from the file before we can 
determine whether the record being searched for is 
in the file. This can be determined by accessing the 
first-level index without having to access the data 
block, since there is an index entry for every record 
in the file. 
 
4. DISCUSSION OF RESULTS 
 
A multilevel index improves the performance of 
searching for a record based on a specified indexing 
field value. However, the problems with insertions 
and deletions are still there, because all index levels 
are physically ordered files. To retain the benefits 
of using multilevel indexing while reducing index 
insertion and deletion problems, database 
developers often adopt a multilevel structure that 
leaves some space in each of its blocks for inserting 
new entries. This is called a dynamic multilevel 
index and is often implemented by using data 
structures. 
 
A stepwise method of deriving the high-
performance implementation of a set of operations 
is proposed. This method is based on the ability to 
organize the data into a multilevel data structure to 
provide an efficient implementation of all the 
operations. Typically, for such data organization 
the performance may deteriorate over a period of 
time and that can be corrected by reorganizing the 
data. This data reorganization is done by the 
introduction of maintenance processes. For a 
particular example, the multilevel data organization 
and the different models of maintenance processes 
possible are considered. The various models of 
maintenance process provide varying amounts of 
concurrency by varying the degree of atomicity in 
different operations. Performance behavior for the 
different models is derived and a correctness proof 
for the developed implementation is outlined 
(Moitra  et al., 1988). 
 
CONCLUSION 
 
A complete implementation of the whole process 
from preprocessing of the multilevel data structures 
has been implemented. The implementation also is 
a framework to process and search data, so that 
further work can be based on the developed 
structure. Different approaches to extract data in 
multilevel stack are discussed and implemented. A 
new method of data structure is presented in this 
paper.  
 
REFERENCES 
 
1. Browne, W. J., (2009), MCMC Estimation in 
MLwiN, v2.10,  Centre for Multilevel 
Modelling, University of Bristol. (Chapter 
15).  
2. http://www.cmm.bristol.ac.uk/learning-
training/multilevel-m-support/books.shtml. 
3. http://www.cs.uct.ac.za/mit_notes_devel/Data
base/Latest/html/ch07s06.html. 
4. Moitra, A., Lyengar, S. S., Bastani, F. B., and 
Yen, I. L., (1988), Journal IEEE Transactions 
on Software Engineering, V14.  
5. http://www.facweb.iitkgp.ernet.in/~pds/2009a
/slides/l9-linkedlist.pdf 
6. http://cslibrary.stanford.edu/103/LinkedListBa
sics.pdf 
 
Page 408
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Mohammad Ariful Islam,  
E-mail: arifbitk@yahoo.com 
DEVELOPMENT OF A SOFTWARE FOR CALCULTING THE 
THERMODYMIC AND TRANSPORT PROPERTIES OF LiBr 
AQUEOUS SOLUTION 
 
 
Md. Abdul Wakil, Mohammad Ariful Islam *, Md. Nayem Ashraf and Md. Aslam 
Hasib 
Department of Mechanical Engineering, Khulna University of Engineering & Technology, 
Khulna-9203, Bangladesh 
 
 
 
With the development in the field of refrigeration, the vapor absorption cycles has gained renewed interest in 
the last decade due to environmental problems of commonly used refrigerants in vapor compression system. 
The most common refrigerant-absorbent pairs for absorption systems are water/lithium bromide and 
ammonia/water. LiBr aqueous solution has been the most popular choice in absorption cooling industry. 
Properties of the LiBr aqueous solution are very important in order to design and analyze the performance of 
absorption refrigeration system. Various researchers have given extensive amount of correlations to calculate 
the thermodynamic and transport properties of LiBr aqueous solution for wide range of temperature and 
concentration. Currently, there is a lack of suitable software to calculate the thermodynamic and transport 
properties. To minimize this deficiency software is developed for calculating the thermodynamic properties 
(such as enthalpy, entropy, specific heat, vapor pressure, density) and the transport properties (such as 
thermal conductivity, mass diffusivity, surface tension, viscosity) of LiBr aqueous solutions. For the 
development of the software an object oriented programming VISUAL BASIC is used. Correlations for of 
thermodynamics and transport properties are taken from literature.  
 
Key words: Absorption refrigeration system; Lithium Bromide aqueous solution; Thermodynamic 
properties; Transport properties; Computer programming.  
 
1. INTRODUCTION 
 
With the development in the field of refrigeration, 
cooling and heating systems based on vapor 
absorption cycles has gained renewed attention in 
the last decade due to environmental problems of 
commonly used refrigerant in vapor compression 
system. The most commonly used absorbents for 
absorption refrigeration system are water/lithium 
bromide and ammonia/water. However, LiBr 
aqueous solution has widely been used in the 
absorption refrigeration industry for a long time due 
to its outstanding thermodynamic characteristics. 
Thermodynamic and transport properties of the 
LiBr aqueous solution are very import in order to 
design and analyze the performance of absorption 
refrigeration system. Various researchers are given 
extensive amount of correlations to calculate the 
thermodynamic and transport properties of LiBr 
aqueous solution for wide range of temperature and 
concentration.  
 
Refrigerant properties software is a very import tool 
to analyze, design and simulation of refrigeration 
system. REFPROP is widely used commercial 
software for various refrigerants used vapor 
compression system. However, there is a lack of 
suitable software for calculating the thermodynamic 
and transport properties of vapour absorption 
system. In this perspective, a software is developed 
for thermodynamic and transport properties of LiBr 
aqueous solution. Correlations of properties are 
taken from more recent and updated literature. For 
the development of the software an object oriented 
programming VISUAL BASIC is used. 
 
2. CORRELATIONS FOR 
THERMODYNAMIC AND 
TRANSPORT PROPERTIES OF 
LiBr AQUESOUS SOLUTION 
 
 
To developed a versatile software for properties of 
LiBr aqueous solution, appropriate properties 
Page 409
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
  
correlations for wide range of temperature and 
concentration are needed. An ample amount of 
correlations are available for thermodynamic 
properties. However, correlations for transport 
properties are very few. For the thermodynamic 
properties, Lower (1960) published in 1960 the 
early prominent correlation. It was the first 
complete study that provided all thermodynamic 
properties of the solution. Using a Gibbs energy 
equation, author successfully described the 
thermodynamic properties of the solution based on 
his own experimental data. Later McNeely (1979) 
developed a Duhring equation from extensive 
collection of equilibrium vapor pressures and 
calculated the enthalpies for wide range of 
temperature and concentration. It has been very 
popular in the industry because it is easy to use and 
quite accurate in the working range of conventional 
absorption machine. Herold and Moran (1987) have 
reproduced McNeely’s (1979) data using Gibbs 
energy equation with a modified Debye-Huckel 
model.  Feuerecker et. al. (1993) carried out a study 
based on their own pressure measurements for the 
solution in the concentration range from 40 to 76 
LiBr wt% and temperature range 45 to 190oC and 
showed good agreement with McNeely (1979). 
Kaita (2001) suggested a new set of equations for 
the high temperature and pressure ranges of triple-
effect machines by supplementing the vapor 
pressure data of Feuerecker et. al.(1993).  
 
Transport properties of LiBr aqueous solution is 
very import for design and simulation of absorption 
system. However amount of correlations for 
transport properties are very few. Hattori et. al. 
(1997) developed a correlation for mass diffusivity 
and showed that it can predict the experimental data 
within ±2%. Japanese society of thermo-physical 
properties (JSTP) provided some correlations for 
mass diffusivity, viscosity, thermal conductivity 
and surface tension in their handbook. 
 
3. DEVELOPMENT OF THE 
SOFTWARE 
 
For the development of the software various types 
of programming languages are available such as 
Visual Basic, C, C++ , JS Script, and FORTAN. 
Among them VISUAL BASIC is chosen as a 
programming language for this work due to its 
flexibility and visual interface. Visual Basic is an 
object-oriented computer programming language 
from Microsoft. It can be possible to make an EXE 
file for the application which is made by Visual 
Basic and this exe FILE can be run freely by DDL 
(Dynamic link Library). 
 
Thermodynamic and transport properties 
correlations that are used for the software are given 
in table 1 and 2. Properties correlations are selected 
based on their accuracy in wide range of 
temperature and concentration. 
 
Table 1: Correlations for thermodynamic properties 
 
Properties Correlations 
Entropy  Patek and.Klomfar, 2006  
Feuerecker et. al., 1993 
 
Density  Patek and Klomfar, 2006  
JSTP Handbook, 2008 
Vapor pressure  Patek and.Klomfar, 2006  
Uemura and Hasaba, 1964  
McNeely, 1979 
 
Specific heat  Patek and.Klomfar, 2006  
Iyoki and Uemura, 1989 
Jeter et. al., 1992 
Rockenfeller, 1987 
JSTP Handbook, 2008 
McNeely, 1979  
Patterson et. al., 1988  
 
 Enthalpy  Patek and.Klomfar, 2006  
Rockenfeller, 1987 
McNeely, 1979 
Patterson et. al., 1988  
JSTP Handbook, 2008 
 
 
Table 2: Correlations for transport properties 
 
 
Developed software provides the various options 
for the used to calculate their required properties. 
Fig. 1 and 2 show the start menu of the software. It 
provides several options for user. User may choose 
a specific correlation or a specific property. 
Software also provides the properties in tabular for 
either varying the temperature or concentration. 
Also user may obtain most accurate properties 
among the correlations. Some screen shots of the 
software are shown in Fig. 1 to 4.  Authors are also 
trying to develop a DLL file to use this software to 
other programming language. 
Properties Correlations 
Mass diffusivity JSTP Handbook, 2008 
Hattori et. al., 1997  
 
Viscosity JSTP Handbook, 2008 
Thermal 
conductivity 
JSTP Handbook, 2008 
Surface tension JSTP Handbook, 2008 
Page 410
  
 
 
Fig. 1: Program output for selection of correlations 
 
 
 
 
Fig. 2: Program output for selection of properties 
 
 
 
Fig. 3: Program output for density calculation 
 
 
 
Fig. 4: Program output for properties in tabular 
form. 
 
4. CONCLUSIONS 
 
LiBr aqueous solution has been the most popular 
choice in absorption cooling industry. Properties of 
the LiBr aqueous solution are very important in 
order to design and analyze the performance of 
absorption refrigeration system. In this work a 
software is developed for thermodynamic and 
transport properties using various correlations. 
Developed program can provides various 
thermodynamic and transport properties in the 
range from 273 K to 500 K in temperature and for 
mixture composition 0 to 75 wt% of LiBr aqueous 
solution. It can also provide properties in tabular 
form.  
 
 
REFERENCES 
 
1. Feurecker, G., Scharfe, J.,  Greiter, I.,  Frank, 
C., Alefeld, G. (1993) Measurement of 
thermophysical properties of aqueous LiBr 
solutionsat high temperatures and 
concentrations, Proc Int Absorp Heat Pump 
Conf ASME 31, pp493–499. 
2. Hattori, M., Aoki, K., Yamada, S., Okubu, T. 
(1997) Holographic measurement of the 
diffusion coefficient of Lithium Bromide in 
aqueous solution, Trans of the JSRAE 14(1),  
pp97-104. 
3. Herold, K.E, .Moran, M. J. (1997) 
Thermodynamic properties of lithium bromide 
water solutions, ASHRAE Trans 93, pp35-48. 
4. Iyoki, S.,  Uemura, T.(1989) Vapour pressure 
of the water–lithium bromide system and the 
water–lithium bromide–zinc bromide–lithium 
Page 411
  
chloride system at high temperatures, Int J. 
Refrigeration 12 (5), pp278–282. 
5. Jeter, A.M.,  Moran, J.P.,  Teja, A.S. (1992) 
Properties of lithium bromide–water solutions 
at high temperatures and concentrations—Part 
III: specific heat, ASHRAE Trans 98 (1) , 
pp137–149. 
6. Japanese Society of Thermo-physical 
properties Handbook, 2008. 
7. Kaita, Y. (2001) Thermodynamic properties of 
Lithium Bromide-water solutions at high 
temperatures, International Journal of 
Refrigeration 24, pp374-390. 
8. Lower, H. (1960), Thermodynamische and 
physikalische Eigenschafen der wassrigen 
Lithiumbromid-Losung. Ph.D. Thesis, 
Technischen Hochschule Karlsruhe. 
9. McNeely, L. A. (1979) Thermodynamic 
properties of aqueous solutions of Lithium 
Bromide. ASHRAE Journal 20(12), pp54-55 
10. Patek, J.,  Klomfar, J. (2006) A 
computationally effective formulation of the 
thermodynamic properties of LiBr–H2O 
solutions from 273 to 500 K overfull 
composition range, International Journal of 
Refrigeration 29, pp566-578. 
11. Patterson, M.R., Perez-Branco, H. (1988) 
.Numerical fits of the properties of lithium 
bromide water solution, ASHRAE Trans 94, 
pp2379-2388 
 
 
Page 412
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*Corresponding Author: Md. Anamul Haque,  
E-mail: arifcse12@gmail.com 
E-COURT IN BANGLADESH : AN EMPIRICAL APPROACH 
 
 
Md. Anamul Haque* 
Department of Computer Science & Engineering, Jahangirnagar University, Savar, Dhaka-1342 
e-mail: arifcse12@gmail.com 
 
A. K. M. Kamrul Islam  
Department of Computer Science & Engineering, Jahangirnagar University, Savar, Dhaka-1342 
e-mail: kamrul@iubat.edu 
 
Judicial court system is a vital portion of governance which is inescapable for developed country as well as 
for developing country like Bangladesh. However, from the placement of litigation to the discharge of a 
case, traditional court system confronts significant amount of time consumption and difficulty in 
maintenance like file management, rehearing, and date placement etc. This paper demonstrates an efficient 
electronic automated court system that will replace traditional court system entirely and will provide 
dramatic savings and improvements in the work of courts and practices of law. E-court system retains a 
central web-portal that incorporates authenticated public access with the case practitioners, regulators 
modules: Case Management System (CMS), Judiciary Automated Calendar System (JACS) and E-filing 
regarding all aspects of traditional system’s functionality. 
 
Key words: CMS (Case Management System), JACS (Judiciary Automated Calendar System), E-Filing, E-
Governance, E-Docket. 
 
1. INTRODUCTION 
 
Democracy is the ever-most accepted 
egalitarianism worldwide which is getting its 
comprehensiveness with the advancement of 
modern technology. Leading governments, with 
high intention of democratic transparency and 
social security; leaning towards captivation of 
Information and Communication Technology 
(ICT). In this regard, a methodology is exercising 
over few last years in which general social people 
will be incorporated in all the government 
activities. Largely, this is termed as E-Governance 
[7]-[5]. E-Governance is a combination of all the 
automated government activities: E-billing, E-Tax, 
E-Transportation, E-court e.t.c where each activity 
attributed the same basic pattern. The design 
pattern of E-Governance is of three conceptual 
levels: Information (Data gather and disseminate), 
Interaction (Direct access of citizen and 
department) and Transaction (Information exchange 
and manipulation) [2]. 
 
For last few years, E-governance is an important 
issue of which Bangladesh government is mulling 
over. Several E-Governance sectors have already 
planned and financed to implement. In this paper 
we are concerned with the automated litigation, 
court proceedings, court hearing management and 
all the other court doings by transposing the current 
system to automated computerized system, i.e. E-
Court [4]. However, transforming the current court 
system to electronic doesn’t replace the entire 
system. Through E-court, place litigation, court 
hearing date management, court trial can be 
performed using web-portal and automated court 
haring. There will be two types of court trials: 
Electronic; where every event will be maintained 
and monitored by video conferencing and LCD 
touch screen, and Conventional; here there the 
traditional court system will be kept intact except 
audio/visual recording and documentation.  This 
paper demonstrates and proposes an E-Court 
system in details that is properly applicable in 
Bangladesh as well as any other country. 
 
The e-court system will bring bright prospects to 
the parties involved and to the nation generally, and 
it will saves time, replace papers by digitalized all 
the documents This judicial system will be more 
efficient with improved transparency, and on the 
other hand, the public’s level of access to the 
judiciary will increase, thus increasing their level of 
confidence in the judicial system. And by reducing 
the corruption of the case it will bring the perfect 
endings of the case. 
 
Page 413ISBN: 978-984-33-2140-4
  
2. RELATED WORK OF E-COURT 
 
By digging down the implementation and research 
of E-Court we can find out several countries as the 
pioneers to E-court: Australia, USA, Malaysia, 
Canada and currently in India. Nevertheless, most 
recently some European countries are showing high 
interest and determinism to establish E-court. The 
potential developments are exercising for the last 
five years over countries. 
 
Jo Sherman and Allison Stanfield explained the 
mechanism of E-court integration in Australia in a 
paper titled “Federal Court of Australia: e-Court 
Integration Project“. Australia first established its 
electronic courtroom in early 90’s in which 
automation was limited to court system and 
database products and display technologies was 
handled by the programmer in house. Such system 
was highly customizable and programmers were 
employed by a governing body Director of Public 
Prosecution (DPP) [3]. To keep the uniformity, 
DPP routinely supplied the trial result through CD-
ROM to other court to conduct the trial. However, 
this system was economically unsustainable and 
unfeasible. In 1998, Australia deployed a unique E-
Court system with the help of skilled programmers 
and setting new technologies. The only difficulty 
was that there was lack of standards. Finally, 
standardized protocol was set regardless of 
technology usage among the courts [3]-[4]. The 
diversity of different data and presentation formats 
that was used by the law firms and courts came 
down the shade of homogenous identity. Besides, 
these protocols was deposited in a way that will 
help any e-court system thought the world to share 
and access of data resided in any provincial court of 
a country. The success of the top ten law firms 
focuses the luster of the developed system. It is 
noteworthy that similar protocols are now using 
almost all the e-court developed countries including 
UN. The paper “Implementation of a leading edge 
eCourt in Australia” by Sandra Plotter demonstrated 
the prominent steps undertaken for gradual shifting 
of e-court establishment. 
 
“Prospects and challenges of E-Court in 
Malayasia” by Ani Munirah Mohamad explains the 
developments and challenges of e-court integration 
in Malayasia. The courts in Sabah and Sarawak 
have been reported to engage in the e-court system. 
The New Commercial Courts (NCC), equipped 
with a computerized system, will allow for 
electronic filing and tracking of cases, video 
recording and monitoring of trials and SMS text 
alerts for interlocutory hearings [8]. 
 
Some district courts of India came under the 
automation system. The Delhi High Court (HC) has 
introduced the first e-courtroom in India by 
replacing the paper files with a sleek LCD screen 
and a touch screen handbook and digitalized all of 
the documents [1]-[2]. The LCD touch screen was 
used by the judge to make corrections and certified 
the copy using his digital signature. It is also 
considering recording the statement of witnesses 
through video-conferencing to avoid procedural 
delays. “Towards excellence in e-governance” by 
Saxena, K.B.C. outlined the strategy of Indian 
automated e-court integration.  
 
USA already established the e-court system in some 
parts of the country where the e-hearing, video and 
audio conferencing facility is available. The court 
of Arizona, New York and Virginia are the most 
successful among them. 
 
3. IMPORTANCE OF BUILDING E-
COURT 
 
3.1 Traditional court system 
To fathom the intensity of the E-court system we 
first have to understand the court system in hand. In 
the perspective of Bangladesh, there are several 
steps from court litigation to the court proceeding: 
a) The plaintiff prosecutes against a defendant 
through the lawyer. 
b) A complex procedure is to maintain a hearing 
date for trial by the attorney. The attorney place a 
date after being confirmed of the availability of 
the Judge, Magistrate, Police, court reporters and 
interpreters. 
c) Police will take legal action if the defendant is 
convicted. 
d) The defendant will seek and pick an attorney and 
will ask for a rehearing date to the attorney. 
e) The hearing may continue over and over by 
placing if a trial failed to meet the result. 
f) After each hearing all the results are well 
documented which are elemental for the next 
trial. 
 
3.2 Importance of E-court 
There is multifarious importance of electronic 
justice system over traditional system. The 
fundamental steps composed above, requires a lot 
of persons and practical bustle which can be 
mitigated at least up to 60% depending on the 
structure and construction of the e-court system. 
Moreover, for a third world country it is largely 
difficult to have a proper justice if the plaintiff does 
not possess good economical solvency. In essence, 
corruption of implicated bodies can be a significant 
obstruction for apposite judgment.  The paper 
documents that play a vast majority role can be 
Page 414
  
modified intentionally and thus can invert the flow 
of jurisdiction. It is fascination of the technology 
where corruption can be potentially suppressed 
providing righteousness to the people satisfaction. 
 
E-court system supports an automation system for 
the court where any kind of electronic hearing by 
using video conferencing facilities and online 
dispute resolution proceedings may be carried out 
by judges, whilst the parties are not physically 
present at the place. 
 
This automated system is available for 24 hours a 
day, 7 days a week. E-documents can make out of 
touch and secure with proper authentication. 
Electronic justice system provides direct access to 
all the parties of documents and transcripts 
processed after the trial. Judges and Magistrates 
and other authenticated personnel can download 
and visualize the recorded audio-visual documents 
that can help in motivation and predetermination 
for upcoming court proceedings. 
 
Besides, general people have intense 
inquisitiveness to the court proceedings. Automated 
E-court system can contribute to the international 
criminal activities. As long as there is standardized 
data format for all e-courts throughout the world, 
important historical data can be exchanged between 
local courts and international tribunals. This is far 
convenient when an international judge with 
sufficient authentication can download all the 
information of an offender within the blink of an 
eye. 
 
E-court will be the best resort for any kind of cyber 
crime. With the increasing demand and usage of 
technology in our diurnal deeds, cyber criminals are 
trying to find the glitch of the web and taking the 
advantage of the fault. Spoofing and spamming e-
mail, database and website hacking, stealing secret 
information are the most wearisome and anxious 
incidents in the cyber world. After the 
transplantation of the E-court with current system, 
all the personnel will be intelligent enough to 
handle such crime electronically. 
 
4. PROPOSED E-COURT SYSTEM 
 
Our proposed mechanism is to establish a 
technology incorporated court system where there 
is a web- portal and central database management 
system. Parties involved in any case can govern and 
conduct their regular court activities having the 
information from the database using the web-portal. 
Updated information and data can store back to the 
database.  Along with the conventional irrevocable 
tasks there are three interrelated basic parts that 
integrate the E-court system. 
1. CMS (Case Management System). 
2. JACS (Judiciary Automated Calendar 
System). 
3. E-Filing. 
 
4.1 Basic E-court System  
Every person or group that is the participant of the 
E-court system (Fig.1) is called a party. Party 
should be identified in our system with unique 
identification number (ID). ID is provided against 
an existing unique number which will be NID 
(National ID) in the case of single person and Reg. 
No. (Registration Number) for corporate body. All 
the lawyer, attorneys, court reporters, interpreters, 
judges and magistrates should be registered as 
system user with associated privilege. Information 
about the party and system user will be 
comprehensive. If there is an existing E-governance 
where data about each citizen is pre-stored, E-court 
system can retrieve information otherwise data with 
all the sufficient information along with the 
photograph and NID will have to supply to the 
system. There should be an unbiased governing 
body (super system administrator) that would be 
responsible to delegate proper authentication to all 
the users. As a result, highly privatized web-portal 
area should be secured and prevented. There is a 
distinct information history to keep the records 
metadata i.e. the information about record; the time 
of record entry in the database, the time of 
modification, party by whom the record entered / 
modified.  This solidifies the systems integrity and 
cohesiveness. There will be no way out for a hacker 
or moulder to be remain intractable. 
A plaintiff places a litigation using the web-portal 
with details information. Being sponsored by an 
attorney, plaintiff should be included in the 
attorney’s supervision list. He/She will confirm the 
litigation to progress to the court. It is the job of the 
attorney to manage a hearing date using the JACS. 
Being confirmed a trial date a tribunal is ready to 
proceed to CMS. Necessary documents will come 
from the E-filing. CMS may face multiple hearing 
dates. Each hearing date’s proceedings are similar. 
After each CMS process, audio/video recording of 
trial would be uploaded as a process of E-filing. 
 
 
 
 
 
 
Page 415
  
Upper court referral 
Place Litigation 
Approve and 
proceed to court 
E-Filing 
CMS JACS 
Court Decision 
Appeal 
against 
court 
decision
Yes 
No 
Plaintiff  
Defendant 
Attorney
Plaintiff 
Attorney 
Discussion
Documentation
Criminal 
Action
Investigation 
Database E-Filing
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 1: Activity of E-court System 
 
A defendant may protest against a court decision 
and consign an appeal by its attorney. In that case, 
the case may reprocess to the upper court tribunal. 
Depending on the proceedings a case may be 
cancelled, postponed or in favor of any involved 
party. Such a case status can only set by the case 
judge. E-docket that holds the entire lawsuit’s 
history including its proceedings reports in different 
courts will be available in E-Filing and is accessible 
for absolute authorized person. 
 
4.2 CMS (Case Management System) 
CMS is the nucleus that links all the other limbs of 
our proposed E-court system [3]. The role play of 
any case is the CMS. Nevertheless, a case may be 
placed and an initial investigation may be done by 
the police department, it is CMS (Fig. 2) where the 
parties rely to reach to an end of the case. Sponsor 
attorney of a plaintiff will manage a trial date by 
the JACS (Judiciary Automated Calendar System) 
[3]-[4]. Being set a trial date and confirmed 
relevant people’s availability, a CMS takes place. A 
trial place will be preoccupied by audio visual 
equipments. Court proceeding will be recorded and 
uploaded in the system. Not only this will ease the 
job of the judges, attorneys but also offer flexibility 
of access to these files even at home. Judge will 
make decision in presence of attorneys, magistrates 
and polices and plaintiff. A trial consequences an 
investigation. Successful investigation 
consequences criminal action. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 2: CMS (Court Management System) 
 
Documentation is the process of E-filing after a 
discussion. E-docket and audio/visual recording 
and other necessary documents are among 
documentation. 
 
4.3 JACS (Judiciary Automated Calendar 
System) 
Scheduling attorney of the plaintiff schedules for an 
available hearing date. JACS [3] is intelligent 
enough to deliver an available hearing date for the 
trial. Attorney only needs to supply the judge, 
magistrate, interpreters, court reporters and 
opposing counsellor’s identity. JACS will hunt for 
the near-most available trial date regarding the 
availability of the supplied people. Scheduling 
attorney may assign or reject the available date. In 
case of rejection, He/She may choose an available 
manually by searching obligatory personnel 
availability. Several tasks (Fig. 3) need to be 
completed by scheduling attorney. .Following 
depiction (Fig. 3) figures out JACS and its 
operation: 
 
 
Page 416
  
Scheduling 
Attorney 
1. Check/Look for available 
hearing date. 
2. Check/Look availability 
of opposing attorney. 
3. Select available court 
interpreter. 
4. Select available court 
reporter. 
5. Submit subpoena.  
Hearing 
Date 
Get system 
generated 
date 
Set manual 
Date 
JACS 
Audio 
Transcription 
Digitalizat
ion 
Video 
Synchronization 
Archiving 
Cataloguing 
Indexing 
 
 
 
 
 
 
 
 
 
 
Fig. 3: Operational JACS 
 
4.4 E-Filing 
E-Filing [3]-[4] (Fig.4) is a process of updating the 
database of particular case with every trial’s 
information. Audio and video of each hearing is 
recorded. Audio transcription and digitalized video 
is synchronized and archived. Accurate disk 
cataloguing and indexing information is stored in 
the database. When a system user want to retrieve 
files of a specific case via web-portal, list of files 
along with the audio/visual recording are showed 
up. To record audio/visual hearing, court system is 
preoccupied with camera, audio recorder and ADC 
converter and synchronizer. 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 4: E-Filing 
5. CONCLUSIONS 
 
Our cogent proposed mechanism leads us to a 
precise conclusion. This system can easily be 
established with marginal setup expense and lower 
maintenance cost. In essence, to keep pace with 
technological transformation of E-governance 
throughout the world, it is inescapable to automate 
the conventional court system. Furthermore, this 
proposed system is comprehensive enough to keep 
the consideration of local court system and to 
exchange of data with international E-court 
systems. Future trend of our proposed mechanism 
is to make highly data exchangeable and functional 
web-portal and operate a pilot project under a 
sponsorship. 
 
 
REFERENCES 
 
1. Menson, S. 2003. “E-governance the new line 
of force in India”, Times of India, 13 July at 
http://www.ibm.com/industries/government/do
c/content accessed, on 13 April, 2006. 
2. NASSCOM. 2003. “Accelerating E-
Governance in India”, NASSCOM (National 
Association of Software and Services), 8 April, 
2006. 
3. Sandra Potter, “Implementation of a leading 
edge eCourt in Australia”, Internet Law 
Bulletin, Vol-8, pp.1-13, April-2005. 
4. Jo Sherman and Allison Stanfield, “Federal 
Court of Australia: eCourt Integration Project“, 
pp. 4-36, January-2004. 
5. OECD. The e-government imperative: main 
findings, Policy Brief, Public Affairs Division, 
Public Affairs and Communications 
Directorate, OECD, 2003. 
6. Saxena, K.B.C. 2005. Towards excellence in e-
governance, International Journal of Public, 
Sector Management, Vol. 18(6), pp.498-513. 
7. Steven.L.Clift, “E-Government and 
Democracy”, pp-5-15, 2002. 
8. Ani Munirah Mohamad, “Prospects 
and challenges of E-Court in 
Malayasia”,  pp.1-5,Nov-2009.  
Page 417
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
 
*
 Corresponding Author: Rosina Surovi Khan,  
E-mail: surovi99@yahoo.com 
INTERFACE DESIGN OF A CLIENTS-SERVER DISTRIBUTED 
SYSTEM 
 
Rosina Surovi Khan* 
Ahsanullah University of Science and Technology 
141-142 Love Road, Tejgaon Industrial Area, Dhaka-1208, Bangladesh 
 
 
 
This paper is based on the interface design of a distributed system that involves clients and one server. Two 
different write-information clients exert separate signatures to their message lines in message queues and 
write these messages in blocks to a single message file. The server takes note of the signatures, extracts the 
appropriate blocks from the file and displays them in its interface under two categories of information. Two 
corresponding read clients extract their appropriate information from the single file and display their 
particular information separately in their interfaces. The idea behind this project is to present a distributed 
system and the message transfers that can take place among clients and server through the usage of message 
queues, signed messages, threads and a message file all incorporated into one system which previous papers 
have not demonstrated. The designed system stands out to be a useful and knowledgeable experiment not 
only for academic purposes but also in respect of research as it demonstrates how all the components taken 
into account together can work in harmony in a step by step manner and on which further future work can be 
carried out. 
Keywords: Distributed system, Threads, Message queues, Signature, Clients-Server interaction 
 
1. INTRODUCTION 
 
A distributed system is defined to be a collection of 
independent computers that appears to users as a 
single coherent system. In other words, the 
distributed system is organized as a middleware. 
The middleware layer extends over multiple 
machines, and offers each application the same 
interface. The goals of distributed systems are to 
connect users and resources and offer distribution 
transparency, openness, scalability and security. [5] 
The work outlined in this paper is based on the 
interface design of a  distributed system that has 
been implemented in C Sharp using Microsoft 
Visual C# 2008 Express Edition editor. The 
experimental work involves the usage of threads 
along with message queues, signed messages and a 
message file all incorporated into a clients-server 
system, something which previous papers have not 
approached. There are four clients and one server in 
the system. The server will receive text messages 
from a parts write client interface that submits parts 
information of company products and also receive 
messages from an address write client interface that 
submits addresses of customers. Message transfers 
from these clients to the server take place via 
signed messages with the help of message queues 
separately. The write clients write these messages 
to a single file and the server extracts the parts and 
addresses messages from the file via two threads, 
one for each type of message and displays them in 
its separate list boxes. Two read clients will extract 
parts and addresses message information in list 
boxes respectively on demand. 
Section 2 describes the traditional way in which 
clients connect with the server. The next section 
explains the importance of threads and how the 
designed system uses threads to maintain 
synchrony among the clients and server. Section 4 
goes on to demonstrate how message queues exert 
signatures on messages sent from the write clients, 
how they assist in transferring these messages to 
the server side and how the server seggregates the 
two type of messages and displays in its interface 
under separate categories. The next section shows 
how two read clients extract the content of the 
messages on demand. Section 6 demonstrates the 
snapshots of the message file, clients and server 
interfaces and how they all work together in 
harmony in a step by step manner. The paper ends 
on a concluding note of the work achieved in this 
experiment and the scope for future work. 
Page 418ISBN: 978-984-33-2140-4
  
2. CLIENTS-SERVER CONNECTION 
 
The Client Server model is usually based on a 
simple, connection-oriented request/reply protocol. 
The client sends a request and gets an answer. The 
reply message serves as the acknowledgement to 
the request. [6] 
 
 
 
Fig. 1: General interaction between a client and a 
server 
 
Each client binds to the server through a 
communication endpoint called socket. The socket 
listens and binds to a local IP address. The server 
waits for requests and finally accepts client 
connection request. Each client gets remote IP 
address and connects to remote server host via 
socket. [5] 
Writing data from the server to a client’s interface 
is equivalent to sending some data to the client and 
displaying in the client’s interface and vice versa. 
Reading data from a client means receiving data 
from the client to the server and displaying in the 
server’s interface and vice versa.  
 
Fig. 2:  Connection-oriented communication pattern 
using sockets 
 
3. USAGE OF THREADS 
Threads are like little mini-processes that were 
invented to allow parallelism to be combined with 
sequential and blocking system calls. Blocking 
system calls make programming easier and 
parallelism improves performance. [6] 
In the designed system, two user threads are 
created. One is used so that the server can read 
parts message blocks from a single message file to 
which the parts write client writes. The other thread 
is for the server to read address message blocks 
from the same file to which the address write client 
submits address messages. 
Using threads this way, a synchronous order is 
maintained in which the two types of write clients 
write to the message file along with the server 
reading from the message file and displaying their 
messages in its interface. Otherwise without the 
usage of threads this harmony is impossible to 
achieve. 
 
4. INTERACTION BETWEEN WRITE 
CLIENTS AND SERVER 
Asynchronous persistent communication is 
achieved through the support of middleware-level 
message queues. Queues correspond to buffers at 
communication servers. Basic interface to a queue 
in a message-queuing system is summarized in the 
following table. [5] 
Table 1. Basic interface to a message queue 
 
 
In the system parts write client before sending its 
message to parts messge queue adds  a  signature 
“Queue1” to parts message line to differentiate it 
from address message blocks. Similarly address 
write client adds the signature “Queue2” to address 
message line to differentiate it from parts message 
blocks.  
//Signature "Queue1" is added to parts message to 
differentiate from address message blocks  
partsItems.Message="Queue1"+String.Format("\r\n
")+"Part Desc " + part_desc_txt.Text + 
String.Format("\r\n") + "Quantity " + qty_txt.Text + 
String.Format("\r\n") + "Part No " + 
part_no_txt.Text + String.Format("\r\n")+ "Price 
per Each " + price_each_txt.Text; 
mq.Send(partsItems); 
Code 1 [2]: Addition of signature to parts queue 
Parts queue writes parts messages to a message file 
from which the server attempts to read via a thread. 
Similarly address queue writes address message 
Page 419
  
blocks to the same file from which the server once 
more attempts to read via another thread. From this 
single file, the server checks if a block begins with 
the signature “Queue1” or Queue2”. If the block 
begins with Queue1 the server extracts it from the 
file and displays it in its parts list box. If a block 
begins with Queue2 the server extracts and displays 
in its address list box. The write clients can send 
messages to the server side in any order. 
//creates an instance MessageQueue, which points 
//to the already existing MyQueueParts 
if(MessageQueue.Exists(@".\Private$\ 
                                                      MyQueueParts")) 
        mq1=new System.Messaging.MessageQueue      
                              (@".\Private$\MyQueueParts"); 
else 
 //creates a new private queue called MyQueueParts 
        mq1=MessageQueue.Create(@".\Private$\ 
                                                       MyQueueParts");     
        mq1.Formatter = new System.Messaging.         
              XmlMessageFormatter(new Type[]{typeof     
                                                         (WriteItems)}) ; 
 while (true) 
     { 
        System.Messaging.Message m1; 
        // checks if parts queue mq1 has messages 
         m1 = mq1.Peek();          
        System.Messaging.Message msg1 =     
                                                     mq1.Receive(); 
         WriteItems outpartsItems =     
                                     (WriteItems)msg1.Body; 
         //Writing messages from parts queue to file 
         using (StreamWriter sw1 = new        
          StreamWriter(outpartsItems.FileName, true)) 
           
           {   sw1.WriteLine(outpartsItems.Message); 
                sw1.Flush();  } 
         
          using(StreamReader sr1 = new     
          StreamReader(outpartsItems.FileName, true)) 
        {  int queue = 0; 
            string line1; 
 //Read from the file and display parts queue                         
//message blocks in server’s parts list box until the 
//end of the file is reached            
        while ((line1 = sr1.ReadLine()) != null) 
             {  if (line1.StartsWith("Queue1")) 
                      { queue = 1;} 
                 else if (line1.StartsWith("Queue2")) 
                       { queue = 2;} 
                 else if (queue == 1) 
                          {     
                  
                  Client_Parts_Records.Items.Add(line1) ; 
                            } 
                        } 
               } 
               mq1.Close(); 
Code 2 [4]:  Interaction between parts write client 
and server 
 
5.INTERACTION OF READ CLIENTS 
IN THE SYSTEM 
 Parts read client reads four lines at a time from the 
single file that the parts write client has previously 
written to. The read client checks if this block starts 
with the signature “Queue1”. If it does, the client 
extracts it and displays it in its interface’s list box. 
The same goes for the address read client which 
will check if a block starts with the signature 
“Queue2”. The read clients can read messages in 
any order. 
 
String buffer; 
 
using (StreamReader stream =  File.OpenText     
               (@"C:\rsk8332\Project2\Server\Msg.txt")) 
             {  buffer = stream.ReadToEnd();  } 
 
//Stores into each index of lines array the individual 
fields and  their values of parts block  
 
string[] lines = buffer.Split(new string[] { "\r\n" },         
              StringSplitOptions.RemoveEmptyEntries); 
 
string[] result = new string[4]; 
 
if (lines[i].StartsWith("Queue1")) 
{ 
 //Copies into result 4 lines of  each parts  block 
  Array.Copy(lines, i + 1, result, 0, 4);         
  Client_Read_Parts_Records.Items.AddRange              
                                                                (result); 
  i = i + 5;  
} 
else 
{ i = i + 4; } 
 
Code 3 [1,3]:  Interaction of parts read client in the 
system 
 
 
Page 420
  
6. INTERFACE DESIGN SNAPSHOTS 
 
Initially the message file to which the write clients 
write may have information as shown in Fig. 3. 
 
 
 
Fig. 3:  Single Message File 
 
 
 
 
 
 
 
 
 
 
 
 
  
 
 
 
 
 
 
 
     
           
 
 
 
 
 
 
 
 
Extracting information from the message file, the 
Server Graphical User Interface (GUI) when it is 
started shows parts and address information in 
separate list boxes as shown in Fig 4. 
 
A “parts” block message is submitted via Parts 
Write Client GUI as shown in Fig. 5. An “address” 
block message is submitted via Address Write 
Client GUI in the same way. Accordingly, the 
Server GUI shows in its separate list boxes both 
newly submitted parts and address message blocks 
from the corresponding write clients by reading 
from the single message file as shown in Fig. 6. 
Parts Read Client GUI reads all the parts 
information from the single message file as shown 
in Fig. 7. Address Read Client GUI reads all the 
address information from the message file in the 
same way. The write and read clients can interact 
with the server via the message file in any order. In 
this way, message transfers take place during 
clients-server interaction in the designed system. 
This synchrony has been possible to achieve 
through the combined usage of a message file, 
threads, signed messages and message queues as 
explained in the earlier sections.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
    
 
 
 
 
 
 
 
Fig. 4: Server Graphical User Interface (GUI) 
 
Page 421
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                                   
 
 
 
 
 
 
 
 
 
 
 
                                         
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 5:  Parts Write Client GUI 
Fig. 6:  Server GUI showing updated info 
Fig. 7:  Parts Read Client GUI 
Page 422
  
7. CONCLUSION AND FUTURE 
WORK 
      
In the designed system, write clients use message 
queues to transfer their messages to the server end, 
while attaching signatures to the beginning of 
message lines with the server reading the messages 
from a file under separate threads and using the 
signatures to identify the message blocks while 
extracting them from the file, and while read clients 
can utilize the same signatures in the same file to 
extract their corresponding messages. This is the 
subtleness of the experimental work, the system’s 
homogeneity details being hidden from a high 
level. Thus the use of signatures in message lines, a 
message file, message queues, the utilization of 
threads and overall clients-server interaction are 
components of the designed system which make the 
system a good and useful implementation, giving 
insights on distributed systems by taking into 
account the collective components working in a 
series of coordinated steps. The work can be 
extended for future scope to take into account 
issues of security such as encryption and 
authentication during transfer of messages between 
clients and server. 
 
 
REFERENCES 
[1] Allen S. (2010), Copying Arrays, 
<http://dotnetperls.com/array-copy>, Accessed 
June 2010 
[2] Microsoft Support (2007), Message Queuing,   
<http://support.microsoft.com/kb/815811>, 
Accessed  June 2010 
[3] Mojica J. (2003), Splitting Arrays, Peachpit 
Press, 
<http://www.peachpit.com/articles/article.aspx?p=3
1938&seqNum=14>, Accessed June 2010 
[4] Strawmyer  M. (2004), Message Queuing, Code 
Guru Site: 
<http://www.codeguru.com/Csharp/Csharp/cs_misc
/article.php/c4241/>,  Accessed June 2010 
[5] Tanenbaum A. S. (1995), Distributed Operating 
Systems, Pearson Education, Inc. 
[6] Tanenbaum & Steel V. (2007), Distributed 
Systems: Principles and Paradigms, Prentice Hall, 
Inc. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Page 423
Proceedings of the
Conference on Engineering Research, Innovation and Education 2011
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh
* Corresponding Author: A. R. M. Jalal Uddin Janmali, 
E-mail: armjamali@yahoo.com
PACKING NON-IDENTICAL CIRCLES IN A SMALLEST 
CIRCULAR CONTAINER BY MODIFIED MONOTONIC BASIN 
HOPPING HEURISTIC APPROACH 
A. R. M. Jalal Uddin Jamali *, M. Asadul. Alam
Dept. of Mathematics, Khulna University of Engineering & Technology, Bangladesh
A.  Grosso
Dept. of Computer Science, University of Turin, Italy
Packing problems have mathematical as well as practical application point of interest. Monotonic Basin 
Hopping (MBH) heuristic approaches are successfully implemented for solving equal circles problems. For 
the presence of combinatorial part, unequal radii, simple extension of MBH approach is not the appropriate 
way to co-opt the problem of packing non-identical circles within a smallest circular container. Here, we 
present a modified Monotonic Basin Hopping heuristic approach to solve the problem. As well as some new 
perturbation moves are proposed which are suitable for the case of unequal circles packing problems.. 
Several improvements with respect to the best results reported in the literature have been detected. 
Key words: Circle Packing, Monotonic Basin Hopping, Multistart.
1. INTRODUCTION
The packing problem have a spectrum of 
application including production and packing for 
the textile, apparel, naval, automobile, aerospace 
and food industries, news paper, web pages design, 
in particular, to problems related to cutting and 
packing [Dyckhoff, 1990]. They are bottleneck 
problems in Computer Aided Design (CAD) and 
Computer Aided Manufacturing (CAM) where 
design’s plans are to be generated for industrial 
plants, electronic modules, nuclear and thermal 
plants, etc [Hifi M. and R. Hallah, 2009]. In 
particular, we consider in this paper, the Non-
Identical Circle Packing in a Circular Container 
(NICPCC) problems. The NICPCC problems can 
be described as follows:
Problem: To find the minimum circular container 
radius Dn which contains N non-identical and non-
overlapping circles with given radii. 
Mathematically, 
rmin                                                            (1)
Subject to 
Iirrrryx
iiii
 ;2 2222                        (2)
  jiIjirryyxx jijiji  ,,;)()( 222        ( 3)
rri )max(                                                         (4)
Though there is a long history of solving packing 
problems in literature, problems of non-identical 
circles in a minimized circle have received very 
little attention. Very few papers addressing the 
problem of packing non-identical paper; but most 
of them considered non-circular container like 
square container, rectangular container [Dyckhoff, 
1990]. Stoyan and Yaskov [Stoyan and Yaskov , 
(1998)] developed a mathematical model for 
packing different radii circles into a minimal length 
strip. Hifi and M’Hallah [Hifi and M’Hallah, 2008]
proposed adaptive and restarting techniques based 
approach for circular packing problems. Addis et. al 
[Addis et. al, 2008a] proposed a heuristic approach 
to solve unequal circle packing problems. Addis et 
al. [Addis et. al, 2008] investigated the problem of 
packing equal circles in the unit square and 
proposed a quite successful method (MBH ) for the
problem.  Jamali et al.   [Jamali et al.,2009  ] also 
used MBH approach to solve identical circles in a 
circular container rather than square container.  
Finally, a survey about this problem can be found in
[Szabó et al.,2005], and a recent book has been 
dedicated to the subject [Szabó et al., 2007].
In comparison with the best known problem of 
placing identical circles in a smallest container, 
here the fact that each disk has a different radius 
generates new difficulties and challenges. In fact, 
while the problem with identical radii can be 
considered as a pure continuous optimization 
problem, here the fact that each circle has a 
different radius adds some sort of a combinatorial
structure over the original one. This is an extremely 
challenging global optimization test problem. 
ISBN: 978-984-33-2140-4 Page 424
Hence researchers are searching for the efficient 
heuristic approximation algorithms to solve the 
problems. Here we proposed a modified Monotonic 
Basin Hopping (MBH), which is denoted as 
sequential Insertion Based MBH approach to solve 
the non-identical circles packing problems.
2. PROPOSED MODIFIED 
MONOTONIC BASIN HOPPING 
ALGORITHM
In order to deal with the case of non-identical 
circles one may think to extend the approaches 
employed for the case of equal circles with a slight 
variant in the perturbation moves: for instance, for 
the Full Jerk (FJ) perturbation strategy the 
coordinates of each circle i are displaced by a 
uniform random perturbation within the interval 
[−Δri,Δri], where ri denotes the radius of circle i 
(for Random Perturbation Jerk (RPJ) and Fixed 
Perturbation Jerk (FPJ) the displacement is 
restricted to a subset of circles) [Hifi and  
M’Hallah, 2008]. But, as we will see through some 
experiments, this simple extension is not the best 
way to tackle the problem. Indeed, the case of non-
identical circles has some peculiarities which have 
to be taken into account. The combinatorial side of 
this problem, represented by the different radii of 
the circles, can (and actually should) be exploited in 
some ways. In particular, we will propose a three 
phase modified MBH approach where the 
algorithm  optimize a fraction of relatively larger 
circles, and then insert one or a part of the 
remaining smaller circles sequentially and 
simultaneously optimize them.
The procedure consists of three main steps:  
(a) apply the Removal Strategy to remove “small ” 
circles;
(b) apply MBH on the remaining subset of larger 
circles;
(c) apply Insertion Rule for sequentially inserting 
the missing circles.
In what follows we define this approach as 
Sequential Insertion Based MBH (SIB-MBH). 
Besides all components of the MBH approach, 
there are two further components in this new 
approach namely (i) Removal Strategy (RemS) and 
(ii) Insertion Rule (IR). Before giving a formal 
description of SIB-MBH, we describe these below.
(i) Removal Strategy (RemS): It is observed from 
the experiments that small circles are sometimes 
relatively easily inserted in holes of optimized 
configurations for some subset of the larger circles 
without having to enlarge the container or with just 
a small enlargement. According to our Removal 
Strategy, circles are indexed in decreasing order 
with respect to their radius. Then, a
fraction of “small” circles is removed.
Of course, we need to define what a “small” circle 
is. We define a circle i
as a small circle if its radius is at least four times 
smaller than the largest one,
i.e., circle i is small if
j
nj
i rr 2,1
max
4
1

                                                       
(5)
Let us denote the set of initially removed circles as 
SR; then



 
 jnjiR
rriS
2,1
max
4
1
:,                                    (6)
This strategy strongly simplifies some instances of 
the problem through a considerable reduction of the 
search space during the first phase where some 
circles are removed.
(ii) Insertion Rule (IR): 
In the insertion process of a given circle cs in  SR, 
first the algorithm creates a regular grid of points 
over a square region containing the circular 
container. The step of the square grid is half of the 
inserted circle’s radius. The edge length of the 
square region is the sum of the diameter of the 
container and the radius of the circle to be inserted, 
so that the circular container, which is optimized 
previously by the reduced circles, is fully enclosed
within the square (both have the origin as their 
common center). Next, the algorithm searches for 
“free” spaces where to insert circle cs. Given a point
(xi, yi) over the grid, we declare the space around it 
as free, if its distance from the other circles’ centers 
is at least equal to rs, the radius of the circle to be 
inserted. In other words, if we place circle cs with 
center in point xi, yi) over the grid, the other circles’ 
centers are not in the interior of such circle. Note 
that at least one free space certainly exists. Indeed, 
according to the above definitions, all the corners of 
the square certainly correspond to free spaces. It is 
worthwhile to note that the definition of “free”
space does not mean that the space is large enough 
to contain circle cs with no overlap with the other 
circles: a partial overlap is permitted and, actually, 
if the circle to be inserted is small compared to
other circles, then even full overlapping may occur 
during the insertion process.
It may also happen that the new circle is not fully 
(or even not at all) contained in the circular 
container. In spite of this partial or full overlap with 
other circles and of the possibility of crossing the 
border of the circular container, a local search 
procedure started at the new configuration with the 
added circle is able to adjust it in such a way that 
no overlap occurs without enlarging the radius of
the circular container or with an as small as 
possible enlargement of such radius.
Page 425
Once we have defined the insertion procedure, we 
are ready to give a formal description of the whole 
algorithm:
Sequential Insertion Based MBH :
Step 1(RemS): remove the set SR of all the 
“small” circles
Step 2(MBH): Apply MBH on the reduced 
problem.
Let X be the outcome of MBH
   While SR =    
     Let s Є argmax{ri : i Є SR}
Set X = IR(X, s)
Set SR = SR \ {s}
   EndWhile
Return X
In the above algorithm MBH can be easily 
substituted by any other algorithm returning a
configuration in the reduced space.  
3. COMPUTATIONAL EXPERIMENT
AND DISCUSSION
In this section we will perform some experiments to 
investigate different issues. In particular we will 
study:
• The performance of the proposed perturbations;
• The performance of the Sequential Insertion 
Based MBH (SIB-MBH) approach;
The test instances which will be considered are 
those reported in [Hifi  and M’Hallah, 2008]. 
These are 18 test instances for the case of unequal 
circles. The characteristics of each test are indicated 
in Table 1. In such table column Test n. denotes the
identifier of the instance; column n denotes the 
number of circles of the instance; column Radii 
denotes the different radii of the circles in the 
instance; column BestKnown denotes the best 
known value in the literature for the instance.
Table 1. Test set with unequal circles
Page 426
3.1 Experiments with different perturbation 
moves and with the sequential insertion 
strategy
The different perturbation moves which will be tested are 
the Full Jerk (FJ) one [Jamali et al., 2009] (with 
perturbation range ∆i = 0.8ri for the coordinates of the i-
th circle), the Random Jump (RJ) perturbation move 
(with a number of randomly selected   circles, on which 
the perturbation is carried on, equal to ┌(n/20 + 
1)┐, and the Radius Based Random Swap (RBRS) 
one (with ┌(n/20 + 1)┐, randomly selected pairs of 
circles on which the perturbation is carried on). 
Experiments are performed both with the standard 
MBH approach and with the moderate MBH i.e. the 
SIB-MBH approach. In all cases we set 
MaxNonImp =200. The number of runs is R = 50 
for all tests except for the highly computationally
demanding Test n. 18 for which we reduced the 
number of runs to R= 6.
For what concerns SIB-MBH, we report in Table 2 
for each test instance the total number n of circles 
for the instance and the reduced number of circles 
after removal of the “small” circles. We observe 
from the table that for some test instances like, e.g., 
n. 6-10  a large number of “small” circles is 
removed. For some other instances a small number 
of circles is removed (like, e.g., instances n. 4 and 
11). Finally, for the test instances n. 1, 2, 3, 12, 13 
and 18 there is no “small” circle and, consequently, 
the MBH and SIB-MBH approach are equivalent 
ones.
Table 2. The Impact of Removal Strategy in
SIB-MBH approach
       
Table 3. The performance of MBH approaches with different perturbation moves. Note that in this table 
OurBestResults is denoted as OBRs. 
Page 427
The results are reported in Table 3. Column Test n. 
denotes the identifier of the test instance as 
indicated in Table 1. Column OBRs 
(OurBestResult) denotes the best results we could 
obtain during all our experiments. Note that in all 
cases a value (in the Column OBRs) at least as 
good as the BestKnown one in the literature as 
reported in Table 1, is reached and that values in 
boldface indicate better results compared to the 
BestKnown ones. The next following three columns 
report the number of successes on each instance for 
each of the three perturbation moves tested (FJ, RJ, 
RBRS) with MBH approach. The last three 
columns report the number of successes on each 
instance for each of the three perturbation moves 
tested (FJ, RJ, RBRS) with SIB-MBH, i.e. with the
use of the sequential insertion strategy. It is 
worthwhile to explain here what do we mean by 
number of successes? When the number of 
successes is equal to 0, this means that the approach 
was unable to reach the best known result in the 
literature. For all the instances for which the best 
result obtained by an approach was at least as good 
as the best known one in the literature, the number
of successes is the number of runs where the best 
result has been obtained. In the latter case, when a 
result better than the best known one in the
literature could be obtained, we also report within 
parenthesis such result. We also remark here that 
for Test n.13, we have obtained the best result –
113.5552♠ by the 500 runs of SIB-MBH(RBRS) 
approach 2, while for Test n.18 we have obtained 
the best result– 11.5119♣ by the SIB-PBH(FJ) 
approach discussed later on.
In the table the row named Failure reports the total 
number of instances where the approach was unable 
to reach the best known result in the literature (or, 
equivalently, the number of instances for which the 
number of successes is equal to 0). Similarly, row 
Success reports the total number of instances where 
the approach was able to obtain a solution at least 
as good as the best known one. Row Imp. reports 
the  total number of instances for which the 
approach was able to obtain an improved solution 
and, finally, row B. Imp. indicates the total number 
of instances for which the approach was able to 
obtain an improved solution which is also the 
overall best among all those obtained in the 
different experiments. Now we briefly discuss the 
results reported in Table 3. At first we consider the 
performance of the different perturbations moves 
within the standard MBH approach, i.e. MBH 
without sequential insertion strategy. We observe 
that the MBH(RBRS) approach was able to obtain 
success in 13 instances out of 18; in five instances 
it was able to improve the available 
BestKnownResult  value and in three cases the 
improvement is a best one. Unfortunately, there are 
also five failures. Note that enlarging the number of 
runs only partially helps. Indeed, when we extended 
the number of runs to R = 500, we could get at least 
one success for all the instances but still two 
failures, namely for the two tests n. 9 and 10. The 
situation is even worse for the MBH(FJ) and 
MBH(RJ) approaches, for which the number of 
failures is clearly higher compared to that of the 
MBH (RBRS) approach; moreover, though there 
are some improvements in both the approaches, 
none of them has a best improvement.
Things get definitely better when we consider the 
performance of the different perturbations moves in  
the SIB-MBH approach. The SIB-MBH(RBRS)  
approach has no failure, five improvements and 
three best improvements; both SIBMBH (FJ) and 
SIB-MBH(RJ) approaches, though inferior with 
respect to SIB-MBH (RBRS), have only three 
failures but one best improvement. If we focus our 
attention on the comparison between MBH(RSBS) 
and SIB-MBH(RSBS), we can remark that the five 
failures in MBH(RSBS) occur with instances n. 6-
10, for which the SIB-MBH(RSBS) approach first 
removes a relatively large number of (“small ”) 
circles. Once such circles are removed, the 
problems get quite easy ones and the following 
sequential insertion can always be carried on 
relatively easily without having to enlarge the 
radius of the circular container (i.e., all the missing 
circles can be inserted in the “holes” of the 
container).
The total elapsed CPU times of the experiments for 
SIB-MBH(RBRS) approach is shown in the table 4. 
Table 4. The total elapsed CPU times 
of the experiments for SIB-
MBH(RBRS) approach
Page 428
Note that all the tests have been performed on a 
Pentium IV 2.4 GHz with 1GB RAM.
4.  CONLUIDING REMARKS
For the presents of combinatorial nature, in presents 
of unequal radii, we have proposed two new 
perturbation moves name Random Jump (RJ)and 
Radius based Random Swap (RBRS) for solving 
NICPCC problems. Experimentally it is shown that 
RBRS is more efficient in non-identical circle 
packing problem. We also proposed another variant 
of MBH approach – Sequential Insertion Based
MBH (SIB-MBH) approach which is only suitable 
for unequal circle packing problems. By 
experimentation we saw that SIB-MBH is more 
efficient than MBH approach for non-identical 
circle packing problems. We have also 
investigated the efficiency of the proposed 
algorithm for solving packing non-identical circles 
in minimum circular and have compared with 
available ones Below we point out the main 
achievements regarding packing problems:
• Proposed a variant of MBH approach -- SIB-
MBH approach for NICPCC. The use of the 
sequential strategy clearly enhances the 
performance of all the approaches, independently 
from the perturbation move employed (for a 
given perturbation move the performance with 
the sequential strategy is almost always better 
than the one without);
• Proposed two perturbation techniques for unequal 
circle packing problems. The RBRS move is a 
clear winner with respect to the FJ and RJ moves 
with a lower number of failures, a higher number 
of improvements and best improvements, and 
with a number of successes almost always larger 
than those obtained with the other moves. The 
only exception is represented by instance n.18. 
The peculiarities of this instance and a possible 
explanation for the worse behavior of RBRS,
with respect to FJ on it, will be discussed later
on.
• Radius Based Random Swap (RBRS) perturbation 
based SIB-MBH/PBH approach seems the most 
robust one in NICPCC.
• Obtained many improved solutions compared to 
the available literature
REFERENCES
1. Addis, M. Locatelli, F. Schoen, “Disk packing 
in a square: a new global optimization 
approach”, INFORMS: Journal on Computing, 
vol. 20849(4), pp. 516-524(2008a).
2. Addis, B., Locatelli, M., Schoen, F.: Efficiently 
packing unequal disks in a circle. Oper. Res. 
Lett. 36(1), 37–42 (2008a).
3. Cassioli A. , Locatelli M. and Schoen F., 
“Dissimilarity measures for population-based 
global optimization algorithms”, 
Computational Optimization and Applications, 
Springer , Vol.  45(2), DOI: 10.1007/s10589-
008-9194-5, 2010, pp.  257-281
4. Castillo I., Kampas F. J., Pinter J. D., “Solving 
circle packing problems by global 
optimization: numerical results and industrial 
applications”, European Journal of 
Operational Research, vol. 191 (3), Elsevier,  
2008, pp. 786-802 .
5. Dyckhoff , H., “A typology of cutting and 
packing problems”, Eur. J. Oper. Res, Elsevier, 
vol. 44,  1990, pp.  145-159. 
6. Hifi M., and R. M’Hallah, Adaptive and  
starting techniques-based algorithms for 
circular packing problems, Computational 
Optimization and Applications, vol. 39, pp. 17-
35 (2008).
7. Hifi M. and R. Hallah M’, “A Literature 
Review on Circle and Sphere Packing 
Problems:” Models and Methodologies, 
Advances in Operations Research,   Hindawi 
Publishing Corporation, Volume 2009, Article 
ID 150624, doi:10.1155/2009/150624, pp. 1-22
8. Jamali A. R. M. Jalal Uddin, A. Grosso, M. 
Locatelli, F. Schoen, Packing Identical Circles 
in a Minimized Circular Container by 
Monotonic Basin Hopping Heuristic Approach, 
Proceedings of 12th International Conference 
on Computer and Information Technology 
(ICCIT 09), Dhaka, Bangladesh.
9. Specht, E Packomania web site maintained by  
www.packomania.com , (2010).
10. Stoyan, Y., Yaskow, G.: Mathematical model 
and solution method of optimization problem 
of placement of rectangles and circles taking 
into account special constraints. Int. Trans. 
Oper. Res. 5, 45–57 (1998).
11. Szabó, P.G., Markót, M. C., T. Csendes, 
Global optimization in geometry-circle 
packing into the square. In: Audet, C., Hansen, 
P., Savard, G. (eds.) Essays and Surveys in 
Global Optimization, pp. 233– 266. Kluwer, 
Dordrecht (2005).
12. Szabó, P. G., M. C. Markót,, T., Csendes, E. 
Specht, L. G. Casado, I. Garcia,, New 
Approaches to Circle Packing in a Square, 
Optimization and Its Applications, Springer, 
Berlin (2007).
Page 429
  
 
 
Page 430
This Page Intentionally Balnk 
Page 431
This Page Intentionally Balnk 
Page 432
This Page Intentionally Balnk 
Page 433
This Page Intentionally Balnk 
Page 434
This Page Intentionally Balnk 
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Nazmin Akter,  
E-mail: nazmin.akter125@gmail.com 
Parallel Computing Using Remote Method Invocation 
 
Nazmin Akter* and Wadia Iqbal Chowdhury 
Metropolitan University, Sylhet, Bangladesh 
 
 
This paper consists of parallel computing using RMI (Remote Method Invocation). Parallel computing is the 
simultaneous use of multiple compute resources to solve a computational problem. This paper is on Parallel 
Computing using RMI system within 4 hosts. It will carry out Prime number calculations that would show 
how many prime numbers are there in the given number (user input) which could be a small or a large 
number. In single machine or host this calculation will take much time and instructions are executed one 
after another. It distributes the task among multiple hosts where the task will execute concurrently. For 
concurrency multithreading is used. This is done by using Remote Method Invocation system as because 
RMI itself is a distributed system. This paper describes key features of parallel computing and Remote 
Method Invocation its architecture and how it works. 
 
Key words: Parallel computing, Remote Method Invocation, RMI architecture, RMI parameters, Function 
of   RMI. 
 
 
1. INTRODUCTION 
 
In parallel computing a problem is broken into 
discrete parts that can be solved concurrently. Each 
part is further broken down to a series of 
instructions. Instructions from each part execute 
simultaneously on different CPUs [1]. RMI is a 
mechanism that comprises two separate programs, a 
server and a client. The server creates some remote 
objects, makes references to these objects 
accessible, and waits for clients to invoke methods 
on these objects. And in the client program obtains 
a remote reference to one or more remote objects 
on a server and then invokes methods on them. In 
this mechanism the server and the client 
communicate and pass information back and forth. 
 
It is referred to as distributed object application. It 
is relatively easy to use and remarkably powerful 
technology and allows the programmers to develop 
distributed Java programs with the same syntax and 
semantics used for non-distributed programs [3]. 
 
2. RMI ARCHITECTURE 
 
The RMI architecture defines how objects behave, 
how and when exceptions can occur, how memory 
is managed, and how parameters are passed to, and 
returned from, remote methods. RMI architect 
creates a system that extends the safety and 
robustness of the Java architecture to the distributed 
computing world. 
 
2.1 Interfaces - The Heart of RMI 
The RMI architecture is based on one important 
principle: the definition of behavior and the 
implementation of that behavior. RMI allows the 
code that defines the behavior and the code that 
implements the behavior to remain separate and to 
run on separate JVMs. In RMI, the definition of a 
remote service is coded using a Java interface.  
 
The implementation of the remote service is coded 
in a class. Therefore, the key to understanding RMI 
is to remember that interfaces define behavior and 
classes define implementation [3]. 
 
Fig. 1: The diagram illustrates the separation [3] 
 
It supports two classes that implement the same 
interface. The first class is the implementation of 
the behavior, and it runs on the server. The second 
Page 435ISBN: 978-984-33-2140-4
  
class acts as a proxy/stub for the remote service and 
it runs on the client. 
 
 
Fig. 2: RMI system implementing same interface 
[3] 
 
A client program makes method calls on the proxy 
object, RMI sends the request to the remote JVM, 
and forwards it to the implementation. Any return 
values provided by the implementation are sent 
back to the proxy and then to the client's program.  
 
3. RMI ARCHITECTURE LAYERS 
 
3.1 Stub and Skeleton layers 
The stub and skeleton layer of RMI lie just below 
the Java developer’s view. The stub uses the Proxy 
design pattern, an object in one perspective is 
represented by another (the proxy) in a separate 
perspective and it knows how to forward method 
calls between the participating objects [3]. 
 
The skeleton understands how to communicate with 
the stub across the RMI link. The skeleton carries 
on a conversation with the stub; it reads the 
parameters for the method call from the link, makes 
the call to the remote service implementation 
object, accepts the return value, and then writes the 
return value back to the stub. 
 
3.2 Remote Reference layer 
The Remote Reference Layers defines and supports 
the invocation semantics of the RMI connection. 
An object RemoteRef is offered by this layer which 
represents the connection to the remote service 
implementation object. This object understands the 
invocation semantics for remote services. To 
forward the method call the stub objects use the 
invoke() method in RemoteRef. 
 
3.3 Transport layer 
The Transport Layer makes the connection between 
JVMs. All connections are stream-based network 
connections that use TCP/IP. TCP/IP provides a 
persistent, stream-based connection between two 
machines based on an IP address and port number 
at each end. Usually a DNS name is used instead of 
an IP address. On top of TCP/IP, RMI uses a wire 
level protocol called Java Remote Method Protocol 
(JRMP). JRMP is a proprietary, stream-based 
protocol.  
 
The RMI transport layer is designed to make a 
connection between clients and server, even in the 
face of networking obstacles. 
 
 3.3 Naming Remote Objects 
Clients find an RMI remote service by using a 
naming or directory service that runs on a well-
known host and port number. RMI can use many 
different directory services, including the Java 
Naming and Directory Interface (JNDI). RMI itself 
includes a simple service called the RMI Registry, 
rmiregistry. The RMI Registry runs on each 
machine that hosts remote service objects and 
accepts queries for services, by default on port 
1099. 
 
3.4 How RMI works? 
On a host machine, a server program creates a 
remote service by first creating a local object that 
implements that service. Next, it exports that object 
to RMI. When the object is exported, RMI creates a 
listening service that waits for clients to connect 
and request the service. After exporting, the server 
registers the object in the RMI Registry under a 
public name [2].  
 
On the client side, the RMI Registry is accessed 
through the static class Naming.  It provides the 
method lookup () that a client uses to query a 
registry. The method  lookup() accepts a URL that 
specifies the server host name and the name of the 
desired service. The method returns a remote 
reference to the service object 
 
4. RMI PARAMETERS 
 
4.1 Parameters 
Parameters can pass by two ways: 
a) Pass-by value. 
b) Pass-by reference. 
 
4.2 Primitives Parameters 
When a primitive data type is passed as a parameter 
to a remote method, the RMI system passes it by 
value. RMI will make a copy of a primitive data 
type and send it to the remote method. If a method 
returns a primitive data type, it is also returned to 
the calling JVM by value.  
 
 
Page 436
  
4.3 Object Parameters 
When an object is passed to a remote method, the 
semantics change from the case of the single JVM. 
RMI sends the object itself, not its reference, 
between JVMs. It is passed by value, not the 
reference to the object. Similarly, when a remote 
method returns an object, a copy of the whole 
object is returned to the calling program object.  
 
Unlike primitive data types, sending an object to a 
remote JVM is a nontrivial task. A Java object can 
be simple and self-contained, or it could refer to 
other Java objects in complex graph-like structure. 
Because different JVMs do not share heap memory, 
RMI must send the referenced object and all objects 
it references. (Passing large object graphs can use a 
lot of CPU time and network bandwidth. 
 
RMI uses a technology called Object Serialization 
to transform an object into a linear format that can 
then be sent over the network wire. Object 
serialization essentially flattens an object and any 
objects it references. Serialized objects can be de-
serialized in the memory of the remote JVM and 
made ready for use by a Java program [3].  
 
4.4 Remote Object Parameters 
A client program can obtain a reference to a remote 
object through the RMI Registry program. There is 
another way in which a client can obtain a remote 
reference, it can be returned to the client from a 
method call [3].   
 
5. CREATING DISTRIBUTED 
APPLICATION BY USING RMI 
 
5.1 Steps to develop distributed a 
Application 
To develop a distributed application the following 
general steps are required: 
 
a) Interface definition for remote service. 
(example: PrimeNumber.java) 
b) Implementations of remote service. (example: 
PrimeNumberImpl.java) 
c) Stub and Skeleton files. 
d) A server to host the remote service. (example: 
PrimeServer.java) 
e) An RMI Naming Service that allows clients to 
find the remote services. 
f) A client program that needs the remote services 
(example: PrimeClient.java).  
 
5.2 Steps to build RMI system 
To develop a RMI system the following general 
steps are required: 
 
a) At first a java code should be written for the 
interfaces (example: PrimeNumber.java) and 
compile it. Then implement same interface in 
the server and client, where the stub class of 
client and the implementation class (example: 
PrimeNumberImpl.java) of server uses this 
interface defines the behavior. 
 
Fig. 3: RMI System. 
 
b) Write a java code for the implementation 
classes which runs in server. The behavior is 
implemented in the implementation that was 
defined in the interface. 
 
c) Run the RMI compilers, rmic, which runs on 
the implementation class. It generates stub 
(example: PrimeNumberImpl_Stub) as jdk 1.5 
versions is used.   
 
d) Write a java code for the remote service host 
program (example: PrimeServer.java) it 
contains only the service. 
 
e) Write a java code for the client program and 
compile it. The client sends the request to the 
hosts to do its task and receives the result. 
 
f) Lastly install and run the RMI system. For this, 
start the registry rmiregistry on each server 
which contains the information of the remote 
service of each server. The client gets the 
service information from the rmiregistry and 
hooks up with its desired server. Then run the 
Page 437
  
servers and send the request from the client 
host. Fig.3 shows the details of the process. 
 
5.3 Analysis 
The following figure shows the time difference 
between single and four hosts. It will carry out 
Prime number calculations that would show how 
many prime numbers are there in the given number 
(user input) which could be a small or a large 
number. In single machine or host this calculation 
will take much time and instructions are executed 
one after another. Our aim was to distribute the task 
among multiple hosts where the task will execute 
concurrently. For concurrency we have used 
multithreading. This is done by using Remote 
Method Invocation system as because RMI itself is 
a distributed system. And here it is taken some 
inputs and show the time that it takes for 
calculation. The white bar shows the calculation 
time for single host and black bar shows the 
calculation time for multiple host. From the graph 
and table it can be easily understand the advantages 
of this system.  
 
Table 1:  Efficiency comparison of Single host with 
four hosts. 
Number Single Host 
(sec) 
Four Hosts 
(sec) 
50,000 1.839 1.452 
1, 00000 5.094 3.539 
1, 50000 11.866 7.43 
2, 00000 17.097 9.173 
 
With the above data the following graph could be 
drawing which shows the time differences between 
single and four hosts. 
 
 
Fig. 4: Time differences between single and four 
host 
 
 
6. CONCLUSION 
RMI or Remote Method Invocation is used for 
parallel processing. It is a Distributed object 
application. The RMI System can process a large 
volume of workloads in parallel by distributing the 
workloads to multiple machines. It is the system 
that support only java program. From this paper, it 
is clear that distributed program using RMI is much 
faster then non-distributed program.  
 
7. REFERENCES 
 
1. Parallel Computing, Online article. accessed at: 
http://computing.llnl.gov/tutorials/parallel_com
p/  
2. Sun’s RMI FAQ, Online article. accessed at: 
http://java.sun.com/javase/technologise/core/ba
sic/rmi/index.asp  
3. jGuru Remote Method Invocation, Online 
article. accessed at: 
http://java.sun.com/developer/onlineTraining/r
mi/RMI.html  
Page 438
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
*
 Corresponding Author: A. K. M. Kamrul Islam,  
E-mail: kamrul3000@gmail.com 
PERFORMANCE EVALUATION OF KALMAN FILTER IN 
ACCOUSTIC ECHO CANCELLATION 
 
 
A. K. M. Kamrul Islam  
Department of Computer Science & Engineering, IUBAT- International University of Business,  
Agriculture & Technology, Uttara, Dhaka-1230. 
e-mail: kamrul@iubat.edu 
 
Md. Anamul Haque* 
Department of Computer Science & Engineering, Jahangirnagar University, Savar, Dhaka-1342. 
e-mail: arifcse12@gmail.com 
 
 
In wireless communication each signal propagates different paths and is debilitated by fading, attenuation, 
non-linear distortion and noise. Similar circumstance is found in the sound system of a conference room. 
Output signal turns out from the speaker reflected back to the microphone from numerous directions of the 
room. Analogically, these reflected feedback signals resemble the multi-path propagation of wireless 
communication; exception is that the noise level is very low. The signal path of the feedback signal is a non-
linear system can be replaced by a finite impulse response filter. The aim of the project work is to resolve the 
situation eliminating both noise and feedback signals from the microphone to combat the occurrence of 
echo. In this regard, Kalman filter is used to recover the original signal from the noisy and severely 
interfered microphone signal before sending to the speaker. Performances of Kalman filter is also analyzed 
in acoustic echo cancellation technique.   
 
 
Key words: Predictor-corrector algorithm, near and far-end signal, Accoustic echo cancellation (AEC) and 
Kalman equation, Kalman gain. 
 
1. INTRODUCTION 
 
In wireless communication, the transmitted signal 
from any source may traverse through multiple 
paths towards the receiver. Such propagation 
happens by the obstruction or reflection of natural 
barriers such as ground, buildings, vehicles, hills at 
different atmospheric levels [1]-[2]. As a result of 
such propagation, the receiver receives multiple 
copies of same signal each of different physical 
length. Each signal experiences different noise, 
attenuation, phase shift and delay [3]-[4]. Sound 
system in a conference room resembles the 
consequences of wireless transmission [5]. A voice 
signal been sent by one participant come out from 
the speaker propagates through multiple paths and 
echoed back from the conference room walls 
crossing multiple directions yield the distortion of 
root voice signal of the microphone. The 
distinguishing feature between the two analogous 
systems is that the feedback signal in acoustic echo 
cancellation retains less signal length and also low 
strength. The goal of the paper is to learn the 
performances of Kalman filter through evaluation. 
Frequency domain adaptive filter (FDAF) has an 
adaptable feature riding which the coefficients of 
the signal continually adjust. At every time state the 
input signal is estimated and after processing error 
signal is generated and refine the coefficients of the 
estimated signal. Least mean square (LMS) filter 
uses the instantaneous estimates of its weights 
where FDAF uses weight vector gained from all the 
previous estimates. Kalman Filter is widely used 
due to its recursive strategy to estimate the current 
Page 439ISBN: 978-984-33-2140-4
  
state of the process from the previous measur
update in a way that would keep the mean square 
error minimized. 
 
2. KALMAN FILTER 
 
The Kalman filter is an adaptive least square error 
filter which is distinct from other adaptive filters 
due to its state-space concepts and recursive
features [6]. It is an efficient algorithm for 
estimating a signal in presence of Gaussian noise 
and to continuously update the best estimate with 
the system current state. In particular, each
estimate is computed from the previous best 
estimate and current input data without altering 
stationary or non-stationary environments [7
Kalman filter has been applied in areas like 
Aerospace, Marine Navigation, nuclear power plant 
implementation and many others. 
 
3. THEORY & CONCEPT OF
    KALMAN FILTER 
 
One step predictor is the key of mathematical 
formulation of Kalman filter [8]. It predicts state 
space while introducing new observation 
input [9].  
 
 
 
ement 
 
 updated 
]. 
 
y(n) in the 
At the end of processing of y(n), it calculates the 
error covariance of prediction and updates the mean 
square estimation for the imminent operation. As an 
inherent part of correction of predict, Kalman gain 
G(n) works along with the new observation 
For this reason, Kalman filter is also known as the 
predictor-corrector algorithm [10]. Mathematical 
equations of Kalman Filter which are also known as 
kalman equations mentioned below along with their 
respective details. 
Kalman gain equation in (1) is: 
()1,(),1()( −+= CnnKnnFnG H
Where error correlation matrix k(n, n-
defined by the expectation of the error correlation 
matrix of previous time unit. 
ε (n, n-1) is the predicted state-error vector at time 
n [10] 
The inverse of the correlation matrix 
R-1(n) in (3) is described by multiplication of the 
previous error vector k(n, n-1)(2) with correlation 
of measurement matrix[10] C(n) in presence of 
relevant Gaussian measurement noise (A white 
noise added by Gaussian distribution). Explicitly it 
is: 
 
Fig: Block diagram of Kalman Filter including one 
step predictor 
()1,([)1,( ∈−∈=− nnnEnnK H
1 )()1,()([)(− +−= QnCnnKnCnR H
α(n). 
1) −Rn      (1) 
1) can be 
  (2) 
of innovations 
   (3)  
)]1, −n
1
2 )]( −n
Page 440
  
As a detection of the innovation i.e. the new 
information of observation y(n) can be 
in (4): 
Time state update of one unit for current use is the 
result of multiplication of a transition matrix 
F(n+1, n) and previous time state (
∧
x
incorporating Kalman gain G(n) and innovation 
α(n) as shown in (5). This is the basic prediction 
equation. 
( ) ( ) ( )|,1|1 1
^^
ynxnnFynx nn ++=+ −
Correction of error correlation matrix
current time can be obtained by (6): 
)()()1,()1,()( +−−= KnCnGnnFnnKnK
In the final part of the calculation, we need to 
update the measurement of the future error 
correlation matrix k(n+1, n). As an integral part of 
this, white Gaussian process noise Q1
added to it. Mathematical equation has composed in 
(7) 
,1()(),1(),1( nnFnKnnFnnk H ++=+
 
4. ACCOUSTIC ECHO 
    CANCELLATION 
 
An acoustic echo cancellation is noise cancellation 
of a recorded speech signal. A recorded speech 
signal from the loud speaker returns to the 
microphone as an echo reflecting from the room 
and mingled with original speech signal. This 
signal is also called far-end speech signal. The 
speaker signal, i.e. the near-end speech signal at the 
microphone input thus is not uniform and distorted 
[8]. During the processing of the distorted signal 
adaptive filter produces the best estimation of the 
noisy signal. Subtraction of this noisy signal from 
original signal will solve the problem. Concurrently 
an error signal will be generated mirroring the 
difference between the actual signal and our 
approximation and hence coefficients will be 
updated. 
 
4.1 Experimental Setup 
Signal inserted in microphone of a hall room is the 
direct speech signal )(nd  of the speaker and 
echoed signal )(ˆ nd  that arises from the reflection 
of walls in Fig.1. Direct speech signal is called 
near-end signal (NES) and the echoed
called far-end signal (FES). The combined
signal of the microphone, ()( dn =µ
Objective of an echo canceller is to remove the far
end signal so that only near-end signal is sent to the 
)|()()()( 1−
∧
−= nynxnCnynα
calculated as 
       (4) 
)| 1−nyn  
)()( nnG α (5) 
 of the 
)1,( −nn    (6) 
(n) will be 
)() 1 nQ+    (7) 
 signal is 
 input 
)(ˆ) ndn + . 
-
loud speaker. The path or channel between loud 
speaker and the microphone is represented by a 
long finite impulse response filter. For an instance, 
Room environment of an acoustic echo canceller 
depicted in Fig. 1. 
 
Fig.1: Room environment of Acoustic Echo 
Canceller 
 
5. RESULTS 
 
We used chebyshev2 filter to have the basic channel 
impulse response of the room. The filter is assumed 
to be fourth order (N=4) and sampling frequency 
as 8000. Stop-band ripple presumed as
frequency Wn will be in the range (0.1 <  Wn < 
0.7). Let us consider number of time sequences 
= 4001. The time domain and frequency domain 
views of the system are show in Fig. 2 and 3 
respectively. 
 
Fig.2: Impulse response of the room 
(Frequency domain) 
AE
NE
FES 
FES 
M
Noised Cancelled 
Received 
 
 
 
 
                 + 
∑ 
 
 
 
 
fs 
 20 and edge 
M 
 
 
Page 441
  
                   Fig.3: Impulse Response of the room 
(Time Domain) 
 
5.1 Kalman Filter Observations 
Let us observe the performance of Kalman filter
considering the signal to noise ratio (SNR = 45
SNR=30)  and number of samples 15000
 
KalmanSignalDenoiser(Noisy, Clean, f
method of working with Kalman filter in Matlab. It 
consists with three parameters: noisy signal, desired 
signal and sampling frequency. The output is our 
target signal and the mean error, max error and 
standard deviation of all the points around the mean 
error have been identified is in Fig.4. 
The amplitude of the filtered wave and mean square 
error in error estimation had shown in 
4,5,6,7,8,9,10,11 respectively for Kalman filter at 
SNR= 45 to 30. 
 
At SNR = 45, Number of Samples = 15000 
 Fig.4: Amplitude comparison of Filtered wave 
relating to original wave (in milivolts)
0 0.05 0.1 0.15 0.2 0.25 0.3
-0.8
-0.6
-0.4
-0.2
0
0.2
0.4
0.6
Time [sec]
Am
pl
itu
de
Room Impulse Response
 
 
 
 to 
.  
s) is the 
Fig. 
 
 
Fig.5: Error in estimation of clean wave relating to 
original wave (mean error = 1.383x10
 
At SNR = 40, Number of Samples = 15000
 
Fig.6: Amplitude comparison of Filtered wave 
relating to original wave (in milivolts)
Fig.7: Error in estimation of clean wave relating to 
original wave (mean error = 3.714x10
 
0.35 0.4 0.45 0.5
 
 
-5). 
 
 
 
 
-5). 
Page 442
  
At SNR = 35, Number of Samples = 15000
Fig.8: Amplitude comparison of Filtered wave 
relating to original wave (in milivolts)
 
Fig.9: Error in estimation of clean wave relating to 
original wave (mean error = 8.6318
 
At SNR = 30, Number of Samples = 15000
 
 
 
 
 
x10-5). 
 
Fig.10: Amplitude comparison of Filtered wave 
relating to original wave (in milivolts)
 
 
 
 
 
 
     
 
 
 
 
 
 
Fig.11: Error in estimation of clean wave 
original wave (mean error = 2.0361x10
 
Table-I demonstrates the results of observation
Kalman filters. We portrayed the observation of 
several SNR from 45 to 30.  
 
Table-I Performances of kalman filter with varying 
signal to noise (SNR) ratio
 
SNR(db) 
Errors in Kalman Filter
Max Min 
45 0.0230 1.38e-5 0.0037
40 0.0344 3.71e-5 0.0061
35 0.0578 8.63e-5 0.0093
30 0.0918 2.03e-4 0.0143
 
 
 
relating to 
-4). 
s of 
 
 
SD ET 
 3.96 
 3.26 
 3.15 
 3.18 
Page 443
  
According to the analysis, change in Max error, 
Mean error and standard deviation (SD) of the 
mean error of Kalman filter with the increase of 
SNR are mutually related. At the time of SNR = 45 
db Max error of Kalman filter is 0.0230 which 
prescribes its good performance. One important 
thing to notice is that Kalman filter require much 
execution time (ET). As the noise increases the max 
error also increases and ET decreases due to the 
adaptability. For Kalman filter max error is 
inversely proportional to the SNR and retain strong 
convergence. 
 
6. CONCLUSIONS 
 
We can conclude this paper with subtle differences 
on the performances of Kalman filter regarding 
acoustic echo cancellation technique. Besides its 
aptitude in almost all system Kalman filter 
performs best in a heavily noisy system. The only 
shortcoming of the Kalman filter  
is its lengthy process time. Kalman filter, which 
contains an easy operational algorithm, is easy to 
implement than other filters. Kalman filter 
continuously update the best estimate with the 
system current state and provides good 
convergence. For heavily noisy system Kalman 
filter performs extremely well. We can easily apply 
it in areas like Aerospace, Marine Navigation, 
nuclear power plant implementation. Though 
Kalman filter can smoothly handle the noise from 
the original signal, it takes comparatively much 
time for processing.  
 
REFERENCES 
 
1.  Marvin K. Simon, Mohamed-Slim Alouini, 
“Digital Communication over Fading 
Channels: A Unified Approach to Performance 
Analysis”, Copyright  2000 John Wiley & 
Sons, Inc. ISBN 0-471-31779-9, pp.4-10, 
pp.15-20. 
2.  D. Molkdar, “Review on radio propagation 
into and within buildings,” IEE Proc. H, vol. 
138, February 1991, pp. 61–73. 
3. Zhiwei Zeng, “Digital Communication via 
Multipath Fading Channel”, Cpre537x Final 
Project, November 2000, pp.17-22.  
4. J. K. Cavers and P. Ho, “Analysis of the error 
performance of trellis coded modulations in 
Rayleigh fading channels,” IEEE Trans. 
Commun., vol. 40, January 1992, pp. 74–80. 
5. P. Yegani and C. McGlilem, “A statistical 
model for the factory radio channel,” IEEE 
Trans. Commun., vol. COM-39, October 1991, 
pp. 1445–1454. 
6. E. R. Ferrara, Jr., “Fast Implementation of 
LMS Adaptive Filter,” IEEE Trans. 
Acoust.,Speech, Signal Processing,vol. ASSP-
28, pp. 474-475 (1980). 
7. Alexandar D. Poularikas, Zayed M. Ramadan, 
“Adaptive Filtering Primer with Matlab”, 
CRC-Taylor and Francis, ISBN 0-8493-7043-
4, 1999, pp.55-58, pp.101-2. 
8. Satoru Emura, Yoichi Haneda, and Shoji 
Makino, “Enhanced Frequency-Domain 
Adaptive Algorithm for Stereo Echo 
Cancellation”, IEEE Transc. Vol-II, pp.1901-
03. 
9.  J. S. Soo and K. K. Pang, “Multidelay Block 
Frequency Domain Adaptive Filter,” IEEE 
Trans. Acoust. Speech, Signal Processing, vol. 
ASSP-38, pp. 373-376 (1990). 
10. Greg Welch and Gary Bishop, “An 
Introduction to the Kalman Filter”, TR 95-041, 
Department of Computer Science University of 
North Carolina at Chapel Hill, April 5, 2004, 
pp.3-7. 
 
 
Page 444
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Second B. Author,  
E-mail: somebody@somewhere.com 
Importance of Physics Education for the Undergraduate Medical 
Students of Bangladesh 
 
Dr. Ramit Azad,  
PhD in Physics and Mathematics 
Department of Operations Management 
American International University-Bangladesh,  
Dhaka, Bangladesh 
rmt_azad@yahoo.com 
 
and 
 
Dr. Lourdes Reyna Penaranda Villegas 
PhD in Biological Sciences 
lourdesp@mail.ru 
 
Abstract 
 
The study is done to identify one of the remarkable lacking in conducting undergraduate medical course 
curriculum (MBBS) in Bangladesh and that is the absence of the study of physics. Physics deals with the 
most general laws of nature. The human body and its components are physical objects that can be viewed, 
measured and altered in ways that resemble what a physicist might do with any physical object. There is a 
long tradition of physicists and physics-based techniques making important contribution to biology and 
medicine. The relationship between physics and medical science proves that collaboration between different 
disciplines can be hugely productive. Physics is at the heart of many medical techniques, and life scientists 
are finding new ways to study biological matter. Bio-systems are based on the same laws as physical 
systems. Medical physics is an applied branch of physics concerned with the application of the concepts and 
methods of physics to the diagnosis, management and treatment of human disease. Some vital areas of 
application are ionizing radiation, imaging with X-rays, ultrasound and MRI, nuclear medicine, 
electroencephalography, electrocardiography, thermography, hyperthermia, optical imaging, and RF and 
laser surgery. For this purpose an internet survey has been conducted and it is found that medical students in 
different highly developed countries like USA, Russia, Germany, England, France etc. are studying physics 
long before. Unfortunately the study of physics is not included in the undergraduate medical education 
curriculum in Bangladesh. Some may raise question, whether it is really meaningful to teach physics in 
undergraduate since it is taught in the higher secondary schools. However, the course taught in the secondary 
school level it is very much general. For the better understanding of the subject and its correlation with 
future professional activities is necessary to study physics at advanced level. For instance physics is taught in 
BUET and other universities teaching engineering. Pharmacy students are also studying physics.  Now it is 
suggested that physics courses should be included in the undergraduate medical curriculum in Bangladesh. 
This course will facilitate to understand the advanced medical courses.  
 
Key words: medical education, physics, medical techniques, life science, medical physics, interdisciplinary 
correlation. 
 
1. INTRODUCTION 
 
The physics has wide application to medicine. 
Physics is changing the way medicine is practiced. 
While a doctor will still use a stethoscope, a 
diagnosis now often requires devices that make use 
of sophisticated physics. As a consequence of 
technological evolution of medical science, doctors 
are more and more recognizing the influence of 
physics to medicine. The history of the application 
of physics to medicine started in the Islamic Golden 
Age. De Gradibus an Arabic book published by 
Page 445ISBN: 978-984-33-2140-4
  
Muslim physician Al-Kindi (801-873 CE) was the 
first attempt at serious quantification in medicine. 
Al-Kindi also developed a system based on the 
phases of the moon, that would allow a doctor to 
determine in advance the most critical days of a 
patient’s illness [1]. Ibn Sina the father of modern 
medicine in his famous book The Canon of 
Medicine (1025 C.E.) [2] , (the first book dealing 
with evidence based medicine) established a set of 
rules, one of them is “The quality of drug must 
correspond the strength of the disease. For example 
there are some drugs whose heat is less than the 
coldness of certain diseases, so that they would 
have no effect on them.”The law is directly related 
to the heat and thermodynamics chapter of physics. 
The contribution of famous Muslim physicist Ibn 
Al-Haytham (Al-Hazen) to anatomy and 
physiology include many improvements in our 
understanding of the process of visual perception in 
his Book of Optics [3], published in 1021. Much 
later in Europe Leonardo da Vinci, showed 
profound interest in the mechanics of human 
locomotion. The subsequent gradual development 
in physical tools contributed to advances in the 
medical sciences. One outstanding example is the 
microscope by Leeuwenhoek during the 17th 
century. The development of electromagnetism in 
the 19th century enabled physicists to make 
contributions to medical treatment and diagnosis. 
D’Arsonval, a French physicist, pioneered the 
therapeutic use of high-frequency electric currents 
and pointed the way towards development of 
critical measuring instruments. Thus 
electrocardiography and electroencephalography 
was developed. The discoveries of X-rays and 
radioactivity by the physicist Roetgen in 1895 and 
Becquerel in 1896 were rapidly followed by the 
application of ionizing radiations to the diagnosis 
and treatment of disease. This actively has been 
primarily responsible for bringing physicists 
directly into the sphere of hospital. Bio-systems are 
based on the same laws as physical systems. 
Medical physics is an applied branch of physics 
concerned with the application of the concepts and 
methods of physics to the diagnosis, management 
and treatment of human disease. Some vital areas of 
application are ionizing radiation, imaging with X-
rays, ultrasound and MRI, nuclear medicine, 
electroencephalography, electrocardiography, 
thermography, hyperthermia, optical imaging, and 
RF and laser surgery. Considering the profound 
relation of physics with medical science highly 
developed countries like USA, Russia, Germany, 
England, France, Italy, Ukraine, etc. included the 
physics education in their medical schools.  
 
 
 
 
2. METHOD  
 
An internet survey was done to different countries’ 
undergraduate and post-graduate program to find 
out if physics is taught at that level. Discussions 
were also performed with doctors who studied 
abroad and also in Bangladesh. 
 
3. RESULTS  
i) In many medical institutions of USA, medical 
physics is taught. Johns Hopkins School of 
Medicine is one of them [4]. 
ii) In all medical institutions of Russia, medical 
students are studying physics. [5] 
ii) Three Canadian universities currently offer 
undergraduate medical physics degrees.  
iii) Lund University of Sweden teaches physics to 
medical students. 
iv) In Bosnia and Herzegovina, medical students 
study biophysics. [6] 
v) In Belgium, medical students are taking general 
scientific courses, biophysics is one of them. 
vi) Medical studies in France include biophysics as 
a first year course. [7] 
vii) In Germany the first two years medical school 
consists of classes of basic sciences, physics is one 
of them [7]. 
viii) In Italy first three years are devoted to basic 
subjects including physics [7]. 
ix) Charles university (Univerzita Karlova) in 
Prague (Czech Republic) teaches physics to the first 
year medical students. [8] 
x) In Japan also medical students are studying 
physics.  
xi) In the MBBS course in India, in phase-1 some 
pre-clinical subjects are taught Biophysics is one of 
them [9]. Also there are books on Medical Physics 
written by Indian authors [10]. 
xii) According to the course curriculum of 
Bangladesh medical colleges, physics is not at all 
included. Thus the Bangladeshi doctors are 
deprived of gaining valuable knowledge in physics 
that could contribute some ground-breaking 
research outcome in near future. 
 
4. DISCUSSION   
 
The inclusion of physics education in the medical 
schools of different highly developed countries 
shows its importance. Some may raise question, 
since physics is taught in the secondary schools, is 
it really meaningful to teach it in undergraduate 
courses? However, the course taught in the 
secondary school level it is very much general. For 
the better understanding of the subject and its 
correlation with future professional activities is 
necessary to study physics at advanced level. For 
instance physics is taught in BUET and other 
Page 446
  
universities teaching engineering (American 
International University-Bangladesh teaches 
physics in engineering faculty which includes 
nuclear physics and modern physics). Pharmacy 
students are also studying physics.  The course 
should cover all necessary branches of physics 
(mechanics, electricity and magnetism, fluids, heat, 
sound, atomic and molecular physics, optics etc.). 
The physical concepts should be medically oriented 
with the intention of relating physics to the 
students’ future professional lives. Each topic 
should start with a medical case related with 
medical diagnosis and treatment. It is well known 
that vital areas of application of physics in 
medicine are ionizing radiation, imaging with X-
rays, ultrasound and MRI, nuclear medicine, 
electroencephalography, electrocardiography, 
thermography, cardiac pacemakers, hyperthermia, 
optical imaging, and RF, laser surgery. Once the 
equipment is accepted, the doctors should have 
sound knowledge on all those machines, so that the 
equipment can be used clinically. The doctors also 
should have knowledge on equipments’ physical 
concept and their effect on human body. 
 
 
5. CONCLUSIONS 
 
Considering the importance of physics education in 
medical science, it is suggested that physics courses 
should be included in the undergraduate medical 
curriculum in Bangladesh. This course will 
facilitate to understand the advanced medical 
courses. Now-a-days medical science has advanced 
beyond imagination but we are still following the 
eighties curriculum. If we don’t add physics in 
MBBS degree curriculum our students will fall 
behind in completion further in international arena 
and we have no right to deprive them in pursuing 
international standard education in Bangladesh. 
 
 
 
 
 
 
 
8. REFERENCES 
 
1. Ibrahim B. Syed PhD, "Islamic Medicine: 
1000 years ahead of its times", Journal of 
the International Society for the History of 
Islamic Medicine, 2002 (2): 2-9. 
2. Ibn Sina, Canon of Medicine, 1025. 
3. Ibn Al-Haytham, Book of Optics (Kitab al-
Manair), 1011-1021 
4. Viewed on 3rd January, 2011, 
http://search.hopkinsmedicine.org/search?q=ph
ysics&client=JHM_frontend&proxystylesheet=
JHM_frontend&output=xml_no_dtd&site=Joh
ns_Hopkins_Medicine_No_Media&btnG.x=34
&btnG.y=9, 
http://www.radonc.jhmi.edu/html/medical_phy
sics.html 
5. Viewed on 3rd January, 2011, 
http://www.medical-education-in-
russia.com/medicaleducationinrussia.htm 
6. University of East Sarajevo, viewed 3rd 
January, 2011, 
http://en.wikipedia.org/wiki/University_of_Eas
t_Sarajevo 
7. viewed 3rd January, 2011, 
http://en.wikipedia.org/wiki/Medical_school 
8. viewed 3rd January, 2011, 
http://www.lfhk.cz/article.asp?nArticleID=499
&nLanguageID=2  
9. viewed on 4th January, 2011, 
http://www.time4education.com/medical/medi
cal.asp?id=mbbs  
10. Ahmed M Mohammad, Physics for Medical 
Students, Wheatmark, 2008. viewed on 4th 
January, 2011, 
http://www.infibeam.com/Books/info/Ahmed-
M-Mohammed/Physics-for-Medical-
Students/1587369818.html  
 
Page 447
Visual-miR: Visualization system of 
precursor microRNA 
Md. Eamin Rahman1 (eamin_sust@yahoo.com), 
2 
Shahidul Islam*3 (si_sumon@yahoo.com), 
Shakhinur Islam Mondal4 
(shakhin2000@yahoo.com)  
1Department of Computer Science & Engineering, 
2Department of Genetic Engineering & Biotechnology  
3Lecturer, Department of Computer Science & 
Engineering, 4Lecturer, Department of Genetic 
Engineering & Biotechnology  
Shahjalal University of Science & Technology, Sylhet 
3114, Bangladesh 
 
Abstract 
MicroRNAs (miRNAs) are single-stranded 
small non-coding RNA molecules of about 
∼22 nucleotides which regulates near about 
30% of human genes involving cancer, tumor, 
neurodegenerative disorders, developmental 
timing, differentiation, proliferation, cell 
death etc. In the biogenesis, mature miRNAs 
are originated from their precursors (pre-
miRNA) containing more informative 
properties with the attributes of stable 
secondary structure. Proper exploration and 
visualization of the diversified sequences of 
pre-miRNA is noteworthy for the biologists in 
effective analysis and experimentation of pre-
miRNAs including the quest of finding a set of 
characteristics for unique identification. This 
article proposes a concept of pre-miRNA 
visualization and implemented a new tool 
Visual-miR for better perception of the 
sequences. This tool uses standard 
information visualization techniques as well 
as other innovative techniques. The Visual-
miR provides different visualization of linear 
pre-miRNAs sequences based on different 
properties with comparative viewpoint. By 
presenting techniques for visualizing pre-
miRNA in this unique tool, we believe to bring 
new prospects for scientists as they seek to 
make sense of the rapidly expanding body of 
miRNA discovery. 
Keywords: Visual-miR, Precursor microRNA, 
Sequence property, Information visualization 
techniques, miRNA discovery.  
Introduction 
Recent years have witnessed an explosive 
growth in RNA research, as numerous new 
non-coding RNAs (ncRNAs) have been 
discovered [1, 2]. It is increasingly evident 
that RNAs play important roles, far beyond 
transferring genetic information from DNA to 
protein. The microRNAs (miRNAs) are a 
special class of non-coding RNAs of ∼22-nt 
length that regulate the protein coding gene 
expression through incomplete 
complementary bindings at the post-
transcriptional level [3]. It is believed that 
near about 30% of human genes are 
regulated by miRNAs [4, 5] and as a 
consequence miRNAs have pulled the interest 
of biologists for its association in cancer and 
tumor with its therapeutic values [6]. Each 
miRNA molecule is derived from its precursor 
molecule precursor miRNA (pre-miRNA) 
which is the most thermodynamically stable 
state and in our system we used pre-miRNA 
sequences. Pre-miRNA has only a single 
Page 448
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
Rasedul Ishlam (rashedul.gen@gmail.com), 
polynucleotide chain which is composed of 
four different nucleotides e. g., A, U, G and C. 
To aid the continuous scientific effort for the 
expansion of the number of known miRNA 
families that is so far rather limited, we used 
the concept of graphical representation that 
will facilitate new insight in the realization of 
miRNA sequences and compare them for 
their different chemical features along with 
its sequence composition. In this study we 
applied a system named Visual-Mir to 
visualize different sequence properties of 
miRNA sequences for better understanding of 
them and visually compare miRNAs. 
Data visualization now benefits from 
developments in technologies that offer 
innovative ways of presenting complex data. 
Biological Data Visualization is a branch of 
bioinformatics concerned with the application 
of computer graphics, scientific visualization, 
and information visualization to different 
areas of the life sciences. This includes 
visualization of sequences, genomes, 
alignments, phylogenies, macromolecular 
structures, systems biology, microscopy, and 
magnetic resonance imaging data. In many 
areas of bioinformatics it is important to be 
able to view information at several levels of 
detail and shift between them readily, which 
can be challenging for software. Graphical 
representations of data can communicate 
complex information, help to understand 
complicated relationships between multiple 
variables, uncover information hidden in the 
data, and solve problems through visual 
representations in the form of data structures 
for expressing knowledge. Software tools 
used for visualizing these data range from 
simple, stand-alone programs to complex, 
integrated systems [7]. A large number of 
tools are available for visualization biological 
data that can range through one-dimensional, 
two-dimensional, multi-dimensional, 
text/web, hierarchies/graphs, and 
algorithm/software. The genome browser 
applications represent a one-dimensional 
world in that they display location-based 
features across a single axis defined by the 
genomic sequence data itself [8]. Two-
dimensional visualization is frequently used in 
RNA secondary structure analysis [9, 10]. For 
example, visualization method is successfully 
used in the study and comparison of 
nucleotide skews at different scales in various 
genomes in understanding this phenomenon 
GC-AT skew along with its evolution in the 
phylogenetic tree [11] and also in graphical 
representations to enumerate, construct, and 
analyze two-dimensional (2D) RNA secondary 
topologies [12]. RNA secondary structure, the 
pattern of base-pairing, contains the critical 
information for determining the three 
dimensional structure and function of the 
molecule which can be understood by three 
dimensional representations [13].  
 A variety of computational methods 
have used the secondary structure of RNA 
molecules to search and categorize ncRNAs 
including miRNAs [9, 14, 15, 16], but many of 
these methods are limited in their use of 
secondary structure. The visualization of 
biological data is hampered by the wide range 
of data types and exponentially increasing 
volume of data available, and by the lack of 
interoperability of existing tools. In this study, 
we present a complete and fine scheme to 
represent sequence features of miRNA 
molecules graphically. These representations 
will facilitate the exploration of the numerous 
detailed facets of each miRNA constituents 
and their combined patterns in creating new 
insights regarding to miRNAs. Herein we 
introduce five categories of 14 different 
techniques of information visualization that 
are discovered in this article as novel two 
Page 449
dimensional representations of miRNA 
sequences. 
 
Materials and methods  
Materials 
Human pre-miNRA sequences are retrieved 
from MirBase [17] release 15.0. We analyzed 
randomly selected 100 pre-miRNA sequences 
from 940 reported pre-miRNA entries for 
their nucleotides with different nitrogenous 
bases (A, U, G and C) and two parent 
compounds of the nitrogenous bases, 
pyrimidine and purine. Visualized information 
of nitrogenous bases and the parent 
compounds are named as AUGC and PuPy 
data type respectively. AUGC data type 
divides the sequence into four groups for four 
different nucleotides e.g., A, U, G and C 
whereas PuPy data type separates each 
sequence into purine and pyrimidine bases. 
These two data types are effectively used in 
our system for proper understanding of the 
chemical properties of pre-miRNAs and to 
realize the sequences form different 
viewpoints of visualization. 
Methods 
This software provides five looks of pre-
miRNA sequences using different visualization 
techniques from exceptional standpoint that 
are named as 1) Ratio Look, 2) Bar Look, 3) 
Vector Look, 4) Skew Look and 5) CMP Look. 
The Ratio Look stands for percentage of 
AUGC and PuPy data types in total sequence 
length as rectangle ratio look with ratio 
percentage in x-axis and a constant width in 
the y-axis is used. Another Ratio Look is pie 
ratio look for the same data within a pie chart 
to visualize the relative proportion of these 
two different data types with distinctive 
colors. The Bar Look represents cumulative 
positional number of occurrences of AUGC 
and PuPy data types for visualization of pre-
miRNA sequences in two types of 
visualization for cumulative groupBar and 
stackBar view. When considering each 
nucleotide as a vector the Vector Look 
presents total sequence as a graph. We 
classified the Vector Look into DV-Curve and 
inverse DV-Curve to observe a particular 
sequence from two inversely related views 
for AUGC data type. DV-Curve means Dual-
Vector Curve that uses two vectors to 
represent one alphabet of nucleotide 
sequences for a good visualization of 
sequences of any length [18]. Inverse DV-
Curve uses inverse interchange of graphical 
vector representation of G and U for the 
same sequence. In the Skew Look, pre-miRNA 
sequences are visualized for GC-AU skew in a 
2-D image to see the occurrence of C and U 
over G and A respectively for these short 
miRNA sequences. The GC skew is usually 
calculated as (C-G)/(C+G), which gives the 
percentage of excess of C over G. Previously 
cumulative GC skew have been used only in 
case of DNA but here we introduce this in 
RNAs as a feature of visualization [19]. CMP 
Look means the comparative look of multiple 
sequences of pre-miRNA that uses the 
originally stacked horizontal bar look 
altogether 100 sequences for AUGC and PuPy 
data types. In the coding section all the 
visualization techniques in this research were 
implemented in matlab. 
Result and Discussion  
Page 450
It is well known that human brain is much 
more powerful than computer to recognize 
figures and complex patterns. This advantage 
of our brain is very helpful for similarity 
analysis in multiple sequences. So it is 
desirable to develop a simple, clear, unique, 
2-D and non-degenerate graphical 
representation of miRNA sequences. 
Molecular biologists can use this graphical 
representation as an intuitive tool to find out 
which sequence is most similar to the target 
sequence from many different coding RNA 
sequences. Existing tools cannot provide the 
chemical features and composition of miRNA 
sequences. As a consequence, in this program, 
we meet the biologists’ need of sequence 
features, even if two miRNAs have similar 
secondary structure to each other, the 
sequence composition can be very different 
[20]. Efficient comparison of pre-miRNA 
sequences must allow the user to visually 
compare two miRNA sequences. Therefore, 
we have developed a miRNA visualization tool 
that fulfills all defined requirements.  
 
1. Ratio Look                                
The ratio look shows the relative proportion 
of AUGC and PuPy data types for a single 
sequence. We classified ratio look as 
rectangle ratio look and pie ratio look. In case 
of rectangle ratio look, ratio percentage of A, 
U, G and C  and purine-pyrimidine is 
represented in x-axis from left to right and a 
constant width in the y-axis for AUGC and 
PuPy data types  respectively (see figure 1.a, 
b). The pie ratio look represents the relative 
proportion of two different data types with 
distinctive colors for the same data within a 
pie chart (see figure 1. c, d). The components 
of rectangle ratio look and pie ratio look 
represent the same information of data but 
using different representation concepts to 
make the visualization more interactive. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1 The relative proportion of components for AUGC and PyPu data types in as rectangle ratio look (a, b) and pie ratio look  (c, d).  
Page 451
2. Bar Look 
A bar look shows information of same data for 
cumulative groupBar and stackBar look. In the 
cumulative groupBar look the sequence is 
positioned on a horizontal axis; the vertical 
axis is used for cumulative bars of 
information of AUGC and PuPy data types (see 
figure 2. a, b) in different colors. For stackBar 
look the sequence is plotted in the x-axis 
according to the sequence length and in the y-axis 
cumulative stacking of AUGC and PuPy data types 
is placed (see figure 2. c, d). The stackBar look 
for AUGC data type represents A, C, G and U 
from bottom to top respectively and purine 
and pyrimidine in the same orientation for 
PuPy data types. This visual representation 
helps to realize these sequence properties 
easily which is not possible to observe from a 
raw sequence. The Bar look representation 
gives a new insight about the cumulative 
sequence properties of pre-miRNAs which is 
beyond the reach to observe from linear 
sequences. 
Figure 2 Cumulative groupBar and stackBar of AUGC and PuPy data types show the cumulative relationship of number of nucleotides 
(a, c) and purine-pyrimidine in the sequence (b, d) in bars and stacks.           
Page 452
3. Vector Look 
We consider each nucleotide as a vector in 
vector look. The vectors with its 
corresponding nucleotide are illustrated in 
Table 1. The graph of Vector Look is 
constructed by placing the nucleotide 
position in the horizontal axis and the vector 
of each nucleotide in vertical axis for only 
AUGC data type in both DV-Curve (see figure 
3. a, b) and inverse DV-Curve (see figure 3. c, 
d). This zigzag view of sequence provides the 
information to biologists for understanding 
how the nucleotides are arranged in the    
precursor microRNA sequences. 
Figure 3 (a) Representations of four nucleotides A, U, C and G of DV-Curve, (b) The DV-Curve of sequence ‘AUCG’, (c) and (d) are the 
examples of DV-curve and Inverse DV-curve of randomly chosen microRNA sequences respectively. 
 
4.  Skew Look  
This view is significantly used in DNA 
visualization which gives the percentage of 
excess of C/A over G/T. Our tool uses this 
sequence property GC (see figure 4. a, b) and 
AU (see figure 4. c, d) skew of miRNA for the 
same purpose only using AUGC data type. 
Skew look is described in method section in 
details. 
 
5. CMP Look 
For comparing pre-miRNA sequences CMP 
Look; randomly selected 100 sequences were 
aligned for their comparative percentage of 
AUGC and PuPy data types. This is mainly the 
comparison of rectangle ratio look for AUGC and 
PuPy data types (see figure 5. a, b). This view 
gives the information about how the 
sequence data are distributed in different 
sequences.   
 
 Application of Visual-Mir 
Based on the fact that human brain is much 
more powerful than computer to some extent 
in pattern recognition, our system will be 
helpful to scientists for sequence analysis, 
comparison and similarity searching. We can 
locate the mutation to find out what 
happened in miRNA through evolution by 
inspecting DV-Curves and Ratio Look. 
Functional properties of pre-miRNA can be 
retrieved from our graphical representation 
of sequence features since those properties 
completely depend on sequence 
arrangement. From the figures of
(c) 
(d) 
Page 453
Visual-Mir we can easily observe relative 
nucleotide compositional information of pre-
miRNA, which is far easier to observe than 
from a letter/text based raw sequences. 
These sequence properties can also be used 
effectively used as features in prediction of 
pre-miRNAs using machine learning 
algorithms. The input format in our system is 
FASTA and embl format of miRNA sequences. 
The user can get images in bmp format as 
output for the different looks by Visual-Mir.
Figure 4 (a) and (b) are GC-skew of two randomly selected pre-miRNA sequences; AU-skew of another randomly selected two 
sequences is (c) and (d). 
Figure 5 CMP look of AUGC (a) and PuPy (b) data types using randomly selected 100 sequences of pre-miRNA in both cases.  
 
Page 454
Conclusion  
In biological science, visualization can play an 
important role in exploratory data analysis, 
where visual representations can help the 
scientist to build up an understanding of the 
content of their datasets. Visualization seeks 
to harness the remarkable capabilities of the 
human visual system to aid cognition, 
through the use of computer-generated 
representations. Biologists can make sense of 
the information more effectively when it is 
presented in an interactive, graphical format. 
This study presents a complete and fine 
scheme to represent miRNA molecules 
graphically. These representations will 
facilitate the exploration of the numerous 
detailed facets of each miRNA element and 
their combined patterns in creating new 
perceptiveness of miRNA.  
 
References 
1. Claverie JM: Fewer Genes, More 
Noncoding RNA.  Science 2005, 
309:1529-1530. 
2. Mattick JS, Makunin IV: Non-coding 
RNA. Human Molecular Genetics 
2006, 15(1):R17-R29. 
3. Bartel DP: MicroRNAs: genomics, 
biogenesis, mechanism, and function. 
Cell 2004, 116, 281–297. 
4. Stark A, Brennecke J, Bushati 
N, Russell RB, Cohen SM:  Animal 
microRNAs confer robustness to gene 
expression and have a significant 
impact on 3’UTR evolution. Cell 2005, 
123:1133–1146. 
5. Kim VN, Nam J: Genomics of 
microRNA. Trends in Genetics 2006, 
22:165–173. 
6. Garzon R, Calin GA, Croce CM: 
MicroRNAs in Cancer. Annual Review 
of Medicine 2009. 60:167–79. 
7. O’Donoghue SI, Gavin AC, Gehlenborg 
N, Goodsell DS, Hériché JK, Nielsen CB, 
North C, Olson AJ, Procter JB, Shattuck 
DW, Walter T, Wong B: Visualizing 
biological data—now and in the 
future. Nature Methods Supplement 
2010, 7(3s):S2. 
8. Loraine AE, Helt GA: Visualizing the 
genome: techniques for presenting 
human genome data and 
annotations. BMC Bioinformatics 
2002, 3:19. 
9. Gan HH, Pasquali S, Schlick T: 
Exploring the repertoire of RNA 
secondary motifs using graph theory; 
implications for RNA design. Nucleic 
Acids Research 2003, 31: 2926–2943. 
10. Gevertz J, Gan HH, Schlick T: In vitro 
RNA random pools are not 
structurally diverse: A computational 
analysis. RNA 2005, 11: 853-863. 
11. Deng X, Havukkala I and Deng X: 
Large-scale genomic 2D visualization 
reveals extensive CG-AT skew 
correlation in bird genomes. BMC 
Evolutionary Biology 2007, 7:234. 
12. Gan HH, Fera D, Zorn J, Shiffeldrim N, 
Tang M, Laserson U, Kim N, Schlick T: 
RAG: RNA-As-Graphs Database—
Page 455
concepts, analysis, and features. 
Bioinformatics 2004, 20:1285–1291. 
13. Sussman JL, Kim SH. Three-
dimensional structure of a Transfer 
RNA common in two crystal forms. 
Science 1976, 192(4242):835-838. 
14. Kim N, Shiffeldrim N, Gan HH, Schlick 
T: Candidates for Novel RNA 
Topologies. Journal of Molecular 
Biology (2004), 341:1129–1144.  
15. Auber D, Delest M, Domenger JP, 
Dulucq S: Efficient drawing of RNA 
secondary structure. Journal of Graph 
Algorithms and Applications 2006, 
10(2):329–351.  
16. Shu W, Bo X, Zheng Z, Wang S: A novel 
representation of RNA secondary 
structure based on element-contact 
graphs. BMC Bioinformatics 2008, 
9:188. 
17. Griffiths-Jones S, Saini HK, van Dongen 
S, Enright AJ: miRBase: tools for 
microRNA genomics. Nucleic Acids 
Research 2008, 36: D154–D158. 
18. . Zhang ZJ: DV-Curve: a novel intuitive 
tool for visualizing and analyzing DNA 
sequences. Bioinformatics 2009, 
25(9):1112–1117. 
19. Andrei Grigoriev: Analyzing genomes 
with cumulative skew diagrams. 
Nucleic Acids Research 1998, 
26(10):2286-2290. 
20. Zuker M: Mfold web server for 
nucleic acid folding and hybridization 
prediction. Nucleic Acids Research, 
2003, 31(13):3406–3415. 
 
Page 456
                                                   Conference on Engineering Research, Innovation and Education 2011
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh
*A. R.  Kuddus
Email: a_ruhul_k@yahoo.com
20 kWp GRID CONNECTED SOLAR POWER STATION: 
MONITORING AND ASSESMENT
A. R. Kuddus*, M. Faisal, W. Zaman, S. Quddus
Department of Electrical and Electronic Engineering
Bangladesh University of Engineering and Technology (BUET), Dhaka-1000, Bangladesh
This paper describes the components, operations and performance of a 20kWp grid-connected photovoltaic 
system installed in Khulna city in Bangladesh.  The photovoltaic system has been running for two years 
successfully. The paper offers the concept of grid connected PV system in Bangladesh as well as analyses the 
performance of PV modules in Bangladeshi climate. Energy production in 2009 was about 10,000 kWh, in 2010
(up to 3rd June, 2010) is about 5,000 kWh. The average daily generation is about 60 kWh. In good irradiance 
conditions, PV modules efficiency is about 5% and efficiency of entire PV system exceeds 4%. Although, 
weather is a strong influencing factor but other parameter settings can make the system performance better. 
There is no problem in compatibility of the 20 kWp photovoltaic systems with Bangladesh grid system.
Keywords: renewable energy; PV system; grid system; solar energy; photovoltaic
1.   INTRODUCTION
The increasing demand of electric power and the 
shortage of present energy resources lead today 
engineers and scientists to think about the 
alternative sources of energy. As a renewable 
energy, the sunlight is a potential resource for 
generating electric power. In recent years, it is 
increasingly used to generate power. As 
photovoltaic system is a rapidly developing 
technology, there is high potential of more and 
more solar power station to be installed in the 
coming decades.
Khulna Solar Plant is installed to introduce 
Renewable Energy (RE) as an alternative solution 
for power generation to overcome regular shortages 
in power supply for urban areas in Khulna division. 
The plant capacity is 20KWp. up to this the 
maximum generation has been recorded as 16KW. 
The plant consists of three independent plants with 
capacity 15KW, 4KWand 1KW. These plants are 
used independently for training purpose. During 
daytime, the solar module generates power by 
utilizing solar energy, charges battery and supplies 
to the loads and grid. At night, no power is 
generated and the load consumes the battery stored 
energy.
Fig. 1: PV panels installed on the roof
2. PV SYSTEM DESCRIPTION
Each module consists of a series and parallel 
combination of many photovoltaic cells. Thin film 
technology is used here. Each module rating is: 
90W, 50 Volt & 1.8A.
Charge Controller controls the charging of the 
battery and prevents the battery from undesirable 
discharging. Each battery rating is: 12V/280Ah.
Page 457
                                                                                     Proceedings of the
ISBN: 978-984-33-2140-4
Inverter rating: 400V/12.6A DC, 230V/21.7A AC.
Automatic Switch Box is a microprocessor based 
automatic controlling mechanism which 
synchronizes voltage and Frequency, controls 
power flow direction and disconnects the solar 
panel from grid during abnormal conditions. AC 
load consists of some fans, fluorescent lights, 
security lamps etc. Total load is approximately 
700W. In this system, an 11KV/415V distribution 
transformer’s LT side is used for grid connection. 
Though in strict sense, it’s not a grid connection.
      
Fig. 2: Control room and batteries.
As the capacity of Khulna solar plant is 20KWp, so 
its maximum generation is 20KW. During daytime, 
the solar modules absorb solar energy from sun 
light and convert this energy into electrical energy. 
The generation of electrical power is subject to 
irradiance, temperature, maximum power tracking, 
grid demand etc.
Fig. 3: Block diagram of solar system
Sufficient irradiance is available from 9am to 3pm. 
So, significant amount of electrical power is 
generated during this time. The generated electrical 
energy is supplied to the official load of 
approximately 700W and charges the batteries. 
When the battery is fully charged, the surplus 
power is fed to the grid. Here the grid is the LT side 
of a distribution transformer at 415V.
As the solar modules generate dc power, so 
inverter is used to convert the dc power into ac 
power and then supplied to load and grid. Charge 
controller is used to avoid unexpected battery 
discharging. If the solar module can’t generate 
power for any inconvenience, then power is drawn 
from the grid to run the official loads and charge 
the battery.
The amount of power supplied to grid from solar 
module is dependent on grid demand. If grid 
demand increases, solar supply also increases. If 
grid demand decreases, solar supply also decreases. 
So solar supply falls during load shedding i.e. solar 
power can’t be supplied to grid during load 
shedding.
During night, no irradiance is available so no power 
is generated. So at night power is drawn from the 
battery and supplied to security lamps.
The total system is controlled by automatic switch 
box which is a microprocessor programmed device. 
It also disconnects the solar system from the grid 
during over/under voltage conditions. The 
generation is being recorded and plotted graph by 
computer. 
3. OPERATION AND MAINTENANCE
                      
Fig. 4: Power flow diagram
In Khulna Solar Plant, the power may be supplied 
from solar panel, grid or battery and the power may 
be consumed by official load and grid. The power 
flow direction will be different for different 
conditions. The Automatic Switch Box controls the 
power flow and synchronizes voltage and 
frequency. The power flow conditions are as 
follows:-
When the solar plant generates power sufficiently, 
the total generated power will be extracted from 
solar panel. The generated power will charge the 
battery first. If the battery is fully charged then the 
power will be supplied to the official load.  If the 
difference between solar power generation and grid
    Solar 
    Panel
Inverter
Charge
Controller
Battery
Automatic
Switch
Box
ac load 
Grid 
GRID
BATTERY SOLAR LOAD
Page 458
demand is at least 3kw, then the surplus power will 
also be supplied to grid.
If the power generated from solar panel is 
insufficient for office load, then power from grid 
will compensate to load.
If the solar panel doesn’t generate any power then 
the official load will be supplied by the battery (at 
night). If the battery power is also unavailable, then 
the power will be drawn from the grid. This time 
the grid power will supply the office load as well as 
charge the battery.
If the grid voltage becomes over/under the nominal 
value, then the solar panel will be disconnected 
from the grid. Thus the solar panel can’t supply 
power to grid during load shedding. 
4. YIELD STATISTICS AND 
ANALYSIS
This project has been running from February, 2009. 
The generation of electrical energy is recorded 
everyday. The available data is from the end of 
February, 2009 to the beginning of June, 2010. The 
daily generation is recorded in kilowatt-hours. The 
following two tables show the daily generation of 
two years:-
From the Fig. 5, it is seen that the maximum daily 
generation was recorded on May 8, 2009 and it is 
102 kW-hr. 
Fig. 5: Energy yield day by day for 2009 in kWh.
Here, the generation from day 1 to day 10 of each 
month in 2009 is shown. Sometimes the generation 
falls as the generation is subject to load shedding, 
present grid demand, cloud, rainfall etc.
Fig. 6: Comparison between irradiation and 
generation.
  Fig. 7: Energy yield day by day for 2009
Fig. 8: Energy yield distribution in 2010
From the fig. 7, it is seen that the power generation 
falls nearly to zero though the presence of good 
Page 459
irradiation conditions. This is occurred due to the 
load shedding. As the PV output is connected to the 
LT side of a distribution transformer at 415V, so 
when load shedding occurs, PV can not supply to 
grid.
In the fig. 8, daily generation of each    month of 
2009 is shown. It is seen that the generation varies 
with irradiance from month to month.
5. IMAPCT ON GRID
The large scale penetration of photovoltaic 
generation will affect the power system in different 
ways. Normally the photovoltaic system is 
connected to the grid in such a way that if any 
disturbance occurs, the photovoltaic generation will 
automatically be disconnected from the grid 
system. Thus during disturbances, large power 
generating unit will be disconnected and will thus 
intensify the disturbance. Again if cloud travels 
over the photovoltaic panel area, the irradiance will 
suddenly fall which in turn reduce the photovoltaic 
generation as well as the voltage. However, the 
power factor control may mitigate such voltage 
fluctuations [5].
6. ENVIRONMENTAL EFFECT
Using the common evaluation method, 10,000 kWh 
is equivalent to 2.43t oil or 3.89t coal consumption 
reduction, and 9.95t CO2 emission reduction [4].
7. CONCLUSIONS
This photovoltaic power system has been 
successfully running for near two years. The daily 
generation of the photovoltaic system is good. 
However, if the load shedding effect can be 
avoided, then the yield will further increase.
The solar panels are faced at south direction at an 
angle near the latitude. However, the tilt angle 
should be such that the sun light is approximately 
vertical to the panels around the peak irradiation 
hours. If possible, the grid connected PV system 
should have sun tracking devices, they effectively 
increase the yield. Again the power required for 
tracking arrangement and yield increase both 
should be considered.
As the presented above results show, in Bangladesh 
condition PV system works satisfactorily. There 
were no problems with compatibility with 
Bangladesh grid system. Thus it is encouraged to 
install more photovoltaic power plants to meet the 
crisis and increasing demand of power the country.
ACKNOWLEDGEMENTS
The monitoring and assessment of the project was 
possible through the cooperation of the authority, 
technicians and trainees of Khulna Renewable 
Energy and Training Centre. The authors give 
sincerely thanks to Khulna Renewable Energy and 
Training Centre, for their cooperation and 
assistance to us.
REFERENCES
1. Chowdhury, B.H.,  Muknahallipatna, S.,  
Cupal, J.J., Hamann, J.C., Dinwoodie, T.,
Shugar, D., A 50 kilowatt distributed grid-
connected photovoltaic generation system for
the University of Wyoming ,  Photovoltaic
Specialists Conference, 1997, Page(s): 1369 –
1372.
2. Pietruszko, S.M., Gradzki, M., (2005), 1-kW 
grid connected PV system after 3 years of 
monitoring ,Photovoltaic Specialists 
Conference, 2005 , Page(s): 1730 – 1733.
3. Sung-Hun Ko, Seong-Ryong Lee, Dehbonei, 
H., Nayar, C.V., (2006); A Grid-Connected
Photovoltaic System with Direct Coupled
Power Quality Control , IEEE transactions on 
Industrial Electronics, IECON 2006 , Page(s): 
5203 – 5208.
4. Wang, J., Jiang J. (2008),   Experience On
10kw Grid-Connecting Solar Power Station , 
ICEMS 2008, Page(s): 2654 – 2656.
5. Yun Tiam Tan, Kirschen, D.S., (2007), Impact
on the Power System of a Large Penetration of
Photovoltaic Generation, Power Engineering 
Society General Meeting, 2007, IEEE   
Page(s): 1 – 8.
Page 460
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
*Corresponding Author: Second B. Author,  
E-mail: rupai_2005@yahoo.com 
 
A CMOS IC USING NANO-POWER ELECTRONIC CIRCUITS FOR 
LIFE-SAVING APPLICATIONS IN BANGLADESH 
 
R. Sultana and A. Begum 
Department of Electronics and Communication Engineering 
University of Information Technology and Sciences, Dhaka, Bangladesh 
 
S. Binzaid, PhD 
Founder and Director, SERES, Bangladesh  
seres-usa.com 
 
 
Nano-power electronics is an area of emerging semiconductor VLSI technology where scaled down CMOS 
circuits are primarily used in this work. A fabricable CMOS integrated chip (IC) is designed using Magic 
CAD tools and it was also incorporated with scalable design techniques of MOSIS. A circuit components 
reduction technique is applied to redesign a sense amplifier circuit to lower the power to nano-watts level. 
This scalable design technique improved power by lowering from 7.15E-03 watts to 1.31-09 watts for the 
sense amplifier. Applications of this IC have been explored and it is found be a life-saving design for 
launches in Bangladesh waterways. Application of two types of sensor is identified to use with this IC that 
can sense the catastrophic situations ahead of time by the proper placement in the launch. Floor plan of all 
components and their pin-assignments of the IC layout are described. PSPICE simulation to verify the 
operation and power consumption of components in the chip is presented in the paper.  
 
Key words: Nano-Power; CMOS; Scalable Design; MOSIS, CAD; PSPICE 
 
1. INTRODUCTION 
 
Nano-power electronics is a fast developing field of 
engineering. The circuitry is composed of micro 
and nano-meter device scale, having ultra-low 
power electronic components. There are different 
types of semiconductor switches and devices that 
operate in nano-power range. Nano-power 
electronics have recently been used in various fields 
of engineering, biotechnology, physics, chemistry, 
space systems etc [1]. Upcoming technology 
includes nano scale electronics and semiconductor 
nanotechnology would also primarily consider 
consumption at nano-power levels. Micro and nano 
scale electromechanical systems including MEMS 
(Microelectromachanical System) which function 
with other nano power elements built within 
systems. They are very useful for engineering, 
medical science and many other areas of life saving 
applications  [2]. 
 
1.1 Goals and Objectives 
The goals of this project are to provide an overview 
of nano-power electronics design of an integrated 
chip and an assessment of how that technology can 
be utilized in Bangladesh. The objectives are 
following: 
• To design, simulate and verify nano-power 
electronic circuits by using scalable 
CMOS technology. 
• Layout of a test chip that can be fabricated 
by MOSIS standard processes using the 
scalable design CIF file. 
• To discuss about sensing signals and 
process by the chip using nano-power 
circuits that can save lives from 
catastrophic events. 
 
2. CIRCUIT DESIGN, SIMULATION 
AND VARIFICATION OF SENSE 
AMPLIFIERS   
 
The main concern of this work involved with two 
amplifiers to compare and determine their 
performance. These are sense amplifier based flip-
flop and advanced modified sense amplifier. The 
sense amplifier based flip-flops are run with digital 
signals [3]. Borivoje and Oklobdzija designed this 
high-performance and low-power digital system 
and it works at low milliwatts power. It contains 
Page 461ISBN: 978-984-33-2140-4
  
total twelve transistors. Four of them are large and 
the others are normal in size. It is a CMOS design 
having six PMOS and six NMOS transistors.  The 
circuit has four inputs: R, R-bar, S, S-bar and two 
outputs: Q, Q-bar. 
 
 
 
Fig 1: Schematic of sense amplifier based flip-flop 
 
 
Fig 2: MAGIC layout of sense amplifier based flip-
flop 
 
PSPICE simulations and verification are necessary 
by converting circuit layouts into mathematical 
models; thus determine their behaviors. Figure 3 
shows the input signals R, R-bar and S-bar of the 
sense amplifier based flip-flop. Figure 4 shows the 
output signal Q. The mathematical representation of 
these simulations show that the total power 
dissipation of the sense amplifier based flip-flop is 
7.15E-03 watts. It is a very good sense amplifier 
where no power sensitive issues present. This 
milliwatts-power flip-flop based amplifier has some 
other advantages, as it is a logical toggle switch.  
  
Fig 3:  Input signals of sense amplifier based flip-
flop 
 
Fig 4: Output signal of sense amplifier based flip-
flop 
 
On the other hand, advanced modified sense 
amplifier is a mixed signal circuit, deigned by Dr. 
Shuza Binzaid [4]. The circuitry of advanced 
modified sense amplifier is very simple. It contains 
two PMOS and three NMOS transistors. It has two 
input terminals V1, V2, enable and the output 
terminal Vout. 
 
Figure 7 shows the two input signals and the enable 
signal. Figure 8 shows the output signal. The 
simulation and verification of the advanced 
modified sense amplifier shows that the total power 
dissipation is 1.31E-09 watts. This sense amplifier 
is fast and it operates at nanowatts, which can be 
suitable even for the remote power scavenging 
applications.  
 
 
 
Page 462
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 5: Schematic of the advanced modified sense 
amplifier  
 
 
 
Fig 6: MAGIC layout of the advanced modified 
sense amplifier  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 7: Input signals of the advanced modified sense 
amplifier with buffer inverter 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 8: Output signals of the advanced modified 
sense amplifier with buffer inverter 
 
By comparing the simulation and verification 
results, it is confirmed that the advanced modified 
sense amplifier dissipate less power than the sense 
amplifier based flip flop 
 
3. DESIGN OF THE NANO-POWER 
    CHIP 
 
In this work, a nano-power chip has been designed 
following rules of MOSIS silicon process 
technology. The MOSIS scalable CMOS design 
techniques were used with MAGIC 2-D CAD tools 
for designing VLSI layout. SPICE circuit 
simulation tools were used to simulate each circuit 
component in the chip in order to verify the 
integrity and performance [5-8]. 
 
In figure 9, showing the designed chip floor plan 
having 20 pins. It contains a PMOS transistor, a 
NMOS transistor, a NAND gate, a buffer inverter, 
an inverter, an advanced modified sense amplifier, 
a sense amplifier based flip-flop. Pin assignments 
are presented in table 1.  
 
Fig 9: Floor plan of the chip 
Table 1: List of devices in the chip and their pin 
assignments 
Page 463
  
 
SL 
No 
Name of 
devices 
Pad 
Assigned 
Pin Name 
1 PMOS 
Transistor 
 
17,18 
 
OP6, IN9 
2 NMOS 
Transistor 
 
15,16 
 
OP5, IN8 
3 NAND Gate  12,13,14 IN6, IN7, OP4 
4 Inverter 1,2 OP1, IN1 
5 Inverter 
Buffer 
 
19,20 
 
OP7,IN10 
6 Sense 
Amplifier 
Based Flip-
Flop 
 
7,8,9,10,11 
 
IN4, OP3, 
IN5,Vdd, 
GND 
7 Advanced 
Modified 
Sense 
Amplifier 
 
3,4,5,6 
 
OP2, IN2, 
IN3, Enable 
 
Every integrated chip has an interface to the 
external world through the metal pins of its 
package. These pins are connected inside package 
to metal on the silicon chip by welded micro-thin 
gold wires. The connecting metals in the chip 
silicon are called pads. The pad frame is also 
known as the I/O region. A quad package pad 
frame is used for the projected chip. Figure 10 
shows the layout of a pad. Figure 11 shows the 
completed chip with pad frame. It contains testable 
devices and circuits. Each side of the chip is having 
5 pins around the quad pad frame. MOSIS service 
can also facilitate with packaging vendors of such 
quad pad frame designs. 
 
 
 
Fig 10: Layout of a bonding pad on silicon 
 
 
 
Fig 11: Complete chip with pad frames  
MAGIC layout rule checker command ‘drc’ is 
applied to the design for the final checkup [9]. Then 
a CIF file is made. Then MOSIS header is added to 
the file when no errors were found in CIF file. This 
CIF file with header can be sent for fabrication 
using MOSIS service. The MOSIS service is a 
prototyping service that offers fast turnaround 
standard cell and full custom VLSI circuit 
development at very low cost. MOSIS has 
developed methods for merging many different 
designs from various organizations and place onto a 
single wafer. Wafer fabrication runs are scheduled 
on a regular basis for available fab processes of 
present semiconductor technologies with multi-
layer metal CMOS/bulk technologies. MOSIS also 
provides different technologies for custom 
fabrication and also various chip packages [10]. 
4. LIFE-SAVING REAL APPLICATIONS 
OF THE CHIP 
 
Bangladesh is a riverine country. Rivers play an 
important rule on transport media.  Every year there 
occur many accidents in rivers. As unfortunate 
results, many lives and properties are at loss. 
Overloading and clashing of transports like boats, 
launches, ferries are the main reasons of these 
accidents. 
 
The designed chip in this project can prevent 
accidents caused due to overloading or clashing 
especially with dockyards. Figure 12 shows a ship, 
which has two types of sensors. They are the sensor 
belt for the docking sides and the pressure sensor of 
the buoyancy [11]. 
 
Page 464
  
 
Fig 12: Applications on a ship showing sensors 
positions for sense amplifier circuits 
 
A pressure sensor is used for monitoring the 
buoyancy conditions of the floating factors of the 
ship. It can be placed under the center of the keel. 
When the ship becomes overloaded, it can sense the 
threshold to electronic system with the designed 
chip for producing an alarm signal to captain of the 
ship, before leaving the dock. An electronic circuit 
can also send the signal to the dockyard regulatory 
service teams about the ship’s risky situation. 
 
The Sensor belt is for sensing the force on the frame 
of the ship if a clash is caused by the ship with the 
dockyard or any obstacle. It is placed on the 
surroundings of the ship’s hull. The system can 
measure the electrical signal of the pressure V1, 
caused by clashing force and then compare it to the 
reference critical voltage V2 input to the chip. If the 
strength of the clash crosses the safe level, then the 
chip can produce signal Vout for the alarm and thus 
it can prevent a catastrophic event. 
 
5. CONCLUTION  
 
A mixed signal chip is designed for low power 
practical applications. All the circuit layouts were 
completed by using MAGIC and their simulations 
for electrical characteristics were completed by 
using SPICE tools. Also following MOSIS SCMOS 
design rules, layout of pads was complete and DRC 
was verified. A 20-pin pad frame was designed for 
the chip. These chip components include two types 
of sense amplifiers: sense amplifier based flip-flop 
and advanced modified sense amplifier. Spice 
simulation showed they dissipated 7.15E-03 watts 
and 1.31E-09 watts, respectively. So the new 
advanced modified sense amplifier is improved 
significantly. It was in the range of nano-power. 
Also from these results, it is found that the power 
dissipation was reduced by 5.46E-06 times. 
 
For future work of this project, it is planned to 
implement the designed chip to a water transport. 
This chip with sense amplifiers can be used to 
detect collision forces and also the overloading 
conditions of the ship. This chip easily monitors 
and determines certain dangers; thus help avoiding 
catastrophic situations. So the system can save 
lives.  
 
REFERENCES 
 
1.    Binzaid, S. and Attia, J.O. (2009), Compound 
Active-Region-Cutout-Enclosed-Layout 
Transistor for Space Electronic Applications, 
International Review of Physics, Vol. 3, No. 4, 
Page(s): 250-255, 2009. 
2.    Vittorio,     S.A.     (2001),     Eletromechanical  
Systems(MEMS), <http://www.csa.com/discov 
eryguides/mems /overview.php>, Oct. 2001.  
3.   Nikolic, B., Stojanovic, V., Vojin G., Jia, W., 
Chiu, J. and Leung, M. (1999), Sense 
Amplifier Based Flip-Flop, IEEE International 
Solid-State Circuits Conference, Page(s): 282-
283, Feb. 16, 1999. 
4.    Binzaid, S. and Attia, J.O. (1996), Design of A 
Switched Capacitor SRAM IC, RADSCON’96, 
Radiation Studies Conference, NASA, Texas, 
USA, Page(s): 55-61, 1996. 
5.  MOSIS Documents (2009), Design Rules 
MOSIS Scalable CMOS (SCMOS), 
<http://www.mosis.com/Technical/Designrule
s /scmos>, May 11, 2009. 
6.   Wilinski, J., An Introduction to the MAGIC 
VLSI Design Layout System, 
<http://terpconnect.umd.edu/~newcomb/vlsi/m
agic_tut/Magic_x3.pdf> 
7. National Instruments (2008), SPICE 
SimulationOverview, <http://zone.ni.com/dev 
zone/cda/tut/p/id/5414>, Sep. 24, 2008. 
8.  Ousterhout, J. (2008), MAGIC tutorial 1-11, 
Computer Science Division, Electrical 
Engineering and Computer Sciences, 
University of California, Berkeley, CA 94720, 
<http://opencircuitdesign.com/magic/tutorials/t
ut1.html>, Feb. 3, 2008. 
9.  Ousterhout, J. (2008), MAGIC tutorial 1, 
Computer Science Division, Electrical 
Engineering and Computer Sciences, 
University of California, Berkeley, CA 94720, 
<http://opencircuitdesign.com/magic/tutorials/t
ut1.html>, Feb. 3, 2008. 
10.  The MOSIS Service (2004), MOSIS Scalable 
CMOS (SCMOS) Design Rules (Revision 
8.0), Mosis.org, Oct. 4, 2004. 
11. Hodanbosi, C. and Fairman, J.G. (2010), 
Buoyancy: Archimedes Principle, NASA, 
<http://www.grc.nasa.gov/www/k12/windtunn
el/activities/buoy_archim-edes.html>, 17 Feb. 
2010. 
 
Page 465
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh  
* Corresponding Author: Omar Farrok,  
E-mail: omarruet@gmail.com  
 
A COMPARATIVE STUDY OF ELECTRICAL, HALL EFFECT AND 
MAGNETIC PROPERTIES OF Co THIN FILMS DEPOSITED ON 
GaAs(001), Si(001) AND GLASS SUBSTRATES 
 
N.A. Shafi1, O. Farrok*, Z. Islam2 and J. Islam3 
 
1SAR SECURITIES LTD, Motijheel, Dhaka-1000.  
*Rajshahi University of Engineering & Technology, Rajshahi-6204, Bangladesh 
2University of Blekinge Institute of technology, Blekinge, Sweden.  
3Rajshahi University (RU) Rajshahi-6204, Bangladesh 
 
 
Cobalt (Co) thin films have been prepared by e-beam evaporation technique on glass, Si(001) and 
GaAs(001) substrates at a pressure of about 2×10-4 Pa. The thickness of the films is 100nm. The deposition 
rate of the films was about 0.93 nms-1. The as-deposited films have been annealed in open air for 4 hours at 
constant temperature of 523 K. Magnetic, electrical and Hall Effect properties of the films have been 
studied. Magnetic and electrical study showed that the interfacial resistance (IR) is present at Co/Si interface. 
Coercivity of 100nm Co films on glass substrate is found to be 44 Oe. It is increased to 77 Oe for the same 
thickness Co film on GaAs substrate. Electrical resistivity for the as-deposited and annealed films has been 
measured as a function of temperature ranging from 303 to 451 K. The resistivity of the films on glass 
substrate is increased after annealing. It is only 11 µΩ-m for 100nm films. At room temperature, the values 
of resistivity for both the as-deposited and annealed films on silicon substrate were 6.04 µΩ-m and 15.66 
µΩ-m, respectively. The positive value of T.C.R indicates that the metallic behavior of the films. The Hall 
effect measurement showed that the Hall coefficient of Co films on glass substrate is decreased with 
increasing film thickness. It is found to increase after annealing for both Co films on glass and silicon 
substrates. The carrier concentration was 13.3 x1019 cm-3 for 100nm Co film on glass but it is decreased 3.8 
x1019 cm-3 for the same thickness Co film on silicon substrate. Co thin films have been produced by electron 
beam bombardment heating technique and thickness meesures in Fizeau fringes method. Electrical resistivity 
and Hall Effect studies are measured Van-der-Pauw technique. 
 
Key words: Spin injection efficiency; interfacial resistance; coercivity; anisotropy; hysteresis loop 
 
1. INTRODUCTION 
 
Electrical spin injection of electrons across a 
ferromagnetic metal and semiconductor interfaces 
yields an injection efficiency η of 1% or even less 
[1-2]. Spin injection efficiency is largely affected 
by interfacial resistance (IR) at the interface of 
ferromagnetic metal and semiconductor due to 
conductivity mismatch [3-4]. It is known that it 
depends on  
 
It is possible to increase the above value by 
introducing interfacial resistance (IR) at the 
interface between semiconductor and ferromagnetic 
metal. 
 
 
Page 466ISBN: 978-984-33-2140-4
  
2. THEORY  
 
If the in plane anisotropy field (Hani) is comparable 
to the anisotropy field(Hint) due to interface, then 
the M~H curve will be a straight line (Fig-1). In the 
absence of anisotropy field due to interface (in the 
case of glass substrate) or very  
small interfacial anisotropy field (in the case of 
GaAs substrate). The M~H curve shows typical 
hysteresis loop as shown in Fig-2. 
 
 
 
 
Our objective is to verify that there is an interface 
in Co/Si system. To verify this, we have measured 
the hysteresis loop of Co/Si, Co/glass and 
Co/GaAs. The interfacial resistance mainly due to 
the formation of CoSi and its resistivity is much 
larger than the resistivity of pure Co film. 
Therefore, the same thickness Co film on Si should 
show larger resistivity than Co on GaAs (small 
interface) as well as glass substrate 
 
3. RESULTS AND DISCUSSION 
 
Fig-3(a) and Fig-3(b) represents a comparison of 
such hysteresis loops for both the cases. For these 
measurements, magnetic field was applied parallel 
to the sample surface and the hysteresis loops were 
recorded up to the saturation magnetization. One 
can see from observed results that the hysteresis 
loop of Fig-3(a) and Fig-3(b) are not square in 
shape indicating that the magnetization processes of 
sample having some interfacial anisotropy. If the 
dominant part of interfacial anisotropy lie 
perpendicular to the sample plane then the 
magnetization process are different. The effective 
magnetic field also reduced in this case and equal to 
the vector sum of these fields. Therefore, the 
saturation field is higher than the coercive field. 
Observed coercivity and saturation magnetization 
values are found to be 44Oe and 1.541 x 10-4 emu 
respectively on glass substrate. 77Oe and 2.373 x 
10-4 emu values are found of coercivity and 
saturation magnetization on GaAs substrate. Then 
on the silicon substrate are zero. The crystalline hcp 
Co phase is obtained for Co/glass system. It is well 
known that when the crystal grains are large, 
crystalline magnetic anisotropy is large and 
magnetization in each crystal grain orients in 
different directions, because easy axes are not 
parallel to each other [5]. Therefore, larger grain 
size should lead to a large coercivity in Co/GaAs 
than Co/glass thin films [6]. 
The interfacial resistance (IR) at the Co/glass 
interface is zero. The M ~ H curve shows typical 
hysteresis loop of polycrystalline Co films. But in 
the case of Co/GaAs, the interfacial reaction is low 
and IR value is believed to be small. Co films on 
the silicon substrate, the interfacial reaction is high. 
Co forms CoSi at the interface and it is not 
magnetic material. It is believed to be diamagnetic 
or paramagnetic and its moments lie perpendicular 
to the substrate surface. Therefore, the M ~ H curve 
does not show in the hysteresis loop.  
(a) 
(b) 
 
Page 467
  
  
(c) 
Fig-3: Variation of normalized magnetization or 
magnetization with magnetic field for as-deposited 
100nm Co thin films on (a) glass substrate (b) 
GaAs substrate and (c) silicon substrate 
 
The variation of resistivity with temperature for 
both the as-deposited and annealed 100nm Co thin 
film deposited on glass and silicon substrates is 
shown in Fig-4(a) & (b). It is seen from the Figures 
that for both the cases resistivity higher for film on 
silicon substrate. It is also evident that the annealed 
films have higher order of resistivity than as-
deposited films for both the cases. 
 
 
(a) As-deposited 
 
 
(b) Annealed 
 
Fig-4: Variation of resistivity with temperature 
for100nm Co thin films on glass and silicon 
substrates 
The variation of sheet resistance with temperature 
for both the as-deposited and annealed 100nm Co 
thin film deposited on glass and silicon substrates is 
shown in Fig-5(a) & (b). It is seen from the Figures 
that for both the cases sheet resistance high for film 
on silicon substrate. It is also evident that the 
annealed films have higher sheet resistance than as-
deposited films for both the cases. 
 
(a) As-deposited 
 
(b) Annealed 
Fig-5: Variation of sheet-resistance with 
temperature for 100nm Co thin films on glass and 
silicon substrates 
The TCR for 100nm Co thin films on silicon and 
glass substrates is shown in Fig-6(a) and 6(b).  
 
(a) As-deposited 
2 108
2.5 108
3 108
3.5 108
4 108
4.5 108
5 108
5.5 108
300 320 340 360 380 400 420 440 460
100nm
Glass substrateSilicon substrate
Sh
ee
t r
es
is
ta
nc
e,
 R
S[

s
qu
ar
e]
Temperature, T [K]
Page 468
  
 
(b) Annealed 
Fig-6: Variation of T. C. R (%) with temperature 
for 100nm Co thin films o on glass and silicon 
substrates 
Fig-7(a) and 7(b) show the variation of Hall 
coefficient with magnetic field for both the as-
deposited and annealed 100nm thick Co film 
deposited on glass and silicon substrates. It is 
revealed from the Figures that for both the glass 
and silicon substrates carrier is p-type. It is also 
observed that film deposited on silicon substrate 
has higher Hall coefficient. It is also evident that 
after annealing Hall coefficient increases for film 
deposited on both substrate. 
 
(a) As-deposited 
 
(b) Annealed 
Fig-7: Variation of Hall co-efficient with applied 
magnetic field for 100nm Co thin films on glass 
and silicon substrates 
The variation of carrier mobility with magnetic 
field for both the as-deposited and annealed 100nm 
thick Co film deposited on glass and silicon 
substrates at room temperature is shown in Fig-8(a) 
and 8(b). It is seen that deposited film on silicon 
substrate has higher carrier mobility than that of 
glass substrate. 
 
 
(a) As-deposited 
 
 
(b) Annealed 
 
Fig-8: Variation of carrier mobility with applied 
magnetic field for 100nm Co thin films on glass 
and silicon substrates 
 
The variation of carrier mobility with magnetic 
field for both the as-deposited and annealed 100nm 
thick Co film deposited on glass and silicon 
substrates at room temperature is shown in Fig-9(a) 
and 9(b).  
 
(a) As-deposited 
20
25
30
35
40
45
50
1 2 3 4 5 6 7 8
Glass substrate
Silicon substrate
C
ar
rie
r m
ob
ili
ty
, 

 [c
m
2 /V
-s
ec
]
Magnetic field, B [KGs]
100nm
20
40
60
80
100
120
140
1 2 3 4 5 6 7 8
100nm
Glass substrate
Silicon substrate
C
ar
rie
r m
ob
ili
ty
, 

 [c
m
2 /V
-s
ec
]
Manetic field, B [KGs]
0
20
40
60
80
100
120
140
1 2 3 4 5 6 7 8
Glass substrate
Silicon substrate
C
ar
rie
r c
on
ce
nt
ra
tio
n,
 n
 [(
n/
cm
3 )
x1
01
9 ]
Manetic field, B [KGs]
100nm
Page 469
  
 
(b) Annealed 
 
Fig-9: Variation of carrier concentration with 
applied magnetic field for 100nm Co thin films on 
glass and silicon substrates 
 
It is seen that film deposited on silicon substrate has 
lower carrier concentration than that of glass 
substrate for both the cases. 
 
4. CONCLUSION 
 
Magnetic and electrical studies showed that the 
interfacial resistance (IR) is present at Co/Si 
interface. Coercivity of 100nm Co film on glass 
substrate is found to be 44 Oe. It is increased to 77 
Oe for the same thickness Co film on GaAs 
substrate. At room temperature, the values of 
resistivity for both the as-deposited and annealed 
100nm Co films on silicon substrate were 6.04 µΩ-
m and 15.66 µΩ-m, respectively. The resistivity of 
same thickness Co film on glass substrate was 
found to be 5.09 µΩ-m for as-deposited and 11.33 
µΩ-m after annealed. The carrier concentration was 
5.2 x1020 cm-3 for 100nm Co film on glass but it is 
decreased 2.2 x1020 cm-3 for the same thickness Co 
film on silicon substrate. Therefore, we have 
accomplished our purpose by comparing the 
properties of pure Co film (Co/glass) with Co film 
having CoSi interface (Co/Si). 
 
REFERENCES 
 
1. P. R. Hamar, B. R. Be nnett, M. J. Yang and 
M. Johnson, Phys. Rev. lett. 83 (1999) 203.  
2. S. Gardelis, C. G. Smith, C: H. W. Barnes, E. 
H. Linfield and D. A. Ritchic, Phys. Rev. B 60 
(1999) 7764. 
3. G. Schmidt, D. Ferrand, L. W. Molenkamp, A. 
T. Filip and B. J. Van Wees, Phys. Rev. B 62 
(2000) R 4790.  
4. S. Agrawal, M. B. A. Jalil, and K. L. Teo, J. 
Appl. Phys. 97 (2005) 103907. 
5. B.D. Cullity, “Introduction to Magnetic 
Materials,” Addison Wesley, Massachusetts, 
1972. 
6. A. Sharma, R.Brajpuriya, S. Tripathi, D.Jain, 
R. Dubey, T. Shripathi, S.M. Chaudhari, 
“Materials Science and Engineering,” B 130 
(2006) 120-125. 
 
 
2
4
6
8
10
12
14
1 2 3 4 5 6 7 8
100nm
Glass substrate
Silicon substrate
C
ar
rie
r c
on
ce
nt
ra
tio
n,
 n
 [n
/c
m
3 x
10
19
]
Magnetic field, B [KGs]
Page 470
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Kalyan Kumar Halder,  
E-mail: kalyan_kuet@yahoo.com  
A RECURRENT NEURAL NETWORK BASED BACK EMF 
ESTIMATOR FOR POSITION SENSORLESS CONTROL OF IPM 
SYNCHRONOUS MOTOR DRIVE 
 
 
Kalyan Kumar Halder*, Md. Mejbaul Haque and Naruttam Kumar Roy  
Department of Electrical & Electronic Engineering, KUET, Khulna-9203, Bangladesh 
 
B. C. Ghosh  
Department of Electrical & Electronic Engineering, AIUB, Dhaka-1213, Bangladesh 
 
 
This paper investigates the performance of a position sensorless Interior Permanent Magnet (IPM) 
synchronous motor drive based on Recurrent Neural Network (RNN). The drive system is powered through 
a Space Vector Modulated (SVM) voltage source inverter. The input stationary two-axis phase voltages, 
corresponding phase currents, and motor speed error are fed to a RNN to estimate the back Electromotive 
Force (EMF) along stationary α-β axes. The RNN back EMF model is trained off-line and it estimates the 
back EMF components accurately. The rotor position information is used for vector control of the IPM 
motor drive. A Proportional-plus-Integral-plus-Derivative (PID) controller is used to control the motor 
variables in closed loop. To validate the effectiveness of the drive system, simulation study is carried out 
under different operating conditions. The proposed drive is found to work effectively under these conditions 
with excellent dynamic performance. 
 
Key words: Back EMF; IPM synchronous motor; recurrent neural network; sensorless control; space vector 
modulation  
 
1. INTRODUCTION 
 
Nowadays, permanent magnet synchronous motors 
are widely used in industries because of their 
inherent advantages such as lower mass, lower 
moment of inertia, highly efficient, and being easy 
to control and maintain. IPM motors are recently 
built with NdFeB permanent magnet material and 
have applications in high performance drives. A 
high performance IPM drive system for four 
quadrant operation is proposed in (Bose, 1988). The 
paper describes drive performance under constant 
load torque and field weakening regions. The 
control law is implemented in a microprocessor 
based environment. Fuzzy logic controller based 
four switch converter with reduced cost is proposed 
in (Uddin et al., 2006). Hysteresis current control 
processed through fuzzy logic controllers activated 
by speed error and change of error is used in the 
paper. Application of fuzzy logic controllers for 
avoiding exact modeling uncertainties attracted the 
authors in (Roy et al., 2008) to apply it in the IPM 
motor control. They used hysteresis current 
controller to force the current vector in the three 
phase load according to a reference trajectory. 
Microprocessor based implementation of an IPM 
synchronous motor drive system is provided in 
(Bose and Szczesny, 1988). The proposed system is 
claimed to be suitable for vehicle applications. 
Simple current control method and simulation are 
found to be complying with the proposal. In (Chen 
et al., 2002) the authors proposed maximum torque 
per ampere method to control an IPM motor drive. 
The drive system has been applied for flux 
weakening region also.  
  
IPM motors require proper modeling for controller 
design because of their inverse type saliency effect. 
Analysis and description of the motor models under 
different operating conditions are considered in 
(Ohm et al., 1995). A detailed analysis of IPM 
lumped parameter model starting from variable 
inductance and mutual coupling is presented and a 
simplified model in synchronous d–q reference 
frame is deduced by the authors. The paper also 
shows the d-q equivalent circuit and describes 
methodology to measure the lumped parameters of 
the machine. Machine inductances based on angle 
dependent reluctances are considered in (Nakamura 
et al., 2003) for dynamic analysis. The authors also 
presented simulated results those comply with their 
proposal. 
Page 471ISBN: 978-984-33-2140-4
  
β 
α 
δ 
ψ 
Va 
Vb 
Vc 
 it im 
d 
q 
A good number of researchers have been working 
with IPM motors to design controllers with 
minimum sensors. IPM motors possess magnetic 
saliency that introduces harmonics in the motor 
current. This phenomenon is introduced in 
(Ogasawara and Akagi, 1998) to find out position 
and speed of the IPM motor. The authors proposed 
harmonic current extraction method with practical 
circuit. An extended induced voltage model based 
sensing of back EMF and rotor position is 
presented in (Tanaka and Miki, 2007). It uses a 
position error estimation to calculate speed and 
rotor position. A sliding mode observer based 
estimation of back EMF along stationary mutually 
perpendicular reference frames is shown in (Xu and 
Rahman, 2004). The estimated back EMF 
components are then used to find out rotor position. 
A Novel back EMF detection technique in 
brushless dc motor is shown in (Lai and Lin, 2008). 
The paper proposes unexcited phase detection to 
find out the back EMF.  A RNN based stator flux 
estimator is proposed in [Halder and Ghosh, 2010]. 
The authors showed that the rotor position can be 
estimated accurately by using RNN. This rotor 
position information is then used for vector control 
of IPM synchronous motor drive.  
 
This paper proposes a rotor position estimator using 
back EMF based on RNN. The voltage source 
inverter based systems exhibit poor performances if 
flux estimation is considered. The back EMF 
components along stationary perpendicular axes are 
used to calculate instantaneous position of the rotor. 
Space vector modulation technique is used to 
reduce the ripple in torque. The proposed control 
system is tested for sudden change of load and 
speed reversal condition. 
 
2. MATHEMATICAL MODEL 
 
A mathematical model of the IPM synchronous 
motor is required for proper simulation of the 
system. Fig. 1 shows different axis of the IPM 
motor. The dynamic model of the IPM motor in the 
synchronously rotating d-q reference frame can be 
expressed as follows (Ohm et al., 1995): 
ddrfrqqqq iLipLiRv ωψω +++=               (1)  
qqrdddd iLipLiRv ω−+=                            (2) 
Flux Linkages along the fictitious d-q axes are: 
qqq iL=λ                                                       (3) 
fddd iL ψλ +=                                               (4) 
Where, vd and vq are the d-q axes voltages, id and iq 
are the d-q axes stator currents, Ld and Lq are 
inductances acting along the d-q axes, λd and λq are 
the d-q axes stator flux linkages respectively, R is 
the stator resistance per phase, ωr is the rotor speed,  
 
 
 
 
 
 
 
 
 
 
 
Fig. 1: Stationary and rotating axes of the IPM 
synchronous motor 
 
ψf is the permanent magnet flux, and p is the 
derivative operator (d/dt). 
The developed electromagnetic torque is given as: 
))((
2
3
qdqdqf
p
e iiLLi
P
T −+= ψ                         (5)  
The torque balance equation for the motor speed 
dynamics is given by 
mmmmLe BpJTT ωω ++=                             (6) 
The machine model can be expressed in state-space 
form as: 
fmpddmpqq
q
q PiLPiRvdt
di
L ψωω −−−= (7) 
qqmpdd
d
d iLPiRvdt
diL ω+−=                   (8) 
mmLe
m
m BTTdt
dJ ωω −−=                         (9) 
and mpr p ωω ⋅=                                              (10) 
Where, ωm is the rotor mechanical speed and Pp is 
the number of pole pairs. 
  
3. PROPOSED CONTROL SCHEME 
 
The high performance control strategy is 
implemented in closed loop using PID controller as 
shown in Fig. 2. The speed error is processed to 
generate the torque producing component of the 
stator current (it*). The torque angle δ is a function 
of (it*/ im*) and is assumed in this study as 






=
−
*
*
1tan
m
t
i
iδ                                                  (11) 
The d-q axes reference current components are 
formulated as follows: 
δδ sincos *** tmd iii −=                                   (12) 
δδ sincos *** mtq iii +=                             (13) 
The reference voltage components Vd* and Vq* are 
calculated using (1) and (2). 
Page 472
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
The reference voltage vector u* and the inverter 
switching time are calculated using the formula 
presented in (Bose, 1997). 
If γ is the angle between resultant voltage vector 
and Vq* then  








=
−
*
*
1tan
d
q
V
Vγ                                                 (14) 
The d-q axes back EMF components are given by 
frddrq iLe ψωω +=                                       (15) 
qqrd iLe ω−=                                                    (16) 
If ψ is the angle of resultant back EMF with α- axis 
then 






=
−
s
s
e
e
α
βψ 1tan
                                              (17)  
Estimated angle of voltage vector,  
ψγθ +=                                                  (18) 
The reference phase currents are formulated as 
follows:   
θθ sincos *** tma iii −=                                   (19) 
)120sin()120cos( 0*0** −−−= θθ tmb iii     (20) 
)120sin()120cos( 0*0** +−+= θθ tmc iii   (21) 
The stationary 3-phase (a-, b-, c-) to stationary 2-
phase (α-, β-) transformation is given by 
cbas iiii 5.05.0 −−=α                                   
(22) 
)(
2
3
cbs iii −=β                                             (23) 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
4. RECURRENT NEURAL NETWORK 
BASED BACK EMF ESTIMATION 
 
The Recurrent Neural Network is a single layer 
neural network with input and output nodes. The 
output nodes act as summing nodes and in this 
study the two output variables, i.e., α- and β- 
components of stator back EMF are fed to the input 
with unit delay operator. The value of activation 
function at the output node is taken unity. The 
common inputs for both the outputs are α-, β- 
components of stator current and the speed error. 
The α-component of stator voltage is given as input 
for α-axis stator back EMF estimation. Similarly, 
the β-component of stator voltage is given as input 
for β-axis stator back EMF estimation.  The 
resultant matrix equation can be written as (Rafiq et 
al., 2006): 
 












=





+
+
)(
)(
0
0
)1(
)1(
22
11
ke
ke
W
W
ke
ke
s
s
p
p
s
s
β
α
β
α
siW
W
α





+
21
11
 
siW
W
β





+
22
12












+
β
α
v
v
W
W
23
13
0
0
ωEW
W






+
24
14
         (24)  
 
Where, pW11 , pW22 , 11W , 22W  , 13W , 14W  etc. are 
the weights of the RNN, which is shown in Fig. 3.  
 
 
ωre PID 
controller 
Control     
voltage 
calculation 
Back 
EMF and 
angle 
estimator 








−
*
*
1tan
d
q
V
V
SVM 
switching 
control 
 
a-b-c    
to α-β 
trans. 
Speed Sensor 
 
Inverter 
IPM 
motor 
Axes 
trans. 
Σ 
ωm 
∗
tiEω 
∗
dv
 
- 
+ 
Flux 
Program 
∗
qv
 
∗
mi  
γ 
ψ 
θ 
+ 
+ 
Va 
Vb 
Vc 
ia ib ic 
iαs 
iβs 
vαs 
vβs 
Vdc 
Reference 
voltage vector 
calculation 
 
u
* 
Σ 
∗
di  
∗
qi  
Fig. 2: Proposed control scheme of the IPM synchronous motor drive 
 
Page 473
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 3: Stationary α- and β-axis stator back EMF 
estimation by RNN 
 
5. SIMULATION RESULTS 
 
Computer simulations are conducted in order to test 
the performance of the drive system under different 
operating conditions. The system under 
consideration is simulated in a Pentium-based PC 
with C++ environment. The incremental time ∆t for 
simulating the system is 0.5µs and the sampling 
time for SVM is 0.5ms. 
 
5.1 Performance of RNN for Back EMF and 
Angle Estimation 
The effectiveness of the proposed RNN back EMF 
estimator along α-β axes is verified before 
implementing it in the drive system. Actual back 
EMF components calculated from exact values of 
motor variables are computed and compared with 
the estimated back EMF components. Fig. 4(a) & 
(b) show the estimated α- and β-axis back EMF 
components respectively. It can be visualized that 
the proposed RNN estimates the back EMF 
components accurately. A complete matching of the 
variables is indicated in the following figures. Fig. 
4(c) shows the estimated angle which follows very 
closely the actual angle deduced from the machine 
model. 
 
5.2 Starting Performance of the IPM 
Synchronous Motor Drive 
The motor was started with a command speed of 
955 rpm and load torque of 2.5 N-m from standstill 
condition. Fig. 5(a) shows the simulated speed 
response of the drive. It is observed that this drive 
follows the command speed closely and reaches the 
set value at 0.27 sec. The drive shows very fast 
speed response with no overshoot.  Fig. 5(b) shows 
the developed torque that oscillates around the load 
torque when the motor reaches the set speed. It is 
noticed that higher electromagnetic torque is 
generated during the motor acceleration. Some 
pulsations in electromagnetic torque is noticed 
which is due to switching voltage disturbances of 
the devices with SVM. 
 
 
        (a)  
 
              (b) 
 
            (c) 
 
0.28 0.32 0.36 0.40
-400
-300
-200
-100
0
100
200
300
400
B
ac
k 
em
f i
n
 
v
o
lt
Time in second
 Actual
 Estimated
0.28 0.32 0.36 0.40
-400
-300
-200
-100
0
100
200
300
400
B
ac
k 
em
f i
n
 
v
o
lt
Time in second
 Actual
 Estimated
0.28 0.32 0.36 0.40
-1
0
1
2
3
4
5
6
7
8
A
n
gl
e 
in
 
ra
di
an
Time in second
 Actual
 Estimated
1−z
1−z
Eω 
+ 
+ 
• 
• 
iαs 
 
Vαs 
 
W11p 
W
W22p 
W11 
W21 
W12 
W22 
W23 
W13 W14 
W24 
  
Vβs 
 
iβs 
 
)1( +ke sα  
)1( +ke sβ  
 
Page 474
  
Fig. 4: (a) α-axis components of estimated and 
actual back EMF, (b) β-axis components of 
estimated and actual back EMF, and (c) Estimated 
and actual rotor angle 
 
            (a) 
 
               (b) 
 
Fig. 5: (a) Simulated speed response, (b) Developed 
electromagnetic torque under transient and steady-
state condition 
 
5.3 Performance under Load Change and 
Speed Reversal Condition 
To demonstrate the effect of load change on the 
performance of the drive, the load torque was 
doubled to 5.0 N-m at 1.0 sec. The developed 
electromagnetic torque and speed response are 
given in Fig. 6(a) & (b). Sudden application of load 
torque causes no appreciable variation in speed. 
The steady-state error is almost negligible. To 
verify the effect of speed reversal, the command 
speed was suddenly reversed from 955 rpm to -955 
rpm at 0.6 sec. Again the command speed was set 
to 955 rpm at 1.2 sec. Fig. 7(a) shows the speed 
response for reversal of speed. It is observed that 
the drive system follows the command speeds 
accurately without any oscillation. Fig. 7(b) shows 
the corresponding developed electromagnetic 
torque. 
 
          (a) 
 
             (b) 
 
Fig. 6: (a) Developed electromagnetic torque, (b) 
Simulated speed response for change in load torque 
 
 
 
          (a) 
0.0 0.4 0.8 1.2 1.6
0
200
400
600
800
1000
1200
Sp
ee
d 
in
 
rp
m
Time in second
 Reference speed
 Actual speed
0.0 0.4 0.8 1.2 1.6
0
2
4
6
8
To
rq
u
e 
in
 
N
-
m
Time in second
 Load torque
 Developed torque
0.3 0.6 0.9 1.2 1.5 1.8
0
2
4
6
8
To
rq
u
e 
in
 
N
-
m
Time in second
 Load torque
 Developed torque
0.3 0.6 0.9 1.2 1.5 1.8
0
200
400
600
800
1000
1200
Load torque suddenly 
increased here
Sp
ee
d 
in
 
rp
m
Time in second
 Reference speed
 Actual speed
0.3 0.6 0.9 1.2 1.5 1.8
-1200
-800
-400
0
400
800
1200
Sp
ee
d 
in
 
rp
m
Time in second
 Reference speed
 Actual speed
Page 475
  
 
          (b) 
 
Fig. 7: (a) Simulated speed response, (b) Developed 
electromagnetic torque for speed reversal condition 
 
6. CONCLUSIONS 
 
A position sensorless vector control methodology 
with recurrent neural network for IPM synchronous 
motor SVM drive has been presented in this paper. 
The results obtained in this work indicate that the 
proposed position sensorless control scheme 
produces very fast response of the IPM 
synchronous motor drive. This methodology needs 
only speed transducer and very simple three phase 
voltage regulated SVM inverter. It is observed that 
the proposed drive with RNN based back EMF 
estimator is capable to estimate accurately back 
EMF and rotor position both in steady-state and 
transient conditions. The proposed control scheme 
is sufficiently stable and robust under load 
disturbances and speed reversal condition. 
 
 
REFERENCES 
 
1. Bose, B.K. (1988), A high-performance 
inverter-fed drive system of an interior 
permanent magnet synchronous machine, IEEE 
Trans. on Industry Applications, 24(6), pp. 
987-997. 
2. Uddin, M.N., Radwan, T.S. and Rahman, M.A. 
(2006), Fuzzy-logic-controller-based cost 
effective four-switch three-phase inverter-fed 
IPM synchronous motor drive system, IEEE 
Trans. Industry Applications, 42(1), pp. 21-30. 
3. Roy, N.K., Rafiq, M.A., Kundu, R. and Ghosh, 
B.C. (2008), Fuzzy logic enhanced fast speed 
response control of interior permanent magnet 
synchronous motor drive, IETECH Journal of 
Electrical Analysis, 2(4), pp. 244–249. 
4. Bose, B.K. and Szczesny, P.M. (1988), A 
microcomputer-based control and simulation of 
an advanced IPM synchronous machine drive 
system for electric vehicle propulsion, IEEE 
Trans. Industrial Electronics, 35(4), pp. 547-
559. 
5. Chen, L., Davis, R., Stela, S., Tesch, T. and 
Antze, A. F. (2002), Improved control 
techniques for IPM motor drives on vehicle 
application, Proceedings of IEEE IAS Annu. 
Meeting 2002, Oct. 13-18, 2002, Pittsburgh, 
PA. 
6. Ohm, D.Y., Brown, J.W. and Chava, V.B. 
(1995), Modeling and parameter 
characterization of permanent magnet 
synchronous motors, Proceedings of 24th 
Annual Symposium on IMCSD, June 5-8, 1995, 
San Jose, USA. 
7. Nakamura, K., Saito, K. and Ichinokura, O. 
(2003), Dynamic analysis of interior permanent 
magnet motor based on a magnetic circuit 
model, IEEE Trans. on Magnetics, 39(5), PP. 
3250-3252. 
8. Ogasawara, S. and Akagi, H. (1998), 
Implementation and position control 
performance of a position-sensorless IPM 
motor drive system based on magnetic 
saliency, IEEE Trans. Industry Applications, 
34(4), pp. 806-812. 
9. Tanaka, K. and Miki, I. (2007), Position 
sensorless control of interior permanent magnet 
synchronous motor using extended 
electromotive force, Electrical Engineering in 
Japan, 161(3), pp. 41-48. 
10. Xu, Z. and Rahman, M.F. (2004), Encoder less 
operation of a direct torque controlled IPM 
motor drive with a novel sliding mode 
observer, Proceedings of AUPEC 2004, Sep. 
26-29, 2004, Brisbane, Australia. 
11. Lai, Y.S. and Lin, Y.K. (2008), Novel back-
EMF detection technique of brushless DC 
motor drives for wide range control without 
using current and position sensors, IEEE 
Trans. on Power Electronics, 23(2), pp. 934-
949. 
12. Halder, K.K. and Ghosh, B.C. (2010), Vector 
control of four switch three phase inverter fed 
interior permanent magnet synchronous motor 
drive without position sensor, Journal of 
Electrical Engineering, 10(2), p. 61-68. 
13. Bose, B.K., Power Electronics and Variable 
Frequency Drives (1997), IEEE Press, New 
York, USA. 
14. Rafiq, M.A., Sarwer, M.G. and Ghosh, B.C. 
(2006), Fast speed response field-orientation 
control of induction motor drive with adaptive 
neural integrator, Istanbul University-Journal 
of Electrical & Electronics Engineering, 6(2), 
pp. 229-235.  
0.3 0.6 0.9 1.2 1.5 1.8
-15
-10
-5
0
5
10
15
To
rq
u
e 
in
 
N
-
m
Time in second
 Load torque
 Developed torque
Page 476
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Ahmed, K.S. and Ali.L., 
E-mail: shabbir_528@yahoo.com and liakot@iict.buet.ac.bd  
AN AES PROCESSOR ON A  RECONFIGURABLE HARDWARE 
 
Ahmed, K.S. and Ali.L * 
Institute of Information and Communication Technology 
Bangladesh University of Engineering and Technology, Bangladesh   
 
Advanced Encryption Standard (AES) plays a crucial role to secure information. So implementing the AES 
in a faster and secured way is expected. AES can be implemented in software/hardware. In hardware 
implementation ASIC solution requires high cost and much design time while FPGA based implementation 
offers lower cost, quicker and more customizable solution. This paper represents implementing AES in 
FPGA with minimum latency and speedy throughput where Verilog HDL is used to simulate the operations. 
Both Encryption and Decryption are carried out and simulated in an iterative design approach to minimize 
the hardware consumption. Here the operation of AES like substitution bytes, mix column are simplified to 
reduce complexity and to produce a simple design which would deliver a high throughput and minimum 
latency with EP2C35F672C6 device from Altera provided Cyclone II family. The design would be used for 
both end system and also for transmission device with full of confidence and accuracy. 
 
Index Terms—AES, FPGA, Verilog HDL, cryptography, encryption. 
 
1. INTRODUCTION 
 
With the growth of information and communication 
technology, the processing of data and transferring 
the same through different media involves security 
[1]. A number of crypto algorithms have been 
developed [2-4]. Keeping pace with maturity of the 
security technology the hackers, the electronic 
eavesdroppers, virus and the electronic frauds have 
been coming into the field with new sophisticated 
techniques to attack the security mechanism 
[14,15]. So to protect any unusual attack to the 
valuable information source and their transmission, 
the algorithm Advanced Encryption 
Standard(AES), a Federal Information Processing 
Standard (FIPS) is approved by National Institute 
of Standards and Technology(NIST)[4,7,8,11].But 
AES has 10(Ten) round of complex algebraic and 
matrix operation which involve high processing 
power and introduce delay in encryption and 
decryption process. For this reason at the start of 
this work the speed is treated as a major issue and 
concentration is given on hardware based 
implementation. There are also two types of 
hardware based implementation. FPGA (Field 
Programmable Gate Array) based implementation 
is chosen in this work as FPGA offers lower cost, 
flexibility and reasonable performance than ASIC 
(Application Specific Integrated Circuit) 
implementation. Previously researcher proposed 
implementation of AES processor on FPGA 
hardware dropping many security features since 
earlier version of the FPGA available in the market 
was low capacity. Now high capacity FPGA from 
different vendor is coming in the market. Recently 
design of an AES processor using VHDL and its 
implementation on Xillinx FPGA without 
sacrificing any security feature of the algorithm is 
reported [6]. Altera’s FPGA is another famous 
FPGA to the customers. It offers a lot of high 
capacity FPGAs under different families. 
Literatures [10],[12],[13],[18],[21-23] describe 
design and implementation of AES processor in the 
FPGA platform where maximum throughput 
achieved is 21.54 Gbps with latency 71 clock cycle. 
However reduced latency is essential for 
developing real time applications. So a research 
work conducted to implement the AES processor 
on this FPGA to achieve minimum latency with 
suitable speed performance. 
 
2. AES STRUCTURE 
 
AES, also known as Rijndael, is a block cipher 
adopted as an encryption standard by the US 
government, which specifies an encryption 
algorithm [8-11]. The AES algorithm is capable of 
using cryptographic keys of 128, 192, and 256 bits 
to encrypt and decrypt data in blocks of 128 bits 
sequence. In this paper 128 bits key is used for 128 
bit data block. The input, output and cipher key bit 
sequences are processed as arrays of bytes that are 
formed by dividing these sequences into groups of 
eight contiguous bits to form arrays of bytes. The 
different transformations operate on the 
intermediate result, called the state, which is the 
intermediate cipher result. The state can be 
pictured as a rectangular array of bytes. This array 
Page 477
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
  
has four rows; the number of columns is denoted by 
Nb and is equal to the block length divided by 32. 
The cipher key is similarly pictured as a 
rectangular array with four rows. The number of 
columns of the cipher key is denoted by Nk and 
is equal to the key length divided by 32. The 
number of rounds is denoted by Nr and depends on 
the values Nb and Nk. It is given in Table 1. 
 
Table 1. AES Key length and Rounds. 
 
Key Length   
Nk 
Block Size 
Nb 
Number of 
Rounds Nk 
AES 128 4 4 10 
AES 192 6 4 12 
AES 256 8 4 14 
For the AES algorithm, the number of rounds to 
be performed during the execution of the 
algorithm is dependent on the key size. The 
number of rounds is represented by Nr, where Nr = 
10 when Nk = 4, Nr = 12 when Nk = 6, and Nr = 14 
when Nk = 8. For both its cipher and inverse cipher, 
the AES algorithm uses a round function that is 
composed of four different byte-oriented 
transformations:                          
1) Byte substitution using a substitution 
table (S-box), 2) Shifting rows of the 
state array by different offsets, 3) 
Mixing the data within each column 
of the state array, and 4) Adding a 
round key to the state. 
 
Input Bytes                 
in0 In4 In8 In12 
in1 in5 in9 in13 
in2 in6 in10 in14 
in3 in7 in11 in15 
State Array                     
S0,0 S0,1 S0,2 S0,3 
S1,0 S1,1 S1,2 S1,3 
S2,0 S2,1 S2,2 S2,3 
S3,0 S3,1 S3,2 S3,3 
Output Bytes 
 
 
 
 
 
 
Fig 1: States of the AES 
 
The input and output used by Rijndael at its 
external interface are considered to be one 
dimensional arrays of 8- bit bytes numbered 
upwards from 0 to the 4*Nb-1. These blocks hence 
have lengths of 16 bytes array indices in the ranges 
0..15. The cipher key is considered to be a one-
dimensional arrays of 8-bit bytes numbered 
upwards from 0 to the 4*Nk-1. These  blocks hence 
have lengths of 16, 24 or 32 bytes and array indices 
in the ranges 0..15, 0..23 or 0..31 for 128 bit,192 bit 
and 256 bit key respectively. The cipher input bytes 
are mapped onto the state bytes in the order a0,0, 
a1,0, a2,0, a3,0, a0,1, a1,1, a2,1, a3,1, a4,1 ... and the 
bytes of the cipher key are mapped onto the array 
in the order k0,0, k1,0, k2,0, k3,0, k0,1, k1,1, k2,1, 
k3,1, k4,1 ... At the end of the cipher operation, 
the cipher output is extracted from the state by 
taking the state bytes in the same order as shown 
in Fig1. 
     
Encryption Process of AES: Four different stages 
are used, one for permutation and three for 
substitution. The stages together provide confusion, 
diffusion and nonlinearity[4]. The stages are as 
follows: 
 
Substitute bytes: Uses an S-box to perform a byte-
by-byte substitution of the block. For encryption 
and decryption, this function is indicated by 
SubBytes () and InvSubBytes () respectively.  
 
Shift rows: A simple permutation. For encryption 
and decryption, this function is indicated by 
ShiftRows () and InvShiftRows () respectively. 
 
Mix Columns: A substitution that makes use of 
arithmetic over GF(28), with the irreducible 
polynomial m(x) = x8 + x4 + x3 + x +1. For 
encryption and decryption, this function is indicated 
by MixColumns () and InvMixColumns () 
respectively[1].  
 
Add round key: A simple bitwise XOR operation of 
the current block with a portion of the expanded 
key. For both encryption and decryption this 
function is indicated by AddRoundKey (). 
 
3. FPGA IMPLIMENTATION  
 
Hardware implementation can be both by ASIC 
Solution or by FPGA.ASIC(Application Specific 
Integrated Circuit) solution can be better for mass 
production but which incurs more design time and 
also a costly solution[6,11,12]. 
But Field programmable gate array (FPGA) is an 
integrated circuit that can be reconfigured by the 
designer to produce different design and test a lot of 
circuits with a minimal time which is also be a 
customizable solution. It means that the circuit may 
be usable for different application. With each 
configuration, which takes only fraction of a 
second, an integrated circuit can perform a 
completely different function which is said to be a 
customizable solution[19]. 
out0 out4 out8 out12 
out1 out5 out9 out13 
out2 out6 out10 out14 
out3 out7 out11 out15 
 
Page 478
  
 
For this reason this project is intended to develop 
FPGA based customized high speed AES processor 
to get low latency and high throughput for 
encryption and decryption. In this project a FPGA 
solution is developed and tested using Altera 
provided FPGA and Verilog HDLwith the help of  
Quartus II software. 
 
4. DESIGN PARTITIONING AND 
MODULES 
The project is partitioned in to main four basic 
modules and key expansion operation in the main 
module for encryption and same for decryption 
cycle. 
 
AES_SUB_BYTE Module: This module perform  
the Substitution byte operation of AES algorithm. 
The substitution byte transformation of  input state 
to the output state involves basically two algebraic 
calculation for each byte which is responsible for 
high processing time. So for this reason a 16 x 16 
byte lookup table is used for substitution to 
eliminate complex algebraic operation which will 
increase throughput. 
 
AES_SHIFT_ROW Module: This module is used 
for performing shift row operation of the AES. The 
operation is very simple just to alter the position of 
the bytes on the state matrix. 
AES_MIX_COLUMN Module: This is a operation 
in AES to multiply the present state of AES to a 
constant matrix by the multiplication rules used in 
GF(28) Field[1,8]. 
 
AES_KEY_EXPANSION: This  is very simple. It 
takes the key which is supplied for the algorithm 
which is called symmetric key and generate 10 
additional key for next 10 rounds by a complex 
algebraic operation. Key expansion is performed at 
the starting of encryption process in the encryption 
main module. 
 
There is another AES operation which is 
AddRoundKey where key of each round is XORED 
with the state during round operation. There is no 
separate module for AddRoundKey but this is done 
in main module of encryption and standard modules 
named as onetonine module where other AES 
operation are done simultaneously.  
 
Onetonine module: This module is treated as 
standard module in AES which perform the 
operation of a standard round in AES.  Nine 
standard rounds includes all four operation of AES 
such as substitution byte, shift row, AddRoundKey 
and  Mix column operation .In the encryption part  
at  first key expansion is performed to generate ten 
additional key from the supplied symmetric key and 
then AddRoundKey which is done by the supplied 
symmetric key  in the main encryption module 
called AES_Encryption module. After then other 
nine standard rounds are performed in 
AES_Encryption module each containing 4 basic 
operation of AES. The standard module onetonine 
is called from the main module 
AES_ENCRYPTION for each round from one to 
nine.10th Round is different from standard round 
where mix column operation is skipped. For this 
reason it is done from AES main module 
AES_ENCRYPTION.Operational diagram of AES 
is shown in Fig 2. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 2: Operational Diagram of modules of AES 
Is key 
expansion 
Done 
Add Roundkey 
Operation 
State=Plaintext XOR 
Symmetric Key 
 
Key Expansion Operation 
Symmetric Key 
Input(128 Bit) 
 
Key 
Memory 
10 Key 
[1-10] 
 
Plain 
Text 
Input 
(128 
Bit) 
Round Module(onetonine) 
Aes_Sub_Byte(State) 
AES_Shift_Row(State) 
AES_Mix_column(State) 
AES_Round_key(State) 
Round=Round+1 
Is it 10th Round 
Yes 
No 
Aes_Sub_Byte(State) 
AES_Shift_Row(State) 
AES_Round_key(State) 
Output Cipher (128 
Bit) 
 
Yes 
No 
Symmetric 
Key 
Key 
(Round) 
10th Key 
Page 479
  
In Fig 3 the processing and memory unit used in 
AES processor is shown where memory S-Box 
used by Sub Byte module, Round key is generated 
by key expansion processor using Round constants 
and supplied key in memory and the key produced  
are used by add_round_key processor in each 
round. Inv S-Box memory is used by Inv_sub_byte 
processor in each round of decryption module. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 3: Design Components of the total 
implementation 
 
5. RESULTS & SIMULATIONS 
 
The design of the AES processor described in the 
previous section has been coded by Verilog HDL. 
The Quartus II development software is used for 
coding and simulation. The design is implemented 
on  Altera provided Cyclone II FPGA which is 
based on a high performance architecture with 
sufficient memory. Here in this project the device 
used is EP2C35F672C6. 
Compilation results of Encryption are as follows: 
Total Logic Elements           :3405/33216 
Total Combinational functions   :3405/33216 
Dedicated logic registers:          :1 
Total registers                  :1 
Total Pins           :388/475 
Total memory bits           :327680/483,840 
 
Simulation Results: At first each operation like 
substitution byte, shift row, mix column  and key 
expansion operation are simulated using verilog 
code and design files. Output is realized using input 
vectors and key from NIST publication [4]. 
 
Fig 4: Simulation of one Standard round (one to 
nine round) 
 
In encryption module each standard round is 
simulated and output is verified.  Figure 4 shows 
the simulation of one standard round where all 
basic operations (Substitution bytes shift rows mix 
columns and add round key) are performed and 
latency is observed. 
 
The simulation results of full encryption module is 
shown in Fig 5 where input vectors and key is 
given from NIST standard publication [4] and 
output was verified. 
Plain text: 3243f6a8885a308d313198a2e0370734 
Cipher Key :2b7e151628aed2a6 ab f71588 09 cf 4f 
3c 
 
Fig 5: Simulation of full Encryption Module 
 
The output result of the encryption was found 
accurately after 11 clock cycle from the starting of 
encryption process. So the latency of encryption is 
only 11 clock cycle. In the Fig 5  the generated last 
key(10th) is shown as keyout and latency is 
observed by keyready function. As the device used 
is Altera EP2C35F672C6 from Cyclone II family 
has maximum clock frequency of 50MHz, so the 
encryption through put will be 6.4Gbps as per clock 
cycle encrypt 128 bits data samples. If other device 
having more clock frequency is used then 
throughput can be increased linearly. 
 
The output of the algorithm are visualized by the 8 
seven segment display of the FPGA board where 
first, second ,third and forth 32 bit of the cipher 
produced from 128bits  plaintext  shown in the 
simulation of Fig 5. Fig 6, 7, 8 & 9 respectively 
shows the output of FPGA where input is given by 
toggle switch or by input data to the program. 128 
bit encryption key are also given to the code 
directly. 
 
 
 
Fig 6: Seven segment output of FPGA (1st 32 bit cipher) 
 
 
 
 
 
 
 
 
 
 
 
                   
  Processing Units                                Memory Units 
    Encryption Processor 
Includes: i)Sub_Byte  
               ii)Shift_row  
               iii)Mix_column  
               iv)Add_Round_key  
                         
 
 
    Decryption Processor 
Includes: i)Inv Sub_Byte  
                ii)Inv Shift_row  
                iii)Inv Mix_column  
                iv)Add_Round_key  
 
 
Key Expansion Processor 
Inv S-
Box 
S-Box 
Round 
Key 
Round 
Constant 
Page 480
  
 
 
Fig 7: Seven segment output of FPGA (2nd  32 bit cipher) 
 
 
 
Fig 8: Seven segment output of FPGA (3rd   32 bit 
cipher) 
 
 
 
Fig 9: Seven segment output of FPGA (4th    32 bit 
cipher) 
 
Overall the simulation of quartus II software and 
implementation results on the FPGA board found 
accurate with reduced latency of 11 clock cycle. 
 
7. CONCLUSION AND FUTURE  
WORKS 
 
This is the work to implementing a faster 
cryptosystem in hardware to ensure speedy IT 
security. A synthesizable Verilog design is 
developed for each of the encryption and 
decryption module and has been tested with FPGA 
cyclone II device EP2C35F672C6. Where the 
performance of the each of the sub module with 
entire Encryption and decryption module is found 
satisfactory with proper accuracy having minimum 
latency and speedy throughput which can be 
described as a simple, portable and efficient AES 
implementation for secure communication in a 
reconfigurable hardware with reduced latency. In 
this implementation total throughput gained is 
6.4Gbps and latency of 11 clock cycle/210ns with 
max clock frequency of 50Mhz. 
  
AES is a strong algorithm due to its large rounds 
and algebraic complexity inside the rounds[9]. For 
this reason this project is conducted to implement 
the AES in hardware to speed up the AES enabled 
processing system where minimum latency with 
required throughput is gained which would required 
for real time application. Portable electronic system 
is the vision of this day where power is an 
important issue. So power analysis of the processor 
can be carried out. The proposed processor can be 
implemented on ASIC to improve its performance.     
                                                            
REFERENCES 
 
1. Stallings W.  “Cryptography and Network     
Security: Principles and  Practices. ”4th 
ed.,  Pearson Education,    Inc. pp. 63-173. 
2006. 
2. Pfleeger C. “ Security in Computing. ”  
Upper Saddle River, NJ: Prentice Hall,  
1997. 
3.  Schneier B. “Applied Cryptography,” 2nd 
 Edition, Wiley, New York, 1996. 
4. “Advanced encryption standard  
       (AES)”,Federal Information Processing  
        Standards Publication (FIPS PUB) 197,  
       National Institute of Standards and  
       Technology (NIST), November,  
       2001.Available at:    
      http://csrc.nist.gov/publication/drafts/dfips-              
     AES.pdf 
5.  Daemen J. and Rijmen V., “AES 
Proposal: Rijndael, ” Version 2.    
Submission to NIST, March 1999. 
Available at:      
http://csrc.nist.gov/encryption/aes 
6. Ashwini M. D, Mangesh S. D and     
Devendra N. K “,FPGA  Implementation    
of  AES Encryption and  Decryption”.  
7. Daemen J. and Rijmen V., “Rijndael: The  
Advanced Encryption Standard”.  Dr.  
Dobb’s Journal, March, 2001. 
8. NIST, “DRAFT NIST Special Publication  
       800-131, Recommendation for the  
       Transitioning of Cryptographic Algorithms  
       and Key Sizes”, Federal Information  
       Processing Standards Publication (FIPS  
       PUB) 197, National Institute of Standards  
       and Technology (NIST), January, 2010. 
9. Leopld G., “U.S. unveils advanced    
       encryption standard,” EE Times  
December 10, 2001.Available   at:    
http://www.eetimes.com/story/OEG20011
205S0060. 
10. Qin H., Nonmember, SASAO T. and   
        IGUCHI Y.,Members ,“A Design of AES    
        Encryption Circuit with 128 bit keys using  
        Look-UP Table Ring on FPGA”,IEICE 
        TRANS. INF. & SYST.,VOL.E89-   
        D,NO.3 MARCH 2006. 
 
Page 481
  
11.  Rahman T., Pan S. and Zhang Q., “Design 
of a High Throughput 128-bit (Rijndael 
Block Cipher)”,Proceeding of 
International Multiconferrence   of  
Engineers and computer scientists 2010    
Vol II IMECS 2010, March 17- 19,2010, 
Hongkong. 
12. Hodjat A. and Varbauwhede I.,“A 21.54 
Gbits Fully Pipelined AES Processor on 
FPGA”, IEEE Symposim on Field-
Programmable Custom Computing 
Machines,April 2004. 
13. Jarvinen et al, “A fully pipelined 
memoryless 17.8 Gbps AES-128  
encrypter”,International Symposium                 
on Field Programmable Gate 
arrays,pp.207-215.2003. 
14. Cheng K., Chang T. and Lo J., 
“Cryptanalysis of   Security Enhancement 
for a Modified Authenticated Key 
Agreement   Protocol”, International 
Journal of Network Security, Vol.11, 
No.1, PP.55-  57,  July    2010. 
15. Salama D.A.M, Hatem M. A.K and    
Hadhoud M.M, “ Evaluating the   effects 
of symmetric Cryptography Algorithms on  
Power Consumption for Different Data 
Types.”, International Journal of Network   
  Security,Vol.11,No.2,PP.78-
87,Sept.2010. 
        16.  Ngo H. H, Wu X., Le D. P, Wilson C.,  
               and Srinivasan B., “Dynamic  Key 
               Cryptography and Applications”,    
               International Journal of Network Security,  
                 Vol.10, No.3, PP.161-174, May 2010. 
        17.  Selvaraju N. and Sekar G., “A Method to  
               Improve the Security Level of ATM  
              Banking Systems Using AES Algorithm”,  
               International Journal of  Computer  
               Applications (0975 –  8887), Volume 
               3 – No.6, June  2010. 
       18.    Zambreno J., Nguyen D. and Choudhary  
               A.,“Exploring Area/Delay Tradeoffs in an  
               AES FPGA Implementation”,FPL 2004,  
               LNCS 3203, pp. 575–585, 2004. 
        19.   Mroczkowski P., “Implementation of the 
                block cipher Rijndael using Altera  
                FPGA”, May 2000. [Online].  
 Available at:   
http://csrc.nist.gov/archive/aes/round2/.../2
0000510-pmroczkowski.pdf                 
       20.  Altera Corp. (2007, February). “Cyclone II  
              device family data sheet [Online]”.  
Available at: 
http://www.altera.com/literature/hb/cyc2/c
yc2_cii51001.pdf 
       21. Kenny D., “Energy Efficiency Analysis and  
             Implementation of AES on an FPGA”,  
             University of Waterloo,2008. 
       22. Xiao S.,Chen y. and Luo P., “The  
              Optimized Design of Rijndael Algorithm  
              Based on  SOPC”, International  
              Conference on Information and  
              Multimedia  Technology,2009 
        23.    Helion Technology Limited, “High  
                performance AES cores for Altera  
                FPGA”, 
 Available at: http://www.helion 
Page 482
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Md. Imran Momtaz,  
ANALYSIS OF THE RADIATION PROPERTIES OF HALF-
WAVELENGTH J-POLE ANTENNA ARRAYS 
 
 
Md. Imran Momtaz*, Samiul Hayder Choudhury and Md. Abdul Matin 
Department of Electrical and Electronic Engineering, 
Bangladesh University of Engineering and Technology 
 
 
In this paper, the analytical expression of the radiation pattern of a half-wavelength J-pole antenna array has 
been derived assuming sinusoidal current distribution in the limit  λ/4 to 3λ/4. The proposed expression is 
valid for any number of elements in the array. The results have been compared with the center fed half-
wavelength dipole array with similar current distribution in the limit -λ/4 to λ/4. It has been observed that for 
a J-pole array, the field pattern is more pronounced than that of a center fed dipole array. 
 
Key words: Azimuth plane, broadside array, end-fire array, field pattern, j-pole array 
 
1. INTRODUCTION 
 
When the feed points of the antenna elements are 
arranged in a straight line then it is called a linear 
array [1]. There are five controls that can be used to 
shape the overall pattern of the antenna array [2]. 
These are: (a) the geometrical configuration of the 
overall array (linear, circular, rectangular, spherical 
etc.), (b) the relative displacement between the 
elements, (c) the excitation amplitude of the 
individual elements, (d) the excitation phase of the 
individual elements, and (e) the relative field 
pattern of the individual elements. 
 
The J-pole antenna is a half-wave, end-fed, dipole 
antenna having omni-directional radiation pattern 
[3] [4]. In this configuration, the conventional end 
fed antenna is elevated at least 1/4 wavelength 
above ground, thus eliminating the ground losses 
and ”normalizing” the radiation pattern [5]. 
 
 
Fig. 1A J-pole antenna array 
As shown in Fig. 1 a linear array of n-element half 
wave Jpoles are assumed to have sinusoidal current 
distribution. For each element we have considered 
stub current feed. Beyond the feed position, the 
antenna position of the J-pole element extends from 
λ/4 to 3λ/4 along element axis. 
 
2. DEDUCTION OF THE FIELD 
PATTERN OF AN N-ELEMENT 
HALF-WAVELENGTH J-POLE 
ANTENNA ARRAY 
 
Let us consider an n-element uniform, linear J-pole 
antenna array. The term linear implies that all 
elements of the array are spaced equally along a 
straight line, and the term uniform indicates that the 
magnitude of the current in each element is the 
same and the phase shift is progressive [6]. 
 
The current distribution of a single half-wavelength 
J-pole antenna is assumed to be, 
 
)cos(~ 0 zII β−=  
 
In phasor form the current distribution can be  
written as, 
 
°∠= 180~ 0II  
 
Therefore, the current distribution in the k-th 
element of an N-element J-pole antenna array can 
be expressed as, 
 
Page 483ISBN: 978-984-33-2140-4
  
 
 
Fig. 2. Comparison of field pattern of J-pole array 
with that of half wavelength dipole array with d = 
λ /2 
 
)180(~~ 0 °+∠=∠= αα kIIIk  
 
The current distribution in the (k+1)-th element is, 
 
}180)1{(~ 0)1( °++∠=+ αkII k  
 
The electric field of a single element J-pole antenna 
is found to be [4], 
 















+





=
−
θpiθpi
θpi
η β
cos
2
coscos
2
3
cos
sin4
~ 0
r
eIjE
rj
+ θθ
piθpi aj r














+





cos
2
sincos
2
3
sin
 
 
The electric field can be expressed as, 
 
)
2
(1),(
piβ
θ φθ
−−
=
rj
m e
r
FEE  
 
where, 
pi
η
4
0IEm =  =maximum electric field 
   









+= )cos
2
cos()cos
2
3
cos(
sin
1),( θpiθpi
θ
φθF


++ )}cos
2
sin()cos
2
3{sin( θpiθpij  
where, 
 
φθ cossin1 drr −=  
 
 
Fig. 3. Radiation pattern of J pole array in the xy 
plane with α  = pi   and d = λ /2 
 
 
 
Fig. 4. Radiation pattern of J pole array in the xy 
plane with α  = pi /2 and d = λ /4 
 
 
For an n-element antenna array, the overall electric 
field can be expressed as, 
 
]...1[1),( )1(2)2( ψψψ
piβ
θ φθ −
−−
++++= njjj
rj
m eeee
r
FEE  
 
where,  
αφθβψ += cossind  
d=separation between two successive elements. 
Multiplying the above equation by ψje and then 
subtract the product from the above equation, we 
get, 
 
Page 484
  
]
1
1[1),( )2( ψ
ψpiβ
θ φθ j
jn
rj
m
e
e
e
r
FEE
−
−
=
−−
 
][1),(
22
22
2
2)
2
(
ψψ
ψψ
ψ
ψ
piβφθ jj
jnjn
j
jn
rj
m
ee
ee
e
e
e
r
FE
−
−
−−
−
−
=  
]
)
2
sin(
)
2
sin(
[1),( 2
)1()
2
(
ψ
ψ
φθ
ψpiβ
n
ee
r
FE
nj
rj
m
−
−−
=  
 
Therefore, the normalized array pattern is, 
)
2
sin(
)
2
sin(
)( ψ
ψ
ψ
n
F =  
 
According to the principle of pattern multiplication, 
the total field pattern of an array of similar elements 
is the product of the element pattern, ),( φθF and 
the array pattern, )(ψF  [6]. 
 
),()(),,( φθψψφθ FFF ×=  
),(]
2
)1(
sin
2
)1([cos
)
2
sin(
)
2
sin(
φθψψψ
ψ
Fnjn
n
−
+
−
=
                 

 −
= )cos
2
3
cos(
2
)1({cos
sin)
2
sin(
)
2
sin(
θpiψ
θψ
ψ
n
n
 
)cos
2
3
sin(
2
)1(
sin)cos
2
cos(
2
)1(
cos θpiψθpiψ −−−+ nn
)cos
2
3
sin(
2
)1({cos)}cos
2
sin(
2
)1(
sin θpiψθpiψ −+−− njn
 
 
3. RESULT AND DISCUSSION 
 
The radiation pattern has been plotted in Fig. 2. 
Distinct improvement is observed in the radiation 
pattern of J-pole array over that of half-wave dipole 
array. The radiation pattern of half wavelength 
dipole array was obtained from [2]. In Fig. 3 the 
radiation pattern of a broad side array has been 
plotted. Here, the value of α  has been assumed to 
be equal to pi  and number of element in the array 
was 10. In Fig. 4 the radiation pattern was plotted 
assuming α  = pi /2 and d = λ /4. The J-pole array 
also works equally well as end-fire array whose 
radiation pattern is plotted in Fig. 5. Here, α  = pi  
and d = λ /8 have been assumed. 
 
 
 
 
Fig. 5. Radiation pattern of J pole array in the xy 
plane with α  = pi and d = λ /8 
 
 
4. CONCLUSIONS 
 
The general analytical expression of the radiation 
pattern of a J-pole antenna array has been presented 
assuming sinusoidal current distribution. It is found 
from the analysis that the Jpole antenna array 
exhibits improved field pattern compared to that of 
a half-wavelength array.  
 
REFERENCES 
 
1. V. V. Sarwate, Electromagnetic fields and 
waves, pp. 396, 397, New Dehli: New Age 
International Limited, ISBN 8122404685. 
2. Constantine A. Ballanis, Antenna Theory, 2nd 
ed., John Wiley & Sons, Inc, 1997. 
3. J-pole antenna - Wikipedia, the free 
encyclopedia, Website: 
http://en.wikipedia.org/wiki/J-pole antenna 
4. Samiul Hayder Choudhury, Md. Imran 
Momtaz and Md. Abdul Matin, “Analytical 
Deduction of the Salient Properties of a Half 
Wavelength J-pole Antenna,” International 
Conference on Computational Intelligence and 
Communication Networks (CICN) ’10. 
5. Paul Graham, A Discussion of Antenna 
Theory, Website: 
http://k9erg.tripod.com/theory.htm 
6. Guru B.S., Hiziroglu H.R., Electromagnetic 
Field Theory Fundamentals, 2nd Edition, 
ISBN 0521830168, 2004. 
Page 485
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Zinnat Ara Islam  
E-mail: zara807@yahoo.com  
BI-EDF-BASED OPTICAL AMPLIFICATION AND                              
MULTIWAVELENGTH LASER 
 
 
Zinnat Ara Islam* and Dr. Sulaiman  wadi Harun  
Department of Electrical Engineering, University of Malaya, KL, Malaysia 
 
 
 
This research focuses on the exploitation of nonlinear effects in photonic crystal fiber (PCF), mainly the 
Stimulated Brillouin Scattering (SBS) to generate multi-wavelength signal in a Bismuth-based Brillouin 
Erbium Fiber Laser (BEFL). A 2.15m Bismuth-based Erbium-doped Fiber (Bi-EDF) with erbium ion 
concentration of 3250 wt. ppm is used in this study as a linear gain medium. The gain and noise figure 
characteristics of the Bismuth-based Erbium-doped Fiber Amplifier (Bi-EDFA) are also demonstrated. The 
Bi-EDFA exhibits gain in L-band region with a forward pumping scheme. The maximum gain of 12.1 dB 
has been obtained at input signal power of –40dBm and wavelength of 1610nm. By using a bi-directional 
pumping scheme with a higher pump power, gains of more than 20dB are obtained within a wavelength 
band from 1570 to 1620nm. The bi-directional Bi-EDFA is then used to assist a multi-wavelength generation 
in PCF-based Brillouin fiber laser (BFL). The PCF-based BFL or BEFL uses a ring configuration with 20m 
long PCF as a nonlinear gain medium. The injected BP wavelength and power as well as the power of 1480 
nm pumps and effective cavity loss in the cavity exhibited a great effect on the number of wavelengths and 
output power of the generated wavelength comb. The ring cavity BEFL with lower cavity loss could 
generate up to 13 lines Stokes and anti stokes lines. The stable output laser comb of 13 lines with a line 
spacing of 0.08nm is obtained at a BP wavelength of 1574 nm by using a total power of 1480 nm pump of 
240mW. The number of lines increases as the pump power increases. The anti-Stokes is also observed due to 
the four-wave mixing effect. The multi-wavelength BEFL signal has potential applications in wavelength 
division multiplexing (WDM), optical fiber sensor system, optical component testing and spectroscopy 
applications. 
 
Key words: Photonic crystal fiber, Stimulated Brillouin Scattering, 
Bismuth-based Erbium-doped Fiber Amplifier, Four-wave mixing, wavelength division multiplexing. 
 
 
1. INTRODUCTION 
 
The area of photonic crystal fibre (PCF) technology 
has progressed rapidly in recent years and has been 
successfully applied to the development of a variety 
of photonics devices and applications [6-1]. 
Stimulated Brillouin scattering (SBS) is a nonlinear 
effect resulting from the interaction between 
intense pump light and acoustic waves in a medium 
and giving rise to backward propagating frequency-
shifted light [2]. Although Brillouin generation can 
be detrimental in coherent optical-communication 
systems [4], it has been advantageously utilized in 
the past few years for the many applications such as 
optical-fiber characterization [9], distributed strain 
and temperature measurements [12-7] and narrow-
bandwidth amplification [5]. Perhaps the largest 
interest has arisen from the use of SBS to produce 
Brillouin fiber laser [10-11] with applications such 
as gyroscopes [14]. Photonics crystal fibers (PCFs) 
are a class of micro-structured fiber which 
possesses a solid core surrounded by a cladding 
region that is defined by a fine array of air holes 
that extend along the full fiber length. Due to the 
high index difference between silica core and air 
hole cladding, these PCFs allow much stronger 
mode confinement, and thereby much higher 
nonlinearities than that of a conventional single 
mode fiber (SMF) [3]. This fiber can be used as a 
nonlinear gain medium to develop a compact BFL. 
In the previous reports, BFLs have been achieved 
using more than 70m long PCF as a gain medium 
[8-13]. 
 
BFL has various applications in optical 
communication and sensing technology and can be 
constructed using stimulated brillouin scattering 
(SBS) effect in single mode fibers. SBS is a 
Page 486ISBN: 978-984-33-2140-4
  
nonlinear effect resulting from interaction between 
intense pump light and a acoustic waves in a 
medium and giving rise to backward propagation 
frequency - shifting light. The required gain 
medium length can be substantially reduced using 
PCF to replace a conventional SMF. However most 
of earlier works on PCF-based BFLs are mainly on 
single wavelength operation. In next sections, we 
present the first experimental demonstration of a 
multi-wavelength BFL operating in long wave 
length band (L-band) region. The proposed BFL 
also uses a very short length of PCF in conjunction 
with 45 highly nonlinear bismuth–oxide based 
erbium-doped fiber (Bi-EDF) as a linear gain 
medium to assist in multi- wavelength operation.  
 
2. EXPERIMENTAL SETUP OF THE 
PCF- BASED BFL 
 
The experimental setup for the PCF-based BFL is 
shown in Fig 1 The ring resonator consists of a 
circulator, a 20m long PCF, a 215 cm long Bi-EDF, 
two 1480 nm pump diodes, two wavelength 
selective couplers (WSCs), three isolators, a (80-20, 
90-10, 95-5) output coupler and a polarization 
controller (PC). The PCF used as a nonlinear gain 
medium is a polarization maintaining fiber which 
has a cut-off wavelength of 1000 nm, zero 
dispersion wavelength of 1040 nm, nonlinear 
coefficient of 11 (W.km)-1 and a mode field 
diameter of 4.0 µm. The Bi-EDF used has an 
erbium concentration of 3,200 ppm with a cut-off 
wavelength of 1440 nm and a pump absorption rate 
of 83 dBm at 1480 nm. The Bi-EDF is pumped bi-
directionally using two 1480 nm lasers. Optical 
isolators are used to block the Brillouin pump (BP) 
from oscillating in the cavity and also to ensure a 
unidirectional operation of the BFL. An external 
cavity tunable-laser source (TLS) with a linewidth 
of approximately 20 MHz and a maximum power 
of 8 dBm is used as the brillouin pump (BP). PC is 
used to control the birefringence (breakage of a 
light ray into two different directions therefore 
creating two separate light rays) of the ring cavity 
so that the power of the laser generated can be 
controlled. The experiment executed using 3 
different type of couplers that are 80-20, 90-10 and 
95-5. The output for the BFL is tapped from the leg 
with smaller ratio of the output and is then 
characterized using an optical spectrum analyzer 
(OSA) with the resolution of 0.015.    
             
 
 
Fig 1: Configuration of multi-wavelength BFL 
 
The BP is injected into the ring cavity and then 
PCF via the circulator to generate the backward 
propagating Stokes light at opposite direction. 
However, since the PCF length is not sufficient 
enough, the back-scattered light due to Rayleigh 
scattering is relatively higher than the Stokes light. 
Both back-scattered pump and the Stokes lights are 
amplified by the Bi-directionally pumped Bi-EDF 
and oscillate in the ring cavity to generate first 
stokes in the anti clockwise direction. This 
oscillation continues and when the intensity of the 
first brillouin stock is higher than the threshold 
value for brillouin gain, the second order SBS is 
generated in clockwise direction and this signal 
blocked by the isolator in the cavity however, the 
back-scattered light from second SBS will be 
amplified by the Bi-EDF. 
 
However, the nonlinear gain by both PCF and Bi-
EDF only amplifies the Stokes light and thus the 
Stokes light is more dominant and laser is 
generated at the Stokes wavelength. The spacing 
between the BP and the BFL is obtained at 
approximately 10 GHz, which is equivalent to the 
Stokes shift in the SMF. 
 
3. RESULT AND DISCUSSION 
 
The operating wavelength of the BFL is determined 
by the bi-directionally pumped Bi-EDF gain 
spectrum which covers the L-band region from 
1560 to 1600 nm as well as the cavity loss. As 
show in figures 2 (a), (b) and (c) the free running 
spectrum of the BFL or without BP (TLS) off for 3 
different type of couplers. As shown in three 
figures the peak wave generated at around 1574nm 
with bandwidth is approximately 3nm due to the 
difference between Bi-EDF’s gain and cavity loss is 
largest in this wavelength region. The chosen BFL 
is operating wavelength must be with in or close to 
the bandwidth of free running BFL. Therefore the 
BP is set with in 1574 nm region. The free-running 
BFL also exhibits a peak power of approximately -
Page 487
  
6 dBm with 20 dB bandwidth of approximately 1 
nm for 80-20 coupler. And the peak power for 90-
10 is approximately -10 dBm and for the 95-5 
coupler is about -15 dBm. The cavity loss is lowest 
with 80-20 coupler and therefore the peak power is 
highest. 
 
 
 
 
 
 
 
Fig 2: Free-running spectrum of the VFL using (a) 
80-20 coupler, (b) 90-10 coupler, (c) 95-5 coupler  
 
Figures, 3 (a), (b) and (c) show the output spectrum 
of the BFL at output couplers of 80-20, 90-10 and 
95-5, respectively. The experiment was carried out 
for three different pump powers. Both 1480 pump 
is set at the same power and power of each pump is 
varied from 60 mW to 140 mW. The threshold of 
the BFL is observed to be around 60mW for all set-
ups. The BP wavelength is optimized at 1574.0 nm 
which is within the lasing bandwidth of the free 
running BFL. For all figures at pump power below 
of 60 mW (threshold) the erbium gain is very low 
and cannot be sufficient to compensate for the loss 
inside the laser cavity and thus no Stokes are 
observed. When increasing the 1480nm pump 
power the number of wavelength generated is 
increased and the anti-Stokes wave is also 
appeared, which is attributed to the increment of the 
erbium gain with pump power. This situation 
provide sufficient signal for SBS as well as the 
four-wave mixing to generate stokes and anti 
stokes. In this experiment, more than 13 lines are 
obtained at the maximum 1480 nm pump power of 
140 mW with wave length spacing of 
approximately 0.08nm. 
 
At pump power of 140 mW, the BFL is achieved at 
1574.08 nm for 80-20 coupler with the peak power 
of 8 dBm and the 3 dB bandwidth of approximately 
0.02 nm (which is limited by the OSA resolution) 
as shown in figure 3 (a) for 80-20 coupler. For 90-
10 coupler of figure 3 (b), the first Stokes peaks at 
5 dBm is with the maximum 1480 nm pump power. 
For (95-5) coupler of figure 3(c), more than 13 
lines are obtained with peak power of about 
0.3dBm and the 3 dB bandwidth of about 0.2 nm at 
the maximum 1480nm pump power. The number of 
line is largest at this coupling ratio as a result of the 
lowest cavity loss. The side mode suppression ratio 
(SMSR), which is defined as the power difference 
between the BFL’s peak with the second highest 
peak obtained are obtained at approximately 
26.31dB, 24.42dB, 16.33dB for 80-20 ,90-10 and 
95-5 couplers, respectively as shown in Figure 3. 
The best spectrum is obtained with (95-5) coupler. 
The multi-wave length output of the BFL is 
observed to 50 be stable at room temperature with 
only minor fluctuation observed coinciding with 
large temperature variances. The side modes are 
mainly due to anti Stokes and additional Stokes of 
the BFL, which arises due to four-wave mixing 
effect in the ring cavity. 
 
 
 
 
 
Page 488
  
 
 
Fig 3: The BFL output spectrum for (a) 80-20 
coupler, (b) 90-10 coupler and (c) 95-5 coupler  
 
The laser reached threshold of a pump power of 60 
mW, and at the higher pump powers yield two sets 
of spectral lines corresponding to odd-and even 
order stokes and anti-stokes waves that counter-
propagated in the ring. Figure 4 shows the output 
spectrum of the BFL for (95-5) coupler with and 
without polarization controller (PC). PC is used to 
adjust the polarization state of the light inside the 
cavity. Proper adjustment of the birefringence or 
polarization of the light is important to achieve a 
multi-wavelength oscillation. As shown in the 
figure, a better spectrum is obtained by adjusting of 
PC. The anti-stokes waves can also be observed in 
PCF-based BFL because of four-waves-mixing 
between pump and stokes waves or between 
different stokes order. At a pump power of 140 
mW, four-wave mixing between the two first odd-
orders stokes waves lead to the generation of more 
than 15 spectral lines. 
 
 
 
Fig 4: BFL output spectra with and without PC 
 
 
                   
 
Fig 5: Out put peak power as a function of  
           1480 total pump powers (nm) 
Figure 5 shows the peak power of the BFL for 
different coupler against the total input 1480nm 
pump power and BP pump power, respectively. The 
BP is fixed at 8 dBm and 1547nm. The BFL starts 
to lase at 1480nm pump power of 60mW which is 
the threshold power. Below this power, the erbium 
gain is very low and cannot sufficiently compensate 
for the loss inside the laser cavity and thus no 
Stokes is observed. The peak power increases as the 
1480nm pump power increases which is attributed 
to the increment of the erbium gain with pump 
power. As we see also the peak power for 80-20 
coupler is higher than 90-10 and 95-5 coupler. 
Saturation power pump for both pumps is around 
145 mw. The output of the BFL is observed to be 
stable at room temperature with only minor 
fluctuations observed coinciding with large 
temperature variances. 
 
 
Fig 6: The Brillouin stoke and anti-stoke            
peak power against BP power 
 
 
 
Fig 7: Comparing the threshold power for the 3 
couplers                                   
 
Figure 6, shows the peak power of stokes and anti 
stokes against the input pump power. The coupling 
ratio is set at 95-5, which is the optimum. As shown 
in this figure, the threshold for pump power BP to 
generate the Stoke and anti-Stokes wave is around 
5 dBm. Figure 7 shows peak power of the first 
Stokes against input BP power at different coupling 
ratio. As shown in the figure, the Brillouin 
threshold for (95-5) coupler is approximately 4 dB 
higher than the (80-20) coupler. The Brillouin 
threshold is obtained at 2 dBm and 1.5dBm with 
80-20 and 90-10 coupler respectively. 
 
Page 489
  
4. CONCLUSION  
 
In summary, a new configuration of multi-
wavelength BFL is proposed and demonstrated 
using a PCF in conjunction with bi-directionally 
pumped Bi-EDF. The BFL uses a ring cavity 
structure to generate Stokes and anti-Stokes via 
SBS and FWM processes. The proposed BFL is 
able to generate up to 13 lines including anti-Stokes 
with a channel spacing of 0.08 nm at the 1574 nm 
region at a BP power of 5 dBm and the total 1480 
nm pump power of 240 mW. The multi-wavelength 
BFL is stable at room temperature and also 
compact due to the use of only 20 m long of PCF 
and 215 cm long of Bi-EDF.  
 
5. FUTURE WORK 
 
This research work can be extended for future 
research to reduce further the length of Bi-EDF or 
to replace the Bi-EDF with other enhanced rare 
earth dopant fibers likes Zarconia-Yttria doped 
fiber that can maintain high flat gain per length 
coefficient of compact amplifiers. In the future, a 
development study can be done by employing a 
state of the pump-signal technique which is useful 
for determine the Brillouin linewidth with high 
frequency resolution near to 1 MHz. 
 
 
REFERENCES 
 
1. A. Cucinotta, F. Poli, S. Selleri, L. Vincetti, 
and M. Zoboli, “Amplification  properties of Er 
-doped photonic crystal fibers,” J. Lightwave 
Technol., vol. 21, pp. 782–788, Mar. 2003. 
2. Agrawal, G. P., Nonlinear fiber optics, 2nd 
Edition, 370–403, Academic, San Diego,        
California, 1995. 
3. Bjarklev, A., J. Broeng, and A. S. Bjarklev, 
Photonics crystal fibers, Kluwer Academic 
Publishers, 2003. 
4. Chraplyvy, A. R., “Limitations in lightwave 
communications imposed by optical-fiber 
nonlinearities,” J. Lightwave Technol., Vol. 10, 
1548–1557, 1990. Progress in 
Electromagnetics Research Letters, Vol. 8, 
2009 149 
5. Ferreira, M. F., J. F. Rocha, and J. L. Pinto, 
“Analysis of the gain and noise characteristics 
of fiber Brillouin amplifiers,” Opt. quantum 
electron, Vol. 26, 34–44, 1994. 
6. J. Limpert, T. Schreiber, S. Nolte, H. Zellmer, 
T. Tunnermann, R. Iliew, F. Lederer,      J.          
Broeng, G. Vienne, A. Petersson, and C. 
Jakobsen, “Highpower air-clad large-mode-
area photonic crystal fiber laser,” Opt. Express, 
vol. 11, pp. 818–823, 2003 
7. Kurashima, T., T. Horiguchi, and M. Tateda, 
“Distributed temperature sensing using 
stimulated Brillouin scattering in optical silica 
fibers,” Opt. Lett., Vol. 15, 1038–1040, 1990. 
8. Lee, J. H., Z. Yusoff, W. Belardi, M. Ibsen, T. 
M. Monro, and D. J. Richardson, “Investigation 
of brillouin effects in small-core holey optical 
fiber: Lasing and scattering,” Opt. Lett., Vol. 
27, 927–929, 2002. 
9. Rich, T. C. and D. A. Pinnow, “Evaluation of 
fiber optical waveguides using brillouin 
spectroscopy,” Appl. Opt., Vol. 13, 1376–1378, 
1974. 
10. Shen, G.-F., X.-M. Zhang, H. Chi, and X.-F. 
Jin, “Microwave/millimeter-wave generation 
using multi-wavelength photonic crystal fiber 
brillouin laser,” Progress In Electromagnetics 
Research, PIER 80, 307–320, 2008. 
11. Smith, S. P., F. Zarinetchi, and S. Ezekiel, 
“Narrow-linewidth stimulated brillouin fiber 
laser and applications,” Opt. Lett., Vol. 16, 
393–395, 1991. 
12. Tateda, M., T. Horiguchi, T. Kurashima, and 
K. Ishihara, “First measurement of strain 
distribution along field-installed optical fibers 
using brillouin spectroscopy,” J. Lightwave 
Technol., Vol. 8, 1296–1272, 1990. 
13. Yang, X., X. Dong, S. Zhang, F. Lu, X. Zhou, 
and C. Lu, “Multiwavelength erbium-doped 
fiber laser with 0.8-nm spacing using sampled 
bragg grating and photonic crystal fiber,” IEEE 
Photonics Technol. Lett., Vol. 17, 2538–2540, 
2005. 
14. Zarinetchi, F., S. P. Smith, and S. Ezekiel, 
“Stimulated brillouin fiberoptic laser 
gyroscope,” Opt. Lett., Vol. 16, 229–231, 1991. 
Page 490
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Md. Rejvi Kaysir  
E-mail: rejvikaysir@yahoo.com 
CHARGE CONTROL STUDIES IN InxGa1-xN/InN/ InxGa1-xN-BASED 
DOUBLE CHANNEL HIGH ELECTRON MOBILITY TRANSISTORS 
(DHEMTs) 
 
Md. Rejvi Kaysir*, Md Rafiqul Islam, Md. Sherajul Islam, Ashraful G. Bhuiyan 
Determent of Electrical and Electronic Engineering, KUET, Khulna-9203, Bangladesh 
 
A. Hashimoto and A. Yamamoto 
Graduate School of Engineering, University of Fukui, 3-9-1 Bunkyo, Fukui 910-8507, Japan 
 
 
This paper describes the charge control studies of InxGa1-xN/InN/InxGa1-xN double channel high electron 
mobility transistor (DHEMT).This includes the solution of the Schrödinger and Poisson equations self 
consistently to find the electronic states in InxGa1-xN/InN/InxGa1-xN selectively doped  double heterostructure 
system. The model takes into account the highly dominant spontaneous and piezoelectric polarization effects 
to predict the two dimensional electron gas (2DEG) sheet density more accurately at the heterointerfaces.The 
band profile is calculated for the first three sub band energy with In composition x = 0.05. A large 
conduction band offset of about 1.58eV is obtained for the proposed device , which ensure the better carrier 
confinement and higher sheet charge density.The two dimensional electron sheet concentration of high up to 
4.97×1018 cm-3 for lower InN /InGaN hetero interface and 4.78×1017 cm-3 for upper InGaN/InN hetero 
interface are found for In content of 0.05. This analysis provides indepth investigation of the performance of 
the DHEMT and to optimize their design. 
 
Keywords: 2DEG, Heterostructure, Schrödinger’s equation, Self consistent calculation, DHEMT.
 
1. INTRODUCTION 
 
Indium nitride (InN) semiconductor has been 
regarded as a very interesting and highly promising 
material system for both optical and microwave 
applications. In recent years, there has been interest 
in the development of HEMTs based on InN 
because of their high critical electric field for high 
saturation velocity and breakdown (Mimura et al., 
2005). Advances have also been made in 
InGaN/InN HEMTs since the early report of two 
dimensional electron gas (2DEG) and high electron 
mobility (Hasan et al., 2008). However, they often 
suffer from low current densities due to the 
relatively small carriers in the channel.The sheet 
carrier density can be improved to some extent by 
increasing the doping in the donor layer at the 
expense of lower breakdown voltages.A  better 
apporach to achieve high current driving capability 
is by distributing doping into multiple donor 
regions by employing multiple heterojunctions.In 
this way multiple Two-Dimensional Electron Gases 
(2DEGs) are formed and high current density can 
be expected (Kwon et al., 1995).  
Dual channel HEMT device uses a heterojunction 
on both sides of the undoped conductive channel. 
 
The electron confinement in the channel is expected 
to be stronger in the double heterostructure than in 
the conventional single heterostructure due to the 
enhanced polarization induced electric field. Chen et  
al. have proposed and demonstrated an 
AlGaN/InGaN/GaNdouble-heterostructure transistor 
(DHFET) where the electron confinement is 
significantly improved due to enhanced potential 
barriers at the AlGaN/InGaN and InGaN/GaN 
heterointerfaces (Hasan et al., 2008). Current 
collapse free performance of the DHFET was 
demonstrated.However, there is very little 
theoretical works on the InN-based HEMTs, which 
are mainly concentrated in the conventional single 
channel HEMT.Recently, we have calculated the 
2DEG properties in InN based double channel 
HEMTs.The 2DEG sheet carrier concentration and 
mobility for dual channel is higher than 
conventional single channel HEMTs (Hasan et al., 
2008). Therefore, attention should be given in the 
InN-based dual channel HEMT. For improving the 
device performance an indepth investigation of 
charge control studies in InGaN/InN/InGaN double 
heterostructures is urgently required. 
In this work, a self-consistent charge control model 
based on one dimensional Schrodinger-Poisson 
equations is developed to study the performance. To 
Page 491
  
get an insight into the physical operation and carrier 
control mechanism of InN based DHEMT this 
model is applied to investigate the quantum 
confinement and the effect of applied gate voltage 
on the carriers. The highly dominant effect of 
spontaneous and piezoelectric polarization is 
incorporated in the present model to accurately 
predict the 2DEG sheet charge density at the 
InGaN/InN and InN/InGaN interfaces.  
 
2. DEVICE STRUCTURE  
 
The schematic of the proposed InGaN/InN/ InGaN 
device model is shown in Fig. 1. An undoped 30nm 
InN channel layer is sandwiched between two n-
InGaN layers with a thickness 20nm. Intentional 
stress will be produced at the interfaces due to the 
lattice mismatch between InGaN/InN and 
InN/InGaN heterostructures. Electrons will be 
defused to the lower energy InN layer where they 
are confined due to the energy barrier at the 
heterointerface.The region of the InxGa1-xN 
depleted of electrons forms a positive space charge 
region, which is balanced by the accumulated 
electrons at the InN heterointerface. The technique 
of modulation doping is a perfect means of 
introducing electrons into the InN layer without the 
adverse effects of donors. With increasing the 
spacer layer thickness enhances the electron 
mobility by reducing columbic scattering.However 
it reduces the 2DEG carrier density as well, which 
is not desired because of the reduction in electron 
transfer. Therefore a compromise should be made 
between the donor density in   n-InGaN, conduction 
band edge discontinuity , which is controlled by the 
In   content in the n-InxGa1-xN, and the thickness of 
the undoped InGaN spacer layer to maximize both 
saturation velocity and the electron density of  
2DEG in the HEMT undoped  InN channel. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig.1: Schematic view of proposed 
InGaN/InN/InGaN based DHEMT. 
3. MODEL FORMULATION 
 
The model considered first obtains the potential 
profile in the DHEMT structure by solving the 
Schrödinger equation and Poisson equation self-
consistently. The Schrödinger equation yields the 
confined charge terms in the Poisson equation 
which, in turn, determines the potential profile. 
This potential profile is fed back into the 
Schrödinger equation until the solution of Poisson 
equation goes to convergence. According to the 
effective mass approximation, the one dimensional 
Schrödinger equation is given by 
 
)()()()(1
2 *
2
zEzzV
dz
zd
mdz
d
iii
i ψψψ =+




h
 (1)                                                                     
 
Where, m is the effective mass, Ψi is the 
wavefunction of the i th sub band and is found from 
the solution of Schrodinger equation couple with 
Poisson’s equation, Ei is the energy of i th subband. 
The unknown potential energy V (z) is given by 
 
 
                                                 
)()()( zEzqzV c∆+−= φ                  (2) 
 
 
q is the electronic charge, )(zEc∆ is the conduction 
band offset and )(zφ  is the electrostatic potential 
and is found from the solution of Poisson’s 
equation, expressed as 
                                                                    
])()([)( −+ −−+−=



AD NznzpNqdz
zd
dz
d φ
ε   (3) 
 Where, ε is the dielectric constant, ND+, p(z), n(z), 
NA-, are the density of ionized doping donors, free       
holes, free electrons, and ionized doping acceptors. 
In the simulation region we assume NA- = p(z) = 0 
and the inherent electron accumulation at InN 
surface due to the effects of surface charge and 
dislocation densities is not considered. For InGaN/ 
InN and InN/InGaN material, we must take account 
of the polarization sheet charge at the interfaces in 
Poisson’s equation, and the boundary condition is                        
 
σεε −=−
−−
InNInNNGaInNGaIn EE xxxx 11    (4)                        
    
 
Where, E is the electric field, ε is the dielectric 
constant and σ  is the bound polarization induced 
charges at the surface of InGaN.For the top hetero 
interface of InGaN/ InN σ (x) is given by  
 
Substrate 
(20 nm ) n-InGaN Layer 
(20 nm ) n-InGaN Layer 
(10 nm)  InGaN Spacer Layer  
(10 nm)  InGaN Spacer Layer  
Source Gate  Drain 
2DEG 
     Channel-1 
Channel-2 
   InN (30nm) 
Page 492
  
)()(1)(1)( 11 InNPNGaInPNGaInPx spxxspxxpz −+= −−σ
  C/m2              (5) 
 
For the bottom InN/InGaN hetero interface     
)()(1)(2)( 11 InNPNGaInPNGaInPx spxxspxxpz −+= −−σ
 C/m2               (6) 
 Where, Ppz(InxGa1-xN) and Psp InxGa1-xN) are given 
by Ambacher et al. ( Ambacher et al., 2002)     
 
P1pz(InxGa1-xN) =[-0.113(1-x)+0.0276x(1-x)]  C/m2 
P2pz(InxGa1-xN) =[-0.17x+0.17)]       C/m2 
P1sp(InxGa1-xN) = -0.042x-0.034(1-x) +0.037x(1-x)          
C/m2 
Psp(InN) = -0.032 C/m2 is given by (Sacconi et 
al.,1997). 
 
 
 
4. RESULTS AND DISCUSSION  
 
To study charge control characteristics of a device 
it is needed to examine in detail the band profile of 
the device.The conduction band profile for the 
InGaN/InN/InGaN DHEMT using self consistent 
solution of the Schrödinger and Poisson equation 
over the entire device structure is shown in Fig. 2. 
The band profile is calculated for the first three sub 
band energy (i.e, for E1, E2 and E3 quantum states) 
for In mole fraction of 0.05.The parameters used 
for the calculation is shown in Table 1. A large 
conduction band offset of about 1.58eV for In mole 
fraction of 0.05 is obtained for the proposed device, 
which ensure the better confinement and higher 
sheet charge density. 
 
0 10 20 30 40 50 60 70 80 90
0.0
0.5
1.0
1.5
2.0
2.5
3.0
3.5
4.0 In mole fraction=0.05
           T=300K
Po
te
n
tia
l(e
V
)
Depth,x(nm)
 
 
Fig. 2: Conduction Band profile as a function of 
distance of InGaN/InN/InGaN DHEMT. 
 
0 10 20 30 40 50 60 70 80 90
0.00E+000
1.00E+018
2.00E+018
3.00E+018
4.00E+018
5.00E+018
ND=1018 cm-3
2D
EG
 
Co
n
ce
n
tr
at
io
n
 
(cm
-
3 )
Depth,x(nm)
 
Fig. 3: Charge distribution of lower hetero interface 
as a function of distance of InGaN/InN/InGaN 
DHEMT. 
 
The calculations here shown have been obtained 
considering the polarization charge at the 
InGaN/InN and InN/InGaN interfaces. The 2DEG 
forms at the hetero interface with a peak 
concentration of high up to 4.97×1018 cm-3 is found 
for lower InN/InGaN interface of 
InGan/InN/InGaN DHEMT for dopinng density 
ND=1018 cm-3 as shown in figure 3.The high 
concentration mainly caused by two factor, one is 
the large piezoelectric polarization caused by the 
significant lattice mismatch between InGaN and 
InN. The other is strong quantum confinement 
effect caused by the large conduction band offset of 
about 1.58eV. Also,The 2DEG forms at the hetero 
interface with a peak concentration of high up to 
4.78×1017 cm-3 is found for upper InGaN/InN 
interface of InGan/InN/InGaN DHEMT for doping 
density of 1018cm-3  in InGaN layer as shown in 
figure 4.  
 
Table 1.  Parameters used for the calculation. 
 
Parameters Description Value 
x Mole fraction 0.05 
T Temperature  300K 
∆Ec Conduction 
band offset 
1.58eV 
Φb(x) Barrier height 0.822eV 
ε0 Absolute 
permittivity 
8.854×10-12 F/m 
 
εs 
 
Permittivity of 
InGaN 
9.22ε0 
 
Psp(x) 
 
Spontaneous 
polarization of 
mole fraction x 
-0.0326 C/m2 
 
 
Page 493
  
0 10 20 30 40 50 60 70 80 90
0.00E+000
1.00E+017
2.00E+017
3.00E+017
4.00E+017
5.00E+017
2D
EG
 
Co
n
ce
n
tr
at
io
n
 
(cm
-
3 )
Depth,x (nm)
Nd=1018 cm-3
 
Fig. 4: Charge distribution of upper hetero interface 
as a function of distance of InGaN/InN/InGaN 
DHEMT. 
The lower hetero interface has higher sheet carrier 
concentration due to the lage polarization induced 
charge. So, the total carrier concentration in the 
device is much higher than the Single Channel 
High Electron Mobility Transistor (SHEMT). 
 
 
5. CONCLUSIONS 
 
We have studied InGaN/InN/InGaN double channel 
high electron mobility transistor (DHEMT) with 
high 2DEGs. A self consistent charge control 
model is developed to calculate the electronic states 
of the device.The model takes into account the 
highly dominant spontaneous and piezoelectric 
polarization effects to predict the 2DEG sheet 
charge density more accurately at the 
heterointerfaces. The band profile is calculated for 
the first two sub band energy for In mole fraction of 
x = 0.05. A large conduction band offset of about 
1.58eV is found, which ensure the better 
confinement and higher sheet charge density. The 
two dimensional electron sheet concentration of 
high up to 4.97×1018 cm-3 for lower InN/InGaN 
hetero interface and 4.78×1017cm-3 for upper 
InGaN/InN hetero interface are found for In content 
of 0.05.This high density 2DEG leads to 
unprecedent high power densities and high current 
drive capability that are one order of magnitude 
higher than SHEMT. 
 
 
 
REFERENCES 
 
1. Mimura,Takashi (2005), Development of High 
Electron Mobility Transistor, Jpn. J. Appl. 
Phys., Vol. 44, No. 12, pp. 8263–68.  
2. Hasan, Md. Tanvir, Bhuiyan, Ashraful G., 
Yamamoto, Akio. (2008), Two dimensional 
electron gas in InN-based heterostructures: 
Effects of spontaneous and piezoelectric 
polarization, Solid-State Electronics,Vol. 52, 
No. 1, pp. 134-39, January 2008. 
3. Hasan, Md. Tanvir, G. Bhuiyan Ashraful, 
Properties of two dimensional electron gas 
(2DEG) in InGa (Al) N/InN-based HEMTs, 
submitted in Japan Journal of Applied Physics( 
unpublished). 
4. Kwon, Y., Pavlidis D., Brock, T.L, Striet, D.C. 
(1995), Experimental and Theoretical 
Characteristics of High Performance 
Pseudomorphic Double Heterojunction 
InAlAs/In0.7Ga0.3As/ InAlAs  HEMTs,IEEE 
Trans. Electron Devices,Vol.42,no.6,pp. 1017-
1025. 
5. Hasan, Md. Tanvir, Kaysir, Md. Rejvi, Islam, 
Md Sherajul, G. Bhuiyan, Ashraful , Islam, Md 
Rafiqul, Hasimoto, A., Yamamoto, Akio 
(2010),2DEG Properties in InGaN/InN/InGaN- 
based double channel HEMTs,Phys. Status 
Solidi C, Vol.7, No. 7-8, pp. 1997-2000. 
6. Ambacher, O., Majewski, J., Smart, C., Shealy, 
J.R. (2002), Pyroelectric properties of Al 
(In)GaN/GaN hetero and quantum well 
structure, Journal of Physics: Condens matter 
Vol. 14pp.3399-4334. 
7. Sacconi, F., Carlo, A. D., Lugli, P., Morkoc, H. 
(1997), Spontaneous polarization and 
piezoelectric constants of III-V nitrides, 
Vol.56, No.16, pp.R100244-7. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Page 494
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
A. S. M. Iftekhar Uddin,  
E-mail: horrorfan72@yahoo.com  
DESIGN & IMPLEMENTATION OF UP-CONVERTER ON FPGA 
HARDWARE WITH OFDM (TRANSMITTER & RECEIVER) SIGNAL 
 
 
 
A. S. M. Iftekhar Uddin 
Assistant Professor, Dept. of Electronics & Communication Engineering 
Sylhet International University, Shamimabad, Bagbari, Sylhet – 3100, Bangladesh 
 
 
With the rapid growth of digital communication in recent years, the need for high-speed data transmission 
has been increased. The mobile telecommunication industry faces the problem of providing the technology 
that be able to support a variety of services ranging from voice communication with a bit rate of a few kbps 
to wireless multimedia in which bit rate is up to 2 Mbps. Many systems have been proposed and OFDM 
system has gained much attention for its outstanding method. Among various implementation process of 
OFDM system into hardware Field-Programmable Gate Array (FPGA) has gained the best choice due to its 
fastest functionality and flexibility to the program design. An FPGA could be reprogrammed for new 
functions by a base station to meet future needs particularly when new design is going to fabricate into chip.  
This research is the continuation and improvement over the previous research entitled “Design of an OFDM 
Transmitter and Receiver using FPGA”. In this research I have used the previous method and added an 
additional up converter for mixing the OFDM output signals and pre-amplifier before the final amplify of 
the output signal and reverse process to get the original base band signal at the receiving terminal. This new 
scheme reveals that at a room temperature (400c) the transmission rate (speed) raised to a high value and the 
system requires fewer repeaters in the transmission procedure. At the same time I have used MAX2023 in 
this scheme which has reduced the overall size of the transmitter/receiver that also made the system easier 
and cost effective.  
 
Keyword: OFDM; FPGA; Up-converter; Transmission speed and Pre-amplification. 
 
1. INTRODUCTION 
 
Although OFDM was first developed in the 1960s, 
only in recent years, it has been recognized as an 
outstanding method for high-speed cellular data 
communication where its implementation relies on 
very high-speed digital signal processing. This 
method has only recently become available with 
reasonable prices versus performance of hardware 
implementation[2][3]. Since OFDM is carried out in 
the digital domain, there are several methods to 
implement the system. One of the methods to 
implement the system is using ASICs (Application 
Specific Integrated Circuit) which are the fastest, 
smallest and lowest power way to implement 
OFDM into hardware. The main problem using this 
method is inflexibility of design process involved 
and the longer time to market period for the 
designed chip.  Another method that can be used to 
implement OFDM is general purpose   
Microprocessor or Micro Controller which is highly 
programmable and flexible in term of changing the 
OFDM design into the system. The disadvantages 
of using this hardware are, it needs memory and 
other peripheral chips to support the operation [3][4]. 
Beside that, it uses the most power usage and 
memory space, and would be the slowest in term of 
time to produce the output compared to other 
hardware. Field-Programmable Gate Array (FPGA) 
is an example of VLSI circuit which consists of a 
“sea of NAND gates” whereby the function are 
customer provided in a “wire list”. This hardware is 
programmable and the designer has full control 
over the actual design implementation without the 
need (and delay) for any physical IC fabrication 
facility. An FPGA combines the speed, power, and 
density attributes of an ASIC with the 
programmability of a general purpose processor 
will give advantages to the OFDM system. An 
FPGA could be reprogrammed for new functions 
by a base station to meet future needs particularly 
when new design is going to fabricate into chip[9]. 
This will be the best choice for OFDM 
implementation since it gives flexibility to the 
program design besides the low cost hardware 
component compared to others. 
Page 495ISBN: 978-984-33-2140-4
  
2. BASIC PRINCIPLES AND 
GENERATION OF OFDM SIGNALS 
 
In the multipath environment, broadband 
communication systems suffer from frequency 
selective fading. OFDM is an attractive modulation 
scheme used in broadband wireless systems that 
encounter large delay spreads.  OFDM  avoids  
temporal  equalization altogether,  using  a  cyclic  
prefix  technique  with  a  small  penalty  in  
channel capacity. Where  Line-of-Sight  (LOS)  
cannot  be  achieved,  there is  likely  to  be  
significant multipath  dispersion,  which  could  
limit  the  maximum  data  rate.  Technologies like  
OFDM  are  probably  best  placed  to  overcome  
these,  allowing  nearly arbitrary data rates on 
dispersive channels. An OFDM signal consists of N 
subcarriers spaced by the frequency distance  f  
thus,  the  total  system  bandwidth  B  is  divided  
into  N  equidistant  subchannels. On each 
subcarrier, the symbol duration Ts = 1/ f is N times 
as large as in the case of a single carrier 
transmission system covering the same bandwidth.   
 
To implement the OFDM transmission scheme, the 
message signal must first be digitally modulated. 
The carrier is then split into lower-frequency sub-
carriers that are orthogonal to one another using a 
scheme such as BPSK, QPSK, or some form of 
QAM (16QAM or 64QAM for example). To 
convert the sub-carriers to a set of orthogonal 
signals, the data is first combined into frames of a 
suitable size for an FFT or IFFT where The Fast 
Fourier Transforms (FFT) is used to calculate the 
spectral content of the signal and the Inverse Fast 
Fourier Transforms (IFFT) performs the reciprocal 
operation[1]. 
 
3. FIELD PROGRAMMABLE GATE 
ARRAYS (FPGA) 
 
In order to implement large circuits, it is 
convenient to use a type of chip that has a large 
logic capacity. A field-programmable gate arrays 
(FPGA) is a programmable logic device that 
supports implementations of relatively large 
logic circuits contains three main types of 
resources: logic blocks, I/O blocks for connecting 
to the pins of the package, and interconnection 
wires and switches. The logic blocks are arranged 
in a two-dimensional array, and the 
interconnection wires are organized as horizontal 
and vertical routing channels between rows and 
columns of logic blocks. The routing channels 
contain wires and programmable switches that 
allow the logic blocks to be interconnected in 
many ways. FPGA can be used to implement logic 
circuits of more than a few hundred thousand 
equivalent gates in size[7][9].  Equivalent gates is a 
way to quantify a circuit’s size by assuming that 
the circuit is to be built using only simple logic 
gates and then estimate how many of these gates are 
needed. 
 
When a circuit is implemented in an FPGA, the 
logic blocks are programmed to realize the 
necessary functions and the routing channels are 
programmed to make the required interconnections 
between logic blocks. The FPGA device is 
configured by using the in-system programming 
(ISP) method, which means that the FPGA can be 
programmed while the chip is still attached to its 
circuit board. The storage cells in the LUTs in an 
FPGA are volatile, which means that they lose 
their stored contents whenever the power supply 
for the chip is turned off. Hence the FPGA has to 
be programmed every time power is applied. Of 
this, a small memory chip that holds its data 
permanently, called a programmable read-only 
memory (PROM) is included on the circuit board 
that houses the FPGA. The storage cells in the 
FPGA are loaded automatically from the PROM 
when power is applied to the chips. 
 
4. FPGA IMPLEMENTATION 
 
The base band signals from FPGA are sent to a 
D/A converter. After the reconstruction filtering, 
the D/A output signals are provided at the input 
of the I/Q modulator (Maxim MAX2023). This 
mixing stage is used to shift the baseband signal to 
an IF at 1.95 GHz. The selected I/Q-modulator 
supports IF- frequencies between 1.5 to 2.3GHz. 
The core devices of the second up conversion 
stage are the mixers (Mini- Circuits ZX05-
42MH) and the preamplifiers (Hittite 
HMC409LP4). The frequency shifted 2nd stage 
input signal is filtered to suppress all out-of-band 
signal components and scaled by a step-attenuator 
and then transmit. 
 
To generate low distortion local oscillator signals 
for the mixers, the outputs of the two LO 
generators were boosted by amplifiers and low 
pass filtered to minimize the second and third 
order harmonic distortion. After the amplifiers’ 
output signal is reduced to the desired magnitude it 
is applied to the input of the receiver branch. Here, 
the down conversion to the IF frequency is 
performed. The mixer output signal is then filtered 
to suppress all undesired signal components and 
amplified to the required input power level of the 
I/Q demodulator (also Maxim MAX2023). The 
signals provided by the demodulator are filtered 
before they are fed into the A/D converters. These 
devices show the same characteristics as the 
corresponding D/A converter. To assure a fixed 
phase relationship between the different 
Page 496
  
frequencies used in the test-bench the local 
oscillators were locked to the same 10 MHz 
reference clock. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
One last thing to say about the assembly already 
shown, is that the use of two signal generators, one 
at 1.95 GHz and the other one at 1.55 GHz, is not 
due to a limitation of the signal generators but it is 
because a limitation of the electronics used in the 
signal amplifiers, that is why two signal generators 
has been used and not only one at the single 
frequency of 3.5 GHz. The use of the signal 
generator must begin just when the output signal 
from the FPGA is stabilized; the reason of this is 
because before the stabilization of the signal some 
peaks are generated, and those peaks can damage 
the devices. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 2: Modulator single-sideband 
suppression vs LO frequency 
 
 
Fig. 3: Modulator output IP3 vs LO 
frequency 
PARAMETER CONDITION 
MODULATOR VCC = + 4.75V to + 5.25V, fIQ = 1 MHz, PLO = 0dBm, TC = +250 C 
Base band input 
differential impedance fI/Q = 1 MHz 55 Ω 
RF output IP3 
Pout = 0 dBm fLO = 1750 MHz + 24.2 dBm 
fBB1 = 1.8 MHz fLO = 1850 MHz + 23.5 dBm 
fBB2 = 1.9 MHz fLO = 1950 MHz + 22.0 dBm 
RF output IP2 Pout = 0 dBm + 61 dBm fBB1 = 1.8 MHz, fBB2 = 1.9 MHz, fLO = 1850 MHz 
Output power variation 
over temperature Pout = + 5.6 dBm, fI/Q = 100 kHz, TC = - 40
0C to + 850C 0.25 dB 
RF return loss fLO = 1850 MHz 17 dB 
Output noise density - 174 dBm/Hz 
Output noise floor Pout = 0 dBm - 165 dBm/Hz 
DEMODULATOR VCC = +4.75V to +5.25V, fIO = 1850 MHz, PRF = PLO = 0dBm, fBB = 1MHz, TC = +250 C 
RF input frequency 1500 – 2300 MHz 
Conversion loss fBB = 25 MHz 9.5 dB 
Noise figure 9.6 dB 
I/Q gain mismatch fBB = 1 MHz 0.025 dB 
I/Q phase mismatch fBB = 1 MHz 0.56 degrees 
 
Table 1: Electrical properties of MAX2023 (Modulator/Demodulator) 
Fig. 1: Proposed block diagram of up conversion on FPGA. 
 
Page 497
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 7 and 8 shows the improvement of 54 Mbps 
output OFDM signal at 3.5 GHz range providing 
31dB gain and +32.5 dBm of saturated power with 
an error vector magnitude of 2%. Basically this 54 
Mbps signal provides +22dBm of output power. 
 
5. CONCLUSION 
 
The proposed scheme of up converting the 3.5 GHz 
baseband OFDM signal from FPGA where the 
MAX2023 modulator/demodulator is composed of 
a pair of matched double-balanced passive mixers 
and a balun has increased the transmission speed of 
about 31 dB and at the same time the overall size of 
the Tx/Rx system. Though the transmission speed 
has raised, the complexity remain unchanged which 
has made the system easier and cost effective. As 
the transmission speed has raised to a high value, it 
requires fewer repeater in the transmission 
procedure. This research is modeled on the basis of 
mathematical analysis and the output is calculated 
through simulation of hardware and for this reason 
the output simulation graph showed some fading 
effect and some mismatch. 
 
REFERENCES 
 
1. E. C. Ifeachor and B. W. Jervis, Digital Signal 
Processing, A Practical Approach, Prentice Hall, 
2002. 
 
2. K.A. Vinger, J. Torresen, “Implementing 
evolution of FIR‐filters efficiently in an 
FPGA.” Proceeding, NASA/DoD Conference on 
 
Fig. 4: Modulator output IP2 vs LO 
frequency 
 
Fig. 5: Demodulator intput IP3 vs LO 
frequency 
 
Fig. 6: Demodulator I/Q imbalance  vs LO 
frequency 
Fig. 7: Gain, Power & Quiescent supply 
current vs Vdp @ 3.5 GHz 
 
 
Fig. 8: EVM vs gain @ 3.5 GHz OFDM  
                       54 Mbps signal 
+32.5 dBm 
+22 dBm 
Page 498
  
Evolvable Hardware, 9‐11 July 2003. Pages: 26 
– 29. 
 
3. Xilinx Inc., “Virtex‐II Pro™ Platform FPGAs: 
Functional Description,” DS083‐2 (v3.0), 
December 10, 2003. 
 
4. Sudhakar Yalamanchili, Introductory VHDL, 
From Simulation to Synthesis, Prentice Hall, 
2001. 
 
5. Liang, R. Tessier, O. Mencer, “Floating point 
unit generation and evaluation for FPGAs,” 
Annual IEEE Symposium on 
Field‐Programmable Custom Computing 
Machines, 2003. FCCM 2003. 11th, 9‐11 April 
2003, Pages:185 – 194. 
 
6. K. Wiatr, “Implementation of multipliers in 
FPGA structures,” 2001, International 
Symposium on Quality Electronic Design, 
26‐28 March 2001, Pages: 415 – 420. 
 
7. M. Karlsson, M. Vesterbacka, L. Wanhammar, 
“Design and implementation of a complex 
multiplier using distributed arithmetic,” 
Workshop on Signal Processing Systems, 1997. 
SIPS 97 - Design and Implementation, 1997 
IEEE, 3‐5 Nov. 1997 Pages: 222 – 231. 
 
8. S. Vassiliadis, E.M. Schwarz, B.M. Sung, 
“Hard‐wired multipliers with encoded partial 
products” IEEE Transactions on Computers, 
Volume: 40, Issue: 11, Nov. 1991 Pages: 1181 – 
1197. 
 
9. R.J. Andraka and A. Berkun, “FPGAs Make 
Radar Signal Processor on a Chip a Reality,” 
Proceedings, 33rd Asilomar Conference on 
Signals, Systems and Computers, October 
24‐27, 1999, Monterey, CA. 
 
Page 499
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh   
* Corresponding Author: Md. Forhad. Zaman,  
   E-mail: m.fzaman@yahoo.com 
 
DESIGN AND FABRICATION OF A DIGITAL POWER FACTOR METER 
Md Forhad Zaman1, Md Selim Hossain2 Shahadute Hossain3, Khorshed Alam4 
Department of Electrical and Electronic Engineering 
Rajsshahi University of engineering and Technology,  
Rajshahi – 6204, Bangladesh 
1m.fzaman@yahoo.com 2Selim_hossain@yahoo.com 
 
Abstract- This paper is being to design a reliable digital power factor meter and fabricate the designed digital 
power factor meter. The circuit is used only integrated circuit (IC’s) and liquid crystal display (LCD) to 
display the output of the meter. The second part of the paper describes its performance and compare with the 
electromechanical type meter and conventional type meter. And finally analysis the data results of the meter 
and discuss the error and limitation of the proposed meter. It has been seen that the reading of conventional 
power factor meter and designed power factor meter are close to each other at high power factor but at low 
power factor, the difference in reading between two meters is being increase. 
Keywords- Microcontroller, Analog and Digital power factor, Error and limitation. 
1. INTRODUCTION 
In the modern world, the electrical energy is almost 
exclusively generated, transmitted and distributed 
in the form of alternating current. Practically, there 
is generally a phase difference between voltage and 
current. Hence, the question of power factor (phase 
difference between voltage and current) is 
immediately comes into picture. A low power 
factor is highly undesirable as it causes an increase 
in the current, resulting in additional losses of 
reactive power in all the elements of the power 
system. In order to ensure most favorable 
conditions for a supply system from engineering 
and economical point of view, it is important to 
have power factor as close as possible. Therefore, a 
continuous monitoring is always needed to set the 
power factor to a desired value. [1] 
In this paper, a digital power factor meter was 
designed by a very simple logic, that that provides 
the operating power factor which is displayed by a 
liquid crystal display (LCD). It must be easier than 
an analog meter to understand, which is the most 
important of the fabricated power factor meter. This  
 
 
power factor meter can be used for both single 
phase and three phase supply .The logic is very 
simple and the cost of the power factor meter is 
desirable.  
 Digital power factor meter displays measurements 
of power factor as discrete numerals rather than 
pointer deflection on continuous scale that used in 
electromechanical meter. A digital meter reduces 
operator training, measurement error and possible 
instrument damage through overload. [2] 
There are some significant advantages than analog 
meter 
 Reduces human reading and interpolation error. 
 Eliminate parallax error. 
 Increase reading speed. 
 Higher order of accuracy than analog system. 
 Digital lag or lead information. 
2. BLOCK DIAGRAM 
 
 
 
 
 
 
 
 
Fig.. 1 Block Diagram representation of proposed 
configuration 
Page 500ISBN: 978-984-33-2140-4
D7   D6    D5   D4     E   RS
Quad 
comparator
LM339
Microcontroller
ATmega32
+BL
Vdd
Vss
-BL
V0
R/W
211116x2
A digital power factor meter was designed using 
microcontroller in which a computer program was 
written to execute XOR operation of two rectangular 
waveforms, to convert power factor angle into 
power factor and to display the power factor by 
LCD display with lag or lead information. The 
rectangular waveform is the output of a quad 
comparator which compare the voltage and current 
waveform of a load under operating condition. The 
current waveform was taken using current 
transformer.   The function of the voltage waveform 
is to collect the wave shape of voltage across the 
load under operating condition, which is fed to a 
step down transformer to reduce the operating 
voltage.  
The function of the quad comparator is to compare 
both the voltage waveform and current waveform 
separately. The output of this quad comparator is to 
be feed into the microcontroller. The quad 
comparator has four comparators. Thus, it can 
compare four waveforms at a time separately.  
 A microcontroller “ ATmega32” is used, in which a 
computer program to be written to execute XOR 
operation of two rectangular waveforms, to convert 
power factor angle into power factor and to display 
the power factor by LCD display in the numeric 
form.[3]. 
A liquid crystal display (LCD) device “YM1602C” 
is used by which the output of the microcontroller  
(resultant power factor and lagging leading 
information) is displayed. 
3. CONNECTION DIAGRAM 
This device consist of four independent precision 
voltage comparators with an offset voltage 
specifications as low as 2mV max for LM33. This 
comparator was designed specifically to operate 
from a single power supply over a wide range of 
voltages. Operation from split power supplies is also 
possible. This comparator also has a unique 
characteristic in that the input common-mode 
voltage range includes ground even though operated 
from a single power supply voltage. 
  
 kRRRR 1,10 4321
 
 
 
 
 
  
 
 
 
 
 
 
 
 
 
 
 
Fig.. 2 Complete circuit diagram of the designed power factor meter 
  
 
 
 
 
 
 
  
Page 501
4. OPERATING PRINCIPLE 
 
In alternating current system, there is a phase 
difference between voltage and current, which 
always exists. The cosine of the angle between 
the voltage and current in an a.c circuit is known 
as power factor (p.f). [3][4]. The quad comparator 
used in the project takes the voltage and current 
wave shape of a load under the operating 
condition to provide two rectangular wave forms 
by comparing the wave shape separately. Then 
the XOR operation of the two outputs of the quad 
comparator is done by, which gives the power 
factor angle. The execution of XOR operation 
and the conversion of power factor angle into the 
power factor are done by a computer program in 
the used microcontroller. Finally, the measured 
power factor is displayed in digital form by the 
LCD display. Fig: (art-4.3) denotes the graphical 
representation of operation. Fig- 4.9 shows the 
operation of the digital power factor meter. [5] 
 
 
 
 
 
 
 
 
 
 
 
6. ERROR ANALYSIS 
In this paper, it has used a current transformer 
and voltage transformer. The first one deals with 
phase error and ratio error [8]. The current 
transformer used during the experiment has a 
negligible ratio error and that was considerable. 
But the phase error has a great effect on our 
project result. Phase error means, shift in phase 
between primary and secondary currents. The 
figure 4 shows the Phase shift between primary 
and secondary of used CT is actual Pf is 0.952 
where the designed power factor meter reading 
was 0.975. 
 
 
 
 
 
 
Fig.. 3 Operation of the designed digital power 
factor meter 
5. RESULT AND DISCUSSION 
The designed power factor meter was tested 
several times. It was done a simple R-L series 
circuit to test the performance of the designed 
meter [6][7]. A Conventional electromechanical 
power factor meter was also connected with the 
testing circuit so that it can compare the reading 
to two power factor meters.  
The reading was taken by varying the value of 
inductance and resistance. Table 5.1 shows 
different reading of two power factor meter and 
reading of p.f using watt meter, voltmeter& 
ammeter method. 
    
 
 
 
Fig. 4 Phase shift between primary and secondary 
of CT 
S.L 
No. 
Reading of 
the 
fabricated 
power  
factor 
meter 
Reading of 
the 
conventional 
power factor 
meter 
Reading of 
p.f using 
wattmeter, 
voltmeter& 
ammeter 
method. 
1 0.998 0.985 0.970 
2 0.975 0.952 0.936 
3 0.927 0.903 0.921 
4 0.890 0.871 0.884 
5 0.851 0 .847 0.847 
6 0.813 0.792 0.802 
7 0.795 0.670 0.783 
8 0.742 0.528 0.712 
9 0.648 0.483 0.625 
Current wave shape at primary of CT Current wave shape at secondary of CT 
Page 502
7. CONCLUSION 
The objective of our project was to design a 
reliable digital power factor meter. From the data 
table it is seen that the reading of conventional 
power factor meter and designed power factor 
meter are close to each other at high power factor, 
nearly from 0.851 to 1.00. As the actual power 
factor decrease, the difference in reading between 
two meters is increases. The reason is that, the 
phase error of used CT plays a bad role there. It is 
seen that, the phase shift between primary and 
secondary of CT varies non-linearly with the 
variation of actual power factor. That’s why the 
designed power factor meter does not give actual 
output. During the experiment it could not 
remove this error but the error was detected. So 
the result is that, it is partially successful in 
completing the project. By minimizing the error 
properly we can get a reliable digital power factor 
meter. The logic used to design the power factor 
meter is very simple. It will give the power factor 
by digital display. So it must be very easy to read. 
The designed digital power factor meter can be 
used for both single phase and three phase 
system. The components used in the project are 
available in the market and has considerable cost. 
8. LIMITATION 
o Maximum current at the secondary of CT 
must be less than 3.3Amp. 
o This fabricated power factor is capable of 
measuring the power factor within a range of 
.684 to .998 with more precisely. 
9. REFERENCES 
1. V.K. Mehta & Rohit Mehta, “Principles of 
power system”, First multicolor edition. 
2. A.K Sawhney,” Electrical and Electronic 
Measurements and Instrumentation” , fourth 
edition. 
3. Robert L. Boylestad, “Introductory circuit 
analysis”, Tenth edition.  
4. Rosenblatt & Friedman,” Direct and 
alternating current machinery”, second 
edition. 
5. Ronald J. Tocci & Neal S. Widmer, “Digital 
system”, Eighth edition 
6. Robert L. Boylestad & Louis Nashelsky 
,”Electronic devices and circuit theory”, 
ninth edition. 
7. V.K. Mehta & Rohit Mehta,” Principles of 
electronics”, ninth edition. 
8. B.L. Theraja & A.K. Theraja,” A text book 
of electrical technology”, First multicolor 
edition. 
9. Rafael M. Inigo, Member, IEEE, “An 
Electronic Energy and Average Power-
Factor Meter with Controllable Nonuniform 
Rate” IEEE transaction on industrial 
Electronics and control instrumentation, Vol. 
IECI-27, No. 4, NOV. 1980. 
10. Kadhim N. Kadhim, Majid A. H. Abdul-
Karim,” Digital power factor meter based on 
digital frequency divider”, International 
Journal of Electronics, Volume 65, Issue 1 
July 1988 , pages 111 – 116.  
 
 
Page 503
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Muhibul Haque Bhuyan,  
E-mail: muhibulhb@gmail.com 
DESIGN AND IMPLEMENTATION OF A MICROCONTROLLER 
BASED ELEVATOR CONTROL SYSTEMS 
 
 
1Muhibul Haque Bhuyan*, 2Md. Maidul Haque, 2M. Abdur Rauf 
and 2Md. Mazharul Islam Khan 
1Department of Electrical and Electronic Engineering 
Daffodil International University, Shukrabad, Dhaka, Bangladesh 
2Department of Electrical and Computer Engineering 
Presidency University, Banani, Dhaka, Bangladesh 
E-mail: muhibulhb@gmail.com, opu_bd2@yahoo.com 
 
 
Abstract 
In this paper, we have designed and implemented a prototype elevator and its control systems using a very 
low cost microcontroller (PIC16F84) based circuit. Thus the conventional analog control circuit has been 
replaced. The elevator is operated by using DC motors and gears along with timing belt. Forward and 
reverse direction of motion of the DC motor is obtained by using a MOSFET bridge. An assembly language 
program has to be developed for the microcontroller for implementing different logic operations, such as, 
floor selection, sensor signal detection, alarm signal transmission and reception etc. Different mechanical 
parts, such as, cabin, doors, gears, guide, timing belt etc. have also been designed for the prototype system. 
Before implementation of the system, we have simulated the microcontroller based control circuit using 
‘Proteus’ software. It was found that the simulation results are satisfactory and practical systems work very 
well. We also expect that this will save our valuable foreign currency if we go for practical implementation. 
 
Key words: Microcontroller, DC motor, elevator, gear, control circuit. 
 
1. INTRODUCTION 
 
An elevator (or lift in British English) is vertical 
transport equipment that efficiently moves people 
or goods between floors or levels of a building [1]. 
At present, many high rise buildings are being built 
in Bangladesh to be used as apartments, offices, 
shopping malls, hospitals etc. So, all these high rise 
buildings require elevator. But these are very costly 
because they are being imported from different 
foreign countries. 
Elevators are generally powered by electric motors 
that either drive traction cables and counterweight 
systems like a hoist, or pump hydraulic fluid to 
raise a cylindrical piston like a jack. So, these 
motors need to be controlled by sophisticated 
control circuits. If the costs of these control circuits 
and other parts can be reduced then the overall 
costs of the elevator will be reduced. In this work, 
we have developed a low cost elevator system 
using microcontroller based control circuit. 
Because microcontroller has emerged as one of the 
low cost controller IC and many works have been 
found in the literatures using microcontroller for 
minimizing the cost [2-5]. The whole system and 
the controller circuit have been tested for various 
conditions of the elevator operation and it has been 
observed that the system works very well. 
 
2. HARDWARE DESCRIPTION 
 
The overall system architecture is shown in Fig. 1 
as a block diagram. The circuit configuration is 
each component is briefly described in this section.  
The 8-bit PIC microcontroller IC 16F877 was  
chosen  to obtain  the  analog  data  from  the  
sensor circuit  in  transmitting to control the DC 
motors. This microcontroller has a 25 MHz 
processor (the current compiler runs the processor 
at 20  MHz),  33  input/output  (I/O)  pins, (8k*14 
words) of Enhanced FLASH  program  memory, 
(386*8bytes)  of  RAM,  (256*8bytes)  of  data  
EEPROM.  The PIC  does  not  have  an  operating  
system  and  simply  runs  the program  in  its  
memory  when  it  is  turned  on.  This PIC 
microcontroller has several hardware features that 
are very useful for use in a UAV and simplify the 
interfacing of sensors and  motors with the  
microcontroller, such as an analog to digital  
converter  (ADC), interrupts, timers, and 
Page 504
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
  
capture/compare/pulse width modulation (CCP) 
channels. One microcontroller circuit produces the 
required signals for controlling the levels and 
another microcontroller produces the control 
signals for the car. For each floor, one board is 
needed and for car control each level requires one 
such board. 
 
 
Fig. 1 Block diagram of microcontroller based 
elevator control system 
 
Our designed system has the various electrical and 
mechanical parts. The main components are the two 
DC motors with gear, one motor for the car 
operation and the other motor for the door 
open/close. Besides, motors’ driver circuits have to 
be designed. There are various sensors for the 
transmitter (Tx) and the receiver (Rx) circuit, one 
microcontroller (PIC16F84) circuit. Power supplies 
for various controller circuit and motors have also 
been designed. Since this system is a prototype 
system, therefore, only a +12V DC power supply 
was required. 
 
3. SOFTWARE DEVELOPMENT 
 
The program is developed for the microcontroller 
using the MPLAB software in assembly language 
and then debugged and edited as required. Finally 
the hex codes are generated to be loaded into the 
microcontroller by the TOP2049 Universal 
Programmer using the TOPWIN software [8]. 
MPLAB is an Integrated Development 
Environment (IDE) tool for this task. The 
architecture and flow chart of the developed 
program are shown in Figs. 2-4. The clock 
frequency used for this program is set at 4 MHz.  
The program is written in assembly language. A 
typical assembly language program consists of 
assembler directives, sub-routines (if needed) and 
the main program code.  
Assembler directives are a collection of commands 
that tell the assembler such things as the type of 
microcontroller being used, its clock speed, etc. 
They also allow names to be used for memory 
locations, ports and registers for making the 
program more readable [8].  
In Figs. 3-4, we have shown two flow charts [9], 
one for the level board microcontroller’s and the 
other for the car board microcontroller’s. The flow 
charts are self explanatory. 
 
 
Fig. 2 Program architecture 
 
 
Fig. 3 Flow chart of the program for level board 
 
 
Fig. 4 Flow chart of the program for car board 
 
Page 505
  
4. SYSTEM DESCRIPTION 
 
At first, we develop the motor control circuit as 
shown in Fig. 5. This circuit uses opto-couplers and 
relays to control the DC motor’s operation. The 
circuit is designed in such a way so that the motor 
can be driven in forward or reverse direction. 
 
 
Fig. 5 Motor control circuit diagram 
 
Then we design the sensor circuit for the car board 
and level board as shown in Fig. 6. In this circuit, 
the photo diode transmits the signal and the 
phototransistor receives it. Then we develop the 
microcontroller circuit to integrate these circuits. 
The complete hardware circuit is shown in Fig. 7. 
 
 
Fig. 6 Sensor circuit diagram 
 
 
Fig. 6 Complete hardware circuit without 
microcontroller circuit 
Then we have to design the mechanical parts of the 
system. Of them, the door control panel is shown in 
Fig. 8. This is a wooden frame where different 
switch boards and LEDs are connected. The 
photograph of the complete system is shown in Fig. 
9. It is a 3-storied prototype elevator model. 
 
 
Fig. 8 Door control panel 
 
 
Fig. 9 The complete system 
 
5. CONCLUSIONS 
 
In this work, we have designed and implemented a 
prototype elevator and its control systems using a 
very low cost microcontroller based circuit. Thus 
the conventional analog control circuit has been 
replaced. The elevator is operated by using DC 
motors and gears along with timing belt. Forward 
and reverse direction of motion of the DC motor is 
obtained by using a MOSFET bridge. An assembly 
language program has been developed for the 
microcontroller for implementing different logic 
operations. Different mechanical parts have also 
been designed for the prototype system. Before 
implementation of the system, we have simulated 
the control circuit. It was found that the simulation 
results are satisfactory and practical systems work 
very well. We also expect that this will save our 
valuable foreign currency if we go for practical 
implementation. As future scopes, the main 
controller can be re-designed in such a way so that 
a three phase induction motor can be operated 
through a speed control circuit.  
Page 506
  
REFERENCES 
 
1. http://en.wikipedia.org/wiki/Elevator. 
2. Mahbubul Hoq, Yasmeen Mawla, Mohammod 
A. S. Haque and Saleh M. Jahangir, “Design 
and Development of a Microcontroller Based 
Traffic Light Control System,” Proceedings of 
BES Conference, Dhaka, Bangladesh, April 
2003, pp. 122-126. 
3. Muhibul Haque Bhuyan, Md. Anayet Rabby, 
Md. Anwar Parvez and Md. Mostayanul Gofur, 
“Microcontroller Based Display System 
Design using LED Array,” Proceedings of the 
Conference on Engineering Research, 
Innovation and Education (CERIE) held at 
Shahjalal University of Science and 
Technology, Sylhet, Bangladesh, 11-13 
January 2010, pp. 417-420. 
4. Muhibul Haque Bhuyan, Md. Anayet Rabby 
and Md. Mostayanul Gofur Tarik, 
“Microcontroller based Automatic Traffic 
Light Control System Design,” Proceedings of 
the National Conference on Electronics and 
Telecommunications for Digital Bangladesh 
organized by the Bangladesh Electronics 
Society, Dhaka, Bangladesh, 2-3 June 2010, 
pp. 139-142. 
5. Md. Lutfor Rahman and Muhibul Haque 
Bhuyan, “Linearization of Voltage-Controlled 
Oscillator by Microcontroller Based PLL 
Frequency Synthesizer,” Proceedings of the 
Conference on Engineering Research, 
Innovation and Education (CERIE) held at 
Shahjalal University of Science and 
Technology, Sylhet, Bangladesh, 11-13 
January 2011, accepted in this conference. 
6. Thomas E. Kissel, “Industrial Electronics –
Applications for Programmable Controllers, 
Instrumentation and Process Control, and 
Electrical Machines and Motor Controls,” 
Prentice-Hall of India Pvt. Ltd., 3rd Edition, 
India, 2005. 
7. Charles A. Schuler and William L. McNamee, 
“Industrial Electronics and Robotics,” 
McGraw-Hill Book Co. International Edition, 
Singapore, 1986. 
8. Microchip Technology, Inc., USA, 2001,  
PIC16F877A  Data  Sheet, 
www.microchip.com 
9. D. V. Hall, “Microprocessors and Interfacing: 
Programming and Hardware,” McGraw-Hill 
International, 1997. 
 
Page 507
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: R. R. Mahmud,  
E-mail: r.r.mahmud@gmail.com  
DESIGN AND IMPLEMENTATION OF A MICROCONTROLLER  
BASED LIQUID LEVEL CONTROL SYSTEM  
 
 
M. S. Hossain, R. R. Mahmud*, T. Ahmed
 
and
 
M. Shahed
  
 
Dept. of EEE, Ahsanullah University of Science and Technology (AUST), Bangladesh  
Dept. of EEE, Rajshahi University of Engineering and Technology (RUET) 
 
 
This paper presents design and implementation of a microcontroller based automatic liquid level control 
system. The design part contains one hardware portion (motor, transistor, resistors, relay, liquid tank, dc 
voltage source, ac voltage source and coupling circuit) and another software portion (microcontroller 
operating program). The liquid level control system is very essential for factory, laboratory, house and other 
places where liquid level controlling is essential. The conventional liquid level control systems which are not 
programming based that can’t sense, operate and display for the little amount fluctuation of liquid level. But 
the performance of our programming based propose liquid level control system can handle and operate very 
smoothly and display very little amount of variation and fluctuation of liquid level compare with the 
conventional system. Again our research device is very cheap to implement compare to others. A detail 
design procedure including block diagram, circuit design, algorithm, flow chart, description of the 
microcontroller and the practical outputs are presented in this paper. 
 
Key words: Liquid Level Detector; Microcontroller; Programming, Automatic Controlling Circuit.  
 
1. INTRODUCTION 
 
Liquid level control systems play important role 
in industrial application such as in food processing, 
beverage, dairy, filtration, effluent treatment, 
Pharmaceutical industry, water purification system, 
Industrial chemical processing and spray coating. 
So that the requirement of industrial manufacturing 
processes, the liquid level control system is applied 
to many processing fields. Many efforts [1-10] have 
been given in this field by a number of researchers. 
Our topic is different from the other researchers 
who have done their research on the same area. To 
show in difference between our findings and others, 
we would like to explain their researches. The 
principle of Proportional Integral Differentiator 
(PID) is that the action of the controller is 
calculated by multiplying a constant factor with the 
error, the integral of the error and the derivative of 
the error [1]. Ziegler- Nichols has developed a well 
known design methods to provide a closed-loop 
response with a quarter-decay ratio [2]. A simple PI 
controller design method has been proposed by 
Wang and Shao that achieves high performance for 
a wide range of linear self-regulating processes [3]. 
Ari Ingimundarson and Tore Hagglund have 
compared the performance of PI, PID and dead-
time compensating controllers for level controlling 
[4]. A design method for robust PID controller for 
liquid level to address the model uncertainty has 
been proposed by Ming Ge et al [5]. Presently, it is 
becoming increasingly advantages in carry out 
information processing and control functions using 
digitally methods for controlling level [6]. It is well 
known fact that the digital control system can offer 
high accuracy and high-speed response [7]. These 
are the reasons that cause strong motivation to 
design and implementation of the automatic control 
system based on the digital controller. Recently, a 
variable structure control for liquid level in the 
discrete-time domain has received much the 
attention [8-10]. These are the reasons that cause 
strong motivation to design and implement the 
automatic control system based on the digital 
microcontroller. So from the above discussions so 
far as we know that our designed liquid controlled 
system can handle and operate very smoothly, 
accurately and display very little amount of 
variation and fluctuation of liquid which has not 
explained to the other papers. 
 
2. BLOCK DIAGRAM OF LIQUID 
LEVEL CONTROL SYSTEM 
 
The general block diagram contains liquid level 
detector circuit, liquid tank, coupling circuit, 
Page 508ISBN: 978-984-33-2140-4
  
automatic control unit, microcontroller and motor. 
The design part contains one hardware portion 
(motor, transistor, resistors, relay, liquid tank, dc 
voltage source, ac voltage source, coupling circuit 
and automatic control unit) and another software 
portion (microcontroller and microcontroller 
operating program). 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 1: Block diagram of a microcontroller based 
automatic liquid level control system 
 
3. HARDWARE PORTION 
 
It is a device which automatically controls the 
supply of liquid to avoid the dissipation of liquid. 
DC motor is used mainly to control the liquid level 
in the device. Motor will active when liquid is 
under the desired level and out of order when liquid 
is over the desired level. Application of the 
transducer is used here for sensing the height of 
liquid in tank. Using the liquid level, the motor 
pump is either ON or OFF condition. The complete 
circuit diagram of the project is given below. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 2: Schematic circuit diagram of automatic 
liquid level control system 
 
 
Fig. 3: Interface between microcontroller and 
personal computer for burning 
 
4. SOFTWARE PORTION 
 
Microcontroller is a programmable device which 
contains a microprocessor, memory as same as a 
single chip computer. As microcontroller is a low 
cost programmable device, it is used in the 
automatic control application like robot, microwave 
oven, digital watch, mobile phone, electronic 
display and some conditions where circuit is 
difficult. 
 
 
 
Fig. 4: Internal block of a microcontroller 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 5: Pin configuration of LCD 
 
 
Page 509
  
 
 
Fig. 6: PCB layout of the total system 
 
4.1 Flow chart of the microcontroller 
program   
Here the sensor senses the height of the liquid level. 
If the level is below the desired level then the motor 
is started, otherwise off. The same work is done 
continuously until the power supply is on. When 
the power supply is off then the program is ended. 
 
 
 
Fig. 7: Flow chart of for the program of the 
microcontroller based automatic liquid supply level 
control system 
 
5. IMPLEMENTATION OF THE 
AUTOMATIC LIQUID LEVEL 
CONTROL CIRCUIT 
 
Required components are collected from the local 
market and connected on the project board 
according to the circuit diagram and performance of 
the total system is tested and our desired result is 
obtained. 
 
 
(a) 
 
 
(b) 
 
Fig. 8: Implemented circuit of the microcontroller 
based automatic liquid level control system 
 
6. RESULTS 
 
The overall performance of the task is very good & 
the response is very fast. This system also stores the 
information of motor state (that is the ON or OFF 
state).This information may be used during 
electricity disturbance period. This system is not 
affected by temperature or other factor. The Upper 
level of the water tank =10ml and the Lower level 
of the water tank =0ml are fixed for our desired 
level. 
 
Table1 
Measuring test result on the basis of the liquid level 
in the tank 
 
Page 510
  
7. CONCLUSIONS 
 
The control circuit was constructed on a project 
board and performance was tasted in the laboratory.  
The proposed automatic liquid level control system 
was worked properly. It always keeps the liquid 
tank filled by liquid. A single drop of liquid is not 
wasted. DC motor is turn on when the liquid level 
is gone below the desired mark of the liquid tank. If 
the power supply is off for some hours or for some 
days then the system is off, otherwise it is always 
on. It is very reliable for non-stopping liquid 
supply. Also the components are available in the 
local market and very cheap. So this 
microcontroller based liquid level control system is 
very essential, reliable and efficient. 
 
 
REFERENCES 
 
1. Luyben, W. L., (1990) Process modeling, 
simulation and control for chemical engineers, 
Second Edition, Tata McGraw Hill USA. 
2. Zeigler, J. G. and Nichols, N. B., (1942) 
Optimum Settings for automatic controllers, 
Trans. ASME, 64, pp 759 –768.  
3. Wang, Y. G., and Shao, H. H., (2000) Optimal 
tuning for PI controller, Automatic, 36, pp 147-
152. 
4. Ingimundarson, A. and Hagglund, T., (2002), 
Performance comparison between pid and 
dead-time compensating controllers, J. Proc. 
Cont, 12, pp 887 – 895. 
5. Ge, M., Chiu, M. S. and Wang, Q. G., (2002) 
Robust PID controller design via LMI 
approach, J. Proc. Cont, 12, pp 3-13. 
6. Rodd, M. G. and Deravi, F., (1989), 
Communication systems for industrial 
automation, Prentice Hall. 
7. Kuo, B. C., (1980), Digital control systems, 
Holt Saunders International Editions. 
8. Gao, W., Wang, Y. and Homaifa, (1995), 
Discrete time variable structure control 
systems, IEEE Transactions on Industrial 
Electronics., 42(2), pp 117-122. 
9. Pan, Y. and Furuta, K., (1997), Discrete-time 
VSS control design, International Journal of 
Robust and Nonlinear Control, 7, pp 373-386. 
10.  Hung, J. Gao, W. and Hung, J. C., (1993), 
Variable structure control: a survey, IEEE 
Transactions on Industrial Electronics, 40(1), 
pp 2-22. 
11. Barnett, R. H. (1995), The 8051 Family of 
Microcontrollers, Prentice Hall. 
12. Motorola Sensor Device, Third Edition 
Motorola Inc. (TMOS), 1995. 
13. Anandanatarajan, R. and Chidambaram, M., 
(2005), Experimental Evaluation of a 
Controller Using Variable Transformation on a 
Hemi-spherical Tank Level Process, Proc. 
NCPICD, pp 195-200. 
Page 511
 Proceedings of the 
International Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Muhibul Haque Bhuyan,  
E-mail: muhibulhb@gmail.com 
DESIGN AND IMPLEMENTATION OF A PLC BASED 
SCREW AIR COMPRESSOR FOR INDUSTRIAL APPLICATIONS 
 
 
1Poresh Kanti Das and 2Muhibul Haque Bhuyan* 
1Department of Electronics and Telecommunication Engineering 
Daffodil International University, Dhaka, Bangladesh 
2Department of Electrical and Computer Engineering 
Presidency University, Banani, Dhaka, Bangladesh 
E-mail: poreskanti@yahoo.com, muhibulhb@gmail.com 
 
 
Abstract 
Programmable Logic Controllers (PLCs) have been used in various control systems in order to increase 
efficiency, to reduce the initial investment and to minimize the long term maintenance costs. Every industrial 
plant requires compressed air to perform various operations. This can be obtained by air compressor. Screw 
air compressor has high capacity and stable flow in varying conditions. But this requires sophisticated 
control algorithm. In this work, we have designed and implemented a PLC based screw air compressor for 
industrial applications. LEDs are used to indicate different conditions of the air compressor, such as, over 
load, no load, full load, cooling fan’s on/off, vent valve’s open/close or oil level low/high conditions etc. 
Besides, to show different error messages, such as, oil level error signal, over temperature error, over air 
pressure error, over motor current error signals etc. few more LEDs are used. Manual and automatic modes 
of operations have been incorporated in the system.  Besides, reset system has been included in case of 
emergency. In practice, it is found that the developed control system works very well for different types of 
input signals from the sensors and provides appropriate output. 
 
Key words: PLC, screw air compressor, relay. 
 
1. INTRODUCTION 
 
Different industry needs different control algorithm 
and this must be compatible with its goals, its 
competitive environment and any salable benefits.  
Industrial practice differs from the theoretical 
technique, such as, nonlinearity, high-order 
dynamics and process uncertainty.  But  more  
subtle are  the differences  in  the  scale of  
industrial designs  over  what  can  be  taught  or 
the requirements for compatibility with human 
operation and maintenance with the 
multidisciplinary  system design [1]. 
Automation plays great role in contemporary 
industries. Through  the  twentieth  century  it  has  
been  evolved  from  simple sequential control  to  
the complicated electronics  systems. 
Programmable Logic Controller (PLC) has become 
the most powerful change to occur in the 
electronics world for factory automation [2]. This is 
well suited to the cyclical and repetitive operations 
[3]. Unless a system reconfiguration is required, the 
functions executed by a PLC are fixed, the 
programs need not be changed and therefore, they 
may be stored in a Programmable Read Only 
Memory (PROM) [4-5]. Today it  is  hard  to  
imagine  a  factory  without  robots,  numerically 
controlled machines  and  programmable  logic  
controllers  (PLC) [6].  PLCs are being used in 
automatic controlling of doors in public transport 
systems [7-8]. Few works on traffic controllers are 
found using microcontroller [9]. But PLC has many 
advantages over microcontroller, such as, graphic 
mode programming, noise immune, less hardware 
connections, easy downloading of program, faster 
acting etc. Thus, an automatic traffic control system 
has been developed using PLC. The system is 
developed for a junction of four roads only [10]. 
Besides, PLC based automatic railway gate control 
system has also been designed [11]. 
The work is aimed at designing and implementation 
of a PLC based industrial controller for the screw 
air compressor. The system has been tested for 
various faulty and fault free condition and it has 
been observed that the system works very well. 
Few suggestions for the future extensions of this 
work have also been provided. 
 
Page 512ISBN: 978-984-33-2140-4
  
2. SOFTWARE DEVELOPMENT 
 
IBM PC is used to develop the ladder program for 
the PLC and also to edit, compile, debug and then 
finally to download the program in to the PLC. The 
PC’s serial port (COM1) is connected to the PLC’s 
DIN socket by a 9 pin serial connector [12]. At that 
time, the PLC must be in PROG mode [4]. After 
downloading the program PC is no longer required. 
Then the PLC is set in RUN mode to send the 
output signals to its output ports. The developed 
ladder program for the PLC is given in Fig. 1.  
 
 
 
Fig. 1 Complete PLC program of the screw air 
compressor for industrial automation 
 
Different examine ON and OFF instructions are 
used to get the signals from the sensors and 
different output energize instructions are used to 
send appropriate signals at the various output 
devices. Besides, various timer ON instructions are 
used to make the delays in sending and receiving 
the signals and also reset instructions are used to 
reset the timer instructions. 
 
3. HARDWARE IMPLEMENTATION 
 
Every manufacturing plant requires compressed air 
to perform various operations. This compressed air 
can be obtained by air compressor. Air compressors 
are classified by various types. The most useful and 
important air compressor gives trouble free 
operation during working conditions.  
Screw air compressors are modified stage of rotary 
air compressor. It is a single stage, oil flooded and 
driven by electric motor through a coupling. Its 
casing accommodates a pair of male and female 
helical rotors, machined with highest precision and 
mounted on rolling bearings as shown in Fig. 2. 
 
 
 
Fig. 2 (a) A schematic of the screw air compressor 
 
 
Fig. 2 (b) Screw of the screw air compressor 
 
The male rotor has four helical lobes which mesh 
with six flutes of the female rotor. The speed of 
male rotor is 1.5 times higher than female rotor. 
The male rotor is driven by coupling through step-
up gears. The male rotor lobes rotate into the 
Page 513
  
female rotor flutes, the air is trapped in the inter 
lobe spaces and smoothly compressed until the 
lobe-flutes reach the outlet port. Pulsation free air is 
delivered by screw air compressor, due to the 
continuous compression takes place in all the lobe-
flute spaces. 
The oil injected through the lower gusset of the air 
compressor casing mixes with the indrawn air and 
ensures an efficient sealing between the rotors and 
the casing and at the same time, giving an intensive 
cooling during the compression process. Huge 
quantity of lubrication oil cools the compressed air; 
therefore inter coolers are not necessary in screw air 
compressor. The oil, which lubricates the 
compressor, seals the clearance spaces [13]. 
In air cooled models, the oil is cooled in oil cooler 
by separate fan motor whereas it is cooled by water, 
in water cooled models.  
The screw compressor is not equipped with valves 
and has no mechanical forces that cause unbalance. 
This means it can work at a high shaft speed and 
combine a large flow rate with small exterior 
dimensions. An axial acting force, dependent on the 
pressure difference between the inlet and outlet, 
must be taken up by the bearings [14-15]. 
For hardware implementation of this work, 
Programmable Logic Controller (PLC) of model 
K7M - DR20U, brand LS, Korea, is used. To run 
the PLC as well as the whole system an external 
DC Power Supply Unit (220 V AC- 24V DC, 6 
Amp) needs to be designed. Twelve external relays 
of 24 V DC, six piano switches, six push switches, 
one selector switch, two dozen LEDs are used. The 
schematic of the connections of the circuit diagram 
is shown in Fig. 3. LEDs indicate the various input 
and output status of the control systems. Relays 
actuate the output LEDs when energized by the 
output signals of the PLC. Switches give the 
appropriate input signals to the PLC. Internal 
hardware connection is shown in Fig. 4 and the 
systems control panel is shown in Fig. 5. 
 
 
Fig. 3 Schematic of the circuit diagram 
 
Fig. 4 Hardware set-up, internal wiring connections 
 
 
Fig. 5 Front view of the control panel of the screw 
air compressor 
 
4. SYSTEM OPERATION 
 
When power switch is on, vent valve is 
automatically ON for few moments, then air will be 
released from air tank/air reservoir to reduce load 
from the main motor. When compressor is ready for 
start then push switch is pressed to start ON button. 
After that, at first the motor moves without clutch 
at no load power. After some times, the motor 
moves with full load including clutch. After for a 
few moments, suction valve will open and air to be 
entered into the air inlet to make air pressure. The 
screw is attached with the main motor through belt 
and pulley which will be moved slowly and make 
air train. In the mean time, oil spray continues into 
the compressor chamber to reduce the temperature 
inside the chamber and it also smoothes the 
mechanical friction. 
Air train becomes pressurized slowly during 
moving the screw. That means, air pressure 
increases into the compressor chamber. When a 
certain pressure creates into the compressor then 
the inlet valve closes and the outlet valve starts and 
the screw rotates in the opposite direction and this 
completes one cycle of the compressor. After that 
pressurized air is deposited into the air oil barrel. 
Air and oil will be separated into the air oil barrel 
through the oil separator. Oil continues to spray 
again through oil line from the oil tank into the 
compressor chamber and oil circulations to be 
Page 514
  
continued in such a way. It is to be mentioned that a 
thermostatic gate valve and oil cooler already 
connected with the oil line.  
Normally when oil temperature is lowered than 600 
C then oil passes to the oil spray line through oil 
filter directly by passing thermostatic valve. But 
when temperature rises above 600 C the 
thermostatic gate valve is opened automatically. So, 
oil flow path is connected to the oil spray line 
through thermostatic valve, oil cooler and oil filter. 
When a certain air pressure is developed into the air 
barrel then minimum pressure valve becomes open 
through air cooler and connected with the air 
service line. 
If over air pressure is developed for any reason then 
the safety valve connected with air barrel becomes 
open and releases the air pressure. If after 
sometimes compressor body is heated (say, 700 C) 
from normal temperature then the connected 
cooling fan becomes on automatically and it 
becomes off at a certain temperature. 
It is to be mentioned that compressor can run in two 
modes, e.g., normal mode and auto mode. 
Generally, start and stop buttons are used to run the 
compressor at normal mode. In auto mode, high 
and low pressure switch of air barrel are used to run 
the compressor as desired. That means, compressor 
stops for high level pressure and starts again for a 
certain low level pressure. 
When in any case machine becomes faulty then 
machine stops automatically and error signal is 
generated and is displayed in the control panel. This 
fault may be checked in certain suction after the 
formation of an error signal and removed this fault 
easily. Some of the error signals that are displayed 
in the control panel of this work are oil level, over 
temperature, over air pressure, over motor current 
error signals etc. 
To run the compressor again, reset button is to be 
pressed after the remedy of an error signal or fault, 
otherwise the system will not run. The complete 
operation of the system is shown in Figs. 6-7 using 
pulse diagrams. 
 
 
Fig. 6 Pulse diagram of input and output devices of 
control panel 
 
Fig. 7 Pulse diagram of input and output devices of 
control panel 
 
To compare our work, with the existing systems we 
have studied two existing methods used in 
industrial motor controller for the screw air 
compressor- one is inverter and the other one is 
star-delta starter. When these types of starters are 
used then PLCs are not used. Star-delta starter is 
used due to its low cost, but its connection is 
cumbersome and the contactors may burn when 
shot circuit occurs. Inverters are very expensive and 
its design and implementation is time consuming. 
But PLC programming is very easy to use and it 
saves time, money and man power. 
 
5. CONCLUSIONS 
 
In this work, we have developed a control system 
for screw air compressor based on PLC for 
industrial automation. We have used different 
sensors to sense the signals. A prototype process 
control model has been developed and implemented 
using different switches and lights. Ladder program 
is developed for the PLC in an IBM PC and then 
the whole program is downloaded to the PLC from 
the PC through its serial port. The signals for lamps 
are obtained from different external output ports of 
the PLC and input ports of PLC are used to get the 
sensed signals into the PLC. In practice, it is found 
that the developed system works very well. 
The advantage of using the PLC is that since the 
same PLC is used for several controlling functions 
of an industrial process using screw compressor, 
the system will automatically be synchronized for 
different functions. There is no need to install 
additional synchronizing equipment or circuitry or 
need to develop separate program. The main 
limitation of the system is that the real time sensors 
could not be incorporated in this model, but the 
provision for accommodating real time control is 
there. As future extension of this work, more 
sensors at the input and output ports can be added 
according to the needs. In this regard, few 
modifications in the PLC program may be required. 
Page 515
  
REFERENCES 
 
1. E. H. Bristol, “An Industrial Point of View on 
Control Teaching and Theory,” American 
Control Conference, Boston, MA, USA, June 
19-21, 1985, pp. 24-27.  
2. T. E. Kissel, “Industrial Electronics- 
Applications for Programmable Controllers, 
Instrumentation and Process Control, and 
Electrical Machines and Motor Controls,” 
Prentice-Hall of India Pvt. Ltd., 3rd Edition, 
India, 2005. 
3. C. A. Schuler and W. L. McNamee, “Industrial 
Electronics and Robotics,” McGraw-Hill Book 
Co. International Edition, Singapore, 1986. 
4. PC45/ML Curriculum Manual. 
5. www.rshelectronics.co.uk/electronicsclubkits.h
tm 
6. J. Świder and K. Foit, “The use of the 
Mitsubishi PLC systems in student’s 
preparation for realization of industrial tasks,” 
Journal of Achievements in Materials and 
Manufacturing Engineering, vol. 14, issue 1-2, 
January-February 2006, pp. 190-196. 
7. M. Fornal, “The model of an automatic 
controlled door as an example of application of 
PLC in public transports vehicles,” BSc. Engg. 
Thesis, Gliwice, Poland, 2005. 
8. B. Jazwiec, “Application of PLC in 
mechatronic systems on the example of a 
transportation lift,” BSc. Engg. Thesis, 
Gliwice, Poland, 2005. 
9. M. Hoq, Y. Mawla, Mo. A. S. Haque and S. M. 
Jahangir, “Design and Development of a 
Microcontroller Based Traffic Light Control 
System,” Proceedings of BES Conference, 
Dhaka, Bangladesh, April 2003, pp. 122-126. 
10. M. H. Bhuyan, M. A. Kabir, M. A. Rahman 
and A.-A.-Mamun, “Development of an 
Automatic Traffic Signal Control System 
Using PLC,” Proceedings of the Conference on 
Engineering Research, Innovation and 
Education (CERIE), Shahjalal University of 
Science and Technology, Sylhet, Bangladesh, 
11-13 January 2010, pp. 360-364. 
11. M. H. Bhuyan and M. A. Kabir, “PLC based 
Automatic Railway Gate Control System,” 
Proceedings of the National Conference on 
Electronics and Telecommunications for 
Digital Bangladesh, Bangladesh Electronics 
Society, Dhaka, Bangladesh, 2-3 June 2010, 
pp. 136-138. 
12. D. V. Hall, “Microprocessors and Interfacing: 
Programming and Hardware,” McGraw-Hill 
International, India, 1997. 
13. http://hubpages.com/hub/How-Electric-Screw-
Air-Compressor-Works 
14. http://www.screwcompressor.com.au/index.ph
p?/archives/8-Introduction-to-Screw-
Compressor/ 
15. http://www.supremeco.wordpress.com 
 
Page 516
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Muhibul Haque Bhuyan,  
E-mail: muhibulhb@gmail.com 
DESIGN AND IMPLEMENTATION OF A REMOTE SENSING 
ELECTRICITY SUPPLY CONTROL FOR 
INDUSTRIAL APPLICATIONS 
 
 
1Debashis Das and 2Muhibul Haque Bhuyan* 
1Department of Electrical and Computer Engineering 
Presidency University, Banani, Dhaka, Bangladesh 
2Department of Electrical and Electronic Engineering 
Daffodil International University, Shukrabad, Dhaka, Bangladesh 
E-mail: das120003@gmail.com, muhibulhb@gmail.com 
 
 
Abstract 
In this work, we have developed a remote sensing electricity supply control systems for industrial 
applications. For this purpose, we have used a magnetic contactor, two cell phones, two voltage amplifiers 
and one relay. The output voltage of cell phone’s ringer is used for sensing and providing the control signals 
from the remote position. Magnetic contacts and relays are used to turn on or to turn off the electricity 
supply from the main distribution board. The circuit has been designed, implemented and tested in various 
industrial areas in Bangladesh and it has been found that this controller circuit works very well. 
 
Key words: Electricity supply control, cell phone, remote sensing. 
 
1. INTRODUCTION 
 
Now a day, several industrial fire accidents have 
occurred in Bangladesh mainly because of electrical 
short circuits problem. When these accidents occur, 
switching off the main distribution board is must. 
But it can not be done at that time due to various 
practical reasons, such as non-availability of key of 
the main board, or the person in-charge, or the 
place of the accidents is near the main board, or on 
its way etc. So, if this can be done by remote 
sensing then damages and losses can be reduced or 
even can be avoided. 
This work is aimed at designing and 
implementation of an electric supply controller 
circuit using magnetic contactors for the industrial 
application. The controller circuit has been 
implemented using two cell phones. It has been 
observed after practical testing that the designed 
circuit works very well. 
 
2. HARDWARE DESCRIPTION 
 
Fig. 1 shows the block diagram of the electric 
supply control circuit. The ac source is connected to 
the load through a magnetic contact [1-2]. The 
magnetic contractors are connected to the ac source 
via two relay contacts (1 and 4 in Fig. 1), one 
normally open (NO) control terminal of the 
magnetic contact (2) and one push button switch 
(3). Relay contact 1 is normally open and relay 
contact 4 is normally close. Push button switch 3 is 
also normally open. Two relay coils are connected 
to the output terminals of the two voltage amplifiers 
(as shown in Fig. 1) whose inputs are connected to 
the output signals of the two mobile phones. The 
output signals of the mobile phones used here are 
the vibration signals produced by the mobile sets. 
These signals are too week to energize the relay 
coils and these are DC signals. Therefore, DC 
voltage amplifiers are used. To get the DC bias for 
the two voltage amplifiers, two step down 
transformers (220V/12V, ac, 50 Hz, 500 mA) and 
two bridge rectifiers are also used. Push button 
switch 3 is used here so that the electric supply to 
the load without the help of the mobile phone can 
be connected. Switch, SW is used so that the 
electric supply to the load without the help of the 
mobile phone can be disconnected. 
Fig. 2 shows the photograph of the voltage 
amplifiers. Here two bipolar junction transistors 
(BJT) are used in common emitter mode for the DC 
voltage amplification [3]. The gain of the amplifier 
is 5. The output of the mobile phone set is the input 
voltage of this amplifier and it is 1.2 V, DC. So, the 
output voltage of the amplifier is 6 V, DC. Since 
this voltage drives the relay coil (black box in Fig. 
Page 517ISBN: 978-984-33-2140-4
  
2), so relay used here is a 6 V DC relay [1]. Both 
relays have two contacts, normally open (NO) and 
normally close (NC) contacts. 
Bulbs are used as the load in our controller circuit 
as shown in Fig. 3. If the load is larger then another 
large sized magnetic contact is used and this 
magnetic contact is energized by the output of this 
small magnetic contact. 
 
 
Fig. 1 Block diagram of the electric supply 
controller for industrial application 
 
 
 
Fig. 2 Photograph of the voltage amplifier 
 
Fig. 4 shows the back view of the cell phones from 
which terminals of the ringer has been taken out of 
the cell phone and connected to the voltage 
amplifier’s input terminals. Cell phone settings 
have to be customized, such as, ringer tone should 
be made off, all message alerts should be turned 
off, authorized cell numbers should be saved in the 
cell phone’s SIM by using different names and the 
calls from the other numbers should be blocked so 
that any unauthorized person can not operate or 
control this system. 
 
 
Fig. 3 Top view of the control circuit 
 
 
Fig. 4 Back view of the control circuit 
 
4. SYSTEM OPERATION 
 
When power switch (SW) is ON and cell phone call 
is made then the coil relay 1 is energized by the  
output of the voltage amplifier connected to the 
mobile phone’s ringer signal and thus normally 
open contact of relay 1 is closed. Immediately after 
that coil of the magnetic contacts are also energized 
Page 518
  
and hence the magnetic contacts 2 gets closed. Now 
if the cell phone is OFF then the relay coil 1 is de-
energized and hence relay contact 1 becomes OFF, 
but magnetic contact remains energized as long as 
the magnetic contract 2 remains closed. Therefore, 
the load connected to the ac source via the magnetic 
contact gets the electric power supply. But if there 
any accident, such as, short circuit, occurs in the 
load side then we may switch it OFF by making 
another call from the cell phone. This time the 
output signal of another mobile phone is amplified 
by the voltage amplifier and it actuates the relay 
coil 4 and hence the normally closed contact of 
relay 4 becomes OFF. Hence the power supply is 
cut from the load. If we want the electric power 
supply to be established manually then we can 
press the push button switch 3 and hence magnetic 
contacts 2 will be closed and the load continues to 
get the ac supply as before. 
 
5. CONCLUSIONS 
 
In this work, we have developed a remote sensing 
electricity supply control systems for industrial 
applications. Magnetic contacts and relays are used 
to turn on or to turn off the electricity supply from 
the main distribution board. Cell phone sets have 
been customized very carefully so that any 
unwanted signals can not activate the cell phone 
and thus to control the electricity supply connected 
with the load side. The circuit has been designed, 
implemented and tested in various industrial areas 
in Bangladesh and it has been found that this 
controller circuit works very well. The design and 
implementation cost is very small with regards to 
its applications. 
 
 
REFERENCES 
 
1. Thomas E. Kissel, “Industrial Electronics –
Applications for Programmable Controllers, 
Instrumentation and Process Control, and 
Electrical Machines and Motor Controls,” 
Prentice-Hall of India Pvt. Ltd., 3rd Edition, 
India, 2005. 
2. Charles A. Schuler and William L. McNamee, 
“Industrial Electronics and Robotics,” 
McGraw-Hill Book Co. International Edition, 
Singapore, 1986. 
3. D. V. Hall, “Microprocessors and Interfacing: 
Programming and Hardware,” McGraw-Hill 
International, 1997. 
 
Page 519
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: R. R. Mahmud  ,  
E-mail: r.r.mahmud@gmail.com  
DESIGN AND IMPLEMENTATION OF AN INTELLECTUAL 
SECURITY SYSTEM FOR THE WORLD WIDE APPEARANCE OF 
OWNER  
 
 
R. R. Mahmud*, O. Farrok 
Lecturer, Dept. of EEE, Ahsanullah University of Science and Technology (AUST), Bangladesh 
 
M. Ahmed, S. N. M. A. Kader and M. J. Rahman 
Student, Dept. of EEE, Ahsanullah University of Science and Technology (AUST), Bangladesh 
 
 
This paper presents design and implementation of an intellectual optical security system for any unsecured 
place which gives acknowledgement to owner of the security signal on owner appearance at any place in the 
world where the mobile communication is available. Security system is essential for house, educational 
organization, public places and other important architecture. The security system CCTV and others are very 
expensive and need man power. But the proposed design security system is cheaper for installing and 
maintaining and providing better performance than the conventional security system. This security system 
can protect both vertical and horizontal area of almost 16 thousand square feet. A detail design procedure 
including block diagram, theoretical description, circuit design and practical outputs are presented in this 
paper. Design steps are presented in a sequential manner that would be advantageous for the beginners as 
well as for the advanced readers. 
 
Key words: LASER; LDR; Siren generator; Counter; Coupling circuit with mobile. 
  
Section 1.01 1. INTRODUCTION 
 
A security system is a device that detects intruder 
and any unwanted objects. Security is a vital need 
for man kind from long years ago. At first door 
security was need. After that huge area, money and 
other valuable things are need to be secured. The 
security system has been invented from long years 
by a number of researches. Most of the previous 
researches are based on electronic circuits and now 
computerized security systems are very popular like 
CCTV. Our proposed security system is different 
from the other researchers who have done their 
research on the same area. To show in difference 
between our findings and others, we would like to 
explain their researches. An electric fence security 
system was developed in 1936–1937 by William 
Bill Gallagher [7]. In 1962, another inventor Doug 
Phillips invented the non-short able electric fence 
based on security system using capacitor discharge 
[6]. Electronic security system has been invented in 
1984 for the first time [7]. In 1971, a detection 
security System was designed by another researcher 
Hedin et al in United States of America. The 
invention had a logic system which included 
differential amplifier systems with individual photo 
resistors
 
[1]
.
 In 1972, an alarm system for sensing 
smoke and intruders was designed by W. Henry and 
Gans Frederick [2]. In 1973, intrusion detector was 
made by Missio, V. Danilo et al which could detect 
only the intruder [3]. Also in 1973, another project 
called segment locating alarm system for security 
was designed by Schlisser [4]. In 1976, an original 
optical security alarm circuit system was invented 
by Todeschini and John David [5]. So far as we 
know that all the mentioned project inventions are 
explained about the alarm based security system 
and intruder detection system but there is no 
technique to give acknowledgement to the owner 
through mobile communication with low alarm 
circuit which creates no disturbance to the 
neighbor. But our proposed circuit can do so. That 
is why our proposed security system is unique, 
efficient and cheap as for manufacturing and 
maintenance.  
 
2. BLOCK AND LAYOUT 
DIAGRAM OF THE SECURITY 
SYSTEM  
 
It includes a light source (infrared), some lens to 
collimate the light into a beam and a photodiode or 
other photoelectric sensor as a light detector. The 
Page 520ISBN: 978-984-33-2140-4
  
light passes in front of the detector to a straight line. 
When intruder or any unwanted objects are come in 
between the  beam and mirror then the light does 
not incident on the sensor for any time then the 
circuit triggers the mobile to make call to the 
owner. The block diagram of the total system is 
given in figure 1. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 1: Block layout diagram of the proposed whole 
security system 
 
First all the mirrors are adjusted in a balanced way 
that the light is covered and surrounded the whole 
area. The beam is first incident upon on the first 
mirror, then after reflecting it is incident on the 
second mirror and so on. In the similar process the 
beam is reflected and incident on the sensor. The 
LASER beam is constructed around the protected 
area of about 3 inches away from the wall. About 
16 thousands square feet can be protected by our 
proposed protected system. When the intruder or 
any unwanted objects are tried to enter that area 
then it creates barrier to the LASER beam. This 
event turns on the mobile communication circuit 
and within six seconds a call is send to the owner 
mobile cell phone as any appearance of the owner 
in any place of the world where the mobile network 
is available. Blocks based on operation of the whole 
system is represented in figure no 2. A high power 
LASER diode is used in this research circuit. Light 
dependent resister (LDR) is used for sensing the 
LASER light. The time counter are used for 
splitting the pulse which is generated by the pulse 
generators. Alarm tone is generated by the tone 
generator. Photo coupler is used here for triggering 
the mobile for sending a call to the owner. The 
splitter fixes the time interval of the pulse in three 
second. After sensing once the reset button is need 
tobe reset all the systems. When the reset button is 
pushed then the whole process starts instantly, 
otherwise it will continue the whole process.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 2: Block diagram of operation of the whole 
security system 
 
3. DETAIL CIRCUIT DESIGN OF 
THE TOTAL SECURITY SYSTEM 
 
Detail circuit design of our proposed security 
system is given in the figure no 3. In this circuit 
Page 521
  
design +6v DC is applied as voltage source. 1n4007 
rectifier diode rectifies the current to 100mA. When 
light incidents upon the 1 no LDR, the LDR is 
acted like an 18 k ohm resistor. According to the 
KVL, the voltage is divided between both the no 1 
LDR and R1 resistor. R1 is 220k ohm and the 
voltage across R1 is supplied to the input pin 2 of 
no 1 555IC. When the laser beam or light is 
interrupted by intruder or any  other unwanted 
objects then the no 1 LDR is acted like open circuit 
cause increasing its resistivity to the level of 
infinite then the voltage across the R1 becomes 0 
volt. In this condition, no 1 555 IC generates a 
pulse which is delivered from the output pin no 3. 
The pulse is rectified by diode D2 and further 
rectified by D3. A voltage is developed across the 
resistor R6 which is acted like base voltage of the 
transistor T2. Then the collector voltage is 
developed across the resistor R10 again which is 
the base voltage of T3. Then T3 supply its collector 
voltage which is developed across the R11, D4 and 
R14, R15, C5, R16 respectively. Again the voltage 
is divided according to KVL between R14, R15. 
IC3 555 which is used as an astable multivibrator  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
generates a pulse which is delivered from the 
output pin 3 to the 14 no pin of IC4. IC4 keeps the 
amplitude of the pulse same and fixes the time 
interval of the pulses in three seconds. The split 
pulses are delivered by the output pins 3 and 4 
sequentially. Each pulse develops voltages across 
R17 and R18 sequentially. So that a base voltage is 
developed across the base of T6 and then second 
pin of the photocoupler gets the collector voltage 
from T6 sequentially and 1 no pin gets the voltage 
direct from the collector of T3 which is developed 
across the R16. The 3 and 4 no pins of 
photocoupler are connected directly to the send key 
of the mobile cell phone and they are shorted 
sequentially after every 3 second. The collector 
voltage of T3 is divided between R11 and D4 
according to KVL. The voltage developed across 
the D4 works as the input of IC2. When 3.3 volt is 
developed across the 5 no pin of IC2 then it 
generates an alarm tone and actives the mobile cell 
phone to create a call to the owner under the 
network with the owner station of any place in the 
world. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 3: Detail circuit design of the total security system 
 
Page 522
  
4. RESULTS, OUTPUTS AND 
COMPLETE SNAPSHOTS OF 
THE SECURITY SYSTEM  
 
From the given below figure no 4 (a) shows the 
whole security system which is deactivating mode 
before the intruder enters into the laser barrier. (b) 
Shows when the intruder enters in between the 
LDR sensor and the laser beam which creates an 
interrupt by the intruder. This turns on the whole 
circuit of the security system and the mobile call 
establishing circuit system triggers to create a call. 
(c) Shows full view of the security system and both 
mobiles of the security system and owner, which 
are activated automatically. (d) Shows the call 
sending process from the security system mobile 
(which is triggered by the circuit) to the number of 
the owner. (e) Shows the incoming call process of 
the owner’s mobile from the security system 
mobile.    
 
 
(a) 
 
 
                                    (b) 
 
          
(c) 
 
(d) 
 
 
(e) 
 
Fig. 4: Results of the whole security system  
(a) Total system without entering the intruder or 
any unwanted object  
(b) Total system with entering the intruder or any 
unwanted object 
(c) Establishing a call between the security system 
mobile and owner mobile 
(d) Sending call from the security system mobile 
to the owner mobile      
(e) Incoming call from the security system mobile 
to the owner mobile 
 
5. CONCLUSIONS 
Our proposed intellectual optical security system is 
better than the conventional security system. It is 
not expensive. No need of man power to provide 
security. It is a fully electronic sensor based circuit 
with DC supply, which provides a continuous alarm 
and a number calling system through a cell phone. 
This project can protect an area of around 16 
thousand square feet. This proposed circuit can also 
use to capture the image of the intruder by 
connecting a camera with this circuit and it has a 
wide military application. The proposed Intellectual 
optical security system is deferent from the other 
security system because of the owner calling 
Page 523
  
system through a cell phone with a burglar alarm 
and its multipurpose use. It also deferent for its nice 
control switching circuit which can switch anything 
in a time controlled manner. 
 
 
REFERENCES 
 
1. Hedin, R. A. and Bolzano, A. F., (1971), 
Perimeter intrusion detection system, United 
States Patent 3623057, no 04/824625.  
2. Henry, W. W. and Frederick G., (1972), Alarm 
system for sensing smoke and intruders, United 
States Patent 3683352, no 05/127276. 
3. Missio, D. V. et al, (1973), Intrusion detector, 
United States Patent 3727207, no 05/049333. 
4. Schlisser, G. and Insler, J. R., (1973), Segment 
locating intrusion alarm system, United States 
Patent 3711846, no 05/113324.  
5. Todeschini, D. J., (1976), Optical security 
system, United States Patent 3987428, no     
05/587308. 
6. Online documentation viewed on 14th March at 
the web site: www. wikipedia.org 
7. First electronic security system viewed on 14th 
March at the web site: 
www.hnd.usace.army.mil/esc.  
Page 524
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Muhibul Haque Bhuyan,  
E-mail: muhibulhb@gmail.com 
DESIGN AND MANUFACTURING OF A LOW COST 
SYNCHRONOUS MOTOR-GENERATOR FOR 
ELECTRICAL MACHINE LABORATORY 
 
 
1Debashis Das, 2Muhibul Haque Bhuyan* and 1Rafiqul Islam 
1Department of Electrical and Computer Engineering 
Presidency University, Banani, Dhaka, Bangladesh 
2Department of Electrical and Electronic Engineering 
Daffodil International University, Shukrabad, Dhaka, Bangladesh 
E-mail: das120003@gmail.com, muhibulhb@gmail.com 
 
 
Abstract 
In this work, we have developed a very low cost synchronous machine which can be run as both 
synchronous motor as well as alternator. When the machine runs as an alternator, an induction motor or a 
DC shunt motor is required as the prime mover. This has also been developed. The machine has four poles. 
Its stator voltage is 415 V (AC), stator current is 0.75 A, rotor voltage is 0 to 240 V (DC) and rotor current is 
0.4 A. With this machine, at least eight experiments can be performed for the undergraduate level students. 
There are future expansion provisions in this machine. All the experimental results support theory. It has 
also been found that the machine reduces the cost by around 67 % than that of an equivalent machine 
imported from foreign country. 
 
Key words: Synchronous motor, alternator, electrical machine laboratory. 
 
1. INTRODUCTION 
 
At present, many public and private universities in 
Bangladesh have established Electrical and 
Electronic Engineering (EEE) department due to 
the high demand of this subject at home and 
abroad. But the establishment of electrical machine 
laboratory for the EEE department is a big 
challenge due to the huge expenditures. To 
establish an electrical machine laboratory, we need 
to purchase various machines, such as, DC motor, 
DC generator, induction motor (1-φ/3-φ), alternator 
(1-φ/3-φ), synchronous motor, transformer (1-φ/3-
φ), electrodynamometer, power supply, various 
measuring instruments etc. Synchronous motor and 
alternator are the two important machines because 
many important experiments and research works 
can be carried out using these two machines. These 
machines are very expensive since these are being 
imported from foreign companies.  
 
The work is aimed at designing and manufacturing 
of a low cost synchronous motor-generator for 
electrical machine laboratory. All the designed 
steps are described step by step and are shown in 
the photographs of various stages. The machine has 
been tested for various experiments and it has been 
observed that the experimental results match the 
theoretically obtained results very well. 
 
2. BASIC THEORY 
 
The motor that has zero slip, i.e. no load and full 
load speeds are same, are called synchronous 
motor. In this motor, stator winding takes the 3-
phase AC supply and the rotor winding takes the 
DC supply to produce magnetic flux. Stator 
winding also makes a rotating magnetic field which 
rotates at a speed of 120f/P. But stator’s magnetic 
poles and rotor’s magnetic poles are in opposite 
direction. So these two fields become locked at a 
particular speed and both the fields rotate at the 
same speed of 120f/P. This speed is called 
synchronous speed and that’s why this motor is 
called synchronous motor. Loading capacity 
depends on the magnetic strength produced by the 
motor. The magnetic strength can be varied by 
varying the excitation of rotor winding [1-3].  
 
In case of alternator, rotor is driven by a prime 
mover and rotor field is excited by DC field. Like 
synchronous motor, its stator field produces a 
rotating magnetic field by taking 3-phase AC 
Page 525
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
 *
 Corresponding Author: Muhibul Haque Bhuyan,  
E-mail: muhibulhb@gmail.com 
supply. The stator thus induces the electromotive 
force in the stator terminals. Its amplitude depends 
on the rate of change of flux that depends on the 
speed of the prime mover, flux density and number 
of poles [1-4]. 
 
2. DESIGN PROCEDURE 
 
There are two parts in this design. One is the 
synchronous motor and the other one is the 
alternator. There are many parts that have to be 
designed, such as, the rotor, the stator, the yoke or 
the frame etc. In the following subsections, design 
procedures of these parts are described. 
 
2.1 Rotor Design 
At first, two identical rotors of two squirrel cage 
induction motors are taken. Then materials inside 
the rotor of one motor is removed to make a hole 
inside it, but on the outside surface squirrel winding 
remains as shown in Fig. 1.  
Now the second induction motor is turned in lathe 
machine to strip off the squirrel winding as shown 
in Fig. 2. 
 
 
Fig. 1 Rotor with hole having squirrel cage winding 
 
 
Fig. 2 Rotor turned in Lathe machine to remove 
squirrel cage winding 
 
Turing process should be completed in such a way 
that rotor of Fig. 2 can be entered into the hole of 
the rotor of Fig. 1. After that slots should be made 
on the rotor of Fig. 2 to wind DC coils on it. DC 
coils should be placed from the two opposite limbs. 
After that rotor of Fig. 2 should be glued into the 
rotor of Fig. 1 as shown in Figs. 3-4. Finally, 
vanishing oil should be given on the winding. The 
rotor will be placed inside the stator. 
 
 
Fig. 3 One rotor is being entered into the another 
rotor 
 
 
Fig. 4 Final rotor of the synchronous motor 
 
2.2 Stator Design 
There are two types of stator winding connections, 
such as, lap winding and wave winding [5]. In this 
machine, we have used lap winding connection, 
because this type of winding reduces starting 
current of the machine [6]. It has full pitch and 
single layer. Total number of slots used here are 24 
and the total number of poles used are 4. The coil 
span for full pitch winding are 24/4=6. Therefore, 
the electrical degree completed for per rotation of 
the stator is 1800×4=7200. That is, two full cycles 
will be completed. The electrical degree for one slot 
is 7200/24=300. The winding connection is shown 
in the diagram given in Fig. 5. 
 
 
Fig. 5 Stator winding connection diagram 
 
Fig. 6 shows the stator which is made by laminated 
sheet that has been cut by using a 24-slot dice 
applying pressure. The dice has such a special 
Page 526
 *
 Corresponding Author: Muhibul Haque Bhuyan,  
E-mail: muhibulhb@gmail.com 
shape so that the slots in the sheets are obtained at 
the inner periphery of the stator. All the slots are 
identical. In these slots, conductors for the stator 
coils are placed. Around 220 to 240 identical sheets 
are required to cut for preparing the stator. All the 
sheets are pressed together and then clipped by 4 
metal strips across the periphery. 
 
Fig. 7 shows the stator with the coil inside the 24 
slots. The coils are connected as per stator winding 
diagram shown in Fig. 5. The wires of the coil are 
taken from copper wires. The designed rotor of Fig. 
4 is then inserted into the stator of Fig. 7. 
 
Fig. 8 (a) shows the yoke with front and back 
flanges. These are made by aluminium in foundry 
shop. After inserting the stator and rotor inside the 
yoke, front and back flanges will be connected at 
the two ends of the yoke by nuts. The yoke with 
connected flanges at the end is shown in Fig. 8 (b). 
 
Fig. 9 shows the side view of the completed 
machine. At the back side of the machine, two 
terminals of the rotor winding are connected with 
the two slip rings on which the carbon brushes 
touch the slips rings. Through this carbon brushes, 
DC supply is given to the rotor winding. 
 
Fig. 10 shows the front view of the completed 
machine and its input/output terminal panel. 
Ratings are also written at the front panels. 
 
 
Fig. 6 Stator made by laminated core with 24 slots 
 
 
Fig. 7 Stator with coils inside the slots 
 
Fig. 8 (a) Yoke with front and back flanges 
 
 
Fig. 8 (b) Yoke with front and back flanges fitted 
 
 
Fig. 9 Side view of the completed machine 
 
 
Fig. 10 Front view of the completed machine 
 
The specifications of the designed machine, both 
the alternator and synchronous motor are shown in 
Table 1. 
Page 527
 *
 Corresponding Author: Muhibul Haque Bhuyan,  
E-mail: muhibulhb@gmail.com 
Table 1 Machine specifications 
Specifications Rated Values Motor Alternator 
Rated voltage, V 415 415 
Rated current, A 0.75 0.40 
Rated power, W 310 - 
Rated Volt-Ampere, VA 310 165 
Rated speed, rpm 1500 1500 
Rated field voltage, V 0~240, DC 0~240, DC 
Frequency, Hz 50 50 
No of poles, P 4 4 
No of conductors per 
slot, Z 92 92 
 
3. EXPERIMENTAL RESULTS 
 
Numerous experiments have been performed using 
the designed machine. Two important results are 
shown here for the brevity of the paper, one is V-
curve plot for the synchronous motor and another is 
open circuit voltage plot for the alternator. All 
experimental results are taken by using 
conventional meters. So, there may be some 
measurement errors, but the results are very much 
similar to that of theoretically obtained results. 
 
3.1 Synchronous motor’s experiment 
When the machine run as a synchronous motor, 
various experiments can be performed, such as, V-
curve plot, synchronous condenser, loading curve 
etc. Here we have shown the V-curve of our 
designed machine in Fig. 11. In the figure, we see 
that as the field current is increased from 0 mA, 
armature current of the motor is decreased becomes 
minimum after a certain point and again as the field 
current is increased the armature current is 
increased and thus the curves look like a V-shape of 
the English alphabet [1]. This result is very much 
similar to that of the observed results in the book 
[1-4]. The magnitude of the armature current 
reflects the transfer of reactive energy into or out of 
the machine.  If the field is providing just the right 
amount of flux to produce the torque, the armature 
current will transmit only real power. At this 
condition, the armature current is minimized for 
this particular load and the terminal power factor is 
unity. For a given level of real power transmission, 
the position on the V-curve is controlled by the 
magnitude of the field current.  In fact, at very low 
power levels the synchronous motor can be made to 
“look” capacitive and can be used as a continually 
adjustable power factor corrector.  
  
The impedance parameters for the equivalent 
circuits can be found by testing the machine.  The 
armature resistance is found by placing a DC 
source across the appropriate armature terminals 
and measuring the voltage and current. The 
resistance is the ratio of voltage to current 
multiplied by an appropriate correction to account 
for skin effect (approximately 1.2 at 60 Hz). 
 
0 100 200 300 400 500 600 700
0
50
100
150
200
250
Field Current (mA)
Ar
m
a
tu
re
 
Cu
rr
e
n
t (m
A)
 
Fig. 11 V-curve of the synchronous motor 
 
3.2 Alternator’s experiment 
When the machine run as an alternator, various 
experiments can be performed, such as, finding 
open circuit characteristics, short circuit 
characteristics, loading characteristics, 
determination of voltage regulation etc. Here we 
have shown the open circuit characteristics of our 
designed machine in Fig. 12. For plotting the open 
circuit characteristics, the alternator is run by a 
prime mover at synchronous speed. The field 
excitation is varied in steps and the corresponding 
open circuit voltage is recorded. The data are taken 
till the open circuit voltage approximately 25 to 30 
% higher than the rated value. An open circuit 
characteristics is finally plotted. In the figure, we 
see that as the field current is increased from 0 mA, 
open circuit voltage is increased and after a certain 
point the open circuit voltage will be fixed due to 
the saturation of the magnetic flux in the field 
circuit. This result also supports the theory [2-6]. 
 
0 100 200 300 400 500 600
0
100
200
300
400
500
600
Field Current (mA)
O
pe
n
 
Ci
rc
u
it 
Vo
lta
ge
 
(V
)
 
Fig. 12 Open circuit characteristics of the alternator 
Page 528
 *
 Corresponding Author: Muhibul Haque Bhuyan,  
E-mail: muhibulhb@gmail.com 
5. CONCLUSIONS 
 
In this work, we have developed a very low cost 
synchronous machine which can be run as both 
synchronous motor as well as alternator. Using this 
machine few experiments have been performed and 
it has been observed that these results support the 
theoretically observed results. It has also been 
found that the machine reduces the cost by around 
67 % than that of an equivalent machine imported 
from foreign country. There are future expansion 
provisions in this machine. Computer interfacing 
can be incorporated with this machine so that the 
experimental data can be acquired in the PC 
through the RS232 interfacing cable and parallel 
ports of the PC. Besides, we will design the other 
machines that are required for the electrical 
machine laboratory by cost reduction. 
 
REFERENCES 
 
1. Geoff Klempner and Isidor Kerszenbaum, 
“Operation and Maintenance of Large Turbo 
Generators,” ISBN 0-471-61447-5, John Wiley 
and Sons Inc., USA, 2004.  
2. T. Wildi, “Electrical Machines, Drives and 
Power Systems,” Prentice Hall, USA, 1995. 
3. Fitzgerald, Kingsley and Umans, “Electric 
Machinery,” McGraw-Hill Book Company, 
USA, 1983, Chapter 7.  
4. M. S. Sarma, C. William, “Electric Machines,” 
Brown Publishers, USA, 1985.  
5. Irving L. Kosow, “Electric Machinery and 
Transformers,” Prentice-Hall, Inc., USA, 1995.  
6. David Brown, E. P. Hamilton, 
“Electromechanical Energy Conversion,” 
MacMillan Publishing Company, USA, 1984. 
 
Page 529
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: R. R. Mahmud,  
E-mail: r.r.mahmud@gmail.com 
DESIGN AND SIMULATION OF A MULTI-LANGUAGE DIGITAL 
CLOCK BY SWITCHING SYSTEM  
 
 
R. R. Mahmud*, O. Farrok 
Lecturer, Dept. of EEE, Ahsanullah University of Science and Technology (AUST), Bangladesh 
 
M. S. A. Sharif 
Student, Dept. of EEE, Ahsanullah University of Science and Technology (AUST), Bangladesh 
 
 
This paper presents design and simulation of a microcontroller based multi-language digital clock. The 
design part contains one hardware portion (DC power supply, LCD display and a microcontroller) and 
another software portion (program for operating microcontroller). The conventional digital clocks which are 
available in market can display only one language. But our designed digital clock is flexible enough to use in 
different countries as it can display multi-language at a time using switching system. Again our research 
device is very cheap to implement compare with others. The programming algorithm of multi-language 
digital clock can be used to display same meaningful sentence in different language by a single 
microcontroller through graphical display. This type of digital clock can be used where different cultural 
people gather together. Detail design procedures i.e., block diagram, circuit design, algorithm, flow chart, 
description of the microcontroller and the simulation outputs are presented in this paper. Design steps are 
presented in a sequential manner that would be advantageous for the beginners as well as for the advanced 
readers who are interested to research with microcontroller. 
 
Key words: Graphical display; Microcontroller; DC power supply unit; LCD display.  
 
1. INTRODUCTION 
 
An efficient use of multi-language digital clock and 
multi-language digital display of any text are many 
folds; it has a greater advantage than a single 
display clock, it can be used where different 
cultural people gather together, cheaper than single 
language digital clock, nice to display and easy to 
implements. The display part can be a LCD or 
graphical display. The operating program for 
microcontroller is designed by programming 
language C in AVR platform because of AVR 
studio is very suitable for ATMEGA type 
microcontroller. Except one or two, there are not 
many efforts have been done in this field by 
researchers. But our topic is different from the other 
researchers who have done their research on the 
same area. To show in difference between our 
findings and others, we would like to explain their 
researches. One of the researchers K. Benkrid [1] 
who have designed multi-language framework to 
FPGA hardware development which aims to satisfy 
the dual requirement of high level hardware design 
and efficient hardware implementation. Another 
researchers Wichit Sirichote designed a normal 
electronic digital clock by using seven segment 
display which is not multi-language [2]. Only Thai 
language is discussed by wikipedia [3]. Again 
Hindi language can be learned from the reference 
no 4. All the mentioned papers explained about 
electronic seven segment digital clock based on 
single language, detail description about different 
language. But so far as we know that there is no 
paper explains about the microcontroller based 
multi-language digital clock. So our paper is unique 
that all the design, simulation and results of our 
proposed research are presented in this paper.  
 
2. BLOCK DIAGRAM OF THE 
MULTI LANGUAGE DIGITAL 
CLOCK SYSTEM  
 
Power supply unit is used to produce constant 5 
volts. Microcontroller which is the main part of this 
proposed research work that process the program 
and control all hardware operation. Switch is a push 
pull device which is used to produce a high pulse 
through the microcontroller input pin. Liquid 
crystal display (LCD) is used to display the clock. 
The total system is given below based on block 
diagram in figure 1. 
Page 530ISBN: 978-984-33-2140-4
  
 
Fig. 1: General block diagram of the multi-
language digital clock system 
 
3. CIRCUIT DESIGN OF THE MULTI-
LANGUAGE DIGITAL CLOCK 
 
The microcontroller needs a DC supply of +5 volts 
to the pin no 1 of the microcontroller and it 
grounded through a resister for sensing 0 when 
supply is off. The pin no 14, 15, 16, 18, 19, 20, 21 
of the microcontroller are declared as outputs and 
are connected with the pin no 4, 5, 6, 11, 12, 13, 14 
respectively of the LCD. After pressing the switch, 
a high pulse is gone to the pin no 1 to the 
microcontroller and after that the microcontroller 
becomes active. This high pulse is checked by the 
program and then the program is running in the 
loop of second, minute, hour step by step. LCD is 
used here for displaying the time in digital multi-
language pattern. 
 
 
 
Fig. 2: Detail circuit design of the multi- 
language digital clock system 
 
The main part microcontroller is a programmable 
device which contains a microprocessor, memory 
as same as a single chip computer. As 
microcontroller is a low cost programmable device, 
it is used in the automatic control application like 
robot, microwave oven, digital watch, mobile 
phone, electronic display and some conditions 
where circuit is difficult. The block diagram of the 
microcontroller is given below in the figure no 3. A 
liquid crystal display (LCD) is a thin, flat electronic 
electronic visual display that uses the light 
modulating properties of liquid crystals (LCs). This 
is used in a wide range of applications including 
computer monitor, television, instrument panels, 
aircraft display and also in consumer devices such 
as video players, gaming devices, clocks, watches, 
calculators, and telephone. This model has 20 
character and four lines. This LCD operate in +5v.  
and pin configuration of the LCD is given in the 
figure no 4. 
 
 
 
Fig. 3: Block diagram of microcontroller 
 
 
 
Fig. 4: Pin configuration of LCD 
 
4. SOFTWARE PORTION  
 
4.1 SIMULATION SOFTWARE 
Proteus 7.6 is a software for microprocessor 
simulation, schematic capture, and printed circuit 
board (PCB) design [5]. It is developed by lab 
center electronics. The XGamestation micro edition 
was designed using lab center’s proteus schematic 
entry and PCB layout tools. Also AVR Studio 4 
provides a complete set of features including 
debugger supporting run control including source 
and instruction-level stepping and breakpoints, 
registers, memory and I/O views and target 
configuration and management as well as full 
programming support for stand alone programmers. 
 
Page 531
  
4.2 Flow chart of the microcontroller 
program  
Here 8 pin of microcontroller as output is used 
which connected with LCD.  1 no pin is used as an 
input where switch is connected. Here the program 
is written in programming C language. The 
program can be divided in some parts. One part of 
the program is for clock and shows the clock in 
LCD. And other part is for controlling the language 
before show the clock in LCD. Under this part the 
clock data is send to LCD and then declare the 
function for different language and apply a simple 
condition of changing language by switching. For 
every high pulse from switch the language is 
changed. When we connect the power in project 
then a high pulse goes to the micro controller 
program under the microcontroller for matching 
this pulse with the statement of program. The LCD 
displays Bangla language first, then English, Hindi 
and Thai. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
4.3 Algorithm of the microcontroller 
operating program 
 
Step 1: Initialize the LCD 
Step 2: Custom character design 
Step 3: Switch press check 
Step 4: increase second from 0 to 59 
Step 5: Increase minute 0 to 59 
Step 6: Increase hour from 1 to 12 
Step 7: Convert each number in ASCII code 
Step 8: Show clock in bangle for switch =1 
Step 9: Show clock in English for switch =2 
Step 10: Show clock in Hindi for switch =3 
Step 11: Show clock in Thai for switch = 4 
Step 12: Go to step 3  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 5: Flow chart of the microcontroller operating program 
 
Page 532
  
4.4 Design of the numeric value for different 
language  
Microcontroller first initializes the LCD. Then 
declare the custom character. For design custom 
character we use custom code under the function. 
For generating the custom code, bascom-AVR 
software is used. In bascom-AVR software has a 
tool which can be applied for LCD design. First the 
custom character is designed by LCD designer. An 
example of one in Bangla is designed and given in 
figure no 6. Also figure no 7 shows the coding 
technique of design one in Bangla.  
 
 
 
Fig 6: Design procedure of one in Bangla language 
by the bascom-AVR software 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 7: Design procedure of one in Bangla language 
by the bascom-AVR software 
 
This custom code displaying one in bangla is given 
below.  
const uint8_t bn_one[8] PROGMEM=  
{ 
28 , 2, 1 , 1 , 13 , 18 , 12 , 32 
};  
 
Microcontroller sends this code in LCD RAM to 
show one in bangla in LCD. In this way different 
language such as Bangla, English, Hindi and Thai 
can be designed. After design the custom character, 
the program is applied to a loop and wait for the 
pulse from switch. After completing language 
designing program converts the all above number in 
ASCII code. 
 
5. SIMULATION CIRCUIT, WAVE 
SHAPES AND RESULTS 
 
 
 
Fig. 8: Simulation circuit of multi-language digital 
clock  
 
In simulation circuit a microcontroller Atmega 32 
and a LCD is used. Also outputs of different 
languages are shown in figure 9. (a) no is the output 
result of the clock in Bangla language. The 
language is displayed at the left-top corner of LCD. 
(b) no represents the bangle and English both 
language in LCD display. When input pulse of 
switch y=2 then the LCD show the bangle and 
English language. (c) shows the Hindi language 
clock time in LCD display. When switch y=3 then 
LCD display is activated for this language. (d) is 
next snap shoot figure of the LCD where it display 
the Thai language. When switch pressed in 4th time 
then the LCD displays the Thai language. 
 
 
 
(a) Bangla language 
 
Page 533
  
 
 
(b) Bangla and English language 
 
 
 
(c) Hindi language 
 
 
 
(d) Thai language 
Fig 9: Simulation results of multi-language digital 
clock 
 
6. CONCLUSIONS 
 
Our proposed designed microcontroller based 
multi-language digital clock is unique, cheaper and 
effective compare with others’. ATmega32 type 
microcontroller is used which is available and easy 
to burn. The circuit is also very simple. The most 
advantage of our designed circuit can display multi-
language time in LCD display by switching system 
step by step. That is why it can be used in that place 
where different cultural people gather together. 
 
 
REFERENCES 
 
1. Benkrid, K., Benkrid, A. and Belkacemi, S., 
(2007), Efficient FPGA hardware 
development: a multi-language approach, 
Journal of Systems Architecture, 53(4), pp. 
184-209  
2. Online documentation about digital clock  is 
viewed on 10 October, 2010, the web site at: 
http://www.kmitl.ac.th/~kswichit/clock/clock.h
tm 
3. Online documentation about Thai language is 
viewed on 10 October, 2010, the web site at: 
http://en.wikipedia.org/wiki/Thai_numerals#Z
ero_to_nine 
4. Online documentation about Hindi language is 
viewed on 10 October, 2010,the web site at: 
http://en.wikipedia.org/wiki/Hindu%E2%80%
93Arabic_numeral_system  
5. Online documentation about Protious 7.6 is 
viewed on 10 May, 2010, the web site at:        
http://www.atmel.com/dyn/resources/prod_doc
uments/doc2503.pdf 
Page 534
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: R. R. Mahmud,  
E-mail: r.r.mahmud@gmail.com  
DESIGN AND SIMULATION OF AUTOMATIC LOAD CONTROL 
WITH HUMAN COUNTING SYSTEM OF A SPACE 
 
 
R. R. Mahmud*, M. Shahed 
Lecturer, Dept. of EEE, Ahsanullah University of Science and Technology (AUST), Bangladesh 
 
M. S. Salman  
Student, Dept. of ETE, Rajshahi University of Engineering and Technology (RUET), Bangladesh  
 
 
This paper presents design, simulation and implementation of a microcontroller based automatic load control 
(for summer-fan and light, for winter only light) with human counting system of a space. The design part 
contains one hardware portion (Ac to DC converter, IR transmitter and receiver sensor, LCD display and a 
microcontroller) and another software portion (program for operating microcontroller). Normally loads are 
switched on and switched off manually by human of a room. The proposed design circuit can control loads 
automatically according to the human entry and exit from a room and count the number of people who are 
present in that place. This is a new research circuit to build digital Bangladesh and to save the power as a 
person has a nature that he forgets to OFF the load when he exits from a room. Again our research device is 
very cheap to implement and has many advantages for human life. Detail design procedures i.e., block 
diagram, circuit design, algorithm, flow chart, description of the microcontroller program and outputs of the 
simulation and practical circuits are presented in this paper. Design steps are presented in a sequential 
manner that would be advantageous for the beginners as well as for the advanced readers who are interested 
to work with microcontroller. 
 
Key words: Microcontroller; AC to DC converter; IR transmitter; IR receiver sensor and LCD display.  
 
1. INTRODUCTION 
 
An efficient use of room load control with counting 
system is very useful and demandable. Most of the 
time human are forgotten to off the load when he 
goes outside. It can also count the total people. 
Many efforts have been done in the field of power 
system, control of load and its parameters by a 
number of researchers. Our topic is different from 
the other researchers who have done their research 
on the same type controlling area. To show in 
difference between our findings and others, we 
would like to explain their researches. In 2009, D. 
Craciun et al proposed a new concept of residential 
consumers’ soft load shedding (SLS) [1]. It has 
taken only a fraction of the consumers’ power, even 
if the effort was spread over a larger number. 
Another author P. A. Gnadt explained the electric 
power distribution system [2]. In 2008 Essam E. 
Khalil designed residential variable load like 
residential air conditioning equipment control 
system with varying of line voltage and frequency. 
In 2008, F. Wernstedt and C. Johansson proposed a 
system about a field test where a distributed load 
control system uses load shedding to even out the 
daily fluctuations found in the energy demand 
within a district heating system. All the mentioned 
papers explained about the power system, room 
load control on the base on frequency and voltage. 
But so far as we know that there is no paper 
explains about room load control system with 
human entry and exit. So our paper is unique that is 
microcontroller based automatic load control with 
human counting system of a space. Again our 
proposed design implemented circuit of automatic 
load control system is cheaper, efficient and easy to 
implement.  
 
2. BLOCK DIAGRAM OF THE 
SYSTEM 
 
The microcontroller based automatic load control 
circuit works on the principle of when a person 
enters into a room, it automatically senses and 
counts the number of entries of the room or space 
and switch on the loads (for summer-fan and light, 
for winter only light) and also calculate when the 
people exit from that room or space and switch off 
the loads if there is no people in that place. Winter 
and summer season is considered on the basis of 
Page 535
ISBN: 978-984-33-2140-4
  
human demand. It only switch on the fans as a load 
in the case of winter and control both fans & lights 
in the case of summer. This circuit is capable of 
counting 255 people of a space or room; it means 8 
bits binary numbers which is considering 255 
successive entries. The general block diagram of 
the total system is given in the figure no 1. Here 
microcontroller is the main part of the system 
which controls the total system. Infrared (IR) is 
used for sensing the entry or exit of people and 
send the sensing signal to the microcontroller unit. 
Liquid crystal display (LCD) is displaying the 
counting result from IR sensor and microcontroller 
unit. The relay operating block is used here for 
controlling and operating the loads according to the 
number of people. In this way the total system 
works.    
 
  
 
Fig. 1: Block diagram of the automatic load control 
with human counting system of a space 
 
3. CIRCUIT DIAGRAM OF THE 
TOTAL SYSTEM 
 
A schematic circuit design of the total system of 
automatic load control with human counting system 
of a space is given in the figure no 2. In this 
schematic circuit diagram, a microcontroller for 
executing logical operations is used here. A LCD 
display device is used to show the outputs of total 
no of people of the space or room. It is a low-power 
flat-panel display made up of a liquid crystal that is 
sandwiched between layers of glass or plastic and 
becomes opaque when electric current passes 
through it. Two relay circuits are used for switching 
purpose which are connected to the loads. A relay 
circuit is typically a smaller switch or device which 
drives (opens/closes) an electric switch that is 
capable of carrying much larger current amounts. 
Here a voltage regulator circuit is used to supply 
fixed DC voltage (i.e. 5 volt). It is a device or 
circuit that maintains a load voltage nearly constant 
over a range of variations of input voltage and load 
current. It used whenever the unregulated voltage 
would vary more than can be tolerated by the 
electrical equipment using that voltage. Some 
resistances are placed in suitable locations for 
limiting excessive current. This is the basic 
arrangement of this schematic circuit. In this circuit 
diagram two sets of IR LEDs as a transmitter and 
receiver arrangement are used. IR LEDs emit or 
demodulate energy in the infrared radio spectrum. 
This arrangement is done for determining either 
entries or exits of people from the room. If first 
sensor detects the object first and then second 
sensor detects, in this case it operates on entry 
mode. On the other side if the second sensor detects 
the object first and then first sensor detects the 
object, in this case it operates on exit mode. A 
microcontroller (ATmega8) is burned with a 
program to operate the whole system. A burner 
circuit is given in the figure no 3. It has 40 pins. Pin 
14 and 15 are used for connecting IR sensors as 
input operation. Pin 7 and pin 1 is connected with a 
1K resistance through the Vcc. Pin 8 is grounded 
and a resistance 1K is connected between pin 8 & 
pin 11. A Vcc voltage is supplied to the pin 7 and 
11 through a switch. Pin 23 to 26 are used as data 
outputs of the display device where pin 17 is used 
to enable the display and 28 set or reset the data. 
Here LED- and LED+ of the display device show 
the output flashing green light. Here Vss, Vo, R/W, 
LED- are grounded and Vdd and LED+ are 
supplied by Vcc voltage. 
 
 
 
Fig. 2: Schematic circuit design of the automatic 
load control with human counting system of a space 
 
 
 
Fig. 3: Interface between microcontroller and 
computer for burning 
Page 536
  
Start
Read Sensor Data
End
Entry/Exit?Increment Count Entry
Decrement 
CountExit
Count>0? Turn Off LoadsTurn On Loads NoYes
Yes
Display the data
4. SOFTWARE PORTION 
 
It contains microcontroller, simulation software, 
programming flow chart, algorithm of the program. 
 
4.1 Microcontroller    
The main part microcontroller is a programmable 
device which contains a microprocessor, memory 
as same as a single chip computer. As 
microcontroller is a low cost programmable device, 
it is used in the automatic control application like 
robot, microwave oven, digital watch, mobile 
phone, electronic display and some conditions 
where circuit is difficult. The block diagram of the 
microcontroller is given below in the figure no 4. A 
liquid crystal display (LCD) is a thin, flat electronic 
visual display that uses the light modulating 
properties of liquid crystals (LCs). This is used in a 
wide range of applications including computer 
monitor, television, instrument panels, aircraft 
display and also in consumer devices such as video 
players, gaming devices, clocks, watches, 
calculators, and telephone. This model has 20 
character and four lines. This LCD operate in +5v.  
and pin configuration of the LCD is given in the 
figure no 5. 
 
 
 
Fig. 4: Block diagram of microcontroller 
 
 
 
Fig. 5: Pin configuration of LCD 
 
4.2 Simulation software 
Proteus 7.6 is a software for microprocessor 
simulation, schematic capture and printed circuit 
board (PCB) design [5]. It is developed by lab 
center electronics. The XGamestation micro edition 
was designed using lab center’s proteus schematic 
entry and PCB layout tools. Also AVR Studio 4 
provides a complete set of features including 
debugger supporting run control including source 
and instruction-level stepping and breakpoints, 
registers, memory and I/O views and target 
configuration and management as well as full 
programming support for stand alone programmers. 
 
4.3 Algorithm of the program 
Step 1: Start. 
Step 2: Read sensor data. 
Step 3: Display data to LCD. 
Step 4: Check entry or exit. 
Step 5: If Entry occurs increment the count. 
Step 6: If Exit occurs decrement the count. 
Step 7: If Count greater than 0 turn ON the loads 
and go to step 2. 
Step 8: If Count equal to zero then turn OFF the 
loads and go to step 2. 
Step 9: Stop. 
 
4.4 Programming flow chart 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 6: Flow chart of the microcontroller operating 
program 
 
5. SIMULATION RESULTS AND 
CIRCUIT 
 
In the simulation circuits of figure 7 one 
microcontroller, one LCD and some sensors are 
used. In this section we have showed some 
simulated results of this system using computer 
simulation software. In the (a) simulation snap shot 
Page 537
  
where switch is either summer or winter mode and 
the counting result is zero. The LCD display shows 
that all loads are off indicating winter or summer 
and that is why the counting result is zero. In the 
(b) simulation where one entry occurs then the 
previous result is incremented by one and the LCD 
display shows all loads (fan and light) are on means 
summer season. In the incrementing technique, the 
snap shot (c) shows that the counting result is 255 
means the total number of people in that space or 
room is 255 which can be calculated by the sensor 
signal and microcontroller and all loads are on in 
that situation. In the (d) simulation result shows 254 
no of people are present in that place when one 
exits then the number of person is decremented by 
one from the previous result and shows the number 
of person is 254 at the mode of summer season. In 
this way for each number of exiting person, it 
automatically decrement the result from the 
previous one and shows result on the LCD display. 
In the (e) simulation where one entry occurs then 
the previous result is incremented by one and the 
LCD display shows winter load only light is on 
means winter season. In the incrementing 
technique, the snap shot (f) shows that the counting 
result is 255 means the total number of people in 
that space or room is 255 which can be calculated 
by the sensor signal and microcontroller and only 
winter load (light) is on in that situation.    
 
 
(a) 
 
 
(b) 
 
(c) 
 
 
(d) 
 
 
(e) 
 
(f) 
Fig. 7: Snap shot of the results of simulated circuit 
Page 538
  
6. CONCLUSIONS 
 
Our proposed designed circuit is a new research 
circuit to build digital Bangladesh and to save the 
power as a person has a nature that he forgets to 
OFF the load when he exits from a room. Again our 
research device is very cheap to implement and has 
many advantages for human life. So it is unique and 
very essential for human life. 
 
 
REFERENCES 
 
1. Craciun, D., Ichim, S., and Bésanger, Y., 
(2009), A new soft load shedding: power 
system stability with contribution from 
consumers, accepted to the IEEE 2009 
Bucharest Power Tech Conference, Bucharest, 
Romania. 
2. Gnadt, P. A., Lawler, J. S., and Whitfield, E. 
W., Automating electric utility distribution 
systems: the athens automation and control 
experiment, prentice hall. 
3. Khalil, E. E. and Shalaby, M. F., (2008), 
Experimental investigations of variable load 
control in residential air conditioning 
equipment, 46th AIAA Aerospace Sciences 
Meeting and Exhibit, 1166, Reno, Nevada.  
4. Wernstedt, F. and Johansson, C., (2008), 
Intelligent distributed load control, 11th 
International Symposium on District Heating 
and Cooling, held on August 31 to September 
2, 2008, Reykjavik, ICELAND. 
5. Online documentation about Protious 7.6 is 
viewed on 10 May, 2010, the web site at:        
http://www.atmel.com/dyn/resources/prod_doc
uments/doc2503.pdf 
 
 
 
Page 539
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Md. Jahirul Islam,  
E-mail: jahirul_kuet@yahoo.com 
DESIGN OF AlAs/GaAs/Ge LATTICE MATCHED MULTIJUNCTION 
SOLAR CELLS 
 
 
Md. Jahirul Islam1* Md. Habibullah2  Sk. Hasan Hafizul  Haque 3 Md. Rejvi Kaysir  4 
 
 
1, 2, 3, 4
 Department of Electrical & Electronic Engineering  
Khulna University of Engineering & Technology 
Khulna-9203, Bangladesh.  
 
 
Abstract - This paper reports the theoretical design and performance analysis of AlAs/GaAs/Ge based triple 
junction solar cell. We have calculated the efficiency of the lattice matched solar cells, considering the effect 
of reflection coefficient. The efficiency of the proposed lattice matched triple junction solar cell is also 
compared with the lattice mismatched triple junction solar cells. The current matching is done by varying the 
thickness. The increase in surface recombination velocity and emitter thickness decreases the efficiency. 
However, the increase in minority carrier life time in emitter and base, doping density increase the 
efficiency. In order to get more accurate results, the effect of depletion width was taken into account. 
However, no significant change is observed between the results –without and with considering the depletion 
width. The efficiency of the proposed solar cell has been found approximately 43.5%. The effect of 
reflection coefficient also has been considered. The efficiency is found to be varied from 23 % to 37% with 
considering reflection loss. This simulated model shows that the proposed model can largely increase the 
efficiency with increasing the number of junctions. 
 
Key words: multijunction; AlAs/GaAs/Ge; lattice matched; minority carrier lifetime; depletion width. 
 
1. INTRODUCTION 
 
Photovoltaic solar cell is becoming widespread and 
very important as a clean and gentle energy source 
for the earth. However, still the efficiency of 
conventional and commercially available solar cells 
is very low. To be competitive with the 
conventional energy source the efficiency of 
photovoltaic cell must be improved. Searches for 
new photovoltaic cells with higher efficiency are 
being conducted all over the world from the 
beginning of this decade. Attempts have been made 
to fabricate photovoltaic cells with materials other 
than silicon and with no lattice mismatch. The same 
time modifications in design are being carried out 
to reduce the reflected component of solar energy 
due to lattice mismatch. 
 
Because of the limitations in the ability of a one-
junction solar cell to utilize efficiently the photons 
of the broad solar spectrum, multifunction solar 
cells have been the focus of much theoretical and 
experimental work in the past few decades. Multi 
junction solar cell is being widely studied over the 
world as the promising approaches to increase the 
efficiency. It has been shown that, theoretically the 
efficiency of MJ solar cells increases as it 
incorporates more & more junctions (Henry, 1980). 
However, practically there is a very little range of 
material that could be used to make these cells. A 
major challenge in achieving widespread use of 
solar cells lies in the identification of suitable 
materials with     appropriate lattice and band gap 
matching. To improve the efficiency of multi 
junction solar cells, some challenges have been 
faced. These are lattice mismatch, band gap 
mismatch, recombination before drift, reflection at 
top surface (Kasap, 2005), top surface contact 
obstruction etc. Due to lattice mismatch, generated 
carrier will be recombined in the defect of the 
lattice. After considering the effect of lattice 
mismatch the efficiency of the proposed solar cell 
has been found approximately 43.5% & the 
approach targeting 50% efficiency is proceeding 
using the invert lattice mismatch quantum well 
solar cells (Takamoto, 2009). In this paper we have 
also find out the effect of anti reflection on MJ 
solar efficiency. 
 
2. MODELING OF MJ SOLAR CELL 
Solar cell design is the most important requirement 
to improve the efficiency of MJ solar cell. 
Page 540ISBN: 978-984-33-2140-4
  
Currently used MJ solar cells are based on two or 
three layers of different material which are usually 
lll-V semiconductors (Yamaguhi, 2003). But lattice 
constant of different junctions are not same. Due to 
lattice mismatch the efficiency decreases. So 
AlAs/GaAs/Ge based solar cell has been proposed 
for higher efficiency. For designing this solar cell, 
the materials are used in buffer layer, tunnel 
junction that have nearly same lattice constant and 
this help to improve the efficiency (Geisz et. al., 
2005). These layer acts as antireflection coating 
which reduces the refection of incident light. The 
figure 1. shows the schematic illustration of the 
proposed AlAs/GaAs/Ge MJ solar cell.  The sub 
cells are arranged from bottom to top with lower to 
higher the band gap. Tunnel junctions are placed 
between the layers of a MJ to avoid the formation 
of junction as well as potential barrier between the 
layers. However dislocations at the interference of 
the GaAs and Ge are limiting the cell efficiency. 
This propagation often causes Shockly-Read-Hall 
recombination in the active cell regions. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 1: Schematic illustration of the proposed lattice 
matched solar cells. 
 
To reduce the number of dislocations and cease 
their propagation through the upper layers of the 
junction cell, step graded buffer layers of InGaAs is 
used. Thus the lattice constant remains same due to 
small composition of In. 
 
3. PERFORMANCE OF AlAs/GaAs/Ge- 
LATTICE MATCHED MJ SOLAR CELLS 
 
However performance of solar cells depends on the 
choice of material used, the direction of light 
energy incident  into the pn junction, the number of 
junctions between the cells, the matching of the 
lattice of the used compound alloys and so on. 
 
The amount of light energy absorbed by the pn 
junction of solar cell is one of the important issues 
in performance evaluation. The less the reflection 
of incident light, the more efficient the solar cell is.  
 
Fig. 2: Efficiency variation of solar cell with 
respect to reflection coefficient. 
 
Figure 2. shows the graphical representation of 
reflectance or reflection coefficient and efficiency 
of lattice matched AlAs/GaAs/Ge-based multi 
junction solar cells. When the percentage of 
reflectance is increased then the efficiency of the 
solar cells is decreased. 
 
The current densities for electrons and holes are: 
   µ 	 


 ′
 
And 
   µ  


 ′
 
 
In the case of an n on p junction with an n-type 
emitter and p-type base the expression for the top 
side of the junction is given by 
 




	 1  
  
 !
 0  
 
Solving this equation the photocurrent is obtained a 
0 5 10 15 20 25 30 35 40
0
10
20
30
40
50
% Reflection coefficient
%
 
Ef
fic
ie
n
cy
Ag Electrode          
AR  
Coating          
        
Intermediate           
        Cell 
Bottom 
Cell 
Top 
Cell 
 
    BSF 
p-GaAs Base 
n-AlAs Emitter 
Window 
 
 
 
    BSF 
 
p-GaAs Base 
 
n-AlAs Emitter 
Window 
 
 
    BSF 
p-GaAs Base 
n-AlAs Emitter 
Window 
Page 541
  
 
  [
1 − $
(%$% − 1                                                                    
×
' ($
 + $) − 
*(($
 cosh '
/ $0 ) + sinh'
/ $0 )
($

 sinh '
/ $0 ) + cosh'
/ $0 )
 
− $3*] 
 
  Fig. 3: Variation of shot circuit current with 
number of junctions. 
 
Open circuit voltage 
 
 567 
89
:
× ln (<!=< + 1  
Where, 
 > = ?%( @*A*BC +
@!*
A!*BD , F = 1,2,3… 
 
Short circuit current decreases as the number of 
junctions increases. Simulation result shows that 
with the increase of number of junctions from 
single to triple short circuit current decreases about 
35%. This result is shown in figure 3. Figure 4 
shows the variation of open circuit voltage with the 
number of junctions. Open circuit voltage increases 
with increasing the number of junctions. For 
choosing of a new junction material, care has been 
taken about lattice constant so that lattice mismatch 
does not create in designing of MJ solar cells. 
 
 
Fig. 4: Variation of open circuit voltage with 
number of junctions. 
As the number of junctions i.e. the number of cells 
increases short circuit current decreases and open 
circuit voltage increases which consequently causes 
the increase of solar cell efficiency. Figure 5 shows 
the efficiency vs. number of junctions relationship. 
Simulation result shows that efficiency increases 
about 30% as the junction number increases from 
single to triple. 
 
Fig. 5: Efficiency variation of solar cell with 
respect to number of Junction. 
 
Surface recombination velocity influence on the 
short circuit current. Higher the recombination 
velocity, lower the short circuit current. Lattice 
matched solar cell causes minimum short circuit 
current which increases the efficiency of the solar 
cells.  
 
Fig. 6:  Effect of surface recombination velocity on 
short circuit current. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
0 1 2 3 4
0
5
10
15
20
25
Number of junctions
Sh
o
rt 
ci
rc
u
it 
cu
rr
en
t (m
A)
0 1 2 3 4
0
0.5
1
1.5
2
2.5
Number of junctions
O
pe
n 
ci
rc
u
it 
v
ol
ta
ge
(v)
0 1 2 3 4
0
10
20
30
40
50
Number of junctions
%
 
Ef
fic
ie
nc
y
0 2 4 6 8 10
x 105
0
5
10
15
20
25
Surface recombination velocity(cm/s)
Sh
o
rt 
ci
rc
ui
t c
ur
re
nt
(m
A/
cm
2 )
Page 542
  
 
Table 1: The Detail Simulation Results of Lattice 
Matched MJ Solar Cells. 
 
Param
eters 
Ge GaAs AlAs 
NA 1016   cm-3 1016   cm-3 1016   cm-3 
ND 1018   cm-3 1018   cm-3 1018   cm-3 
ni 2.33*1013 
cm-3 
1.84*106 
cm-3 
57.16 
cm-3 
NC 1.04*1019   
cm-3 
6.0*1018   
cm-3 
1.2*1019   
cm-3 
NV 4.45*10197 
cm-3 
7.72*1018  
cm-3 
4.62*1019 
cm-3 
Jo 7.2*10-3  A 1.1*10-14  A 8.9*10-25 A 
Voc 0.20V 0.7928V 1.33V 
VT 2.3228 V 
 
Table 2: Comparison table between lattice matched   
and mismatched triple junction solar cells. 
 
Open circuit 
voltage  
Voc (V) 
Short circuit 
current 
Jsc (mA/cm3) 
Efficiency (η) 
Lattice 
matched 
Lattice 
mismatched 
(InGaN) 
Lattice 
match
ed  
Lattice 
mismatche
d 
(InGaN) 
Lattice 
match
ed  
Lattice 
mismatc
hed 
(InGaN) 
2.3228 2.683 22 15.94 43% 37.73% 
 
 
4. CONCLUSION 
 
The theoretical design and performance of lattice 
matched AlAs/GaAs/Ge-based multi junction solar 
cells have been studied. The design and 
performance evaluation are made by developing a  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
simulation model which optimizes the design of 
lattice matched AlAs/GaAs/Ge MJ solar cells for 
high efficiency. The performance evaluation and 
theoretical analysis of efficiency and performance 
of the proposed model shows the efficiency 
approximately 44%. The lattice mismatch is made 
to about nil. This causes the surface recombination 
velocity higher and short circuit current less. The 
current of each junction are made equal by 
adjusting the thickness of the emitter. Some major 
challenges in fabrication such as tunnel junction, 
buffer layer, and anti reflection coating are solved. 
All these results show that the proposed 
AlAs/GaAs/Ge- based multi junction solar cell is an 
excellent candidate for future high efficient MJ 
solar cells. 
 
REFERENCES 
 
1.   Geisz, J.F, Oison, J.M., Friedman, D.J., Jones, K.M., 
Reedy, R.C. and Romero, M.J., (2005), National 
Renewable Energy Laboratory, Golden, CO 80401 
USA. “Lattice-Matched GaNPAs-on Silicon Tandem 
Solar Cell”. 
2.   Kasap, S. O., (2005), Electronic Materials and 
Device. 
3.   Takamoto Tatsuya, (2009), Status of Multijunction 
Solar Cells and Future Development, CS MANTECH 
Conference, Tampa, Florida, USA. 
4.   Henry, C. H., (1980), Limiting efficiencies of ideal 
single and multiple energy gap terrestrial solar cells, 
Journal of Applied Physics, 51(8), pp. 4494-4499. 
5.  Yamaguchi, M., (2003), Free electron concentration 
and mobility of InN and In0.68Ga0.32N as a function of 
displacement damage dose measured by the Hall 
Effect, Solar Energy materials & Solar Cells, 75, pp. 
261-269. 
 
      
Page 543
Proceedings of the 
International Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
2
 Corresponding Author: M.S.R. Shoaib, 
E-mail: shoaibeee@gmail.com 
DESIGN OF VLSI PAD FRAME TOWARDS A LOW POWER I/O 
ARCHITECTURE WITH AN EFFICIENT FLOORPLANNING 
 
 
Rumana Amin1, Imran Chowdhury1, M.S.R. Shoaib1, 2, 3 
 
1Department of Electronics & Communication Engineering 
1University of Information Technology & Sciences (UITS), Dhaka, Bangladesh 
2Bangladesh University of Engineering and Technology (BUET), Dhaka 
3Bioelectric Research Lab, Dhaka, Bangladesh 
 
 
In today’s VLSI field the exponentially increasing factor of integration takes the techniques of chip 
designing to be more cared about both switch level (eg. device, logic gate design, etc.) and chip level (eg. 
pad design, floorplanning, routing, etc.) as size of chip is continually decreasing and power consumption 
challenge is getting tougher. To design a complete & successful functional chip, pad frame design and 
floorplanning are also challenging. This study is an attempt to present a VLSI design of pad frame with less 
power consuming I/O architecture with an efficient way of floorplanning which includes block placement, 
global routing, detail routing. MAGIC is used as layout designing CAD tool to design the pad frame as it is 
the easiest and worldwide CAD tool for VLSI layout design, and for simulation purpose PSpice is used. This 
study presents details of the key research work, results, techniques and efficient way of pad frame design as 
well as floorplanning. 
 
Key words: Pad; Pad-frame; Leaf-cell; Floorplanning; Global routing; Detailed routing.  
 
1. INTRODUCTION 
 
Number of transistors fabricated on a chip doesn’t 
follow the Moore’s law any longer since about 5 
years. It is increasing exponentially and violating the 
law every day. With the rapid development of VLSI 
fabrication technologies, we have reached an era 
where the minimum feature sizes of the leading 
processes are well below 1µm. Such processes are 
called Deep Sub-Micron (DSM) processes [1]. More 
specifically we are in the pre-nanotech era where 
already the IBM fabrication processes available 
through MOSIS range from 45nm to 0.25µm in 
CMOS [2]. For educational experiment purpose 
0.5µm and 0.6µm processes are very common 
today, and the process keeps changing. This 
changing scenario of the VLSI fabrication process 
and technologies takes more thought about pad 
design and floorplanning because both of them are 
process-specific, mostly pad design. 
 
VLSI chip is a rectangular area with I/O pads 
arranged along the perimeter of the chip in which 
cells are laid out surrounded by routing channels. 
Cells (modules or blocks) are logic models of a 
rectilinear shape with a predefined internal layout. 
Nets are physical wires that provide 
interconnections between cells [4]. 
 
 
Fig 1: A precise view of pad and its position [10]. 
 
Nets are laid out on a reserved chip space known as 
a routing channel [4]. In simple, pads are the 
intermediate junction distributed around the edge of 
the chip to keep connection between the chip core 
and the outside world through the package leads. 
Page 544
ISBN: 978-984-33-2140-4
  
Pad design is a chip level design which is connected 
to the package leads by bonding wires. 
Floorplanning is also a chip level design in which 
leaf cells are used as building blocks and wiring 
(routing) is done to connect the blocks to the pads 
[5] such that the congestion of bonding wires, 
parasitic effects between wires, and area 
consumption are reduced to possibly minimum. 
 
The paper is organized as follows. Section 2 
represents the design of leaf cells, section 3 
describes the detail of pad frame designing, section 
4 describes the block placement and routing with the 
designed leaf cells and pad frame for floorplanning 
purpose. Section 5 describes the results of the study, 
and section 6 concludes the paper. 
 
2. LEAF CELL DESIGN 
 
Leaf cells or leaf layouts are gate-level cells that are 
logic models containing up to a hundred transistors 
[3] used as blocks during floorplanning. In this 
study this is not the concern as the paper is focused 
on pad frame and floorplanning. So for the sake of 
simplicity a NAND, NOR, and inverter buffer are 
used as predesigned leaf cells for example. In our 
previous paper [6], the requirements and way of 
designing leaf cell is described. Figure 2 represents 
the layouts of predesigned cells. 
 
 
 
Fig 2: Optimized layout of a NAND gate (A), NOR 
gate (B), Inverter buffer (C), and a single Inverter 
(D) in sense of area consumption, hence power, 
with W/L=3λ/2λ for nMOS and W/L=6λ/2λ for 
pMOS. In the buffer stage W/L of 2nd stage inverter 
is double than 1st stage inverter. 
 
3. PAD FRAME DESIGN 
 
A chip is not very useful if it cannot be connected 
to the outside world. Pads do this connection job 
through the package leads. But unfortunately there 
are no true rules by MOSIS for generic pad design 
except the minimum size of a pad is 90µmX90µm 
[2]. A pad is a large piece of metal to which the 
external wire is soldered and typically uses all 
layers of metal [7]. In this study purpose, 3 metal 
layers pad is designed with minimum area of 
90µmX90µm and efficient contact placement 
which is reliable against bonding failure [8-9]. The 
pattern of vias over the pad is rectangular. It can be 
changed depending on the flexibility, choice of 
designer, or electromechanical optimization issues. 
The required commands and design methodology 
of the layout (pad in this case) are studied and 
described in our 1st paper [6]. Figures 3, 4, 5, and 6 
below represent steps of the pad design. 
 
 
 
Fig 3: metal3 with minimum area of 90µmX90µm 
(A), metal2 over metal 3 with the same area (B). 
 
 
 
Fig 4: via2 between metal2 and metal3 (A), metal1 
over figure A. 
 
 
 
Fig 5: via1 between metal1 and metal2 at the 
perimeter of the pad to avoid bonding failure by 
expansion of metal1 due to high heat produced 
during welding (A), metal1 soldered to the pad for 
on-chip wire connection (B). 
 
Pad placement is used as the seed for the cell 
placement [11]. Placing I/O pads around a VLSI 
chip boundary is a problem such that it leads to a 
reduction in the cost of cells placement. Pad 
Page 545
  
placement is typically done as the last stage in a 
VLSI layout design. However, some cell placement 
packages are sensitive to the pad placement and 
require such placement to be done first [12]. 
Normally the total chip layout in the die is covered 
with glass to protect it from further oxidization 
after fabrication. Since pads need to be connected 
to the package leads by bonding wire (generally 
gold or silver wire), some area over the pads must 
be keep away from glass covering for welding the 
bonding wires, which is called glass opening. In 
this study 60µmX60µm area is kept for glass 
opening. The predesigned leaf cells need total of 16 
pins considering 3 pads for Vdd and 3 for GND. 
For a 16-pin package that is available in MOSIS the 
pad frame is arranged with 16 pads having 4 pads 
in each side of it and keeping 10µm distances from 
each other. 
 
 
 
Fig 6: 16-pin pad frame with the designed three 
metal layer pads. 
 
4. FLOORPLANNING 
 
When designing a leaf cell, transistors, vias, and 
metals are used as the basic components. But 
floorplanning uses the designed leaf cells as the 
building blocks. Floorplanning is chip level design. 
It is divided into three phases: block placement, 
global routing and detailed routing. Global routing 
assigns wires to routing channels between the 
blocks; detail routing designs the layouts for the 
wiring [5]. Proper placement of logic blocks can 
reduce routing congestion between the I/O pads and 
logic blocks, connected to those and thereby helps 
to achieve good quality routing. Besides the logic 
block placement, exact positioning of the input-
output pads, also known as pad frame generation, is 
quite significant to ensure quality placement [13]. 
In this study 1st of all 4 blocks of predesigned 
modules are placed on assigned area for those. 
Then pins are assigned to each block. Block 
placement is given in figure 7 below that shows 
rational aspect ratio of designed device layouts and 
positions of their pins. 
 
 
 
Fig 7: Block placement of 4 leaf cells. 
 
The predesigned 4 leaf-cells have 18 terminals in 
total, including input, output, supply and ground. In 
the designed pad frame of 16 pads surrounding the 
chip core, 10 pads are assigned for inputs and 
outputs, 3 for power and 3 for ground. The pin 
configuration detail is given in table 1. 
 
Table 1: Pin configuration. 
 
Modules Pin name Pin# 
NOR Gate 
In1 15 
In2 1 
Out 2 
NAND Gate 
In1 11 
In2 12 
Out 14 
Inverter In 6 Out 5 
Inverter Buffer In 7 Out 8 
GND and Vdd for all modules Pin# 
GND 9, 10, 13 
Vdd 3, 4, 16 
 
Conventionally and according to the MOSIS 
specification the pad is very larger than any single 
wire connected to it. So the current in each 
direction is limited by the outgoing wire, and to 
limit inductive voltage drop, several Vdd and Gnd 
can be used [5]. 
 
In floorplanning, routing is come after block 
placement. Routing can be done by manually using 
hand, or using interactive tools. In this study block 
Page 546
  
placement and routing is done by hand first, and 
then MAGIC “box” tool is used to complete the 
design. For global routing the Vdd ring and Gnd 
ring are drawn with 9λ, and in detailed routing, 
connections are given by metal of 3λ of width to 
balance the supply in each direction. The figure 8 
below shows the complete pad layout with modules 
after floorplanning and block placement. 
 
 
 
Fig 8: Leaf cells in designed pad frame with 
complete chip structure after block placement and 
routing. 
 
5. RESULTS & DISCUSSION 
 
The designed complete chip layout consumes total 
of 1967λX1967λ or 491µmX491µm with the pad 
frame in CMOS 0.5µm process. This is very less 
area consuming and at the same time low power 
consuming. The designed leaf cells dissipates 
power of 4.15 milliwatts, 1.14 milliwatts, 0.35 
nanowatts, and 2.08 milliwatts respectively for 
NAND gate, NOR gate, Inverter Buffer, and single 
Inverter. The simulation results for the inputs-
outputs of the modules are given in figures 9, 10, 
11, & 12. 
 
 
 
Fig 9: PSpice simulation result of designed NAND 
gate from the MAGIC extraction file. 
 
 
 
Fig 10: PSpice simulation result of designed NOR 
gate from the MAGIC extraction file. 
 
 
 
Fig 11: PSpice simulation result of designed 
Inverter Buffer from the MAGIC extraction file. 
 
 
 
Fig 12: PSpice simulation result of designed single 
Inverter from the MAGIC extraction file. 
 
Pads used for input and output signals require 
different supporting circuitry which is called I/O 
architecture. The main job of an input pad is to 
protect the chip core from electrostatic discharge 
(ESD). Output pads do the job of driving the large 
capacitances seen on the output pin [5]. Input and 
output pads also do the job of maintaining the 
signal directions. The pad driver and ESD circuit of 
each pad occupies a certain amount of space, 
disallowing any other circuitry within that space 
and increase the total power consumption and 
Page 547
  
dissipation of entire chip. Besides, there are also 
power/ground (P/G) pads and analog pads. Analog 
pads are not used in this study. An important 
problem in P/G network design is to use the 
minimum amount of chip area for wiring P/G 
networks, while avoiding potential reliability 
failures due to electromigration and excessive IR 
drops [14]. As the size and power consumption and 
dissipation of the I/O architecture depend on the 
on-chip core circuitry, pad size, pad generation or 
pad placement, etc., so these are some important 
concern in designing a low power complete chip. 
 
In this study leaf cells are designed area-efficiently 
with ultra low power dissipations. Pads are 
designed with minimum area specification and 
reliable against bonding failure, and distributed 
equally around the edge of the chip as the order of 
pins is the fact to determine the routability of a 
system. They are sufficiently large to hold a wire 
and input or output circuitry but efficient in area 
consumption and power consumption as well. The 
chip core is fit in the mid of the pad frame. To 
reduce inductive voltage drop, 3 Vdd and 3 GND 
pads have been used which is maximum in this 
case. Block placement is done in a way that makes 
the routing path shorter. Wire bending is kept 
minimized to protect from parasitic inductive 
effect. Thus all the floorplanning job and pad frame 
design considerations is towards an efficient 
complete chip layout, hence the I/O circuitry is to 
be efficient corresponding to this whole work. 
 
6. COLCLUSION 
 
As fabrication technology keeps advancing, many 
deep sub-micron (DSM) effects have become 
increasingly evident and can no longer be ignored 
in VLSI design. Besides, increasing complexity and 
decreasing feature size have made the demand of 
more I/Os a significant problem to packaging 
technologies. So, a successful floorplanning and 
efficient pad frame design is very important and 
also challenging at the same time. This study is an 
attempt to design a pad frame with efficient 
floorplanning towards low power I/O architecture. 
It is also tried to make the on-chip circuitry area-
efficient having ultra low power dissipation so that 
I/O architecture or circuitry goes followed by that 
efficiency. Further study may be focused on more 
robust and efficient pad frame design and 
floorplanning using interactive tools with different 
and new approach. 
 
REFERENCES 
 
1. Sunil P. Khatri, Amit Mehrotra, Robert K. 
Brayton, Ralph H. J. M. Otten, Alberto 
Sangiovanni-Vincentelli, A Novel VLSI 
Layout Fabric for Deep Sub-Micron 
Applications, DAC 99, New Orleans, 
Louisiana. 
2. http://www.mosis.com/ 
3. Louis M. Monier Jeremy Dion, Recursive 
Layout Generation, WRL Research Report 
95/2, MARCH 1995. 
4. KHALED AL-ZAMEL and MUKKAI S. 
KRISHNAMOORTHY, Input/Output Pad 
Placement Problem, Department of Computer 
Science Rensselaer Polytechnic Institute, Troy, 
NY 12180, 1995, Vol. 3, No. 1, pp. 53-57. 
5. Wane Wolf, Modern VLSI Design, System-on-
chip Design, 3rd edition, pp. 7, 360-391. 
6. Imran Chowdhury, Rumana Amin, Md. 
Shoaibur Rahman, Sazzad Bin Kamal, Shuza 
Binzaid, PhD, MAGIC IN VLSI: A Precise 
Demonstration on MAGIC towards VLSI 
Layout Designing, Conference on Engineering 
Research, Innovation and Education 2011, 
CERIE-241. 
7. Louis Luh, John Choma, Jr., and Jeffrey 
Draper, AREA-EFFICIENT AREA PAD 
DESIGN FOR HIGH PIN-COUNT CHIPS, 
University of Southern California, CA 90089. 
8. Sultana, R. and Begum. A., (2010), A CMOS 
IC Using Nano-Power Electronic Circuits, 
Thesis, Department of Electronics and 
Communication Engineering, University of 
Information Technology and Sciences, Dhaka, 
Bangladesh, pp. 18-62. 
9. Personal & academic consultations with Dr. 
Shuza Binzaid, Founder and Director, SERES, 
Bangladesh, seres-usa.com 
10. I/O Pads, ECEN 5263 Digital VLSI Deign, 
September 19, 2005, pp. 1-5. 
11. Input/Output Pad Placement Problem, 
KHALED AL-ZAMEL and MUKKAI S. 
KRISHNAMOORTHY, Department of 
Computer Science Rensselaer Polytechnic 
Institute, Troy, NY 12180, 1995, Vol. 3, No. 1, 
pp. 53-57. 
12. C. Cheng, and E. Kuh, "Module placement 
based on resistive network optimization," IEEE 
Trans. Computer-Aided Design CAD-3 (July 
1984) pp. 218-225. 
13. R. Farbarik, X. Liu and M. RossmanThuy, 
CAD tools for area distributed I/O pad 
packaging, Proc. of IEEE Multi-Chip Module 
Conference (MCMC ‘97), pp.-125,1997. 
14. Sheldon X.-D. Tan, C.-J. Richard Shi, and Jyh-
Chwen Lee, Reliability-Constrained Area 
Optimization of VLSI Power/Ground 
Networks Via Sequence of Linear 
Programmings, IEEE Transaction On 
Computer-aided design of integrated circuits 
ans systems, vol. 22, No. 12, December 2003, 
pp. 1678-1684 
Page 548
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: M. Shahed,  
E-mail: engr.mshahed@gmail.com 
DESIGN, SIMULATION AND PERFORMANCE ANALYSIS OF 
HIGH VOLTAGE MULTISTAGE PULSE FORMING NETWORK 
 
 
M. Shahed*, O. Farrok, R. R. Mahmud  
Lecturer, Dept. of EEE, Ahsanullah University of Science and Technology (AUST), Bangladesh 
 
F. Eva  
Student, Dept. of EEE, Rajshahi University of Engineering and Technology (RUET), Bangladesh 
 
 
This paper presents design, simulation and performance analysis of high voltage multistage pulse forming 
network among two stages, four stages and ten stages system. A pulse forming network can be constructed 
using lumped energy storage elements like inductors and capacitors for 100 meters coaxial transmission line. 
The main purpose of the high voltage pulse forming system is to generate high voltage pulses within certain 
repetition rate using energy compression technique within very short time. Computer aided Orcad P-Spice 
simulation are suitable to analysis performance among various multistage pulse forming networks to 
conserve time and enhance efficiency. Detail design procedure with simulation results i.e., block diagram, 
circuit design, description of the system, simulation wave shapes and performance analysis among various 
multistage pulse forming networks are presented in this paper. Design steps are presented in a sequential 
manner that would be advantageous for the beginners as well as for the advanced readers who are interested 
to research with high voltage microwave pulse forming system. 
 
Key words: High voltage pulse; Pulse forming network; Lumped element.  
 
1. INTRODUCTION 
 
The Pulse Forming Network (PFN) is a simple 
network of producing very High Voltage Pulse 
within certain repetition rate using energy 
compression technique. Distributed parameter 
model can be used for generating High Voltage 
Pulse. Generally, a Pulse Forming Network (PFN) 
can be constructed using lumped energy storage 
elements such as, Inductors and Capacitors. 
However, High Voltage (HV) Pulse with short 
duration in order of hundreds of nanosecond (ns) 
can not be produced by lumped elements.  
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 1: Marx generator (multistage impulse circuit) 
A Marx Generator is a clever way of charging a 
pulse forming network. It is nothing but a 
Multistage Impulse Generator, shown in figure- 1. 
Originally described by E.  Marx in 1924, Marx  
generators are probably the most common way of 
generating short duration, high voltage impulses 
for testing when the voltage level required is higher 
than available charging supply voltages.  
In order to predict the output pulse under load 
mismatch conditions, the ideal model has been 
simulated for three possible conditions. If the Load 
impedance is equal to generator impedance, then it is 
called matched condition. If the Load impedance 
greater than the generator impedance then it is called 
Over- matched condition. Also, if the Load 
impedance is less than the generator impedance, than 
it is called Under- matched condition. Pulse forming 
network can be simulated using various software. 
In this work Pulse Forming Network System has 
been simulated using Orcad P-Spice. The results 
are compared with the existing ones. Here Orcad P-
SPICE Version No. 9.1 is used. SPICE is user 
friendly simulator widely used in circuit analysis. 
SPICE consists of a group of device files, one for 
each active circuit element, and one executable 
file, SPICE has a rich library for integrated 
circuits such as operational amplifiers, comparators 
Page 549
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
  
etc. The user can create a model for part of a circuit 
and save it as a sub-circuit and then use this sub-
circuit later. 
 
2. GENERAL BLOCK DIAGRAM OF       
THE TOTAL SYSTEM 
 
 
 
 
 
 
 
 
 
Fig. 2: General block diagram of the PFN 
 
Figure- 2 shows the general block diagram of the 
total system. The Pulse Forming Network (PFN) is 
charged by a Marx generator to a high voltage and 
discharged through the load. We get the wave 
shapes across the load. For three conditions 
matched, Over-matched and Under-matched the 
wave shapes are analyzed respectively for two, four 
and ten stage. These two, four and ten stage circuits 
are nothing but some multistage L-C circuits.  
 
3. CIRCUIT DESIGN OF 
DIFFERENT STAGE PULSE 
FORMING NETWORK 
 
The simplest form of PFN can be constructed using 
L (Inductors) and C (Capacitors). The number of 
stages used in a real PFN depends on the duration 
of this pulse. The amplitude of the pulse depends 
on the magnitude of the charged voltage. In this 
paper several PFN’s are simulated and the results 
are presented. The theory Circuit Model is used to 
analyze these PFN. Here consider a configuration 
of Circuit Model. The distributed parameters of the 
PFN supplied by the manufacturer's specification 
for 100 meter length are given below. 
 
Table- 1 
Manufacture's Specification 
 
Inductance per meter, L 0.605 µH 
Capacitance per meter, C 0.1 nF 
Series resistance per meter, R 157 µF 
Dielectric constant, ξr 2.5 
Characteristic impedance 50 Ω 
 
3.1 A two-stage PFN 
A two stage Pulse Forming Network (PFN) is 
simulated by Orcad P-SPICE Version No. 9.1. 
SPICE is a user friendly simulator widely used in 
circuit analysis. The values of inductor and 
capacitor are estimated for 100 meter transmission 
line. Here two inductors and two capacitors are 
used. Charging voltage across each capacitor is 200 
kV. Transition time of the closing switch in the P-
SPICE schematics decides the pulse rise and fall 
times, which is of the order of 1 µs.  
 
 
 
 
 
 
 
 
 
Fig. 3: PFN (Circuit model-2 stage) 
 
Figure- 3 depicts a two stage PFN. The element 
values are calculated using the pulse specification. 
Here the parallel capacitors are charged with a high 
voltage source, and discharged through the load 
resistance R1. Inductances are used to obtain the 
flat top of the pulse. 
 
3.2 A four-stage PFN 
A four stage Pulse Forming Network (PFN) is 
designed by P-SPICE. Here four inductors and four 
capacitors are used. The values of inductor and 
capacitor are estimated for 100 meter transmission 
line. The power discharged across the load via a 
switch. The element values are calculated using the 
pulse specification. 
 
 
 
 
 
 
 
 
 
 
 
Fig. 4: PFN (Circuit model-4 stage) 
 
Figure 4 depicts a 4-stage Pulse Forming Network 
(PFN). In this circuit, the values of capacitors (C) 
and inductors (L) are distributed in four identical 
sections. 
 
3.3 A ten-stage PFN 
A ten stage Pulse Forming Network (PFN) is 
simulated in figure below. Here ten inductors and 
ten capacitors are used. The values of inductor and 
capacitor are estimated for 100 meter transmission 
line. Here the circuit arrangement is largest among 
the three. The inductors are in the range of micro 
henrys and the capacitors are in the range of 
MARX 
GENERA 
TOR 
 
PULSE 
FORMING 
NETWORK 
LOAD 
Page 550
  
nanofarads. Figure- 5 shows a ten stage PFN. The 
element values are calculated using the pulse 
specification. 
 
 
 
 
 
 
 
 
 
 
Fig. 5: Pulse forming line (Circuit model-10 stage) 
 
4. RESULTS AND WAVE SHAPES  
 
Now we see the wave shapes of two, four and ten 
stage circuits for matched, Over-matched and Under-
matched conditions. X- axis represent voltage and Y-
axis represent time. In this wave shapes voltage 
ranges from -200 kV to 200 kV and the time ranges 
from 0 sec to 20 µsec. We compare among these 
wave shapes and determine that, which types of L-C 
circuit configuration are more efficient for high 
voltage (HV) pulse operation.  
 
Fig. 6: Matched load for  
2-stage circuit model (80 Ω) 
 
 
Fig. 7: Under- Matched load for  
2-stage circuit model (40 Ω) 
 
 
Fig. 8: Over- Matched load for  
2-stage circuit model (120 Ω) 
 
Figures 6, 7 and 8 depict the load voltage of two 
stage circuit for R1 =80Ω, 40Ω and 120Ω 
respectively. When R1= 80Ω, then matched 
condition (Load impedance = generator impedance) 
occurs, when R1= 40Ω then Under-matched 
condition (Load impedance < generator impedance) 
occurs and when R1= 120Ω then Over-matched 
condition (Load impedance > generator impedance) 
occurs. It can be seen from Fig. 7 that for R1 =40Ω, 
the PFN becomes under matched and the negative 
pulse appear due to multiple reflections. The pulse 
duration is about 4µs. 
 
 
Fig. 9: Matched load for  
4-stage circuit model (80 Ω) 
 
 
 
Fig. 10: Under- Matched load for 
 4-stage circuit model (40 Ω) 
 
Page 551
  
 
Fig. 11: Over- Matched load for 
 4-stage circuit model (120 Ω) 
 
Figures 9, 10 and 11 depict the load voltage of four 
stage circuit for matched load (80Ω), under-
matched load (40Ω) and over-matched load (120Ω) 
respectively. 
 
 
Fig. 12: Matched load for  
10-stage circuit model (80 Ω) 
 
 
Fig. 13: Under- Matched load for 
10-stage circuit model (40 Ω) 
 
 
Fig. 14: Over- Matched load for 
10-stage circuit model (120 Ω) 
 
Figures 12, 13 and 14 depict the load voltage of ten 
stage circuit for matched load (80Ω), under-
matched load (40Ω) and over-matched load (120Ω) 
respectively. It can be seen from the simulation 
results that, as the number of stages are increased, 
the shape of the pulse become rectangular. For 
example, a 10-stage Pulse Forming Network is 
shown in Figure- 5, the output for R =80Ω, is 
closest to a rectangular pulse. The ringing near the 
discontinuities is due to the convergence failure. 
 
5. CONCLUSIONS 
 
In this paper, several PFN’s are simulated results 
are presented for matched, Over-matched and Under-
matched conditions. The number of stages are 
increased, the shape of the pulse become 
rectangular for each conditions. We get more 
accurate pulse. In practice, a PFN is charged by 
means of a high voltage power source and then 
rapidly discharged into a load via a high voltage 
switch, such as a spark gap or hydrogen thyratron. 
The load may be a high power microwave oscillator 
such as a klystron or magnetron, a flash lamp, or 
even an electromagnet. Depending upon the 
application, the output Pulse Repetition Rate 
(PRR) may range from a fraction of a thousand of Hz. 
The high voltage (HV) pulsed power  technology  
has  drawn  renewed  interest  recently  due  to  its  
indispensable applications in the fields of pulsed 
high power microwave (HPM) generation. 
 
REFERENCES 
 
 
1. Naidu, M. S. and Kamaraju, V., (1983), high 
voltage engineering, tata mcgraw-hill. 
2. Jha, R. S., (1981), high voltage engineering, 
dhanpat rai and sons. 
3. Wadhwa, C. L., (1995), high voltage 
engineering, new age International (p) limited. 
4. Amin, M. R., (1996), distributed parameter 
simulation of a coaxial pulse forming Line, the 
institute of engineers, Bangladesh. 
5. Kuffel, E., Zaengl, W. S., high voltage 
engineering, pergamon press. 
Page 552
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: M. A. G. Khan 
E-mail: qmagk@yahoo.com  
DESIGNING BIREFRINGENCE OF INDEX-GUIDING PHOTONIC 
CRYSTAL FIBERS 
 
 
M. A. G. Khan*, S. M. A. Razzak and M. Y. Hussain  
Department of Electrical and Electronic Engineering, Rajshahi University of Engineering & 
Technology (RUET), Bangladesh  
 
 
This paper presents birefringence tailoring of photonic crystal fibers using artificial defects along one of the 
orthogonal axes. The APSSTM software based on the finite difference method with anisotropic perfectly 
matched layer boundaries is used as the design tool. According to simulation, it is shown that it is possible to 
design very high birefringence of the order 10-2 by creating artificial defects in a double control 
configuration. The effects of axial artificial defects on fiber birefringence are also investigated. Photonic 
crystal fibers having such high birefringence are crucial for optical fiber based sensing applications. PACS 
No: (42.81.-i) Fiber Optics; (42.81.Gs) Birefringence, Polarization; (42.25.Lc) Birefringence 
 
Key words: photonic crystal fiber, birefringence design, fiber design and characterization and finite 
difference method. 
 
1. INTRODUCTION 
 
Photonic crystal fibers (PCFs) [1] are made up of 
silica-air microstructure running down the entire 
fiber length. The silica-air microstructure contains 
microscopic air-holes arranged in a periodic or an 
aperiodic fashion [2]. Properties of such fibers are 
determined mostly by the positions and dimensions 
of air-holes [3]. A wide range of index contrast can 
be created between cores and claddings of these 
fibers (especially for index guiding PCFs that guide 
light based on the total internal reflection (TIR) 
mechanism) which effectively help tuning 
birefringence in addition to dispersion, leakage, and 
nonlinearity [4]. As a result PCFs are being 
considered nowadays in different areas of optics 
including both linear and nonlinear regimes [5].   
 
A fiber birefringence although usually an 
undesirable property, it is crucial for many 
applications including signal processing, optical 
communication systems, and more specifically 
sensing applications [6].  In sensing applications, 
fibers are often required to maintain a linear 
polarization state in order to reduce polarization 
coupling [6]. In fiber-optic gyroscopes and 
polarimetric sensors where high temperature 
variations are present, birefringence PCFs are more 
suitable for such applications because undoped 
silica PCFs offer high temperature stability as well 
as high power sustainability. As a result 
Birefringent PCF designs have attracted much 
attention over the past years [6]-[18].  There are 
various ways of designing birefringence in PCFs. 
Introducing anisotropic materials or applying 
stresses in the cladding region are among the ways 
that results in birefringence. Simply speaking in 
order to create birefringence it is essential to break 
the symmetry between two orthogonal axes. For 
PCFs, it is a general practice to change air-hole 
dimension of a pair of holes in either axis. In 
addition, considering fabrication constraints it is 
required to create defect near the core. Of the 
reported polarization maintaining (PM) PCFs [6]-
[18] to date, PCFs [6, 8] modulates air-holes, [7] 
has a microstructure core, [9, 10] scale down air-
holes dimension along one of the axes, and [11] 
uses a squeezed hexagonal lattice with elliptical air-
holes. Again, PCFs [12, 13] have air-holes defect in 
the core, [14, 15] use rectangular lattice structures, 
[16, 17] use respectively a stress applying part and 
two scaled-up air-holes near the core, and [18] has a 
squeezed hexagonal lattice.  These PCFs assume 
birefringence of the order 10-4 to 10-3 with various 
pitches. The PCF [11] with a squeezed hexagonal 
lattice and elliptical air-holes can provide 
birefringence of the order 10-2, the highest 
birefringence reported to date.  In this case, the 
pitch used is too small along the compressed axis. 
All these designs differ in birefringence magnitudes 
because of the variations in pitch values.  
 
In this paper, we have presented three closely 
related designs for achieving highly birefringent 
fibers based on an octagonal cladding concept. 
Page 553ISBN: 978-984-33-2140-4
  
Very high birefringence of the order 10-3 to 10-2 is 
confirmed by introducing artificial defects and a 
double control concept. We also have analyzed 
effects of artificial air-hole defects on the fiber 
birefringence. Although there are other ways of 
designing birefringence in the literature, such 
alternative designs for highly birefringent fibers 
might make the PCF technology valuable in future. 
Moreover, this type of investigation is also crucial 
for next generation PCFs where a PCF simply 
being superior to others with a single parameter can 
make its way for telecom and non-telecom 
applications [20].  
 
2. PCF MODELS 
 
Figs. 1-3 show PCFs with artificial axial defects. In 
the Fig.1 four pairs of air-holes are designated by 
numbers ‘1’, ‘2’, ‘3’, and ‘4’. This figure contains 
four different axial defect cases of PCFs namely 
model-1, model-2, model-3, and model-4.  Model-1 
is similar to the structure of Fig.1 except numbered 
‘1’ holes are missing. Model-2 is similar to model-1 
with numbered ‘2’ air-holes are missing. Similarly, 
model-3 represents the model-2 with numbered ‘3’ 
air-holes are missing and model-4 is similar to the 
model-3 with numbered ‘4’ air-holes are missing. 
Figs. 2 and 3 show model-5 and model-6 
respectively that represent  respectively model-2 
with two enlarged air-holes near the core and 
model-2 with 3 pairs of elliptical air-holes 
designated by numbers ‘1’ and ‘2’. The fiber pitch 
is Λ and Λ' being the pitch between adjacent air-
holes on a ring. The pitch Λ’ is related to Λ by the 
relation Λ' = 0.765Λ.  
 
3. SYNOPSIS OF THE SIMULATION 
METHOD  
 
In the APSS [23], the finite difference method 
(FDM) [19] with perfectly matched layer (PML) 
boundary is used as the main simulation tool. The 
computational window was surrounded by perfectly 
matched layers (PMLs) which are considered the 
efficient boundary conditions for the PCF 
simulation. For sufficient accuracy a dense mesh 
was used in both axial directions. Once the modal 
effective refractive index, neff was obtained by 
solving an eigenvalue problem drawn from 
Maxwell equations using FDM, birefringence B, 
beat length LB can be obtained using the following 
equations [10]- 
)()()( λλλ yx nnB −=                           (1) 
)()()(
)( λ
λ
λλ
λλ
Bnn
L
yx
B =
−
=
       (2) 
Where, nx is the real of neff along x-axis, ny is the 
real part of neff along y-axis, and λ is the 
wavelength. A detail methodology of the FDM is 
provided in the appendix. 
 
3. SIMULATION RESULTS 
 
Fig. 4 shows wavelength response of birefringence 
of ordinary octagonal PCFs. Since ordinary 
octagonal fibers have eight-fold axial symmetry, 
they show very low birefringence.  Fig. 1 depicts 
that the birefringence at 1550 nm is about 2×10-9. 
Therefore, such octagonal cladding PCFs can be 
used for applications where polarization 
insensitivity is crucial. Fig. 5 shows birefringence 
of octagonal PCFs with four-different defect cases 
as is illustrated in Fig. 1. We use d/Λ = 0.50, Λ = 
1.50 µm, and five-rings. It shows that fiber 
birefringence is directly related to the degree of 
defects. Increasing defects result in increased 
birefringence although the rate of increase differs. 
For example, the value of birefringence at 1550 nm 
is 2.95×10-3 for model-1 and it is 3.2×10-3 for 
model-2 resulting in an increase of 2.5×10-4. 
Further defects, for instance, model-3 and model-4 
although result in higher values but the changes are 
not noticeable.  We have seen similar results for 
both the pitches 1.0 and 2.0 µm. This investigation 
clearly dictates that the model-2 can be considered 
as an optimum defect case. With this consideration 
we then investigate the effect of air-filling fraction 
or equivalently air-hole dimension relative to the 
pitch on the fiber birefringence. Figure 6 shows 
birefringence at 1550 nm of the model-2 for three 
different pitches, d/Λ, and five-rings. We see that 
birefringence of the model-2 can be as high as 
8.25×10-3 and a corresponding beat length of 0.18 
mm at 1550 nm for d/Λ = 0.70 and Λ= 1.50 µm. 
Decreasing the pitch to 1.0 µm results in a very 
high value of birefringence of the order 0.018. 
Again, increasing the pitch to 2.0 µm results in a 
birefringence of 4.2×10-3 for the same d/Λ.  
 
The birefringence of model-2 can further be 
increased by using a double control technique i.,e., 
using two large air-holes (model-5) in one of the 
axes nearest the core of the model-2 as shown in 
Fig.2. Diameters of these two air-holes are made 
1.75 times larger than that of other air-holes. Fig. 7 
shows the corresponding results for model-5 and 
model-2. It can be seen in the figure that the 
birefringence at 1550 nm for the model-2 is 3.2×10-
3
 and it is 4.42×10-3 for the model-5. This means an 
overall increase of 1.22×10-3 is achieved by the 
double control technique. Finally, the original 
model-2 is again modified as shown in Fig. 3. Here 
three pairs of elliptical air-holes are used with 
ellipticities rx/ry = 0.67 and 1.5 respectively for 
Page 554
  
numbered ‘1’ and numbered ‘2’ air-holes of Fig. 3. 
With this modification, Fig. 8 shows the simulation 
results. It is clear from the figure that a very high 
value of birefringence of the order 0.015 is possible 
with d/Λ = 0.67, and a relatively higher pitch of Λ 
= 1.50 µm.  
       
In the light of above simulations, therefore, it is 
logical to conclude that the proposed octagonal 
structure PCFs may become potential alternative of 
the hexagonal fibers for both polarization 
insensitive and highly polarization maintaining 
applications.   
 
4. DISCUSSION 
 
We have used octagonal instead of conventional 
hexagonal structures for obtaining high values of 
birefringence. Such a structure is essential to 
implement the newly proposed double control 
concept. Moreover, octagonal structures offer wider 
single mode operation, higher nonlinearity, and few 
other advantages in comparison to hexagonal 
counterparts [24]. The only limiting factor for this 
structure is that the fabrication issue. Fortunately, 
fabrication precision and accuracy are advancing day 
by day. Reportedly the versatile stack and draw 
method can assemble structure of almost any size 
and shape [24]. It is forecasted that a fiber simply 
being superior to others to a single property would 
make the fiber technology valuable [25]. Therefore, 
we hope that the micro and nano-fabrication 
scientists will be able to find out a way to 
manufacture such structures in future.  
 
5. CONCLUSION 
 
Birefringence tailoring techniques as well as 
designs of highly Birefringent PCFs has been 
presented based the finite difference method. It has 
been shown by simulations that octagonal PCFs 
assume very low birefringence property in its 
ordinary form as well as very high birefringence of 
the order 10-2 by introducing axial artificial defects.  
 
6. APPENDIX 
 
Here we present a summary of discritization of the 
FDM method. The time-dependent Maxwell’s 
equations can be written in the following form [21]: 
 
E
rt
H
×∇−=
∂
∂
)(
1
µ
               (3) 
 
E
r
rH
rt
E
)(
)(
)(
1
ε
σ
ε
−×∇=
∂
∂
             (4) 
 
Where ε(r), µ(r) and σ(r) are the position-dependent 
permittivity, permeability and conductivity of the 
material, respectively. In FDM, Maxwell’s 
equations are discretized in space and time by the 
well known Yee-cell technique on a discrete three-
dimensional mesh. In photonic crystal fibers each 
of the above field components has take the 
form zieyxzyx βφφ ),(),,( = , where φ  denotes 
any field component and the propagation constant 
along the z-direction is β. When the z-derivatives 
are replaced by iβ, the equations can simply be 
expressed in terms of the transverse variables only. 
Fig. 9 depicts a two dimensional unit cell over the 
fiber’s cross section. Thus the x-component of 
Maxwell’s first curl equation becomes- 
 








∂
∂
−
∂
∂
−=
∂
∂
z
E
y
E
t
H yzx
µ
1
          (5) 
 
( ) ( ) ( ) ( ) ( )








−
∆
−+∆
−
−
=
+
jinyEiy
jinzEji
n
zE
ji
tji
n
xHji
n
xH ,
,1,
,
,
2
1
,
2
1
β
µ
                           
(6) 
Where n denotes the discrete time step, and i and j 
denote the discretized grid points in the x-y plane, 
∆x and ∆y are the intervals between two 
neighboring grid points, and ∆t is the time 
increment respectively. In a similar way, rest of 
field components can be obtained. 
 
In order to simplify the complex computation it is 
assumed that Ez, Hx, and Hy have components 
)cos( φβ +z (with real amplitudes) and Hz, Ex, 
and Ey have components )sin( φβ +z (with real 
amplitudes). Equation (6) then becomes
            
( ) ( ) ( ) ( ) ( )








−
∆
−+∆
−
−
=
+
jinyEy
jinzEji
n
zE
ji
tji
n
xHji
n
xH ,
,1,
,
,
2
1
,
2
1
β
µ
                                                                              (7)
 
Similarly,    
 
( ) ( ) ( ) ( ) ( )








−
∆
−+∆
+
−
=
+
jinxEx
jinzEji
n
zE
ji
tji
n
xHji
n
yH ,
,,1
,
,
2
1
,
2
1
β
µ
                       (8) 
 
( ) ( ) ( ) ( ) ( ) ( )










∆
−+
−
∆
−+∆
+
−
=
+
x
jinyEji
n
yE
y
jinxEji
n
xE
ji
tji
n
xHji
n
zH
,,1,1,
,
,
2
1
,
2
1
µ
          (9) 
Page 555
  
( ) ( ) ( ) ( ) ( )














+
+
∆
−
+
−
+
∆+
∆
+
∆+
∆−
=
+ ji
n
yHy
ji
n
zHji
n
zH
tjiji
tjinxEtjiji
tjijijinxE ,2
1
1,2
1
,
2
1
2/
,,
,
2/
,,
2/
,,
,
1 β
σεσε
σε
                (10) 
    
( ) ( ) ( ) ( ) ( )














+
+
∆
−
+
−
+
∆+
∆
−
∆+
∆−
=
+ ji
n
xHx
ji
n
zHji
n
zH
tjiji
tjinyEtjiji
tjijijinyE ,2
1
,12
1
,
2
1
2/
,,
,
2/
,,
2/
,,
,
1 β
σεσε
σε
                (11) 
( ) ( ) ( ) ( ) ( ) ( )














∆
−
+
−
+
−
∆
−
+
−
+
∆+
∆
+
∆+
∆−
=
+
y
ji
n
xHji
n
xH
x
ji
n
yHji
n
yH
tjiji
tjinzEtjiji
tjijijinzE
1,2
1
,
2
1
,12
1
,
2
1
2/
,,
,
2/
,,
2/
,,
,
1
σεσε
σε
           (12) 
The time-stepping formulas are stable numerically 
if and only if 
  
222 )2/(
1
β+∆+∆
≤∆
−− yxc
t
 
Where c is the speed of the light. 
 
 
REFERENCES 
 
1. J. C. Knight, T. A. Birks, P. St. J. Russell, and D. 
M. Atkins, “All-silica single-mode optical fiber 
with photonic crystal cladding,” Opt. Lett. 21, 
pp.1547-1549 (1996).  
2. Bjarklev A., Broeng J., and Bjarklev A. S. (2nd 
ed.): Photonic Crystal Fibres, Kluwer Academic 
Publishers, USA (2003)  
3. S. M. A. Razzak and Y. Namihira, “Proposal for 
highly nonlinear dispersion-flattened octagonal 
photonic crystal fibers,” IEEE Photon. Technol. 
Lett. 20, pp.249-251 (2008). 
4. T-L. Wu, and C. H. Chao, “A Novel 
Ultraflattened Dispersion Photonic Crystal 
Fiber,” IEEE. Photon. Technol. Lett. 17, pp.67-
69 (2005). 
5. Ferrando, E. Silvestre, J. J. Miret, and P. Andres, 
“Nearly zero ultraflattened dispersion in 
photonic crystal fibers,” Opt. Lett. 25, pp.790-
792 (2000).  
6. H. Ademgil and S. Haxha, “Highly Birefringent 
photonic crytal fibers with ultralow chromatic 
dispersion and low confinement losses,” IEEE J. 
Lightwave Technol. 26, pp.441-448 (2008). 
7. M.-Y. Chen, “Polarization and leakage 
properties of large-mode-area microstructured-
core optical fibers,” Opt. Express 15, pp.12498-
12507 (2007). 
8. T.-J. Yang, L.-F. Shen, Y.-F. Chau, M.-J. Sung, 
D. Chen, and D. P. Tsai, “High birefringence and 
low loss circular air-holes photonic crystal fibers 
using complex unit cells in cladding,” Opt. 
Commun. 281, pp.4334-4338 (2008). 
9. J. Ju, W. Jin, and M. S. Demokan, “Properties of 
a highly Birefringent photonic crystal fiber,” 
IEEE Photon. Technol. Lett. 15, pp.1375–1377 
(2003). 
10. Ortigosa-Blanch, J. C. Knight, W. J. Wadsworth, 
J. Arriaga, B. J. Mangan, T. A. Birks, and P. S. J. 
Russell, “Highly birefringent photonic crystal 
fibers,” Opt. Lett. 25, pp.1325–1327 (2000). 
11. Y. Yue, G. Kai, Z. Wang, T. Sun, L. Jin, Y. Lu, C. 
Zhang, J. Liu, Y. Li, Y. Liu, S. Yuan, and X. 
Dong, “Highly birefringent elliptic-hole 
photonic crystal fibre with squeezed hexagonal 
lattice,” Opt. Lett. 32, pp.469–471 (2007). 
12. T. P. Hansen, J. Broeng, S. E. B. Libori, E. 
Knudsen, A. Bjarklev, J. R. Jensen, and H. 
Simonsen, “Highly birefrngent index-guiding 
photonic crystal fibers,” IEEE Photon. Technol. 
Lett. 13, pp.588–590 (2001). 
13. S. Li, Y. Li, Y. Zhao, G. Zhou, Y. Han, and L. 
Hou, “Correlation between the birefringence and 
the structural parameter in photonic crystal 
fiber,” Opt. & Laser Tech. 40, pp.663-667 
(2008). 
14. M. Chen, and R. Yu, “Design of defect-core in 
highly Birefringent photonic crystal fibers with 
anisotropic claddings,” Opt. Commun. 258, 
pp.164-169 (2006). 
15. M. Chen, R. Yu, and A. Zhao, “polarization 
properties of rectangular lattice photonic crystal 
fibers,” Opt. Commun. 241, pp.365-370 (2004). 
16. J. R. Folkenberg, M. D. Nielsen, N. A. 
Mortensen, C. Jacobsen, and H. R. Simonsen, 
“Polarization maintaining large mode area 
photonic crystal fiber,” Opt. Express 12, pp.956-
960 (2004). 
17. K. Suzuki, H. Kubota, S. Kawanishi, M. Tanaka, 
and M. Fujita, “optical properties of a low-loss 
polarization-maintaining photonic crystal 
fibers,” Opt. Express 9, pp.676-680 (2001). 
18. L. Zhang C. Yang, “Photonic crystal fibers with 
squeezed hexagonal lattice,” Opt. Express 12, 
2371-2376 (2004). 
19. S. M. A Razzak and Y. Namihira, “Tailoring 
dispersion and confinement losses of photonic 
crystal fibers using hybrid cladding,” IEEE J. 
Lightwave Technol. 26, pp.1909-1914 (2008). 
Page 556
  
20.  J. C. Knight, “Photonic crystal fibres,” Nature 
424, pp.847-851 (2003). 
21. Min Qiu," Analysis of guided modes in photonic 
crystal fibers using the time domain finite 
difference time-domain method," Microwave 
and optical technology letters 30(5), pp.327-330 
(2001). 
22. J. P. Berenger, “A perfectly matched layer for 
the adsorption of electromagnetic waves, “J 
Comput Phys 114                     (1994), 185-
200. 
23. Apollo Photonics Solution Suite: 
www.apollophoton.com 
24. K. Kaneshima, Y. Namihira, N. Zou, H.Higa, 
and Y. Nagata, “Numerical Investigation of 
Octagonal Photonic Crystal Fibers with Strong 
Confinement Field,” IEICE Trans. Electron 
E89-C, pp. 830-837 (2006).   
25. P. St. J. Russell, "Photonic crystal fibers," 
Science 299, 358–362 (2003). 
Page 557
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Abu Naim Rakib Ahmed,  
E-mail: naimeee_2020@yahoo.com 
Designing of Armature Winding Using Programming Technique Instead 
of Using Conventional Method 
 
Abu Naim Rakib Ahmed1*, Dewan H. S. Salehin1, M. Imran Hossain1, and   
Mohiuddin Ahmad1, 
1Department of Electrical and Electronic Engineering, 
Khulna University of Engineering and Technology, Khulna-9203, Bangladesh 
 
 
Abstract - Armature winding of a machine is defined as an arrangement of conductors designed to 
produce emfs by relative motion in a heteropolar magnetic field [2]. When anyone wants to design 
armature winding for any types of machine they should keep remind some important factors such 
as coil span of each armature coil, emf being produced in the winding, polarity of brush so that no 
circulating current can flow, the sequence of different coil sides, find out is that winding is 
integrated or fractional slot winding. Hence, armature winding design in a conventional way takes 
great time and moreover the procedure for fractional and integrated slot winding is totally 
different. So in our work we are using programming language technique for designing armature 
winding which will take about 15 seconds for designing armature winding without any difficulties. 
In our work, we have used programming language c++ [4], both for calculation and winding layout 
drawing. The program has made it very easy for us to design an armature winding in a very short 
time. 
. 
 
Key words: Integrated slot winding, Fractional slot winding, Slot per pole per phase equation, dummy coil, 
and graphics of winding layout. 
1. INTRODUCTION 
 
The paper deals with the designing of armature 
winding using programming technique. For 
designing armature winding, one should remember 
some important factors like back pitch, front pitch, 
coil span, coil sides, commutator pitch, condition of 
electrical symmetry [1,3] etc. Moreover, the 
direction of current and generation of emf in the 
winding should be considered. In addition the 
design procedure for the integrated slot winding 
and fractional slot [1] winding is totally different. 
In conventional way for designing the armature 
winding, anyone needs to remember all those above 
factor and then sit down with their pencil and paper 
for calculation of the front pitch, back pitch, coil 
span or is that fractional or integrated slot winding. 
So, for doing all this term together the probability 
of error increase in a great rate and it is also time 
consuming.  
In the following paper, we do the above things by 
using programming language technique and it will 
also give us the full layout of the armature winding 
within a few seconds. The paper demonstrated a 
simple algorithm of how the slot of various phase 
are distributed and what will be the sequence of 
pole phase group. By knowing the number of 
phase, number of pole and the number of slot, we 
can easily design the armature winding. Moreover, 
this algorithm gives us the full distribution of slot, 
the direction of current and the start and finishing 
point of the coil design. 
2. The Modeling process 
 
 
For armature winding design, we need to know the 
number of phase, number of pole and the total 
number of slots. Here from this above data, we 
need to determine the value of number of pole in 
unit(d), number of slot per phase in each unit(M) 
and no. of coil in each group(I and n). In the figure 
(1), we demonstrated a flow chart of our work. 
After determining the value of M, d, n and I we 
determine if the pole is divisible by the phase? If it 
does then we go through the angle procedure, if  
it does not then we calculate the value of D. After 
performing the calculation we have determined the 
distribution of slot into different phase then we 
completed our graphical work. The problem is done 
Page 558ISBN: 978-984-33-2140-4
  
in a Windows XP service pack-3 environment with 
C++. 
 
 
 
 
Fig 1: Flow Chart of armature winding design. 
 
3. Mathematical Expression 
 
 
In the integral slot windings, every pole phase 
groups has the same number of series connected 
coils. But in fractional slot windings, all the pole 
phase groups do not have the same number of series 
connected coils as q is always a mix number. Since 
the fractional coils are impossible, the only 
alternative left is not to make all the phase group 
identical i.e. practical winding is only possible 
when one pole phase group has one coil fewer 
than the others.  
When, however it is found necessary to use a 
lamination that does not give an integral slot 
winding. Its number of slots must make it 
possible for all phases to have same number of 
coils. This means that if a lamination is to be 
used for a 3 phase machine the total number of 
slots should be divisible by 3 in order that each 
phase has the same number of coils. 
Average number of slots per pole per phases,  
q = S / (m*p)               [1] 
   
        = M / d 
So, Number of slot per pole per phase 
             = I 


                             [2]
   
Here, Phase= m; Pole= p; Slots=S; Number of 
pole in a unit = d 
Number of slots per phase in each unit =M 
Number of slots in each unit= m*M 
Number of unit = p/d 
Each phase in a unit contains (d-n) groups of I 
coil and n groups of (I+1) coils each. Double 
layer winding can be either  
I.Integral slot 
II.Fractional slot  
When the number of slots per pole per phase is 
an integer, it is known as an integral slot 
winding. When the number slot per pole and 
also the number pole per phase are not integers 
then the winding is known as fractional slot 
winding. 
To solve the problem, at first we calculate the 
value of a variable D (difference between two 
slots), 
Where D =


; Where x= the smallest 
integer value which makes D an integer 
In general the series is: 
 
1, 1+D, 1+2D, 1+3D, … … … ,[1+(m*M-1)*D-
ymM] ; where y= an integer 
 
The value of mM has to be subtracted from the 
terms which become larger than mM.  
But, if pole is devisable by phase then no value of x 
can make D an integer and to solve this problem we 
have to proceed in another way: 
Electrical angle between consecutive slots, =   
(180*p / S) degree 
Number of slot in a unit = mM 
Thus, the slot star of this winding will have mM 
phasors.  
Calculation the 
angle of coil 
span 
Calculate the 
value of D 
Save work into bitmap 
file 
Stop 
Calculate the 
values of M,d,n 
and I 
Is 
pole%phase 
=0  
Read phase, pole 
and slot 
Start 
 
A 
 
Graphical Works 
Page 559
  
Using this angle we can distribute the slots in a unit 
into 360 degrees with a difference of angle between 
consecutive slot degrees. 
Now the position of slots can be determined 
according to the value of the angle in ascending 
order 
 
4. Result 
 
The algorithm is developed both for the fractional 
and integrated slot winding. Here, we give the 
result of the two samples for fractional and 
integrated slot winding. 
 
4.1. Fractional slot winding 
 
Here for fractional slot winding we used 3 phase
pole and 78 slots. So, the calculation for the 
winding design are given below 
                       S         78      13            
                q = ----- = ------ = ---- =  3 ----
                      mp      3*8      4             
 
Number of slots per phase in each unit, M=13
Number of poles in a unit, d=4 
I=3 
n=1 
Number of Units, p/d = 8/4 = 2 
Each phase in a unit has 
d - n = 3 groups of I = 3 coils each and
n = 1 group of I + 1 = 4 coils each 
 
                         1 + m*M*P     1 + 3*13*P
We know, D =   ---------       =   ----------
                              d                     4 
The smallest value of P for D be an integer is, P= 1, 
D= 10 
 
Each phase in a unit has 
3 groups of 3 coils each and 
1 group of 4 coils each 
 
 4 
1 
 
4      
 
 
 
 
The distribution of slots is as below: 
 
Phase=1 
                  1  2  3  4  11  12  13  21  22  23
33 
 
Phase=2 
                  5  6  7  14  15  16  17  24  25  26
36 
 
Phase=3 
                 8  9  10  18  19  20  27  28  29  30
39 
 
The winding layout for the fractional slot winding 
is 
 
  
   Fig 2: The winding layout of 3 phase 4 pole and 
78 slots 
 
4.2. Integrated slot winding 
 
For fractional slot winding, we show the layout of 3 
phase, 4 poles and 24 slot machine. The calculation 
for the integrated slot winding is shown in below 
                       S         24       2           0
               q = ----- = ------ = ---- =  2 ----
                      mp      3*4      1           1     
Number of slots per phase in each unit, M=2 
Number of poles in a unit, d=1 
I=2 
n=0 
Number of Units, p/d = 4/1 = 4 
Each phase in a unit has 
d - n = 1 groups of I = 2 coils each  and
n = 0 group of I + 1 = 3 coils each 
 
                      1 + m*M*P     1 + 3*2*P
We know, D =   ---------       =   ----------
                            d                     1 
  31  32  
  34  35  
  37  38  
 
 
 
 
 
 
 
Page 560
  
The smallest value of P for D be an integ
D= 7 
Each phase in a unit has 
1 groups of 2 coils each and 
0 group of 3 coils each 
 
The distribution of slots is as below: 
The distribution The distr ibus as below             Phase=1              1  2   
 
Phase=2              3  4   
 
Phase=3              5  6   
 
 
 
 
 
 
 
The winding layout for the integral slot winding is
 
 
Fig 3: The winding layout of 3 phase 4 pole and 24
 
5. CONCLUSIONS 
 
In this paper, an algorithm is developed for 
designing the armature winding .By knowing the 
value of phase, slot and the pole we can easily get 
the layout of armature winding. In our method both 
fractional and integral slot winding can be design 
without any calculation. This is a computer aided 
design. It has the advantage of eliminating  tedious 
and time consuming hand calculation thereby 
releasing the designer from numerical drudgery to 
allow him devote time to grapple with physical and 
logical ideas. These computer aided designs also 
ensure the less error than hand calculating design.
 
REFERENCES 
 
1. A.K.Sawhney “A Course in Electrical Machine 
Design,” 2006 Edition 
er is, P= 1, 
 
 
 
 
 
2.   O.I. Okoro, M.U. Agu and E. Chinkuni “Basic 
Principles and Functions of Electrical 
Machines” in the Pacific Journal of Science 
and Technology Volume 7. Number1.
2006 
3. Rosenblatt and Friedman “Direct and 
Alternating Current Machinery” 2006 Edition
 
4. E Balagurusamy “Programming in ANSI C” 
2000 Edition. 
 May 
 
Page 561
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2010 
CERIE 2010, 11-13 January, Sylhet, Bangladesh 
 
DEVELOPMENT OF AN EMBEDDED SYSTEM FOR LOW POWER 
MESSAGE DISPLAY 
 
Mohammad Mohidur Rahman Khan, Md. Liakot Ali, S.M. Tofayel Ahmad 
Department of Information and Communication Technology 
Institute of Information and Communication Technology 
Bangladesh University of Science and Technology, Bangladesh 
E-mail: mishu028@yahoo.com, liakot@iict.buet.ac.bd, ntofayel@yahoo.com 
 
ABSTRACT 
 
Electronic display is now the most conventional means of presenting information all over the world. Due to 
its attractive brightness and simple operability, it is one of the most popular medium of presenting different 
types of information to the mass people. The display elements in an embedded system consume the major 
portion of the total power required to run the whole system. When large amount of display elements are used 
power dissipation issue becomes acute. In many cases special cooling arrangements like heat sink, cool air 
circulation, fan etc. are used to keep the system workable. The demand of low power consumption for 
embedded systems motivates to explore new approaches for managing power. This paper proposes an 
alternative approach to develop a low power consuming embedded system for message display by 
introducing a new scanning technique. In the proposed system a controller scans all the display units 
continuously to ensure that only one unit is on at any given time. In this way power consumption will be 
much lower than that of existing static display system. Here a ‘Muslim Calendar’ containing date, time and 
prayer times for five salah has been developed as a test case. Seven segment displays are used as display 
units. 
 
Key Words: Microcontroller, Scanning, Message, Display, Low Power 
 
1. INTRODUCTION 
 
Electronic display-we see it everywhere, in 
computers, watches, DVD players and many 
other electronic devices to display numeric and 
some alphabetic characters. It is also used for 
showing messages in digital calendars, billboards, 
shopping malls, airports, stadiums and many 
other places. It is a commonly used and efficient 
way of displaying information. Although 
electronic display is widely used, power 
consumption is still an important issue. In an 
electronic circuit, the major part of the total 
power is consumed by the display elements. If a 
large amount of display units are used in a system 
then the power requirement to run the system will 
also increase proportionately. In that case extra 
cooling arrangements may be required to keep the 
system workable. So the demands of low power 
consumption for embedded systems are 
motivating new approaches to manage power 
dissipations issues. 
 
2. BACKGROUND 
 
A lot of research works have been done for 
displaying numeric digits of languages other than 
English where the researchers used Seven  
 
 
Segment Display or some modification on it [1-
5]. Display is one of the major power consumers 
in modern computer system [6-7]. Power 
consumption is even more critical when multiple 
display units are used together for displaying 
message. In some cases, it needs extra cooling 
arrangements for heat dissipation. Researchers 
have proposed plasma screen or organic light-
emitting devices (OLED) to reduce power 
consumption for display element [8-9]. So 
reducing the power consumption for display 
element is an important research area. 
 
3. THE PROPOSED SYSTEM 
 
This project concentrates on the power 
dissipation issues for display devices. A scanning 
technique has been introduced in the proposed to 
minimize the power consumption for display 
elements. The objective is to connect all the 
display elements in parallel with each other and 
turning only one unit on at a time for a very short 
period and move to the next unit. If each unit can 
be illuminated periodically in a very short span of 
time the human eye will see the entire message as 
Page 562ISBN: 978-984-33-2140-4
 if all the units are turned on whereas only one 
unit is on at any given time. 
 
Here seven segment displays are used as display 
units and as a test case a Muslim Calendar 
(displays Date, Time and Prayer times of Five 
Salah) is developed with 30 units of seven 
segment display. As the algorithm for 
illuminating display units follow the scanning 
technique only one unit of seven segment display 
is turned on at any given time. So theoretically 
the total power consumption for illuminating 
display units is reduced by 30 times. Hence 30 
units of seven segment displays can be 
illuminated by only the power required by one 
unit. 
 
4. BLOCK DIAGRAM OF THE 
SYSTEM 
 
The basic units of the proposed system can be 
divided into 7 parts: Microcontroller, Display 
elements, Display Decoder, Real Time Clock 
(RTC), Shift Registers, Power Unit and Switches. 
 
Here the microcontroller controls the input of the 
shift registers. The output of the shift registers are 
connected to the common cathodes of 30 seven 
segment displays. The microcontroller initializes 
all the output pins of the shift register at level 1 
(sends logic 1 thirty times in the input of the shift 
registers), making all the seven segment displays 
to be turned off. At this point the microcontroller 
sends logic 0 once and logic1 29 times so that 
each display receives the signal 0 sequentially 
while other displays receive signal 1. In this 
process, only one display is turned at a time and 
shifted sequentially. 
 
 
 
 
 
 
 
The output pins of the display decoder are 
connected in parallel to all seven segment 
displays. The Microcontroller sends appropriate 
input for the decoder when corresponding seven 
segment display has logic 0 at its common 
cathode. 
 
A real time clock is used to keep the date and 
time. The microcontroller reads time from the 
RTC each minute and changes the display clock 
and date accordingly. The prayer time table is 
loaded in the program memory of the 
microcontroller as an array of structure. The 
prayer times change with the change of day and 
month field of the date. There is a battery 
connected to the RTC so that it can keep the time 
and date when the main power is not available. 
 
Three switches are used to set time and date. One 
switch is used to select which field of the time 
and date is to be changed. Other two switches are 
used to count up and count down the selected 
field. All these operation is controlled by the 
microcontroller. 
 
5. SCHEMATIC DESIGN 
 
Figure 2 shows the schematic design of the 
proposed system. The main part of the system is 
the Atmel ATMEGA88 microcontroller. All 
other components are connected to it and 
controlled by it. The four input pins (D0-D3) of 
the seven segment decoder (CD4511BE) are 
connected to the first four pins of port B (PB0-
PB3) of the microcontroller. These pins are used 
to provide the appropriate data to be displayed by 
a particular seven segment display. The seven 
output pins (a-g) of the display decoder are 
connected to all seven segment displays’ input 
pins (a-g) in parallel along with seven 100 Ω 
registers. 
 
 
 
 
 
 
 
 
 
 
 
 
M
ic
ro
co
ntrolle
r
 
Display Elements 
RTC
 
Switches 
P
o
w
e
r
 
U
nit
 
Display
 D
ecod
e
r
 
Shift Registers 
Page 563
  
       Fig 1: Block diagram of the system 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 2: Schematic diagram of the proposed system 
 
Four shift registers (74HC164) are used in this 
project. The input pins (Dsa & Dsb) of the first 
shift register are made short and is connected to 
the second pin of the Port C (PC1) of the 
microcontroller. The clock pin (CP) of the shift 
register is connected to the first pin of the Port C 
(PC0) of the microcontroller. Each pair of input 
pins of the rest three shift registers are made short 
just like the fist one and is connected to the last 
output pin (Q7) of the immediate previous one. 
All the output pins of the shift registers are 
connected to the common cathode of the seven 
segment displays sequentially.  
 
The SDA and SCL pins of the Real Time Clock 
is connected to the fifth (PC4) and sixth (PC5) 
pin of the Port C of the microcontroller. Two pull 
up registers are also connected to these pins. The 
SQW pin of the RTC is connected to the fourth 
pin (PC3) of the Port C of the microcontroller. A 
3.2786 MHz crystal is connected to X1 and X2 
pins of the RTC and a 3 volt battery is also 
connected to its Vbat and GND pin.  
 
Three input switches are connected to the third 
fourth and fifth pin of Port D (PD2-PD4) of the 
microcontroller. These three pins are made 
ground with three 10kΩ registers. 
 
6. RESULT 
 
After putting all the components on the circuit 
board and programming the microcontroller the 
total system looks like as follows. 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 3: The Artview of the Proposed System 
Here the first block of four (top left corner) seven 
segment displays shows time. First two units of 
this block represent hour while second two 
Mode
Up
Down
10k
10k
+ -
3V
74LS164
Dsa
Dsb
CP
MR
Q7
Q6
Q5
Q4
Q3
Q2
Q1
Q0
74LS164
Dsa
Dsb
CP
MR
Q7
Q6
Q5
Q4
Q3
Q2
Q1
Q0
74LS164
Dsa
Dsb
CP
MR
Q7
Q6
Q5
Q4
Q3
Q2
Q1
Q0
+
V5V
+
V5V
DS1307
X1P1
X2P2
VbatP3
GNDP4SDAP5SCLP6SQWP7VCCP8
XTAL1
3.2768MHZ
+V
5V
abcdefg.
Gnd
DISP11
abcdefg.
Gnd
DISP12
abcdefg.
Gnd
DISP14
abcdefg.
Gnd
DISP13
+
V
5V
abcdefg.
Gnd
DISP23
abcdefg.
Gnd
DISP24
abcdefg.
Gnd
DISP26
abcdefg.
Gnd
DISP25
abcdefg.
Gnd
DISP27
abcdefg.
Gnd
DISP28
abcdefg.
Gnd
DISP30
abcdefg.
Gnd
DISP29
abcdefg.
Gnd
DISP21
abcdefg.
Gnd
DISP22
abcdefg.
Gnd
DISP20
abcdefg.
Gnd
DISP19
abcdefg.
Gnd
DISP17
abcdefg.
Gnd
DISP18
abcdefg.
Gnd
DISP16
abcdefg.
Gnd
DISP15
+
V5V
abcdefg.
Gnd
DISP8
abcdefg.
Gnd
DISP7
abcdefg.
Gnd
DISP10
abcdefg.
Gnd
DISP9
abcdefg.
Gnd
DISP5
abcdefg.
Gnd
DISP6
abcdefg.
Gnd
DISP1
abcdefg.
Gnd
DISP2
4511
6D3
2D2
1D1
7D0
5EL
4BI
3LT14g15f9e10d11c12b13a
abcdefg.
Gnd
DISP4
abcdefg.
Gnd
DISP3
74LS164
Dsa
Dsb
CP
MR
Q7
Q6
Q5
Q4
Q3
Q2
Q1
Q0
PC6P1PD0P2PD1P3PD2P4PD3P5PD4P6VCCP7GNDP8PB6P9PB7P10PD5P11PD6P12PD7P13PB0P14 PB1P15
PB2P16
PB3P17
PB4P18
PB5P19
AVCCP20
AREFP21
GNDP22
PC0P23
PC1P24
PC2P25
PC3P26
PC4P27
PC5P28
ATMEGA88
33k
0.1k
0.33k
0.33k
0.33k
0.33k
Date Time 
Fazr Zuhr Asr 
Maghrib Esha 
Page 564
 represent minute. The second block of six (top 
right corner) seven segment displays represents 
date where the first, second and third two units of 
the block represent day, month and year 
respectively. The remaining five blocks of four 
seven segment displays represent the prayer times 
of five salah; Fazr, Zurh, Asr, Maghrib and Esha 
as labeled in the figure 3. Here each first two 
units of each block represent hour and the 
remaining two units of each block represent 
minute. 
 
There are three buttons: Mode, Up and Down. 
The Mode button selects which unit of time or 
date is to be changed. Then the buttons Up and 
Down are used to count up or down respectively 
to set the selected unit of time or date. 
 
Scanning technique is a power aware solution for 
message display. Here we have used 30 seven 
segment displays. But as scanning technique is 
applied, at any given time only one seven 
segment display is on. So, theoritically the system 
should consume 1/30 times less power than it 
would take to make all the seven segment 
displays on at a time. But following table shows 
the practical senario. 
 
Table 1: Current and Power Consumption by the 
Display Elements 
 
So, in practical the power consumption is not as 
less as 30 times of the total power needed. But 
still it minimizes the power consumption to a 
considerable amount that is 65% less power and 
66% less current are required to run the display 
units of the system when the scanning technique 
is applied. 
 
Another important point is for the scanning 
technique only one Display Decoder is used. If 
this technique is not applied then 30 Display 
Decoders should be used for 30 seven segment 
display. Furthermore a microcontroller has 
limited number of pins. So, a commonly used 
microcontroller may not be able to connect all the 
display decoders at a time due to its fixed number 
of pins. So, the solution enables a circuit to be 
operated in less power, less area hence less cost. 
 
7. CONCLUSION AND FUTURE 
WORKS 
 
Power management has a considerable 
importance in electronic circuits. In electronic 
displays, power consumption increases with the 
size and number of the display units. This project 
uses scanning technique to reduce power 
consumption. The embedded system developed 
as a test case demonstrates a power aware 
solution using scanning technique. The seven 
segment displays used as display units consume 
less power when scanning technique is used. 
Since the algorithm allows only one display unit 
to be illuminated at any given time rather than all 
the units receiving power, it consumes significant 
less power. The scanning technique in the 
embedded circuit requires only one Display 
Decoder for all the display units. 
 
As stated, the project has 30 units of seven 
segment displays and by using scanning 
technique the total power consumption is reduced 
by 30 times (theoretically). But a common 
question may arise; will this technique work if 
the number of display units is increased by a 
significant number (1000 or more)? In that case 
some flickering will be experienced.  This is 
because human eye can hold an image in the 
brain for only 1/10 of a second. So if the scanning 
frequency is such that each display unit is 
illuminated for less than 1/10 of a second, 
flickering will be observed, that is, power 
consumption factor will not be inversely 
proportionate to the number of display units as 
stated earlier. 
 
To remedy this, the scanning technique can be 
modified in such way that a group of display 
units would be considered as a cluster. The total 
system can have number of clusters. The 
scanning technique will be applied on these 
clusters so that each cluster will be turned on at 
any given time. But in this case we need to use 
the same number of display decoders as number 
of display units in a cluster. 
 
In future, the modified scanning technique 
(clustering approach) can be incorporated in other 
embedded systems with large number of display 
units. Some microcontrollers with built-in 
scanning mechanism are available in the market. 
Current and Power Consumptin for 30 Units of 
Seven Segment Displays 
 
With Scanning 
Technique 
Without 
Scanning 
Technique 
Curren 
Consumption 25mA 75mA 
Power 
Comsumption 0.13 watt 0.375 watt 
Page 565
  
Future works can be done using those 
microcontrollers. 
8. REFERENCES 
 
[1] Azad, M. A. K., Sharmeen, R., Ahmed, S. and 
Kamruzzaman, S. M., "A unique 10 Segment 
Display for Bangla Numerals" in proceedings of 
8th International Conference on Computer and 
Information Technology (ICCIT), 2005. 
 
[2] Karri, R., and Orailoglu, A., “Standard Seven 
Segmented Display for Burmese Numerals” in 
proceedings of  Consumer Electronics, IEEE 
Transactions, vol-36,  issue: 4, pp 959-961, 1990. 
 
[3] Islam, R., Alam, M. G. R., and Uddin, M. N., 
“An 8-Segment Display for Simple and Accurate 
Representation of Bangla Numerals” in 
proceedings of 4th International Conference on 
Electrical and Computer Engineering ICECE , 
2006. 
 
[4]  Islam, M.M., Hossain, M. K., Hasan, K.S., 
and Haque, A.L.“A 7-Segment Display for 
Bangla, English and  Other Indian Numerals” in 
proceedings of 5th International Conference on 
Electrical and Computer Engineering ICECE 
2008, 20-22 December 2008,  
 
[5]  Rabbi, F.R.,  Hossain, M. K.,  and  Ahmed, 
M.  “An 8-segment display for both English and 
Bangla digits,” in Proceedings of 6th 
International Conference on Computer and 
Information Technology (ICCIT), Dhaka, 
Bangladesh, 2003, pp. 338-341 
 
[6] Moshnyaga, V.G. and Morikawa, E., “LCD 
Display Energy Reduction by User Monitoring” 
in proceedings of IEEE International Conference, 
pp 94 – 97, 2005. 
 
[7]  Bhunia, S., Mahmoodi, H.,  Mukhopadhyay, 
S., Ghosh, D., and Roy ,K. “A Novel Low-Power 
Scan Design Technique Using Supply Gating”  in 
Proceedings of the IEEE International 
Conference on Computer Design (ICCD’04) 
1063-6404/04 
 
[8] Aerts, W. F., Verlaak, S. and Heremans P., 
“Design of an Organic pixel Addressing Circuit 
for an Active-Matrix OLED Display”, in 
proceedings of IEEE Transactions on Electron 
Devices, vol-49, issue-12, pp 2124-2130, 2002. 
 
[9] Kimmel, J., Hautanen, L. and Levola, T., 
“Display technologies for portable 
communication devices”, in proceedings of the 
IEEE, vol-90, issue-4, pp 581-590, 2002.
 
 
 
 
 
 
 
 
 
Page 566
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Md. Habibullah,  
E-mail: mhueeekuet@gmail.com 
DIRECT TORQUE CONTROL OF 4-SWITCH 3-PHASE VOLTAGE 
SOURCE INVERTER FED INDUCTION MOTOR DRIVE 
 
Md. Habibullah*           Kalyan Kumar Halder           Md. Abdur Rafiq        
Department of Electrical and Electronic Engineering, Khulna University of Engineering and 
Technology, Khulna-9203, Bangladesh 
 
B. C. Ghosh  
Department of Electrical and Electronic Engineering, American International University-
Bangladesh, Dhaka-1215, Bangladesh 
 
 
Abstract: This paper proposes a direct torque control (DTC) methodology for 4-switch 3-phase (4S3P), 
voltage source inverter (VSI) fed induction motor (IM) drive. In the proposed approach, instead of a 
conventional 6-switch, 3-phase inverter (6S3P) a 4S3P inverter is utilized. This reduces the cost of the 
inverter, the switching losses, and the complexity of the control board for generating pulse width modulated 
(PWM) signals. Furthermore, the proposed control approach reduces the computation for real time 
implementation. A proportional plus integral (PI) controller is used to process the speed error for generating 
reference torque to the IM. Two hysteresis controllers are used for torque and flux loops. The output of these 
hysteresis controllers with stator flux angle drives the switches into on or off state. Closed-loop control of 
the stator flux magnitude and the electromagnetic torque of the motor with Clarke’s transformation are used 
in this study. The robustness of the drive system is tested for different perturbed operating conditions and 
found to work acceptably under these conditions. 
 
Key words: Direct torque control; four switch three phase inverter; induction motor; robustness. 
 
1. INTRODUCTION 
 
More than two decades ago, DTC was introduced to 
give fast and good dynamic torque response. DTC 
can be considered as an alternative to the field-
oriented control (FOC) technique (Takahashi and 
Noguchi, 1986, Depenbrok, 1988). In fact, a DTC 
scheme accomplishes the closed-loop control of the 
stator flux magnitude and the electromagnetic torque 
of the motor without the intermediary of any current 
loop or shaft sensor. To this end, the DTC scheme 
senses the stator currents and the dc-link voltage and 
processes them, together with the states of the 
inverter switches, to estimate the actual values of the 
controlled variables.   
Many technical papers have appeared in the 
literature since the DTC was introduced in 1986, 
(Takahashi and Noguchi, 1986) mainly seeking to 
improve the performance of DTC of induction 
motor drives. Two of the major issues which are 
normally addressed in DTC drives are the variation 
of the switching frequency of the inverter used in 
the DTC drives with operating conditions and the 
high torque ripple for using torque hysteresis 
comparator. To improve the performance of DTC, 
researchers consider different analytical approaches 
(Idris and Yatim, 2004, Casadei et. al., 1998, 
Bertoluzzo et. al., 2006). Idris and Yatim, 2004 and 
Casadei et. al., 1998, proposed a constant switching 
frequency torque controller to replace the 
conventional hysteresis based controller. In 
(Bertoluzzo et. al., 2006), the hardware of a DTC 
scheme is reduced by using only one sensor of 
current and by inserting it in the inverter dc link.  
    Nowadays, researchers are working not only for 
better performance of the drives but also trying to 
reduce the cost of the drives. Conventional six 
switch three phase (6S3P) inverters have been 
widely used for AC motor drives for the last few 
decades. But the reduction of the number of power 
transistor switches from six to four reduces the cost 
of the inverter, decreases the switching losses and 
complexity of the control algorithms instead of 
generating six PWM signals (Uddin et. al., 2006, 
Dzung et. al., 2007). A cost effective four switch 
three phase (4S3P) inverter is proposed for IM 
drives in (Uddin et. al., 2006). The authors show a 
performance comparison of the 4S3P inverter fed 
drive with 6S3P inverter fed drive in terms of speed 
response and total harmonic distortion of the stator 
current. But overshoot and undershoot can not be 
eliminated in the speed response of the drive system. 
Page 567ISBN: 978-984-33-2140-4
  
The same authors propose fuzzy logic controller 
based control scheme for 4S3P inverter fed interior 
permanent magnet synchronous motor (IPMSM) 
drive. Vector control of induction motor using 4S3P 
inverter for high performance industrial drive 
systems is presented in (Dzung et. al., 2007). The 
authors verified the complete scheme by simulation 
and experimentally in a DSP environment.  
This paper presents a new technique to improve the 
performance of direct torque controlled VSI fed IM 
drive by using four switches in the inverter circuit. 
A mathematical model of the drive system is utilized 
to analyze the transient and steady-state responses of 
the motor. The performance of the induction motor 
drive under sudden change of load torque and speed 
reversal condition is also investigated in order to 
verify the robustness of the proposed control 
scheme. The proposed 4S3P inverter fed IM drive is 
found acceptable considering its cost reduction and 
other advantageous features mentioned earlier. 
 
2. MATHEMATICAL MODEL OF IM 
 
The mathematical model of a 3-phase, Y-connected 
induction motor is expressed by the following 
equations in the α-β stationary reference frame as 
(Crause et. al., 1995, Boldea and Nassar, 1999). 
 












0
0
S
S
v
v
β
α
= 












+−−
+
+
+
pLRLpLL
LpLRLpL
pLpLR
pLpLR
rrrrmrm
rrrrrmm
mSS
mss
ωω
ωω
00
00














r
r
s
s
i
i
i
i
β
α
β
α
(1)    
[ ] [ ]( )rrsmrrrsmrpe iLiLiiLiLiPT ααβββα +−+= 2
3
        (2) 
Lm
m
e TBdt
d
JT ++= ω
ω
  and 
p
r
m P
ω
ω =     (3) 
Where svα , svβ  are α-β -axis stator voltages, 
respectively; siα , siβ are α-β -axis stator currents, 
respectively; riα , riβ are α-β -axis rotor currents, 
respectively; sR , rR  are the stator and rotor 
resistances per phase, respectively; sL , rL  are the 
stator and rotor inductances per phase, respectively; 
mL  is the mutual inductance, eω , rω and 
)( resl ωωω −= are the synchronous, rotor, and slip 
angular speeds, respectively; pP  is the number of 
pole pairs, p  is the differential operator, eT  is the 
electromagnetic developed torque, LT  is the load 
torque, J is the rotor inertia, and B is the rotor 
damping coefficient. 
 
3. FOUR SWITCH THREE PHASE 
INVERTER MODEL 
 
In the 4-switch inverter, as shown in Fig. 1 a three 
phase system is obtained by connecting the phase 
‘c’ terminal of the stator windings directly to the 
centre tap of the DC link capacitors. The single 
phase AC supply is rectified by the front-end 
rectifier. The capacitors are used to level the output 
DC voltage. The three phase voltages to the IM 
motor can be expressed as follows (Uddin et. al., 
2006): 
 
[ ]124
3
−−= ba
dc
a SS
VV
                               (4)                    
[ ]124
3
−−= ab
dc
b SS
VV
                                (5) 
[ ]1
3
2
+−−= ba
dc
c SS
V
V
                               (6) 
 
Where, Vdc is the maximum voltage across the DC 
link capacitors, Sa and Sb are the switching states (0 
or 1) of upper switches in the legs of phases ‘a’ and 
‘b’ respectively. 
 
 
 
 
 
4. DIRECT TORQUE CONTROL    
      SCHEME 
 
The block diagram of a direct torque controlled IM 
drive system with the 4S3P inverter is shown in 
Fig. 2. The basic principle of DTC is to directly 
select stator voltage vectors according to the 
differences between the reference and actual torque 
and stator flux linkage. The stator flux linkage is 
calculated by integrating of difference between the 
input voltage and the voltage drop across the stator 
resistance as given by 
Fig. 1: 4-switch 3-phase inverter fed IM drive. 
 
Front end rectifier Four switch inverter 
AC  
Page 568
  
( ) ( )dtiRvt t ssss ∫ −=
0
ϕ                                      (7) 
Where, vs, is, and φs are the stator voltage vector, 
stator current vector, and stator flux vector, 
respectively. 
The stationary 3-axes (a-, b-, c-) to stationary 2-
axes (α-, β-) transformation is given by                
cbas xxxx 5.05.0 −−=α                         (8)                                                  
 )(
2
3
cbs xxx −=β                                         (9) 
Where, x is either voltage or current vector. 
The stationary α- and β- axis components of stator 
flux vector φs  can be obtained as follows: 
( ) ( )dtiRvt
t
ssss ∫ −=
0
αααϕ                               (10) 
( ) ( )dtiRvt t ssss ∫ −=
0
βββϕ                               (11) 
The stator flux linkage vector is given by 
( ) ( )22 sss βα ϕϕϕ +=                                   (12) 
and the angle θs is written as 






=
−
s
s
s
α
β
ϕ
ϕ
θ 1tan                                             (13) 
The electromagnetic torque can be estimated as 
follows: 
( )sssspe iiPT αββα ϕϕ −= 2
3
                           (14) 
The voltage vector plane of a 4-switch inverter fed 
system is divided into four sectors as shown in Fig. 
3 (Ivonne et. al., 2008). When the flux linkage 
vector stands in sector S1, the application of voltage 
vector V1 will increase the flux linkage amplitude 
and decrease the torque, whereas V2 increases the 
flux linkage amplitude and increases the torque. 
Following this principle, a voltage vector switching 
table for the 4-switch inverter fed DTC system can 
be tabulated in Table 1.The torque and flux 
hysteresis comparators are two valued comparators 
and the output of these comparators are denoted as τ 
and Φ, respectively. τ or Φ = 0 means that the 
actual values of these variables are above the 
reference and out of the hysteresis limit and τ  or Φ 
=1 means that the actual values of these variables 
are below the reference and out of the hysteresis 
limit.  
 
 
 
 
ωref 
AC Supply 
PI  
Controller 
 
Speed Transducer 
 IM 
 4S3P 
Inverter 
Tref 
θs 
ωm 
Σ 
 
- 
+ 
ia 
Sa 
Front-end 
Rectifier 
Sb 
φref 
+ 
+ 
- 
- 
dT 
dφ 
Torque 
Hysteresis 
Controller  
Flux 
Hysteresis 
Controller  
Switching 
Table 
 
Torque 
and Flux 
Estimator 
  
ib 
Vdc 
ic 
φs 
Te 
(a-b-c) 
to (α-β) 
iα 
iβ 
vα 
vβ 
Fig. 2: System diagram of direct torque controlled IM drive. 
 
Page 569
  
 
 
Table 1 Voltage vectors table 
φ  τ  S1 S2 S3 S4 
0 0 V4 V1 V2 V3 
0 1 V3 V4 V1 V2 
1 0 V1 V2 V3 V4 
1 1 V2 V3 V4 V1 
 
5. SIMULATION RESULTS  
 
The effectiveness of the proposed control scheme 
has been verified by computer simulations under 
different operating conditions. A simulation model 
of the IM has been developed in the C++ 
environment. The name plate rating and motor 
parameters used in this simulation study are given 
in Appendix.  
 
5.1 Starting Performance of the Proposed 
IM DTC Drive 
 
The motor was started with a command speed of 
1500 rpm and load torque of 1.0 N-m from 
standstill condition. The motor reaches to the 
command speed at 0.16 second. Fig. 4 (a) shows 
the speed response of the proposed direct torque 
controlled IM drive. The actual speed follows the 
command speed accurately without steady-state 
error and oscillations. Fig. 4 (b) shows the 
estimated electromagnetic torque. It is observed 
that higher electromagnetic torque is generated 
during the motor acceleration. Difference between 
developed and load torques is due to viscous 
damping torque of the drive system. Fig. 4 (c) 
shows the starting current as well as the steady state 
current response and Fig. 4 (d) shows the trajectory 
of the stator flux linkage. 
0.0 0.2 0.4 0.6 0.8 1.0
0
300
600
900
1200
1500
Sp
e
e
d 
in
 
rp
m
Time in sec
 Reference 
 Actual
 
         (a)             
0.0 0.2 0.4 0.6 0.8 1.0
0
5
10
15
20
25
To
rq
u
e 
in
 
N
-
m
T ime in sec
                                      
       (b) 
0.06 0.12 0.18 0.24 0.30
-8
-4
0
4
8
Cu
rr
e
n
t i
n
 
a
m
p
Time in sec
 I
a
 Ib
 I
c
 
          (c)            
-1.0 -0.8 -0.6 -0.4 -0.2 0.0 0.2 0.4 0.6 0.8
-0.8
-0.6
-0.4
-0.2
0.0
0.2
0.4
0.6
0.8
ϕ β
s
ϕ
αs
 
                                              (d) 
Fig. 4 (a) Simulated speed response, (b) Developed 
electromagnetic torque, (c) Current response, and 
(d) stator flux locus for the proposed 4S3P VSI-fed 
IM drive at a load torque 1.0 N-m. 
 
                                                                                      
             
                                    
S1 
S2 
S3 
 
S4 
 
V1 (00) 
V2 (01) 
V3 (11) 
V4 (10) 
α 
β 
V1 
V2 
V3 
V4 
φs 
Fig. 3: Voltage vectors of a 4-switch 3-phase inverter 
fed system. 
(b)
Page 570
  
5.2 Performance under Sudden Load and 
Speed Changes 
The performance of the IM drive under different 
operating conditions was also investigated in order 
to verify the robustness of the proposed control 
scheme. Fig. 5 (a) shows the speed and torque 
response of proposed drive under speed reversal 
condition. It is observed that the motor speed 
follows the reference speed without any overshoot 
or undershoot. The load torque of the motor was 
suddenly increased from 1.0 Nm to 2.0 Nm at 0.5 
second and corresponding speed and torque 
response are shown in Fig. 5(b). No dip in the 
speed response indicates the robustness of the 
proposed controlled drives against load 
disturbances.  
 
0.0 0.5 1.0 1.5 2.0 2.5 3.0
-1500
-1000
-500
0
500
1000
1500
Sp
e
ed
 
in
 
rp
m
Time in sec
 Reference
 Actual
                
0.0 0.5 1.0 1.5 2.0 2.5 3.0
-60
-40
-20
0
20
40
60
To
rq
u
e
 
in
 
N
-
m
Time in sec
 
                                           (a) 
0.0 0.2 0.4 0.6 0.8 1.0
0
300
600
900
1200
1500
Sp
ee
d 
in
 
rp
m
Time in sec
 Reference
 Actual
                      
0.0 0.2 0.4 0.6 0.8 1.0
0
10
20
30
40
50
To
rq
u
e 
in
 
N
-
m
Time in sec
 
                                            (b) 
 
 
 
 
 
 
6. CONCLUSION 
A direct torque control methodology for 4-switch 3-
phase inverter fed induction motor drive is 
presented in this paper. The control system needs 
very simple structure and is capable to estimate the 
torque and the stator flux acceptably. The results 
obtained and presented in this work indicate that 
the proposed control scheme produces very fast 
response of the IM drive without any overshoot and 
undershoot. The drive is also robust to load 
disturbances, and speed reversal conditions. Thus 
the proposed low cost control scheme is suitable for 
industry applications.  
APPENDIX 
The motor parameters are summarized below: 
Rating: 3-phase, 1 hp, 415 V, 1.8A, 2-pole pair. 
Parameters: 
Stator resistance, Rs =13.25 Ω 
Rotor resistance, Rr = 16.818 Ω 
Mutual inductance, Lm = 0.7114 H 
Stator self inductance, Ls = 0.7359 H 
Rotor self inductance, Lr = 0.7359 H 
Moment of inertia, J = 0.0075 Kg-m2 
Damping coefficient, B = 0.00107 Nm-sec/rad 
Fig. 5 Simulated speed and torque response for the 
4S3P VSI-fed IM drive for (a) speed reversal, and 
(b) change of load torque from 1.0 N-m to 2.0 N-m 
at t=0.5sec.  
 
Page 571
  
REFERENCES 
1. Takahashi and Noguchi, T., (1986), A New 
Quick-Response and High Efficiency Control 
Strategy of An Induction Motor, IEEE Trans. 
Ind. Appl., IA-22(5), pp. 820-827.  
2. Depenbrok, M., (1988), Direct Self Control 
(DSC) of Inverter-Fed Induction Machine, 
IEEE Trans. Power Electron., 3(4), pp. 420-
429. 
3. Idris N. R. N. and Yatim, A. H. M., (2004), 
Direct Torque Control of Induction Machines 
with Constant Switching Frequency and 
Reduced Torque Ripple, IEEE Trans. Ind. 
Electron., 51(4), pp. 758-767. 
4. Casadei, D., Serra, G. and Tani, A., (1998), 
Improvement of Direct Torque Control 
Performance by Using A Discrete SVM 
Technique,” in Proc. IEEE PESC’98, 2, pp. 
997-1003.  
5. Bertoluzzo, M., Buja, G. and Menis, R., 
(2006), Direct torque control of an induction 
motor using single current sensor,  IEEE 
Trans. Ind. Electron., 53(3), pp. 778-783. 
6. Uddin, M.N.,  Radwan, T.S.  and. Rahman, 
M.A, (2006), Performance Analysis of a Cost 
Effective 4-Switch, 3-Phase Inverter Fed IM 
Drive, Iranian Journal of Electrical and 
Computer Engineering, 5(2), pp. 97-102. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
7. Uddin, M.N., Radwan, T.S. and Rahman, M.A, 
(2006), Fuzzy-logic-controller-based cost 
effective Four-Switch Three-Phase inverter-fed 
IPM Synchronous Motor Drive System, IEEE  
Trans.  Ind. Appl., 42(1), pp. 21-30. 
8.  Dzung, P. Q., Phuong, L. M., Binh, T. C. and 
Hoang, N. M., (2007), A Complete 
Implementation of Vector Control for a Four-
Switch Three-Phase Inverter Fed IM Drive, 
International Symposium on Electrical & 
Electronics Engineering, 24-25 October, 2007, 
HCM City, Vietnam. 
9. Crause, P. C., Wasynczuk, O. and Sudhoff, S. 
D., (1995), Analysis of Electrical Machines, 
Institute of electrical & electronics engineers, 
1995. 
10.  Boldea, L. and Nassar, S. A., (1999), Electric 
Drives, CRC press LLC, 1999.  
11. Ivonne, Y. B., Sun, D. and He, Y. K., (2008), 
Study on Inverter Fault-Tolerant Operation of 
PMSM DTC, Journal of Zhejiang University 
Science A,  9(2), pp. 156-164. 
 
Page 572
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Kazi Wohiduzzaman 
E-mail: ohid13@metrouni.edu.bd 
Economic impact of installing solar concentrator technology in rural Bangladesh 
 
Kazi Wohiduzzaman 
Metropolitan University, Sylhet, Bangladesh 
 
This paper studies the viability of use of solar concentrator technology in solar cells for producing more 
electricity. Last couples of year many researchers are try to out a good result in solar electricity, we believe 
that we have made substantial progress towards providing a more flexible solar concentrator technology, 
which gives us more powerful electricity than usual solar electricity plant. Solar concentrator technology 
uses a large area of lenses or mirrors to focus sunlight on a small area of photovoltaic cells. This paper main 
focus on cost reduce and more electricity. We believe that it is possible to produce more than 35%-40% 
electricity at less than 30% of the present cost. This technology is more important for Bangladesh especially 
for rural area of Bangladesh, where electricity is not available. 
 
Key words: PV system; CPV; concentrated technology; PV cost:  
 
1. INTRODUCTION 
Concentrator photovoltaic (CPV) systems use a 
large area of lenses or mirrors to focus sunlight on a 
small area of photovoltaic cells. If these systems 
use single or dual-axis tracking to improve 
performance, they may be referred to as Heliostat 
Concentrator Photovoltaics (HCPV). The primary 
attraction of CPV systems is their reduced usage of 
semiconductor material which is expensive and 
currently in short supply. Additionally, increasing 
the concentration ratio improves the performance of 
general photovoltaic systems. 
 
 
Fig: 1- A solar cell in sunlight collecting 
Despite the advantages of CPV technologies their 
application has been limited by the costs of 
focusing, tracking and cooling equipment. However 
some of the ambitious projects using CPV 
technologies are taken in different parts of the 
world. [1] 
 
2. Solar tracking technique  for CPV 
 
In CPV system sun light tracking is an important 
section. The popular and simple sun light tracking 
systems are given below.  
   
2.1. Parabolic trough concentrator 
A parabolic trough is a type of solar thermal energy 
collector. It is constructed as a long parabolic 
mirror (usually coated silver or polished aluminum) 
with a Dewar tube running its length at the focal 
point. Sunlight is reflected by the mirror and 
concentrated on the Dewar tube. The trough is 
usually aligned on a north-south axis, and rotated to 
track the sun as it moves across the sky each day. 
Alternatively the trough can be aligned on an east-
west axis; this reduces the overall efficiency of the 
collector, due to cosine loss, but only requires the 
trough to be aligned with the change in seasons, 
avoiding the need for tracking motors. This 
tracking method works correctly at the spring and 
fall equinoxes with errors in the focusing of the 
light at other times during the year (the magnitude 
of this error varies throughout the day, taking a 
minimum value at solar noon). There is also an 
error introduced due to the daily motion of the sun 
across the sky, this error also reaches a minimum at 
solar noon. Due to these sources of error, 
seasonally adjusted parabolic troughs are generally 
designed with a lower solar concentration ratio. In 
order to increase the level of alignment, some 
measuring devices have also been invented.  
Heat transfer fluid (usually oil) runs through the 
tube to absorb the concentrated sunlight. This 
increases the temperature of the fluid to some 
400°C. The heat transfer fluid is then used to heat 
Page 573
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
  
steam in a standard turbine generator. The process 
is economical and, for heating the pipe, thermal 
efficiency ranges from 60-80%. The overall 
efficiency from collector to grid, i.e. (Electrical 
Output Power)/(Total Impinging Solar Power) is 
about 15%, similar to PV (Photovoltaic Cells) 
 
 
Fig:-2 Solar tracking technique. 
2.2. Parabolic dish concentrator 
A dish system uses a large, reflective, parabolic 
dish (similar in shape to satellite television dish). It 
focuses all the sunlight that strikes the dish up onto 
to a single point above the dish, where a receiver 
captures the heat and transforms it into a useful 
form. Typically the dish is coupled with a Stirling 
engine in a Dish-Stirling System, but also 
sometimes a steam engine is used. These create 
rotational kinetic energy that can be converted to 
electricity using an electric generator. [2] 
 
The advantage of a dish system is that it can 
achieve much higher temperatures due to the higher 
concentration of light (as in tower designs). Higher 
temperatures lead to better conversion to electricity 
and the dish system is very efficient on this point. 
However, there are also some disadvantages. Heat 
to electricity conversion requires moving parts and 
that result in maintenance. In general, a centralized 
approach for this conversion is better than the 
decentralized concept in the dish design. Second, 
the (heavy) engine is part of the moving structure, 
which requires a rigid frame and strong tracking 
system. Furthermore, parabolic mirrors are used 
instead of flat mirrors and tracking must be dual-
axis. 
 
2.3. Power tower concentrator 
Power towers (also known as 'central tower' power 
plants or 'heliostat' power plants) capture and focus 
the sun's thermal energy with thousands of tracking 
mirrors (called heliostats) in roughly a two square 
mile field. A tower resides in the center of the 
heliostat field. The heliostats focus concentrated 
sunlight on a receiver which sits on top of the 
tower. Within the receiver the concentrated sunlight 
heats molten salt to over 1,000 °F (538 °C). The 
heated molten salt then flows into a thermal storage 
tank where it is stored, maintaining 98% thermal 
efficiency, and eventually pumped to a steam 
generator. The steam drives a standard turbine to 
generate electricity. This process, also known as the 
"Rankine cycle" is similar to a standard coal-fired 
power plant, except it is fueled by clean and free 
solar energy. 
The advantage of this design above the parabolic 
trough design is the higher temperature. Thermal 
energy at higher temperatures can be converted to 
electricity more efficiently and can be more cheaply 
stored for later use. Furthermore, there is less need 
to flatten the ground area. In principle a power 
tower can be built on a hillside. Mirrors can be flat 
and plumbing is concentrated in the tower. The 
disadvantage is that each mirror must have its own 
dual-axis control, while in the parabolic trough 
design one axis can be shared for a large array of 
mirrors. [3] 
 
3. Advance of CPV system 
 
The largest solar electric generating plant in the 
world produces a maximum of 354 megawatts 
(MW) of electricity use CPV system and is located 
at Kramer Junction, California. Another plant is 
under construction in California of 850 MW under 
California energy commission. In Sothern Nevada 
City have 110MW electric plant using 
Concentrating solar system. There is also small 
electricity producing plant in Austin city its 
produce 60 MW electricity. Now a day’s USA are 
work with CPV system to produce more and more 
electricity. 
  
3.1. Comparison between CPV and conventional  
        Solar system: 
 Solar CPV 
system 
conventional 
Solar system 
Size Small Big 
Effective area Very Big. Normal. 
Efficiency  High.  Low. 
Construction  Simply hard.  Easy 
construction. 
Capture 
ability  
Sun light can 
be captured 
easily and 
quickly. 
Sun light can 
be captured 
easily but not 
quickly.  
Charging 
capability 
Need 5-6 hour 
sunlight to 
charge a 
Need 8-10 
hour sunlight 
to charge a 
Page 574
  
battery.  battery. [4] 
Current 
capacity  
For a given 
size we obtain 
minimum 40% 
more current 
then a 
conventional 
solar cell 
system. [5] 
For a given 
size we obtain 
minimum 
40watt current. 
 
Reduced cost  It is possible to 
reduce 30% 
cost to use 
concentrating 
photovoltaic 
system (CPV) 
in solar panel.  
The price of a 
solar system 
ranges from 
25,000 taka 
($360) to 
65,000 taka 
($940) 
depending on 
capacity. [6] 
Table 1 shows a comparison between conventional 
solar system (PV) and Concentrator Photovoltaic 
technologies. A CPV system provides more 
economic and powerful electricity. By using solar 
concentrator technology we can get much more 
current than normal solar cells. An important aspect 
of CPV system is it delivers more solar power from 
a compact size of system which eliminates the need 
to build larger systems occupying big areas. 
3.2. PV system Efficiency 
Figure:-3 show the development of efficiency of 
different types of PV systems. Its is evident from 
the graph that the efficiency of a CPV system is 
much higher then a convention system. 
 
 
Fig-3:  efficiency difference of PV system. 
 
As conventional solar systems are still relatively 
expensive, but using highly efficient CPV systems 
will reduce the cost by 30%. [7] 
 
4. Solar Photovoltaic (PV) technology in  
    Bangladesh 
Rural electrification through solar PV technology is 
becoming more popular, day by day in Bangladesh. 
Today, more than 230,000 households are using 
solar powered systems in Bangladesh. [8] Giving 
rise to opportunities for a whole new generation of 
entrepreneurs to make use of this new power supply 
for the poor Infrastructure.  
Solar Home Systems (SHSs) are highly 
decentralized and particularly suitable for remote, 
inaccessible areas. In Bangladesh Solar program 
mainly targets those areas, which have no access to 
conventional electricity and little chance of getting 
connected to the grid within 5 to 10 years. It is one 
of its most successful programs.  
Currently, SHSs can be used to light up homes, 
shops, fishing boats etc. It can also be used to 
charge cellular phones, run televisions, radios and 
cassette players. SHSs have become increasingly 
popular among users because they present an 
attractive alternative to conventional electricity 
such as no monthly bills, no fuel cost, very little 
repair, maintenance costs, easy to install any where 
etc. 
 
4.1. Solar electricity necessary in rural area 
This is some of the impact electricity is bringing to 
people’s lives the people of rural Bangladesh need 
electricity badly to improve their life. Basically it is 
quite impossible to live up without electricity. 
Another most important thing is they are not 
economically well of so if they use electricity they 
can save there money to use costly fuel. Time spent 
by a child on studying is likely to be increased by 
about 6 percent under electric lighting than when 
kerosene lamp or dry cell battery is used. 
Increase of electricity use at home leads to a 
decrease of 20 percent in children’s school-days 
missed caused by illness, compared to non-
electrified areas; Electricity use at home makes 18 
percent more time available per day for listening to 
radio compared to areas without electricity. Time 
spent on household chores decrease by 6 percent in 
the electrified households compared to non-
electrified households. [4] 
Use of electricity at home increases the incidence of 
home business by about 8 percent compared to non-
use of electricity at home. More security and 
income generation opportunities including reduced 
work load for women.  Businesses such as rice 
mills, saw mills, grocery, tailoring shops, 
restaurants, market places etc with the help of SHSs 
have increased their income by extending working 
Page 575
  
hours after dusk. PV systems have opened up new 
opportunities for employment and income 
generation activities, such as community television 
centers, electronic repairing shops, mobile phone 
shops etc.  
 
4.2. Bangladesh problem and opportunities 
About 80% of the people in Bangladesh live in 
villages where the main source of income is 
agriculture. Another income source is fishing and 
small business. [9] 
Most of the people are living below in average 
income level. In our country maximum village are 
not connected with national grids to give or served 
current to our rural area people. 
This is really too hard to use solar panel to 
electricity at present costing rate. Most of these 
people are deprived of electricity, which is a 
necessity in today’s life. Getting grid electricity to 
these villages has proved to be beyond their reach, 
thus making it much more reasonable to turn to 
renewable energy (which is available in Abundance 
and cheaper) for electrification. 
Solar electricity of solar concentrator technology is 
very important in our country, there are no another 
way to develop our country or cant live properly 
without solar current. 
Only 30% of the total population having access to 
the grid electricity clearly indicates the acute 
shortage of electrical power in Bangladesh. The 
scenario is far worse in rural areas Due to the 
shortage of power. Our country is one of the poor 
countries in the world, so economic problem is one 
of the major problems to develop national grid. We 
don’t have much electricity to fill our expectation, 
and Bangladesh is the land of river, this is another 
reason of our country why the government face 
problem to develop electricity in all over the 
Bangladesh, for the reason of big river don’t go 
there national grid line.  
Bangladesh receives about 300 clear sunny days per 
year, [10] and this is enough to produce an 
enormous amount of solar energy in a sustainable 
way. For this reason, it is easy to develop solar 
electricity of solar concentrator technology forward 
in the right direction.  
This is our great opportunity that we get more than 
300 days sun light, if we able to set our solar 
concentrator technology than we can reduce energy 
source like fuel and gas. In our country Average 
solar radiation varies between 4 to 6.5 kWhm-2day-
1. And Maximum amount of radiation is available 
in the month of March-April and minimum in 
December-January. 
 
4.3. Current status of solar electricity in  
       Bangladesh 
The Government of Bangladesh aims at providing 
electricity to its entire rural population by 2020 to 
help boost up social development and economic 
growth. In 2002, access to electricity in Bangladesh 
was about 30 percent. With the Rural 
Electrification Board connecting about 40,000 
consumers every year, it would take more than 35 
years to provide access to electricity to all. 
Furthermore, it is physically difficult and 
economically not feasible to bring the whole 
country under a grid based on electricity network 
because Bangladesh is a delta with more than 400 
rivers. [11]. Access to electricity has increased to 
38% from 30% in 2004. At the same time 80,000 
consumers had been provided with Solar Home 
Systems (SHS), surpassing the original target of 
50,000. 
These households, connected by SHS, would have 
never received electricity if only conventional 
electrification methods had been used. Access to 
electricity has increased to 41% from 38% in 2006. 
Grameen Shakti (GS) and Rahim Afrooz are giving 
the rural people solar panel. GS has developed one 
of the most successful projects for popularizing 
Solar Home Systems to millions of rural villagers. 
Currently GS is one of the largest and fastest 
growing rural based renewable energy companies 
in the world. As of July 2007, GS has installed 
more than 100,000 SHSs in rural areas with more 
than 4000 SHSs installed per month. This success 
especially was the result of unique approach, 
blending market and social forces together to take 
world’s most up to date technology to the rural 
people. The cost of a single unit of PV system as 
supplied by GS and RA is about 25000/- to 60000/- 
by capacity range of solar cell.  
By using solar concentrator technology it is 
possible to reduce cost and get more current. If we 
use this technology we can reduce 30% [6] costs 
and get more electricity. This technology helps our 
rural people to get current. They waste their money. 
But they can’t get proper light. To use this 
technology this people can change their life. 
4.4. Comparison of costs between convention PV  
       & Concentrator PV (CPV) systems 
The following table contains a comparison between 
the cost of a CPV and normal PV system. 
Introduction of CPV system would reduce 1656 
million taka from the period 2005/6 – 2009/10). 
The saving is noticeably large which could be 
reinvested in solar electricity to increase number of 
clients. 
 
Page 576
  
Year Number 
of users 
Total cost (Million 
Taka) 
Cost 
reduction 
(Million 
Taka) PV 
system 
CPV 
system 
2005/6 85000 680 476  
2007/8 215000 1720 1204  
2009/10 390000 3120 2184  
5 Years  5520 3864 1656 
** The PV system user data and PV system cost collected from  Grameen 
Shakti. 
 
5. CONCLUSIONS 
 
It is evident from the study that using concentrators 
on conventional solar photovoltaic systems increase 
the performance of the system. It increases the 
Efficiency, Sun tracking for increased energy 
production. It increases supply of solar electricity 
which is proved to be efficient and very cost 
effective for rural Bangladesh. If the Bangladesh 
use of concentrator technology (CPV) could be 
ensured then it would increase 40% more electricity 
and reduce 30% cost compared to conventional 
systems. 
 
Introduction of the PV to CPV systems from the 
period 2005/6 to 2009/10, about more than one Lac 
household could be brought under solar electricity 
without spending addition money. I want say if 
solar electric generating plant established using 
CPV in rural area than it possible to remove 
darkness in our country to fulfill electricity 
demand, where national grid is not reached. 
Again focus in Bangladesh weather more than 300 
sunny days in a year, so this is huge opportunity to 
build solar electric plant use CPV technology. 
 
REFERENCES 
 
1. Lenardic, Denis, "History of 
photovoltaics". PVResources.com, 2005. 
       http://www.pvresources.com/en/history.php 
2. "Linear-focusing Concentrator Facilities: 
DCS, DISS, EUROTROUGH and LS3". 
Plataforma Solar de Almería. Archived 
from the original on 28 September 2007. 
Retrieved 2007-09-29. 
3. utility-scale photovoltaic power system-
“The solar collector is the key element in a  
              solar energy          system” 
       http://www.powerfromthesun.net/chapter1/ 
4. “Solio Solar-Powered Charger and 
Battery” 
       http://www.amazon.com/Solio-Solar-Powered- 
               Charger-Battery-iPod/dp/B000BD1A6Y 
5. Waren Nishikawa, Steve Horne and Jane 
Malia “LCOE for Concentrating 
Photovoltaics (CPV)” 
6. “Solar power lights up lives in rural 
Bangladesh” 
       http://www.reuters.com/article/ 
               lifestyleMolt/idUSDHA3651120070515 
7. Rusi Patel "Solar Concentrating Power vs. 
PV Power" Sunday, March 2, 2008. 
8. Solar Powered Village Kick-Starts 
Development Goals 
       http://www.nowpublic.com/environment/solar- 
              powered-village-kick-starts-development-  
              goals 
9. “Promoting solar PV for poverty reduction 
in Bangladesh” 
       http://www.hedon.info/PromotingSolar 
              PVForPovertyReductionInBangladesh. 
10. Kristine Heine, +1-202-371-9600, 
kheine@globalcommunicators.com, for 
Grameen Shakti. “Bangladesh Renewable 
Energy Pioneer Grameen Shakti Presents 
Rural-Based Solar Home” 
11. .International development association 
(IDA) “Electricity for rural population in 
Bangladesh” 
        http://www.worldbank.org/IDA/electricity for  
              rural area 
Page 577
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Omar Farrok,  
E-mail: omarruet@gmail.com  
 
Electrical, Hall Effect and optical properties of undoped Co thin films 
 
N.A. Shafi1, O. Farrok*, Z. Islam2 and J. Islam3 
 
1SAR SECURITIES LTD, Motijheel, Dhaka-1000. 
*Rajshahi University of Engineering & Technology, Rajshahi-6204, Bangladesh 
2University of Blekinge Institute of technology, Blekinge, Sweden.  
3Rajshahi University (RU) Rajshahi-6204, Bangladesh 
 
 
Undoped Co thin films have been prepared onto glass substrate by e-beam evaporation in vacuum at about 
2×10-4 Pa. The thickness of the films ranges from 50 to 200 nm. The deposition rate of the films was about 
0.93 nms-1. The as-deposited films have been annealed in open air for 4 hours at constant temperature of 523 
K. Electrical resistivity for the as-deposited and annealed films has been measured as a function of 
temperature ranging from 303 to 451 K. The resistivity of as-deposited films on glass substrate is found to 
increase from 8.51 to 3.32 µΩ-m as the thickness of the films increased from 50 to 200 nm. The resistivity of 
the films on glass substrate is increased after annealing. The activation energy is found to decrease with 
increasing film thickness. On the other hand, the grain size is increased with increasing film thickness. The 
activation energy of 50nm as-deposited Co film on glass substrate was found to 0.027 eV. It is decreased to 
0.0086 eV for to 200nm film. The grain size was found to increase with increasing film thickness. The Hall 
Effect measurement showed that the Hall coefficient of Co films on glass substrate is decreased with 
increasing film thickness. It is found to increase after annealing for both Co films on glass substrate. The 
carrier concentration was 13.3 x1019 cm-3 for 100nm Co film on glass substrate. The refractive index is 
found to decrease with increasing film thickness for both as-deposited and annealed films on glass substrate. 
It is observed that the dielectric constant is strongly depends on thickness of the films. It is about 10 for 50 
nm but decreased to only 2 for 200 nm films. These studies may be of importance for the application of this 
material in electronic and magnetic storage devices and magnetic sensor. Co thin films have been produced 
by electron beam bombardment heating technique and thickness meesures in Fizeau fringes method. 
Electrical resistivity and Hall Effect studies are measured Van-der-Pauw technique.Optical studies is 
measured by Murman method. 
 
Key words: Hall Effect, Dielectrice, Refractive index, Carrier, Mobility.  
 
1. INTRODUCTION 
 
Research and development on thin films has led to 
the conclusion that different classes of materials are 
of particular interest for different applications. 
Cobalt is of particular interest because the material 
has in recent a variety of applications spin-
FET[1],spin-valve transistors[2-3],head for 
magnetic hard disk drives[4], MRAM[2,5], 
GMR[6,7,8-14], TMR[15-18], magnetic field 
sensor[19-21]. A large value of GMR ratio 
observed at room temperature in sputtered sample 
of Co/Cu layered structure if the Cu spacer layer 
thickness is chosen to make the oscillatory 
exchange coupling between Co layers [22-24]. 
Incorporating a ferromagnetic component into an 
integrated electronic device structure offers several 
advantages [25]. Therefore, an understanding of 
growth and micro-structural evolution of Co thin 
layers, their corresponding crystal structures and 
associated magnetic and transport properties are of 
great technological interest. However, as per the 
best of our knowledge no report available in the 
literature correlates electrical, Hall Effect and 
optical properties of Co thin films on glass 
substrates. Therefore, in the present work, we have 
studied the electrical, Hall Effect and optical 
properties of Co thin films deposited on these 
substrates. The results obtained from different 
characterization techniques are analyzed and 
discussed. 
 
2. EXPERIMENTAL 
 
Undoped Co thin films have been produced onto 
glass substrates by electron beam bombardment 
heating technique in vacuum at about 2×10-4 Pa 
from pure solid Co obtained Japan. Before 
Page 578ISBN: 978-984-33-2140-4
  
deposition, the deposition chamber was thoroughly 
cleaned with emery paper and cotton wool by 
wetting acetone and was then dried with a dried 
with a dryer. A small quantity of source materials 
was loaded into clean cermet hearth based on the 
source turret. The glass substrates were then first 
cleaned in chromic acid solution and then washed 
in distilled water. After washing and drying in hot 
air, the substrates were then again cleaned in 
acetone and dried in hot air, and were then again 
cleaned in acetone and dried in hot air, and were 
then used for deposition. Finally, the cleaned 
substrates were placed on the substrate holder about 
0.1m above the source turret and the chamber bell-
jar was placed on the base plate. A mechanical 
shutter was operated form outside, isolated the 
substrates from the evaporants. When the chamber 
pressure reduced about 2×10-4 Pa, the deposition 
was then started with 30mA by turning on the low-
tension control switch. All films were deposited at 
room temperature.     
 
3. EFFECT OF CURRENT ON 
DEPOSITION  
To assess the effect of chamber current on 
deposition conditions, five Co films of variable 
thickness were deposited at variable current. The 
variation of deposition rate with deposition current 
Co thin films on glass substrate is shown in Fig-1. 
From this graph, it is seen that the deposition rate 
increases with increasing deposition current at 
constant time of 25sec. At higher current more 
samples evaporates from the source thus the 
deposition rate increases [26].  
 
Fig-1: Variation of deposition rate with deposition 
current of Co thin films on glass substrate. 
 
4. RESULTS AND DISCUSSION 
 
In this section the results and discussions of various 
experimental studies on Cobalt thin films have been 
presented step by step. A brief description of 
electrical properties has been seen on variation of 
resistivity, temperature coefficient of resistance 
with temperature and variation of ln with inverse 
temperature, variation of activation energy and 
grain size with thickness, size effect of co thin film. 
It is also seen that Hall Effect studies like variation 
of hall coefficient, carrier concentration with 
magnetic field. A brief description of optical 
studies is observed on variation of transmittance, 
refractive index and dielectric constant with 
wavelength.  
 
4.1 ELECTRICAL PROPERTIES OF 
Co THIN FILMS 
  
The resistivity of as-deposited Co thin films of 
thicknesses 50, 100 and 200 nm are shown in Fig-2(a) 
.After annealing Co thin films of thickness 100 and 
200nm, the resistivity is represented in Fig-2(b). The 
resistivity is changed with temperature for both as-
deposited and annealed films. It is seen from the 
graphs that the values of resistivity increase with 
increasing temperature. This type of variation 
indicates the metallic behavior of the films[27]. It is 
evident from the graph that the resistivity increases 
when film thickness decreases. This follows 
Funchs-Sondhiemer size effect theory [28-29]. 
 
 
Fig-2(a): Variation of resistivity with temperature 
for as-deposited Co thin films on glass substrate. 
 
 
Fig-2(b): Variation of resistivity with temperature 
for annealed Co thin films on glass substrate. 
Page 579
  
Variation of Temperature Coefficient of Resistance 
(TCR) with temperature for both as-deposited and 
annealed Co films on glass substrate is shown in 
Fig-3(a) and 3(b). It is seen from the graphs that for 
both the cases the TCR is positive, which indicates, 
that films are metallic. The TCR value is 
anomalous for both the cases with variation 
temperature [30]. 
 
 
Fig-3(a): Variation of T. C. R (%) with temperature  
for as-deposited Co thin films on glass substrate. 
 
 
 
Fig-3(b): Variation of T. C. R (%) with 
temperature for annealed Co thin films on glass 
substrate. 
 
It is observed that lnσ vs. 1/T curve is a linear and it 
is increased with inverse temperature for the as-
deposited Co films. Grain sized is related to the 
potential barrier and according to Garter [31] grain 
size is inversely proportional to the activation 
energy. It is seen from Fig-4 and table-1 that the 
activation energy is found to decrease for Co films. 
It is also seen from the graphs that the grain size is 
increased with increasing film thickness. These 
agrees with the fact that the grain size depends on a 
lot of factors such as deposition condition, 
annealing temperature, dislocations, minor defects, 
stacking faults etc [32]. 
 
 
Fig-4: Variation of activation energy and grain size 
with thickness for as-deposited Co thin films on 
glass substrate. 
 
Table-1: Activation energies and grain sizes 
evaluated for Co thin films. 
Activation energy  Grain size 
Thickness, 
t[nm] 
Activation energy, 
E[eV] Grain size, r[Ao] 
As-
deposited 
Annealed As-
deposited Annealed 
50 0.027  177.78  
100 0.0185 0.0123 259.46 390.24 
200 0.0086 0.0371 558.14 129.38 
 
Variation of lnσ with thickness for Co films is 
shown in Fig-5. It is observed that the conductivity 
increases sharply with thickness up to 200 nm and 
above this there is no remarkable change in 
conductivity. The thickness dependence of 
conductivity is well in conformity with Fuchs-
Sondheimer theory [27-28, 33-34]. 
 
 
Fig-5: Variation of lnσ versus thickness for 
undoped Co thin films on glass substrate. 
 
According to the theory of size effect, during the 
growth of the film discrete islands are formed on 
the substrate result in discontinuous film. The 
scattering of conducting electrons become large for 
this growth. In fact the film is highly resistive. But 
due to increase of the film thickness it become 
continuous, as a result the conductivity of the films 
Page 580
  
is increased. The conductivity of the films at the 
lower thickness may decreases sharply due to 
surface scattering. In addition to surface scattering, 
the usual lattice defect and grain boundary 
significantly contribute to conductivity. For the 
films at higher thickness increases in conductivity 
may be due to the formation of large crystallites. 
This types work is done as NiO [35]. 
 
4.2 HALL EFFECT STUDIES OF Co 
THIN FILMS 
 
Hall effect studies for both the as-deposited and 
annealed Co thin films on silicon and glass 
substrates have been carried out by Van-der-paw 
[36] technique. The effect of magnetic field on 
various parameters has been investigated by the 
Hall studies. 
 
The Hall coefficient of as-deposited Co thin films of 
thicknesses 50, 100 and 200 nm are shown in Fig-6(a). 
The Hall coefficient of annealed Co thin films of 
thicknesses 100 and 200 nm, the Hall coefficient is 
represented in Fig-6(b). It is seen from the Figures that 
for both the cases Hall coefficient is always positive 
[37]. This indicates that the carrier in the Co thin films 
is always holes. It is also evident from the Figures that 
the Hall coefficient increases with increasing 
applied magnetic field. It is revealed that Hall 
coefficient is higher for films of lower thickness. 
After annealing, Hall coefficient increases from that 
for as-deposited films. 
 
Fig-7(a) and 7(b) represents the variation of carrier 
concentration with magnetic field of Co thin films 
on glass substrate. It is observed from the Figures 
that for as-deposited films carrier concentration is 
lower than annealed films. It is also evident that for 
both the cases carrier concentration decreases with 
increasing applied magnetic field. Both the carrier 
concentration increase monotonically with the 
concentration of Co increased [38]. 
 
 
Fig-6(a): Variation of Hall co-efficient with 
applied magnetic field for as-deposited Co thin 
films on glass substrate. 
 
Fig-6(b): Variation of Hall co-efficient with applied 
magnetic field for annealed Co thin films on glass 
substrate. 
 
Fig-7(a): Variation of carrier concentration with 
applied magnetic field for as-deposited Co thin 
films on glass substrate. 
 
 
Fig-7(b): Variation of carrier concentration with 
applied magnetic field for annealed Co thin films 
20
30
40
50
60
70
80
1 2 3 4 5 6 7 8
50nm
100nm
200nm
C
ar
rie
r c
on
ce
nt
ra
tio
n,
 n
 [(
n/
cm
3 )
x1
01
9 ]
Magnetic field, B [KGs]
Page 581
  
on glass substrate. 
4.3 OPTICAL PROPERTIES OF Co 
THIN FILMS  
 
Spectral transmittance T() and near normal 
reflectance R() of Co thin films on glass substrate 
have been measured at wavelength 370<<1100 
nm using SHIMADZU UV-visible 
spectrophotometer. 
 
Fig-8 shows the variation of refractive index with 
wavelength of incident light. It is clear from the Figure 
that the refractive index increases with increasing 
wavelength but it is decreased with increasing film 
thickness. The value of refractive index of 200nm as-
deposited film is 1.3 but it is increased to 1.8 for 50nm 
films at 400nm wavelength. Refractive index is non 
linear [39]. 
 
 
Fig-8(a): Variation of reflective index with 
wavelength for as-deposited Co thin films on glass 
substrate. 
 
 
Fig-8(b): Variation of reflective index with 
wavelength for Annealed Co thin films on glass 
substrate. 
 
The dependence of dielectric constant on 
wavelength for both the as-deposited and annealed 
Co thin films of different thicknesses is shown in 
Fig-9 (a) and 9(b). It is evident from the Figures 
that for the as-deposited films dielectric constant 
ranges from 1.91 to 10.91 and for annealed films it 
ranges from 1.88 to 7.1. The frequency dependence 
which is found to be similar to that for metal-
dielectric composites.This compound can work as a 
metal-dielectric composite even in a form of single 
crystal, a possible mechanism of which is suggested 
on the basis of the electronic conFiguration of Co 
ions [40]. 
 
 
Fig-9(a): Variation of dielectric constant with 
wavelength for as-deposited Co thin films on glass 
substrate. 
 
Fig-9(b): Variation of dielectric constant with 
wavelength for annealed Co thin films on glass 
substrate. 
 
5. CONCLUSION  
 
Various deposition parameters especially the 
chamber current has remarkable effects on the 
deposition of e-beam evaporated Co thin films. The 
thickness dependence of electrical resistivity is well 
in conformity with Funchs-Sondhiemer size effect 
theory. The TCR and electrical resistivity studies 
exhibit metal behavior. The calculation of 
activation energy suggests that thermally activated 
conduction mechanism plays significant role in 
conduction process. Hall Effect studies of Co 
samples exhibit a p-type carrier. Optical studies 
exhibit high refractive index in the near infra-red 
region. At the same case, dielectric constant exhibit 
high in the near infra-red region.   
 
REFERENCES 
 
[1]  S. Datta and B. Das, Appl. Phys. Lett. 56 
(1990) 665. 
[2] D.J. Monsma et al., IEEE Trans. Magn. 33 
(1997)3495. 
[3]  R. Jansen et al., J. Appl. Phys. 89 (2001) 7431. 
[4]  Wall Street Journal, 10 November 1997, p. B8. 
Page 582
  
[5]  D.D. Tang et al., IEEE Trans. Magn. 31 (1995) 
3206. 
[6]  M. N. Baibich et al., Phys. Rev. Lett. 61 (1988) 
2472. 
[7]  J. M. Daughton et al., IEEE Trans. Magn. 30 
(1994) 4608. 
[8]  P. Grunberg et al., J. Appl. Phys. 61 (1987) 
3750. 
[9]  N. Hosoito et al., J.Phys. Soc. Jpn. 59 (1990) 
1925.  
[10] A. Barthelemy et al., J. Appl. Phys. 67 (1990) 
5908. 
[11] Treuya Shinjo and Hidefumi Yamamoto, 
J.Phys. Soc. Jpn. 59 (1990) 3061. 
[12] E. Velu et al., Phys. Rev. B 37 (1988) 668. 
[13] T. Takahata et al., J. Magn. Magn. Mat. 82 
(1989) 287. 
[14] C. Dupas et al., J. Appl.Phys. 67 (1990) 5680. 
[15] J. S. Moodera et al., Phys. Rev. Lett. 74 (1995) 
3273. 
[16] J. S. Moodera and G. Mathon, J. Magn. Magn. 
Mater. 200 (1999) 248. 
[17] S. S. P. Parkin et al., J. Appl. Phys. 85 (1999) 
5828. 
[18] J. De Boeck and G. Broghs, Phys. World 12 
(1999) 27. 
[19] G. A. Prinz, Science 282 (1998) 1660. 
[20] S. A. Wolf et al., Science 294 (2001) 1488. 
[21] S.S.P. Parkin et al., Proc. IEEE 91 (2003) 661. 
[22] S.S.P. Parkin et al., Phys. Rev. Lett. 64 (1990) 
2304. 
[23] S.S.P. Parkin et al., Phys. Rev. Lett. 66 (1991) 
2152. 
[24] S.S.P. Parkin et al., Phys. Rev. Lett. 58 (1991) 
2710. 
[25] Mark Johnson, IEEE Trans. Mag. 36 (2000) 
2758. 
[26] Chopra KL. Thickness measurement and 
analytical techniques, In: Thin films                                                                                                                                                                                            
phenomena. New York: McGraw-Hill; 
1969.p.346. 
[27] Transactions of the Japan Institute of Metals, 
Vol. 29, No. 3 (1988), pp. 183 to 190. 
[28] K. Fuchs, Proc. Cambridge Phil. Soc., 34 
(1938) 100. 
[29] F.H. Sondheimer, Phys. Re., 80 (1950) 401. 
[30] Fuchs K. Electron transport phenomena in 
metallic films. In: Chopra KL, editor. Thin film 
phenomena. New York: McGraw-Hill; 
1969.p.346. 
[31] Sondheimer EH. Adv. Phys. 1952;1:1. 
[32] A K Pal et al 1976 J. Phys. D: Appl. Phys. 9 
2261. 
[33] C. J. Grater, Physics, 17 (1951) 77. 
[34] L.I Maissel and R. Glang., “Hand book of Thin 
Film Technology” McGraw-Hill, Book 
company-New York 1970. 
[35] A.Hakim, J. Hossain, K.A. Khan Renewable 
Energy (2009). 
[36] Van-der-Pow, Philips Res. Rept., Vol. 13, 
1958, P.1. 
[37] J Ivkov and E Babic 1990 J. Phys.: Condens. 
Matter 2 3891. 
[38] K Gopinadhan et al 2008 J. Phys.: Condens. 
Matter 20 125208. 
[39] Hiroki Yamamotoa) and Shuhei Tanaka, 
VOLUME 81, NUMBER 6 ,5 AUGUST 2002. 
[40] Y. Nagao and I. Terasaki* Phys. Rev. B 76, 
144203 (2007) Volume 76,  Issue 14. 
 
Page 583
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
    
* Corresponding Author: Shamendu Roy Rohit 
E-mail: rohit.shamendu@aiub.edu 
Experimental Analysis on Wireless Energy Transfer via Strongly 
Coupled Magnetic Resonances 
 
1Shamendu Roy Rohit*, 2Md Tasnim Alam, 3Shadeeb Hossain, 4Adnan Maqsud,  
5Najia Hossain, 6Dr. Mohammad Tarique and 7Md. Maruf Hossain 
Department of Electrical and Electronic Engineering, American International University-
Bangladesh 
 
 
This paper describes a simple system of transferring energy wirelessly via strongly coupled magnetic 
resonance using non-radiative near field. Here the feasibility of transferring energy by using a small 
receiving self-resonant coil with respect to a large source self-resonant coil is experimentally verified. 
Experimental results show that a number of small coils can act as receiver at a time. Moreover, it is found 
that each receiving coil acts as a repeater; hence with the increase in number of the receiving self-resonant 
coil the efficiency increases. Experimental results also show that when the parameters of the source and 
receiving self-resonant coil are same, the efficiency of transferring energy is more than 62%; the distance of 
energy transfer is around 1.2 meter and any non metallic objects placed in between the source and receiving 
coil does not interrupt in the energy transfer mechanism. The future applying fields are wide, such as 
supplying power wirelessly to portable devices including laptops, cell phones, MEMS, pacemaker etc.. 
 
Key words: Wireless, Energy transfer, magnetic resonance, non radiative near field, coupling. 
 
1. INTRODUCTION 
 
Wireless power transfer concept existed since the 
20th century by Nikola Tesla [1-3]. In his proposed 
system for power transfer over large distances 
involved extremely large electric fields which could 
cause a major health hazard. Therefore it was 
banned. Due to the recent advancement in 
technology, portable devices such as cell phones, 
lap top etc has become very popular. These portable 
devices need their battery to be recharged. To 
recharge them wirelessly the concept of wireless 
power transfer is again reconsidered [4-6]. 
 
Recently a group of MIT students were able to 
transfer power in watt range using strongly coupled 
magnetic resonance [7-8]. They used magnetic 
coupling to power up the source self-resonant coil. 
Another group of students from China were also 
able to transfer power up to 50W at a small distance 
using wire coupling self-resonant coils [9]. Both of 
the groups suggested that it could be possible to 
transfer power using a very small self-resonant 
receiving coil with respect to the source self-
resonant coil. In this paper the feasibility of their 
suggestions are experimentally proven along with 
their previous work, using different size of coils 
having different diameters, different cross sectional 
area of the wire of the self-resonant coil and 
different helix length.  
The concept we employed allows a source and a 
receiver to exchange energy efficiently over mid-
range distance, with little or no loss of energy 
occurring to secondary objects. By mid range we 
mean that the separation between the two objects 
should be of the order of a few times of the size of 
the objects.  
 
The wireless power transfer for mid-range or long 
range distances is done by electromagnetic 
radiation which is very harmful for biological 
tissues. Radiative transfer [10] is used to transfer 
information for communication purposes but if it is 
used for power transfer the efficiency becomes 
extremely low. It also requires Line Of Sight 
communication and if the radiation is omni 
directional efficiency is extremely low.  Even if the 
radiation is made unidirectional it might be 
hazardous to the living organism, interrupting its 
Line Of Sight communication between the 
transmitter and receiver and also a sophisticated 
receiving mechanism is needed. 
 
An alternative approach is used to overcome this 
obstacle by designing the transmitter and receiver at 
the same resonant frequency for the mid range 
energy transfer. When two objects have same 
resonant frequency there is a strongly coupled 
regime of operation [11]. If energy transfer is made 
in this regime, the efficiency is extremely high. 
Page 584ISBN: 978-984-33-2140-4
  
This method supports mid range power transfer and 
also supports omni directional power transfer with 
no loss to the secondary object whose resonant 
frequency is different to that of the source and 
receiving self-resonant coil. 
 
Considering the danger of the electric field, 
magnetic fields as well as magnetic systems are 
used to establish magnetic resonance [12]. This 
method is safer and does not involve health hazard. 
As previously stated for efficient power transfer 
between two objects they need to be operated in a 
strongly coupled regime. In our experiment we 
achieved this condition in MHz range (at initial 
setup) and KHz range (at second and third setup) of 
frequencies. 
 
Resonant induction is widely used in many 
technologies available today (e.g. radio receiver 
[13]), yet their efficiencies are not very good at mid 
range distances. The strong-coupling regime, for 
which the resonance is a precondition, makes the 
power transfer efficient. 
 
2. ENERGY TRANSFER VIA 
COUPLED MAGNETIC 
RESONANCES 
 
Resonance is a way to transfer energy from one 
object to another. For example, if a tuning fork with 
a certain resonant frequency is stroked then it starts 
vibrating. If a second tuning fork having the same 
resonant frequency is brought close to first one then 
the second one starts vibrating at its maximum 
amplitude. It is due to the resonance phenomenon. 
The energy which makes the second fork phonating 
comes from sound wave generated by the first fork; 
the energy transfer medium is sound field. Every 
object has its own self-resonant frequency. 
Therefore any two objects having same self- 
resonant frequency can exchange energy efficiently 
in between them, only when they are in resonance.   
 
Similar to sound energy transfer principle, 
electromagnetic resonance can be used for electric 
energy transfer mechanism. But it involves electric 
field radiation which is a major health hazard for 
the living beings. Considering the danger to people 
and other organisms in electric field, the magnetic 
field is safe and more suitable to be used as the 
energy-transfer medium. Therefore, in this 
experimental analysis magnetic resonance is used 
for energy transfer mechanism. 
 
Let us consider a simple LC system consisting of an 
ideal capacitor and an ideal inductor connected in 
parallel as shown in figure 1. Assuming that an 
amount of energy was supplied to the system at 
some instant (by placing a charge on the capacitor), 
and also considering there is no connection to the 
outside, energy may be stored in the system in two 
forms: 
Fig. 1 A simple LC oscillating circuit. 
1. Electric energy in the capacitance 
                Uc = ½ C V2 
2. Magnetic energy in the inductance 
                  UL = ½ L I2 
Where, I is the current flowing through the 
inductance L and V is the voltage across the 
capacitor C.   
 
The presence of energy in the capacitor implies a 
voltage across the capacitor, and a consequent rate 
of change of current and stored magnetic energy in 
the inductance. Similarly, the presence of magnetic 
energy implies a current flowing in the inductance, 
and a consequent rate of change of voltage and 
stored electric energy in the capacitor. As a result 
there is an oscillation in the system, since the 
presence of energy in one form requires a rate of 
change of energy in the other. The total energy in 
this system remains constant as an ideal dissipation-
less condition is assumed [14]. Hence the electric 
field is trapped in the capacitor and forming a loop 
of variable magnetic field around the inductor as 
shown in the figure 1.  
 
In practical case, an ideal capacitor and an ideal 
inductor cannot be found. Therefore there is a loss 
of energy occurring when electric energy is 
converted to magnetic energy and vice versa. Hence 
the oscillation frequency changes and to keep the 
oscillation frequency same the total energy of the 
system needs to be kept constant. For this reason 
energy needs to be supplied from an external source 
with the same frequency as the oscillating 
frequency of the system.    
 
 Two magnetic systems consisting of such LC 
circuit with same inherent resonant frequency will 
generate strong magnetic resonance and form a 
magnetic resonance system. If there are more than 
two resonators in effective range, they can also join 
the resonance system. One resonator can be 
Page 585
  
connected with continuous power supply to serve as 
the energy source and the other consuming the 
energy acts as receiver. Hence we are transferring 
energy from one place to another by using an 
invisible magnetic field instead of using electrical 
wires.  
 
More the number of receivers, power transfer will 
be more efficient as with the increase of the 
receiving coils, the strength of the magnetic field 
will be increased. Moreover with the increase in 
resonant frequency the power transfer efficiency 
will be increased as the response of the secondary 
objects will be less. Power transfer efficiency wi
be maximum when the resonant frequency will be 
in the range 1 MHz to 50 MHz [8]. 
 
      3. ARCHITECTURE OF ENERGY 
TRANSFER SYSTEM VIA COUPLED 
MAGNETIC RESONANCE 
 
 
Fig. 2 Schematic diagram of energy transfer system 
via coupled magnetic resonance.
 
 A simple system of energy transfer via coupled 
magnetic resonance is shown in figure 2. A high 
frequency pulse generator is connected with a LC 
system where inductor Ls and capacitor Cs 
constitute a self-resonant source coil to generate an 
alternative non-radiative magnetic field. The 
resonant frequency of LC circuit (source coil) is fs. 
The high frequency pulse is generated by switching 
a high DC voltage using a metal transistor (NPN). 
A driving circuit is used to apply a voltage at the 
base of the transistor. The frequency of this driving 
circuit is assumed to be fd. Experimentally found 
that when fd is close or equal to fs, energy is 
transmitted from source to receiving coil. Inductor 
Lr and capacitor Cr constitute the receiving 
resonant coil to produce resonance with the 
magnetic field which is generated by source 
resonant coil. The parameters of the receiving coil, 
Lr and Cr do not need to be identical with that of 
the source coil but only one condition needs to be 
satisfied that is fs = fr for efficient energy transfer 
where fr is the frequency of receiving resonant coil. 
 
ll 
 
self-
self-
 
There are different equations for calculating the 
inductance for different shapes of a coil. As we are 
using circular loop coil in our resonant system 
thereby the coil inductance can be expressed as 
[15]. 
 
   	ln    1.75
 
Where, N = coil turn, µo = 4pi × 10-
permeability of vacuum, R = radius of coil (m), a = 
radius of conductor section (m). 
 
If inductor L and capacitor C in resonance circu
are determined, the circuit resonant
could be calculated by using, 
 
   √                     
 
4. EXPERIMENTAL SETUP AND 
OBSERVATIONS 
 
In the 1st setup for energy transfer experiment 
showed in the fig. 3. Here the parameters o
and receiving resonant coils are same. The diameter 
of inductance coil is 160mm, the diameter 
 
Fig.3.Initial experimental setup for lightening
bulb 
 
Fig. 4 The experimental setup for lightening a bulb 
at a distance 1.7 meter 
        (1) 
7 (H/m) is the 
it 
 frequency f 
(2) 
f source 
 
 
 a  
 
Page 586
  
Fig. 5 The experimental setup for lightening a 
number of bulbs connected to the large resonance 
coil and a single bulb connected to a 
resonance coil together.
 
of conductor section is 2.016mm and 
number is 5. The parameter of capacitor connected 
with the inductance coil is 6.6nF with withstand 
voltage up to 630V. The applied voltage 
source self-resonant coil is 20V DC and 
maximum current is 2A. The on
frequency of power transistor (NPN) is 700 kHz. 
Experimental result shows that the power tra
efficiency is more than 68%, and the maximum 
distance of energy transfer can reach up to 
 
  In the second setup of energy transfer experiment 
showed by fig. 4, larger diameter self
are used. The parameters of receiving
coil are same with the source self-resonant
diameter of inductance coil is 50cm. T
of conductor section is 1.83mm and the coil turn 
number is 7. The value of the capacitor is 
that can withstand voltage up to 630V. 
voltage in the source self-resonant coil is 20V DC 
and the applied maximum current is 3
driving frequency is 102 kHz. The experimental 
result shows that the transfer efficiency is still more 
than 62%. The transfer distance is nearly 1.2 meter 
which is longer than that by using small diameter 
self-resonant coils. Experiments of energy transfer 
show that transfer efficiency varies with the 
distance between the source and receiving self
resonant coils. With the increase of the distance 
between source and receiving self-resonant 
transfer power and efficiency are decreased.
 
In the third setup for energy transfer experiment is 
shown in figure 5. A self-resonant coil 
diameter is used as receiver which has different 
inductance and capacitance as coil diameter is 
different from the source self-resonant 
diameter of the inductance coil is 6 cm. The 
diameter of conductor section is 0.38mm and the 
 
small 
 
the coil turn 
in the 
the applied 
-off control 
nsfer 
580mm.  
-resonant coils 
 self- resonant 
 coil. The 
he diameter 
4.4nF 
The applied 
A. The 
-
coil, the 
 
having small 
coil. The 
coil turn number is 23. The total ca
25nF. The resonant frequency of this coil is same as 
the driving frequency fd. If both of the receiver and 
source self-resonant coil have the same diameter of 
the helix and the same diameter of the conductor 
section, energy will only be transferred from source 
to receiver, when the frequency of the pulse 
generator is higher than the frequency of the self
resonant coils. Experimentally we have observed 
that using small receiving self-resonant 
respect to source self-resonant coil, energy will be 
transmitted only, when the driving frequency and 
the self-resonant frequency of the small coil is 
same. To find the reason for this phenomenon 
further investigations are required. In the same 
arrangement if another receiving self
with large diameter same as source 
coil is brought, the energy transfer efficiency is 
increased significantly in the small 
coil. Moreover, small self-resonant 
constant power within 73 cm between the source 
and the large receiving self-resonant 
the feasibility of using a small coil to power up a 
portable device which we have observed 
experimentally. Up to 5 small self-
having the same parameters and resonant 
have been used at a time during the performance of 
the experiment and it has been seen that the 
efficiency of the power received remains nearly 
constant for each self-resonant coil. This small 
resonant coil can be built in the printed circuit 
board (PCB) so that it can be fitted inside the 
portable device. Keeping the resonance frequency 
same, shape and size of the self-resonant 
be changed to desired geometry.     
 
     An important feature is that energy transfer can 
go through various objects. Different kinds of 
objects were placed between the source and 
receiving self-resonant coils to verify this
Experiment result shows an uninterrupted 
of energy. Non-metallic objects and liquids 
walls, books, wooden products, organic glass 
panels, water, leather, and textiles have no impact 
on power transfer. The impact of metallic objects 
on the system depends on different characteristics 
of metal conductor. It would have slight impact if 
the object with size less than the diameter of 
resonant coil, or which cannot generate a larger 
eddy current; If the metallic objects which can 
generate larger eddy current or form a close loop
are close to this system, the impact will be greater 
even block energy transfer.  
 
 In addition, it is found that when a LC resonant
circuit with the same parameters and sizes of the 
source resonant circuit is placed between th
and receiving self-resonant coil, the e
distance and power transfer efficiency can be 
pacitance is 
-
coil with 
-resonant coil 
self-resonant 
self-resonant 
coil receive a 
coil. It proves 
resonant coils 
frequency 
self-
coil can 
 feature. 
transfer 
such as 
self-
, 
 
e source 
nergy transfer 
Page 587
  
improved. More analysis and experimental study 
still need to be done to analyse the root of this 
phenomenon. 
 
5. ANLYSIS OF EXPERIMENTAL 
RESULT 
 
 
Fig. 6 Relationship between the induced voltages in 
the receiving self-resonant coil with the distance 
from the source self-resonant coil to receiving self-
resonant coil. 
 
 
Fig. 7 Relationship between the power transfer 
efficiency with the distance from the source self-
resonant coil to receiving self-resonant coil. 
 
 
Fig. 8 Relationship between the induced EMF in 
the receiving self-resonant coil with different 
driving frequency fd. 
 
Fig. 6 demonstrates that the relationship between 
the induced voltages in the receiving self-resonant 
coil with the distance between the source self-
resonant coil and receiving self-resonant coil when 
there is no load is connected with the receiving self-
resonant coil. Fig. 6 is plotted from the data found 
in the experimental setup-2. 
 
Fig. 7 shows that the efficiency is around 62% for 
roughly 1.2 m distance after which the efficiency 
drops significantly. Fig. 7 is plotted from the data 
found in the experimental setup-2. An important 
feature is found when the receiving coil is close to 
the source self-resonant coil the energy drawn by 
the source self-resonant coil from the supply is less 
and it increases when the distance between the 
source self-resonant coil and the receiving self-
resonant coil is increased. It is one of the built-in 
advantages of this system.  
 
Fig. 8 shows the relationship between different 
driving frequencies (fd) and induced EMF in the 
receiving self-resonant coil. The experimental 
result shows that when the induced voltage reaches 
the maximum, the driving frequency fd is not 
completely consistent with the inherent resonant 
frequency of the LC resonant circuit, there existed a 
certain deviation. We found that inherent resonant 
frequency of LC resonance circuit is 79.34 kHz, 
while the induced EMF in the receiving self-
resonant coil reaches the maximum when the 
driving frequency is 102 kHz. More experimental 
study still needs to be done to find the reason of this 
phenomenon. 
 
7. CONCLUSIONS 
 
A novel wireless energy transfer system has been 
proposed in this paper. The proposed system has a 
very simple architecture compared to other existing 
system. It has been experimentally verified that by 
making the receiving self-resonant coil very small 
with respect to the source self-resonant coil power 
can be transferred efficiently. Moreover a number 
of small self-resonant coils can act as a receiver at 
the same time keeping the efficiency nearly same. 
Nevertheless, there are still a lot of research and 
experimental work to be done to make the 
technology of wireless power transfer more 
practical. 
 
REFERENCES 
 
1. Tesla N. U.S. patent 1,119,732 (1914). 
2. Tesla N., Nikola Tesla: Lectures, Patents, 
Articles (NikolaTesla Museum, Belgrade 
1956), p.A109.  
3. Tesla N., Colorado Springs Notes 1899-1900 
(Nikola Tesla Museum,Belgrade,1978) 
4. Fernandez J. M., Borras J. A., U.S. patent 
6,184,651 (2001). 
5. Esser A. and Skudelny H.C., “A New 
Approach to Power Supplies for Robots”, 
VOtage Vs Distance 
0
5
10
15
20
25
0 50 100 150 200
Distance ( cm)
Vo
lta
ge
 
(V
)
Efficiency Vs Distance
0
0.2
0.4
0.6
0.8
1
0 50 100 150 200
Distance (cm)
Ef
fic
ie
n
cy
Votage Vs Frequency
0
5
10
15
20
25
0 20 40 60 80 100 120 140
Frequency ( KHz)
Vo
lta
ge
 
(V
)
Page 588
  
IEEE Transactions on Industry Applications, 
Vol. 21, No. 5, pp. 872-875, September 1991. 
6. Hirai J., Kim T.-W., Kawamura A., “Wireless 
transmission of power and information and 
information for cable less linear motor drive”, 
IEEE Trans. Power Electron. 15, 21 (2000). 
7. André Kurs A., Aristeidis Karalis A., Moffatt 
R., Joannopoulos J. D., Fisher P., Soljacic M., 
“Wireless Energy transfer via strongly coupled 
Magnetic Resonances”. Originally published in 
Science Express on 7 June 2007:Vol. 317. no. 
5834, pp. 83 – 86, DOI: 
10.1126/science.1143254. 
8. Karalis A., Joannopoulos J. D.  & Soljacic M., 
“Efficient wireless non-radiative mid-range 
energy transfer”. Ann. Phys (2007), 
10.1016/j.aop.2007.04.017. 
9. Zhu C., Liu K., Yu C., Ma R., Cheng H. 
“Simulation and Experimental Analysis on 
Wireless Energy Transfer Based on Magnetic 
Resonances”, IEEE Vehicle Power and 
Propulsion Conference (VPPC), September 3-
5, 2008, Harbin, China.   
10. Vanderelli T. A., Shearer J. G., Shearer J. R., 
U.S. patent 7,027,311 (2006). 
11. Aoki T., Dayan B., Wilcut E., Bowen W.P., 
Parkins A.S, Kippenberg T.J. , Vahala K.J., 
and Kimble H.J. Nature 443,671 (2006) 
12. Brien K.O’, Scheible G.  and Gueldner H., The 
29th Annual Conference of  the IEEE1, 367 
(2003)  
13. Zierhofer C.M and Hochmair E.S., “Coil 
design for improved power transfer efficiency 
in inductive links”, IEEE Transactions on 
Biomedical Engineering 37, 716 (1990). 
14. Ramo S., Whinnery J. R., Theodore Van Duzer 
T. V., “Field and Waves in communication 
electronics”, 1st Edition (published by 
WIIELY) 
15. Daqian Fang. Handbook of Electrical 
Calculations. Shandong Science and 
Technology Press, 1994. 
Page 589
  Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Md. Salah Uddin Yusuf,  
E-mail: ymdsalahu2@gmail.com 
FAST INTER MODE DECISION ALGORITHM FOR H.264/AVC 
VIDEO STANDARD 
 
 
Md. Salah Uddin Yusuf * and Mohiuddin Ahmad  
Department of EEE, Khulna University of Engineering & Technology, 
Khulna-9203, Bangladesh 
 
 
In this paper, a relative sum of absolute difference (RSAD) based fast inter mode decision algorithm is 
proposed for H.264/AVC video standard. The main idea is to determine the best inter mode based on RSAD 
cost instead of the rate-distortion cost.  This approach can avoid most of the computationally intensive 
processes in the H.264/AVC mode decision, such as integer transform, quantization, variable length coding 
and pixel-reconstruction. It can solve the problem of SAD-based cost function for H.264/AVC mode 
decision in biasing to the smaller block size modes. The experimental results indicate that the proposed 
algorithm can reduce 60% to 68% of the total encoding time with negligible degradation in the rate-
distortion performance. The proposed algorithm is also combined with SKIP mode early termination 
algorithm for further time saving and computation reduction. The enhanced algorithm could save up to 10% 
more of the encoding time with only a little rate-distortion degradation.  
 
Key words: H.264/AVC, SAD Cost Function, Video Coding, Mode Decision, SKIP mode  
 
1. INTRODUCTION 
 
The newest video coding standard is known as 
H.264/AVC (Wiegand et al., 2003, and Sullivian 
and Wiegand, 1998) which greatly outperforms the 
previous standards in terms of both picture quality 
and compression efficiency. To achieve this 
superior coding performance, H.264/AVC adopts 
many advanced techniques, such as directional 
spatial prediction for intra frame coding, variable 
and hierarchical block transform, arithmetic 
entropy coding, multiple reference frame motion 
compensation, etc. It also uses seven different block 
sizes (16x16, 16x8, 8x16, 8x8, 8x4, 4x8 and 4x4) 
for motion compensation in inter mode coding, The 
purpose to employ variable block size coding is that 
large block modes (such as 16x16, 16x8 and 8x16) 
can be used for stationary image block prediction 
with high coding efficiency while small block 
modes can be used for high or complex image 
blocks with better prediction accuracy. 
In the last few years, a number of fast mode 
decision algorithms (Jing and Chau, 2004, Wu et al. 
2005, Kuo and Chan, 2006, Lin et al., 2006, Wei 
and Ngan, 2006) have been proposed to reduce the 
computational complexity. Kim et al. proposes an 
adaptive mode decision algorithm (Kim et al., 
2004). Some of the aforementioned algorithms try 
to classify the MB into large partition or small 
partition and skip checking some unnecessary 
modes. However, they still need to compute the 
rate-distortion costs of possible modes for the 
ultimate mode decision, which involve 
computationally intensive processes of image 
transformation. In H.264/AVC SAD and SATD-
based cost functions are developed 
(http://bs.hhi.de/~suehring/tml/download/Unofficial/) 
as fast mode decision techniques. However, the 
major drawback is that the rate-distortion 
performance of the encoded video is quite 
degraded, which affects their practical 
implementation. In this paper, a relative sum of 
absolute value (RSAD) based fast mode decision 
algorithm is proposed, which can avoid rate-
distortion cost computation while maintaining high 
rate-distortion performance of the H.264/AVC 
codec. 
The rest of the paper is organized with section 2 
introducing the rate-distortion cost functions for 
H.264/AVC standard. The proposed algorithm is 
described in section 3. The SKIP mode early 
termination algorithm is reviewed in section 4. The 
parameters selection technique is described in 
section 5. Simulation results are presented in 
section 6 and the conclusion is given in section 7. 
 
2. RATE–DISTORTION COST FUNC-
TIONS FOR H.264/AVC 
 
Page 590ISBN: 978-984-33-2140-4
  
In H.264 encoding process, the best MB coding 
mode is selected by computing the minimum RD 
cost of all possible modes and this cost is defined as 
 
RJ RD ⋅+= λ),,(SSD),( CSCS       (1) 
 
where λ is the Lagrangian multiplier.  The R is the 
number of bits for encoding the header information, 
motion vectors and quantized residual block, 
respectively. In equation (1), SSD(S, C) is the sum 
of the squared difference (SSD) between the 
original blocks S and the reconstructed block C, 
and it can be expressed as: 
 
22
1
0
1
0
)(),(SSD
Fijij
N
i
N
j
cs CSCS −=−= ∑ ∑
−
=
−
=
 (2) 
where sij and cij are the (i, j)th elements of the 
current original block S and the reconstructed block 
C, respectively. Moreover, N is the image block 
size (N = 4 in H.264 standard) and 
F
 is 
Frobenius norm. As the computation of spatial-
domain SSD is very time-consuming so to 
accelerate the coding process, the JVT reference 
software provides a fast SAD-based cost function: 
 
 
1
SAD
SAD( , ) 4        if intra 4 4 mode
SAD( , )                       otherwise
K
J
λ+ ⋅ ×⎧
= ⎨
⎩
S P
S P
  (3) 
 
where SAD (S,P) is sum of absolute difference 
between the original block S and the predicted 
block P. The λ1 is also approximate exponential 
function of the QP, which is almost the square of λ, 
and the K equal to 0 for the probable mode and 1 
for the other modes. This SAD-based cost function 
could save a lot of computations with quite 
significant degradation of coding efficiency. Thus, 
SAD is not an appropriate criterion to determine the 
best mode. Actually, the SAD values of different 
inter modes usually have the following relation: 
SAD16x16≥  SAD16x8 (SAD8x16)≥  SAD8x8. The 
reason behind is that the small partition motion 
estimation can always provide better prediction 
accuracy than the large mode motion estimation. 
According to this relationship, the JSAD cost 
function is inclined to choose smaller block mode 
as the best mode since their SAD values are 
smaller. That’s why JSAD cost function is not 
appropriate for the best mode selection.  
 
3. RSAD BASED MODE SELECTION 
ALGORITHM 
 
3.1 Definition of RSAD Based Cost Function 
The reason why H.264/AVC employs variable 
block-size modes is that sometimes the current MB 
cannot be well predicted by large partitions, which 
means the difference between the current MB and 
predicted MB is quite large. Thus, the MB should 
be divided into smaller partitions for better motion 
compensation. On the other hand, if the current 
block can be well predicted by the large block 
mode, it is unnecessary to encode the block with 
smaller partitions which require more encoding 
complexity and more bits to represent the motion 
vectors and side information. Thus, we need to use 
an appropriate criterion to tell whether the current 
MB achieves adequate prediction accuracy or not. 
SAD value presents the difference between the 
current MB and predicted MB, so it can reflect the 
prediction accuracy of different modes. As 
mentioned earlier, JSAD cost function is not 
appropriate for mode decision since smaller modes 
usually lead to smaller SAD values so that smaller 
block mode is inclined to be considered as the best 
mode. Therefore, we should admit the intrinsic 
SAD differences between small partitions and large 
partitions. Besides, we should realize that the SAD 
values are also significant in mode decision. A 
small SAD difference among different modes 
indicates that large partition may well predict the 
current MB without splitting into small partitions; 
while a large SAD difference means the prediction 
accuracy of small modes outperforms that of the 
large mode, so that the small mode is likely to be 
the best mode. Since the SAD difference covers a 
wide range and fluctuates greatly, it is difficult to 
claim whether the SAD difference is small or large. 
So, we can define a new parameter, relative SAD 
(RSAD) cost, to measure the SAD difference 
between two modes. 
The RSAD cost between two modes, mode 1 
(representing large partition) and mode 2 
(representing small partition), is defined as below: 
1
21
21 SAD
SADSADRSAD −=>−                    (4) 
where 21 >−RSAD  represents the relative prediction 
accuracy between mode 1 and mode 2. According 
to the definition of RSAD, a small RSAD cost 
indicates a small SAD difference between two 
modes, which means that their prediction accuracy 
is similar. In this case, mode 1 is likely to be a 
better choice since it needs fewer bits to encode its 
motion vectors. On the other hand, a large RSAD 
cost implies that mode 2 is more likely to be the 
better mode since its prediction accuracy obviously 
outperforms the large partition mode 1. Therefore 
RSAD is a new measure to select the better mode 
instead of the conventional costs such as SAD, 
SATD and RD cost. 
 
3.2 RSAD Cost Function for Mode Decision 
Based on the above idea, a threshold TR can be 
predefined to tell whether the RSAD is small or 
large.  If RSAD1->2 <TR, select the large partition 
mode 1 as the better mode; Otherwise select the 
small partition mode 2 as the better mode.  It is 
Page 591
  
obvious that TR affects the probability of mode 1 or 
mode 2 to be the selected. When TR increases, mode 
1 is more likely to be the better mode while a low 
TR making mode 2 more likely to be the better 
mode. 
How to select the threshold TR is vital to this 
RSAD-based mode decision algorithm and which 
have to be robust for different types of block 
contents.  In addition, TR should also be adaptive to 
SAD of the mode 1 ( 1SAD ) as it indicates whether 
the large partition block is well predicted or not. If 
1SAD  is small due to mode 1 is already well 
predicted then it is more likely to be the better 
mode, as a result we can use a larger TR.  In 
contrast, if 1SAD  is large, the mode 2 with small 
partition should have higher chance to be the better 
mode and TR should be smaller.  To implement this 
idea, we use another adaptive threshold TS to 
distinguish whether 1SAD  is small or large.  As a 
higher QP leads to rougher quantization, the error 
between the original block and reconstructed block 
will increase, then the overall SAD values will be 
higher, so the threshold TR should be also increased.   
 
Let us first introduce a RSAD-based mode selection 
algorithm for two modes only as follows: 
Step I:    Initialize QP value, TS, TRS , TRL as QP. 
Step II: Calculate the SADs of mode 1 and 2. 
Step III: If SAD1<TS, TR = TRS, else TR = TRL 
StepIV: Calculate 12121 )/SADSADSAD(RSAD −=>−  
Step V: If RSAD1->2<TR,choose mode 1as the better 
mode; Else, choose mode 2 as the better mode.  
In this algorithm, the TRS and TRL represent the 
RSAD thresholds for small and large SAD blocks, 
respectively. Here, the above algorithm is very easy 
to demonstrate the concept of the RASD for mode 
decision, but it is not very suitable for practical 
implementation with more than two modes. In this 
algorithm, we need to compare 21 >−RSAD  with the 
threshold RT . If   1 2RSAD RT−> ≤ , 
1 2 1 2 1RSAD (SAD SAD )/SAD RT−> = − ≤ , then 
1 2 1SAD SAD SADRT≤ + ⋅ .  
Thus, the comparison between 21RSAD >−  and RT  
is equal to the comparison between 1SAD  and the 
compensated 2SAD  ( 2 1SAD  plus SADRT ⋅ ).  
 
3.3 RSAD-Based Cost Implemented for 
H.264/AVC Inter Mode Decision 
H.264/AVC video standard supports seven inter 
modes of different block size and shapes, including 
mode 16x16, 16x8, 8x16, P8x8 (8x8, 8x4, 4x8, and 
4x4). In this papers, 8161616 xxRSAD >− ,  1681616 xxRSAD >−  
and 
881616 xPxRSAD >− are employed for mode decision 
and we need to find the best mode among these 
four inter modes. In order to present the algorithm 
clearly, compensated SAD values of mode 16x8, 
8x16 and P8x8 are employed in the following 
algorithms. Then, the RSAD-based mode decision 
algorithm for H.264/AVC can be implemented as 
following algorithm for Inter modes 16x16, 16x8, 
8x16, P8x8 selection: 
Step I:  Initialize QP value, TS1, TRS1 , TRL1, TS2,  
TRS2 , TRL2 based on the QP. 
 Step II: Calculate the SAD cost of these four inter   
modes: SAD16x16, SAD16x8, SAD8x16 and SADP8x8. 
 Step III: If SAD16x16<TS1, then TR1 = TRS1 and TR2 = 
TRS2; else TR1 = TRL1 and TR2 = TRL2 
 Step IV: Calculate compensated SAD16x8, SAD8x16 
and SADP8x8 with 
              SAD16x8 = SAD16x8+TR1•SAD16x16 
              SAD8x16 = SAD8x16+TR1•SAD16x16 
              SADP8x8 = SADP8x8+TR2•SAD16x16 
StepV: 
16x16 16x8 8x16 P8x8Best mode argmin(SAD ,SAD ,SAD ,SAD )=  
where TS1, TRS1, and TRL1 are SAD threshold and 
RSAD thresholds for selecting Inter modes of 16x8 
and 8x16 partitions and TS2, TRS2, and TRL2 are SAD  
and RSAD thresholds for selecting Inter mode of 
P8x8. Based on this algorithm, we can determine 
the best inter mode by comparing the SAD of 
largest partition mode (Inter 16x16) and  
compensated SADs of the smaller partition modes. 
In this simplified algorithm, the RSAD has been 
implemented to only select the best mode from four 
Inter modes. Actually, Inter P8x8 contains four sub-
modes: Inter S8x8, Inter S8x4, Inter S4x8 and Inter 
S4x4 modes. Similarly, we can implement the 
proposed RSAD-based mode decision algorithm to 
choose the best sub-mode among all possible sub-
modes with another set of thresholds. The RSAD-
based sub mode decision process can be 
summarized as: 
Step I: Initialize QP value, TS3, TRS3 , TRL3, TS4, 
TRS4 , TRL4 based on the QP. 
Step II: Calculate the SAD cost of four  sub inter 
modes: SADs8x8, SADs8x4, SADs4x8 and SADs4x4. 
Step III: If SADs8x8<TS3, then TR3 = TRS3 and TR4 = 
TRS4; else TR3 = TRL3 and TR4 = TRL4 
Step IV: Calculate compensated CSADs8x4, 
CSADs4x8 and CSADs4x4 with 
              SADs8x4 = SADs8x4+TR3•SADs8x8 
              SADs4x8 = SADs4x8+TR3•SADs8x8 
              SADs4x4 = SADs4x4+TR4•SADs8x8 
Step V: 
8 8 8 4 4 8 4 4Best submode argmin(SAD ,SAD ,SAD ,SAD )s x s x s x s x=  
where TS3, TRS3, and TRL3 are SAD and RSAD 
thresholds for selecting Inter sum modes of s8x4 
and s4x8 partitions and TS4, TRS4, and TRL4 are SAD 
threshold and RSAD thresholds for selecting Inter 
sub mode of s4x4.  
Page 592
  
 
4. REVIEW OF SKIP MODE EARLY 
TERMINATION ALGORITHM 
 
In H.264/AVC, SKIP mode is employed to encode 
some static objects and background that almost 
remain the same in the adjacent frames (Choi et al., 
2006). It usually, dominates among other modes 
and the motion vector is predicted by using the 
motion vectors of the neighboring MBs. As no 
residual block is encoded, the transform, 
quantization and entropy coding can be avoided. 
When the SKIP mode is selected, only a skip 
indicator is transmitted. Thus, if we can decide in 
advance whether the best mode is SKIP mode or 
not, the computationally intensive mode decision 
process can be omitted. SKIP mode is the best as 
long as the following conditions are satisfied (Choi 
et al., 2006): 
1) The best motion compensation block size for this 
MB is 16x16. 
2)  The best reference frame is the previous frame. 
3)  The best motion vector is the predicted MV. 
4) The transform coefficients of the 16x16 block 
size are all quantized to zero. 
 
5. PARAMETERS SELECTION 
 
As mentioned in section 3, the selection of the 
RSAD thresholds TR and thresholds for classifying 
small and large SAD of the large partition is vital 
for the proposed. So, how to select those thresholds 
such that they are not sensitive to different video 
content is a vital task. In order to evaluates the best 
thresholds, at first we do not consider the sub-mode 
related parameters and only consider TRS1, TRS2, 
TRL1, TRL2 and TS. Here, we use the iterative 
searching method to obtain the optimal thresholds 
by the following algorithm: 
Step 1:  Initialize the threshold TRS1(0), TRS2(0), 
TRL1(0), TRL2(0) and TS1(0)  for a specific QP value; 
Step 2:   Adjust the thresholds TRS1, TRS2, TRL1, and 
TRL2 in order to achieve local minimum RD cost. 
Denote the updated threshold as TRS1(i), TRS2(i), 
TRL1(i), TRL2(i); 
Step 3: Adjust the threshold TS1 in order to achieve 
smaller RD cost. Denote the updated threshold as 
TS1(i); 
Step 4:  Repeat Step 2 and Step 3 until the RD cost 
cannot be further reduced. Record the optimal 
values. 
Based on the extensive simulation upon various 
types of video contents (low motion, medium 
motion and high motion), we find that the selection 
of the thresholds TRS1, TRS2, TRL1, and TRL2 is nearly 
not varied with the video contents as shown in 
Table 1 and the relationship between TS1 and QP is 
also very robust, which is shown in Table 2. In 
addition, the optimal thresholds TRS3, TRS4, TRL3, 
TRL4 and TS2 for sub-mode selection can also be 
obtained via the iterative searching method. These 
results are shown in Tables 3 and 4. 
These optimal thresholds based on experimental 
results are also nearly not varied with the video 
contents. Such phenomenon is also found in other 
video sequences and QP factors but due to the 
limited length of the paper, we cannot list all of 
them here. Fortunately, we can select a group of 
optimal thresholds for (TRS1, TRS2, TRL1, TRL2) and 
(TRS3, TRS4, TRL3, TRL4) for practical implementation 
of the proposed RSAD-based mode decision 
algorithm, which are shown in Table 5. Moreover, a 
set of TS1 and TS2 thresholds are also selected based 
on the results of Tables 2 and 4 for difference QPs, 
which are shown in Table 6. In practical 
implementation, we can use a table to store all the 
optimal TS1 and QP and use table- lookup method 
to decide those thresholds for a specified QP value. 
  
Table 1:  The optimal thresholds TRS1, TRS2, TRL1, and TRL2 found based on simulation. 
20 24 
QP 
TRS1 TRS2 TRL1 TRL2 TRS1 TRS2 TRL1 TRL2 
Akiyo 0.15 0.30 0.03 0.07 0.15 0.30 0.03 0.07 
Foreman 0.15 0.30 0.03 0.06 0.15 0.30 0.03 0.07 
Stefan 0.15 0.30 0.03 0.07 0.15 0.30 0.03 0.07 
32 40 
QP TRS1 TRS2 TRL1 TRL2 TRS1 TRS2 TRL1 TRL2 
Akiyo 0.15 0.30 0.03 0.07 0.15 0.30 0.03 0.07 
Foreman 0.15 0.31 0.03 0.07 0.15 0.30 0.03 0.07 
Stefan 0.16 0.31 0.03 0.06 0.15 0.30 0.03 0.08 
 
Table2: The optimal threshold TS1 found based on simulation. 
 QP=20 QP=24 QP=32 QP=40 
Page 593
  
Akiyo 200 400 900 1550 
Foreman 200 400 850 1500 
Stefan 200 400 900 1500 
 
Table 3: The optimal thresholds TRS3, TRS4, TRL3, and TRL4 found based on simulation. 
20 24 
QP TRS3 TRS4 TRL3 TRL4 TRS3 TRS4 TRL3 TRL4 
Akiyo 0.20 0.40 0.10 0.20 0.20 0.40 0.10 0.20 
Foreman 0.20 0.40 0.10 0.20 0.20 0.40 0.10 0.20 
Stefan 0.20 0.40 0.10 0.20 0.20 0.40 0.10 0.20 
32 40 QP 
TRS3 TRS4 TRL3 TRL4 TRS3 TRS4 TRL3 TRL4 
Akiyo 0.20 0.40 0.10 0.20 0.20 0.40 0.10 0.20 
Foreman 0.21 0.40 0.10 0.20 0.20 0.40 0.10 0.20 
Stefan 0.19 0.40 0.10 0.20 0.20 0.40 0.10 0.20 
 
Table 4:  The optimal threshold TS2 for P8x8 sub-modes       Table 5:  The selected thresholds for    RSAD      
found based on simulation                                                                based  mode decision algorithm. 
 QP=20 QP=24 QP=32 QP=40 
Akiyo 150 200 450 800 
Foreman 150 250 450 800 
Stefan 150 200 450 800 
 
6. EXPERIMENTAL RESULTS 
 
The proposed algorithm was tested using the first 
50 frames from many video sequences all in QCIF 
format. Here due to page limitation, the results of 
“Akiyo” sequences of low spatial detail and 
changes in motion, “Foreman” of medium motion 
changes with dominant luminance changes and. 
“Stefan” of panning motion and has distinct fast 
motion changes are listed. The experiment was 
carried out in the JVT JM9.6 encoder with the test 
parameters are listed as below: 
- CABAC is enabled; 
- GOP structure is IPPP; 
- Max search range for motion 
estimation is 32; 
- QP values are 20, 24, 32, and 40; 
Compared with the original H.264/AVC encoder in 
terms of the rate-distortion optimization and 
computation time, the proposed algorithm achieves 
a little R-D performance degradation, as listed in 
Table 7, as well as considerable computation time 
reduction shown in Table 8.  
Table 6:  The relationship between TS and QP 
QP 20 24 32 40 
TS1 200 400 900 1500 
TS2 150 200 450 800 
 
From the simulation results, we can conclude that 
the proposed RSAD algorithm can reduce the 
encode time by around 60% to 68% in different QP 
values. When we combine this with SKIP mode 
Table 7:  R-D performance of RSAD-based mode 
decision algorithm 
Sequence QP ∆Bit Rate % 
∆ PSNR 
– dB 
20 -0.05 -0.05 
24 -0.31 -0.05 
32 -0.22 -0.03 
Akiyo 
 
40 -0.08 0 
20 +0.17 -0.09 
24 -0.07 -0.08 
32 -0.04 -0.06 
Foreman 
40 +0.72 -0.02 
20 +0.82 -0.09 
24 +0.50 -0.11 
32 -0.02 -0.10 
Stefan 
40 +0.65 -0.03 
 
Table 8:  Encoding time reduction of the proposed 
RSAD algorithm 
QP 20 24 32 40 
Akiyo -67.8% -67.2% -64.3% -62.3% 
Foreman -64.7% -64.4% -61.6% -60.5% 
Stefan -65.7% -64.2% -62.7% -59.8% 
 
early termination scheme, it accompanied with a 
little higher rate-distortion degradation as shown in 
Table 9 but the computation time can be further 
TRS1 TRS2 TRL1 TRL2 TRS3 TRS4 TRL3 TRL4 
0.15 0.30 0.03 0.07 0.20 0.40 0.10 0.20 
Page 594
  
reduced up to 10%, as shown in Table X. The 
results imply that the combination of SKIP mode 
early termination algorithm leads to higher 
computational reduction in slow motion sequences 
than in high motion sequences. The result indicates  
 
Table 9: R-D performance of RSAD-based mode 
decision algorithm combined with SKIP mode early 
termination algorithm 
Sequence QP ∆Bit 
Rate % 
∆ PSNR -
dB 
20 -0.08 -0.06 
24 -0.41 -0.06 
32 +0.32 -0.03 
Akiyo 
 
40 +0.22 -0.02 
20 +0.20 -0.11 
24 -0.14 -0.09 
32 -0.06 -0.06 
Foreman 
40 +0.93 -0.01 
20 +0.78 -0.10 
24 +0.66 -0.11 
32 +0.09 -0.11 
Stefan 
40 +0.80 -0.04 
 
Table 10: Encoding time reduction of the proposed 
RSAD algorithm combined with SKIP mode early 
termination algorithm 
QP 20 24 32 40 
Akiyo -72.43% -72.01% -71.57% -69.93% 
Foreman -66.48% -65.46% -65.49% -64.96% 
Stefan -66.11% -65.26% -64.92% -63.80% 
 
that our proposed algorithm indeed outperforms 
some other fast algorithm in terms of video quality 
and compression ratio. Similarly, higher coding 
efficiency can be achieved in the large QP.  
The encoding time is not the only criterion to 
evaluate an algorithm’s efficiency. In the hardware 
implementation we mainly focus on the number of 
rate-distortion operations on different modes 
because the computation of rate-distortion cost is 
quite heavy in the coding process. From this aspect, 
our proposed algorithm is quite efficient since it 
determines the best mode only based on the RSAD 
cost function.  
 
7. CONCLUSION 
 
In this paper, a fast Relative SAD based inter mode 
decision algorithm is proposed for H.264 coding 
standard. This algorithm is motivated by the fact 
that SAD values can reflect the prediction accuracy 
among different inter modes. However, directly 
using SAD to determine the best mode has been 
proved to be not a satisfied choice. Thus, we 
proposed a new RSAD cost function as the measure 
to decide the best inter modes among 16x16, 16x8, 
8x16 and P8x8. and also best sub-mode of 8x8 
blocks. Therefore, the tremendous computation of 
the rate-distortion cost can be skipped. Finally, we 
combine the proposed algorithm with SKIP mode 
technique and achieve further time saving and 
computation reduction. Experimental results 
indicate that the proposed algorithm reduced 
considerable encoding time as well as maintaining 
the quite similar rate-distortion performance. 
 
ACKNOWLEDGEMENT  
 
This research was partially supported by CASR 
grants memo: KUET/CASR10/26(30) of KUET, 
Khulna, Bangladesh. 
 
REFERENCES 
 
[1] Choi, I., Lee, J., Jeon, B., (2006), Fast coding 
modes election with rate-distortion optimization 
for MPEG-4 Part-10 AVC/H.264, IEEE Trans. 
Circuits Syst. Video Techno., vol. 16, pp. 1557-
1561. 
[2] G. J. Sullivian and T. Wiegand, (1998), “Rate-
distortion optimization for video compression”, 
IEEE Signal Process. Mag., vol. 15, pp.74-90. 
[3]   Jing, X. and Chau, L. P. (2004), Fast approach 
for H.264 inter mode decision, Electron. Lett., 
40(17),   pp. 1051-1052. 
[4] Joint Video Team (JVT) Reference Software 
version 6.1d and JM 9.6. Available: 
http://bs.hhi.de/~suehring/tml/download/Unoff
icial/.  
[5]  Kim, Y. H., Yoo, J. W., Lee, S. W., (2004), 
“Adaptive mode decision for H.264 encoder”, 
Electron. Lett., 40(19), pp. 1172 – 1173. 
[6] Kuo, T. Y. and Chan, C. H., (2006), Fast 
variable block size motion estimation for 
H.264 using likelihood and  correlation of 
motion field, IEEE Trans. Circuits Syst. Video 
Technol., 16(10), pp.1185-1195. 
[7] Lin, Z. P., Yu, H. T., and Pan, F., (2006), A 
scalable fast mode decision algorithm for 
H.264, Proc. IEEE ISCAS 2006. 
[8] Wei, Z. Y., and Ngan, K. N., (2006), A fast 
macroblock mode decision algorithm for 
H.264, Proc. IEEE APCCAS, pp. 772-775. 
[9] Wu, D., F. Pan, K. P. Lim and S. Wu., (2005), 
Fast intermode decision in H.264/AVC video 
coding,  IEEE Trans. Circuits Syst. Video 
Technol., 15(7),  pp.953-958. 
[10] Wiegand, T., Sullivan, G. J.,  Bjontegaard, G, 
and Luthra, A., (2003), Overview of the 
H.264/AVC video coding standard, IEEE 
Trans. Circuits Syst. Video Technol., vol. 13, 
pp. 560-576. 
Page 595
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
*
 Corresponding Author: Dr. Md. Rafiqul Islam  
E-mail: rafiq043@yahoo.com 
GROWTH AND CHARACTERIZATION OF MOVPE InxGa1-xN  
(x ~ 0.4) 
 
 
Md Rafiqul Islam*, Md. Rejvi Kaysir, Md. Jahirul Islam and Ashraful G. Bhuiyan  
Determent of Electrical and Electronic Engineering, KUET, Khulna-9203, Bangladesh 
 
A. Hashimoto and A. Yamamoto 
Graduate School of Engineering, University of Fukui, 3-9-1 Bunkyo, Fukui 910-8507, Japan 
 
 
InxGa1-xN alloys are excellent candidate for future MJ solar cells. The InGaN material system poses many 
challenges which are extended into the performance of the devices. In this paper, the challenges related to 
the film growth are overcome individually for MOVPE growth. The InGaN film with indium contents 0 to 
0.4 are successfully grown by controlling the fundamental growth parameters such as the precursor gas flow 
rates and temperature. The variation of TMI/(TMI+TEG) molar ratio shows a significant effect on the 
growing films. The formation of metallic In originates from the higher value of TMI/(TMI+TEG) molar 
ratio with low V/III ratio while the lower value of TMI/(TMI+TEG) causes the phase separation. It is also 
necessary to control the growth rate and epitaxial film thickness to suppress the phase separation in the 
material. The film quality of grown films is studied with increasing the In composition . 
 
Key words: InGaN, MOVPE, Growth, Film quality, Electrical properties. 
 
1. INTRODUCTION 
 
Indium gallium nitride (InGaN) is an attractive 
semiconductor material for optoelectronics and 
high-temperature and high-power electronics. 
Especially, this material is a promising candidate 
for future multi-junction tandem solar cells with 
high conversion efficiency (Islam et al., 2008). 
InGaN alloys also have shown a higher degree of 
resistance to radiation damage than other 
photovoltaic materials in common use today 
(Walukiewicz et al., 2003). To realize a tandem 
solar cell based on InGaN, it is needed to grow 
InGaN alloys with In content from about 0.23 to 1 
(Islam et al., 2008). GaN is the most extensively 
studied material and comparatively has matured 
among the III-nitrides, while the lower band gap 
InGaN, which is more useful for photovoltaic 
application, is still a topic of fundamental research. 
Although Ga-rich InGaN devices have been 
commercially realized, the growth and properties of 
this material still have not been well understood. 
Increasing the indium composition in InGaN during 
growth, poses many challenges in controlling phase 
separation and defect density due to the large 
difference in lattice as well as thermal expansion 
coefficient mismatch between InN and GaN and 
high volatility of In atoms. Therefore, a 
fundamental study of the growth of InGaN is an 
important issue for fabricating high performance 
device. 
In this paper the growth of InGaN has been 
discussed in details. The suppression of phase 
separation and metallic In incorporation has been 
investigated. To construct novel devices, it is of 
crucial importance to investigate the crystalline 
quality and electrical properties. In this paper, these 
properties are also studied. 
 
2. EXPERIMENTAL PROCEDURE 
 
The films are grown on (0001) sapphire substrates 
by using the metalorganic vapor phase epitaxy 
(MOVPE) with a horizontal reactor. A thin GaN 
buffer layer grown at low temperature (550°C) or a 
GaN template of about 1.4 µm thick grown at 
1000°C is used as an interlayer. The InGaN films 
with thickness about 1.5 µm are grown at 750-
900°C in the pressure of 150 Torr. Triethylgallium 
(TEG), trimethylindium (TMI), and ammonia 
(NH3) are used as Ga, In, and N sources, 
respectively. Full width at half maximum (FWHM) 
of X-ray rocking carve (XRC) of different planes 
are also measured to evaluate crystalline quality. 
The mean tilt angle depends on (0002) FWHM and 
can be measured directly by ω-scan using X-ray 
diffraction (XRD). However, the twist angle can 
hardly be measured directly. Here, the method 
Page 596
ISBN: 978-984-33-2140-4
  
developed by Srikant et al. (Srikant et al.  1997) has 
been used to analyze the experimental data. In this 
method, every rocking-curve (0002, 10-13, 10-12, 
10-11 and 30-32) was fitted into a pseudo-Voigt 
function. Finally, the twist has been obtained from 
the theoretical estimation. Electron concentration 
was measured with four-probe van der Pauw 
technique. 
 
3. RESULT AND DISCUSSION 
 
3.1 Effect of precursor gas flow 
A systematic study of InxGa1-xN epitaxy is 
performed to get indium compositions in the range 
from 0 to 0.4 by MOVPE. The primary variables 
used to control the In composition is the precursor 
gas flow rates that is the TMI / (TMI + TEG) molar 
ratio. XRD data of the InGaN epi-layers are 
represented on the same scale in Figure 1 for 
comparison. The XRD data indicates the 
composition and quality of constituent materials in 
the epitaxy. The InGaN (0002) peaks which is 
clearly visible, indicate the respective indium 
compositions and another secondary InGaN peaks 
are also observed, which indicate the presence of 
phase separation in the material. The corresponding 
(0002) peak of GaN template is observed at around 
2θ = 34.6°. The peak observed at around 32.9°, 
(101) metallic indium indicates the amount of 
segregated indium droplets (Lu et al., 1997).  
 
The InGaN films are grown at 800 °C with a TMI / 
(TMI+TEG) molar ratio 0.2 to 0.74. Initially, the 
growth is conducted with TMI / (TMI+TEG) molar 
ratio of 0.2 where a secondary peak of InGaN is 
clearly observed. This may be due to the strain state 
in the material varies to a much greater extent due 
to the additional gallium species. It has also been 
reported that InGaN alloys are unstable over most 
of the composition range at normal growth 
temperature (Ho and Stringfellow,  1997) especially 
in the range of 0.2 (Koukitu and Seki, 1998). The 
reason is that at high temperatures, most of the 
input Ga deposits into the solid phase, whereas In 
remains in the vapor phase without deposition. 
Thus, inhomogeneity occurs and the 
inhomogeneous compositions in the unstable 
regions may be the reason of phase separation. To 
suppress the phase separation the TMI flow rate has 
been changed that means the TMI / (TMI+TEG) 
molar ratio has been increased to 0.38 which 
increases the InN incorporation in the InGaN films 
as well as suppresses the phase separation (Jani et 
al., 2007). Further increase of the TMI / (TMI + 
TEG) molar to 0.74, increases the In composition 
along with the formation of metallic indium in the 
film. Furthermore, the V/III ratio at TMI / 
(TMI+TEG) ratio 0.2 to 0.74 is 8600, 6600 and  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
4100 respectively. In case of higher TMI / 
(TMI+TEG) molar ratio, the formation of In peak is 
due to the dissociation of InN and condensation of  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
32 33 34 35 36 
2θ (degree) 
InxGa1-xN 
x=0.11, 0.2 
x= 0.2 
x= 0.24 
In
te
n
si
ty
 (
a.
u
.)
 
In
G
aN
 (
0
0
0
2
) 
G
aN
 (
0
0
0
2
) 
S
ec
o
n
d
ar
y
 
p
h
as
e 
In
 (
1
0
1
) 
 
(a) TMI/(TMI+TEG) 
      = 0.2 
(b) = 0.38 
(c) = 0.74 
Fig. 1: XRD ω-2θ profiles of InGaN films grown at 
800 °C with different TMI/(TMI+TEG) molar ratio. 
32 33 34 35 36 
In
G
aN
  
(0
0
0
2
) 
2 θ (degree) 
Growth temperature  
=850 
o
C 
 =820 
o
C 
 =800 
o
C 
 =780 
o
C 
 =750 
o
C 
InxGa1-xN 
x = 0.05 
x = 0.15 
x = 0.20 
x = 0.39 
x = 0.28 
G
aN
  
(0
0
0
2
) 
In
te
n
si
ty
 (
a.
u
.)
 
Fig. 2: XRD ω-2θ profiles of InGaN films grown at 0.38 
TMI / (TMI+TEG) molar ratio with different temperature. 
Page 597
ISBN: 978-984-33-2140-4
  
indium on the growing surface at the low V/III ratio 
(Komaki et al., 2007). On the other hand, for higher 
V/III ratio (comparatively under N-rich condition), 
the In peak has been eliminated due to excess 
activated nitrogen on the growing surface. 
 
3.2 Effect of growth temperature 
From the results of the earlier paragraph, it is clear 
that the InGaN film grown at 800 °C with TMI / 
(TMI + TEG) molar ratio 0.38 is without phase 
separation and metallic In incorporation. In order to 
control the In composition in the range of 0 to 0.4 
the InGaN film has been grown with the same 
(0.38) TMI / (TMI+TEG) molar ratio at a different 
temperature. Figure 2 shows the XRD ω-2θ profiles 
of InGaN films grown in the temperature of 750 °C 
~ 850 °C. Finally, InGaN films with an In content 
up to 0.4 has been successfully grown without 
phase separation as well as metallic In 
incorporation. 
 
3.3 Controlling the In composition 
Figure 3 (a) shows the variation of In composition 
as a function of TMI folw rate with a different 
temperature. Here the TMI / (TMI+TEG) molar 
ratio is 0.11 to 0.38 with a TEG flow rate of 100 
sccm. The In composition increases with the 
increase of TMI flow rate although at lower TMI 
flow rate the films show phase separation. The 
variation of In composition as a function of growth 
temperature with different TMI / (TMI+TEG) 
molar ratio is shown in Fig. 3 (b). The result shows 
that In content in the InGaN epi-layer is markedly 
decreased with increasing growth temperature 
indicating the evaporation of InN at high 
temperature because of high volatility of nitrogen 
over InN. In addition, it has been reported that the 
decomposition of InN starts from about 600 
o
C 
(Togashi et al., 2008). From the above figure it is 
clear that the In composition almost linearly varies 
with TMI flow rate as well as temperature up to  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
0.38 TMI / (TMI+TEG) molar ratio. When the TMI 
/ (TMI+TEG) molar ratio is above 0.38, the In 
composition is changed by TMI / (TMI+TEG) ratio 
at higher temperature (>800
 o
C) while anomalous 
behaviour is observed at low temperature (≤800 
o
C). 
 
3.4 Crystalline quality 
The crystalline quality of the grown films is studied 
by XRD analysis. InGaN has also been grown on 
GaN buffer in order to understand the film quality 
on buffer layer. The variation of tilt and twist of 
InGaN epi-layers as a function of In composition 
grown on LT-GaN buffer or HT-GaN template is 
shown in Fig. 4. The tilt and twist of InGaN epi-
layer is higher throughout the whole composition 
grown on GaN buffer than that of template. This 
indicates using GaN template is effective for the 
growth of InGaN. The tilt as well as twist of InGaN 
grown on GaN template increases remarkably with 
the increase of In composition as can be seen from 
fig. 4 (a) and (b). It is also clear that up to around 
0.08 In composition the tilt and twist increases 
linearly and the increasing tendency is not so high, 
while around 0.3 to 0.4 In composition, the 
increasing trend of tilt and twist is very high. More 
clearly we can explain these differences in this way. 
Since the InGaN films are grown directly on the 
GaN template without any compositional graded 
buffer layer. The lattice mismatch and thermal 
expansion coefficient between InGaN epi-layer and 
GaN template is responsible for the increase in tilt 
and twist with the raise of In composition. It is 
well-known that in lattice-mismatched hetero-  
(a)  
100 200 300 400 500 
0 
0.1 
0.2 
0.3 
0.4 
TMI flow (sccm) 
In
 C
o
m
p
o
si
ti
o
n
 
Tg    With phase 
       separation  
750 
o
C 
800 
o
C 
850 
o
C 
900 
o
C 
Without phase 
separation  
(b)  
In
 C
o
m
p
o
si
ti
o
n
 
Growth temperature (
o
C) 
750 800 850 900 
0 
0.1 
0.2 
0.3 
0.4 
TMI/ 
(TMI+TEG) 
 
0.38 
0.74 
0.89     
Without 
metallic In 
With 
metallic In 
Fig. 3: Variation of In composition in grown InGaN 
films, (a) as a function of TMI flow rate with 
different growth temperature, (b) as a function of 
growth temperature with different TMI/(TMI+TEG) 
molar ratio. 
Page 598
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 4: Variation of (a) tilt, (b) twist as a function of 
In composition grown on GaN buffer or GaN 
template 
 
epitaxial systems, pseudomorphic growth occurs 
for epilayer thicknesses less than the critical 
thickness; however, beyond the critical thickness, 
elastic strain energy is relieved with the formation 
of dislocation densities depending upon the lattice 
mismatch. In case of large lattice mismatch 
stepwise growth, when the film thickness exceeds 
the critical thickness, a high density of dislocations 
is introduced into the layers to relieve the strain at 
once. This builds up strong dislocation-dislocation 
interaction forces which prevent easy dislocation 
gliding. Therefore, most of the dislocations freeze 
in place and do not relieve the misfit strain 
efficiently. The film will, thus, introduce further 
dislocations to relieve the strain and make 
dislocation gliding more difficult as the growth 
proceeds. To improve the quality of InGaN epi-
layers, the incorporation of a compositional graded 
inter layer will be essential (Islam et al., 2010). 
 
3.5 Electrical properties 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
The control of electrical properties in III-Nitride 
semiconductor is very important for the fabrication 
of device. The quality of an electronic material is 
conventionally given in terms of its majority carrier 
mobility at low electric fields, measured by Hall 
effect, which simultaneously provides information 
on the carrier concentration. As-grown GaN and 
InN is always n-type with a very high background 
carrier concentration. The electrical properties of 
InGaN are found to be poor; carrier concentration 
was measured in the range of 10
18 
~10
20
 cm
-3
 and 
mobility in the range of 20-100 cm
2
/V.s, for In 
composition up to 0.4. It can be seen from the 
figure that with the increase of In composition the 
electron concentration increases while the mobility 
decreases. The donor concentrations of InGaN are 
10
19
~ 10
20
 cm
-3
, while those of GaN and InN grown 
with the same reactor are ~ 10
18
 cm
-3
 (Fig. 5) and 
10
18
 ~ 10
19
 cm
-3
 (Yamamoto et al., 2006), 
respectively. Note that the tilt as well as twist that 
means defect density of InGaN films increases with 
the increase of In composition (Fig. 4). Such 
defects seem to act as donors. Therefore, it is 
(b) Twist 
In Composition in InGaN 
 
On GaN buffer 
On GaN template 
 
0 0.1 0.2 0.3 0.4 
40 
60 
80 
100 
X
R
C
 F
W
H
M
 (
ar
c 
m
in
) 
(a) Tilt 
0 0.1 0.2 0.3 0.4 
0 
10 
20 
30 
40 
In Composition in InGaN 
 
X
R
C
 F
W
H
M
 (
ar
c 
m
in
) On GaN buffer 
On GaN template 
 
(a)  
 
E
le
ct
ro
n
 c
o
n
ce
n
tr
at
io
n
 (
cm
-3
) 
 
0 0.1 0.2 0.3 0.4 
10 
18 
10 
19 
10 
20 
(b)  
 
M
o
b
il
it
y
 (
cm
2
/V
s)
 
 
In composition in InGaN 
 
0 0.1 0.2 0.3 0.4 
0 
20 
40 
60 
80 
100 
Fig. 5: Variation of (a) electron concentration, (b) 
mobility as a function of In composition grown on 
GaN template. 
 
Page 599
  
reasonable to conclude that the defect density is one 
of the candidates for high residual donors.  
 
4. CONCLUSIONS 
 
The understanding of various growth parameters 
such as the precursor gas flow rates and 
temperature is of immense importance for 
successful growth of high quality InxGa1-xN epi-
layers. By controlling these parameters InGaN 
films with In composition in the range from 0 to 0.4 
are successfully obtained without phase separation 
as well as metallic In incorporation by MOVPE. 
The variation of TMI/(TMI+TEG) molar ratio 
shows a significant effect on growing films. The 
formation of metallic In originates from the flow of 
higher value of TMI/(TMI+TEG) molar ratio 
during lower V/III ratio while the lower ratio of 
TMI/(TMI+TEG) causes the phase separation. The 
effective way to control the In composition of 
InGaN is found by temperature. Crystalline quality 
of grown films is markedly deteriorated with 
increasing In composition. The lattice mismatch 
and difference in thermal expansion coefficient 
between GaN template and InGaN epi-layer is 
primarily considered as the reason to deteriorate the 
film quality for higher In composition. The InGaN 
film grown on GaN template is found to show 
superior quality than the film grown on GaN buffer 
layer. The InGaN films with higher In composition 
show high residual donors. It is thought that the 
high defect density is responsible for the high 
residual donors in the grown film. 
 
REFERENCES 
 
1. Islam, Md. Rafiqul, Hasan, Md. Tanvir, 
Bhuiyan, A. G., Islam,  M. R. and  
Yamamoto, A. (2008), DESIGN AND 
PERFORMANCE OF InxGa1-xN-BASED MJ 
SOLAR CELLS, IETECH J. of Electrical 
Analysis, pp. 2 (4), 237-243. 
2. Wu, J., Walukiewicz, W., Yu, K. M., Shan, 
W., Ager III, J. W., Haller, E. E., Lu  Hai, 
Schaff,  W. J., Metzger , W. K. and Kurtz , 
S.(2003), Superior radiation resistance of 
In1−xGaxN alloys: Full-solar-spectrum 
photovoltaic material system, J. Appl. Phys. 
94, pp. 6477-6482. 
3. Srikant, V, Speck, J. S. and Clark, D. R. 
(1997), Mosaic structure in epitaxial thin 
films having large lattice mismatch, J. Appl. 
Phys. 82, pp. 4286-4295. 
4. Thothathiri, H. Lu, M., Wu, Z. and Bhat,I. 
(1997), Study of indium droplets formation on 
the InGaN films by single crystal x-ray 
diffraction, J. Electron. Mater., 26, pp. 281. 
5. Ho, I. and  Stringfello, G.B. (1996), Solid 
phase immiscibility in GaInN, Appl. Phys. 
Lett., 69, pp. 2701-2703. 
6. Koukitu, A., Seki, H. (1998), Thermodynamic 
study on phase separation during MOVPE 
growth of InxGa1-xN, J. Cryst. Growth 
189/190, pp. 13-18. 
7. Jani  Omkar, Yu Hongbo, Trybus Elaissa, 
Jampana  Balakrishnam, Ferguson Ian, 
Doolittle Alan, Honsberg  Christiana, (2007), 
EFFECT OF PHASE SEPARATION ON 
PERFORMANCE OF III-V NITRIDE 
SOLAR CELLS, 22nd European 
Photovoltaic Solar Energy Conference,, 
Milan, Ital, 3-7 September 2007. 
8. Komaki, H., Katayama, R., Onabe, K., Ozeki, 
M., Iraki, T. (2007), Nitrogen supply rate 
dependence of InGaN growth properties by 
RF-MBE,  J. Cryst. Growth, 305, pp. 12-18. 
9. Togashi, R., Kamoshita, T., Nishizawa, Y., 
Murakami, H., . Kumagai, Y, and Koukitu, A. 
(2008), Experimental and ab-initio studies of 
temperature dependent InN decomposition in 
various ambient, Phys. Stat. Sol. C, 5, pp. 
1518-1521. 
10. Islam, Md Rafiqul, Ohmura, Y., Hashimoto,  
A., Yamamoto, A., Kinoshita, K. and Koji, Y. 
(2010), Step-graded interlayers” for the 
improvement of MOVPE InxGa1-xN (x ~ 0.4) 
epi-layer quality, Phys. Status Solidi C, Vol. 
7, No. 7-8, pp. 2097-2100. 
11. Yamamoto, A., Miwa, H., Shibata, Y. and 
Hashimoto, A. (2006), NH3/TMI molar ratio 
dependence of electrical and optical properties 
for atmospheric-pressure MOVPE InN, Phys. 
Stat. Sol. (c), 3, pp. 1527-1530. 
 
  
Page 600
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Debabrata Kumar Karmokar  
E-mail: debeee_kuet@yahoo.com 
IMPEDANCE MATCHED COMPACT ZIGZAG INVERTED-F 
ANTENNA FOR WI-FI OPERATION IN A LAPTOP 
 
 
Debabrata Kumar Karmokar*, Md. Selim Hossain and Khaled Mahbub Morshed  
Faculty of Electrical & Electronic Engineering 
Khulna University of Engineering & Technology, Khulna-9203, Bangladesh 
 
Md. Nurunnabi Mollah 
Department of Engineering & Technology, Eastern University, Dhaka, Bangladesh 
 
 
Abstract—This paper presents an impedance matched compact zigzag inverted-F antenna (IFA) for Wi-Fi 
operation in a laptop. The antenna occupies very small area of 8 × 18 mm2. Also provides a high gain of 6.91 
dBi with the peak return loss of -49.75 dB, VSWR of 1.006 and input impedance of 50.2045 Ω at 5.5 GHz. 
This antenna covers a 10 dB return loss bandwidth of 609 MHz (5250 MHz~5859 MHz). In addition an 
impedance matching pie filter is used to ensure impedance matching between the source and the antenna. As 
well, the antenna has acceptable radiation characteristics.  
 
Keywords: Inverted-F antenna (IFA); Compact Antenna; Matching Network (MN); Zigzag IFA; Wi-Fi 
 
1. INTRODUCTION 
 
Recently, the swift growth in wireless 
communication system leads to several growing 
demands with the designing of various portable 
devices require small, low profile and multi-function 
antenna. In order to satisfy these demands, inverted-
F antenna (IFA) has been widely used in portable 
devices due to its compact, low profile 
configuration, ease of fabrication and favorable 
electrical performance. The wireless fidelity (Wi-Fi) 
operates in the 2.4 GHz band (2.4–2.484 GHz) and 5 
GHz band (5.15–5.35 GHz, 5.47–5.725 GHz, and 
5.725–5.875 GHz) (Pazin et. al., 2008, Wong and 
Lai, 2008, Wu et. al., 2005).  
 
A T-shaped monopole antenna with dual shorted L-
shaped strip-sleeves for dual operating band with 
bandwidth of 834 MHz (1962~2796 MHz) and 576 
MHz (5328~5904 MHz) at lower and upper 
frequency bands respectively (Wu et. al., 2005), a 
internal composite monopole antenna for 
WLAN/WiMAX operation in a laptop computer 
covers triple operating band with bandwidth of 347 
MHz (2371~2718 MHz), 600 MHz (3192~3792 
MHz) and 841 MHz  (5051~5892 MHz) at lower, 
middle and upper frequency band respectively  
(Wong and Chou, 2006), a modified two-strip 
monopole antenna for Wi-Fi and WiMAX 
applications (Chung et.al., 2009), internal wideband 
metal-plate antenna for laptop application covers a 
wider bandwidth of 3.9 GHz (2.1~6.0 GHz) (Wong 
and Chou, 2005), flat plate antenna with shorted 
parasitic element for laptop applications with 
impedance bandwidth of 190 MHz (2330~2520 
MHz, centered at 2.4 GHz) and 2140 MHz 
(4520~6660 MHz, centered at 5.5 GHz) for the 2.4 
and 5.8 GHz WLAN band respectively (Wong et. 
al., 2005) have been proposed. 
 
To provide the increasing demand and cover up the 
widespread applications of 5 GHz band (5.15–5.35 
GHz, 5.47–5.725 GHz, and 5.725–5.875 GHz) for 
Wi-Fi operation a low profile antenna with wider 
bandwidth, high gain and less gain variation within 
the antenna bandwidth is desired. To meet up most 
of the mentioned requirements, the proposed zigzag 
inverted-F antenna (IFA) is one of the good 
candidates within the micro-strip printed antennas 
because of its compact size and good input 
impedance than other printed antennas. 
 
In this article, we present a promising low profile 
antenna named zigzag inverted-F antenna (zigzag 
IFA) for 5.5 GHz Wi-Fi operations. 
 
2. ANTENNA GEOMETRY 
 
In designing the low profile antenna for Wi-Fi 
operation in a laptop, we examine the possibility of 
increasing antenna bandwidth, gain and 
Page 601
  
h1 
maintaining the input impedance near about 50 Ω 
by using impedance matching network throughout 
the application bands with simplifying its structure 
using method of moments (MoM’s) in Numerical 
Electromagnetic Code (Burke and Poggio, 1981). 
The cost of FR4 substrate is higher than the 
RT/duroid 5880. For the lower cost, in numerical 
analysis we considered the substrate permittivity of 
the antenna is εr = 2.2 (RT/duroid 5880) with 
substrate thickness of 1.58 mm. Our attempt was to 
reduce the size of the antenna with improved gain 
for the 5.5 GHz Wi-Fi operation in a laptop.  
 
 
 
(a) 
 
 
 
 
 
 
 
 
 
 
(b) 
 
Fig. 1: Structure of zigzag inverted-F antenna (a) 3-
D and (b) 2-D view. 
 
The antenna is assumed to be feed by a 50 Ω 
coaxial cable, with its central conductor connected 
to the feeding point and its outer conductor 
connected to the ground plane. For impedance 
matching, we use pie type matching network as 
shown in Fig.4. Fig. 1(a) and Fig. 1(b) show the 
structure of zigzag IFA 3-D and 2-D view 
respectively. Here one leg of zigzag IFA directly 
connected to the feeding and another leg spaced s 
from the ground plane.  In the analysis the 
dimensions of the ground plane considered as 60 
mm × 60 mm. Fig. 2(a) represents the variation of 
return loss for different values of h1 of zigzag IFA. 
From the analysis on Fig. 2(a) for the optimized 
value of h1, we see that when the value of h1=4 mm, 
the antenna provides maximum return loss but gain 
reduces remarkably at the operating band as shown 
in Fig. 2(b). The return loss and gain variation for 
different values of t are shown in Fig. 3(a) and (b) 
respectively.   
3 4 5 6 7
-60
-50
-40
-30
-20
-10
0
S 1
1 
(dB
)
Frequency (GHz)
 h1=2 mm
 h1=3 mm
 h1=4 mm
 
             
      (a) 
 
3 4 5 6 7
0
2
4
6
8
10
G
ai
n
 
(dB
i)
Frequency (GHz)
 h1=2 mm
 h1=3 mm
 h1=4 mm
 
(b) 
Fig. 2: Variation of (a) return loss and (b) gain of 
different value of h1 of zigzag IFA. 
 
Table 1. Dimension of the proposed antenna 
Antenna 
name 
Antenna 
parameters 
Values 
(mm) 
Dimension 
(mm2) 
Zigzag 
IFA 
l 15 
8×18 
t 3 
l+t 18 
h 8 
h1 3 
d 2 
s 5 
 
 
For the value of t=4 mm, the antenna provides high 
return loss but gain is very low for the required 
band. Besides the values of t=2 mm and t=4 mm 
does not cover the required 5.5 GHz band. Besides 
when the value of t=3 mm, the antenna fully covers 
the 5.5 GHz band for Wi-Fi operation. Table 1 
represents the optimized dimensions of the 
proposed antenna of Fig.1.        
 
s 
Feed 
d 
t 
h 
l 
t 
Page 602
  
3 4 5 6 7
-60
-50
-40
-30
-20
-10
0
S 1
1 
(dB
)
Frequency (GHz)
 t=2 mm
 t=3 mm
 t=4 mm
 
         (a) 
 
3 4 5 6 7
0
2
4
6
8
10
G
ai
n
 
(dB
i)
Frequency (GHz)
 t=2 mm
 t=3 mm
 t=4 mm
 
(b) 
Fig. 3: Variation of (a) return loss and (b) gain for 
different values of t of zigzag IFA. 
 
    
 
 
 
 
 
 
Fig. 4: Matching network (MN) for zigzag IFA 
 
Table 2. Matching network parameters 
Network parameters Value 
Xp1 0.25 pF 
Xp2 0    pF 
Xs 2.02 nH 
 
3.  SIMULATION RESULTS 
 
The simulated return losses of proposed zigzag IFA 
with and without matching network (MN) are 
shown in Fig. 5. From the simulation results, the 
zigzag IFA has return loss bandwidth of 609 MHz 
(5250~5859 MHz) and 1150 MHz (5750~6900 
MHz). From the simulation result we see that the 
zigzag IFA without matching network covers a 
wider impedance bandwidth than the antenna with 
matching network. But the impedance bandwidth 
without matching network covers extremely little 
portion of the required operating band on the other 
hand, with matching network the antenna covers 
almost all portion of the 5.5 GHz Wi-Fi operating 
band with the peak value of the return loss is -
49.75dB.  
 
 
3 4 5 6 7
-60
-50
-40
-30
-20
-10
0
S 1
1 
(dB
)
Frequency (GHz)
 without MN
 with MN
 
Fig. 5: Return loss variation of zigzag IFA with 
frequency 
 
3 4 5 6 7
0
2
4
6
8
10
G
ai
n
 
(dB
i)
Frequency (GHz)
 without MN
 with MN
 
Fig. 6: Gain variation of zigzag IFA with frequency 
 
The peak gain variation of the zigzag IFA as a 
function of frequency is shown in Fig. 6. From the 
obtained results, antenna peak gain varies from 7.84 
to 5.46 dBi at within the 10 dB return loss 
bandwidth of the zigzag IFA. The value of VSWR 
of zigzag IFA is 1.006 at 5.5 GHz. So, the obtained 
Coaxial 
Connector 
 
Xs 
 
Xp2 Antenna 
 
Xp1 
Page 603
  
3 4 5 6 7
-75
-50
-25
0
25
50
75
100
Ph
as
e 
(de
gr
ee
)
Frequency (GHz)
 without MN
 with MN
result indicates that the value of VSWR is very low 
and it is near to 1 as shown in Fig. 7. 
 
3 4 5 6 7
0
5
10
15
20
V
SW
R
Frequency (GHz)
 without MN
 with MN
 
Fig. 7: VSWR variation of zigzag IFA with 
frequency 
 
3 4 5 6 7
0
100
200
300
400
500
600
700
800
900
Im
pe
da
n
ce
 
(O
hm
)
Frequency (GHz)
 with MN
 without MN
 
Fig. 8: Impedance variation of zigzag IFA with 
frequency 
 
Fig. 9: Phase variation of zigzag IFA with 
frequency 
-30
-15
0
0 30
60
90
120
150180210
240
270
300
330
-15
0
 
 
 
             (a) 
 
-30
-15
0
0 30
60
90
120
150180210
240
270
300
330
-15
0
 
 
 
              (b) 
-30
-15
0
0
30
6090120
150
180
210
240 270 300
330
-15
0
 
 
               (c) 
-30
-15
0
0
30
6090120
150
180
210
240 270 300
330
-30
-15
0
 
 
              (d) 
Fig. 10:  (a) Total gain pattern in E-plane, (b) Total 
gain pattern in H-plane, (c) Vertical gain pattern in 
E-plane (d) Horizontal gain pattern in E-plane of 
zigzag IFA at 5.5 GHz. 
 
Page 604
  
Fig. 8 represents the antenna input impedance 
variation. From the obtained results, the input 
impedance of zigzag IFA is 66.70006 Ω at 5.5 GHz 
without impedance matching network and the 
impedance away from 50 Ω. So impedance 
matching network is necessary. Using matching 
network between the source and the antenna, the 
input impedance of zigzag IFA is found to be 
50.20454 Ω at 5.5 GHz and the impedance 
variation is very low within the operating band. So 
with impedance matching network the input 
impedance of the proposed antenna is near about 50 
Ω.  
 
Fig. 9 represents the antenna phase shift causes due 
to the impedance mismatch as a function of 
frequency. Also, from the simulation study, the 
antenna offers a phase shift of -50.68816o without 
matching network. Besides with matching network 
the phase shift is -0.29023o. With matching network 
the phase shift of zigzag IFA closer to 00 all over 
the antenna bandwidth.  
 
Peak gain comparison with the proposed antenna 
and reference antennas for Wi-Fi application are 
listed in Table 3. From the comparison table, 
proposed zigzag IFA has much higher gain than the 
antennas have been proposed earlier for 5.5 GHz 
Wi-Fi operation. Fig. 10 represents the radiation 
patterns of the antenna for 5.5 GHz resonant 
frequency of total gain in E and H-plane. The 
antenna’s normalized total radiation in E and H-
plane is almost omnidirectional at the 5.5 GHz Wi-
Fi operating frequency. In overall considerations, 
zigzag inverted-F antenna is much better than all 
other antennas. 
 
Table 3. Gain comparison between the proposed 
and reference antennas 
Antenna 
Peak Gain (dBi) 
at 5.5 GHz Wi-Fi 
Zigzag inverted-F (Proposed) 6.91 
T-shaped monopole (Wu et. al., 
2005) 
1.0 
Composite monopole (Wong 
and Chou, 2006) 
4.6–5.3 
Metal-plate antenna (Wong and 
Chou, 2005) 
4.6-5.2 
Flat-plate antenna with a 
shorted parasitic element 
(Wong et. al., 2005) 
4.2-5.7 
4. CONCLUSIONS 
 
Optimized impedance matched compact zigzag IFA 
for Wi-Fi application is proposed using numerical 
simulations. The antenna occupies extremely small 
area with bandwidth of 609 MHz (5250~5859 
MHz). Moreover the gain of the antenna is high and 
the gain variation of the antenna is very low within 
the operating band. From the analysis, the gain, 
radiation pattern, return loss, input impedance, 
VSWR and phase shift of the antenna is suitable for 
the specified applications than the antennas 
proposed earlier. Due to the compact area occupied, 
the proposed antenna is promising to be embedded 
within the spacing between the casing of the laptop 
and the supporting metal frame of the display as an 
internal antenna employing 5.5 GHz Wi-Fi 
operation. 
 
REFERENCES 
 
1. Pazin, L., Telzhensky, N. and Leviatan, Y., 
(2008), “Multiband Flat-Plate inverted-F 
antenna for Wi-Fi/WiMAX operation”, IEEE 
antennas and wireless propagation letters, 7, 
pp. 197-200 
2. Wu, J. -W., Wang, Y. -D. Hsiao, H. -M. and 
Lu, J. -H., (2005), “T-Shaped Monopole 
Antenna with Shorted L-Shaped Strip-Sleeves 
for WLAN 2.4/5.8-GHz Operation”, 
Microwave and Optical Technology Letters, 
46(1), pp. 65-69 
3. Wong, K. -L. and Chou, L. -C., (2006), 
“Internal Composite Monopole Antenna for 
WLAN/WiMAX Operation In A Laptop 
Computer”, Microwave and Optical 
Technology Letters, 48(5), pp. 868-871 
4. Chung, K. L., Mak, T. H. and Tam, W. Y., 
(2009), “A Modified Two-Strip Monopole 
Antenna for Wi-Fi and WiMAX Applications”, 
Microwave and Optical Technology Letters, 
51(12), pp. 2884-2886 
5. Wong, K. -L. and Chou, L. -C., (2005), 
“Internal Wideband Metal-Plate Antenna for 
Laptop Application”, Microwave and Optical 
Technology Letters, 46(4), pp. 384-387 
6. Wong, K. -L., Chou, L. -C. and Su, C. –M., 
(2005), “Dual-Band Flat-Plate Antenna with a 
Shorted Parasitic Element for Laptop 
Applications”,  IEEE Transactions on 
Antennas and Propagation, 53(1), pp.539-544 
7. Burke, G. J. and Poggio, A. J., (1981) 
“Numerical Electromagnetic Code-2”, Ver. 
5.7.5, Arie Voors. 
 
 
 
Page 605
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: R. R. Mahmud,  
E-mail: r.r.mahmud@gmail.com  
IMPLEMENTATION AND RESULTS OF A MICROCONTROLLER 
BASED DUOBINARY ENCODER CIRCUIT FOR 
COMMUNICATION SYSTEM  
 
 
R. R. Mahmud * 
Dept. of EEE, Ahsanullah University of Science and Technology (AUST), Bangladesh 
 
M. A. G. Khan and S. M. A. Razzak  
Dept. of EEE, Rajshahi University of Engineering and Technology (RUET), Bangladesh  
 
 
This paper presents microcontroller based practical circuit with results of a duobinary encoder (duobinary 
code from binary bit stream) for data communication system. Binary code has two level of bit sequence that 
is 1 and 0. On the other side, duobinary (DB) is a three-level code that is 1, 0 and -1 level. A duobinary 
encoder improves the digital system performance and the power efficiency of transmission . Microcontroller 
based duobinary encoder can encode the binary signal to duobinary signal by simple circuit operation with 
the help of microcontroller. The three bits comparison part of the encoding technique can be done by 
microcontroller portion very easily. Detail design procedures and outputs of the implemented practical 
circuits are presented in this paper. 
 
Key words: Duobinary encoder; Digital design; Microcontroller application and Two input inverting adder 
circuit.  
 
1. INTRODUCTION 
 
An efficient use of channel bandwidth and 
transmitted power is achieved through duobinary 
coding scheme. A binary data stream can be 
encoded into a duobinary signal (three level data 
(1, 0, -1)) simply by adding the binary data stream 
with its one bit delayed stream or by a precoding 
technique. Duobinary transmission was first 
invented in 1960 but applied in 1990 in the fiber 
optic communication system [5]. The advantages of 
duobinary transmission over binary transmission 
[5] are many folds; it has a narrower bandwidth 
than binary format, it saves transmitted power as 
the dc level of the signal is lower, easy to 
implement, and it suffers less from Stimulated 
Brillouin Scattering (SBS). Many efforts have been 
given in this field by a number of researchers. Our 
topic is different from the other researchers who 
have done their research on the same area. To show 
in difference between our findings and others, we 
would like to explain their researches. In 1990 only 
duobinary encoder and decoder signals are shown 
by J. Builting [2]. In 2008, Y. C. Lu et al 
demonstrated that 100% driving voltage did not 
need for optimal duobinary system [4]. One of the 
researchers Jiang who have shown that the 
complexity setup to the transmitter portion can be 
reduced by using a single-arm Mach-Zender 
modulator (MZM) for bandwidth 10 GB/s and for 
252 km of uncompensated standard single mode 
fiber (SSMF) [6]. In 2003, Demir Öner explained 
about the advantages and disadvantages of different 
line codes including duobinary code [8]. A 3 dB 
bandwidth of Bessel Low Pass Filter could be used 
to generate electrical duobinary signals for 40 GB/s 
duobinary system which was designed by A. 
Rahman et al [10]. In 2009, another author S. W. 
Shaker et al designed and implemented duobinary 
turbo codes which are used in wireless digital 
communications system [13]. All the mentioned 
papers explained about the performance of 
duobinary transmission, the bandwidth of low pass 
filters, signal and comparison of line codes and 
modulation technique of communication system. 
But so far as we know that there is no paper 
explains about this duobinary encoder and decoder 
technique with detail circuit design. So our paper is 
unique that is microcontroller based schematic 
circuit design of a complete duobinary encoder 
(duobinary code from binary bit) and duobinary 
decoder (binary code from duobinary code) for data 
communication system. Again our proposed 
Page 606ISBN: 978-984-33-2140-4
  
microcontroller based design circuit for duobinary 
encoder is cheaper, efficient and easy to implement 
compare with our previous design [11-12]. The 
circuit design of duobinary decoder is same but 
only modification is applied to the duobinary 
encoder part. One example of duobinary encoder 
and decoder bit sequence from binary is given 
below in figure 1. 
 
 
 
Fig. 1: Example of a duobinary encoder and 
decoder bit sequence from binary bit stream 
 
2. DUOBINARY ENCODER 
 
The circuit which converts duobinary code from 
binary bit sequence is called duobinary encoder. 
This duobinary encoder is used for data 
communication system. 
 
2.1 Block diagram of a duobinary encoder 
The duobinary encoding technique is a part of 
transmitter portion. First binary bit is generated. 
Then it is encoded to duobinary bit sequence which 
is given below in figure 2. Our proposed circuit 
design is a new technique where the speed 
controlling operation has been done by a 
microcontroller (Atmega32) through assembly 
language program which is given as block diagram 
in the figure no 2. By the block diagram of figure 
no 2, the not operation, exclusive-or operation (one 
input of the exclusive-or is come from not 
operation and another input from the previous 
output bit of the exclusive-or operation), bit shifting 
and each three bits comparison are done by the 
microcontroller itself and it is given a fixed speed 
data stream having two levels 0 and 1. In the block 
diagram of figure 2, source is binary input. The 
inverting amplifier and two input inverting adder 
have been used for converting the three level bits 
(having 1, 0, -1) from two level bits (0 and 1). The 
function of inverter is to generate the negative 
magnitude voltage. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 2: Block diagram of duobinary encoder system 
 
2.2 Algorithm of duobinary encoder 
The conversion technique from binary to duobinary 
bit stream follows some rules called algorithm 
which is given below. 
Step 1: It contains three level means 1, 0, -1. 
Step 2: Duobinary code depends on comparison of 
every 3 bit numbers for each and every               
position. 
Step 3: If the neighbor 2 bits among 3 bits are same 
then it tends to change the state. If it is            
not same then it holds the level means 0 
level. 
Step 4: Initially the level starts from -1. 
Step 5: If the signal is on state 1 and getting signal 
of state rise then it will be on state 1 level             
because 1 is the highest level in positive 
side. 
Page 607
  
Step 6: Similarly, if the signal is on state -1 and 
getting signal of state fall then it will be on             
state -1 level because -1 is the lowest level 
in negative side. 
 
3. MICROCONTROLLER BASED 
CIRCUIT  
 
Microcontroller is a programmable device which 
contains a microprocessor, random access memory 
(RAM), read only memory (ROM), registers etc as 
same as single chip computer. As microcontroller is 
a low cost programmable device, it is used in the 
automatic control application. For example robot, 
microwave oven, digital watch, mobile phone, 
electronic display and some conditions where 
logical circuit operation is difficult. Algorithm of 
the assembly language program for microcontroller 
of duobinary encoder is given below. Atmega32 
type microcontroller is used in simulation circuit.  
 
3.1 Algorithm for the program of the 
designed duobinary encoder circuit 
Step 1: Initialize the assembly program and all 
necessary registers. 
Step 2:  Define output port and input port. 
Step 3: Take the desired number from inside the 
program. 
Step4: Applying not operation of the desired 
program. 
Step 5: Applying exclusive-or operation (one input 
from current not operation and another 
input from ex-or operation of previous bit) 
of the number after            not operation. 
Step 6: Compare each and every 3 (three) bit 
number after exclusive-or operation for step 
up, step down and step hold condition. 
Step 7: Take previous state data from output port 
for determine state condition. 
Step 8: Give the output data to the output port. 
Step 9: Loop. 
 
3.2 Flow chart and description of assembly 
language program for duobinary                    
encoder circuit  
From the figure 3, initially all the necessary 
registers are declared as different suitable names. 
Then first take the desired number from program 
where the number is given by the user and can be 
changed before burning. Then the number is 
converted to 1’s complement means not operation. 
Then save the first complement number to a 
register named initial. After that exclusive-or 
operation has been done between count and initial 
register. Previously count register has been zero so 
the not output data has done exclusive-or operation 
with the previous bit means by default 0. The result 
is shifted left and the 8 bit position has been saved 
to the 8 bit position of a register. Increment count 
register after 1 bit exclusive-or operation and save 
the result to a register named first result. In this way 
the whole exclusive-or operation has been 
completed and it has been saved to the register 
named first result. Then the output ports have been 
declared and initially it should be x (portb 1) = 0 
and y (portb 2) = 1. Next the exclusive-or output is 
shifted 1 bit and taken every three bits for 
comparison and taken the previous output data for 
determining state condition. The program has been 
given output data according to the compare result 
with 0, 1, 2, 3, 4, 5, 6 and 7. In this way the output 
results are got by two ports. One is x (port b1) and 
another is y (port b2). 
In this way the program compares 3 bits numbers 
each and every time and gives the output result 
until the interrupt code is active. After this 
programming three types of output bits to the 
output ports X (port b1) and Y (port b1) can be 
obtained by the designed duobinary encoder circuit. 
 
Table 1 
Three cases or levels of duobinary encoder circuit 
 
 
From the above table 1, these outputs of PPIA / X 
(port b1) and PPIB / Y (port b1) have the values of 
positive and zero level logic voltage. But we need 
negative level logic means -1 level but there is no 
logic gate which will give -1 logic output. So we 
have to apply these programming outputs to the 
circuits called inverting amplifier and two inputs 
inverting adder circuit which is given below and 
finally 1level, 0 level and -1level logic voltage of 
duobinary coding can be obtained from the output 
of two inputs inverting adder circuit which is given 
below in the table no 2. 
 
Table 2 
 Truth table that follows the duobinary three  
(1, 0,-1) level of the two input inverting adder 
 
Page 608
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 4: Flow chart of assembly language program for duobinary encoder circuit 
Page 609
  
4. SIMULATION AND SCHEMATIC 
CIRCUIT OF DUOBINARY 
ENCODER 
 
Protious 7.6 software is used here which is 
basically electronic based simulation software. 
Atmega32 is used here for a microcontroller, 
LM358N is used for making inverting amplifier, 
two input inverting adder and magnitude 
comparator, IC74136 is for exclusive-or gate, 
IC7404 is for not gate, battery is for fixed dc power 
supply. Inverting amplifier is used for making x to 
–x and result of two input inverting adder = x-y. 
Then the duobinary encoding can be achieved. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 5: Proposed schematic full circuit of duobinary 
encoding and decoding system 
 
5. WAVE SHAPES AND RESULTS 
OF DUOBINARY ENCODER 
CIRCUIT 
 
Figure 6 is the simulation result by Protious 7.6 
simulation software. The yellow shape of 
duobinary encoder represents X, blue shapes 
represents Y and red shape represents duobinary 
code in figure 6 which is the example of figure 1. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 6: Simulation result of duobinary encoder 
 
6. IMPLEMENTED CIRCUIT AND 
RESULTS OF A DUOBINARY 
ENCODER 
 
One microcontroller (Atmega32), five resistors 
with 100Ω each, two operational amplifiers 
LM358N and some wires are used to implement the 
duobinary encoder. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 7: Implemented designed full circuit of 
duobinary encoder system 
 
After connecting the probes of an oscilloscope the 
wave shapes of duobinary encoder code can be 
obtained, has been given to the figure no 8 which 
are the 100 percent accurate results of the example 
of duobinary encoder as same as figure 1. 
 
Page 610
  
 
 
Fig. 8: Wave shapes of duobinary encoder from 
oscilloscope 
 
7. CONCLUSIONS 
 
The design circuit of duobinary encoder can be 
implemented any required place in communication 
system as duobinary has greater advantages than 
binary format. Our microcontroller based duobinary 
encoder generates low average power and that is 
why the duobinary data can travel long distance in 
communication system. Our proposed design 
circuit of duobinary encoder generates duobinary 
data at Mbps speed. Again proposed circuit design 
is a new technique where the speed controlling 
operation has been done by a microcontroller 
(Atmega32) through assembly language program 
and the not operation, exclusive-or operation, bit 
shifting and each three bits comparison are done by 
the microcontroller itself and a fixed speed data 
stream 0 and 1 are obtained. For this reason, the 
circuit becomes simple for the three bits 
comparison portion and additional clock pulse 
generator circuit is not need to the above proposed 
duobinary encoder circuit. So proposed design 
circuit is easy to implement, cheaper and more 
efficient than the previous design of duobinary 
encoder circuit. These circuits of duobinary encoder 
circuit gave hundred percent accurate results which 
are given in figure 1, 7 and 8 with respect to the 
time interval and bit sequence.    
 
 
REFERENCES 
 
1. Bravetti, P., Moller, L., et al, (2004), Impact of 
response flatness on duobinary transmission 
performance: an optimized transmitter with 
improved sensitivity, IEEE Photon. Technol. 
Lett, 16(9), pp 2159-2161. 
2. Builting, J., (1990), Introduction to duobinary 
encoding and decoding,” Elektor Electronics, 
pp 50-52. 
3. Barik, M. A., et al, (2010), Performance 
analysis of modulated laser with continuous 
wave laser in fiber optic communication 
system, Conference on Engineering Research, 
Innovation and Education, Dhaka, Bangladesh, 
pp 11-13. 
4. Gu, X., Dodds, S. J., et al, (1996), Duobinary 
technique for dispersion reduction in high 
capacity optical systems modeling, experiment 
and field trial, IEEE Proc- Optoelectron, 
143(4).  
5. Jiang, L. A., (1998), Propagation properties of 
duobinary transmission in optical fibers, Thesis 
submitted to Massachusetts Institute of 
Technology. 
6. Kaiser, W., Wuth, T., et al, (2001), A simple 
system upgrade from binary to duobinary, 
National Fiber optic Engineers conference, pp 
1043-1050. 
7. Kim, H. and Yu, C. X., (2002), Optical 
duobinary transmission system featuring 
improved receiver sensitivity and reduced 
optical bandwidth, IEEE Photon. Technol. 
Lett., 14(8), pp 1205-1207.  
8. Öner, D., (2003), Criteria for choosing line 
codes in data communication, Journal of 
Electrical & Electronics Engineering, 3(2), pp 
843-857.    
9. Miller, R., (1998), A bessel filter crossover, 
and its relation to other types, The 105 
Convention of the Audio Engineering Society, 
San Francisco, CA, September 26-29. 
10. Rahman, A., Broman, M., et al, Optimum low 
pass filter bandwidth for generating duobinary 
signal for 40 gb/s systems, Thin Film 
Technology Corp. 1980 Commerce drive, 
North Mankato, MN, 56003, USA.   
11. Mahmud, R. R., Khan, M. A. G. and Razzak, S. 
M. A., (2010), Design of a duobinary encoder 
and decoder circuits for communication 
systems,” accepted to the 6th international 
conference on electrical and computer 
engineering (ICECE),16-18 December, Dhaka, 
Bangladesh. 
12. Shaker, S. W., Elramly, S. H., et al, (2009), 
Design and implementation of low-power turbo 
encoder for DVB-RCS software radio,” 17th 
Telecommunication Forum TELFOR 2009, 
Belgrade, Serbia, November 24-26, 2009.   
13. Xie, C., et al, (2004), Improvement of optical 
nrz and rz duobinary transmission systems with 
narrow bandwidth optical filters, IEEE Photon. 
Technol. Lett., 16(9), pp 2162-2164. 
14. Online documentation about Protious 7.6 
software viwed on 3 June at the web site:        
http://www.atmel.com/dyn/resources/prod_doc
uments/doc2503.pdf 
 
Page 611
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
* Corresponding Author: Shakil Ahamed Khan,  
E-mail: shakil_pilabs@yahoo.com 
IMPLEMENTATION OF ARTIFICIAL INTELLIGENCE IN 
EMBEDDED SYSTEM FOR AUTOMATIC VOLTAGE REGULATOR 
 
 
Shakil Ahamed Khan*  
Dhaka International University, Dhaka 
 
Md. Ismail Hossain 
International Islamic University Chittagong, Dhaka 
 
 
Fuzzy logic control is being increasingly applied to solve control problems in areas where system 
complexity, development time and cost are the major issues. Engineers and researchers are today 
considering fuzzy logic algorithm in order to implement intelligent functions in embedded systems. In this 
paper, the application of a simple microcontroller to deal with a two variable input and a single output fuzzy 
logic controller has been tested for automatic voltage regulation of an inverter. A set of linguistic fuzzy 
control rules are set up which are conditional linguistic statements and establish the relationships between 
the inputs and the outputs, so that the output voltage of an inverter is stabilized. This paper discusses the low 
cost implementation of fuzzy algorithm in an 8-bit microcontroller using the tools and techniques to generate 
optimized fuzzy based real time code in C for ATMega32 microcontroller which will demonstrate how fuzzy 
logic might provide elegant and efficient solutions in the design of multivariable control based on 
experimental results rather than on mathematical models.  
 
Key words: Voltage source inverter (VSI); pulse width modulation (PWM); fuzzy logic control (FLC); 
centre of gravity (COG); microcontroller 
 
1. INTRODUCTION 
 
In recent years, the distributed generation system 
using new energy sources has attracted much 
attention (Uematsu et. al., 2002). Since this 
distributed generation system links to a commercial 
source, a utility interactive inverter is required.  
Pulse Width Modulation (PWM) inverters are of 
huge and great impact in many engineering 
disciplines. It plays a big role in the field of power 
electronics regarding voltage sources to vast 
amount of electronics equipments and machine 
controllers. In this case, some different levels of 
DC voltage are applied as an input for the inverter 
because there are new energy sources such as solar 
batteries and fuel cells provide different DC voltage 
levels. However, in certain applications, such as 
steel mills, paper mills, robotics, machine tools, the 
drive operates under a wide range of load change 
characteristics and the output voltage of an inverter 
vary substantially. 
    To overcome this drawback, we have proposed a 
scheme as shown in Fig. 1, based on the use of 
conventional DC-DC converter, followed by a 
PWM inverter where feedback and artificial 
intelligence control system is implemented.  
 
 
Regulated output voltage is assured by varying the 
duty cycle of the PWM pattern with the use of fuzzy 
logic control algorithm using microcontroller. The 
control algorithm includes a complicated 
computation process to eliminate the variations in 
the load disturbance and systems parameters and 
also obtain high performance AC system. Designing 
a conventional controller presents problems since 
modeling the system is very difficult due to its non-
linearity. For controlling such a complicated system, 
fuzzy logic control can be the best solution (Bor-
SenChen et. al., 1999). Fuzzy logic controllers have 
the advantages of working with imprecise inputs, 
not needed an accurate mathematical model, and 
handling nonlinearity (Veerachary et. al., 2003).   
However, fuzzy technique, which has gained 
popularity in recent years, looks very promising for 
this application. The use of fuzzy logic in gate 
signals control in PWM voltage source inverter 
(VSI) is tackled, analyzed, and implemented in this 
paper, where MATLAB/SIMULINK simulation and 
experimental results are described. The results show 
how well this controller eliminates  
 
Page 612ISBN: 978-984-33-2140-4
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
the complexity and provides a very fast rise time for 
voltage stability of an inverter. 
 
2. DESIGN CONSIDERATION 
 
    The full bridge inverter stage is designed with 
MOSFET power transistors as shown in Fig. 4,. 
The drive signal for MOSFET power transistors is 
generated by the PWM (pulse width modulation) 
module contained in the microcontroller. The 
proper value of duty cycle is selected with the use 
of fuzzy logic control algorithm depending on the 
condition of inverter output voltage. With fuzzy 
logic, output voltage is stabilized while variation of 
the input range is 150V to 250V. For sensing the 
inverter output voltage, potential transformer is 
used to step down the output voltage and rectified 
by using full wave rectifier circuit. The output is 
then feed back to ADC0 pin of ATMega32 
microcontroller. The ADC module contained in 
ATMega32 microcontroller is used to convert the 
voltage levels to digital value and can work on 
voltage up to 5V. A/D conversion is completed by 
using software program. With a 10-bit ADC over 
the full range of mains voltage (0~300V) scaled to 
0 to 5V. The resolution is 300/1024 or 0.3V. This is 
too high a resolution called for. The rms value of 
the voltage is calculated by using the formula as 
given in (1). 
 
                
n
V
V n
n
rms
24
1

                        (1) 
 
Where n is the total number of sample taken and Vn 
is the nth sampled voltage. If the output voltage 
decreases the Vrms voltage also decreases. The 
output voltage of inverter is rule-based. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
The rules logic is built into the software developed 
where fuzzy logic control system is applied so that 
whenever Vrms voltage decreases or increases; duty 
cycle of PWM varies to regulate the output voltage. 
MATLAB simulation results are shown in Fig. 2 
and Fig. 3. Normalized PWM and normalized 
output sine waves are shown in these figures. As 
the amplitude of the output voltage decreases, the 
duty cycle of each pulse in PWM increases to 
regulate the output voltage as observed in Fig. 2 
and Fig. 3.   
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 2:  PWM at normal condition 
 
 
 
 
 
 
 
 
 
 
 
 
 
                        Fig. 3:  PWM at loaded condition  
 
Fig. 1:  Detailed block diagram of the systems proposed 
 
Page 613
  
µ 
 
Fig. 4:  Full bridge inverter circuit 
 
 
3. FLC IMPLEMENTATION ON  
    EMBEDDED SYSTEMS 
 
    The inputs to an AVR using fuzzy logic 
controller are usually an error voltage E and a 
change of error ∆E as given in (2) and (3) 
respectively. 
 
           )1()()(  nVnVnE                        (2) 
           )1()()(  nEnEnE                     (3) 
 
E and ∆E are calculated and converted to the 
linguistic variables during fuzzification. Linguistic 
variables are non-precise variables that often 
convey a surprising amount of information. To 
simplify the control calculation, the values of error 
voltage E and change of error ΔE can be 
normalized with (4) before fuzzification process:  
  
         









*
*
*
*
,1
,
,1
YY
YYY
Y
YY
YS                         (4) 
 
     Where, max
* YY  , so the scopes of error E and 
change of error ΔE will be [-1, 1]. Fig. 5 shows the 
relations between measured error and the 
linquistive term, such as positive small, positive 
medium and positive big. At some point the error is 
positive small and at some point the error is 
positive big the space between positive big and 
positive small indicates an error that is, to some 
degree, a bit of both. The horizontal axis in the 
following graph shows the measured or crisp value 
of error voltage. The vertical axis describes the 
degree to which a linguistic variable fits with the 
crisp measured data. 
 
  
Fig. 5: The relationship between linguistics variable 
and error 
 
        To add the linguistics variable positive big to a 
computer program running in an embedded 
controller, translation the graphical representation 
into meaningful code is needed. The following C 
code fragment gives one example of how to do this. 
The function error- Positive Big ( ) returns a degree 
of membership, scaled between 0 and 1, indicating 
the degree to which a given error can be positive 
big. This type of simple calculation is the first tool 
required for calculations of fuzzy logic operations.  
                    char Error_ Positive Big (int  CRISP) 
                         { 
                            if (CRISP < 0.4) 
                                 return(0); 
                           else 
                                { 
                                   if (CRISP >= 0.4)  
                                      return(CRISP * 2.5); 
                                  else 
                                       { 
                                         return(1);  
                          }}          }  
 
      Rule evaluation is done by using an algorithm 
where loops compare the antecedent value 
depending on the rule being evaluated in a repeated 
fashion until all rules are evaluated.  
 
       The fuzzy logic controller output is typically a 
change in duty ratio ∆D of the power converter. 
The linguistic variables assigned to ∆D for the 
different combinations of E and ∆E as shown in 
Table 1 which is based on a DC-DC conversion 
unit. If, for example, the error voltage E is PB, and 
∆E is PS, then we want to largely increase the duty 
ratio, that is ∆D should be PB for very fast rise time 
of voltage stability. 
 
Table 1.  Fuzzy rule base table 
 
   E 
∆E 
NB NS ZE PS PB 
NB NB NB NS ZE ZE 
NS NB NS ZE ZE PS 
ZE NB ZE ZE PS PS 
PS ZE ZE PS PS PB 
PB ZE PS PS PB PB 
Page 614
  
The final step in the fuzzy logic controller is to 
combine the fuzzy output into a crisp systems 
output. The result of the defuzzification has to be a 
numeric value which determines the change of duty 
cycle of the PWM signal used to drive the 
MOSFET of the H-bridge inverter. There are 
various methods to calculate the crisp output of the 
system. Centre of gravity (COG) method is used in 
our application due to better results it gives. The 
COG for our application is expressed 
mathematically, as given in (5). 
                      





 4
1
4
1
][
][][
n
n
iY
iFiY
D                  (5) 
Where Y[i] is the ith members of the output vector 
and F[i] are the multiplying coefficients of the 
output membership function as shown in Table 1, 
and ∆D is the change of duty cycle, and this 
number represents a signed number which is added 
or subtracted from the present duty cycle to 
generate the next system response for voltage 
stability. 
4. FIRMWARE DESCRIPTION 
      The overview of fuzzy logic control voltage 
stabilizer is shown in Fig. 6. Before entering the 
main control loop firmware initialize itself. The 
Liquid Crystal Display is used to display duty 
cycle. The information of output voltage, change of 
error voltage and duty cycle is used to tune fuzzy 
rules. The main loop is responsible for updating 
ADC value and calculating output voltage, error 
voltage and differential error voltage. Using these 
variables, duty cycle is calculated. The calculation 
is performed by using fuzzy logic algorithm based 
on a single chip ATMega32 microcontroller. Timer 
1 generates interrupt in every 10ms. The interrupt 
signal from the timer 1 causes AD conversion 
started. The ADC value is used to calculate Vrms 
which is proportional to the output voltage.   
 
5. TEST AND RESULT  
       The experimental result for the real time test of 
fuzzy voltage controller is shown in Fig. 7 where 
the control of DC bus voltage of DC-DC converter 
section is done using fuzzy logic algorithm. Fig. 
7(a) shows the duty cycle of PWM signal for a 
fixed input voltage and Fig. 7(b) shows the 
increased duty cycle using fuzzy logic algorithm for 
decreased input voltage to obtain output voltage 
stability. RS232 communication was established 
with computer for monitoring the output DC bus 
voltage. 
 
 
 
Fig. 6:  Fuzzy AVR FIRMWARE 
 
With the use of MATLAB code, online data of 
output voltage is plotted using serial 
communication as shown in Fig. 9. Continuous 
monitoring of the voltage showed that, output of the 
DC bus voltage is stabilized very fast for changed 
input voltage. Fig. 8 shows the 
MATLAB/SIMULINK simulation result of 
normalized output voltage using fuzzy logic control 
and without using fuzzy logic control for step input 
voltage change.  
 
Page 615
  
 
(a) 
 
 
 
 
(b) 
 
Fig. 7:  Experimental layout for the real time test 
 
 
 
 
Fig. 8:  MATLAB/SIMULINK result of fuzzy logic 
 
 
 
 
 
 
 
Fig. 9:  Online output voltage monitoring using 
serial communication 
 
 
6. CONCLUSION 
 
     This paper has demonstrated the implementation 
of fuzzy logic control for the control of fluctuated 
AC to a consumer home due to different levels of 
DC voltage as an input for the inverter and non 
linear load characteristic. The FLC is easy to 
implement and require a small amount of 
inexpensive components in compact size. The 
designed controller showed good ratification 
performance between 150V and 250V input and 
provide a stable output. The test result showed that, 
the controller provides a very fast rise time for 
voltage stability of an inverter within less then 1 
second.  
 
 
 
REFERENCES 
 
1. T. Uematsu, K. Tanaka, Y. Takayanagi, H. 
Kawasaki, and T.Ninomiya, "Utility 
Interactive Inverter Controllable for a Wide 
Range of DC Input Voltage," PCC 2002, 
Osaka, Japan, 2002, pp. 498-503. 
2. Bor-SenChen, Chung-Shi Tseng and Huey-
Jian Uang, “Robustness Design of Nonlinear 
Dynamic Systems via Fuzzy Linear Control,” 
IEEE Fuzzy Systems, vol. 7, no. 5, pp. 571-
585, Oct. 1999. 
3. M.Veerachary, T.Senjyu,and 
K.Uezato,“Neural-network-based maximum-
power-point tracking of coupled-inductor 
interleaved-boost-converter-supplied 
PVsystem using fuzzy controller,” IEEE    
Electron, vol.50, no.4, pp.749–758, Aug.2003.  
Using fuzzy logic 
Without using fuzzy logic 
To MOSFET 
Q1 & Q3 To MOSFET Q2 & Q4 
Page 616
 Proceedings of the 
International Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Md. Forhad. Zaman,  
   E-mail: m.fzaman@yahoo.com 
 
IMPLEMENTATION OF BOOST CONVERTER FOR LOW POWER 
APPLICATION 
*M.F.Zaman1, M.H.Suman2, M.F.Rahman3 
Department of Electrical & Electronic Engineering 
Rajshahi University of Engineering & Technology 
Rajshahi – 6204, Bangladesh 
 m.fzaman@yahoo.com1, mathahyhasansuman@yahoo.com2, mfrahman3@yahoo.com3 
Abstract- This paper deals with a Boost converter for low voltages in battery or photovoltaic applications. 
The performance of the PWM Boost regulators is investigated theoretically as well as experimentally.  In 
order to improve the transient time and inductor ripple current, the Boost converter is considered in both 
continuous and discontinuous mode. At first the steady-state performance is investigated to improve the 
inductor ripple current and it is investigated by using MATLAB simulation. It is shown that, the input ripple 
current of Boost converter can be substantially reduced by using different parameters. Then it is closely 
observed the transient time of Boost converter for those different values. And it is seen that, the output 
voltage goes to steady state after 1 ms, which is expected.  A 60V dc Boost converter has been designed, 
realized and successfully tested in the laboratory. The Boost Converter has been implemented by using 555 
timer to control the switching regulator. The output voltage has been controlled by a switching and sampling 
network. The switching function controls the operation of the device used in boost converter. The feedback 
has been taken from the output and is applied to a comparator circuit to produce the PWM signal for 
switching function. Another intension is to improve the changeover time of Boost Converter by using 555 
timer to produce PWM instead of Conventional Comparator-Op amp method. 
Keywords- Averaged models boost converter, circuit averaging dynamic phasors, modeling, power 
electronics, sampled-data models, simulation, state-space averaging, switched models., 555 timer. 
1. INTRODUCTION 
Step up choppers for DC to DC power conversion 
find widespread applications in different areas [1].  
They are used to boost a varying DC input voltage 
to a higher stabilized DC output voltage or to draw 
a certain current from a DC power source.  These 
features can be used to supply a 60V power from a 
12V battery in automotive applications or to track 
the maximum point of power in photovoltaic 
systems. 
The boost converter has the five basic components, 
namely a power semiconductor switch, a diode, an 
inductor, a capacitor and a PWM controller [2]. To 
illustrate the challenges in modeling and simulation 
of boost converter circuit, we built around the 
example of a boost dc-dc converter. The basic 
Boost converter, intented to provide a voltage step 
up function, is embedded in application ranging 
from power factor corrected (PFC) rectifier circuits 
(whose input  current is made to follow the wave 
shape of the input voltage) to circuits comprising 
the RF amplifier in cell phones [3].  
Fig. 1 depicts a step-up or a PWM boost converter. 
It consists of dc input voltage source VS, boost 
inductor L, controlled switch S, diode D, filter 
capacitor C, and load resistance R. The converter 
waveforms in the Continuous Conduction Mode 
(CCM) are presented in below. When the switch S 
is in the on state, the current in the boost inductor 
increases linearly and the diode D is off at a time. 
When the switch is turned off,  
The energy stored in the inductor is released 
through the diode to the output RC circuit [1].  
Using Faraday’s law for the boost inductor [4], we 
get the following equations 
TDVVDTV SS )1)(( 0             -----(1) 
Page 617
ISBN: 978-984-33-2140-4
LC R
D
S
Vs
IL Io
IcIs
    +   VL   -
+
Vo
_
 
Fig. 1 Basic Boost Converter 
 
Fig. 2 Output of Ideal Boost Converter 
The dc voltage transfer function turns out as 
follows: 
DV
V
M
S
V 

1
10
                        -- (2) 
2. BACKGROUND OF BOOST 
CONVERTER 
Analysis of the circuit is carried out based on the 
following assumptions. The circuit is ideal. It 
means when the switch is ON, the drop across it is 
zero and the current through it is zero when it is 
open. The diode has zero voltages drop in the 
conducting state and zero current in the reverse-bias 
mode. The time delays in switching on and off the 
switch and the diode are assumed to be negligible. 
The inductor and the capacitor are assumed to be 
lossless [7].   
The circuit operation can be divided two modes 
[1][8], Mode-1 begins when transistor M is 
switched on at t=0. The input current, which rises, 
flows through inductor L and MOSFET ‘M’. 
Mode-2 begins when transistor M is switched off at 
t=t1.   These are shown below: 
 
Mode-1: (Switch off):                                                 
 
 
 
 
 
 
 
 
Mode-2: (switch on) 
 
 
 
 
 
 
 
 The basic principle of a Boost converter consists 
of 2 distinct states: 
 In the On-state, the switch M is closed, resulting 
in an increase in the inductor current; 
 In the Off-state, the switch is open and the only 
path offered to inductor current is through the fly 
back diode D, the capacitor C and the load R.  
 These results in transferring the energy 
accumulated during the On-state into the 
capacitor. 
 The input current is discontinuous, stepping 
between a very high inductor current and 0. The 
large ripple usually requires a large input bypass 
capacitor to reduce the source impedance. 
 
 
dt
tdi L )( = 
1
L [Vin (t) - Vc (t)] 
dt
cdV )(
= 
C
ti L )(  -  
RC
tVc )(
 
V0 (t) = Vc(t) 
dt
tdi L )( = 
1
L Vin (t) 
dt
cdV )(
=  -  
RC
tVc )(
 
V0 (t) = Vc(t) 
Page 618
3. CONTINUOUS CONDUCTION 
MODE 
When a boost converter operates in continuous 
mode, the current through the inductor (IL) never 
falls to zero [1][8].  
Boost Converter operates in Continuous mode if the 
inductance and capacitance are greater than the 
critical value [1]. 
The output voltage for this mode can be written as 
Vi
Vo
 = 
K1
1
 
Where k is the duty cycle and it is less than 1. 
The condition for continuous conduction is [4]: 
L
DRDf
2
]1[ 2
  
The circuit tends to become discontinuous,  
i. if the switching frequency f is decreased, 
or  
ii. if the duty cycle D is reduced, or  
iii. if the load resistance increases, or  
iv. If the inductance used has lower value.  
4. DISCONTINUOUS CONDUCTION 
MODE 
In some cases, the amount of energy required by 
the load is small enough to be transferred in a time 
smaller than the whole commutation period. In this 
case, the current through the inductor falls to zero 
during part of the period.  
Boost Converter operates in Discontinuous mode if 
the inductance and capacitance is less than the 
critical value [4][5][6]. 
The output voltage for this mode can be written as 
Vi
Vo
 =1+ 
L
i
IL
TKV
*2
**2
 
Where,  
Critical Inductance Lc = 
f
RK
2
)1( 
  
Critical Capacitance Cc   =
fR
K
2  
5. FILTER INDUCTANCE AND 
CAPACITANCE: 
The ripple of Current depends on the value of 
inductance and ripple of Voltage depends on the 
value of capacitance. So if we desired the output 
voltage and current then we can also control the 
ripple of voltage and current by this formula 
[4][5][6]: 
∆I=
fL
KV s  
∆Vc=
fc
KI a  
Here ‘K’ is the duty cycle. 
6. COMPLETE CIRCUIT DIAGRAM 
OF PROPOSED BOOST 
REGULATORS 
The most interesting aspect of the circuit is how an 
ordinary 555 (Operates as Free Running 
Multivibrator) is used to regulate the output 
voltage. Now, there are hundreds of switched mode 
controllers ICs on the market which are all better 
suited for this job than the 555. The problem with 
all these ICs is that if we build a nice NIXIE clock 
using them, and at one moment in the future the IC 
breaks down, it is more than likely that it is already 
obsolete and out of production. The 555 is (very) 
cheap, performs well enough and most likely will 
remain in production forever [6]. 
This can be realized by PWM control. The PWM 
control of a switched converter is achieved by 
comparing a reference signal Vref with the 
feedback signal taken from the output voltage 
The 555 timer act as PWM (Pulse Width 
Modulator) and it is controlled the duty cycle. The 
duty cycle of PWM is not fixed rather it changes 
continuously depends on output voltage. If the 
output voltage is varying then the duty cycle is also 
changed [9]. 
 
Fig. 3 simple 12-60 V Boost Converter using 555 
timer 
Page 619
0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1
0
5
10
15
20
Inductor Current
In
du
ct
or
 C
ur
re
nt
(A
m
p)
time(secs)
0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1
0
20
40
60
80
Capacitor Voltage
C
ap
ac
ito
r V
ol
ta
ge
(V
ol
t)
time(secs)
0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1
0
1
2
3
4
5
Inductor Current
In
du
ct
or
 C
ur
re
nt
(A
m
p)
time(secs)
0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1
0
5
10
15
20
Capacitor Voltage
C
ap
ac
ito
r V
ol
ta
ge
(V
ol
t)
time(secs)
7. SIMULATION OF THE PROPOSED 
BOOST CONVERTER 
Use MATLAB or Mathematical to do the 
numerical integration. We have complete 
freedom to employ other integration algorithms 
as well as to change the time sequences to suit 
our desire for a complete or just a crude model 
as we show below. The point to consider is 
whether or not we have the interest in 
becoming a computer programmer of power 
electronics problems as this is a very time 
intensive endeavor [4][5][6].  
 
 
 
 
 
Fig. 4. Transient waveform in the Boost Converter 
example for iL(t) and Vc(t). where E=160[V], 
L=0.33 [mH], C= 22 [µF], R=200 [ohm] f= 
50[KHz], Duty Cycle = 66.67 %., Iref=0.5[A] 
8. BOOST CONVERTER OPERATES 
IN CONTINUOUS CONDUCTION 
MODE 
 
 
 
 
 
Fig. 5. Transient waveform in the Boost 
converter when operates in continuous 
conduction mode,  for iL(t) and Vc(t) . Where 
E=15[V]; L=150[µH]; C=220[µF];R=30[];  
ff=25[kHz];Duty cycle=66.7[%];  
9. BOOST CONVERTER OPERATES 
IN DISCONTINUOUS 
CONDUCTION MODE 
 
 
 
 
 
  
 
 
 
 
 
 
Fig. 6. Transient waveform in the Boost 
converter when operates in discontinuous 
conduction mode,for iL(t) and Vc(t) . Where 
E=5[V];L=250[µH]; C=220[µF]; R=100[], 
ff=25[KHz]; Duty cycle=66.7[%];  
10. RESULT AND ANALYSIS 
 
Fig. 7 Capacitor charging and discharging period of 
555 timer 
 
Fig. 8 Output of 555 timer 
0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1
0
10
20
30
40
50
Inductor Current
In
du
ct
or
 C
ur
re
nt
(A
m
p)
time(secs)
0 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1
0
100
200
300
400
500
600
Capacitor Voltage
C
ap
ac
ito
r V
ol
ta
ge
(V
ol
t)
time(secs)
Page 620
 Fig. 9 Output of the Boost Converter 
In our experiment we used only one supply that is 
DC 12V. The capacitor charging and discharging 
duration of 555 timer is obtained in Fig. 7. The 
output of the 555 timer is shown in Fig. 8. And it is 
observed that the pulse width which is generated by 
the timer is not constant initially rather  it is varying 
depends on output voltage of Boost converter and 
after few moments when output voltage of the 
Boost converter is fixed then the gate pulse width 
of the Boost converter is same. That means the 
control voltage of 555 timer is same, so that the 
upper and lower threshold voltage is fixed and 
pulse generated by the 555 timer is same. 
The output of the Boost converter is about 60 V and 
it is constant remember we supply in the Boost 
converter is only 12 V which is shown in Fig. 9. 
11. DISCUSSION AND CONCLUSION 
Boost converter is mainly used where high DC 
power is required and AC power is available. The 
power electronic converters as discussed in this 
paper gave an insight of how the unregulated 
voltage and current of the Boost converter can be 
improved. The output of the converter shows the 
fundamental frequency operation of 25 KHz along 
with high frequency switching harmonics which 
can be filtered using the conventional low-pass 
filter. Moreover, the magnitude of the fundamental 
Voltage and Current are also regulated to the 
desired value i.e. 45V and 0.5 [Amps]. Although 
this fundamental value of voltage and current is not 
fixed rather it depends on the reference value.  
In the paper [3], it has been shown that, the 
inductor current as well as capacitor voltage goes to 
steady state after 4 ms. In the proposed model this 
value, shown in Fig. 4, is about 1 ms. Hence about 
80 [%] improvements in the transient condition 
were achieved.  
The inductor current goes to steady state condition 
within 4[ms] at an inductance of 150[µH]. If this 
value is increased to 250 [µH] keeping other 
parameters fixed, the transient part of the inductor 
current does not die out even after 10 [ms]. 
In many industrial applications, DC-DC converter 
is required to convert a fixed-voltage DC source 
into a variable-voltage DC source. Like a 
transformer, DC-DC converter can be used to step 
down or step up a DC voltage source. 
12. REFERNCES 
 
1. Heinz van der Broeck, Ibrahim Tezcan,“ 1 KW 
Dual Interleaved Boost Converter for Low 
Voltage Applications ” University of Applied 
Sciences Cologne,  Faculty IME, Betzdorfer 
Str. 2  50679 Köln, Germany 
2. Muhammad H. Rashid, “Power Electronics 
circuit device and application” in Prentice-Hall 
of India, 1998, pp. 12-15 & 320-322. 
3. Dragan Maksimovic, V. Joseph Thottuvelil, 
George C. Verghese, “Modeling and 
Simulation of a Boost Converter” in IEEE  
Power  Electronics  Specialists  Conf.  (PESC), 
2000, pp. 1-3. 
4. http://en.wikipedia.org/wiki/Boost_converter 
5. http://services.eng.uts.edu.au 4, France 
6. www.uoguelph.ca/~antoon/gadgets/555/555.ht
ml 
7. Fatima El Guezar, Hassane Bouzahir, 
”CHAOTIC BEHAVIOR IN A SWITCHED 
DYNAMICAL SYSTEM” in Mathematics 
Subject Classification, 1991, pp. 1-3. 
8. Muhammad H. Rashid, “Power Electronics 
Handbook” in Academic Press, 1996, pp. 221-
226. 
9. http://www.elecfree.com/electronic/simple-12-
180v-boost-converter-using-the-555-as-
controller/ 
10. Robbert F. Coughlin, Frederick F. Driscoll, 
“Operational Amplifier and Linear Integrated 
Circuits” in Prentice Hall, 2001, pp-363-374. 
Page 621
  Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
* Corresponding Author: Md. Ismail Hossain  
E-mail: jewel04eee@yahoo.com 
IMPLEMENTATION OF PID CONTROL AND PWM TECHNIQUE 
IN EMBEDDED SYSTEM FOR RIPPLE FREE AND STABILIZED 
SINE WAVE INVERTER 
 
Md. Ismail Hossain* 
International Islamic University Chittagong 
Dhaka, Bangladesh 
 
Shakil Ahamed Khan  
Dhaka International University, Dhaka 
 
Md. Shafiullah and Md. Nazmus Sahadat 
International Islamic University Chittagong 
Dhaka, Bangladesh 
 
Ashraful Arefin 
Dhaka International University, Dhaka 
 
A microcontroller based PWM technique and advanced PID control of generating stabilized sine wave 
inverter with minimized harmonics is implemented in this paper. Our proposed technique is to keep the 
output voltage and frequency stable and constant within a certain range of load so that it can operate 
electrical and electronic devices efficiently. The designed inverter provides a range of operation between 
25W to 660W. Ripple free and stabilized output voltage is obtained by using efficient filter design and 
implementation of PID control action in embedded system which is based on experimental results rather than 
on mathematical model. Appropriate Filter is designed by using Laplace transformation. Size of the 
transformer is reduced by high frequency switching. The design is simulated in Matlab, Proteus Design Suite 
software and finally the results are practically verified. 
 
Keywords: PWM technique, PID control, Microcontroller, Voltage sensor, ADC, Duty cycle, Program 
flow chart, Simulation in Proteus and Matlab, Hardware implementation. 
 
1. INTRODUCTION 
Energy crisis are of special attention now-a-days. A 
need for reasonable power rating inverter is 
required to smoothly operate electrical and 
electronic appliances. Most of the commercially 
available UPS are actually square wave inverters or 
quasi sine wave inverters. Lights and fans can only 
be switched with the help of them and other 
electronic devices cannot be plugged into them as 
they damage them. Available sine wave inverters 
are very expensive and by examining the output 
wave, it is observed that it is not of good quality. 
Quality of output waveform of an inverter is 
determined by the harmonic contents present in it. 
An ideal Inverter should only have a fundamental 
harmonic component at the designed frequency and 
stable output voltage within its range. Square wave 
contains odd harmonics from which fundamental 
harmonic component can be extracted by applying 
higher order filter. Higher order filters in terms of 
inductors and capacitors are physically 
unrealizable, its mathematical analysis becomes 
complex and gain of the system decreases 
drastically. Sine wave inverter is widely used in 
many commercial and industrial applications 
including uninterruptible power supplies, induction 
heating, variable frequency drives, electrical 
vehicle drives and HVDC links. 
2. DESCRIPTION OF OUR 
PROPOSED DESIGN 
Proposed technique is unique of its type because it 
is implemented through a low cost RISC 
microcontroller ATMEGA48 [configuration at 
<http:// www.Atmel.Com>]. The operating speed 
supported by ATMEGA48 is 20 MHz clock inputs. 
The reference voltage of the ADC module is 5 V 
with the resolution of 10 bits. High frequency 
PWM can be generated using this controller. A 
filter is connected at the output stage of the inverter 
Page 622ISBN: 978-984-33-2140-4
  
to translate PWM to a sinusoid wave. The filter is 
designed in such a way that it removes harmonics. 
Voltage regulation is one of the important features 
of our inverter because we use PID control for 
regulating the output voltage. Our designed system 
parameters are given in Table 1: 
Table 1:  System Parameters 
Power rating 660VA 
Output voltage (regulated) 220 V 
Peak output current 3A 
Inverter switching frequency 
for square wave 
16 kHz 
Inverter switching frequency 
for sine wave 
3.9 kHz 
Maximum load (tested) 72 ohms 
 
3. BLOCK DIAGRAM AND 
OVERVIEW 
In the DC-DC converter section, a conventional 
configuration (Fig. 1), involving an input filter, a 
switching bridge, a ferrite core transformer, a 
bridge rectifier and an output filter, is used. The 
input dc, after passing through a low-pass filter is 
fed to the switching bridge circuit. The output of 
the switching bridge is an ac square wave of 12-
30V peak which is then supplied to the primary of 
the ferrite core transformer. The turn’s ratio of the 
transformer is so designed that the output peak 
voltage corresponding to 12V peak is 400V. To 
reduce the transformer size, the input dc voltage is 
first converted to high frequency square ac (16 
KHz) and is then stepped up with the help of ferrite 
core transformer. The secondary voltage of the 
transformer is rectified and filtered with the help of 
ABS (absolute) circuit. Thus, we get a variable DC 
voltage at the converter’s output. The variation of 
the output of the ABS circuit is due to the variation 
of input voltage source. The output of the DC-DC 
converter (output of the filter section) is fed to the 
PWM inverter section. Output of PWM inverter 
section passes through the LC passive filter 
resulting sinusoidal waveform, having very low 
distortion factor (DF). The filter is designed in such 
a manner so that it passes only the fundamental 
frequency, with very few harmonics and in the 
design it is also ensured that the phase shift 
between input and output of the filter at the 
fundamental frequency is negligible. 
4. TRANSFORMER DESIGN 
The ferrite core transformer used in the converter 
was designed, taking reference from [E. Lowdon 
1999]. Core size and required number of turns in 
primary and secondary winding are calculated as 
given below. The targeted efficiency of the 
transformer is 96%. 
5. CORE SIZE 
The power handling capacity of a transformer core 
is determined by its area product Wa, where W is 
the available core window area, and a is the 
effective core cross-sectional area. 
Wa = Pdc.108. ௌ
ସ௘஻௙௄
 
Where, Pdc is output power, S is current density, e 
is transformer efficiency, B is flux density, f is 
switching frequency and K is winding factor. For 
our core, Wa was calculated to be 80cm2. 
6.  NUMBER OF TURNS 
The number of turns is calculated using: 
୒
୚
 =   ଵ
ଶ଼.଺ସ୤ୟ୆×108 
Where, 
f = Frequency of operation of the transformer  
a = Core cross section area, 1.24in2 
B = Flux density in the core, 1Kgauss 
The maximum primary voltage in our case is 30V, 
which requires primary turns of 4.23. And we have 
taken 6 turns, considering some safety margins. 
Now, for obtaining a 240V AC using a minimum of 
12V DC, we need to provide at least 400V DC at 
the inverter bus. So, the required turns ratio is 
400/12 = 33.33. Hence, turns required in the 
secondary coil are 33.33×10 = 333.3. And 
considering some safety margin, we have used 335 
turns. 
7.  FILTER DESIGN FOR FULL WAVE  
RECTIFIER OUTPUT 
After the bridge rectifier a low-pass filter is used to 
produce a low ripple dc voltage. The frequency of 
the ac signal is 16 kHz. Hence, the output of the 
bridge rectifier will contain fundamental and the 
higher harmonics of 16 kHz. Thus a LC filter of 10 
kHz cut-off frequency would be enough. We chose  
C = 330µF and L = 2µH. 
Page 623
  
 
Fig. 1: Block diagram of complete system 
8. PWM SIGNAL GENERATION 
We compare a 50 Hz sine wave with a 3.9 KHz 
unity magnitude triangular carrier wave resulting a 
3.9 KHz PWM wave. 
 
Fig. 2: Comparing Sine wave with Triangular wave 
and PWM signal generation in Matlab 
The time period of output wave 2ߨ rad = 6.28 rad 
which contain 78 PWM pulses and per PWM pulse 
equal to 256µs. So total time of 78 PWM pulses 
equal to 0.02s which is expected 
 
 
 
 
 
 
 
 
 
 
 
 
 
9. GENERATION OF SQUARE WAVE 
 Fig. 3: Basic design of a Square wave inverter 
In this section high frequency around 16 KHz pulse 
is applied to the MOSFET gate which makes square 
wave. Since the switching frequency is high so the 
size of transformer is less. The program flow chart 
for getting PID control square wave is shown in 
Fig. 5. Hardware implementation of gate pulse 
signal is shown in Fig. 4, Fig. 7 and Fig. 9 and 
output is shown in Fig. 6, Fig. 8 and Fig. 10. 
 
Fig. 4: MOSFET gate pulse with 50% duty cycle 
for minimum load.      
Page 624
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 5: Program flow chart for square wave 
generation 
 
 
 
 
Fig. 6: Square wave output                                                   
 
Fig. 7: MOSFET gate pulse with 70% duty cycle 
for medium load.      
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 8: Square wave output                                                   
 
Fig. 9: MOSFET gate pulse with 90% duty cycle 
for maximum load.      
 
 
 
Fig. 10: Square wave output                                                   
Start
Set OC R1A  and 
OCR 1B pins
  in ou tpu t mode 
 in itialize  Tim er1 
eigh t b its fast 
PW M m ode
Tim er1
O verflow 
in terrup t
Clear O C1A on 
Com pare Match
Load OC R1A and 
OCR 1B w ith  50%
D uty cycle  va lue
Enable Tim er1  
overflow   inte rrupt
T CCR 1A XOR  0xA1
Flow chart for PID  contro l M O SFET gate pulse generation 
Enable G loba l  
inte rrupt
Loop
Count=0
Start T im er1  clock 
without p rescaling
R eturn Loop
Enab le  OCIE0ALoad OCR 0A=125Enab le  ADIE  bit
 in itialize  Tim er0
In  CTC  mode
In itia lize ADC
Start T im er0  clock 
with  presca ller 8
C TC m ode
Interrupt
error = se tpo int - actual position
dt = 1m s
Previous_ error = 0
in tegral = 0 
If error >0  or <0
in tegra l = in tegral + (e rro r*d t)
deriva tive  = (e rro r - p revious_error)/d t
output = (Kp*error) +  (K i*in tegral) + 
(Kd*derivative)
Load O CR1A and OC R1B with output 
va lue
Return Loop
Yes
No
previous_erro r = e rro r
A DC  
in terrup t
 sto re = ADC L
 actua l position  =
S tore (converted 
actua l va lue)
Return  Loop
Page 625
  
10. GENERATION OF 50 HZ SINE 
WAVE SIGNAL 
PWM signal from section 8 is now applied to the 
gate of MOSFET alternatively and resulting sine 
wave obtained in the Fig. 13 and Fig. 14 in proteus 
software and hardware implementation in Fig. 17 
and Fig. 18. 
Fig. 11: Basic design of a Sine wave inverter 
Fig. 12: Program flow for sine wave generation 
 
Fig. 13: PWM applied on two sides of bridge      
(Simulation in proteus) 
 
 
 
 
Fig. 14: SPWM at output of bridge (Simulation in 
proteus). 
 
 
 
Fig. 15: PWM signal in expanded form (Hardware 
implementation)            
 
 
 
Fig. 16: PWM signal for sine wave (Hardware 
implementation)            
 
 
 
Fig. 17: PWM Square wave output signal 
(Hardware implementation)            
 
 
 
Fig. 18: Sine wave output signal after filtering 
(Hardware implementation)            
Page 626
  
11. PID CONTROL 
 
Most important features of our sine wave inverter is 
PID control for getting stabilised output voltage. 
From Fig. 1 we see the feedback error voltage is 
properly processed by PID section which determine 
the appropriate duty cycle for the DC to Square 
wave converter section input pulse. As a result we 
minimize the output voltage variation due to instant 
loading effect on our inverter and quick recovery 
time which we observe in Fig. 19, Fig. 4, Fig. 7 and 
Fig. 9.   
Output voltage variation with PID 
Time in Millisecond
O
ut
pu
t v
ol
ta
ge
 in
 D
C
-D
C
 c
on
ve
rte
r s
ec
tio
n(
pu
)
Output voltage variation without PID 
Fig. 19: Output voltage variation control of DC-DC 
converter section with PID (Simulation in Matlab). 
 
12. CONCLUSION 
 
Simulation results and practical implementation of 
the sine wave inverter proves that output sine wave 
is voltage regulated, ripple less and stabilize output. 
For the use of this sine wave inverter in transformer 
less UPS, DC-DC step up converter can be used. 
Different electronic appliances are tested by this 
sine wave inverter. 
 
REFERENCES 
 
1. E.Koutroulis, J.Chatzakis, K.Kalaitzakis and 
N.C.Voulgaris, “A bidirectional, sinusoidal, 
high-frequency inverter design”, IEE Proc.-
Electr. Power Appl., Vol. 148,   No. 4, July 
2001, pp. 315-318 
  
2. YING-YU T., and SHIH-LIANG, J., “Full 
control of a PWM DCAC converter for AC 
voltage  regulation”, IEEE Trans. Aerosp. 
Electron. Syst., 1998, 34, (4), pp. 1218–1226 
 
 
3. E. Lowdon, “Practical Transformer Design 
Handbook”, Howard W. Sams & Co. 
Inc.U.S.A. 1999, 2nd edn. 
 
  
4.  Bonert, R. and Chen, J., "Load Independent 
DC/AC Power Supply for  Higher Frequencies 
with Sine wave Output", IEEE Transactions on 
Industry Applications, Vol. IA- 19, No. 2, 
March/Apri1,1983 pp. 223-227. 
 
5. S.R. Narayana Prakash, P.V. Ananda Mohan, 
B.S.R. Iyengar, “A new sinewave inverter with 
high frequency link and synchronous 
rectification using power MOSFETs”, IEEE 
Power Electronics                 Specialists Conf. 
San Antonio,Texas, U.S.A., June 11-14, 1990 
 
6.  I. Yamato et al., “New conversion system for 
UPS using high frequency link,” in Proc. IEEE 
Power Electronics Specialists Conf., 1988, 
pp.658–663. 
 
 
7. MATSUI, M., NAGAI, M., MOTCHIZUKI, 
M., and NABAE, A. “Highfrequency  link 
DC/AC converter      with suppressed voltage 
clamp circuits– naturally  commutated phase 
angle control with self turn-off  devices”,IEEE 
Trans. Ind. ppl., 1996, 32, (2), pp. 293–300. 
 
8. RASHID, M.M.: “Power electronics: Circuits, 
devices and applications”, Prentice-Hall, 1993, 
2nd edn. 
 
9.  <http:// www.Alldatashit.Com> 
 
10.  < http:// www.Atmel.Com> 
 
 
 
 
 
 
 
 
 
 
Page 627
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Muhibul Haque Bhuyan,  
E-mail: muhibulhb@gmail.com 
LINEARIZATION OF VOLTAGE-CONTROLLED OSCILLATOR BY 
MICROCONTROLLER BASED PLL FREQUENCY SYNTHESIZER 
 
 
Md. Lutfor Rahman and Muhibul Haque Bhuyan* 
Department of Electrical and Electronic Engineering 
Daffodil International University, Dhaka, Bangladesh 
E-mail: rahmanlutfor20@yahoo.com, muhibulhb@gmail.com 
 
 
Abstract 
Today’s mobile communications systems demand higher communication quality, higher data rates, higher 
frequency of operation, more channels per unit bandwidth, low power consumption and smaller size. One 
important part of the communication systems design is the synthesized oscillator. Typical synthesized 
oscillators combine a Voltage Controlled Oscillator (VCO) with a Phase-Locked Loop (PLL) IC, frequency 
reference (e.g. Crystal/TCXO) and a loop filter. This paper describes the evaluation of the PLL and VCO 
and relates those evaluations to information that will allow the circuit designer to optimize the whole 
oscillator design including the loop filter. Few experimental results are also presented. It is found that the 
designed circuit works very well. After the synthesizer has been designed and built, the synthesizer is locked 
very sharp and correctly in time. The spectrum contains many spurious frequencies. The loop bandwidth is 
higher as expected. The phase noise is lower than expected. So, noise of the synthesizer keeps them as small 
as possible. In the PLL system to change the receiving frequency from 38.445 MHz to 38.429 MHz and now 
we have perfect reception. 
 
Key words: PLL, VCO, synthesizer, linearization, microcontroller 
 
1. INTRODUCTION 
 
Phase-locked loops (PLLs) are widely used in 
frequency synthesizers for wireless communication 
systems [1]. A PLL based on a charge-pump is 
preferred over other types because it has a wide 
capture range and zero static phase offset. In 
practice, non idealities of the charge-pump degrade 
the performance of the entire loop. One of the non 
idealities of the charge-pump is the current 
mismatch. The mismatch between the charging 
current and the discharging current causes a phase 
offset and reference spurs in PLL [2]. Frequency 
synthesizers form the basis of most radio system 
designs. The critical part of the communication 
system design is the synthesized oscillator, where 
the Voltage Controlled Oscillator (VCO) is used to 
generate the Radio Frequency (RF) output 
frequency. The Phase Locked Loop (PLL), which is 
analog type, i.e. different from a pure digital PLL, is 
used to stabilize and control the frequency. In fact, 
RF amplifiers used in communication systems 
should be highly linear [3]. The phase locked loop 
(PLL) method of frequency synthesis is now the 
most commonly used method of producing high 
frequency oscillations in modern communications 
equipment to achieve stability and linearity [4]. PLL 
circuits are now frequently being used to 
demodulate Frequency Modulated (FM) signals, 
making obsolete the Foster-Seerly and ratio 
detectors of early years. Other applications for PLL 
circuits include Amplitude Modulated or AM signal 
demodulators, FSD decoders, two-tone decoders and 
motor speed controls. While designing the VCO 
PLL circuits, various design parameters should be 
optimized to obtain linearity [5]. In this paper, we 
have described how linearization of voltage-
controlled oscillator circuit is achieved by using a 
microcontroller based PLL frequency synthesizer. 
The experimental results are shown in the 
oscillograms. Then the output voltage versus 
frequency curve is plotted to show the linearity of 
the circuit. Future scopes of this work have also 
been suggested. 
 
2. PLL FREQUENCY SYNTHESIZER 
 
Basic block diagram of PLL frequency synthesizer 
is shown in Fig. 1. A synthesizer is a device which 
takes an input, or source frequency and from it 
produces an output frequency. The direct 
synthesizer produces an output which is directly 
Page 628ISBN: 978-984-33-2140-4
  
proportional to the input, i.e. input and output 
frequencies are related by a multiplication factor N 
as given in equation (1). 
( )                            1out inf Nf=  
 
 
Fig. 1 Basic block diagram of PLL frequency 
synthesizer 
 
Figure 2 shows the basic block diagram of a phase 
locked loop. The VCO is “locked” to the reference 
frequency, fref, by dividing it by some integer R, the 
VCO output, fout, by some integer N, and then 
comparing the phase of the two signals, generating 
an error signal. This error signal is then amplified 
and filtered to remove phase comparison frequency 
components and modify the phase response of the 
loop to provide closed loop stability. It is always 
the case that the reference is a higher quality 
frequency source than the VCO. The output 
frequency is then given by equation (2). 
( )                              2out ref
Nf f
R
=  
 
 
Fig. 2 Basic diagram of a phase locked loop 
 
The output of a VCO and crystal oscillator can be 
fed into a phase detector. The phase detector (PD) 
compares the phase of the input signal and the 
divided output signal. The PD generates different 
output depending on the type of phase error (lead, 
lag or none). The type of the detector used in this 
work produces outputs of two square wave signals 
(one for positive phase error and one for negative) 
whose pulse-width depend on the size of the phase 
error. In a loop where the input frequency exceeds 
either the maximum RF or reference input 
frequency of a synthesizer it may be necessary to 
use a fixed divide by M prior to the ÷N or ÷R 
functions. M has been used to highlight the 
difference between M and N. N will be referred to 
as the division performed by the synthesizer IC 
used to form the basis of the PLL. The value of M 
will however limit the step size the synthesizer may 
perform as the output frequency will now be, 
assuming the M division is prior to the ÷N. 
( )                              3out ref
MNf f
R
=  
This results in a minimum step size of M*fcomp. 
 
3. DESIGN METHODS 
 
The basic specifications for a frequency synthesizer 
are given in Table 1. 
 
Table 1 Specification of frequency synthesizer 
Specification Requirement 
Frequency tuning 
range 
2.33 GHz  50 MHz 
Step size 500 KHz 
Phase error 
contribution 
<= 3 rms 
Lock time 400 µs for a ±20 MHz step to 
200 Hz of final frequency 
Charge pump 
current (Icp) 
5 mA 
Kvco 45 MHz/V 
Division range (N) 4560 to 4760 
Reference 
frequency (fref) 
10 MHz 
Phase margin 45
0
 
 
From these few parameters, we first need to 
estimate the loop bandwidth of the synthesizer. 
Two “rules of thumb” [6], which may help to 
approximate the frequency of the loop bandwidth, 
are given in equations (3) and (4). 
( )
( )
 
50
Switching time =                          3
2.5
Switching time =                      4
comparison
keep bandwidth
f
f
 
 
4. HARDWARE IMPLEMENTATION 
 
The receivers we have built around the TV tuner 
trainer of model ETT101. The basic block of this 
TV tuner receiver is shown in Fig. 3. The signal 
into the antenna comes to the TV tuner. A TV tuner 
is actually just a down converter for RF signals. It 
can be programmed to any frequency from 46 to 
860 MHz and it down convert the RF signal to an 
IF signal which should be about 33-39 MHz. The 
signal then leaves the TV tuner and enters a SAW 
filter. This is a sharp filter that rejects all 
frequencies except 33-39 MHz. As you understand 
the SAW filter is wide because a TV signal is about 
6 MHz wide. We will still use this filter since we 
can't find any narrow filter for this frequency and it 
works good. After the filter, there is a FM receiver 
with excellent performance. It is a FM receiver and 
Page 629
  
it is tuned to the IF frequency and demodulates the 
IF signal to an audio signal. Under the FM receiver 
there is a PLL synthesizer. The TV tuner will set 
the large step of tuning and the PLL synthesizer of 
the FM receiver will set the fine tuning.  
 
 
Fig. 3 Block of TV Tuner 
 
The receiver unit also needs power supplies of DC 
+5 V, +12 V and +33 V to work. The +33 V is the 
tuning voltage and draw very little current so any 
small step up converter will work. We try to make 
the ripple as low as possible in the step up 
converter to get better performance. The tuner also 
needs some kind of antenna to work. Most tuners 
use 75 W impedance wires and dipole antenna. 
Figure 4 shows the connection diagram at the 
bottom of the trainer board that has been interfaced 
with the TV tuner, FM receiver as well as 
microcontroller IC. 
 
 
Fig. 4 Connection diagram of the trainer board 
 
 
Fig. 5 Circuit interfaced with the trainer board 
 
Fig. 5 shows the interfacing circuit diagram 
designed in this work. Our designed circuit using 
the microcontroller has been interfaced with the TV 
tuner and FM receiver unit through the output ports 
of the microcontroller. We have interfaced with the 
PLL synthesizer so that the faults in the receiver 
can be identified and remedial measures can be 
taken. Mainly two different ICs LMX2306 and 
SA615 have been connected to the ports of the 
microcontroller IC PIC16F870. A separate power 
supply circuit has also been designed using IC 7805 
to get the +5V DC for the different ICs of the 
designed circuit. 
 
5. RESULTS AND DISCUSSIONS 
 
After the hardware implementation, we need to take 
some experimental data to verify our work. We 
received data at 86.555 MHz of frequency. For this 
purpose, we used a circuit that has the block 
diagram as shown in Fig. 6. 
 
 
Fig. 6 Block diagram of the data collection circuit 
 
One example shows below how the PLL corrects 
the tuner’s frequency. 
RF TV tuner = VCO TV tuner - RF FM receiver  
VCO TV tuner = RF TV tuner + RF FM receiver  
and number of tuner steps are: VCO TV tuner/ 
62500 = number of steps required. 
So, if RF TV tuner frequency is 86.555 MHz, that 
of RF FM receiver is 38.445 MHz, then the VCO 
TV tuner frequency is 86.555 + 38.445 = 125 MHz. 
That means we need 125e6/62500 = 2000 steps 
exactly. Now, if the frequency is changed to 86.580 
MHz, then the RF TV tuner frequency is 86.580 
MHz and that of RF FM receiver is 38.445 MHz 
then the VCO TV tuner frequency is 86.580 + 
38.445 = 125.025 MHz. That means, we need 
125.025e6/62500 = 2000.4 steps. 
Since the tuner only can’t jump in decimal steps, 
the tuner will not reach this frequency. If we still 
set the TV tuner step to 2000, the VCO TV tuner 
will be 2000´62500 = 125 MHz.  Since we wanted 
the RF TV tuner to be = 86.58 MHz, the RF FM 
receiver must be 125 - 86.580 = 38.420 MHz. 
As we see the frequency is 38.429 MHz (-25000 
Hz) from the 38.445 MHz. To correct this deviation 
we use the PLL system to change the receiving 
frequency from 38.445 MHz to 38.429 MHz and 
now we have perfect reception. 
Page 630
  
Various experiments have been performed and 
results have been observed for the tested PLL 
frequency synthesizer. Of them, few oscillograms 
have been provided here from Figs. 7-8 taken at 
various test points. The output of the oscillator is at 
the test point 1 at which the frequency is 1000 Hz 
as shown in Fig. 7. It is set by changing the variable 
resistor. The output of the oscillator is connected to 
the clock input of the D-type flip-flop. It divides 
this frequency by a factor of 2. This is observed at 
test point 2 as shown in Fig. 8. The output of the D-
type flip-flop is connected to the channel A input of 
the PLL whose output is at test point 3 and it is 
1500 Hz but is not shown here for brevity. 
 
 
Fig. 7 Waveform at test point 1 (f = 1000 Hz) 
. 
 
Fig. 8 Waveform at test point 2 (f = 500 Hz) 
 
 
Fig. 9 Frequency vs. voltage characteristics curve 
 
The hardware is connected to the PC through its 
COM1 port. Using the software all the data is 
transferred from the hardware through this port to 
the PC by scanning VCO voltage and frequency. 
From the measured data, it is seen that as the 
voltage to the PLL goes from 0 V to 5.0 V, the 
VCO frequency goes from 800 MHz to 1050 MHz. 
The plot is shown in Fig. 9. From the plot it is seen 
that the curve is very much linear. 
 
7. CONCLUSIONS 
 
The purpose of this work is to develop and test a 
method of correcting variations in the tuning 
sensitivity of voltage-controlled crystal-oscillators 
in the phase-locked loops. A method has been 
developed to amplify or attenuate the control 
voltage of the VCXO in order to make the tuning 
curve linear. Extra circuits and a microcontroller 
are added to the loop for measuring the tuning 
sensitivity of the VCXO and to compensate for the 
deviation. After the synthesizer has been designed 
and built, the synthesizer is locked very sharply and 
correctly.  The synthesizer locks in time. In the PLL 
system, if we change the receiving frequency from 
38.445 MHz to 38.429 MHz. Experimental results 
show that the system is working very well. 
Microprocessor or digital signal processors (DSP) 
can be employed with this scheme for faster 
calculation of the frequency or re-tune the VCO. 
 
REFERENCES 
 
1. M. Mansuri, D. Liu, and C. K. Yang, “Fast 
Frequency Acquisition Phase-Frequency 
Detectors for Gsamples/s Phase-Locked 
Loops”, IEEE Journal of Solid-State Circuits, 
vol. 37, pp. 1331-1334, Oct. 2002.  
2. S. Cheng, H. Tong, J. Silva-Martinez, and A. I. 
Karsilayan, “Design and Analysis of an 
Ultrahigh-Speed Glitch-Free Fully Differential 
Charge Pump With Minimum Output Current 
Variation and Accurate Matching”, IEEE 
Transactions on Circuits and Systems, part II, 
vol. 53, pp. 843-847, Sept. 2006. 
3. S. Ganesan, E. Sánchez-Sinencio and J. Silva-
Martinez, “A Highly Linear Low Noise 
Amplifier,” IEEE Transactions on Microwave 
Theory and Techniques, vol. 54, pp. 4079 – 
4085, Dec. 2006. 
4. J. R. Smith, “Modern Communication 
Circuits,” 2nd Edition, McGraw Hill, NY, USA, 
1998, pp. 436-442. 
5. Lutfor Rahman and Muhibul Haque Bhuyan, 
“Design and Optimization of VCO PLL 
Frequency Synthesizer,” Proceedings of the 
National Conference on Electronics and 
Telecommunications for Digital Bangladesh, 
Bangladesh Electronics Society, Dhaka, 
Bangladesh, 2-3 June 2010, pp. 227-232. 
6. Distefano, J. et. al. “Theory and Problems of 
Feedback and Control Systems”, 1990, ISBN 
0-07-017047-9. 
Page 631
Proceedings of the 
International Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
2
 Corresponding Author: M.S.R. Shoaib, 
E-mail: shoaibeee@gmail.com 
MAGIC IN VLSI 
A Precise Demonstration on MAGIC towards VLSI Layout Designing 
 
 
Imran Chowdhury1, Rumana Amin1, Sazzad Bin Kamal1, M.S.R. Shoaib1, 2, 3, Dr. 
Shuza Binzaid4 
1School of Computer Science and Engineering 
1University of Information Technology & Sciences (UITS), Dhaka, Bangladesh 
2Bangladesh University of Engineering and Technology (BUET), Dhaka 
3Bioelectric Research Lab, Dhaka, Bangladesh 
4Founder and Director, SERES, seres-usa.com 
 
Development of VLSI is a unique era in microelectronics, more precisely in integrated circuit industry. VLSI 
is the field which involves packing more and more logic devices into smaller areas combining thousands or 
many more than that of transistors into a single chip. But the design of very large scale integrated circuit is 
far beyond human ability. Therefore, Computer Aided Design (CAD) tools are heavily involved in the 
design process. This is highly expensive and technological at the same time. Unfortunately 3rd world 
countries are lagging far behind in this arena. This study represents a brief demonstration on one of the VLSI 
designing CAD tools known as MAGIC. The study includes a brief and precise direction from the software 
installation to the way of IC fabrication with a design of CMOS inverter and its simulation as example. It 
also includes why MAGIC should be the choice in academic purpose as well as industrial especially in 3rd 
world countries, along with its limitations and superiority. 
 
Key words: VLSI; Magic; CAD Tools; Designing CAD tools; Manhattan design; Cygwin/X; Tcl/Tk  
 
1. INTRODUCTION 
 
According to the low of Gordon Moore (1960), the 
number of transistors that can be placed on an 
integrated circuit would be approximately double 
every two years [1]. This number has grown non-
linearly to a dramatically high value, which is about 
two billion on a quad-core Itanium designed by 
Intel in 2009 [2]. Still the number is significantly 
increasing, and the growing sophistication of 
applications continually adding new levels of 
complexity [1]. So it is needed to use CAD tools 
that can do minimize the complexity and help to 
improve the VLSI design. What CAD does is 
mainly automates the design process making it 
much easier. CADs are categorized on the basis of 
works they handle like Design Entry tool, Analysis 
and Verification tools, Synthesis tools and so on 
[1]. In this paper MAGIC is demonstrated, which is 
a designing CAD tool for VLSI. 
 
Magic is an interactive tool for creating and 
modifying 2-D VLSI circuit layout. It is written by 
John Ousterhout and his graduate students at UC 
Berkeley in 1980’s, and is widely known as the 
earliest tool used for circuit layout [7]. It allows the 
designer to place colored polygons that represent 
physical layers that form the complex circuitry on a 
chip [12]. MAGIC permits only Manhattan designs 
(those whose edges are vertical or horizontal), i.e. 
design strictly by rectangle shapes [5]. 
 
2. INSTALLATION 
 
Most VLSI CAD tools are based on UNIX or Linux 
platforms [3]. Typically, MAGIC also runs under 
Linux or UNIX. But most of the PC users use MS 
Windows platform [8]. In order to use MAGIC 
under Microsoft Windows, it needs some 
intermediate applications [3, 9], those take a bit 
difficulty. First of all it is needed to install Cygwin 
(an implementation of RedHat Linux) which is a set 
of powerful tools to assist developers in migrating 
applications from UNIX/Linux to the Microsoft 
Windows platform [10]. Cygwin is a free open 
source software. Other needed applications are 
X11, and Tcl/Tk (together of Tcl & Tk). X11 is one 
of the packages of Cygwin that makes an 
environment to open window(s) of the desired 
application on Windows platform [9]. Tcl (Tool 
Command Language) is a very powerful dynamic 
scripting language, and Tk (Toolkit) is a graphical 
Page 632ISBN: 978-984-33-2140-4
  
user interface toolkit [11]. In this study the test is 
done in Windows 7 Ultimate and Windows XP SP2 
using Cygwin/X (together of Cygwin & X11) 
v1.7.7-1, Tcl/Tk 8.5.0, and Magic 7.5.107v. 
 
2.1 Portability 
After completing all installations the directory 
“C:\Cygwin” (root directory for MAGIC defined by 
the MAGIC writer) is all that is needed. It can be 
transferred to another PC for using MAGIC there. 
To do that, Cygwin directory is transferred to just 
“C:\” of another PC so that the path of root 
directory remains as previous (C:\Cygwin). The 
directory can be compressed by making it a zip file 
for easier transfer. After transferring the Cygwin 
directory a shortcut of “C:\Cygwin\Cygwing.bat” is 
made in the new PC to its desktop. Icon path of the 
desktop shortcut is changed to 
“C:\Cygwin\Cygwin.ico”. Now all is set and Magic 
can run as on previous PC. 
 
2.2 Running Magic 
To run, Magic it is needed to run X-server first 
(which is come after installing X11). To do that 
Cygwin command window is opened form desktop. 
To open X-server with multiwindow and nolock 
features, “XWin –multiwindow –nolock” is entered 
in the command prompt. An X icon is supposed to 
appear on the task bar. Then the command window 
is to be opened again (after closing or minimizing 
it). Finally just “magic” (to open Magic) is typed. 
Two windows are supposed to appear; one is for 
command and another is for layout (in figure 1). 
Then Cygwin command window is kept minimized 
because closing this window will close the 
windows of Magic. 
 
 
 
Fig 1: MAGIC windows on Windows 7. 
 
3. DESIGNING BY MAGIC 
 
During layout designing in MAGIC, maintaining 
the design rules are fairly easy with the use of 
“grid” which is the unit of lambda (λ) that makes it 
possible to design towards the scalable technology. 
Table 1, 2, 3, and 4 represent a description of some 
useful commands for layout and post-fabrication 
verifications. 
 
To start designing it is also important to know 
about Graphics Tools. Among 4 types of graphics 
tools in MAGIC (BOX tool, WIRING tool, 
NETLIST tool, and RSIM tool) BOX tool is used 
most often (default in MAGIC), which is sufficient 
for basic designing [6]. The purpose of the BOX 
tool is to specify a rectangular area of the layout for 
editing. The left and right mouse buttons are used 
to position the box. Graphics tools can be changed 
by pressing the spacebar with mouse pointing into 
the layout window. Selected tool is used to show on 
the status bar in MAGIC (in figure 2). 
 
 
 
Fig 2: BOX tool selected in MAGIC 7.5 
 
3.1 Command Sets 
Commands can be invoked in MAGIC in 4 ways: 
by (I) typing long commands on the keyboard, (II) 
typing single-character macros on the keyboard, 
(III) pressing icons on toolbar in MAGIC and (IV) 
pressing mouse buttons on the existing layout 
paintings in the same window. All commands will 
be invoked as long as the cursor is in the MAGIC 
layout window creating or selecting a box to edit. 
 
Long commands are preceded by a semicolon ";" or 
colon ":", but it is not must. Commands can be 
abbreviated [4]. Macros are used to be a single 
lower case or upper case key stoke from keyboard. 
Commands are case sensitive. Table 1, 2, 3, and 4 
represent some commands with their descriptions. 
 
Table 1: Some useful commands 
 
Command Macro Description 
grid g Switches grid view 
on or off. 
zoom value  Zooms in or out by a factor. 
zoom 0.5 z Zooms out by factor 2. 
zoom 2 Z Zooms in by factor 2. 
view v 
Shows the whole 
drawing fit to 
window. 
help command  Gives a brief of 
specified command. 
help  Gives a brief of all 
commands. 
Page 633
  
macro  
Displays all current 
Macros. 
save name  
Saves the design with 
given name and 
“.mag” extension. 
save  
Saves all the 
changes. 
load name.mag  
Loads name.mag into 
the window. If it is 
doesn’t exist, Magic 
creates a new empty 
layout field. 
quit  Exits Magic. 
 
"Paint" can be abbreviated to "pai". To select the 
entire area lies within the whole drawing "a" is 
pressed after "s". Label name can be anything but in 
practice it is necessary to label the supply wires 
(nodes) as Vdd! and GND! exactly (the ! means 
that the node spans the entire drawing by 
electrically connecting, and it is global) [6]. 
 
Table 2: Basic painting commands 
 
Command Mac Description 
paint layer  Paints the defined layer 
select s 
Selects area of cell in 
current layout. Toggles 
cells if there are more than 
one connected. 
select more S 
Creates and selects new 
topmost cell on the 
existing layout. 
select area a Selects entire area of 
selection. 
what  Tells what’s selected. 
erase layer  Erases paint underneath the box. 
delete d Deletes everything that’s 
selected by "a". 
undo u Rolls back to previous 
status. 
redo U Get back to current status. 
label name  
Creates label for 
extraction and simulation 
purpose usually. 
erase label  Erases the label from topmost cell of the box. 
erase labels  Erases all labels that lie 
within the area of the box. 
 
Table 3: Some basic common layers’ name 
 
Layer Abbr Mac Description 
nwell nw  pMOS substrate. 
pwell pw  nMOS substrate. 
ndiffusion ndiff F1 n
+
 source/drain 
areas. green gr 
pdiffusion pdiff F2 p
+
 source/drain 
areas. brown brf 
polysilicon poly 
F3 
Gate oxide; slice of 
polysilicon and 
silicide. red p 
metal1 
m1 F5 1st layer metal. blue 
metal2 
m2 F6 2nd layer metal. purple 
metal3 m3 F7 3rd layer metal. 
nwcontact nnc  m1 to nwell 
contact (tie). 
pwcontact ppc  m1 to nwell 
contact (tie). 
ndcontact ndc F9 m1 to ndiff 
contact. 
pdcontact pdc F10 m1 to pdiff 
contact. 
polycontact pc F11 m1 to poly contact. 
m2contact via F12 m2 to m1 contact. 
m3contact via2  m3 to m2 contact. 
ntransistor nfet  Direct nMOS. 
ptransistor pfet  Direct pMOS. 
 
Layers’ name come with command "paint" to draw 
out or "erase" to erase out, like "paint ndiffusion" or 
"pai ndiff". In case of simple design "nwell" and 
"pwell" usually are not used in drawing, because 
those are used to be automatically created when 
".mag" file is converted into ".cif" file in MAGIC. 
 
Table 4: Movement commands 
 
Command Description 
move direction Moves to defined direction by 1λ. 
move direction value 
Moves to the defined 
direction by given values 
of λ. 
move up 10 Upward moving by 10λ. 
stretch direction "stretch" is similar to 
"move" except that it 
stretches and erases as it 
moves. 
stretch direction 
value 
stretch up 10 
copy direction "copy" is similar to 
"move" except that a copy 
of the selection is left 
behind at the original 
position. 
copy direction value 
copy up 10 
upsidedown Flips selection upside down. 
sideways Flips selection sideways. 
clockwise Rotates selection 
clockwise by 90° 
clockwise degrees 
Rotates the selection 
clockwise by multiple of 
90°. 
Page 634
  
rotate Rotates the selection 
counter clockwise by 90°. 
rotate degrees 
Rotates the selection 
counter clockwise by 
multiple of 90°. 
array Xvalue Yvalue Makes matrix of selection 
of x*y. 
array 9 9 Makes matrix of selection 
of 9*9. 
 
The directions of move, stretch, and copy will be 
up, down, left, and right only, and 8, 2, 4, 6 are the 
macros of stretch for the directions respectively. 
Macros "f" and "r" are used respectively instead of 
"sideways" and "clockwise". 
 
To invoke command from toolbar, it is needed to 
open the "Toolbar" from "Option" menu in the 
layout window, then press the middle button (left 
and right button at a time for two button mouse) of 
mouse on toolbar icon after creating a box (in 
figure 3). 
 
 
 
Fig 3: MAGIC’s windows with toolbar (inside red 
rectangle) on Windows 7 
 
To invoke command from existing painting the 
middle button (left and right button at a time for 
two button mouse) of mouse is to be pressed on any 
painting in the layout that is to be painted in the 
box. 
 
 3.2 Starting Designing 
According to top-down design abstraction of digital 
VLSI system, starting the implementation of a chip 
layout on MAGIC takes a necessity of schematic 
circuit model [1]. Figure 4 shows the schematic 
(left) and layout of a CMOS inverter in MAGIC 
(right), which makes more sense of this design 
demonstration. Before starting with the layout a 
VLSI designer should know the basics of MAGIC 
and starts from the technology file. 
 
 
Fig 4: Schematic diagram of a CMOS inverter in 
PSpice 9.1 Student Version (at left), and 
corresponding layout in MAGIC 7.5 (at right) 
The technology of VLSI depends mainly on the 
length of transistor channel, because it is the key to 
optimize speed of an entire chip. Technology is the 
process of silicon that is standardized by fabrication 
facilities. The process composition is accepted by 
design houses to use their electrical parameters. 
The technology file consists of minimum 
dimension of devices allowed by process, electrical 
characteristics and on-silicon-spacing layout design 
rules.  The modern digital VLSI is preferred as 
SCMOS (Scalable CMOS) technology because of 
less power consumption and also cost of producing 
it. MAGIC uses a lambda (λ) based architecture of 
scalable layout designing system. Lambda is the 
unit scale that is used to define the minimum 
technology geometry increment on the die (a piece 
of wafer), the processed silicon of the design layout 
[6]. A square of the grids in MAGIC’s layout 
window is one unit for lambda. The term “scalable” 
means that designed layout can be modified with 
the change of technology that is changing the value 
of lambda (λ). Default value of lambda in MAGIC 
is 1.0µm for SUPERTEX 2 [6]. 
 
3.3 Design Rule Checking 
Design rules specify how far apart various layers 
must be, or how large various aspects of the layout 
must be for successful fabrication. MOSIS SCMOS 
Design Rules specify the complete set of design 
rules defined by the MOSIS VLSI fabrication 
service [6]. Design Rule Checking is performed 
automatically in MAGIC as long as DRC is 
checked on status bar in layout window (inside 
green oval in figure 3). When error occurs, MAGIC 
informs immediately by splattering small white 
dots around the area of concern. The command "drc 
why" or macro "?" tells the occurred error in 
selection. Design Rule Checking can be off by 
Page 635
  
command "drc off" or un-checking DRC, and on by 
command "drc on" or checking DRC. 
 
In figure 4, "ndiff", "pdiff", "poly", "pc", "ndc", 
"pdc", and "m1" layers are used to create an 
inverter layout with their minimum width (3, 3, 2, 
4, 4, 4, and 3λ respectively) keeping the minimum 
distances between all of them with default 
SUPERTEX 2.0µm process. The layout is saved as 
"inverter" that creates "inverter.mag". 
 
3.4 Simulation and Fabrication 
After a circuit layout is drawn, it is needed to test 
its performance by simulating it. To do that layout 
has to be extracted to generate simulation 
information needed to run simulation tools such as 
Spice or IRSIM. The command "extract" or "ext" 
generates separate ".ext" (inverter.ext in this case) 
file for ".mag" file. If the layout includes subcells 
then all subcells can be extracted by "extract all". 
The "extract cellname" extracts a specified cell. The 
extraction file of the designed inverter contains 
information like below: 
 
timestamp 1290837166 
version 7.5 
tech scmos 
style lambda=1.0(scna20_orb) 
scale 1000 1 100 
resistclasses 26670 59550 23860 19690 27260 2000000 49 26 
2505830 
node "0" 44 423 2 -7 ndc 19 18 0 0 0 0 0 0 0 0 0 0 25 22 0 0 0 0 
node "1" 72 423 -14 -7 pdc 0 0 30 22 0 0 0 0 0 0 0 0 33 26 0 0 0 
0 
node "3" 272 5770 -16 -2 p 0 0 0 0 54 54 0 0 0 0 0 0 34 28 0 0 0 
0 
node "2" 116 1880 -14 0 pdiff 19 18 30 22 0 0 0 0 0 0 0 0 80 54 
0 0 0 0 
device mosfet nfet 2 -2 3 -1 2 3 "Gnd!" "3" 4 0 "0" 3 0 "2" 3 0 
device mosfet pfet -14 -2 -13 -1 2 6 "Vdd!" "3" 4 0 "1" 6 0 "2" 6 
0  
 
Then "exttospice inverter.ext" generates 
"inverter.spice" file for simulation using PSpice.  
The conversion to PSpice from the “.ext” file is 
given below: 
 
* SPICE3 file created from inverter.ext - technology: scmos 
M1000 2 3 1 Vdd pfet w=6u l=2u  
+ ad=30p pd=22u as=30p ps=22u  
M1001 2 3 0 Gnd nfet w=3u l=2u 
+ ad=19p pd=18u as=19p ps=18u  
C0 3 gnd! 5.8fF 
 
Latter the input signal is added to the PSpice file. 
Commands scripts to file for plotting and transient 
analysis are added to the file. Simulation plot is 
shown in figure 5.  
 
 
 
Fig 5: Simulation result of designed inverter in 
PSpice 9.1 Student Version with 5 volt power 
supply and input (at upper) with the corresponding 
output (at lower). 
 
Fabrication is the physical implementation of chip 
according to designed layout. The most familiar 
VLSI fabrication service is MOSIS (Metal-Oxide 
Semiconductor Interface Service), which supports 
MAGIC. For fabrication ".mag" file has to be 
converted into CIF (Caltech Intermediate Form) file 
which is to be sent to the fabrication service to 
manufacture. The command "cif" generates 
separate ".cif" (inverter.cif in this case) file for 
".mag" file with the default style of lambda. To 
change the style of lambda for a different process 
"cif istyle lambda=0.6(gen)" and "cif ostyle 
lambda=0.6(gen)" commands have to be invoked 
before "cif" in case of 1.2µm process for example. 
To open the generated CIF file command "cif read 
inverter.cif" is to be invoked after "cif istyle 
lambda=0.6(gen)" (this command is not needed if 
the default style is not being changed). Then to see 
the layout "s" > "a" > "x" (x to expand) macros are 
to be invoked with mouse pointing into the layout 
window.  
 
4. JUSTIFICATION OF MAGIC 
 
After all this demonstration above it is clearly seen 
that MAGIC is very easy to use and understand. 
Though the installation process is a little bit 
difficult, but once it is installed the portability 
makes it much flexible for further use. One of the 
significant features of MAGIC is that its design 
style is based on Mead-Conway "scalable CMOS" 
which means it uses "lambda-based" dimensions 
which makes it easier to write technology file for 
different manufactures. The most advanced feature 
of MAGIC is its liberal Berkeley open-source 
license [3]. MAGIC is not only a color painting tool 
for layout but also it can provide additional 
operations including Built-in Design-Rule-Check 
(DRC), Built-in Hierarchical circuit extractor and 
some other useful functions such as plowing tools 
and routing tools for stretching and interconnecting 
Page 636
  
circuits respectively [3], those are not concerned 
here because of keeping simplicity. 
 
Most VLSI layout designing software cost about 
$10,000 (a simple student version of "Cadence" 
costs about $25,000), which is unaffordable for a 
university or small industry of 3rd world countries. 
Stolen softwares are incomplete and prevent from 
any updates for any latest technology. So, the cost 
free legal license of MAGIC is the main advantage 
in this case. 
 
5. CONCLUSION 
 
It is proposed that this study represents basic and 
most precise demonstration of MAGIC from its 
installation to fabrication of designed layout which 
can be a perfect entrance to the world of VLSI 
designing for the VLSI students or beginners of 
VLSI design. Because it is not possible to develop 
electronics sectors tremendously without VLSI, and 
with an artistic and creative sense MAGIC could be 
the platform that can make someone a successful 
VLSI designer. Very important aspects of MAGIC 
design i.e. lambda, DRC and extraction tools are 
described here. An inverter was demonstrated and 
simulated to confirm its operations.  All necessary 
commands used in MAGIC software are presented 
here. Further study may be focused on full 
functional low power custom chip design using 
MAGIC, and advance demonstration of MAGIC. 
 
REFERENCES 
 
1. Wane Wolf, Modern VLSI Design, System-on-
chip Design, 3rd edition, pp. 2, 7, 27-29. 
2. Intel Corporation, (2010) The Intel® Itanium 
Processor 9300 Series: A Technical Overview 
for IT Decision-Makers, White Paper, February 
3. L. Jin, C. Liu and M. Anan, Dept. of Electrical 
and Computer Engineering, Purdue University 
Calumet, Hammond USA. Open-Source VLSI 
CAD Tools: A Comparative Study. 
4. Mayo, R. N., Arnold M. H., W.S. Scott, D. and 
Hamachi G.T., (and J. Ousterhout) Reduced 
Magic Tutorial from “WRL Research Report 
DECWRL/ Livermore Magic Release”. 
5. John Ousterhout, Magic Tutorial #1: Getting 
Started, Computer Science Division, Electrical 
Engineering and Computer Sciences, 
University of California, Berkeley, CA 94720. 
6. Jeffrey Wilinski. An Introduction to the 
MAGIC VLSI Design Layout System. 
7. Magic VLSI resource. 29 Aug 2010. 
http://www.opencircuitdesign.com/magic/ 
8. OS platform statistics from w3schools. 
http://www.w3schools.com/browsers/browsers
_os.asp. 29 August 2010. 
9. Magic VLSI Resource (2001),http://opencircuit 
design.com/cygwin/. 5 Septmber  
10. Product view from RedHat.com, 2 September 
2010,http://www.redhat.com/services/custom 
cygwin/ 
11. Tcl Developer Exchange. http://www.tcl.tk/. 3 
Septeber 2010 Center of Neutron Research, 
http://www.ncnr.nist.gov/xtal/software/tclpkgs.
html. 
12. Anil Bahuman, khaled Rasheed, Benjamin 
Bishop. An Evolutionary Approch for VLSI 
Standerd Cell Design. IEEE 2002. 
13. Ousterhout, J., Hamachi, G., Mayo, R., Scott, 
W. and Taylor, G., (1984), Magic: A VLSI 
Layout System, Proc. of 21st Design 
Automation Conference, pp. 152-159. 
Page 637
Proceedings of the 
International Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
 
 
2 
Corresponding Author: Shakil Seeraji, 
E-mail: shakil_2010@yahoo.com 
  
 
Microcontroller Based Automatic liquid Level Control Modeling       
1Shakil Seeraji and  2Tasnim Alam 
1
 Lecturer, Department of EEE, Green University of Bangladesh, shakil_2010@yahoo.com 
2Sales and service engineer, Tokai power products Ltd, Dhaka, rim_mist@yahoo.com 
 
 
Abstract - This work presents a design technique for the implementation of the water level control system 
bybased on the use of a single-chip microcontroller.  The proposed model system offers the following 
attractive features: (1) application of the electrode and conductivity of water for sensing the height of water 
in reservoir (2) using the obtained water level for defining on-off condition of the water pump. (3) Water 
supply availability checks option to protect the motor. (4) The system will be on run mode only at the 
predefined time sequence to avoid the power failure due to load shedding and programmable on time select 
option for motors. Water reservoir is filled using single-phase induction motors. The system can operate by 
using manual control or automatic control and also available for monitoring and displaying the process 
status on microcontroller-based control board. Very low power control with backup power supply system. 
In addition this control system scheme can be used in home and industry sector to reduce the wastage of 
water, money, time and manpower. This modern control system provides a simple and economical 
mechanism providing automatic water pump control operation. This control system can also be used in 
teaching and demonstrating in the control engineering laboratory.  
Keywords: Microcontroller, automatic control system, water level sensor, time control sensor, manual and 
automatic control. 
                                                                                                                                                                                                               
INTRODUCTION 
Presently, it is becoming increasingly advantages in  carry  out  information  processing  and  
control functions  using  digitally  methods.    It  is  well known  fact  that  the  digital  control  
system  can  offer high  accuracy  and  high-speed  response.    These are  the  reasons  that  cause  
a  strong  motivation  to design  and  implement  the  automatic  control  system based  on  the  
digital  controller. Actual  systems  and controllers  are  widely  implemented  in  the  discrete- 
time  domain  since  they  employ  microprocessors  or computers  in  general.    Recently,  a  
variable  structure control  in  the  discrete-time  domain  has  much  received the  attention. 
Therefore,  this  work  presents  an  technique  to  implement  the  modeling  of  the  water level  
control  system  based  on  the  use  of  the commercially  available  microcontroller (uC) without  
 
 
 
Page 638
ISBN: 978-984-33-2140-4
  
2 
Corresponding Author: Shakil Seeraji, 
E-mail: shakil_2010@yahoo.com 
  
 
 
 
 
 
 
using   the personal computer (PC).    The system  model  is  designed  using  a   popular   
commercial   microcontroller ATMEGA8,  single phase induction  motors  and  some  electrodes 
as water level detector sensors and variable resistance of material as a time control sensors.    The  
main  benefit  of  the  proposed control  system  modeling  is  able  to  employ  as  an educational  
tool  for  teaching  and  demonstrating  in the  control-engineering  laboratory.  The 
implementation and  experimental  results  can be   shown  to  demonstrate the  usefulness  of  the  
proposed  control  scheme. Furthermore,  it  is  to  be  expected  as  this  control system  can  be  
modified  to  other  actual  systems  for collecting  and  controlling  the  physical  data,  such as,  
pressure,  temperature  and  etc 
 
 
PROPOSED CONTROL SCHEME 
                                                                                                                                                                                                                                                                
Therefore, in this work the automatic water pump controller is used to control the water pump 
motor. The motor gets automatically switched on when water in the overhead tank (OHT) falls 
below the lower limit. Similarly, it gets switched off when the tank is filled up. The circuit is 
simple, compact and economical. It works off a 12V DC power supply and consumes very little 
power. The circuit can be divided into two parts: controller circuit and motor drive circuits.                                
The controller circuit is one which is used for the purpose of controlling the water pump action. 
When the water level reaches a maximum level the motor turns off and when the water level 
goes below the minimum level the motor turns on automatically. 
Page 639
  
2 
Corresponding Author: Shakil Seeraji, 
E-mail: shakil_2010@yahoo.com 
  
 
Figure 1 Proposed
 (Where T1= Reservoir1 an
 Lmax= wate
Figure 1 shows Motor1 is used for reservoir1. It can operate only under certain conditions. If the 
conditions are fulfilled then motor will turn on. Otherwise it will remain off. Here we briefly 
describe about the condition given
the supply is available or not. If water is available at the supply end then it will turn 
the sensor will sense the level of the water in the reservoir1. If wat
the reservoir1 then it will start filling up the reservoir. And when water reaches the upper level of 
the reservoir1 motor will turn off automatically. Again we can control the motor running time by 
using timing control. Suppose we have to run the motor for 40 min every time. After passing this 
40 min motor will turn off.  Here two more conditions to be considered, that in some case it may 
happen that motor already ran for 40 min but reservoi1 filled up just over lower level, 
turn off. Again water can reach the upper level of the reservoir1 before 40 min gone by, at this 
condition motor will also turn off. According to condition given, motor1 can not run more than 5 
times in a day. 
   
Motor2 is used for reservoir2. It has some conditions also. They are
requirement of the water at reservoir2. if the reservoir2 is empty, or water level is under the 
lower level of the reservoir. After
of water at reservoir1. If water level is more than the lower level of the resrvoir1, microcontroller 
will check out the selected times (9am
turning on the motor. If the time matches with the selected time, then it will turn on the motor.
the water at the reservoir1 is available but reservoir2 is already filled up, then motor will turn off.
 
 automatic water level control system .  
d T2= Reservoir2,   
r level maximum and Lmin= water level minimum)
 
-To turn on the motor it will first sense that, whether water at 
er is under the lower level of 
-Sensor will first sense the 
 satisfying the above condition sensor will sense the availability 
-10am, 1pm-2pm, 8pm-9pm) of the day selected for 
 
 
 
on. Again 
motor will 
 If 
 
Page 640
  
2 
Corresponding Author: Shakil Seeraji, 
E-mail: shakil_2010@yahoo.com 
  
 
If the water at the reservoir2 is under filling state but reservoir1’s water crosses its lower level, 
motor will turn off. Again we can control the motor running time by using timing control. 
Suppose we have to run the motor for 40 min every time. After passing this 40 min motor will 
turn off.  Here two more conditions to be considered, that in some case it may happen that motor 
already ran for 40 min but reservoi1 filled up just over lower level, motor will turn off. Again 
water can reach the upper level of the reservoir1 before 40 min gone by, at this condition motor 
will also turn off. Again motor2 can not run more than 3 times in a day. Both the motors can not 
run simultaneously.  
 
Active controls provide complete automation from Start to End in the Water Supply Scheme. 
Since water invariably corrodes most equipment, Active Controls' emphasis has been to supply 
equipment that is not affected by water corrosion; meaning no maintenance 
Development of the system can be divided into two parts i.e., hardware and software. Since the 
development board comes with well-defined ports and communication interfaces, hardware 
implementation was not a time consuming task. Most of the development time went into writing 
the software to drive the board. 
 
 
HARDWARE 
Figure 1 shows the configuration of microcontroller based control scheme, which is applied to 
control the water level of the system. It mainly contains a microcontroller (µC),level sensors, 
time sensors, relay and motor drive circuit ,two ac motors M1 and M2 and manual control 
system. 
We used AVR AT-Mega-8 as our controlling device. It takes decision according to state of the 
water level of tank. To drive the microcontroller it is required to write software according to the 
need. Sensor sends signal to the microcontroller and it takes decision according to the signal. 
Water level sensors, and more particularly to a water level sensor for sensing water levels by 
detecting the electric conductivity of water using reference and measuring electrodes.To detect 
water level we use 6 electrodes. Two electrodes are used for minimum and other 2 are used for 
maximum level detection. And rest two are used for connectivity, i.e. create current  
 
Page 641
  
2 
Corresponding Author: Shakil Seeraji, 
E-mail: shakil_2010@yahoo.com 
  
 
 
 
Figure 2 Water level sensors and connection diagram with microcontroller 
 
 
Flow to base of transistor. In the fig we can see that there are 3 connections coming out of the 
reservoir. Two are for maximum and minimum level detection. Another one is for the current 
flow according to the water level. The lower electrode used is for minimum level and the upper 
one is used for maximum level detection. A 12V supply is fed into the water to make current 
flow to base of transistor.  Our transistors are connected to microcontroller to send the current as 
a measurement of sensor. Transistors are connected in common emitter configuration. According 
to this configuration if a certain amount of current flows through the base, the collector and 
emitter junction become short and current flows through it. We connected a high value resistor 
with the emitter to the ground. So that in case of current flow it can not bypass to the ground, 
rather it will go to the input pins of the microcontroller. 
 
AT
m
eg
a8
L
1234567891011121314
15 16 17 18 19 20 21 22 23 24 25 26 27 28
PC
6 
(R
ES
ET
)
PD
0 
(R
x
D
)
PD
1 
(T
x
D
)
PD
2 
(IN
T0
)
PD
3 
(IN
T1
)
PD
4 
(X
C
K/
T0
)
VC
C
G
N
D
PB
6 
(X
T1
/T
O
SC
1)
PB
7 
(X
T2
/T
O
SC
2)
PD
5 
(T
1)
PD
6 
(A
IN
0)
PD
7 
(A
IN
1)
PB
0 
(IC
P)
(O
C
1A
) P
B1
(S
S/
O
C
1B
) P
B2
(O
C
2/
M
O
SI
) P
B3
(M
IS
O
) P
B4
(S
C
K)
 
PB
5
AV
C
C
AR
EF
AG
N
D
(A
D
C
0) 
PC
0
(A
D
C
1) 
PC
1
(A
D
C
2) 
PC
2
(A
D
C
3) 
PC
3
(S
D
A/
AD
C
4) 
PC
4
(S
C
L/
AD
C
5) 
PC
5
0
R4
6.8k
H
I
Q1
NPN
HI HI
Reservoir2
0
R3
6.8k
Q4
NPN
+12V DC
Supply
R2
6.8k
R1
6.8k
Q2
NPN
+12V DC
Supply
0
Reservoir1
0
H
I
Q3
NPN
Page 642
  
2 
Corresponding Author: Shakil Seeraji, 
E-mail: shakil_2010@yahoo.com 
  
 
 
Figure 3 Time sensors and connection diagram with microcontroller 
 
Time sensor is made by a potentiometer. We can vary the timing control according to the value 
of pot. We know that a potentiometer has two fixed and variable leg. If we give power supply to 
a fixed end and connect another fixed end to the ground we can get variable output voltage by 
varying the variable part of the potentiometer. Similar kind of theory we applied here. We gave 
5V supply to one fixed end of the Potentiometer. And another fixed point to the ground. And the 
variable portion is connected to the microcontroller’s ADC input. This input is worked as sense 
of timing control.  
 
R2
Potentionmeter
0
Potentiometer used
as time sensors
ATmega8L
1
2
3
4
5
6
7
8
9
10
11
12
13
14 15
16
17
18
19
20
21
22
23
24
25
26
27
28PC6 (RESET)
PD0 (RxD)
PD1 (TxD)
PD2 (INT0)
PD3 (INT1)
PD4 (XCK/T0)
VCC
GND
PB6 (XT1/TOSC1)
PB7 (XT2/TOSC2)
PD5 (T1)
PD6 (AIN0)
PD7 (AIN1)
PB0 (ICP) (OC1A) PB1
(SS/OC1B) PB2
(OC2/MOSI) PB3
(MISO) PB4
(SCK) PB5
AVCC
AREF
AGND
(ADC0) PC0
(ADC1) PC1
(ADC2) PC2
(ADC3) PC3
(SDA/ADC4) PC4
(SCL/ADC5) PC5
+5V DC
R1
Potentiometer
D2
DIODE ZENER
0
D1
DIODE ZENER
RE2
RELAY SPDT
0
Q2
NPN
+12V DC
V2
220Vac
R1
1K
0
+12V DC
MOTOR AC1
1
2
ATmega8L
1
2
3
4
5
6
7
8
9
10
11
12
13
14 15
16
17
18
19
20
21
22
23
24
25
26
27
28PC6 (RESET)
PD0 (RxD)
PD1 (TxD)
PD2 (INT0)
PD3 (INT1)
PD4 (XCK/T0)
VCC
GND
PB6 (XT1/TOSC1)
PB7 (XT2/TOSC2)
PD5 (T1)
PD6 (AIN0)
PD7 (AIN1)
PB0 (ICP) (OC1A) PB1
(SS/OC1B) PB2
(OC2/MOSI) PB3
(MISO) PB4
(SCK) PB5
AVCC
AREF
AGND
(ADC0) PC0
(ADC1) PC1
(ADC2) PC2
(ADC3) PC3
(SDA/ADC4) PC4
(SCL/ADC5) PC5
0
RE1
RELAY SPDT
Q1
NPN
V1
220Vac
MOTOR AC2
1
2
R2
1K
Page 643
  
2 
Corresponding Author: Shakil Seeraji, 
E-mail: shakil_2010@yahoo.com 
  
 
Figure 4 schematic diagram of control unit 
 
 
When the reservoir will empty we need to fill them. To fill them we use pumps, which are driven 
by motor. To drive the motors, we need to supply 220V ac. However, we use relays to isolate the 
high voltage circuit from low voltage circuit. Sensing the tank to be empty microcontroller will 
give pulse to the base of a transistor operating the relay portion. And this relays control the 
operation of 220 V ac motors. 
 
 
Figure 5 Manual over-write switch with microcontroller 
 
 
 
 
A push–pull switch is connected to microcontroller. We used this switch for manual overwrite 
purpose. In time of operation a motor can be burned out, or we may have to replace or test it. We 
can not do this by running the system on. For the purposes written above we have to standby the 
system by using manual overwrite control, which has priority over automated control system.  
    
 
 
0
ATmega8L
1
2
3
4
5
6
7
8
9
10
11
12
13
14 15
16
17
18
19
20
21
22
23
24
25
26
27
28PC6 (RESET)
PD0 (RxD)
PD1 (TxD)
PD2 (INT0)
PD3 (INT1)
PD4 (XCK/T0)
VCC
GND
PB6 (XT1/TOSC1)
PB7 (XT2/TOSC2)
PD5 (T1)
PD6 (AIN0)
PD7 (AIN1)
PB0 (ICP) (OC1A) PB1
(SS/OC1B) PB2
(OC2/MOSI) PB3
(MISO) PB4
(SCK) PB5
AVCC
AREF
AGND
(ADC0) PC0
(ADC1) PC1
(ADC2) PC2
(ADC3) PC3
(SDA/ADC4) PC4
(SCL/ADC5) PC5
+5V DC
R1
6.8K
Manual over
write switch
S1
SW DIP-3
1
2
3
6
5
4
Page 644
  
2 
Corresponding Author: Shakil Seeraji, 
E-mail: shakil_2010@yahoo.com 
  
 
 
Figure 6 Simplified diagram for manual control system 
 
We have another two switch connected in parallel to the motors. After disconnected the 
automated system we can still run the motor by using these two switches. In automatic system 
we can not run both the motor simultaneously. But after using manual overwrite switches we can 
run both the motors by using those parallel switches. So we can use parallel switches in any 
condition depended on users wish.    
 
                                                                       
SOFTWARE 
As mentioned earlier, software development was seen as a major portion of the entire research 
project. A complete flowchart of the automatic pump control  system is shown in Figure 7. For 
configure our µC we use embedded C, at platform of AVR studio-4.For downloading the 
software from pc to µC, we use Ponyprog software.   
MOTOR AC2
1
2
F2
FUSE
V1
220Vac
F1
FUSE
MOTOR AC1
1
2
S1
SW SPST
S2
SW SPST
Page 645
  
2 
Corresponding Author: Shakil Seeraji, 
E-mail: shakil_2010@yahoo.com 
  
 
 
Figure 7 Microcontroller operation flow-chart for automatic control system 
 
 
 CONCLUTION        
In this paper , the alternative tecnique in which microcontroller based automatic and manual 
control system are use to control the water level. The proposed control system provides many 
features, such as electrodes can be applied for detecting the water level in the tank and this 
control system consume very little power. 
REFERENCES 
[1] AT MEGA-8 data sheet.www.atmel.com 
Page 646
  
2 
Corresponding Author: Shakil Seeraji, 
E-mail: shakil_2010@yahoo.com 
  
 
[2] www.wikipedia.com 
[3] Muhammad Ali mazaidi, “The 8051 Microcontroller and Embedded System”. 
[4] Pan, Y and Furuta “Discrete time vss control design.” International journal of Robust and 
Non-linear control.          
Page 647
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Md. Salah Uddin Yusuf,  
E-mail: ymdsalahu2@gmail.com 
MODIFIED INTRA_4×4 PREDICTION MODE SCHEME FOR 
H.264/AVC VIDEO CODING 
 
Md. Salah Uddin Yusuf*, Farjana Jhumur* and Mohiuddin Ahmad* 
*Department of EEE, Khulna University of Engineering & Technology 
Khulna-9203, Bangladesh 
 
 
In this paper, we propose a modified intra_4x4 prediction mode scheme is proposed for H.264/AVC, which 
can improve the prediction accuracy for areas without unified orientation. In our scheme, the upper right part 
of one 4×4 block mainly employs vertical prediction while the lower left part mainly uses horizontal 
prediction, predicting both vertical and horizontal directions in one block. The proposed scheme uses simple 
prediction equations with fixed weighting coefficients. Experimental results show that WCP is very 
competitive while comparing to other Intra_4×4 prediction algorithms. 
 
Key words: Video coding, intra prediction, prediction mode, distance based weighted prediction (DWP), 
H.264/AVC. 
 
1. INTRODUCTION 
 
Joint Video Team (JVT) of ITU-T Video Coding 
Experts Group (VCEG) and ISO Motion Picture 
Experts Group (MPEG) has released the latest 
standard for video coding, which is known as 
H.264 or MPEG-4 Part 10 Advanced Video Coding 
(AVC)(www.ee.uta.edu/dip/courses/ee5356/H264sy
stems.pdf, Wiegand et al. 2003). The directional 
spatial prediction for intra coding is one of the 
significant contributions of H.264/AVC. In contrast 
with previous standards, intra prediction in H.264 is 
applied in spatial domain instead of transform 
domain, which utilizes the correlation between 
adjacent blocks to remove spatial redundant 
information in an image. 
 
Many efforts have been done to simplify the intra 
coding in H.264. Fast intra mode decision 
algorithms were proposed to reduce the number of 
modes that needed calculation according to some 
criterion (Meng et al, 2003, Kim et al. 2004). 
Besides, fewer efforts on the intra prediction modes 
innovations were raised, either by altering the 
reference pixels (Min-hua Zhou, 2002) or by 
exchanging the order of intra prediction (Kim et al. 
2004). Most of the algorithms can reduce the time 
complexity remarkably, but few can improve the 
coding efficiency. 
 
Recently, distance-based weighted prediction 
(DWP) method and its simplified version integral 
DWP (iDWP) (Shengsheng et al. 2008) were 
proposed to improve prediction efficiency, where 
the weighted prediction is done by coefficients 
which are inversely proportional to the distances 
between current pixel and its reference pixels. 
Although these methods give some improvement, 
they are computationally complex. This inspires us 
to propose a novel intra prediction mode called 
weighted cross prediction (WCP), which combines 
the vertical and horizontal predictions to replace the 
DC mode in Intra_4x4 prediction. The fixed 
weighting coefficients in our approach have a lower 
computation complexity with a comparable 
performance to DWP and iDWP. 
 
The rest of this paper is organized as follows. We 
briefly introduce the intra prediction in H.264 in 
Section 2. In section 3, we describe our proposed 
method in details and analysis about the simulation 
results will be given in section 4. Finally, 
conclusions will be drawn in section 5. 
 
2. INTRA PREDICTION TECHNIQUE 
IN H.264/AVC 
 
The intra predictions in H.264/AVC are performed 
in a block-based manner, by referring to the 
neighboring samples of previously coded blocks 
which are left to and/or above the block to be 
predicted. In luminance prediction, nine optional 
prediction modes are provided for every 4x4 block, 
named as vertical, horizontal, DC, diagonal-down-
left, diagonal-down-right, vertical-right, horizontal-
Page 648
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
  
down, vertical-left and horizontal-up prediction. 
Vertical, horizontal and DC modes, which are 
specified similar to the modes in Intra_4×4, with 
plane prediction compose all the four prediction 
modes for 16x16 luma block. The Intra_4×4 
prediction is suitable for the parts with significant 
details, while the Intra_16×16 is applied to the 
smoother areas. The encoder chooses the best 
prediction mode to minimize the Lagrangian cost 
function, which takes both distortion and bit rate 
into consideration (www.ee.uta.edu/dip/courses 
/ee5356/H264systems.pdf ). 
 
Figure 1 illustrates 16 samples of 4×4 block 
(labeled as a-p) which are predicted by previous-
decoded samples in the neighboring blocks (labeled 
as A-M), when using the Intra_4×4 prediction. For 
vertical or horizontal modes, the pixel values are 
extrapolated by upper samples or left samples, 
while other directional modes utilize the linear 
weighted average of reference samples. For the DC 
mode, all the predicted pixels are formed by means 
of upper and left samples. 
 
 
 
Fig.1 Intra_4x4 prediction modes 
 
In Intra_4x4 prediction, each block can be predicted 
using either the DC mode or one of the eight 
directional modes. As we know, these eight 
directional modes are used to predict the regions 
with unified orientations. Therefore, it is better if 
the remainder, DC mode, can be used to predict 
some areas that the textures have no unified 
orientation. However, using DC mode to predict 
such areas is not very accurate because it uses one 
value to predict all pixels in the block, which can 
not show any kind of variations between them. 
Since the Intra_4×4 DC mode can not provide 
accurate prediction for some areas without unified 
directions, we replace DC mode with WCP mode, 
which is much simpler than DWP and iDWP 
(Shengsheng  et al. 2008). 
 
3. PROPOSED INTRA PREDICTION 
ALGORITHM 
 
Statistics show that the vertical and horizontal 
predictions are more frequently used than other 
modes, implying higher correlations between the 
reference samples and the pixels to be predicted in 
these two directions (Zhang et al. 2004). Therefore, 
it is possible to enhance the intra prediction 
accuracy by employing more such directional 
predictions, which inspires us to design WCP to 
replace DC mode in Intra_4×4, via combining 
vertical and horizontal predictions.  
 
Furthermore, because only the upper and left 
reference samples are available, we divide the block 
into three parts: the diagonal, upper right part and 
lower left part. Since the diagonal pixels have the 
equal distance between the upper and left reference, 
they can be predicted by both the corresponding 
upper and left reference samples. However, the 
upper right pixels are closer to the upper reference 
while the lower left pixels closer to the left ones. 
Therefore, we mainly use the upper reference 
samples as the major component for the upper right 
part prediction while using the left reference 
samples for the lower left part. In other words, we 
use the vertical prediction as the major component 
for the upper right part, while employing the 
horizontal prediction as the major component for 
the lower left part. 
 
Since correlation between pixels exists in both 
vertical and horizontal direction, we cannot only 
use the vertical or horizontal prediction directly in a 
4×4 block. As a result, when we predict the upper 
right part, we use the left predicted pixel to adjust 
the vertical prediction, while using the upper 
predicted pixel as an adjuster to the horizontal 
prediction for the lower left part similar to  (Baocai 
et al. 2006). 
 
As illustrated in Figure 2, Pi,j (0<= i,j<=3) denotes 
the predicted value of the pixel in the ith row and 
jth column of current 4x4 block. Uj and Li denote 
the reference samples reconstructed from upper and 
left blocks respectively. 
 
 
Fig. 2 Illustration of intra 4x4 prediction 
 
 U0  U1  U2  U3 
 L0 P02 P03 
 L1 P10 P11 P12 P13 
 L2 P20 P21 P22 P23 
 L3 P30 P31 P32 P33 
 M 
P01 P00 
Page 649
  
In order to make a weighted prediction, a larger 
coefficient 3/4 is assigned to the major reference 
samples while a smaller coefficient 1/4 to the 
adjustment ones. The denominators 4 make the 
division operation to be implemented by shift 
operation. Pi,j can be calculated as: 
 
 
 
 
 
 
Since some of the predicted values are based on the 
other predicted values, we have to compute the 
predicted values in the following order. The 
diagonal pixels should be computed first, which are 
only based on Uj and Li. Then, the upper right and 
lower left parts can be computed. The material 
expressions of WCP are listed as follows. It can be 
seen that the longer the distance between the 
reference sample and the pixel is, the smaller the 
coefficient becomes.  
 
0,0 0 0
1 1
2 2
P U L= +  1,1 1 1
1 1
2 2
P U L= +  
2,2 2 2
1 1
2 2
P U L= +  3,3 3 3
1 1
2 2
P U L= +  
0,1 1 0,0 1 0 0
3 1 3 1 1( )
4 4 4 8 8
P U P U U L= + = + +
0,2 2 0,1 2 1 0 0
3 1 3 3 1 1( )
4 4 4 16 32 32
P U P U U U L= + = + + +
1,2 2 1,1 2 1 1
3 1 3 1 1( )
4 4 4 8 8
P U P U U L= + = + +
0,3 3 0,2 3 2 1 0 0
3 1 3 3 3 1 1( )
4 4 4 16 64 128 128
P U P U U U U L= + = + + + +
1,3 3 1,2 3 2 1 1
3 1 3 3 1 1( )
4 4 4 16 32 32
P U P U U U L= + = + + +
2,3 3 2,2 3 2 2
3 1 3 1 1( )
4 4 4 8 8
P U P U U L= + = + +
1,0 1 0,0 1 0 0
3 1 3 1 1( )
4 4 4 8 8
P L P L U L= + = + +  
2,0 2 1,0 2 1 0 0
3 1 3 3 1 1( )
4 4 4 16 32 32
P L P L L U L= + = + + +
2,1 2 1,1 2 1 1
3 1 3 1 1( )
4 4 4 8 8
P L P L U L= + = + +  
3,0 3 2,0 3 2 1 0 0
3 1 3 3 3 1 1( )
4 4 4 16 64 128 128
P L P L L L U L= + = + + + +
3,1 3 2,1 3 2 1 1
3 1 3 3 1 1( )
4 4 4 16 32 32
P L P L L U L= + = + + +
3,2 3 2,2 3 2 2
3 1 3 1 1( )
4 4 4 8 8
P L P L U L= + = + +  
 
We also compare the computation complexity 
between iDWP and WCP. The computation 
complexity of iDWP to predict one pixel includes 1 
multiplication, 2 additions, 1 subtraction, and 2 
shifts, which is an approximation to DWP (Kim et 
al.). The number of operation to predict one pixel in 
WCP is 2.75 additions and 1.75 shifts in average, 
which is less complex than iDWP 
 
4. SIMULATION RESULTS AND 
DISCUSSIONS 
 
The proposed algorithm is simulated on the JM soft 
ware (http://iphome.hhi.de/suehring/tml/) version 
10.2. The performance of WCP is compared with 
intra prediction scheme of H.264 in terms of the 
average PSNR (dB) and the bitrate (kbits/s) for 
several test sequences including both CIF and QCIF 
format. In the experiment, all the sequences have 
100 frames (30Hz), compressed with all Intra 
prediction by applying four quantization 
parameters: QP=20, 24, 28, and 32. The test 
conditions are indicated as follows: 
 
(a) Intra 16x16 and Intra 4x4 are used; 
(b) RD Optimization is used; 
(c) The entropy coding method is CABAC; 
(d) The 8x8 transform is disabled; 
(e) The adaptive rounding is disabled. 
 
Since our proposed method is for low complexity 
intra prediction, we only compare the simulation 
result of WCP and iDWP here. The simulation 
results for WCP and iDWP are listed in table 1 and 
table 2.  
Table 1. Simulation results of CIF sequences 
 WCP iDWP 
Sequence
(CIF) 
ΔPSNR 
(dB) 
Δbitrate 
(%) 
ΔPSNR 
(dB) 
Δbitrate
(%) 
Bus 0.09 -0.96 0.13 -1.35 
Stefan 0.08 -0.78 0.10 -0.95 
Mobile 0.06 -0.48 0.06 -0.44 
Foreman 0.02 -0.23 0.02 -0.30 
average 0.06 -0.61 0.08 -0.76 
Table 2. Simulation results of QCIF sequences 
 WCP  iDWP  
Sequence 
(QCIF) 
ΔPSNR 
(dB) 
Δbitrate 
(%) 
ΔPSNR 
(dB) 
Δbitrate 
(%) 
Salesman 0.07 -0.86 0.11 -1.28 
News 0.06 -0.55 0.09 -0.89 
Claire 0.04 -0.53 0.06 -0.67 
average 0.06 -0.65 0.09 -0.95 
 
The increase of PSNR is calculated when the 
bitrates are equal while the decrease of bitrate is 
calculated when the PSNRs are the same. The rate-
, 1 j , 1
,
1, i 1,
(3 2) 2=[(U 1) 2] 2
( 1) 1
(3 2) 2=[(L 1) 2] 2
j i j j i j
i j i j
i i j i i j
U P U P i j
P L U i j
L P L P i j
− −
− −
⎧ + + >> << + + + >> <⎪
= + + >> =⎨⎪ + + >> << + + + >> >⎩
Page 650
  
distortion (RD) curves of Bus and Salesman 
sequences are shown in Figure 3 and Figure 4. A 
constant performance gain is obtained by WCP 
over H.264 with an average PSNR improvement of 
0.06 dB which reaches its maximum of 0.09 dB in 
CIF sequences. In QCIF sequences, the average 
PSNR increase is 0.06 dB. It can be seen that the 
result of WCP is comparable to iDWP. In mobile 
sequence, the performance is even better than 
iDWP. In addition, WCP shows a better 
performance in CIF than in QCIF sequences 
suggesting its better suitability for high resolution 
sequences.  
2000 3000 4000 5000 6000 7000 8000
32
34
36
38
40
42
44
bitrate(kbits/s)
PS
NR
(dB
)
H.264
WCP
iDWP
 
Fig. 3 RD curve for “Bus” sequence 
 
400 600 800 1000 1200 1400 1600 1800
32
34
36
38
40
42
44
bitrate(kbits/s)
PS
NR
(dB
)
H.264
WCP
iDWP
 
Fig. 4 RD curve for “Salesman” sequence 
 
5. CONCLUSIONS 
 
WCP is proposed to replace DC mode in Intra_4×4 
to solve the problem that DC mode used in the 
regions with no unified direction. To improve the 
prediction accuracy, we utilize the vertical 
prediction as the major approach on the upper right 
part, while the horizontal prediction as the major 
approach on the lower left part, which includes both 
vertical and horizontal predictions in one block. 
The experimental results show improvements 
compared to the original H.264 with DC mode and 
WCP gives comparable RD performance to iDWP 
with lower computation complexity.  
 
ACKNOWLEDGEMENT  
 
This research was partially supported by CASR 
grants memo: KUET/CASR10/26(30) of KUET, 
Khulna, Bangladesh. 
 
REFERENCES 
 
1.  ITU-T Recommendation H.264 and ISO/IEC 
14496-10, “Advanced video coding for generic 
audiovisual services,” May 2003 (and 
subsequent amendment and corrigenda). 
2.   Wiegand, T, Sullivan, G.J., Bjontegaard, G. and 
Luthra,A.,(2003), Overview of the H.264/AVC 
video coding standard, IEEE Trans. Circuits 
Syst. Video Technol., 13(7), pp.560-576. 
3.  Meng, B., and Au, O. C., (2003), Fast intra-
prediction mode selection for 4×4 blocks in 
H.264, Int’l Conf. on Image Processing, 
Barcelona, Spain, 2003, pp.389-392. 
4  Kim, C. S.,  Shih, H.-H., and Kuo, C. C. J., 
(2004), Feature-based intra-prediction mode 
decision for H.264, Proc. Int’l Conf. Image 
Processing, Singapore, Vol. 2, pp.769-772. 
5.   Min-hua Zhou, (2002), Intra prediction with 
simplified prediction modes, ISO/IEC 
JT1/SC29/WG11 and ITU-T SG16 Q.6, JVT 
4th Meeting, JVT-D026, Klagenfurt, Austria, 
pp.22-26. 
6.  Kim, W.,-S., Cho, D.-S., and Kim, K. –W., 
(2002), Intra prediction enhancements, 
ISO/IEC JTC1/SC29/WG11 and ITU-T SG16 
Q.6, JVT 5th Meeting, JVT-E051, Geneva, 
Switzerland, pp.9-17. 
7.  Shengsheng Yu, Yi Gao, Jiazhong Chen, and 
Jingli zhou, (2008), Distance-based weighted 
prediction for H.264 Intra Coding, IEEE IET 
International Conference on Audio, Language 
and Image Processing, pp.1477-1480. 
8.  Nan Zhang, Baocai Yin, Dehui Kong, and 
Wenying Yue, “Spatial prediction based intra-
coding,” 2004 IEEE International Conference 
on Multimedia and Expo (ICME), Taipei, 
Taiwan, pp.97-100, June 2004. 
9.    Baocai Yin, Lei Sun, Dehui Kong, and Pengfei 
Ji, “Adjacent piexels-based intra prediction 
algorithm,” Journal of Beijing University of 
Technology, Vol.32, No.11, pp.1037-1042, 
Nov. 2006. 
10.  JM10.2,  http://iphome.hhi.de/suehring/tml/ .     
Page 651
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
* Corresponding Author: P. K. Shadhu Khan,  
E-mail: poritosh@cuet.ac.bd, poritosh_k@yahoo.com  
PERFORMANCE ANALYSIS OF A SIMPLE POWER QUALITY 
CONDITIONER FOR MITIGATION OF HARMONICS  
 
 
M. R. Tanvir Hossain, P.K. Shadhu Khan*, Md. Rafiqul Alam, A. K. Sen Gupta, Md. 
Afikur Rahman and  Md.Taufiqul Zakaria  
Department of Electrical and Electronic Engineering,  
Chittagong University of Engineering & Technology (CUET),  
Chittagon-4349, Bangladesh 
 
 
Power quality issues are gaining significant attention due to the increase in use of equipment that are 
sensitive to distortions or dips in supply voltages. At the same time, the usage of static power converters has 
been growing tremendously to provide controlled electric power in various applications such as arc furnaces, 
computer power supplies and adjustable speed drives. The nonlinear characteristics of these power 
converters create poor power factor, low system efficiency, interference in nearby communication networks 
and disturbance to other consumers due to increased harmonics, negative sequence and reactive power 
components of current from AC mains. To curb this, regulations apply in many places that limit the 
distortion and unbalance that a customer can inject to a distribution system. These regulations may require 
the installation of active filter on customer premises to reduce harmonics. In this paper behavior of a simple 
converter circuit has been analyzed experimentally to find its effectiveness for cost effective solution as 
power conditioner. The circuit consists of four diodes and one MOSFET has been used at the input of a 
resistive loaded single phase rectifier circuit to mitigate harmonics. It is found that the total harmonic 
distortion (THD) is reduced; power factor and efficiency are improved. The work has also been simulated by 
ORCAD simulation software and it is found that simulation results matched closely with those of 
experimental results.  
  
Key words: Power Quality, Unified Power Quality, Harmonic Mitigation, Power Quality Conditioner, 
Reactive Power 
 
1. INTRODUCTION 
 
The advances in the power semiconductor devices 
have led to the increase in the use of power-
electronic converters in various applications such as 
heating, lighting, ventilating and air conditioning 
applications, large rated dc and ac drives, adjustable 
speed drives (ASDs), HVDC systems, in process 
technology such as electroplating, welding units 
etc., battery charging for electric vehicles, power 
supplies for telecommunication systems etc [1-4]. 
And many of these use ac to dc conversion by 
various rectifiers. Rectifiers are non-linear circuit 
elements and generate harmonic currents. The non-
sinusoidal harmonic currents drawn by the rectifiers 
are injected into the ac power lines /transformers 
/source causing a number of problems for the 
power distribution network and for other electrical 
systems in the vicinity of the rectifier deteriorating 
the power quality at the point of common coupling 
(PCC), thereby affecting the nearby consumers [5-
7]. Consequently, design and development of 
rectifiers with improved waveforms has gained 
importance for stringent power quality regulation 
and strict limit on total harmonic distortion (THD) 
of input current placed by standards such as IEC 
1000-3-2 and IEEE 519-1992 [8-10]. 
 
Several methods have been employed for 
improving the input current wave shape and power 
factor of rectifiers which include both active and 
passive means. Among the passive wave shaping 
methods, the novel method, using an input L-C 
parallel resonant tank proposed by P. D. Ziogas 
[11] in 1990, is worth mentioning. However, 
further improvement of the input power factor is 
difficult to achieve, and the input current’s total 
harmonic distortion is still high, which is the main 
disadvantage of the novel topology. To overcome 
the weakness, Yanchao in 1996 [12] proposed an 
improved passive wave shaping method where a 
capacitor is placed in parallel between the parallel 
resonant tank and the rectifier bridge, which could 
compensate the reactive power and absorb the 
Page 652
ISBN: 978-984-33-2140-4
  
distortion power. As a result the improved method 
has a better filter feature and the higher input power 
factor than the novel method. Though the passive 
methods are attractive for their simplicity, reduced 
cost and reliability [9, 13-14] but they are bulky 
and fail to provide satisfactory results. On the other 
hand, the active methods using high frequency 
switching technique to shape the input current with 
small size filter are much preferred [10, 15]. 
Although due to design complexity and cost of the 
additional circuitry often found them to be 
unacceptable in low power applications. In 1991, a 
novel active power factor correction method for 
power supplies with three phase front end diode 
rectifiers is proposed and analyzed by A. R. Prasad 
and P. D. Ziogas [16]. The implementation of this 
method requires the use of an additional single 
switch boost chopper. This method does not deal 
with total harmonic distortion but the power factor 
is near unity. Based on the analysis of the novel 
active power factor correction of three phase diode 
rectifiers by A. R. Prasad and P. D. Ziogas [16], 
M.A. Khan et al. in 2007 [17] designed a single 
phase rectifier with switching on AC side for high 
power factor and low total harmonic distortion. 
This method uses a single MOSFET switch on the 
ac side to provide alternative path for input current 
to flow and hence make it continuous. The rectifier 
is connected to the ac mains through a series 
combination of inductor and capacitor, which keeps 
the input current smooth and in phase with the 
supply voltage. The simulated results revealed that 
the total harmonic distortion is reduced and overall 
efficiency is improved significantly. 
 
2. OBJECTIVE 
 
In this paper behavior of a simple converter circuit 
has been analyzed experimentally to find its 
effectiveness for cost effective solution as power 
conditioner. The circuit consists of four diodes and 
one MOSFET has been used at the input of a 
resistive loaded single phase rectifier circuit to 
mitigate harmonics. The work has been simulated 
by ORCAD simulation software and the simulation 
outcomes have been verified with those of 
experimental results. 
 
3. CIRCUIT DESCRIPTION  
 
Fig. 1 shows the schematic diagram of the circuit 
present here for making the current continuous. 
When the switch (M1) is ON or closed, it provides 
an alternative path when all the diodes (D1 to D4) 
are reverse biased. Since input current flows 
naturally when the supply voltage approaches its 
maximum value (positive or negative), the switch 
should be triggered off during that period. For the 
rest of the period, the switch should be turned ON 
and OFF with continuously varying duty cycle. The 
duty cycle should be smoothly varying, starting 
with maximum ON period and reaching to 
minimum ON period as the supply voltage sweeps 
through its zero to maximum values. The ON time 
initially should be high to ensure the increase of 
input current to a reasonable value, so that during 
smaller OFF periods current does not fall 
appreciably and thus remains smooth. As the 
supply voltage increases, the ON period should 
decrease accordingly to prevent the input current 
from rising indefinitely and also to allow input 
current sufficient time to fall accordingly during the 
OFF period. This concept reveals that the duty 
cycle of the switching should be varied like a 
rectified cosine function with a frequency twice that 
of the supply.  
 
 
 
Fig. 1: Single phase diode rectifier with switching 
on input side 
 
The inductor (L1) connected in series with the 
supply makes the current smoother by eliminating 
any sharp variation that might exist. However, the 
inductance value required for this purpose may 
become large, causing a significant portion of 
supply voltage to be dropped across it. This would 
result in unacceptably low output voltage. 
Moreover, the phase difference between input 
current and supply voltage in this case would be 
also unacceptable. Therefore a capacitor (C2) has 
been connected in series with L1 to keep the current 
in phase with the supply voltage.  
 
Page 653
  
3.1 The Switching Scheme 
The objective of the switching scheme is to 
enhance the continuity of the input current by 
providing it an alternative path through closing an 
electronic switch. A MOSFET (IRF 840) is used as 
the switch because of its high switching speed 
compared to other semiconductor switches. The 
gate pulses have been generated by a PWM module 
which mainly consists of an opamp, an opto-
coupler and BJT. A 4 KHz triangular wave is 
compared with a 50 Hz sinusoidal signal to 
generate the gate pulses in order that the duty cycle 
can be smoothly varying, starting with maximum 
ON period and reaching to minimum ON period as 
the supply voltage sweeps through its zero to 
maximum values, so as to make the input current 
sinusoidal and in phase with input voltage. The 
opto-coupler is used to provide necessary ground 
isolation between the PWM module and the switch 
while producing the pulses. The BJT amplifier is 
connected for increasing the voltage level at about 
10 volts to drive the switch. 
 
3.2 Input Filter Design 
The values of L1 and C2 forming the input filter are 
chosen in such a way that its resonant frequency 
equals that of the supply frequency which is 50 Hz. 
This produces a selectivity due to which only the 
fundamental frequency component of the input 
current can flow unimpeded and causes negligible 
voltage drop across the LC combination. For a 
given supply frequency the value LC constant can 
be found as-  
CL XX   
Cf
Lf


2
12  
6
22 10132104
1 

 .
f
LC  
The values of the series L-C filter are adjusted to 
produce a series resonance at supply frequency with 
the intention to keep the input current in phase with 
the supply voltage and to improve the overall 
system efficiency.  
 
3.3 Output Filter Design 
A simple capacitive input dc filter is used to reduce 
the ripple content of the output voltage of the single 
phase rectifier. The ripple factor RF can be found 
from 
)RCf(
RF
r 122
1

  
Where rf  is the ripple frequency = 100 Hz. 
Considering the ripple voltage to be reduced to 1% 
after filtering, the value of RC constant can be 
found as 0.12855. Again, for the nth harmonic 
ripple current to pass through the filter capacitor, 
the capacitance value should be so chosen that the 
load impedance must be much greater than that of 
the capacitor. That is, 
Cf
R
r

2
1 . Allowing for 
a dc load of 100Ω the value of the output filter 
capacitor C1 is taken 1.2 mF.  
 
4. RESULTS AND DISCUSSION 
 
The converter circuit was simulated by ORCAD 
simulation software with various combinations of 
input filter L, C values and was verified with 
practical examination to find its effectiveness for 
cost effective solution as power conditioner.  
 
Initially the total harmonic distortion of the input 
current of a single phase rectifier has been studied 
as a power quality problem. Fig. 1 shows the non-
sinusoidal input current wave shape of the supply 
mains due to rectification action. The high current 
peaks cause harmonic distortion of the supply 
current and low power factor. 
  
 
 
Fig.2: The non-sinusoidal input current wave shape 
of the supply mains due to rectification action 
 
This results in a poor power quality, voltage 
distortion, poor power factor at input ac mains, 
slowly varying rippled dc output at load end and 
low efficiency. Thus the switching scheme has been 
developed exploiting a single MOSFET switch 
driven by rectangular gate pulses whose duty cycle 
is continuously varied over the period of supply 
voltage. The switch provides an alternative path for 
the input current makes it sinusoidal during the 
periods when due to the reverse biasing of rectifier 
diodes input current causes to flow otherwise.  
 
Simulating the circuit using ORCAD for various 
combination of LC filter, we get the wave shapes of 
input current and its frequency spectrum, output 
voltage waveforms, samples of which are presented 
Page 654
  
in Fig. 3 and the summary of the simulation results 
is given in Table 1. 
 
200ms 240ms 280ms 320ms 360ms 400ms 431ms
I(V1)
-2.00A
0A
2.00A
2.65A
 
(a) 
0Hz 0.1KHz 0.2KHz 0.3KHz 0.4KHz 0.5KHz 0.6KHz 0.7KHz 0.8KHz 0.9KHz 1.0KHz
0A
0.4A
0.8A
1.2A
 
(b) 
200ms 240ms 280ms 320ms 360ms 400ms 440ms 480ms 506ms
V(V1:+,D2:1) V(C1:2,R1:1)
-25.0V
0V
25.0V
-39.4V
48.4V
 
(c) 
 
Fig. 3: wave shapes of (a) input current, and (b) its 
frequency transform, (c) output voltage along with 
supply voltage for L=37.88mH and C=267.5µF 
 
Table 1. Summary of the simulation results  
 
Input filter THD 
(%) 
Vin 
(V) 
Iin 
(A) 
Vout 
(V) 
Iout 
(A) 
Η 
(%) 
P.f. 
L (mH) C (µF) 
160 64 2.46 11.3 1.24 12.5 0.82 73.150.95 
37.88 267.5 3.55 11.3 0.6 14.3 0.42 89.211 
44.8 226.164.02 4.11 0.22 4.26 0.19 86.530.99 
 
The simulation output shows that the THD of the 
input current has been improved significantly, 
power factor has been close to unity and the overall 
efficiency has also been enhanced.  
 
Additionally using simulation the total harmonic 
distortion (THD) and the efficiencies of the 
prototype are calculated for various switching 
frequencies and the efficiency vs. switching 
frequency curve is plotted as shown in Fig. 4. From 
the curve it is clear that the efficiency is more for a 
switching frequency of 4 KHz. Thus we employed 
the switching frequency of 4 KHz in practical 
implementation of the circuit. 
 
81
82
83
84
85
86
87
88
0 1000 2000 3000 4000 5000 6000
Switching Frequency (Hz)
Ef
fic
ie
nc
y 
(%
) 
 
 
Fig. 4: Circuit efficiency for various values of 
switching frequency  
 
Finally, the simulation results have been verified 
with practical results obtained from a laboratory 
setup as shown in Fig.5. The converter circuit has 
been implemented practically keeping the switching 
frequency of gate pulse at 4 KHZ. The input side 
LC filter has been adjusted to give the desired 
series resonance by varying inductor and capacitor 
bank. When the gate pulses were applied to the 
MOSFET and the input resonant filter was tuned, a 
dramatic change was observed in the input current 
wave shape like the simulation outcome.  
 
It was one of the significant parts of our practical 
work to measure the THD and keep it in allowable 
range. We used Virtual Instrument Kit (VIK) to 
measure THD. VIK is a special instrument which 
measure THD with a probe connected to the node 
where THD is to be measured, and is interfaced 
with computer through parallel port. From the 
computer we can view frequency spectrum 
graphically and measure THD directly using VIK.   
 
 
 
Fig. 5: Laboratory setup of the simple power 
quality conditioner 
 
A sample of wave forms of the gating signals, the 
input current and the output voltage obtained from 
practical realization of the circuit for various filter 
combinations is shown in Fig. 6. Also the summary 
of results of the practical implementation is 
illustrated in Table 2.  
 
Page 655
  
 
(a) 
 
(b) 
 
(c) 
 
Fig. 6: sample experimental wave forms of (a) 
gating signals, (b) input current and (c) output 
voltage for L=37mH and C=267.5µF  
 
Table 2. Summary of the experimental results 
 
Input filter THD 
(%) 
Vin 
(V) 
Iin 
(A) 
Vout 
(V) 
Iout 
(A) 
η 
(%) 
P.f. 
L(mH) C(µF) 
37 267.5 4.92 11.3 0.89 12.83 .628 86.74 0.969 
44.8 226.1 4.29 4.11 0.5424.72 0.39 82.65 0.92 
63 160.1 7.26 4.82 0.6254.96 .435 71.47 0.83 
 
The experimental outcome demonstrates close 
resembles to the simulation output. The THD of the 
input current has been considerably improved 
compare to that without conditioner and, power 
factor has been close to unity and the overall 
efficiency has also been better. A comparative 
study on simulation and practical data is 
demonstrated by bar charts as shown in Fig. 7 & 8.  
Comparative  Study on Simulation and Practical THD of Input Current
0
1
2
3
4
5
6
7
8
L=160mH, C=64uF L=37.88mH, C=267.5uF L=44.8mH, C=226.16uF L=63.29mH, C=160.1uF
Input Resonant Filter
T
H
D
 (%
)
%THD (Simulation)
%THD (Experimental)
 
 
Fig. 7: %THD of input current for different LC 
combination (simulation & experimental) 
 
Comparative  Study on Simulation and Experimental Efficiency
0
10
20
30
40
50
60
70
80
90
100
L=160mH, C=64uF L=37.88mH, C=267.5uF L=44.8mH, C=226.16uF L=63.29mH, C=160.1uF
Input Resonant Filter
E
ffi
ci
en
cy
 (%
)
%η (Simulation)
%η (Experimental)
 
 
Fig. 8: Efficiency of the system for different LC 
combination (simulation & experimental) 
 
With the deployment of the power conditioner 
circuit the performance of the single phase rectifier 
has been improved appreciably as demonstrated by 
simulation and practical implementation. The total 
harmonic distortion (THD) is reduced; power factor 
and efficiency are improved and simulation results 
matched closely with those of experimental results. 
The best result of efficiency is obtained for input 
filter parameter L=37mH, C=267.5uF and 
switching frequency of 4 KHz. In this case THD of 
the input current is about 4%, efficiency more than 
86% and power factor is close to unity. Also the 
output voltage is found to be greater than the input 
voltage amplitude. This is important because as the 
output voltage becomes higher than the supply 
voltage amplitude, the rectifier diodes are reverse 
biased and the current can flow naturally only when 
the switch is turned on.  
 
5. CONCLUSION 
 
In this paper a scheme for improving the input 
current wave shape and power factor of a single 
phase rectifier has been successfully analyzed 
experimentally and also by simulation to find its 
effectiveness for cost effective solution as power 
conditioner. The simulation outcomes matched 
closely with those of experimental results. 
However, the experiment has been conducted in 
low power levels and low voltages. If power levels 
would be high it would offer more desirable results 
Page 656
  
as switching power would be minimized to enhance 
the overall system efficiency. Moreover, the effects 
of different types of loads on required switching 
frequency, duty cycle variation and efficiency 
should also be studied. The use of IGBTs instead of 
MOSFET may have significant effect in reducing 
the THD and the efficiency may still go up. For that 
the input and the output filter circuits should be 
designed accordingly. 
 
REFERENCES 
 
1. Karvelis, G. A. et al. (1998), A comparative 
evaluation of power converters used for current 
harmonics elimination, in Proc. IEEE HQP’98, 
pp. 227-232. 
2. Erickson, R. W. (1997), Fundamental of Power 
Electronics. New York: Chapmann & Hall. 
3. Bose, B. K. (1992), Recent advances in Power 
Electronics, IEEE Trans. Power Electron., vol. 
7, no.  1, pp. 2-16, Jan 1992. 
4. Prasad, A. R. et al. (1988), A comparative 
evaluation of SMR converters with and without 
active input current wave shaping, IEEE Trans. 
Ind. Electron., vol. 35, pp. 461-468, Aug. 1988. 
5. Bashi, S.M. et al. (2005), Three-phase Single 
Switch Power Factor Correction Circuit with 
Harmonic Reduction”, Journal of Applied 
Sciences, vol. 5, no. 1, pp. 80-84. 
6. Redl, R. et al. (1997), Power electronics 
polluting effects, IEEE Spectrum., vol. 34, no. 
5, pp. 32-39, May 1997. 
7. Wyk, J. D. V. (1993), Power Quality, Power 
Electronics and Control, in proceedings 
EPE.93, pp. 17-32, 1993. 
8. IEEE Recommended Practice and 
Requirements for harmonic Control on Electric 
Power Systems, (1992), IEEE Std. 519. 
9. Oscar, G. et al. (1999), An alternative to 
Supply DC Voltages with High Power Factor, 
IEEE Trans. on Industrial Electronics, vol. 46, 
no. 4, pp. 703-709, August 1999. 
10. Yang Z. and Sen P. C. (1998), Recent 
Developments in High Power Factor Switch–
mode Converters, in IEEE proceedings 
CCECE 98, pp. 477-480. 
11. Prasad, A. R. et al. (1990), A novel Passive 
wave-shaping method for single phase Diode 
Rectifiers, IEEE Trans. on Industrial 
Electronics, Vol.37, No.6, Dec.1990, pp. 521-
530. 
12. Yanchao, J. et al. (1996), An improved Passive 
Input Current Wave Shaping Method for 
Single-Phase Rectifier, Industrial Electronics, 
Control and Instrumentation, IEEE IECON, 
Vol. 2, 1996, pp 695-699. 
13. Sen, K. K. and Emanuel, A. E. (1987), Unity 
power factor single phase power conditioning, 
IEEE Power Electronics Specialist Conf, pp. 
516-524. 
14. Barbi, I. and Silva, S. (1990), Sinusoidal line 
current rectification at unity power factor with 
boost quasi-resonant converters, IEEE Applied 
Power Electronics Conf (APEC), pp. 553-562. 
15. Gyugyi, L. and Strycula, E. C. (1976), Active 
Ac power filters, Proc. IEEE/IAS Annual 
Meeting, pp 529-535. 
16. Prasad, A. R. et al. (1991), An Active Power 
Factor Correction Technique for Three Phase 
Diode Rectifiers, IEEE Trans. on Power 
Electronics, vol. 6, no. 1, pp. 83-92, January 
1991. 
17. Khan, M. A. et al. (2007), Design of a single 
phase rectifier with switching on AC side for 
high power factor and low total harmonic 
distortion, IEEE Region 5 Technical 
Conference, April 20-21, Fayetteville, AR, 
2007. 
Page 657
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Md.Walee Zaman,  
E-mail: olee.bd@gmail.com 
PROSPECT OF GRID CONNECTED SOLAR PV POWER PLANT IN 
BANGLADESH 
 
 
Md.Walee Zaman*, Mohammad Faisal, Abu Ruhul Kuddus and Md. Shahidul Quddus 
 
Department of Electrical and Electronic Engineering 
Bangladesh University of Engineering and Technology (BUET), Dhaka-1000, Bangladesh  
 
 
 
Bangladesh is situated between 20.30 - 26.38 degrees north latitude and 88.04 - 92.44 degrees east which is 
an ideal location for utilization of solar energy. Daily average solar radiation varies between 4kWh/m 2 to 
6.5kWh/m2. Average annual solar irradiance is nearly 1,900kWh/m2 which is sufficient to operate a grid 
connected solar photovoltaic (PV) power plant with a generation of megawatt (MW) ranges. Nowadays in 
Bangladesh approximately 40 MW of power is being produced form solar PV panels which includes only off 
grid stand alone systems. Still now there is no grid (11kV or above) connected PV power plant in 
Bangladesh. As there is no fuel cost in PV generation and it produces pollution free green energy with 
nominal maintenance cost, this can be an attractive choice to mitigate the power crisis in Bangladesh. But 
huge land requirement and large installation costs are the main drawbacks. In this paper we have described 
the prospect of large scale PV generation in Bangladesh to support the national grid along with costing and 
technical factors.  
 
Key words: photovoltaic; solar irradiance; grid connected; green energy; power crisis  
 
1. INTRODUCTION 
 
The fossil fuels used for generation of electricity 
are depleting fast. This is more applicable in case of 
Bangladesh. Although there is a rising hope that 
Bangladesh might discover sizable quantity of 
fossil fuel but that may not last long given the 
projected growth in economic activities. Thus the 
issue of sustainable development is gaining steady 
momentum. The renewable energies being 
inherently sustainable and environment friendly, 
are gaining popularity. All developed countries and 
many developing countries in their energy planning 
have included renewable energies as important 
sources of energy for the next century. Many 
countries are planning to develop renewable 
energies (PV, wind, hydro) to cover 10% to 40% of 
their energy needs within couple of decades. 
However, no such effort is seen in Bangladesh 
although Bangladesh has a good prospect in the 
field of solar technology. 
 
2. PV TECHNOLOGY OVERVIEW 
 
Solar energy is the radiant energy that the sun 
produces. This is the result of a process called 
nuclear fusion - the joining of smaller atoms to 
form a larger atom. 
 
Figure 1: electricity generation from photovoltaic 
device 
A solar cell or photovoltaic (PV) cell is a device 
that converts light into electric current using the 
photoelectric effect. The first solar cell was 
constructed by Charles Fritts in the 1880s.  Although 
the prototype selenium cells converted less than 1% 
of incident light into electricity, both Ernst Werner 
von Siemens and James Clerk Maxwell recognized 
the importance of this discovery. Following the 
work of Russell Ohl in the 1940s, researchers 
Gerald Pearson, Calvin Fuller and Daryl Chapin 
created the silicon solar cell in 1954.These early 
solar cells cost 286 $/watt and reached efficiencies 
of 4.5–6%. Nowadays there are varieties of solar 
cells with different technologies and efficiencies. 
A grid connected photovoltaic system is solar 
system where the output of the PV array is 
Page 658ISBN: 978-984-33-2140-4
 2 
 
connected to feed into the grid supply. Grid 
interconnection of photovoltaic (PV) power 
generation system has the advantage of more 
effective utilization of generated power. However, 
the technical requirements from both the utility 
power system grid side and the PV system side 
need to be satisfied to ensure the safety of the PV 
installer and the reliability of the utility grid. 
Clarifying the technical requirements for grid 
interconnection and solving the problems are 
therefore very important issues for widespread 
application of PV systems. 
 
 
Figure 2: grid connected PV system 
In a grid connected PV system, the DC power 
generated by the PV modules in the system is 
converted to AC by power conditioning unit 
(inverter) and fed into the local loads. Any excess 
solar power is supplied to the power line, and any 
shortfall is made up with grid electricity. During 
non sun hours, residence loads are supplied by 
utility grid alone. 
3. PRESENT POWER SCENARIO IN 
BANGLADESH 
 
At present Bangladesh has a requirement of about 
6,000 megawatts electricity but production hovers 
around 4,000 megawatts. [1] 
 
Bangladesh as a developing country has lowest 
coverage of electricity which stands around 32 per 
cent of the total population and the rural areas of 
Bangladesh, where 76 per cent of the population 
live, is seriously deprived of the electricity facility. 
The electrification rate of the country is now 42% 
but the rural areas are not as developed as the urban 
areas seeing that their electrification rate is only 
23% (against 79% or urban areas)[2]. Bangladesh 
has a large unsatisfied demand for commercial 
energy with most of the supply limited to urban 
areas. 
 
Different types of power plants generate electricity 
and synchronize it with the national grid. There are 
some isolated diesel power stations at remote places 
and islands which are not connected with the 
National Grid. Terminal voltages of different 
generators are 11 kV, 11.5 kV and 15.75 kV. In the 
Eastern Zone (eastern side of river Jamuna), 
electricity is generated from indigenous gas and a 
small percentage through hydro power. In the 
Western Zone, Coal and imported liquid fuel is 
used for generation of electricity. 
 
 
 
Figure 3: installed capacity by fuel type [1] 
 
The fuel cost per unit generation in the Western 
Zone is much higher than that of the Eastern Zone. 
Therefore, as a policy, low cost electricity 
generated in the Eastern Zone is transferred to the 
Western Zone through the 230 kV East-West Inter 
connector transmission line.[1] 
 
Bangladesh is now passing through a crisis period 
when short supply of power and energy seriously 
hampers production in agriculture and industry. The 
country almost entirely depends on conventional 
sources of energy like gas, oil and diesel to meet its 
energy demand. But imported oil is too costly and 
gas reserve is depleting day by day. This situation 
demands harnessing other energy resources among 
which solar energy is a vital one. 
 
4. RENEWABLE ENERGY CONSUMPTION 
 
The most viable sources of renewable energy in the 
country are solar, wind, biomass and biogas 
Nowadays in Bangladesh approximately 40 MW of 
power is being produced form solar PV panels 
which includes only off grid stand alone systems 
and mini grid systems(connected to the low level 
transmission line)[3]. At present contribution of 
solar and wind energy in electricity generation is 
only 0.9%. 
Although Solar Home Systems (SHS) are now 
gradually becoming popular in Bangladesh and 
Page 659
 3 
 
have obtained good dimension, grid-connected PV 
systems can be good power sources in cities and in 
remote areas where power generation in the 
existing grid is needed to be increased. 
 
 
 
Figure 4: renewable energy share in electricity 
generation 
 
There are different organizations, entrepreneurs 
implementing solar energy program in Bangladesh 
which includes Solar Home System(SHS), 
Centralized ( AC) System, Centralized(AC) market 
electrification,  water pumping, rural clinic, roof 
top PV mini-grid system, telecommunications, 
railway signaling, refrigeration, cyclone shelters 
etc, ICT training centers, community places etc. 
But still now there is no grid (11kV or above) 
connected PV power plant in Bangladesh. 
 
 
4. PV POWER PLANT: PERSPECTIVE 
BANGLADESH 
 
Bangladesh is situated between 20.30 - 26.38 
degrees north latitude and 88.04 - 92.44 degrees 
east which is an ideal location for solar energy 
utilization. Daily average solar radiation varies 
between 4 to 6.5 kWh per square meter. Maximum 
amount of radiation is available on the month of 
March-April and minimum on December-January. 
There is a good prospect of harnessing solar power 
in Bangladesh. Maximum amounts of radiation are 
available in the month of March-April and 
minimum in December-January. Solar energy 
resource study map has illustrated prospect of solar 
radiation in Bangladesh (Figure-5). 
 
The country's economy operates at low levels of 
commercial energy consumption, which is a crucial 
bottleneck to economic development. The country 
has nevertheless had an economic growth higher 
than 5% for a few years, which led to an increase of 
the electricity demand of 10% per year (around 500 
MW per year). But against current demand of about 
6000 MW estimated, an average of about 1,000MW 
has fallen short in capability out of 5823 MW 
installed capacity due to old age. Additionally, 
about 1,300 MW has fallen short in availability due 
to lack of maintenance and shortage of gas supply. 
 
Figure 5: Global radiation values for different 
locations have been estimated from the measured 
and estimated values of sunshine duration 
 
 
 
Under these circumstances, the Government of 
Bangladesh (GoB) launched the REREDP 
(Renewable Energy Research & Development 
Program) to provide remote rural populations with 
electricity through grid extension and Solar Home 
Systems (SHS). As there is no fuel cost in PV 
generation and it produces pollution free green 
energy with nominal maintenance cost, this can be 
an attractive choice to mitigate the power crisis in 
Bangladesh. 
 
Grid-connected PV power systems are being 
installed in cities in different countries of the world. 
Government policies are being framed to encourage 
and popularize this system by providing necessary 
regulations and incentives in many developed and 
developing countries. From the gradual decrease of 
prices and increased rate of installation of the 
systems in the cities all over the world it can be 
easily comprehended that this system will become 
an important source of electricity in a very short 
time in the urban areas. Currently Bangladesh is 
experiencing the acutest load shedding in its 
Page 660
 4 
 
history. Solar PV power plant can minimize this 
crisis by producing green energy. 
 
 
5. COSTING & OTHER FACTORS 
 
Like any commodity, the electricity price of a PV 
system depends on costs of the individual 
components, transportation and installation costs. 
There may also be associated costs of designing the 
system and purchasing land (particularly for large-
scale projects). In a PV system, the capital cost 
determines the production costs of the generated 
solar power. No cost is incurred for fuels and there 
is a nominal running cost. The total price is very 
difficult to define because it varies with application, 
size of system and location. 
 
installation
 cost 11%
operating 
cost 10%
replacement 
cost 13%
other cost 
6%
capital cost 
60%
 
 
Fig: distribution of cost for a typical grid-connected 
PV system 
 
PV pricing has fallen 40% in 2 years. The trend of 
PV system costing is shown bellow- 
 
 
Fig 6: solar technology costing in future [5] 
The cost of electricity generation from solar is 
higher till now compared to the other conventional 
fuels but it is a source of clean energy from an 
environmental viewpoint. So power utility 
company can introduce green pricing. 
6. CASE STUDY: TYPICAL 
STATISTICS OF A 1 MW SOLAR PV 
POWER PLANT 
Annual Irradiance  1900kWh\m2 
Electricity Output 1 MWp 
Land Required 5 acres(maximum) 
Investment Cost $7 millions 
Maintenance Cost 2% of investment cost 
Life time 25 yrs 
Output Voltage 11kV 
Table 1: features of 1MWp solar PV plant [6] 
 
 
6. ENVIRONMENTAL BENEFITS 
 
Almost all energy production and use involves 
some form of pollution of our environment. Each 
different source of energy, from fossil fuels to 
nuclear, pollutes in a different way and to a 
different degree. 
 
Global warming is caused by the tendency for some 
gases like carbon dioxide which trap heat in the 
earth's atmosphere. This seems to be causing a 
gradual increase in the average world temperatures, 
melting of the ice caps, rising ocean levels, and 
changes in weather patterns. Pollutants such as 
nitrous oxides help to create smog and haze, and 
make it difficult for elderly people and people with 
lung problems to breathe. All these pollutants are 
emitted from conventional power plants. 
 
 
 
Figure 7 :CO2 emission by different fuels (total CO2 
emission 29382 Mt) [7] 
Solar Power uses the sun to produce 
electricity. This does not produce any pollution. No 
other energy can be as environment-friendly as the 
solar energy. This natural resource does not pollute 
the air when being converted into electricity by 
solar panels or other thermal devices. A solar power 
Page 661
 5 
 
plant allows a reduction of up to10 tons CO2 per 
kWp. [4] 
7. CONSTRAINTS 
 
The major obstacles to rapid expansion of PV 
systems in Bangladesh are as follows: 
 
 The main hindrance is the high installation 
cost of PV system due to high price of the 
PV module in international market. Huge 
land requirement is another problem.  
 The lack of awareness about the PV 
technology. 
 Absence of proper planning and design 
 Less financial incentives from the 
government 
 
 
8. CONCLUSION 
 
Grid electrification is essential for economic 
development in Bangladesh. There are more than 
87,000 villages in Bangladesh and most of them are 
not connected to the national grid. At the same 
time, the country has very limited fossil fuel reserve 
for electricity generation. PV grid electricity 
generation system could be effective to extend the 
grid connection and available power for all. It is 
found that the per unit electricity production cost 
from the PV system is cost-competitive with grid-
connected diesel power generation. If clean 
development mechanisms, carbon tax and oil price 
increase are considered, the unit cost would be 
lower than the grid connected diesel power 
generation. Due to the high initial investment cost 
of PV grid system, there should be favorable 
policies for this sector. The instruments that can be 
applied to encourage renewable energy 
technologies promotion are incentives, consumer 
credit schemes, capacity building and to establish a 
renewable energy service authority. So it is high 
time the Government of Bangladesh should take 
necessary steps and provide proper facilities for 
green electrification in Bangladesh. 
 
 
REFERENCES 
 
1 ‘Key Statistics’ BANGLADESH POWER 
DEVELOPMENT BOARD (BPDB) 
<http://www.bpdb.gov.bd> 
2 Philippe GAENG (PlaNet Finance, France), 
Intelligent Energy – Europe (IEE) 
COOPENER- Reinforcing provision of 
sustainable Energy services in Bangladesh and 
Indonesia for Poverty alleviation and 
sustainable Development  
3 Renewable Energy & Environmental 
Information Network (REEIN), Dhaka, 
Bangladesh 
<http://www.reein.org> 
 
4  Key world energy statistics 2010, International 
Energy Agency (IEA) 
<http://www.iea.org> 
 
5 S.Krauter, R.Ruther- Considerations for the 
calculation of green house gas reduction by 
photovoltaic solar energy 
 <http://www.elsevier.com/locate/renene> 
 
6 M. A. H. Mondal, A. K. M. Sadrul Islam -
Techno-economic Feasibility of Grid 
Connected Solar PV System in Bangladesh 
 
7 N. Noor, S. Muneer-Concentrating Solar 
Power (CSP) and Its Prospect in Bangladesh 
8    Are Solar Thermal Power Plants Doomed? 
       Greentech solar technology 
       <http://kanellos.greentechmedia.com> 
        
9    A.Chowdhury -May 5, 2010/TI 
      Solar energy: Its prospects in Bangladesh 
 
Page 662
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Md. Imran Momtaz,  
RADIATION FROM A LARGE CIRCULAR LOOP ANTENNA FOR A 
SERIES OF FOURIER HARMONIC CURRENT DISTRIBUTION 
 
 
Md. Abdul Matin, Samiul Hayder Choudhury and Md. Imran Momtaz 
Department of Electrical and Electronic Engineering 
Bangladesh University of Engineering and Technology 
amatin@eee.buet.ac.bd, samiulhayder@ymail.com, imranmomtaz@eee.buet.ac.bd 
 
 
It has been a challenging problem since long to determine analytically the properties of a large circular loop 
antenna.  A large circular loop antenna cannot maintain a uniform current distribution.  In this paper the 
radiation pattern of a large circular loop antenna has been calculated using a Fourier series of harmonic 
current distribution resembling that used by Pocklington. The results have good qualitative agreement with 
those obtained by different recent numerical methods. 
 
Key words: Bessel function, intensity pattern, loop radius, non-uniform current distribution, 3D pattern. 
 
1. INTRODUCTION 
 
It is long well-known that for very small loops the 
current is almost constant, greatly simplifying the 
derivation of the radiated field expressions [1]. As 
the loop radius increases, the current distribution 
becomes initially sinusoidal [2], and finally 
incorporates a large number of Fourier modes [4-
11]. Then it arises a question of convergence of the 
resulting series. In this paper the far fields are 
calculated by using the current distribution obtained 
by [2]. The far fields are obtained in Fourier-Bessel 
series in a novel form which converges rapidly. 
 
2. FORMULATION OF THE 
PROBLEM 
 
The geometry of the problem is shown in Figure 1. 
A thin conducting circular loop lies in the xy-plane. 
The current flows from Φ=00 to Φ=3600. 
 
The general expression of the vector magnetic 
potential at an arbitrary observation point (x,y,z) be 
[3]: 
ld
R
e
zyxIzyxA
C
jkR
e
′′′′= ∫
−
),,(
4
),,(~
pi
µ
     (1) 
 
 
where,  
+′′′=′′′ ),,(ˆ),,( zyxIazyxI xxe            (2) 
),,(ˆ),,(ˆ zyxIazyxIa zzyy ′′′+′′′  
 
 
Fig. 1: Geometry of the circular loop antenna 
Here, the source coordinates are designated as 
primed and the observation coordinates are 
designated as unprimed. In dealing with Now, the 
current components can be converted from 
Cartesian (x,y,z) to cylindrical (ρ,Φ,z) coordinate by 
using the following formulae: 
 
φφ φρ ′−′= sincos III x
            (3) 
 
 
Page 663
  
φφ φρ ′+′= cossin III y
                    (4) 
zz II =
                                              (5) 
 
The unit vectors can be converted from Cartesian to 
spherical coordinate by utilizing the following 
formulae: 
φφθφθ φθ sinˆcoscosˆcossinˆˆ aaaa Rx −+=
  (6) 
φφθφθ φθ cosˆsincosˆsinsinˆˆ aaaa Ry ++=
  (7) 
θθ θ sinˆcosˆˆ aaa Rz −=
                                 (8) 
 
Using the above equations, the expression for 
current becomes 
{ }ˆ sin cos( ) sin sin( ) cose R zI a I I Iρ ϕθ ϕ ϕ θ ϕ ϕ θ′ ′= − + − +
{ }ˆ cos cos( ) cos sin( ) sinza I I Iθ ρ ϕθ ϕ ϕ θ ϕ ϕ θ′ ′+ − + − −
{ }ˆ sin( ) cos( )a I Iϕ ρ ϕϕ ϕ ϕ ϕ′ ′+ − − + −       (9) 
Since the current is flowing in the φ ′ -direction, 
therefore the above equation is reduced to, 
ˆ ˆsin sin( ) cos sin( )e RI a I a Iϕ θ ϕθ ϕ ϕ θ ϕ ϕ′ ′= − + −
ˆ cos( )a Iϕ ϕ ϕ ϕ ′+ −                                          (10) 
 
The distance R can be expressed as, 
 
)cos(sin222 φφθ ′−−+= ararR
     (11) 
and                   dl adϕ′ ′=                              (12) 
 
Using equations (10), (11) and (12), the spherical 
components of A
~
 become, 
 
φ
φφθ
φφ
pi
µ pi φφθ
φφ ′
′
−−+
′
−= ∫
′
−−+−
d
arar
eIaA
ararjk2
0
22
)cos(sin2
)cos(sin2
)cos(
4
22
(13) 
2 22 2 sin cos( )
2 2
0
sin cos( )
4 2 sin cos( )
jk r a ar
R
a eA I d
r a ar
pi θ ϕ ϕ
ϕ
µ θ ϕ ϕ ϕ
pi θ ϕ ϕ
′
− + − −
′ ′= −
′+ − −
∫
(14) 
                    
2 22 2 sin cos( )
2 2
0
cos cos( )
4 2 sin cos( )
jk r a ar
a eA I d
r a ar
pi θ ϕ ϕ
θ ϕ
µ θ ϕ ϕ ϕ
pi θ ϕ ϕ
′
− + − −
′ ′= −
′+ − −
∫
(15) 
 
The harmonic current distribution to be used here is 
based upon Fourier Analysis [2] having 
resemblance with that obtained by Pocklington [4] . 
It is expressed as  
∑
∞
=
′+=
1
0
00 )cos()(2
sin4)(
υ
υφ φυυ
υpi
pi
kaJIkaJII
 (16) 
Figure 2 represents the numerical plot of IΦ as a 
function of Φ for different values of the electrical 
length, ka of the loop. Figure 3 represents the 
numerical plot of I as a function of ka for different 
values of the azimuthal angle, Φ =00 and Φ =1800. 
 
Fig. 2: Numerical current distribution along the 
circular loop 
 
 
Fig. 3: Numerical current distribution for different 
values of the electrical length, ka at the feed point 
at Φ = 0 and at the opposite point at Φ=180o 
 
For large circular or large circular loop, the distance 
R can be approximated for far field region as, 
  
)cos(sin22 φφθ ′−−≈ arrR
              (17) 
for  ( ar >> ) 
Using binomial expansion, ultimately we have,  
sin cos( )r a
R
r
θ ϕ ϕ′− −
≈ 

                  (18) 
The term sin cos( )r a θ ϕ ϕ ′− −  is considered 
for phase and r   is considered for amplitude. 
Replacing the value of Iϕ and R, we have, 
2
sin cos( )0 0
0
( )
cos( )
4
jkr
jkaaI J ka eA e d
r
pi
θ ϕ ϕ
ϕ
µ ϕ ϕ ϕ
pi
−
′−
′ ′≈ −∫     
2
sin cos( )0
2
1 0
sin
2 ( ) cos cos( )
jkr
jkaaI e J ka e d
r
pi
θ ϕ ϕ
υ
υ
υpi
µ
υϕ ϕ ϕ ϕ
pi υ
− ∞
′
−
=


′ ′ ′+ × − 


∑ ∫
  (19) 
 
Now, the Bessel function has the following useful 
properties [2], 
{ }2 cos( ) 1 11 1
0
cos cos( ) ( ) ( ) cosjp n nn nn e d j J p j J p n
pi
β αα β α α pi β− + −+ −− = +∫
 (20) 
Page 664
  
{ }2 cos( ) 1 11 1
0
cos sin( ) ( ) ( ) sinjp n n
n n
n e d j J p j J p n
pi
β αα β α α pi β− − +
− +− = −∫
 (21) 
∫ =−
−
pi
αβ piααβ
2
0
1
)cos( )(2)cos( pJjde jp
     (22) 
∫ =−
−
pi
αβ ααβ
2
0
)cos( 0)sin( de jp
                     (23) 
Using the above formulae we have, 
0 0 1( ) ( sin )
2
jkr
aI J ka J ka eA j
r
ϕ
µ θ −
≈         (24) 
 {0 11 ( ) ( sin )
odd
jkraI e J ka J ka
r
υ υ
υ
µ θ
pi υ
−
+− ∑  
 }1( sin ) cosJ kaυ θ υϕ−−  
Similarly, we can obtain, 
0 sin 1 ( )
odd
jkr
R
aI eA J ka
r
υ
υ
µ θ
pi υ
−
≈ ∑              (25) 
 { }1 1( sin ) ( sin ) sinJ ka J kaυ υθ θ υϕ− ++  
0 cos 1 ( )
odd
jkraI eA J ka
r
θ υ
υ
µ θ
pi υ
−
≈ ∑              (26) 
 { }1 1( sin ) ( sin ) sinJ ka J kaυ υθ θ υϕ− ++  
 
Now, for far field region, the electric and magnetic 
field components [3] can be approximated as, 
0≈RE
      (27) 
θθ ωAjE −≈
      (28) 
0 cos 1 ( )
odd
jkrk aI ej J ka
r
υ
υ
η θ
pi υ
−
= − ∑  
{ }1 1( sin ) ( sin ) sinJ ka J kaυ υθ θ υϕ− ++  
 
φφ ωAjE −≈
         (29) 
0 0 1 0( ) ( sin ) 1 ( )
2
odd
jkr jkrk aI J ka J ka e k aI ej J ka
r r
υ
υ
η θ η
pi υ
− −
= + ∑
{ }1 1( sin ) ( sin ) cosJ ka J kaυ υθ θ υϕ+ −−  
0≈RH
                                                     (30) 
 
η
φ
θ
E
H −≈
                                                     (31)    
η
θ
φ
EH ≈
                                                   (32)                                          
where, η  is the intrinsic impedance of the medium. 
Therefore we have the average power density, 
[ ]∗×= HEWav ~~Re21~
 
                                  [ ] RrR aWaEE ˆˆ21 22 =+= φθη
 
where, 
221
2r
W E Eθ ϕη
 
= +  
                             (33) 
Finally, the radiation intensity can be found from, 
rWrU
2
=
                         (34) 
 
3. NUMERICAL RESULTS 
 
The numerical results of U are shown in 
Figures 4-8 for different values of the electrical 
length, ka.  
 
Fig. 4: 3D radiation pattern of a large circular loop 
antenna for  ka=0.314 
 
Fig. 5: 3D radiation pattern of a large circular loop 
antenna for ka=1.00 
Page 665
  
 
Fig. 6: 3D radiation pattern of a large circular loop 
antenna for ka=1.5 
 
 
Fig. 7: 3D radiation pattern of a large circular loop 
antenna for  ka=5.0 
 
Fig. 8: 3D radiation pattern of a large circular loop 
antenna for  ka=7.0 
 
Diverse radiation patterns are observed for 
different values of ka. For ka=1.0 and 1.5, 
almost omnidirectional pattern is observed. 
The results have qualitative agreement with 
those obtained in [5-12]. 
 
4. CONCLUSION 
 
Far field radiation pattern of a large circular loop 
antenna has been obtained by using a non-uniform 
harmonic current distribution. 3D radiation patterns 
for ka= 0.314, 1.0, 1.5, 5.0 and 7.0 has been 
obtained by straightforward numerical calculation 
of the radiation intensity pattern. The far field has 
been obtained in Fourier Bessel series converging 
rapidly for υ upto 21. The general feature is omni-
directional power pattern upto ka=2.0. Above this 
value, side lobes are observed. 
 
REFERENCES 
 
1. D. Foster, “Loop antennas with uniform 
current,” in Proc. IRE, vol. 32, 1944, pp. 603–
607. 
2. Matin M. A., and Shaha B. K., “Current 
Distribution of a Circular Loop Antenna” 
Electrical Engg. Research Bulletin, BUET, 
Vol. 5, pp. 8 -12 1989. 
3. Ballanis, C.A., “Antenna theory: analysis and 
design”, Wiley, New York, 1997, 2nd Edition 
4. Pocklington H.C., “Electrical Oscillation in 
Wires”, Cambridge Philosophical Society 
Proceedings, London, England, vol. 9, 1897, p. 
324 
5. Li L.-W., Lim C.-P., and Leong M.-S., 
“Method of moments analysis of electrically 
large circular loop antennas: nonuniform 
currents,” Proc. Inst. Elect. Eng.-Microw. 
Antennas Propag., vol. 146, no. 6, pp. 416–
420, Dec. 1999. 
6. G. Zhou and G. S. Smith, “An accurate 
theoretical model for the thin wire circular 
half-loop antenna,” IEEE Trans. Antennas 
Propag., vol. AP-39, no. 8, pp. 1167–1177, 
Aug. 1991. 
7. W. C. Chew, J.-M. Jin, E. Michielssen, and J. 
Song, Eds., Fast and Efficient Algorithms in 
Computational Electromagnetics. Boston, MA: 
Artech House Publishers, 2001. 
8. Wilson, G, Jones, W & Baker, S. Renewable 
Energy Systems. Journal of Sustainability. Vol 
6. ,pp. 8-16,  May 2002. 
9. LI, L.W., Leong, M.S., Kooi P.S., and Yeo, 
T.S.: “Exact solution of electromagnetic fields 
in both near and far zones radiated by thin 
circular-loop antennas:  a general 
representation”, IEEE Trans., 1997, AP-45, pp. 
1741-1748 
10. Werner, D.H.: “Analytical and numerical 
methods for evaluating electromagnetic field 
Page 666
  
integrals associated with current- carrying 
wires antennas” in Barrett, T.W., and Grimes, 
D.M. (Eds.): “Advanced electromagnetism: 
foundations, theory and applications” World 
Scientific, Singapore, 1995, pp. 682-762 
11. Hristos T. Anastassiu, “Fast, Simple and 
Accurate Computation of the Currents on an 
Arbitrarily Large Circular Loop Antenna” 
12. Shastri S., Shah K. and Shekhar R., “Modified 
Circular Polarized Loop Antenna”, 
Proceedings of International Conference on 
Microwave, 2008, Thakur College of 
Engineering And Technology, Kandivli(East) 
Mumbai 400069, Maharashtra, India. 
 
Page 667
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
*
 Corresponding Author: Kalyan Kumar Halder,  
E-mail: kalyan_kuet@yahoo.com    
 
RECURRENT NEURAL NETWORK BASED COST EFFECTIVE 
FOUR SWITCH THREE PHASE INVERTER FED SYNCHRONOUS 
RELUCTANCE MOTOR DRIVE 
 
 
Kalyan Kumar Halder*, Md. Jahedul Islam and Md. Mejbaul Haque  
Department of Electrical & Electronic Engineering 
Khulna University of Engineering & Technology, Bangladesh. 
 
B. C. Ghosh 
  Department of Electrical & Electronic Engineering 
American International University-Bangladesh, Bangladesh. 
 
 
Abstract: This paper proposes a cost effective position sensorless control methodology for Synchronous 
Reluctance Motor (SynRM) drive. In this control scheme, instead of a conventional Six Switch Three Phase 
(SSTP) inverter a Four Switch Three Phase (FSTP) inverter is used. This improves the cost-effectiveness, 
volume-compactness and reliability of the three phase inverters. The control system estimates the motor 
stator flux and its position using a Recurrent Neural Network (RNN). A simulation model of the drive 
system is developed and analyzed in order to validate the proposed approach. The robustness of the drive 
system is tested for different operating conditions. Simulation results show that the proposed drive system 
provides a fast speed response and good disturbance rejection capability. 
  
Key words: Four switch three phase inverter; flux estimation; recurrent neural network; sensorless control; 
and synchronous reluctance motor. 
 
1. INTRODUCTION 
 
In recent years, Synchronous reluctance motors are 
becoming popular due to their inherent advantages 
such as low cost, mechanical simplicity and robust 
structure. A SynRM is superior to an Induction 
Motor (IM) due to the absence of rotor copper 
losses, to brushless motor due to economical rotor 
structure. Thus these motors are gaining increasing 
interest as a possible alternative of other ac motor 
drives (Litvinov and Davydenko, 2010). SynRM 
has salient poles without any winding or permanent 
magnet on the rotor. The flux linkage of the 
SynRM is directly proportional to the stator 
currents as the rotor circuit of the motor is opened. 
Thus, the torque of a SynRM can be controlled by 
controlling the stator currents [Chiang et al., 2003]. 
Besides, the motors operate at synchronous speed 
so they need simple controller than any other AC 
machines (Mostafa and Dawo, 2009).   
 
Driving a SynRM requires the rotor position 
information to control the motor torque which is 
generally detected by position sensors such as an 
encoder or a resolver. But these position sensors not 
only increase the cost of the drives but also 
decrease the system reliability. Therefore, many 
papers on position sensorless drive of SynRM have 
been published.  
 
An Adaptive Input–Output Feedback-Linearization 
(AIOFL) controller has been designed in (Zarchi et 
al., 2010) for maximum rate of change of torque 
control of an encoderless three phase SynRM drive. 
Variable structure control strategy using the sliding 
mode technique has been the focus of many studies 
for sensorless SynRM control. The application of 
sliding mode controller is proposed in (Mostafa and 
Dawo, 2009) for robust speed control of 
Synchronous reluctance motor drive. A sliding 
mode controller based on Gaussian radial basis 
function neural network is utilized in (Chen et al., 
2009) for SynRM system robust stabilization. In 
(Hofmann and Sanders, 2000), the authors 
developed a refined design of a high-speed SynRM 
drive with minimized eddy-current losses in the 
rotor. The authors also proposed position sensorless 
vector control strategy based on stator flux 
estimation (Hofmann et al., 2004).  
 
Page 668
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
  
Nowadays, many research and development 
projects have been also developed to reduce the 
cost of the power converter.  The conventional 
SSTP inverter was popular since the last few 
decades. But these inverters have some 
disadvantages such as losses in the six switches, 
complexity of the control algorithms and generating 
six PWM logic signals. So researchers are working 
to find out a substitute of the SSTP inverter. In 
(Saravanasundaram and Thanushkodi, 2008), an ac 
to ac converter with least amount hardware is 
proposed for three-phase IM drive. A cost effective 
FSTP inverter is proposed for IM drive in (Uddin et 
al., 2006). The authors showed a performance 
comparison of the FSTP inverter fed drive with 
SSTP inverter fed drive in terms of speed response 
and total harmonic distortion of the stator current. 
The same authors proposed fuzzy logic controller 
based control scheme for FSTP fed interior 
permanent magnet (IPM) synchronous motor drive 
(Uddin et al., 2006). A vector control technique for 
IM using FSTP inverter is presented for high 
performance industrial drive systems in (Dzung et 
al., 2007). The authors verified the complete vector 
control scheme by simulation and experimentally in 
a DSP environment. A RNN based stator flux and 
position estimator is proposed in (Halder and 
Ghosh, 2010) for sensorless control of a FSTP fed 
interior permanent magnet synchronous motor 
drive. The authors showed that with the RNN, 
accurate estimation is possible both under transient 
and steady-state conditions.  
 
This paper considers two ideas to reduce the cost of 
the SynRM drive system; the first one is to reduce 
the inverter size and the other is to eliminate the 
need for position sensor. The performance of the 
proposed cost effective position sensorless SynRM 
drive has been investigated through simulation 
studies. The close loop vector control scheme of the 
drive system has been simulated in C++ 
environment. The hysteresis controller is used to 
control the motor current so that it can follow the 
command current as close as possible to the 
sinusoidal reference. The performances of the drive 
system have also been studied for sudden change of 
load torque and speed reversal conditions. 
 
2. SYNCHRONOUS RELUCTANCE 
MOTOR MODEL  
 
A mathematical model of the SynRM is required 
for proper simulation of the system. The dynamic 
model which describes the behavior of the SynRM 
in the synchronously rotating d-q reference frame 
can be expressed as follows  (Mostafa and Dawo, 
2009): 
qqr
d
ddsd iLdt
di
LiRv ω−+=               (1)                          
                                     
ddr
q
qqsq iLdt
di
LiRv ω++=               (2)          
                               
Where the vd and vq are d- and q- axis terminal 
voltages, respectively. The id and iq are, 
respectively, d- axis and q- axis torque producing 
currents. The Ld and Lq are the d- and q- axis 
synchronous inductances, respectively. The Rs is 
the stator resistance and ωr is the angular speed of 
the rotor. 
 
The developed electromagnetic torque is given as: 
qdqd
p
e iiLL
P
T )(
2
3
−=   (3)                                                                                                             
The mechanical motion of the SynRM can be 
expressed as: 
mm
m
mLe Bdt
d
JTT ω
ω
++=    (4)                                                                                                         
and 
mpr p ωω ⋅=                                      (5)                                                                      
Where Pp, TL, Jm, ωm, and Bm are the number of 
pole pairs, the load torque, the moment of inertia of 
rotor, the mechanical speed of rotor, and the 
viscous friction coefficient, respectively.        
 
3. FOUR SWITCH THREE PHASE 
INVERTER MODEL 
 
Fig. 1 shows the power circuit of four switch 
inverter fed SynRM drive. A three phase system is 
obtained by connecting the phase ‘c’ terminal of the 
stator windings directly to the centre tap of the dc 
link capacitors. The single phase ac supply is 
rectified by the front-end rectifier. The capacitors 
are used to level the output dc voltage. If Vdc is the 
maximum voltage across the dc link capacitors, and 
Sa, Sb are the states of power switches for each 
phase, then three phase voltages of the SynRM can 
be expressed as follows (Uddin et al., 2006):  
  
 [ ]124
3
−−= ba
dc
a SS
V
V           (6)                                                                   
  
 [ ]124
3
−−= ab
dc
b SS
V
V           (7)                                                            
  
 
[ ]1
3
2
+−−= ba
dc
c SS
V
V          (8)                                                           
       If  Sa =1 then T1 is on and T2 is off;   
If  Sa =0 then T1 is off and T2 is on; 
       If Sb =1 then T3 is on and T4 is off;  
  If  Sb =0   then T3 is off and T2 is on. 
Page 669
  
  
Fig. 1: Power circuit of the drive system. 
 
4. PROPOSED CONTROL SCHEME  
 
The proposed control scheme of the drive system is 
shown in Fig. 2. The high performance control 
strategy is implemented in closed loop using PI 
controller. This requires speed error to be processed 
in closed loop to generate the torque producing 
component of the stator current, iq*. The 
magnetizing component of the stator currents id* 
along with iq* are used to generate the reference 
currents ia*, ib*, and ic*. Two independent 
hysteresis current controller with a suitable 
hysteresis band are used to command the motor 
currents ia, and ib to follow the reference currents. 
The hysteresis controllers also generate four 
switching signals which will fire the power 
semiconductor switches of the three phase inverter 
to produce the actual voltages to the motor.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
The reference currents are formulated as follows:   
θθ sincos *** qda iii −=                                (9)                                                                                
)120sin()120cos( 0*0** −−−= θθ qdb iii     (10)                                                                                    
)120sin()120cos( 0*0** +−+= θθ qdc iii     (11)  
The stationary 3-axes (a-, b-, c-) to stationary 2-
axes (α-, β-) transformation is given by 
 
cbas xxxx 5.05.0 −−=α                    (12)                                                                 
)(
2
3
cbs xxx −=β                               (13)                                               
Where, x is either voltage or current vector. 
  
5. RNN BASED STATOR FLUX 
ESTIMATION 
 
The recurrent neural network is a single layer 
neural network with input and output nodes. The 
output nodes act as summing nodes and in this 
study the two output variables, i.e., α- and β- 
components of stator flux linkage are fed to the 
input with unit delay operator. The value of 
activation function at the output node is taken unity. 
The common inputs for both the outputs are α- and 
β- components of stator voltage and current which 
results in the following matrix equation: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
FSTP 
Inverter 
ic ib 
SynRM 
Front-end 
Rectifier 
 
 
ωref 
Flux  
Program 
PI  
Controller 
Vector 
Rotator 
Speed Transducer 
RNN Flux 
and Angle 
Estimator 
id* 
iq* 
θ 
ωm 
Σ 
 
- 
+ ia
*
 
ib* 
ia 
      Clarke 
Transformation 
Hysteresis 
Current 
Controller 
Sa 
iαs 
iβs 
AC  
Sb 
Vdc 
vαs 
vβs 
Fig. 2: Proposed Control Scheme of the SynRM. 
 
Page 670
  
+











=





+
+
)(
)(
)1(
)1(
2221
1211
k
k
WW
WW
k
k
s
s
s
s
β
α
β
α
λ
λ
λ
λ
+











s
s
v
v
WW
WW
β
α
2423
1413












s
s
i
i
WW
WW
β
α
2625
1615
     (14)                     
The inputs are connected to the output node 
through the weights W11, W12, W21, W22 etc. as 
indicated by the line segments and shown in Fig. 3. 
Each output node is also connected to the 
corresponding recurrent input node through 
weights. The weights indicated by the different line 
segments are adjusted by training the neural 
network. 
Estimated angle of reference pole,  








=
−
s
s
α
β
λ
λ
θ 1tan                                     (15)                                      
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 3 Stationary α- and β- axis stator flux 
estimation by recurrent neural network 
 
6. SIMULATION RESULTS 
 
The objective of computer simulation is to verify 
the control strategy proposed in this study for 
different operating situations. The prototype 0.37 
kW SynRM used in this drive system is a three 
phase machine, the parameters of which are 
reported in Table 1. 
 
Table 1: SynRM specifications used for simulation  
 
Number of pole pair: PP 1 
 Stator resistance: Rs 4.2 Ω 
 d-axis inductance: Ld 0.328 H 
 q-axis inductance: Lq 0.181 H 
 Motor inertia: Jm 0.00076 kg-m2 
Friction coefficient: Bm 0.00012 N-
m/rad/sec 
 
 
6.1 Starting Performance of the SynRM 
Drive 
The effectiveness of the proposed flux estimator 
along α- and β- axis needs to be verified before 
implementing it in the drive system. Real flux 
components calculated from exact values of motor 
variables are computed and compared with the 
estimated flux components and rotor angle. Fig. 4 
(a) & (b) show the estimated α- and β- axis stator 
flux respectively. It can be noted that accurate 
estimation is possible by the proposed recurrent 
neural network under both transient and steady-
state conditions. Fig. 4 (c) shows the estimated 
angle which follows very closely the actual angle 
deduced from machine model. 
 
 
 
 
Fig. 4 (a) α-axis components of estimated and 
actual flux, (b) β-axis components of estimated and 
actual flux, and (c) Estimated and actual rotor angle 
for the SynRM drive. 
0.00 0.05 0.10 0.15 0.20
-2
-1
0
1
2
α
-
ax
is 
flu
x
 
(W
eb
er
)
Time (Second)
 Actual
 Estimated
0.00 0.05 0.10 0.15 0.20
-2
-1
0
1
2
β-a
x
is 
flu
x
 
(W
eb
er
)
Time (Second)
 Actual
 Estimated
0.00 0.05 0.10 0.15 0.20
-2
0
2
4
6
8
10
Th
et
a 
(R
ad
ia
n
)
Time (Second)
 Actual
 Estimated
 iβs 
 
)1( +ksαλ  
1−z
1−z
+ 
+ 
• 
• 
vβs 
 
vαs 
 
iαs 
 
W11 
W
W21 
W1
2 W
13 
W1
 
W
)1( +ksβλ  
W1
 
W22 W23 W24 
W25 
W26 
(a) 
(c) 
(b) 
Page 671
  
6.2 Starting Performance of the SynRM 
Drive 
From standstill condition, the motor was started 
with a command speed of 100 rad/sec and load 
torque of 0.2 N-m. The motor reaches to the 
command speed at 0.06 second. Fig. 5 (a) shows 
the speed response of the SynRM drive. The motor 
follows the command speed accurately without any 
steady-state error and oscillations.  
 
 
 
Fig. 5 (a) Simulated speed response, (b) Developed 
electromagnetic torque, and (c) Three phase 
currents under transient and steady-state condition. 
 
Fig. 5 (b) shows the developed electromagnetic 
torque of the drive under starting condition. It is 
observed that higher electromagnetic torque is 
generated during the motor acceleration. Some 
oscillations in electromagnetic torque is noticed 
which is due to switching of the devices with 
hysteresis controller. Difference between developed 
and load torques is due to viscous damping torque 
of the drive system. Fig. 5 (c) shows the actual 
currents of the three phases respectively.  
 
6.3 Performance under Different Operating 
Conditions 
To verify the robustness of the proposed drive 
system, the performance of the SynRM drive was 
also investigated under different operating 
conditions. The load torque of the motor was 
suddenly increased from 0.2 N-m to 1.2 N-m at 0.5 
second. The corresponding speed response of the 
drive is shown in Fig. 6 (a). The speed slightly falls 
but no oscillation in speed is noticed due to this 
load torque disturbance. To examine the 
performance of the drive system under speed 
reversal condition, the command speed was 
reversed from 100 rad/sec to -100 rad/sec at 0.4 
second and again to 100 rad/sec at 0.8 second. Fig. 
6 (b) shows the corresponding speed response 
which confirms the robustness of the drive system. 
 
 
 
Fig. 6 Simulated speed response for (a) sudden 
change of load and (b) speed reversal condition. 
 
7. CONCLUSIONS 
 
A position sensorless vector control scheme with 
recurrent neural network for FSTP fed SynRM 
drive has been presented. The results obtained and 
presented in this work indicate that the proposed 
0.0 0.1 0.2 0.3 0.4 0.5
0
20
40
60
80
100
120
Sp
ee
d 
(R
ad
/se
c)
Time (Second)
 Reference speed
 Actual speed
0.0 0.1 0.2 0.3 0.4 0.5
-1
0
1
2
3
To
rq
u
e 
(N
-
m
)
Time (Second)
 Load torque
 Electromagnetic torque
0.00 0.03 0.06 0.09 0.12 0.15
-8
-4
0
4
8
A
ct
u
al
 
Cu
rr
en
ts
 
(A
m
pe
re
)
Time (Second)
 ia
 ib
 ic
0.0 0.2 0.4 0.6 0.8 1.0
0
20
40
60
80
100
120
Sp
ee
d 
(R
ad
/se
c)
Time (Second)
 Reference speed
 Actual speed
Load is suddenly increased here
0.0 0.3 0.6 0.9 1.2 1.5
-150
-100
-50
0
50
100
150
Sp
ee
d 
(R
ad
/se
c)
Time (Second)
 Reference speed
 Actual speed
(c) 
(b) 
(a) 
(b) 
(a) 
Page 672
  
control scheme produces very fast response of the 
SynRM drive. The drive also shows good 
performance in speed operation under the effect of 
load disturbances and reversal of speed. Thus this 
cost effective drive system fulfills the demand of 
present industry applications.   
 
REFERENCES 
 
1. Litvinov, B.V. and Davydenko, O.B. (2010), 
Synchronous Reluctance Motors with Lowered 
Magnetic Conductivity along Transverse Axis, 
Russian Electrical Engineering, 81(3), pp. 121-
125. 
2. Chiang, H.K., Tseng, C.H. and Hsu, W.L. 
(2003), Implementation of a Sliding Mode 
Controller for Synchronous Reluctance Motor 
Drive Considering Core Losses, Journal of the 
Chinese Institute of Engineers, 26(1), pp. 81-
86. 
3. Mostafa, A.F. and Dawo, E.A. (2009), Sliding-
Mode Control of Synchronous Reluctance 
Motor, International Journal of Electronics, 
Circuits and Systems, 3(2), pp. 91-95. 
4. Zarchi, H.A., Soltani, J. and Markadeh, G.A. 
(2010), Adaptive Input–Output Feedback-
Linearization-Based Torque Control of 
Synchronous Reluctance Motor without 
Mechanical Sensor, IEEE Transactions on 
Industrial Electronics, 57(1), pp. 375-384. 
5. Chen, C.A., Chiang, H.K., Lin, W.B. and 
Tseng, C.H. (2009), Synchronous Reluctance 
Motor Speed Drive Using Sliding Mode 
Controller Based on Gaussian Radial Basis 
Function Neural Network, Artificial Life and 
Robotics, 14, pp. 53–57. 
6. Hofmann, H. and Sanders, S.R. (2000), High-
Speed Synchronous Reluctance Machine with  
Minimized Rotor Losses, IEEE Transactions 
on Industry Applications, 36(2), pp. 531-539. 
7. Hofmann, H.F., Sanders, S.R. and Antably, 
A.E. (2004), Stator-Flux-Oriented Vector 
Control of Synchronous Reluctance Machines 
with Maximized Efficiency, IEEE 
Transactions on Industrial Electronics, 51(5), 
pp. 1066-1072. 
8. Saravanasundaram, S. and Thanushkodi, K. 
(2008), Compound Active Clamping Boost 
Converter-Three Phase Four Switch Inverter 
Fed Induction Motor, International Journal of 
Computer Science and Network Security, 8(8), 
pp. 358-361. 
9. Uddin, M.N., Radwan, T.S. and Rahman, M.A. 
(2006), Performance Analysis of a Cost 
Effective 4-Switch, 3-Phase Inverter Fed IM 
Drive, Iranian Journal of Electrical and 
Computer Engineering, 5(2), pp. 97-102. 
10. Uddin, M.N., Radwan, T.S. and Rahman, M.A. 
(2006), Fuzzy-Logic-Controller-Based Cost 
Effective Four-Switch Three-Phase Inverter-
Fed IPM Synchronous Motor Drive System, 
IEEE  Transactions on Industry Applications, 
42(1), pp. 21-30. 
11. Dzung, P.Q., Phuong, L.M., Binh, T.C. and 
Hoang, N.M. (2007), A Complete 
Implementation of Vector Control for a Four-
Switch Three-Phase Inverter Fed IM Drive, 
International Symposium on Electrical & 
Electronics Engineering, October 24-25, 2007, 
HCM City, Vietnam. 
12. Halder, K.K. and Ghosh, B.C. (2010), Vector 
Control of Four Switch Three Phase Inverter 
Fed Interior Permanent Magnet Synchronous 
Motor Drive without Position Sensor, Journal 
of Electrical Engineering, 10(2), pp. 67-74.  
Page 673
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
 
*
 Corresponding Author: Mohammad Rubaiyat Tanvir Hossain,  
E-mail: mrth.eee.cuet@gmail.com, mrthossain@cuet.ac.bd  
RED LIGHT VIOLATION MONITORING AND REPORTING USING 
MICROCONTROLLER CONTROLLED WIRELESS 
COMMUNICATION 
 
 
Mohammad Rubaiyat Tanvir Hossain*, Tanvir Hassan Bhuiyan, Shovan Bhowmik, 
Ainul Anam Shahjamal Khan 
Department of Electrical and Electonic Engineering, Chittagong University of Engineering and 
Technology (CUET), Chittagong-4349, Bangladesh 
 
 
Traffic accidents are now one of the main causes of death and economic loss in most of the developed 
countries. Noncompliance with traffic laws is severely impeding the safety of the road traffic system. In this 
paper a system for monitoring and reporting incidences of red light violations at the traffic intersection has 
been proposed. A prototype of the system was build and verified experimentally. The system comprises an 
infrared (IR) transmitter and receiver unit for detection of red light violation whereas for identifying the 
vehicle, microcontroller triggered wireless mobile network has been used. The microcontroller was 
programmed to automatically send message containing the car license no, date and time of breaking the rule 
to the numbers of traffic control units stored previously to the cell phone directory. Upon detection of the 
offender, the corresponding action can be performed by the traffic monitoring system. The proposed system 
is simple, cheap, reliable, and exempted from the effects of bad weather conditions, improper lightings etc. 
and thus more suitable for detection of a violation and identification of the vehicle involved.  
 
Key words: Red Light Violation; IR transmitter and receiver; Microcontroller; Wireless communication  
 
1. INTRODUCTION 
 
Traffic signals, through use of time separation, are 
designed to reduce motor-vehicle crashes at 
intersections involving conflicting traffic 
movements. Noncompliance with traffic laws is 
severely impeding the safety of the road traffic 
system. According to an in-depth investigation of 
road accidents in France, 92% of traffic accidents 
are preceded by at least one traffic law violation 
[1].  
 
In most of the developed countries traffic accidents 
are now one of the main causes of death and 
economic loss [2]. According to the Road Safety 
Action Program of European Commission, more 
than one million accidents a year cause over 40,000 
deaths and nearly two million injuries on the roads. 
In addition, the direct and indirect cost has been 
estimated at 160 billion Euros, which is nearly two 
percent of the EU’s GNP. Unfortunately these 
thrilling numbers are increasing every year [3]. In 
Bangladesh road accidents claim on an average 
12,000 lives annually and lead to about 35,000 
injuries [4]. Everyday around eight persons die in 
road accidents and the number of accidents has 
increased by 43% between 1982 and 2000, while 
the number of fatalities has increased by around 
400% within the same period [5]. This indicates 
that not only the occurrence of accidents is on the 
rise the severity of accidents is also increasing.  
 
But motorization is increasing even faster than road 
death and injury [6]. Many low income countries 
have experienced rapid growth in their motor 
vehicle fleet. As said by the Bangladesh Road 
Transport Authority (BRTA) official statistics, the 
number of registered vehicles up to 2003 at Dhaka 
city in Bangladesh was 3,03,215 and the number 
increases to 5,62,815 as on June 2010 [7]. Over the 
years, crash statistics have deteriorated due to the 
ever-growing number of vehicles on the road and 
the increasing vehicle-miles traveled, and this 
situation is becoming a major concern of Federal, 
State and local authorities. Many drivers do not 
comply with traffic signal indications [8]. More 
than one million motor-vehicle crashes occur 
annually at traffic signals in the United States [9-
13] and a major cause of such crashes is drivers 
disregarding traffic signals. A review of 4,526 
police-reported crashes in four U.S. cities found 
that running red lights and other traffic-control 
devices such as stop signs is the most frequent type 
of collision in urban areas and the occupant injuries 
Page 674ISBN: 978-984-33-2140-4
  
occurred in 45 percent of the red light running 
crashes, compared with 30 percent for other crash 
types [14]. This indicates that reductions in red 
light running crashes would be especially beneficial 
in reducing urban crash losses.  
 
Monitoring of traffic intersections for red-light 
violations has historically been done in-person by 
one or more law enforcement officers [15]. But, the 
proliferation of intersections, combined with budget 
pressures, increase number of vehicles on the road 
and other resource limitations, have caused police 
departments to employ automated tools for 
intersection monitoring [16, 17]. Among some 
existing automated systems, fixed-position 
cameras, commonly named as red light cameras, 
increasingly are being used in many foreign 
countries since the 1970s [18, 19] to help 
communities enforce traffic laws by automatically 
photographing vehicles whose drivers run red 
lights. Over time there have been some minor 
variations and automatic enforcement has been 
extended to several types of violations and new 
technologies for detecting violations as well as for 
identifying the violating vehicles has appeared [17, 
20]. Probably the most notable developments have 
been systems involving the use of digital video 
recording [21] with image processing, and systems 
for electronic recognition and identification of a 
vehicle. But though certain countries have used 
photo-enforcement with some degree of success, 
current systems of traffic enforcement using 
photographic techniques have disadvantages that 
generally do not facilitate effective automation and 
validation of the photographs required for effective 
use as legal evidence. For instance, the film-camera 
systems have required white light illumination 
generally in the form of flash units, to provide 
sufficient light to capture violation images in poor 
ambient light or at night. The use of flash 
illumination may be detrimental at night to 
oncoming traffic and has the potential to cause 
temporary driver blindness and consequent safety 
risks as well as preventing authorities from 
deploying systems covertly. Moreover, the 
detection system is invariably unable to provide a 
trigger point that is sufficiently consistent to ensure 
that the positioning of vehicles at the time of 
imaging is identical. Where digital cameras are 
used, systems either require the availability of high-
speed communications lines to meet the demands of 
communicating high-resolution images, or else 
images and data must be collected manually. 
 
2. OBJECTIVE 
 
In this research we have thought out of a system 
which is simple, cheap, reliable, and of course 
offers at least some fundamental advantages over 
the conventional automated systems. Here we have 
used microcontroller controlled wireless 
communication system which makes the system not 
only automatic but also flexible. Also it makes the 
system simple to track the vehicle even when the 
number of traffic is large and also helps the system 
to keep in pace with the motion/running body. 
 
3. DESCRIPTION OF THE SYSTEM 
 
The overall traffic violation processing system of 
the proposed design is shown in Fig. 1. The 
controlling system mainly comprises (i) detection 
of the violation, and (ii) identification of the vehicle 
involved.  
 
 
 
Fig. 1: Block diagram of the proposed traffic 
violation processing system 
 
The IR transmitter and IR receiver cover the 
violation detection unit, while, for identifying the 
vehicles microcontroller triggered mobile 
communication system is used. For purposes of 
explanation, numerous specific details are set forth 
in order to provide an understanding of the present 
invention.  
 
3.1 Detection of Violation 
Fig. 2 shows the violation detection unit of the 
proposed scheme. Most conventional traffic 
surveillance systems use intrusive sensors, which 
include inductive loop detectors [22, 23] micro-
loop probes, pneumatic road tubes, piezoelectric 
cables and other weigh-in-motion sensors for 
detection of violation. Some technologies are 
common to systems for detecting different 
violations, whereas, others are particularly tailored 
to the detection of specific kinds of violations. In 
our proposed system, infrared radiation (IR) 
transmitter and receiver units are used as a wireless 
sensor network with detection accuracy as good as 
Page 675
  
that of inductive loop for detection of traffic signal 
violation. 
 
 
 
Fig. 2: Violation detection unit 
 
When the red light on the signal post is ON, it will 
switch on the IR transmitters to continuously emit 
IR signals. The IR detector will be equipped in-car 
at the lower part of the vehicle. As soon as an 
alleged offender commits an offense at an 
intersection by violating the red light and crossing 
the line where he should stop, the IR detector in the 
car will receive the IR signal from the IR 
transmitter. 
 
3.2 Identification of the Vehicle Involved 
 
 
 
Fig. 3: Circuit diagram of the unit for identification 
of vehicle violating traffic rule 
 
The hardware unit embracing the identification of 
vehicle violating the traffic rule mainly consists of 
a microcontroller operated automatic mobile 
communication system as shown in Fig. 3. The IR 
detector is connected through operational amplifiers 
(LM 324 and LM 741) to the base of the transistor 
Q1. The transistor output is attached to the input of 
the microcontroller unit. The microcontroller is 
interfaced with mobile through four transistors 
connected to the bidirectional I/O port PC0~3 of the 
microcontroller. When the IR detector receives 
signal from the IR transmitter, it passes the signal 
to the operational amplifier. The operational 
amplifier compares a reference voltage with the 
voltage change made by the IR detector receiving 
the IR signal and supply base current to the 
transistor Q1 connected at the output. The transistor 
will turn on and give an interrupt signal to the 
microcontroller. The microcontroller sends pulse to 
the Port C according to interrupt subroutine and 
triggers the transistors Q2 ~ Q5 to activate the 
mobile. In accordance with the program loaded in 
the microcontroller an interrupt /sending message 
option will be performed by the cell. A message 
containing the car license no, date and time of 
breaking the rule is set to send automatically to the 
number(s) of traffic control unit stored previously 
in the cell phone directory. The law enforcing 
agency can easily identify the owner of the vehicle 
from the message received and can take appropriate 
actions against rule violation. 
 
3. RESULTS AND DISCUSSION 
 
The proposed microcontroller based traffic rules 
violation monitoring and reporting system has been 
implemented with a laboratory model and verified 
experimentally. Fig. 4 shows the experimental 
setup of the proposed system. A remote control toy-
car was equipped with the IR detector and the 
microcontroller operated mobile unit. Two IR 
LEDs (Light Emitting Diode) in series with a 100 Ω 
resistor supplied by 5V dc supply has been used as 
IR transmitter. A Photodiode fastened at the lower 
part of the car was used as IR detector to receive IR 
beam transmitted from the transmitter. The road 
was modeled with wooden frame and to house in 
the transmitter unit across the road a glass pane was 
used to bridge the pathway. 
 
 
 
Fig. 4: Experimental setup of the proposed system 
 
Page 676
  
When the transmitter was switched on along with 
the red light on the signal post and the car crossed 
the transmitter and the intersection violating the red 
light, in reference to the program loaded in the 
microcontroller a message with a sample 
identification number was effectively sent to a 
predefined cell phone no. An illustration of the 
received message is shown in Fig. 5. The date and 
time of the sending message was obtained from the 
message property. 
 
 
 
Fig. 5: Message received containing the car 
identification number 
 
This way the laboratory model has substantiated the 
proposed scheme effectively. The system 
automatically monitored, reported and identified 
the disobedient offender using the simple 
microcontroller based wireless communication 
network. The effectual realistic execution of the 
research outcome can be intended to alleviate the 
high intensity of road traffic accident by effectively 
control the violation of traffic rule.  
 
The conventional systems of [15-21] taking images 
of violating vehicles by red light cameras or video 
recorders suffer from significant drawbacks due to 
the poor environment many intersections provide 
for photography. Specifically, improper lighting 
resulting from hours of darkness, solar glare, 
reflections, and shadows may cause photographs 
taken by such existing systems to be of poor quality 
and, therefore, ineffective for identifying the 
operator or the license plate number of a violating 
vehicle. In addition, systems using fixed position 
cameras further suffer from problems of driver 
and/or vehicle identification resulting from 
occlusion of the violating vehicle by other vehicles. 
Moreover, the amount of information provided by 
existing systems regarding the context and/or 
circumstances surrounding an alleged violation is 
often insufficient for effective violation 
enforcement.  
 
On the other hand, the proposed scheme is 
effective, and free from the effects of bad weather 
conditions, improper lightings etc. It can easily 
track the vehicle even when the number of traffic is 
large. Thus it is expected that the proposed system 
would be more suitable to enforce the traffic rules 
by detecting a violating vehicle accurately and 
reducing the road traffic accidents significantly. 
 
5. CONCLUSION 
 
A novel, simple, improved and low cost system for 
monitoring and reporting incidences of red light 
violation at the traffic intersections has been 
suggested in this research. The proposed system 
consists of a traffic rule violation detection unit and 
the alleged offender identification unit. Upon 
detection of a predefined traffic law infraction at 
the intersection and recognition of the suspected 
convict, the corresponding action can be performed 
by the traffic monitoring system. The system is 
more reliable as it is free from the effects of bad 
weather condition, improper lighting which 
influence the performances of red light camera 
system for identifying the operator or the license 
plate number of a violating vehicle. As the overall 
system is automatic it is more secure. However, the 
prime obligation of the system is that there should 
be a dependable wireless mobile communication 
network through out the site of operation. In this 
regard the system can be made more economical 
and simple if the mobile phone unit can be replaced 
by a single RF transmitter IC TLP 434A and a 
receiver IC RLP 434. It would be also desirable that 
the proposed automated scheme for monitoring and 
reporting red light violations at the traffic 
intersections should be realized in practice. 
Furthermore, extended application of the proposed 
scheme, providing the capability to similarly 
monitor and/or record events occurring at railroad 
crossings, border check points, toll booths, 
pedestrian crossings and parking facilities, would 
specifically be desirable in future. 
 
REFERENCES 
 
1.  Rhodes, S. (1989), A qualitative approach to 
accident contributory traffic law violations, 
Aix-en-Provence: CETE Mediterranee. 
2. World report on road traffic injury prevention, 
(2004), Geneva: World Health Organization. 
3. AS, A.T., Hess S. (2005), Red-light cameras 
for the prevention of road traffic crashes. The 
Cochrane Database of Systematic Reviews 
2005, Issue 2. Art. No.: CD003862.pub2. DOI: 
10.1002/14651858, April 2005. 
4. Road accidents and their costs, The Financial 
Express website, viewed 2010. 
<http://www.thefinancialexpress-bd.com/> 
5. Louis Burger Group-BCL, (2005), Strategic 
Transport Plan, Dhaka Transport Coordination 
Board, Ministry of Communications, 
Government of Bangladesh, 2005. (draft) 
Page 677
  
6. Jacobs G, Aeron-Thomas A, Astrop A. (2000), 
TRL Report 445. Crowthorne: TRL, 2000. 
7. The BRTA official website, Viewed 2010 
<http://www.brta.gov.bd/statistics.php> 
8. Retting, R.A., Williams, A.F., and Greene, 
M.A. (1998), Red Light Running and Sensible 
Countermeasures: Summary of Research 
Findings, Transportation Research Record 
1640, pp. 23–26. 
9. U.S. Department of Transportation (USDOT). 
Traffic Safety Facts 1992.Report HS-808-022. 
Washington, D.C., USA, (1993). 
10. USDOT. Traffic Safety Facts 1993. Report 
HS-808-169. Washington, D.C., USA, (1994). 
11. USDOT. Traffic Safety Facts 1994. Report 
HS-808-292. Washington, D.C., USA, (1995). 
12. USDOT. Traffic Safety Facts 1995.Report HS-
808-471. Washington, D.C., USA, (1996). 
13. USDOT. Traffic Safety Facts 1996. Report 
HS-808-770. Washington, D.C., USA, (1997). 
14. Retting, R.A., Williams, A.F., Preusser, D.F., 
Weinstein, H.B. (1995), Classifying Urban 
Crashes for Countermeasure Development, 
Accident Analysis and Prevention, 27, pp. 
283–294, 1995. 
15. Retting, R.A., Williams, A.F., Farmer, C.M., 
Feldman, A.F. (1999), Evaluation of Red Light 
Camera Enforcement in Fairfax, Va., USA, 
ITE Journal, pp. 30-34, August 1999 
16. Freedman, M., and Paek, N. (1992), 
Enforcement Resources Relative to Need: 
Changes During 1978–89, Arlington, Va., 
USA: IIHS, 1992. 
17. Rothengatter, T. (1991), Automatic Policing 
And Information Systems For Increasing 
Traffic Law Compliance, Journal of Applied 
Behavior Analysis, No. 1, 24, pp. 85-87, 1991. 
18. Makinen, T., Hway-liem O. (1992), Automatic 
Enforcement of Speed and Red Light 
Violations, Leidschendam, the Netherlands: 
SWOV Institute, 1992. 
19. Blackburn, R.R., Gilbert D.T. (1995), 
Photographic Enforcement of Traffic Laws, 
National Cooperative Highway Research 
Program, Synthesis of Highway Practice 219. 
Washington, D.C., USA: Transportation 
Research Board (TRB), National Research 
Council, 1995. 
20. Cheung, S. Y., Varaiya, P. (2007), Traffic 
Surveillance by Wireless Sensor Networks: 
Final Report, California PATH Research 
Report, UCB-ITS-PRR-2007-4, ISSN 1055-
1425, Jan 2007. 
21. Rahman, C. A., Badawy, W., Radmanesh, A. 
(2003), “A Real Time Vehicle’s License Plate 
Recognition System”, Proceedings of the IEEE 
Conference on Advanced Video and Signal 
Based Surveillance (AVSS’03), 0-7695-1971, 
2003. 
22. Zhang, X., Wang, Y., Nihan, N.L. (2004), 
Monitoring a freeway network in real-time 
using single-loop detectors: System design and 
implementation, 83rd TRB Annual Meeting, 
January 2004, Washington, D.C. 
23. Oh, S., Ritchie, S.G., Oh, C. (2002), Real time 
traffic measurement from single loop inductive 
signatures, 81st TRB Annual Meeting, January 
2002, Washington, D.C. 
Page 678
 Reduction of PAPR in OFDM Using SLM for Different Route Number 
Md. Zulfiker Mahmud* 
Md. Ibrahim Abdullah** 
Saifur Rahman Sabuj*** 
 
*Lecturer in CSE, Green University of Bangladesh 
** Associate Professor in CSE, Islamic University 
*** Lecturer in EEE, Green University of Bangladesh  
 
 
Abstract-Orthogonal Frequency Division Multiplexing (OFDM) is considered to be a promising 
technique against the multipath fading channel for wireless communications. Peak to average power ratio 
(PAPR) is a major drawback of multicarrier transmission system which leads to power inefficiency in RF 
section of the transmitter. In this paper, we present PAPR reduction on selected mapping (SLM) method 
using different route number. Simulation result shows that the PAPR reduces when route number 
increases.  
 
Keywords: Orthogonal Frequency Division Multiplexing, Peak to Average Power Ratio, Power Amplifiers, 
Selected Mapping, Complimentary Cumulative Distribution Function. 
 
 
I. Introduction 
Orthogonal frequency division multiplexing (OFDM) is one of the most attractive techniques for 
fourth generation (4G) wireless communication. It effectively combats the multipath fading channel, 
improves the bandwidth efficiency and increases system capacity so as to provide a reliable transmission 
[1]. OFDM is to split a high rate data stream into a number of lower rate data streams and modulated by 
subcarriers. These subcarriers are overlapped with each other. The symbol duration increases for lower 
rate data streams, the relative amount of dispersion in time caused by multipath delay spread is decreased. 
Inter symbol interference (ISI) is eliminated almost completely by introducing a guard time in every 
OFDM symbol.  
 
OFDM faces several challenges. The key challenges are large peak to average power ratio 
(PAPR) due to non linearity of amplifier, phase noise problems of local oscillator, frequency offset due to 
Doppler shift or difference between transmitter and receiver. Large peak to average power (PAP) ratio 
distorts the signal if the transmitter contains nonlinear components such as power amplifiers (PAs).  The 
nonlinear effects on the transmitted OFDM symbols are spectral spreading, inter modulation and 
changing the signal constellation. Therefore the PAs requires a back off which is approximately equal to 
the PAPR for distortion less transmission.  This decreases the efficiency for amplifiers.  
 
Researchers have been proposed several PAPR reduction techniques. These techniques are 
divided into two groups. There are signal scrambling techniques and signal distortion techniques. Block 
coding techniques [1, 2], selected mapping (SLM) [3], partial transmit sequence (PTS) [4, 5] etc are 
signal scrambling techniques. Signal distortion techniques are peak windowing [2], envelope scaling [6], 
peak reduction carrier [7], clipping and filtering [4]. 
 
In this paper, we have investigated PAPR reduction on selective mapping (SLM) method using 
different route number in OFDM system.  
 
Page 679ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
 II. PAPR dilemma in OFDM 
Let us consider, Xk (k=0, 1, ..., N-1)  denote the input data symbol whose period is T . Then the 
complex representation of an OFDM symbol is given as: 
                            NTtextx
N
k
ftk
k 


 0.)(
1
0
2                                                                 (1)                    
Where N is the number of subcarriers, and ∆ f = 1/ NT is the subcarrier spacing. The samples are denoted 
by xn (n=0, 1, ……, LN – 1) for the OFDM symbols with the sampling rate L . We consider the sampling 
rate (Nyquist rate) which corresponds to the case of L = 1. The amplitude of the n th sample of an OFDM 
symbol is given as || nn xr  . As N is a sufficiently large number, rn is considered to be approximately 
equal to a Rayleigh random variable. The probability density function (pdf) is given as [4]: 
                     0,
2
)( /2   n
pr
in
n
nR rep
rrf inn                                                                                                (2) 
Where, Pin = 2σ2 is the input power of the OFDM signal. 
 
The PAPR of the OFDM symbol is defined as the ratio of the peak power and the average power 
[8]:               
                    
]|[|
]|max[|
log10 2
2
10
n
n
average
peak
xE
x
p
p
PAPR                                                                               (3) 
Where ܲ݇ܽ݁݌ represents output peak power, ܲܽܽݎ݁ݒge means output average power. ܧ[∙] denotes the 
expected value, ݊ݔ represents the transmitted OFDM signals which are obtained by taking IFFT operation 
on modulated input symbols ܺ݇. Mathematical, ݊ݔ is expressed as: 
                         



1
0
1 N
k
nk
Nkn WXn
x                                                                                                          (4) 
 
             For an OFDM system with N sub carriers, the peak power of received signals is N times the 
average power when phase values are the same. The PAPR of baseband signal will reach its theoretical 
maximum at PAPR (݀10= (ܤlog ܰ. If N is large enough, based on the central limit theorem, the real and 
imaginary parts of xn have Gaussian distribution and its envelope will follow a Rayleigh distribution. This 
implies a large PAPR.  
 
The Crest Factor (CF) is defined as the ratio between maximum amplitude of OFDM signal s( ݐ) 
and root mean square (RMS) of the waveform. The CF is defined as [9]:  
                          PAPR
tsE
tstsCF 
|]|)([||
|])(max[|))(( 2                                                                               (5) 
 
 
III. Selected mapping (SLM) method 
The complementary cumulative distribution function (CCDF) of the original signal sequence 
PAPR above a threshold PAPR0 is written as ܲ0ܴܲܣܲ < ܴܲܣܲ) ݎ). Accordingly K statistical independent 
signal waveforms, CCDF can be rewritten as [{ܲ0ܴܲܣܲ < ܴܲܣ}] K so that the probability of PAPR that 
exceeds the same threshold will drop to a small value [3]. 
  
The probability of PAPR larger than a threshold z can be written as 
NzzPAPRP ))exp(1(1)(  . Assuming that M OFDM symbols carry the same information and 
they are statistically independent of each other. In this case, the probability of PAPR greater than z is 
equals to the product of each independent candidate’s probability. This process can be written as [1]:  
Page 680
                          MNMlow zZPAPRPzPAPRP )))exp(1((}){(}{                                           (6) 
 
In SLM method, firstly M statistically independent sequences which represent the same 
information are generated and then the resulting M statistically independent data blocks 
Mm ,.......2,1,]..SS,[SS T1-Nm,m,1m,0m   are then forwarded into IFFT operation 
simultaneously. Finally, at the receiving end, OFDM symbols TN21m ]........xx,[xx  in discrete time 
domain are acquired and then the PAPR of M vectors are calculated separately. Eventually, the sequences 
xd with the smallest PAPR will be elected for final serial transmission. Fig. 1 illustrates the basic structure 
of SLM method for reducing the high PAPR.  
 
Fig. 1: Basic principles of SLM method 
 
This method can significantly improve the PAPR performance of OFDM system. Assuming that 
for a single OFDM symbol, CCDF probability of PAPR larger than a threshold is equals to ݌. The general 
probability of PAPR larger than a threshold for k OFDM symbols can be expressed as ݌k. It can be 
verified that the new probability obtained by SLM algorithm is much smaller compared to the former. 
Data blocks Sm are obtained by multiplying the original sequence with M uncorrelated sequence Pm.  
 
The different pseudo random sequences Mm ,.......2,1,]..PP,[PP T1-Nm,m,1m,0m   
where nmjnm eP
,
,
  and stands for the rotation factor. φm,n  is also known as the weighting factor is 
uniformly distributed in [0 2ߨ]. The N different subcarriers are modulated with these vectors respectively 
so as to generate candidate OFDM signals. This process can also be seen as performing dot product 
operation on a data block Xn with rotation factor Pm [1].  
                                 TnmNmmm PXPXPXS ],......,,[ 1,11,1,0,0  , m=1,2,……M                                      (7) 
M OFDM frames from frequency domain to time domain by IFFT. The entire process is given by  
                                MmNTyePX
N
tx ftnj
N
nmnm ,........2,1,0,.
1)( 2
1
0
, 


                                 (8) 
Finally, the one which possess the smallest PAPR value is selected for transmission. Its mathematical 
expression is given as [1, 8]:  
                                ))((minarg 1 mMmd xPAPRx                                                                                (9)                                   
Where, argmin (⋅) represent the argument of its value is minimized.   
 
At the receiver, in order to correctly demodulate the received signal, it is necessary to know 
which sequence is linked to the smallest PAPR among M different candidates after performing the dot 
Page 681
 product. Hence, the receiver is required to learn information about selected phase vector sequence and 
ensure that the vector sequence is received correctly.  
 
 
IV. Result and discussion  
It seems that that the ability of PAPR reduction using SLM is affected by the route number M and 
subcarrier number N. Therefore, simulation with different values of M and N and the results exhibits some 
desired properties of signals representing the same information. Comparison of PAPR reduction 
performance with different values of M while N is fixed at 128. Rotation factor is defined as Pm,n∈ 
[±1,±j]. The algorithm executes 10000 times, over sampling factor is 8 and QPSK mapping is adopted as 
modulation scheme in each sub-carrier. Route numbers M=2, M=4, M=8, M=16 are used. Therefore, 
practically, compromise the computing complexity and improvement of performance, we usually take 
M<=8.   
 
 
Fig. 2: Theoretical CCDF vs PAPR curves using SLM method [1] 
 
Fig. 2 shows the theoretical CCDF curves as a function of PAPR distribution when SLM method 
is used. The number of N subcarriers is 128. M takes the value of 1 (without adopting SLM method), 2, 8, 
32 and 128. It is seen in Fig. 2 that route number (M) increases, PAPR of CCDF distribution reduces.  
 
From Fig. 3, it can be observed that the proposed SLM method displays a better PAPR reduction 
performance than the original OFDM signal. If the probability is set to 1% and then the CCDF curves 
with different M values are compared. The PAPR value of case M=2 is about 1dB smaller than the 
unmodified one M=1. Under the same condition, the PAPR value of case M=16 is about 3dB smaller than 
the original one M=1. The performance difference between M=8 and M=16 cases is less than 0.5dB. This 
proves that it will not be able to achieve a linear growth of PAPR reduction performance with further 
increase the value of M (like M>=8), the PAPR reduction performance of OFDM signal will not be 
considerably improved. 
Page 682
  
Fig. 3: Simulation CCDF vs PAPR performances with different values of M 
 
V. Conclusion 
In this paper, we presented modified SLM technique to reduce PAPR. The selected technique 
provides us with a good range in performance to reduce PAPR. SLM algorithm adapted to any route 
number that means it can be used for different OFDM systems with different number of carriers. It is 
particularly suitable for the OFDM system with a large number of subcarriers (more than 128). The 
proposed technique reduces PAPR, decrease the BER over conventional techniques, and improve the 
spectrum efficiency, where the proposed technique is evaluated in presence of nonlinear power amplifier. 
 
 
Reference 
[1] Wang Yi Gu linfeng “An Investigation of Peak-to-Average Power Reduction in MIMO-OFDM 
Systems”, Blekinge Institute of Technology, October 2009. 
[2] Md. Abdullah Al Baki, Mohammad Zavid Parvez “Peak To Average Power Ratio (PAPR) Reduction 
In OFDM Based Radio Systems” Blekinge Institute of Technology, May 2010. 
[3] Bauml, R.W, Fischer, R.F.H and Huber, J.B, “Reducing the peak-to-average power ratio of 
multicarrier modulation by selected mapping,” IEEE Electronic Letters, vol. 32, no. 22, October 1996,  
[4] Xiaodong Li and Leonard J. Cimini, "Effects of Clipping and Filtering on the Performance of 
OFDM," IEEE Communications Letters, vol. 2, no. 5, may 1998.  
[5] Leonard J. Cimini, Jr., Nelson R. Sollenberger, “Peak-to-Average power ratio reduction of an OFDM 
signal using partial transmit sequences,” IEEE Electronic Letters, vol. 4, no. 3, pp. 88-86, march 2000. 
[6] Wilkison, T. A. and Jones A. E., "Minimization of the Peak to mean Envelope Power Ratio of 
Multicarrier Transmission Schemes by Block Coding," IEEE, Vehicular Conference, vol.2, July 1995.  
[7] S. H. Muller, J. B. Huber, “A novel peak power reduction scheme for OFDM,” The 8th IEEE 
International Symposium on Personal, Indoor and Mobile Radio Communications, February 1997. 
[8] Oh-Ju Kwon and Yeong-Ho Ha, “Multi-carrier PAP reduction method using sub-optimal PTS with 
threshold,” IEEE Transactions on Broadcasting, vol. 49, no. 2, pp. 232-53, June 2003.  
[9] Gross. R and D. Veeneman, “Clipping distortion, in DMT ADSL systems,” IEEE Electron. Lett., vol. 
29, pp. 2080-2081, November 1993. 
Page 683
Share Market Price Prediction Using Artificial Neural Network (ANN) 
Zabir Haider Khan1, Tasnim Sharmin Alin2, Md. Akter Hussain3 
 
    1Department of CSE, SUST, Sylhet, Bangladesh. Tell: 880-1914955630, email:  xabirkhan@gmail.com 
       2Department of CSE, SUST, Sylhet, Bangladesh. Tell: 880-1911723340, email: alinflower.sust@gmail.com   
    3Department of CSE, SUST, Sylhet, Bangladesh. Tell: 880-1711485003, email: akter.1985@yahoo.com   
 
                                                         ABSTRACT 
Share Market is an untidy place for predicting since there are no significant rules to estimate or predict the price 
of share in the share market. Many methods like technical analysis, fundamental analysis, time series analysis 
and statistical analysis etc are all used to attempt to predict the price in the share market but none of these 
methods are proved as a consistently acceptable prediction tool. Artificial Neural Network (ANN), a field of 
Artificial Intelligence (AI), is a popular way to identify unknown and hidden patterns in data which is suitable 
for share market prediction. For predicting of share price using ANN, there are two modules, one is training 
session and other is predicting price based on previously trained data. We used Backpropagation algorithm for 
training session and Multilayer Feedforward network as a network model for predicting price. In this paper, we 
introduce a method which can predict share market price using Backpropagation algorithm and Multilayer 
Feedforward network. 
Keywords: Artificial Neural Network (ANN), Prediction, Artificial Intelligence (AI), Backpropagation  (BP), 
Multilayer Feedforward Network, Neural Network (NN). 
1. Introduction                                                                                                         
A share market is a place of high interest to the 
investors as it presents them with an opportunity to 
benefit financially by investing their resources on 
shares and derivatives of various companies. It is a 
chaos system; meaning the behavioral traits of 
share prices are unpredictable and uncertain. To 
make some sort of sense of this chaotic behavior, 
researchers were forced to find a technique which 
can estimate the effect of this uncertainty to the 
flow of share prices. From the analyses of various 
statistical models, Artificial Neural Networks are 
analogous to nonparametric, nonlinear, regression 
models. So, Artificial Neural Networks (ANN) 
certainly has the potential to distinguish unknown 
and hidden patterns in data which can be very 
effective for share market prediction. If successful, 
this can be beneficial for investors and financers 
and that can positively contribute to the economy. 
There are different methods that have been applied 
in order to predict Share Market returns. Tang and 
Fishwick[1]; Wang and Leu [2] provided a general 
introduction of how a neural network should be 
developed to model financial and economic time 
series. During the last decade, Artificial Neural 
Networks have been used in share market 
prediction. One of the first such projects was by 
Kimoto et al. [3] who had used ANN for the 
prediction of Tokyo stock exchange index. 
Minzuno et al. [4] applied ANN again to Tokyo 
stock exchange to predict buying and selling 
signals with an overall prediction rate of 63%. 
Sexton et al. [5] theorized that the use of 
momentum and start of learning at random points 
may solve the problems that may occur in training 
process in 1998. Phua et al. [6] applied neural 
network with genetic algorithm to the stock 
exchange market of Singapore and predicted the 
market direction with an accuracy of 81%. 
This paper demonstrates Back propagation method 
for training the Neural Network and Multilayer 
Feed forward network in order to forecast the share 
values. The aim of this paper is to use ANNs to 
forecast Bangladesh Stock Exchange market index 
values with reasonable a degree of accuracy. 
2. Prediction Method Analysis:  
Trading shares and commodities were primarily 
based on intuitions. As the trading grew, people 
tried to find methods and tools which can 
accurately predict the share prices increasing their 
gains and minimizing their risk. Many methods like  
Page 684
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
fundamental analysis, technical analysis, and 
machine learning method have all been used to 
attempt predictions of share prices but none of 
these methods have been proven as a consistently 
applicable prediction tool.  
2.1 Fundamental Analysis   
Fundamental analysis is the physical study of a 
company in terms of its product sales, manpower, 
quality, infrastructure etc. to understand it standing 
in the market and thereby its profitability as an 
investment [7]. The fundamental analysts believe 
that the market is defined 90 percent by logical and 
10 percent by physiological factors. But, this 
analysis is not suitable for our study because the 
data it uses to determine the intrinsic value of an 
asset does not change on daily basis and therefore 
is not suitable for short-term basis. However, this 
analysis is suitable for predicting the share market 
only in long-term basis.   
2.2 Technical Analysis 
The technical analysis predicts the appropriate time 
to buy or sell a share. Technical analysts use charts 
which contain technical data like price, volume, 
highest and lowest prices per trading to predict 
future share movements. Price charts are used to 
recognize trends. These trends are understood by 
supply and demand issues that often have cyclical 
or some sort of noticeable patterns. To understand a 
company and its profitability through its share 
prices in the market, some parameters can guide an 
investor towards making a careful decision. These 
parameters are termed Indicators and Oscillators 
[7]. This is a very popular approach used to predict 
the market. But the problem of this analysis is that 
the extraction of trading rules from the study of 
charts is highly subjective, as a result different 
analysts extract different trading rules studying the 
same charts. This analysis can be used to predict 
the market price on daily basis but we will not use 
this approach because of its subjective nature. 
2.3 Machine Learning Methods 
Machine learning approach is attractive for 
artificial intelligence since it is based on the 
principle of learning from training and experience. 
Connectionist models [8] such as ANNs are well 
suited for machine learning where connection 
weights adjusted to improve the performance of a 
network. 
3. Challenge in Prediction of share 
market price:                                       
The main problem in predicting share market is that 
the share market is a chaos system. There are many 
variables that could affect the share market directly 
or indirectly. There are no significant relations 
between the variables and the price. We cannot 
draw any mathematical relation among the 
variables. There are no laws of predicting the share 
price using these variables. 
4. Our System Architecture: 
For this kind of chaotic system the neural network 
approach is suitable because we do not have to 
understand the solution. This is a major advantage 
of neural network approaches [9]. On the other 
hand in the traditional techniques we must 
understand the inputs, the algorithms and the 
outputs in great detail. With the neural network we 
just need to simply show the correct output for the 
given inputs. With sufficient amount of training, 
the network will mimic the function [9, 10]. 
Another advantage of neural network is that during 
the tanning process, the network will learn to 
ignore any inputs that don’t contribute to the output 
[9, 10]. 
For our system, there is a training phase where 
some parameters named weights are found from 
this section and Backpropagation Algorithm is used 
for this training phase. These weights are used in 
prediction phase using same equations which are 
used in training phase. This is our basic 
Architecture of our System and this approach is 
known as a Feedforward Network.. There are a lot 
of inputs in share market which are impacts in 
share price. But all the inputs are not used in our 
system because their impact are not significant in 
share market price. We used 5 inputs for the 
system. The inputs are:  General Index (GI), P/E 
ratio, Net Asset Value (NAV), Earnings per Share 
(EPS) and volume. Then we normalized the data 
set according to the network and the feed the data 
to the network. 
4.1 Backpropagation with Feedforeword NN:    
Back-propagation algorithm [8, 11, 14] is basically 
the process of back-propagating the errors from the 
output layers towards the input layer during 
training sessions. Back-propagation is necessary  
Page 685
because the hidden units have no target values 
which can be used, so these units must be trained 
based on errors from the previous layers. The 
output layer has a target value which is used to 
compare with calculated value. As the errors are 
back-propagated through the nodes, the connection 
weights are continuously updated. Training will 
occur until the errors in the weights are adequately 
small to be accepted. On the other hand the 
computational complexity of Back-propagation 
Algorithm is only O(n). These features of the 
algorithm are the main criteria for predicting share 
prices accurately. 
The main steps using the Backpropagation 
algorithm as follows: 
Step 1: Feed the normalized input data sample, 
compute the corresponding output;                                
Step 2: Compute the error between the output(s) 
and the actual target(s); 
Step 3: The connection weights and membership 
functions are adjusted;  
Step 4: IF Error > Tolerance THEN goto Step 1 
ELSE stop. 
 
 
 
5. MODEL ANALYSIS 
We used feedforward neural network which has a 
input layer with 5 neurons, a hidden layer which 
has 5 neurons and a output layer with single 
neuron. The backpropagation algorithm has been 
used for training the network. 
5.1 Training Phase:  
There are two phases 1st is the training phase and 
2nd is the prediction phase. The training phase can 
be divided into two parts, the propagation phase 
and the weight update phase.  
In the propagation phase 1st the input data is 
normalized for feeding the network into the input 
nodes   using the formula:  
  
 
Here, 
        V’ = Normalized Input. 
        V = Actual Input. 
Min A, Max A = Boundary values of the old data     
range.  
New min A, New max A = Boundary values of the 
new data range. In this case it is -1 and 1 because 
the    backpropagation can only handle data 
between –one to one. [12] 
 
 
 
 
                                                           Fig 1: Training phase  
 
 
 
AnewAnewAnew
AA
Avv min_)min_max_(
minmax
min' 



Page 686
From the figure 1 we can see that, the normalized 
input data are fed into the input layer, then the 
weights are multiplied with the each input data and 
enter into the neurons of hidden layer, the function 
of a single neuron are described in the figure 2, in 
our model we used single hidden layer. In our 
model the hidden layer neurons has the same 
functions as the input layers neurons .After that 
each neuron passes the output to the next neuron of 
the output layer. The output layer calculate the in 
the same way as the hidden layer neuron and 
generate the final out put which is the compared 
with the real output and calculate an error signal 
‘e’. 
 
The error ‘e’ is generated from the Propagation 
Phase is used to update the weight using the 
following formula: 
 
 
Updated Weight = weight(old) + learning rate * output error * output(neurons i) *  output(neurons i+1) *  
    (1 - Output (neurons i+1)). 
 
 
The above process is done in every weight matrix 
in the network for updating weight .The Phase 1 
and Phase 2 procedure repeatedly used until the 
sum of square error is zero or close to zero. 
Like the figure 2 each neuron is composed of two 
units. First unit adds products of weights 
coefficients and input signals [12]. Then this output 
enter into the second unit of the neuron which 
contains the nonlinear activation function, in our 
model we use sigmoid function as our activation 
function [13]. The formula of sigmoid activation is: 
  .       
5.2 The prediction phase: 
 
When the neural network is trained then it is ready 
for prediction. After training with acceptable error 
the weights are set into the network then we give 
the trained network the input data set of the day 
which price we want to predict. The trained 
network then predicts the price using the given 
input data set. 
 
 
 
6. Input Data: 
 
Here is a brief description about the inputs that 
affect the share price:  
 
6.1 General Index (GI):  General index is a 
number that measure the relative value of a section 
of share market. It reflects the total economic 
condition of the market. If the general index goes 
down then it means the economic condition of that 
particular market is relatively in poor condition.  
6.2 Net Asset Value (NAV): The Net asset value 
(NAV) of a company is the company’s total assets 
minus its total liabilities. NAV is typically 
calculated on a per-share basis. 
NAV= (Net asset of a company− Liability)/ Total 
number of outstanding share 
 
NAV is also calculated each day by taking the last 
market value of all securities owned plus all other 
assets such as cash, subtracting all liabilities and 
then dividing the result by the total number of 
shares outstanding. 
NAV reflects the financial condition of the 
company. We can judge the company reputation by 
the NAV.
 
 
                                                               Fig 2:  A Single Neuron 
Page 687
6.3 P/E ratio: The P/E ratio makes a relationship 
between the share price and the company’s 
earnings. The P/E ratio of a share is a measure of 
the price paid for a share relative to the annual net 
income or profit earned by the firm per share. 
P/E ratio = Share Price / Earnings Per Share.  
If P/E ratio rises then there is a tendency of the 
company share price falls, the higher P/E ratio then 
the higher probability to decrease the price. 
 
6.4 Earnings per Share (EPS): Earnings per share 
(EPS) is a comparison tool between two 
companies. Earnings per share serve as an indicator 
of a company's profitability. 
EPS =Net Earnings / Number of Outstanding 
Shares. 
For output we use the Price of the share. Using this 
data set we trained the network.  
 
6.5 Share Volume: Share volume can be 
calculated in two different types the daily share 
volume and the monthly share volume. the total 
number of share is sold in a particular day is called 
daily share volume. In monthly share volume is the 
sum of the trading volumes during that month. 
7. Simulation and performance analysis:                           
Using the developed system to predict the future 
stock values with Feedforward Neural Networks 
we can do some analysis to know the performance 
of the Back-Propagation Algorithm.  
 By using the past historical data of ACI  
pharmaceutical company which include only 2 
inputs, we tried to predict stock values for future 4 
days of July from Back-Propagation algorithm we 
are now able to compare the predicted values with 
the real values. Table 1 and Figure 3 show the 
prediction and real values of the ACI 
pharmaceutical Company. The input past historical 
data is from 01-07-2010 to 22-07-2010. 
The average error of the 1st simulation was 2.60 
percent. 
DATE Predicted 
Price  TK 
Actual Price 
TK 
Error 
(%) 
23-07-2010 420.42 427.9 1.74 
26-07-2010 420.13 414.7 1.30 
27-07-2010 436.13 426.7 2.20 
30-07-2010 435.42 414.0 5.17 
Table 1: Predicting price, Actual price and 
Error (%) of ACI pharmaceutical using 2 input 
datasets.
 
 
Fig - 3: Graphical representation of Predicting and Actual price of ACI pharmaceutical using 2 input 
data sets. 
 
 
 
Page 688
For the second simulation we used the past 
historical data of ACI pharmaceutical company 
which include only 5 inputs, we tried to predict 
stock values for future 8 days of November. Table 
2 and Figure 4 show the prediction and real values 
of the ACI pharmaceutical Company. The input 
past historical data is from 1-9-2010 to 31-10-2010. 
The average error  
of the 2nd simulation was 1.53 %. 
DATE 
Predicted 
Price 
(TK) 
Actual 
Price  
(TK) 
Error 
(%) 
01-NOV-2010 392.7 395 0.58 
02-NOV-2010 393.3 387 1.62 
03-NOV-2010 392.5 392 0.12 
04-NOV-2010 392.0 390 0.51 
08-NOV-2010 392.8 389 0.97 
09-NOV-2010 392.5 385 1.94 
10-NOV-2010 392.5 380 3.28 
11-NOV-2010 392.3 380 3.23 
 
 
Table 2: Predicting price, Actual price and 
Error (%) of ACI pharmaceutical using 5 input 
data sets. 
The more input data we have the better training and 
get more close results. This means that, more the 
available data for predicting financial markets, the 
greater the chances of an accurate forecast. But the 
sum squared error was high for the 5 input dataset 
than the 2 input data sets but the prediction error 
was minimal. 
7.1 Observation: 
1. We observed that when we take 2 inputs 
for prediction the sum squared error was 
high. But when we take 4 inputs the sum 
squared error was minimized. But when 
we take 5 input then the sum squared error 
is higher than the 4 input technique.   
2. When we take the data of share market in 
a sequential date, we can predict the share 
price nearer to the actual price. But if we 
take the data of discontinuous date the 
difference between the predicted price and 
actual price was relatively high. 
3. In the training time if any input changed 
suddenly at a high rate then the prediction 
was not near to the actual price. 
 
 
 
 
 
Fig - 4: Graphical representation of Predicting and Actual price of ACI pharmaceutical using 5 input 
data sets. 
Page 689
8. Conclusion:   
 
As researchers and investors strive to out-perform 
the market, the use of neural networks to forecast 
stock market prices will be a continuing area of 
research. The ultimate goal is to increase the yield 
from the investment. It has been proven already 
through research that the evaluation of the return on 
investment in share markets through any of the 
traditional techniques is tedious, expensive and a 
time-consuming process. In conclusion we can say 
that if we train our system with more input data set 
it generate more error free prediction price. 
References: 
[1] Z.Tang and P.A.Fishwick, “Backpropagation 
neural nets as models for time series forcasting,” 
ORSA journal on computing, vol.5, No. 4, pp 374-
384, 1993 
[2] J.H.wang and J.Y.Leu, “stock market trend 
prediction using ARIMA-based neural 
network,”Proc. Of IEEE conference on neural 
networks, vol.4, pp.2160-2165, 1996 
[3] Kimoto,T., asakawa, K., Yoda , M,. and 
Takeoka, M. (1990),Stock market prediction system 
with modular neural network, in proceedings of the 
International Joint Conference on Neural Network, 
1-6. 
[4] Mizuno, H., Kosaka , M., Yajima , H. and 
Komoda N. (1998), Application of Neural Network 
to Technical  Analysis  of  Stock  Market  
Prediction, Studies in  Information  and  Control , 
vol.7, no.3, pp.111-120. 
[5] Sexton, R. S., R. E. Dorsey and J.D.Dohnson 
(1998) , Toward  global optimization of  neural  
networks: A comparison of the genetic algorithm 
and backpropagation, Decision Support systems 
22, 171-185. 
[6] Phua, P.K.H. Ming, D., Lin, W. (2000), Neural 
network With Genetic Algorithms For Stocks 
Predictio, Fifth Conference of the Association of 
Asian-Pacific  Operations  Research  Societies, 5th 
– 7th july, Singapore. 
[7] Samarth Agarwal,Manol Jindal,G.N.Pillai 
“Momentum Analysis based Stock Market 
Prediction using ANFIS”. In Proceeding of the 
International Multiconference of Engineering and 
Computer Scientists 2010 Vol.1, IMECS 2010, 
March 2010, Hong Kong. 
[8] Rumelhart, D.D.m Hinton, G.E. and Williams, 
R.J., Learning Internal Representation, Man, and 
Cybernetics (SMC’91), 1991. 1913-1918. 
[9] “Feedforward neural Networks: An 
Introduction” by Simo Haykin page (2-4) 
[10] “Artificial Intelligence a morden approach”  
(second edition) by Stuart Russell, Peter Norvig  
2004   
[11] Simon Haykin, “Neural Network A 
Comprehensive Foundation”, second edition, 
Prentice Hall, 1998, page 161 – 173. 
[12] Robert J. Van Eyden. “The Application of 
Neural Networks in the Forcasting of Share 
Prices”. Finance and Technology Publishing, 
1996. 
[13] W.Duch and N. Jankowski, “Transfer 
functions: hidden possibilities for better neural 
networks.”, 9th European Symposium on 
Artificial Neural Networks (ESANN), Brugge 
2001. De-facto publications. 
[14] Y.-Q. Zhang and A. Kandel, 
“Compensatory Genetic Fuzzy Neural 
Networks and Their Applications,” Series in 
Machine Perception Artificial Intelligence, 
Volume 30, World Scientific, 1998. 
Page 690
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
* Corresponding Author: Md. Ismail Hossain 
E-mail: jewel04eee@yahoo.com 
SMART ROOM CONTROL UNIT USING  
STANDARD RC5 REMOTE CODE 
 
 
Md. Ismail Hossain*  
International Islamic University Chittagong 
Dhaka, Bangladesh 
 
Shakil Ahamed Khan  
Dhaka International University, Dhaka 
  
Md. Shafiullah 
International Islamic University Chittagong 
Dhaka, Bangladesh 
 
 
Remote control electronic products are available in the market but such type, which is called Smart Room 
Control unit including, Remote control switching more than 2048 devices, remotely speed control of a single 
phase induction motor, automatic water level control of an overhead tank, remotely opening and closing a 
door, monitoring room temperature is not available by using a single control unit. This type control unit is 
very useful in the modern world in the case of domestic application, which makes the most common work 
easy & smart. Often manually control the above systems is very bored. Now a day’s remote control TV is 
more common so by using this TV remote to make a Smart Room Control unit is so interesting & more 
economical. In this paper we present how a control unit can be made by using TV remote which can control 
2048 devices & finally the Successful practical performance of the transmitting and receiving/controlling 
unit will be presented. There are different type TV remotes in the market. Each has own distinct remote 
coding and decoding scheme for data transmission and reception. We have chosen RC5 coding and decoding 
scheme of Philips TV remote. In this paper RC5 decoding system will be presented by a complex program 
algorithm. This program algorithm is implemented in the embedded system. This paper discusses the low 
cost implementation of program algorithm in an 8-bit 8051 microcontroller using artificial techniques to 
control the above appliances. 
 
Keywords: RC5 encoding and decoding, Modulation and Demodulation, Microcontroller, infrared ray, 
phototransistor, Program Flow Chart, Transmitting and Receiving Unit, Dc motor Direction control 
switching, Temperature sensor, ADC, LCD, LASER, transmitting and control unit photos etc. 
 
1. INTRODUCTION 
Use of IR (infrared ray) light as a method for 
wireless communication has become popular for 
remote control applications. In my project widely 
used RC5 coding scheme is used. Before going 
discussion to my project a brief explanation is 
necessary for IR transmitter & receiver scheme. 
 
 
 
2. INFRARED LIGHT 
Infrared actually is normal light with a particular 
color. We humans can't see this color because its 
wavelength of 950nm is above the visible spectrum. 
Unfortunately for us there are many more sources 
of Infrared light. The sun is the brightest source of 
all, but there are many others, like: light bulbs, 
candles, central heating system. Therefore we have 
to take some precautions to guarantee that our IR 
message gets across to the receiver without errors. 
Page 691ISBN: 978-984-33-2140-4
  
 
3. MODULATION 
 Modulation is the answer to make our signal stand 
out above the noise. With modulation we make the 
IR light source blink in a particular frequency. The 
IR receiver will be tuned to that frequency, so it can 
ignore everything else. Modulation also increases 
the distance by boosting the power because if we 
apply constant power then the lifetime of IR LED 
will be reduced.  
Fig. 1:  Modulated signal Transmitter & Receiver. 
In the Fig. 1 we can see a modulated signal driving 
the IR LED of the transmitter on the left side. The 
detected signal is coming out of the receiver at the 
right side.  
4. THE INFRARED DETECTOR 
MODULE 
For selecting an infrared detector module we have 
to follow the following criteria to get maximum 
efficiency 
(a) Select an infrared detector module that has 
maximum spectral sensitivity at the same 
wavelength of the infrared LED.  
(b) Detector module operates at the exact 
frequency of our modulated data carrier 
 
5. RC5 CODING SCHEME 
Table 1.  RC5 frame format 
 
01
 
Fig. 2:  Bi-phase coding 
1 0 000 0 01 1111 11
Fig. 3:  Example of transmission 
The RC5 code is a 14-bit word bi-phase coded 
signal (see Table 1). The time period for 
representing one bit is 1.778ms. The two first bits 
(St1, St2) as shown in Table 1 are start bits, always 
having the value “1”. The next bit is a control bit 
(Ctrl), which is toggled every time a button is 
pressed on the remote control transmitter. Five 
system bits (A4, A3, A2, A1, and A0) hold the 
system address. The command sequence is six bits 
long (C5, C4, C3, C2, C1, C0), allowing up to 64 
different commands per address. The bits are 
transmitted in bi-phase code as shown in Fig. 2. An 
example where the command 0x35 is sent to system 
5 is shown in Fig. 3. 
6. SWITCHING SEVERAL DEVICES 
Fig. 4: Block diagram for switching several devices 
At remote 1 to 7 as shown in Fig. 4 buttons are 
encoded for controlling seven loads such as lights. 
Before pressing any button the status of the 14 bits 
data word is 00000000000000 & no data will be 
sent without pressing any button. When we press 
button 1 then   11100000000001 data will be sent. 
If we hold down the same button then the same data 
will be repeated at every 131ms. Similarly when we 
will press buttons 2, 3, 4, 5, 6, 7 then 
11100000000010, 11100000000011, 111000000-
00100, 11100000000101, 11100000000110, 
11100000000111 data will be sent respectively. 
When the above IR modulated data irradiates the IR 
receiver then micro controller starts the program for 
decoding & storing the data to its registers & 
according to command the micro controller gives 1 
(5V) or 0 (Zero volt or GND) to the corresponding 
output Pin such as P0.0 to P0.6 of AT89C51 
microcontroller [Mazidi and Gillispie 2007], which 
activate or deactivate the transistor (here saturation 
Page 692
  
 
mode or cutoff mode) for relay driving purposes. In 
this way we easily control load (light) on/off. 
7. SPEED CONTROL OF A SINGLE 
PHASE MOTOR 
The remote button as shown in Fig. 5 is encoded for 
controlling speed of a single-phase motor 
(FAN).When pressing this button then 
corresponding data (11100000001101) will be sent 
which will be received by 
Fig. 5:  Block diagram of speed control of a single-
phase motor. 
micro controller & according to command the 
micro controller will give 1 (5V) or 0 (0V or GND) 
to the corresponding output Pin such as P0.7, P2.5, 
P2.6, P2.7 of AT89C51 microcontroller [Mazidi 
and Gillispie 2007]. Here relays are used to change 
the resistance value of the variable resistance so 
that firing angle of the TRIAC will be changed. In 
this way we easily control the speed of a single-
phase motor (FAN).  
8. WATER LEVEL CONTROL OF AN 
OVERHEAD TANK 
 
Fig. 6:  Block diagram of water level control of an 
overhead Tank. 
The remote button as shown in Fig. 6 is encoded for 
controlling the motor of the overhead tank. When 
pressing this button then corresponding data 
(11100000001100) will be sent which will be 
received by micro controller & according to 
command the micro controller will give 1(5V) or 0 
(0V or GND) to the corresponding output Pin such 
as P2.2 of AT89C51 microcontroller [Mazidi and 
Gillispie 2007], for relay driving purposes. In this 
way we easily control the motor. Further detail 
when motor will start then water level will be rising 
& as soon as it touch the upper level then it will 
block the path of LASER transmitter & thus the 
output of the phototransistor receiver will be 
changed (from 0V To 5V) & this changing state 
will be sensed by the AT89C51 microcontroller 
[Mazidi and Gillispie 2007] Input Pin P2.0, which 
further processed & give the output 0 (0V) to the 
P2.2 of AT89C51 microcontroller [Mazidi and 
Gillispie 2007] for stopping the motor. Again when 
water level will decrease for uses of water then as 
soon as it will drop to lower threshold level it will 
open the path of LASER transmitter & thus the 
output of the phototransistor receiver will be 
changed (from 0V To 5V) & this changing state 
will be sensed by the AT89C51 microcontroller 
[Mazidi and Gillispie 2007] Input Pin P2.1 of 
which further processed & will give the output 1 to 
the port for starting the motor. In this way water 
level is limited between lower & upper level. 
9. OPENING\ CLOSING A DOOR 
Fig. 7:  Block diagram of closing/opening a door. 
 
Fig. 8:  Block diagram of the direction Control of 
the motor 
Page 693
  
 
The remote button as shown in Fig. 7 is encoded for 
controlling the door open & close. When pressing 
the upper portion of this button then corresponding 
data (11100000010000) will be sent which will be 
received by micro controller and according to 
command the micro controller will give 1(5V) & 0 
(0V or GND) to the corresponding output Pin such 
as P2.3 & P2.4 of AT89C51 microcontroller 
[Mazidi and Gillispie 2007] for relay driving 
purposes. In this way we easily control the door 
open & close. Further detail when motor will start 
to one direction then door will be moved for 
opening or closing purpose & when the door just 
cross the path of line of sight LED & 
phototransistor then phototransistor output will be 
changed (From 0V To 5V)  & this changing state 
will be sensed by the micro controller input Pin 
P1.6 or P1.7 of AT89C51 microcontroller [Mazidi 
and Gillispie 2007] which further processed & will 
give the output 0 (0V) to the output Pin P2.3 & 
P2.4 of AT89C51 microcontroller [Mazidi and 
Gillispie 2007] for stopping the motor & thus door 
will not thrust the wall. When pressing the lower 
portion of this button then corresponding data 
(11100000010001) will be sent which works as like 
as the upper portion of this button but in opposite 
direction. Here two sensors are used for properly 
speed control of the door motor. From above block 
as shown in Fig. 8 we see that when any one relay 
acts as switch then the current flow in one direction 
& as a result the motor rotate at the certain 
direction & when another relay acts as switch & the 
other stays normal position then the current flows 
in the reverse direction & as a result the motor 
rotate at the reverse direction. In this way we can 
easily control the door open & close. 
10. TEMPERATURE MONITOR 
 Fig. 9:  Block diagram of the temperature monitor. 
At first the temperature sensor senses the 
environment temperature then it gives analog 
voltage to the analog to digital converter (ADC). 
Then this analog voltage is converted to the 8 bits 
data by ADC0804 [configuration at <http:// 
www.Alldatashit.Com>] in 1(5V) & 0 (0V) format. 
This 8 bits data accept by the AT89C2051 micro 
controller input port1 [Mazidi and Gillispie 2007] 
which further process according to its program, & 
gives 4 bits data to the output Port3, which is input 
of the 7 segments SN74LS47 [configuration at 
<http:// www.Alldatashit.Com>] decoder for 
displaying temperature value in decimal format. 
Also many AVR microcontrollers (such as 
ATMEGA8 [configuration at < http:// 
www.Atmel.Com>]) have own ADC. So we can 
use this ADC to take analog data & by its 
instruction we can convert analog to digital data 
and can send this digital data to PORT or by 
programming it can display to LCD as shown in 
Fig. 10.  
11. COMPLETE CIRCUIT DIAGRAM 
 
 
 
 
 
 
 
Fig. 10: circuit diagram of temperature display Unit 
 
Fig. 11: circuit diagram of Control Unit 
Page 694
12. PROGRAM FLOW CHART 
 
 
 
 
Page 695
  
 
13. PICTURE OF MY COMPLE PROJECT 
Fig. 12:  Transmitter (Remote) 
Fig. 13:  Receiving & Processing unit 
 
 
 
Fig. 14:  Temperature display on the LCD 
14. RESULT AND CONCLUSION 
The overall performance of the project is very good 
& the response is so fast that as soon as the remote 
bottom is pressed it corresponding load activates 
simultaneously. In some case such as temperature 
display error about 0.1C. But it is negligible. My 
control unit responses from 35 feet’s distance away. 
By using the idea of my project it is possible to 
design Universal receiver, Message transmitter and 
receiver, Automatic speed control of a single phase 
motor using fuzzy logic, Remote Control Traffic 
System, Robot, Car, Timer, Voltmeter, and 
Ammeter etc. 
 
REFERENCES 
1. Muhammad Ali Mazidi, Janice Gillispie 
Mazidi, Rolin D. Mckinlay. ‘The 8051 
Microcontroller and Embedded systems Using 
Assembly and C’. 2nd ed. 2007. 
2. <http:// www.Alldatashit.Com>  
3. < http:// www.Atmel.Com> 
4. < http://  
www.sbprojects.com/knowledge/ir/rc5.htm> 
5. < http:// www.Raynolds Electronics.Com> 
Page 696
* Corresponding Author: Mohiuddin Ahmad,  
E-mail: ahmad@eee.kuet.ac.bd  
PARAMETERS MEASUREMENT OF CIRCULAR SHAPED CABLES 
USING IMAGE PROCESSING TECHNIQUES  
 
 
Abu Naim Rakib Ahmed#, Dewan H. S. Salehin#, Mohammed Imran Hossain#, and 
Mohiuddin Ahmad#,&,* 
#Department of Electrical and Electronic Engineering, Khulna University of Engineering and 
Technology (KUET), Khulna – 9203, Bangladesh 
 
&Department of Biomedical Engineering, KUET, Khulna – 9203, Bangladesh 
 
 
Cable Parameter measurement is very important for various industrial applications. In general procedure this 
measurement is very laborious and time consuming. In general cases, the result obtained is not always 
satisfactory because of different core shape. In this paper, we introduce an image processing technique for 
measuring the cable parameters efficiently, rapidly, and automatically. For measurement, we only require a 
cross-sectional image of a cable to determine its parameters. The primary goal in this paper is to measure the 
thickness and diameter of cable insulation layers, based on image processing techniques. For capturing the 
cross section image, a magnifying glass and a high definition digital camera is used. Canny and 
morphological operation is used to extract the edge and refilling the edge of the cable. In order to fit the 
shape of cable, least-square ellipse fitting method is employed. Finally, cable insulation parameter is 
measured by using calibration coefficient. We successfully measure the parameters of different types of 
cable and comparing these values with their physical measurement. We obtain 0.17 to 0.50 percent 
measurement errors which represents that our proposed method is efficient and economic for cable 
parameter measurement. 
 
Key words: Cable Parameter; Circular Shape Detection; Image Processing Technique; Geometric 
parameters; Measurement error 
 
1. INTRODUCTION 
 
In conventional way of cable parameters 
measurement, the procedure is much complex and 
time consuming. Hence, a process is required in 
industrial works where precision and efficiency 
both is of essence. Digital image processing is 
introduced in this case where it not only increase 
measuring flexibility but also increases its accuracy 
and efficiency.  Measuring and testing of the 
insulation thickness and diameter of wire and cable 
is very much important for safety of electricity, 
material, equipment and personnel. Proper testing 
of wiring system after installation is essential to 
guarantee good operation in latter procedures. The 
cabling system needs to be measured after 
installation and the results of those measurements 
should be documented for later uses. Measurement 
is also used when cabling problems are suspected. 
However, the traditional method has enormous 
disadvantages due to worker involvement, vision 
tedium, and obviously time consumption. Computer 
vision is the branch of computer science concerned 
with the analysis of images to extract information 
of any sort. In computer vision, an image can be 
analyzed as required. So, a new method based on 
image processing is implemented to define the 
parameters of a cable. Some typical examples of the 
cables with single-core and multiple cores are 
shown in Fig.1.  
 
          
          
 
Fig. 1: Various types of cables 
 
In this method, for cable parameter measurement, 
the cable image is collected by using high 
definition camera. Then Gaussian filter is used for 
Page 697ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
  
smoothing purpose. A simple cable has many 
deformities and unusual substances within it. These 
produce unwanted value change in the picture and 
can be considered as noise. Thus a filter is required 
to eliminate these noises and the process here is 
called smoothing. Then the smoothed image is 
converted into its gray scale image.  
 
A color image has three data for every pixel. This 
data is not required when we need to identify the 
cable parameters. The next step is to detect the 
edges. For edge detection, canny algorithm is used. 
A Canny algorithm is a renowned algorithm to 
detect edges where a certain amount of value 
change is measured and marked as long as the 
change is over that threshold. After the Canny 
operation it can be observed that there are certain 
deformities in the curves. Sometimes it is not 
continuous even sometimes the curves have a 
tendency to be bent more or less than expected. So, 
refilling these curve points is required and in this 
case morphological operation is used. Finally, in 
order to fit the shape of cable, curve fitting 
algorithm is used. This curve fitting makes the 
system simpler and faster and different than other 
methods.  
 
Authors in (Fan and Zou, 2008) measure the cable 
insulation parameters based on an image processing 
techniques. They used binary edge detection and 
binary morphological operation for extracting the 
edge of the cable. The authors in (Shan et al., 2009) 
measured the cable insulation parameters by 
employing background segmentation. The authors 
in (Fan and Wang, 2009) improved the method 
mentioned in (Shan et al., 2009) by employing 
Canny edge algorithm (Canny, 1986) for edge 
detection. All above previous methods, they use 
single core cable.  
 
Instead of using the previous methods mentioned in 
(Shan et al., 2009, Fitzgibbon et al. 1999), our 
method provide greater flexibility, require less time 
and can be used for more than one layer of circular 
wire. Moreover, in our proposed method there is no 
prior foreground and background segmentation 
which is often required in cable parameter 
measurement in (Shan et al., 2009). Compared to 
method mentioned in (Fan and Zou, 2008), (Shan et 
al., 2009), or (Fan and Wang, 2009), our proposed 
method uses not only single core cables but also 
multi-core cables, which is the most faster and 
efficient method.  
 
The entire paper is organized as follows. Section 2 
discusses the composition of hardware system. 
Section 3 covers the acquisition and processing of 
the image where it also includes smoothing, color 
conversion, edge detection, refilling, curve fitting 
and system calibration. Section 4 describes the 
analysis of data and results of the entire work. 
Finally, section 5 concludes the whole work with 
future additions.  
 
2. HARDWARE SYSTEM SETUP 
 
This measurement consists of image acquisition, 
image analysis, and result output. In our paper, 
image acquisition includes magnifying glass and 
high definition camera, acquisition software, and 
computer. But it would better to employ a video 
digital microscope and a CCD camera for capturing 
the image of the cable. We process the image in a 
Windows XP service pack-2 environment with 
Microsoft Visual C++ where OpenCV software 
(http://sourceforge.net/projects/opencv/) is used for 
ease and efficiency. It mostly accomplishes image 
filtering, image conversion, edge detection, refilling 
curve, and curve fitting 
 
3. ACQUISITION AND PROCESSING 
OF IMAGES 
 
3.1 Image Acquisition 
Acquisition is partly a manual system that involves 
acquiring the image of the cable cross section and 
then inserting it in our processing environment. It 
can be evolved to an automated system by 
interfacing it with a computer but that is not our 
primary goal. The cable can be of any size. Cable of 
very small cross section makes the image quite 
unclear so a magnifying glass is included. Once an 
image is acquired we use this image as the input of 
our C\C++ program for further processing. 
 
3.2 Image Smoothing 
We know that the actual gathered images contain 
noises in the process of formation, transmission, 
reception, and processing. Even the actual image 
that we acquire has some problem of its own. The 
cable often has deformities and unnecessary 
substances. These are also accounted as noises. 
Noises deteriorate the quality of the image, blurring 
image and inundating features. This brings 
difficulties to the analysis. Therefore, the main 
purpose is to remove the image noise in the stage of 
pre-treatment. We use Gaussian filtering for image 
smoothing. In this purpose, we use the two-
dimensional isotropic Gaussian distribution form 
which is shown in (1). 
2
22
2
22
),(),( σ
πσ
yx
eyxpyxG
+
−
=                (1) 
In Eq. (1), p is the pixel value at any position of the 
image. This smoothing removes small-scale texture 
and noise for given spatial extent. The distribution 
Page 698
  
has a degree of smoothing or quality of smoothing 
which is denoted by σ, where σ is the standard 
deviation. The σ value is calculated by 
8.03.0)12/( +×−= nσ , where n=3 for horizontal or 
vertical kernel. The standard deviation value 
enables the user to make fine adjustments to the 
amount of spatial averaging that occurs in the 
image. Increasing the value of standard deviation 
results in an increase in the size of the Gaussian 
kernel mask and causes the Gaussian filter to 
remove more spatial frequencies from the specimen 
image.   
  
    (a) Source image                   (b) Smoothed image 
 
Fig. 2: Image smoothing 
 
Larger standard deviations offer greater noise 
reduction but more blurring of edges. We used a 
track bar to vary the smoothing level. For Gaussian 
smoothing 3 by 3 blocks size is taken in our 
program.  Figure 2 shows the image smoothing 
operation of a 3-core cable, where the left image (a) 
represents the source raw image and (b) represents 
the smooth image.  
 
3.3 Color conversion 
The image we acquire is an RGB color image. All 
three data types Red (R), Green (G) and Blue (B) 
are not necessary to determine the circular objects 
in an image. So we consider this extra data to be a 
burden and want to reduce these three into one 
parameter. Therefore, we convert it to a gray scale 
image. To convert any color to a gray scale 
representation of its luminance, one must obtain the 
values of its red, green, and blue (RGB) primaries 
in linear intensity encoding, by gamma expansion. 
We use (2) to convert the color image to the gray 
scale image.  
 
BGRGray ×+×+×= 114.0587.0299.0    (2) 
     
Smooth image                           Gray image 
 
Fig. 3: Color to gray image conversion 
 
The weights depend on the exact choice of the RGB 
primaries, but are typical. Usually, after performing 
the smoothing operation we convert the color image 
into gray image. Figure 3 shows the resulted gray 
image from color image. 
 
3.4 Edge Detection 
The Canny algorithm [5] is that it tries to assemble 
the individual edge candidate pixels into contours. 
These contours are formed by applying a hysteresis 
threshold to the pixels. This means that there are 
two thresholds, an upper and a lower. If a pixel has 
a gradient larger than the upper threshold, then it is 
accepted as an edge pixel; if a pixel is below the 
lower threshold, it is rejected. If the pixel’s gradient 
is between the thresholds, then it will be accepted 
only if it is connected to a pixel that is above the 
high threshold. Canny recommended a ratio of 
high: low threshold between 2:1 and 3:1.  Canny 
also introduced the notion of non-maximum 
suppression, which means that given the pre-
smoothing filters, edge points are defined as points 
where the gradient magnitude assumes a local 
maximum in the gradient direction.  We use 2 track 
bars for varying the threshold parameters.  Figure 4 
represents the extracted edges from gray images 
using canny edge detector.  
    
Gray image                  Edge extracted image 
 
Fig. 4: Edge extraction from the gray image 
 
3.5 Advanced Morphological Operations 
The morphological transformations are used in 
removing noise, isolating individual elements, and 
joining disparate elements in an image. 
Morphology can also be used to find intensity 
bumps or holes in an image and to find image 
gradients. There are three primary morphological 
functions: erosion, dilation, and hit-or-miss. Others 
are special cases of these primary operations or are 
cascaded applications of them. Dilation expands a 
region & erosion reduces. Moreover, dilation will 
tend to smooth concavities and erosion will tend to 
smooth away protrusions. Of course, the exact 
result will depend on the kernel, but these 
statements are generally true for the filled convex 
kernels typically used. Advanced morphological 
transformations include using erosion and dilation 
as basic operations. After the edge of the image is 
detected, we reconstructed the image by 
morphological operation. There are different types 
of morphological operations used in OpenCV 
Page 699
  
library (http://sourceforge.net/projects/opencv/). 
This includes opening, closing, morphological 
gradient, top hat and black hat. We use 
morphological gradient here for reconstructing or 
refilling the edge so that curve fitting will be much 
better. Figure 5 shows the morphological image 
output from edge image. 
 
  
Edge extracted image            Morphological Image 
 
Fig. 5: Morphological operation on edge image 
 
3.6 Curve Fitting 
Curve fitting is the process of constructing a curve 
or function that has the best fit to a series of data 
points, possibly subject to constraints. In our 
experiment, first we detect contours in the 
morphological image then fit the contours to each 
ellipse particularly. This recognition of contour 
then ellipse makes our work simpler and faster. Let 
us represent a general conic by an implicit second 
order polynomial (Fitzgibbon et al. 1999).  
 
0.),( 22 =+++++== feydxcybxyaxF xaxa  (3) 
where T][ fedcba=a  and T22 ]1[ yxyxyx=x . 
);( iF xa  is called the ‘algebraic distance’ of a point 
(x, y) to the conic 0);( =xaF . The fitting of a 
general conic may be approached by minimizing 
the sum of squared algebraic 
distances ∑
=
=
N
i
iA FD
1
2)()( xa of the curve to the N 
data points ix . In order to fit ellipses we would like 
to constrain the parameter vector a so that the conic 
that it represents is forced to be an ellipse. We 
check the appropriate constraint which is the 
discriminant, acb 42 −  be negative [6]. After the 
system is solved, ellipse center and axis can be 
extracted.  
 
 
Fig. 6: Ellipse fitting using least square method 
From an ellipse perimeter, we calculate the 
diameter of the circular object. The circumference 
of an ellipse is )(4 2εaEl = , where, a is the major 
axis, E is the elliptical integral of the second kind, 
and ε is eccentricity which is given by, 
aba /22 −=ε . By least square method, we can 
fit ellipse from some discrete spatial points, which 
is shown in Fig. 6. After measuring the 
circumference of the ellipse, we divide the result by 
π to have the diameter of the same circumference’s 
circle.  
 
      
 Morphological Image              Ellipse fitted image 
 
Fig. 7: Determination of ellipse of morphological 
image 
 
So many ellipses are detected in the ellipse fitting 
step, which is shown in Fig. 7. We eliminate the 
unnecessary ellipses by two steps: 
Step1: Small ellipse elimination: We used a track 
bar for removing the smaller ellipses. 
 
   
(a)                               (b)                        (c)  
  
Fig. 8: Removing of unnecessary ellipses from 
ellipse fitted image.  (a) Ellipse fitted image   (b) 
Image after elimination   (c) Ellipses/circles only 
 
Step 2: Higher eccentric ellipse elimination: We 
used a track bar which changes the acceptable ratio 
of minor and major axes to remove the unnecessary 
ellipses.  
The major and minor axes of the detected ellipses 
and their average values are directly found from the 
images, as shown in Fig. 8. These average values 
are the required parameters for measuring the 
diameter and length. As an example, we obtain 8 
ellipse/circles from the ellipse fitted image. 
 
3.7 System Calibration 
For calibrating the system we calculate a calibration 
constant k, which is multiplied with the measured 
parameter to have the real value. For calculating the 
calibration constant k we need two values. (i) A 
Page 700
  
standard known diameter (d) value is taken, and (ii) 
For the known diameter the pixel diameter value 
(dpixel) is found from the program. Then the 
calibration constant is given in (4). 
pixelddk /=                                             (4) 
In the proposed method, at first the image is 
collected by the computer. Then after processing 
the image, the diameter can be measured in the 
calibrated measurement. The actual length L is 
measured by (5)  
kNL =                                             (5) 
where, N is the number of pixels. 
 
4. EXPERIMENTAL ANALYSIS 
 
In the previous section, we discuss different image 
processing techniques for measuring the physical 
parameters of a multi-core cable. We have collected 
several specimens of single core cable and multi-
core cable. In the previous section, we show the 
image processing steps of a multi-core cable. As an 
example, by using veriner caliper, we measure the 
inner and outer diameter of outer layer, which is 
shown in Table 1. In case of vernier method, we 
place the scale in different places and then take a 
few data. Then for getting the desired diameter or 
thickness, we average those data. Therefore, the 
length, or thickness, or diameter of the specimen is 
calculated by Eq. (6).  
Total reading = M.S.R + V.S.R×V.C   (6) 
Table 1: Inner and outer diameter of outer layer 
Core 1 Core 2 Core 3 
V
er
ni
er
 
m
et
ho
d 
Pr
op
os
ed
 
m
et
ho
d 
V
er
ni
er
 
m
et
ho
d 
Pr
op
os
ed
 
m
et
ho
d 
V
er
ni
er
 
m
et
ho
d 
Pr
op
os
ed
 
m
et
ho
d 
10.12 10.13 10.31 10.18 10.17 10.14 
 
Where, M.S.R, V.S.R, and V.C represent the main 
scale reading, vernier scale reading, and vernier 
constant, respectively. On the contrary, we measure 
the length by our proposed method which is shown 
in Table 1. From the measurement, the percentage 
error is 0.0988%, 1.26%, and 0.294% for core-1, 
core-2 and core-3 respectively.   
Table 2: Data for inner and outer diameter of outer 
layer 
Inner layer (diameter) Outer layer (diameter) 
Vernier 
method 
(mm) 
Proposed 
method 
(mm) 
Vernier 
method 
(mm) 
Proposed 
method 
(mm) 
50.21 50.30 59.30 59.12 
  
We measure the inner and outer diameter of the 
outer layer of the sample specimen, which is shown 
in Table 2. From our procedure, the inner layer 
diameter is 50.30 mm whereas the veriner caliper 
gives 50.21 mm. The percentage error is 0.30% for 
the outer diameter and 0.17% for the inner 
diameter.  We also measure the outer diameter of 
inner cores of the sample specimen, which is shown 
in Table 3. From the measurement, the percentage 
error is 1.06%, 0.25%, and 0.82% for core-1, core-2 
and core-3 respectively.  
Table 3: Outer diameter of inner cores 
Core 1 Core 2 Core 3 
V
er
ni
er
 
m
et
ho
d 
Pr
op
os
ed
 
m
et
ho
d 
V
er
ni
er
 
m
et
ho
d 
Pr
op
os
ed
 
m
et
ho
d 
V
er
ni
er
 
m
et
ho
d 
Pr
op
os
ed
 
m
et
ho
d 
18.8 18.6 20.4 20.35 20.67 20.50 
 
In order to compare our method with the 
conventional method, we also took a very small 
diameter cable of millimeter range (i.e. sample 2). 
The flow diagram of the image processing method 
is shown in Fig. 9.  
 
      
Source image                            Smoothed image 
 
              
Unnecessary ellipse elimination     Gray image 
                              
    
 Ellipse detection              Morphological image 
 
Fig. 9: Diameter Measurement of a cable using 
proposed image processing technique (sample 2). 
 
Page 701
  
For the sample-2, the following measurements are 
noted: M.S.R = 3mm, V.C= 0.05mm, V.S.R = 4. 
Hence,   total diameter = (3 + 4 × .05) = 3.2 mm. 
System calibration constant is measured as, k = d / 
dpixel. Here, d = 3.3 mm and dpixel=314mm. Thus, k 
= 0.01050955414.  This calibration constant is used 
in our program to measure the diameters of 
different layers. The measurement is shown in 
Table 4. 
Table 4: Conventional method and proposed 
method for cable diameter measurement (sample 2). 
Inner Layer(diameter) Outer Layer(diameter) 
V
er
ni
er
 m
ea
su
re
m
en
t 
(m
m
) 
A
ve
ra
ge
   
 V
al
ue
 (m
m
) 
Pr
op
os
ed
 M
et
ho
d 
(m
m
) 
V
er
ni
er
 m
ea
su
re
m
en
t 
(m
m
) 
A
ve
ra
ge
 V
al
ue
 
Pr
op
os
ed
  M
et
ho
d 
(m
m
) 
1.4 
1.38 
1.35 
1.35 
1.45 
1.25 
1.36
3 1.366 
3.2 
3.1 
3.2 
3.167 3.173 
 
From Table 4, the outer diameter is found 3.173mm 
in our method, whereas in classical method it is 
found 3.167mm. The percentage error is 0.19%. 
Similarly, the inner diameter is found 1.366mm in 
our proposed method, whereas it is 1.363mm by 
classical method. Here the percentage error is only 
0.22%. Therefore, the observed result is better 
enough for measuring the cable physical parameter. 
From the above inner and outer diameter we can 
easily determine the cable physical parameter. 
 
From above results, our work shows a better 
performance than the conventional method. The 
limitation of the proposed work includes the use of 
gray image as the input since we can get almost 
similar gray images from different color images and 
canny edge detector uses only gray image as input. 
 
5. CONCLUSIONS 
 
In this paper, we introduced a new procedure for 
measuring cable diameter using morphological 
operation and ellipse fitting method. Ellipse fitting 
method provides rapid action and improves 
performance. By using this method anyone 
hopefully get better result than other previous 
method. It provided greater flexibility and required 
less time than other conventional method. Diameter 
can be measured for several circular layers of any 
wire and we achieved higher degree of automation. 
This method can be used for determining very 
small diameter of any cable. In this paper, we 
measured the circular diameter of cable insulation 
layer for electric and optical cables using image 
processing techniques. In most cases, the error is 
not greater than 0.5%. The system makes use of 
high definition digital camera with USB interface 
without any additional acquisition card. Our future 
plan is to use canny algorithm for color image, 
which will give more accuracy 
 
REFERENCES 
 
1. Fan, L. Zou, and Wang, Y., (2008), Digital 
image processing techniques applied in cable 
insulation parameters measurement, IEEE Int’l 
Conf. on Automation and Logistics, Qingdao, 
China, September, pp. 2315-2319, 2008.   
2. Shan, Y. Wang, Y. and Fan, C., (2009), 
Research of measure system to cable insulation 
parameters based on computer vision, First 
Int’l Workshop on ETCS, Hubei, China, pp. 
776-779, March 2009. 
3. Fan, L. and Wang, D., (2009), The application 
of adaptive Canny algorithm in the cable 
insulation layer measurement,” Second Int’l 
Workshop on Computer Science and 
Engineering, pp. 217-222, 2009.  
4. OpenCV [Online]. Available: 
http://sourceforge.net/projects/opencv/.  
5. Canny, J., (1986), A computational approach to 
edge detection, IEEE Transactions on Pattern 
Analysis and Machine Intelligence, vol. 8, no. 
6, pp. 679-698, November 1986.  
6. Fitzgibbon, A. Pilu, M. and Fisher, R. B., 
(1999), Direct least square fitting of ellipses”, 
IEEE Transactions on Pattern Analysis and 
Machine Intelligence, vol. 21, no. 5, May 1999. 
 
 
Page 702
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Md. Habibullah,  
E-mail: mhueeekuet@gmail.com 
STEADY STATE ANALYSIS OF A CCI-FED INDUCTION MOTOR 
DRIVE WITH FIELD ORIENTATION CONTROL 
 
 
Md. Habibullah*       Md. Jahirul Islam       Md. Abdur Rafiq        
Department of Electrical and Electronic Engineering, Khulna University of Engineering and 
Technology, Khulna-9203, Bangladesh 
 
B. C. Ghosh  
Department of Electrical and Electronic Engineering, American International University-
Bangladesh, Dhaka-1215, Bangladesh 
 
 
Abstract- A definite relation exists between the flux level, torque and slip speed of a vector controlled 
induction motor drive. An untuned vector controller generates an inappropriate slip frequency that changes 
the operating flux of the machine. This affects the electromagnetic torque linearity and steady state 
performance including excess energy loss of the drive system. Proper selection of the magnetizing level 
reduces the energy loss as well as improves the steady state performance of the machine. This paper presents 
an analysis of field orientation controlled induction motor drive under steady state conditions. A power loss 
model of the induction motor is developed to select magnetizing level of the motors. Linear model of the 
induction motor with constant nominal parameters and nonlinear model with magnetic saturation by variable 
magnetizing inductance are considered in the analysis. The magnetizing inductance is expressed as a 
polynomial for a more realistic representation of a saturated induction machine. It is observed that the d-and 
q- axes current components affect the performance of the motor. This study also considers the effects of 
changes in machine variables and parameters on torque and speed response and power losses.  
 
Key words: Steady state; field orientation control; flux level; minimum loss; magnetic saturation.  
 
1. INTRODUCTION 
 
Induction motors have been used as work horse of 
industries for a long age due to their inherent 
constructional advantages. The motor has a 
complex structure comprising of mutually coupled 
magnetic and electric circuits. When the stator coils 
are excited by balanced electrical source, flux 
produced in the stator core sweeps past to the rotor 
core. The mutual flux system is common to coils 
both in stator and rotor and is responsible for the 
effective operation of the motor.  The leakage flux 
is responsible for causing voltage drop in the coils. 
Due to mutual coupling between stator and rotor 
coils, rotor receives power by induction. Like dc 
motor in an induction motor it can be assumed that 
the flux of rotor and perpendicular mmf in the 
stator or vice versa generates the electromagnetic 
torque. Other viewpoint assumes power developed 
in the rotor resistance as a measure of torque 
expressed in synchronous watts.  
    The performances of field-oriented induction 
motors with magnetic saturation have been reported 
in the literatures (Levi and Vuckovic, 1989, Vas 
and Alakula, 1990, Krishnan and Doran, 1987, 
Lorenz and Novotny, 1990). The d-q dynamic 
linear model of the field oriented induction motor 
drive has been extended to include the influence of 
saturation effects of the magnetizing flux linkage in 
(Levi and Vuckovic, 1989). In (Vas and Alakula, 
1990), a model of the field oriented induction motor 
in the space-vector formulation is used to study the 
drive dynamic performance in the field weakening 
region. The influences of changes of the 
magnetizing inductance and rotor resistance on 
drive performances are the subjects of the 
publications in (Krishnan and Doran, 1987, Lorenz 
and Novotny, 1990). In (Ojo and Vipin 1990), the 
researcher takes a different analytical approach to 
consider the simultaneous effects magnetizing 
inductance and rotor resistance variations due to 
temperature changes simultaneously. The effects of 
magnetic flux saturation on the performance of a 
current regulated field oriented induction motor 
drive in analytical form are shown in (Ghosh and 
Bhadra, 1997). Flux saturation also degrades the 
steady state performance of the induction motor 
drive due to the increased core losses. A study of 
Page 703ISBN: 978-984-33-2140-4
  
the nature of copper and core loss components 
reveals that their trends conflict when the core loss 
increases, the copper loss tends to decrease. 
However, for a given load torque, there is an air-
gap flux density at which the total loss is 
minimized. Hence, an electrical loss minimization 
process ultimately comes down to the selection of 
the appropriate operating air-gap flux density. 
Many researchers analyzed the effects of selecting 
flux level for minimizing the losses. They have 
established different loss models of induction 
motor. The model based controller computes losses 
by using the machine model and selects a flux level 
that gives minimum losses (Kirschen et. al., 1985, 
Lim and Nam, 2004, Dong and Ojo, 2006, Sul and 
Park, 1988) neglecting the leakage fluxes. A new 
power loss model of the induction motor based on 
constant parameters is proposed in (Nasiruddin and 
Nam, 2008). The analyses are equally applicable to 
current source or voltage source inverter fed 
induction motor drives.   
This paper endeavors to develop constant parameter 
and magnetic saturation based mathematical models 
of the induction motors to study the steady state 
performances of induction motor drives under 
parameter deviation conditions. It considers 
variations in current along reference axes to deduce 
the machine characteristics for different operating 
and parameter deviation conditions. Steady state 
speed response under parameter deviation 
conditions are also considered in the analysis 
maintaining the power loss in the motor is 
minimum.  
 
2. MATHEMATICAL MODELING 
 
Under the usual assumptions, an induction motor in 
terms of d-q synchronous reference frame variables 
is expressed in steady state conditions as (Garces, 
1980): 
qremqsesdssds iLiLiRv ωω −−=                  (1) 
 dremqssdsseqs iLiRiLv ωω ++=
                   (2) 
 Lmme TBJpT ++= ωω                             (3)                                   
  
( )qrdsdrqsmpe iiiiLPT −= )2/3(                (4)                                                                                                                             
 Where, 
 dsv  and qsv  = the dq-axis stator voltages; dsi  and 
qsi  = the dq-axis stator currents; sR  and rR  = the 
stator and rotor resistances; sL  and rL  = the stator 
and rotor leakage inductances; mL  = the mutual 
inductance; mω  = the angular speed of the motor; 
)( resl ωωω −=  = the slip angular speed; Te = the 
developed torque; LT  = the load torque; J  = the 
moment of inertia; B  = the rotational damping 
coefficient; pP  = the number of pole pairs; p  ≡ 
dtd /  .   
The current components along the reference axes 
are: 
θ
θ
sin
cos
sqs
sds
ii
ii
=
=
                                      (5) 
If the field orientation is established, q-axis rotor 
flux is forced to set zero by aligning d-axis along 
the rotor flux. With this, the following important 
relations are obtained: 
dsmdrr iL==ψψ                                              (6) 
ds
qs
r
sl i
i
τ
ω
1
=                                                        (7) 
qs
r
m
qr iL
L
I −=  and 0=dri                                (8) 
qsdr
r
m
pe iL
L
PT ψ)2/3(=      
                              (9) 
Where, )/( rrr RL=τ  is the time constant of the 
rotor. Hence, only q-axis stator current controls the 
developed electromagnetic torque if rotor flux is 
maintained constant.   
 
3. ANALYSIS OF MAGNETIZATION 
CHARACTERISTICS 
 
A proper magnetic model of the machine is 
required to have an exact idea about the 
performance of the IM drives. This study considers 
nonlinear magnetizing inductances to represent the 
induction motors with saturation. From the 
experimental data the true magnetization 
characteristic can be evaluated (Ghosh and Bhadra, 
1997, Bhadra, 1982). If V  be the applied rms 
voltage to an IM, the mutual flux linkage can be 
written as: 
)(2 mag
e
m ifV == ωψ                    (10) 
To obtain the above characteristic, the machines 
under test were driven at synchronous speed by an 
auxiliary motor and the stator was supplied from a 
constant frequency variable voltage source. From 
the recorded ammeter, voltmeter and wattmeter 
data after subtracting the stator resistance and 
leakage-reactance drops, the magnetizing 
Page 704
  
inductances are shown in Fig. 1 for a squirrel cage 
induction motor (SCIM). All necessary information 
of the motor including nominal parameters in table 
1 is given in the Appendix. 
0.0 0.5 1.0 1.5 2.0
0.0
0.2
0.4
0.6
0.8
1.0
(1.0, 0.82)
 Actual
 polynomial fit
 segmentwise fit
 
Y =-0.01874+1.22958 X-0.78742 X2+0.27603 X3-0.04749 X4+0.00312 X5
m
u
tu
a
l f
lu
x 
in
 
w
b 
(ψ
µα
γ)
Magnetizing current in amp (I
mag)
 
                                          (a) 
0.0 0.5 1.0 1.5 2.0
0.5
0.6
0.7
0.8
0.9
1.0
M
u
tu
a
l in
du
ct
a
n
ce
 in
 
he
n
ry
Magnetizing current in amp
 Actual
 Polynomial fit
 
                                        (b) 
Fig. 1: Magnetization characteristics (a) true 
saturation characteristic and (b) magnetizing 
inductance. 
 
4. POWER LOSS MODEL OF    
    INDUCTION MOTOR 
 
The total power loss model is developed based on 
(Nasiruddin and Nam, 2008) as follows: 
r
r
m
r RL
L
R 2)(=′              (11) 
ss LL σ=′              (12) 
sm LL )1( σ−=′             (13) 
frt RRR ′′=                         (14) 
rf
mr
sd RR
L
RR
′+′
′
+=
2)(ω
            (15) 
tsq RRR +=              (16) 
22
, qsqdsdtotalloss iRiRP +=            (17) 
Study on total power loss by varying the d-axis 
stator current for different torque output was carried 
out with and without considering saturation and 
shown in Fig. 2. It is shown that for constant 
current operation at lower value of dsi  the total 
power loss is higher. The loss decreases 
exponentially and reaches at minimum around ids= 
0.8A. So, by controlling the ids the loss in IM can be 
controlled.  
0.2 0.4 0.6 0.8 1.0
0
500
1000
1500
2000
2500
 6.0 N-m
 4.0 N-m
 2.0 N-m
To
ta
l p
ow
e
r 
lo
ss
 
in
 w
a
tt
S tator d-axis current in amp
    
                                       (a)                            
0.2 0.4 0.6 0.8 1.0
0
500
1000
1500
 6.0 N-m
 4.0 N-m
 2.0 N-m
To
ta
l p
o
w
er
 
lo
ss
 
in
 
w
a
tt
Stator d-axis current in amp
                        
                                       (b) 
Fig. 2: Variations of total power loss with Ids for 
different motor torques considering (a) without 
saturation (b) with saturation. 
 
5. STEADY STATE ANALYSIS 
  
For current controlled drives, the input current to 
the stator is considered as control variable. This 
current may be analyzed to the components along 
the field axis, dsi  and perpendicular to field axis, 
qsi . These current components are internally 
related to each other and generate magnetizing 
current mi  as follows: 
222 )()( qrqsdrdsm iiiii +++=                     (18) 
 Using (7) the current components along d-axis and 
q-axis under the field orientation is: 
slr
qsr
ds L
iR
i
ω
=                                     (19) 
Page 705
  
A control scheme to produce the reference current 
components and actual phase currents are shown in 
Fig. 3. A plot of qsi  versus dsi  along with 
222
qsdss iii +=  for different slip speeds with field 
orientation and nominal parameters is shown in Fig. 
4(a). It is evident that slip plays a vital role to 
correlate the current components along 
synchronous d-and q- axes. Maximum torque per 
ampere curve implies qsds ii =  and shown in Fig. 
4(a). In Fig. 4(b), the exponentially decreasing 
characteristics indicate slip speed variation and the 
inverted characteristics indicate stator q-axis 
current variation both with respect to stator d-axis 
current.  
 The electromagnetic torque developed by the IM 
under field orientation can be written as: 
qsds
r
m
pe iiL
L
PT
2
2
3
=                      (20) 
Considering nominal parameters, the torque 
characteristics as a function of qsi  satisfying 
222
qsdss iii += are shown in Fig. 5(a) increases from 
zero reaches a maximum and then decreases again 
to zero. The family of curves is due to different 
values of si as shown in the figure. It can be shown 
that the maximum value of electromagnetic torque 
is proportional to 2
si . The magnitude of stator 
current si  and its components d- and q- axis play  
0.0 0.5 1.0 1.5 2.0 2.5 3.0
0.0
0.5
1.0
1.5
2.0
2.5
3.0
 slip=5%
 slip=10%
 slip=15%
 slip=20%
 slip=25%
 Maximum torque/amp locus
 Constant stator current locus
St
at
or
 
d-
a
xi
s 
cu
rr
e
n
t i
n
 
a
m
p
Stator q-axis current in amp
 
                                             (a) 
0.0 0.5 1.0 1.5 2.0 2.5 3.0
0
20
40
60
80
100
120
0.0
0.5
1.0
1.5
2.0
2.5
3.0
Stator current
 1.5
 1.8
 2.1
 2.4
 2.7
Sl
ip
 s
pe
e
d 
in
 r
a
d/
se
c
St
a
to
r 
q-
a
xi
s 
cu
rr
e
n
t i
n
 
a
m
p
Stator d-axis current in amp
 
                                          (b)                                                                                         
Fig. 4: (a) Steady state characteristic of d- & q- axis 
stator currents for different slip speeds with field 
orientation and nominal parameters (b) Slip speed 
and q-axis current as function of d-axis current for 
different stator input current. 
A/C supply 
+ 
- 
 
Switching 
Signal 
generator 
 
 
Flux and 
Torque estimator 
Current 
Controlled 
Inverter 
     
eTˆ
*
rψ
  
rψˆ  
ωm 
iqs* 
ids* 
 Ias* 
 Ibs* 
 
bias IM 
 
 
α-β 
abc 
ia 
ib 
+ 
- 
rθˆ
sθˆ
τ  
Φ
Te* 
+ 
 
vθˆ
Slip 
calculator 
& 
Reference 
voltage 
generator 
*
mω
Fig. 3: Proposed IM Drive System 
Page 706
  
role in torque generation as indicated in (20). Fig. 
5(b) shows the variation of d-and q-axis 
components of stator current to produce electro- 
magnetic torques of different percentage of rated 
torque as a function of stator q-axis current. 
 
0.0 0.5 1.0 1.5 2.0 2.5 3.0
0
1
2
3
4
5
6
7
8
9 Stator current
 1.5A
 1.8A
 2.1A
 2.4A
 2.7A
To
rq
u
e
 
in
 
n
-
m
Stator q-axis current in amp
   
(a) 
0.0 0.5 1.0 1.5 2.0 2.5 3.0
0.0
0.5
1.0
1.5
2.0
2.5
3.0
 0.25 % of rated torque
 0.50 % of rated torque
 0.75 % of rated torque
 1.00 % of rated torque
 1.25 % of rated torque
 Maximum torque/amp locus
 Constant stator current locus 
St
a
to
r 
d-
ax
is
 
cu
rr
e
n
t i
n
 
am
p
Stator q-axis current in amp
(b)                                                                
Fig. 5: Variations of (a) electromagnetic torque (b) 
d-axis current as a function of stator q-axis current. 
 
In current controlled drive systems the command d- 
and q-axis components of currents can be written in 
terms of stator current vector *
si  and angle made by 
it with the d-axis ( say *ϕ ) as: 
*** cosϕsds ii =                         (21) 
*** sinϕsqs ii =              (22) 
Accuracy of the angle *ϕ  is required to maintain 
field orientation condition of the drive system. In 
the present study the variation of  ϕ  
]25.175.0[ ** ϕϕ −  is considered to evaluate the 
ratio of torque which is written as: 
**
*
2
** sincos
cossin)(
ϕϕ
ϕϕ
r
r
m
m
e
e
L
L
L
L
T
T
=            (23) 
Here mL  and rL  are calculated from saturation 
model and *
mL  and 
*
rL  are nominal values and are 
constants. The variations of ratio of torque ( eT / *eT
) as function of (ϕ / *ϕ ) are shown in Fig. 6. The 
error in stator current angle with respect to the rotor 
flux causes inaccurate computation of qsi and dsi . If 
magnetic saturation model is considered the 
inductances mL  and rL  change especially for 
higher values of dsi  that causes deviation of 
developed electromagnetic torque. The 
characteristics are greatly affected by the 
differences in the values of command torques. The 
ratio falls drastically at higher desired reference 
torque *eT , say 6 N-m as the angle ratio is greater 
than unity. On the other hand, the ratio increases at 
lower reference torque for the ratio of angles 
greater than unity. The command torque values are 
calculated with nominal parameters of the machine. 
The actual torque values are calculated using 
magnetic saturation model of the machine. This is 
why the ratio does not become unity when angle 
ratio is unity. 
Fig. 7 shows the speed response of the current 
controlled IM under parameter deviation condition. 
The power loss in IM is ensured to minimum by 
controlling the ids at 0.8 A. It is also observed that 
the speed response with stator resistance deviation 
is quite acceptable.   
 
0.8 0.9 1.0 1.1 1.2
0.6
0.8
1.0
1.2
1.4 Reference torque
 2.0 N-m
 4.0 N-m
 6.0 N-m
To
rq
u
e
 
ra
tio
 
(T
e
 
/ T
e*
)
Angle ratio (φ/φ∗)
 
Fig. 6: Effect of current angle error on the motor 
performance on torque ratio as functions of (ϕ / *ϕ
). 
Page 707
  
1.04 1.12 1.20 1.28 1.36
1431
1434
1437
1440
1443
Sp
e
e
d 
in
 
rp
m
Time in sec
 R
s
= R*
s
 R
s
= 0.8R*
s
 R
s
= 1.2R*
s
                                                          
Fig. 7:  Simulation on no load speed response with 
dsi = 0.8A. 
   
6. CONCLUSIONS 
 
Steady state analysis of current fed drives to 
produce electromagnetic torque has been carried 
out using different viewpoints and considerations. 
The relations between the d- and q-axis currents are 
indicated. For field orientation controllers, ids, iqs, 
and slip speeds are interrelated. These current 
components and slip speed affect torque generation. 
The maximum value of torque is found to appear at 
equal values of d- and q-axis components of current 
which can be visualized from Fig. 4(a). The errors 
in angle calculation for different torque outputs 
have a tendency to increase with the angle ratio for 
lower torques. But for high values of reference 
torque the characteristic is reverse in nature. The 
speed response of the motor at steady state with 
stator resistance deviation is found acceptable 
considering minimum power loss. However, the 
characteristics provide an idea to select the flux 
level in a field oriented induction motor controller. 
Hence, by controlling the flux producing current in 
IM the generated torque can be maximized and the 
power loss can be minimized. 
 
APPENDIX 
 
Name plate data: 3-phase; 415V; 1.8A; 1 hp; 50 
Hz; 4-pole; Y-connected. 
Parameters: 
Stator resistance, Rs =13.25 Ω 
Rotor resistance, Rr = 16.818 Ω 
Mutual inductance, Lm = 0.7114 H 
Stator self inductance, Ls = 0.7359 H 
Rotor self inductance, Lr = 0.7359 H 
Moment of inertia, J = 0.0075 Kg-m2 
Damping coefficient, B = 0.00107 Nm-sec/rad 
REFERENCES 
 
1. Levi E. and Vuckovic V., (1989), Field 
oriented control of induction machines in the 
presence of magnetic saturation, Electric 
Machines and Power Systems, 16(2), pp. 133-
147. 
2. Vas P. and Alakula M., (1990), Field oriented 
control of saturated induction machines, IEEE 
Trans. on Energy Conversion, 5(1), pp. 218-
224. 
3. Krishnan R. and Doran F.C., (1987), Study of 
parameter sensitivity in high-performance 
inverter-fed induction motor drive systems, 
IEEE Trans. on Ind. Appl., IA-23(4), pp. 617-
622. 
4. Lorenz R.D. and Novotny D.W., (1990), 
Saturation effects in Field oriented induction 
machines, IEEE Trans. on Ind. Appl., IA-
26(2), pp. 283-289. 
5. Ojo O. and Vipin M. (1990), Steady state 
performance evaluation of saturated field 
oriented induction motors, Conf. Rec., IEEE-
IAS, pp. 52-60. 
6. Ghosh B.C. and Bhadra S.N., (1997), Effects 
of flux level on a CSI-fed field- oriented 
induction motor, IEE Proc. on Electrical 
Power Appl., UK, 144(5), pp. 295-300. 
7. Kirschen D.S., Novotny D.W. and Lipo T.A., 
(1985), On-line efficiency optimization of a 
variable frequency induction motor drive, 
IEEE Trans. on Ind. Appl., IA-21(4), pp. 610-
615. 
8. Lim S. and Nam K., (2004), Loss-minimizing 
control scheme for induction motors, Proc. 
Inst. Elect. Eng., 151(4), pp. 385-397.   
9. Dong G. and Ojo O., (2006), Efficiency 
optimizing control of induction motor using 
natural variables, IEEE Trans. on Ind. Elect.,  
53(6), pp. 1791-1798. 
10. Sul S.K. and Park M.H., (1988), A novel 
technique for optimal efficiency control of a 
current-source inverter-fed induction motor, 
IEEE Trans. on Power Elec., 3(2), pp. 192-
198.  
11. Nasiruddin M. and Nam S.W., (2008), New on 
line loss-minimization-based control of an 
induction motor drive, IEEE Trans. on Power 
Elec., 23(2), pp. 926-932. 
12. Garces L.J., (1980), Parameter adaptation for 
the speed controlled static AC drive with 
squirrel cage induction motor, IEEE Trans. 
Ind. Appl., IA-16, pp.173-178. 
13. Bhadra S.N., (1982), A direct method of 
predict instantaneous saturation curve from rms 
saturation curve, IEEE Trans. on Magnetics,   
Mag-18(6), pp. 1867-1869.  
Page 708
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2010 
CERIE 2010, 11-13 January, Sylhet, Bangladesh 
* Corresponding Author: Omar Farrok,  
E-mail: omarruet@gmail.com  
 
Structural properties and temperature dependence of resistivity of pure 
Co material deposited Co/Si(001) and Co/glass thin films 
 
N.A. Shafi1, O. Farrok*, Z. Islam2 and J. Islam3 
 
1SAR SECURITIES LTD, Motijheel, Dhaka-1000. 
*Rajshahi University of Engineering & Technology, Rajshahi-6204, Bangladesh 
2University of Blekinge Institute of technology, Blekinge, Sweden.  
3Rajshahi University (RU) Rajshahi-6204, Bangladesh 
 
 
Cobalt (Co) thin films have been prepared by e-beam evaporation technique on glass, Si(001) and 
GaAs(001) substrates at a pressure of about 2×10-4 Pa. The thickness of the films 100 nm. The deposition 
rate of the films was about 0.93 nms-1. The as-deposited films have been annealed in open air for 4 hours at 
constant temperature of 523 K. X-ray diffraction (XRD) study reveals that 100nm Co films on glass 
substrate are microcrystalline in nature. Scanning Electron Microscopy (SEM) study of 100nm Co films on 
silicon and glass substrates indicate that there are no sign of grains in as-deposited films, and the surfaces are 
almost smooth and homogenous while they are seen to exhibit a number of grains in the films after 
annealing and the surfaces become rough. The elemental compositions of 100nm Co films on silicon and 
glass substrates have been estimated by Energy dispersive analysis of x-ray (EDAX) study. After a series of 
successive heating and cooling cycles of as-deposited films, the resistivity curves remain almost constant, 
this indicates the stabilization of the sample structure in the temperature range studied. These studies may be 
of importance for the application of this material in electronic and magnetic storage devices. Co thin films 
have been produced by electron beam bombardment heating technique and thickness meesures in Fizeau 
fringes method. Electrical resistivity are measured Van-der-Pauw technique. 
 
Key words: Resistivity, Homogenous, Microcrystalline, Atomic weight, Amorphous. 
 
1. INTRODUCTION  
 
The Co and Co-based thin film structures have 
attracted interest of several researchers in recent 
years due to their possible applications in many 
areas of technology, such as magnetic data storage, 
spin valve and microelectronic devices [1–3]. 
Recently, the area of growth of magnetic thin films 
on compound semiconductor substrates is being 
developed as being interesting from both the 
scientific and technological points of view in 
connection with spintronics [4–6]. Study of metal 
silicides has been a topic of intense basic and 
technological interest because of their potential 
applications in semiconductor industry as Schottky 
barriers, gates, Ohmic contacts, etc. [7-8]. The 
effect of silicide formation on the generation and 
the removal of defects is an important issue for 
better understanding of the mechanism concerning 
silicide formation. Wen et al. [9], through electrical 
measurements, reported that the implantation 
induced interstitials in Si were totally eliminated 
through the formation of Titanium Silicide (TiSi2) 
by the injection of vacancies. Similarly, silicidation 
reactions of metals on Si implanted with various 
species were also investigated [10] and it was found 
that the complete annihilation of implantation 
induced defects depends critically on the distance 
between the silicide/Si interface, the location of the 
original amorphous/crystalline interface, the 
annealing temperature, time etc. 
 
2. DISCUSSION AND RESULTS 
 
The SEM micrograph of as-deposited and annealed Co 
thin films of thickness 100nm on the silicon 
substrate and glass substrate are shown in Fig. 1,2, 
3 and 4[11]. The SEM images are also shown that 
there are no remarkable grains and impurities for 
the annealed Co films [12-14]. So, the surface study 
of as-deposited Co thin film on the silicon substrate 
exhibits very good smooth and homogeneous 
nature throughout the entire surface. The surface 
study of as-deposited Co film on the glass substrate 
exhibits smooth and homogeneous nature 
throughout the entire surface. Then the surface 
studies of annealed Co films on the silicon substrate 
and glass substrate do not exhibit smooth and 
Page 709ISBN: 978-984-33-2140-4
  
homogeneous nature throughout the entire surface.
  
 
Fig.1 SEM image of 100nm as-deposited Cobalt 
thin films on Silicon substrate. 
 
 
Fig.2 SEM image of 100nm annealed Cobalt thin 
films on Silicon substrate. 
 
 
Fig.3 SEM image of 100nm as-deposited Cobalt 
thin films on Glass substrate. 
 
 
Fig.4 SEM image of 100nm annealed Cobalt thin 
films on Glass substrate. 
 
 
Fig.5 EDX image of as-deposited Cobalt thin film 
100nm of Silicon substrate. 
 
The EDX image of as-deposited 100nm Co films 
on silicon substrate is shown in Fig. 5. It is seen 
that the intensity of peaks is very high. This peak is 
from silicon substrate. On the other hand the 
intensity for Co is low. This is due to the fact that 
the volume of the Co materials in the exposed area 
was less than that of silicon material. Only two 
peaks (one for Si and other for Co) indicate that 
there are no impurity atoms in the as-deposited 
film. After annealing, the EDX image of 100nm Co 
films on silicon substrate is shown in Fig. 6. Extra 
one peak oxygen is seen. The atomic weight of Co 
and Si is shown in tables-1and 2 [15]. 
 
 
Fig.6 EDX image of annealed Cobalt thin film 100nm 
of Silicon substrate. 
Page 710
  
 
 
Fig.7 EDX image of as-deposited Cobalt thin 
film100nm of Glass substrate. 
 
The EDX image of as-deposited 100nm Co films 
on glass substrate is shown in Fig. 7. The EDX 
image shows many peaks. The peaks are from 
silicon(Si), oxygen(O), sodium(Na), 
magnesium(Mg), calcium(Ca) and cobalt(Co). The 
origin of these peaks is the glass substrate. On the 
other hand the intensity for Co is low. This is due to 
the fact that the volume of the Co materials in the 
exposed area was less than that of glass material. 
After annealing, the EDX image of 100nm Co films 
on glass substrate is shown in Fig. 8. The atomic 
weight of Co, Si, Ca, Mg, Na and O is shown in 
tables-3 and 4. 
 
 
Fig.8 EDX image of annealed Cobalt thin film 
100nm of Glass substrate. 
 
Table 1. Elemental composition of as-deposited Co 
thin film on silicon substrate. 
Element 
  
 Net 
 Counts 
Weight % 
 
Weight % 
 Error 
Atom % 
 
Atom % 
 Error 
 Si  54128  98.25 +/- 0.78  99.16 +/- 0.79 
 Co  122  1.75 +/- 0.57  0.84 +/- 0.28 
Total   100.00  100.00  
 
 
 
 
Table 2. Elemental composition of annealed Co 
thin film on silicon substrate. 
Element 
  
 Net 
 Counts 
Weight % 
 
Weight % 
 Error 
Atom % 
 
Atom % 
 Error 
 O  11121  48.26 +/- 1.24  65.18 +/- 1.67 
 Si  34827  39.32 +/- 0.43  30.26 +/- 0.33 
 Co  1709  12.42 +/- 0.67  4.55 +/- 0.25 
Total   100.00  100.00  
Table 3. Elemental composition of as-deposited Co 
thin film on glass substrate. 
Element 
  
 Net 
 Counts 
Weight % 
 
Weight % 
 Error 
Atom % 
 
Atom % 
 Error 
 O  10509  43.18 +/- 1.10  59.91 +/- 1.53 
 Na  3069  6.36 +/- 0.25  6.14 +/- 0.24 
 Mg  559  0.63 +/- 0.12  0.58 +/- 0.11 
 Si  34707  32.85 +/- 0.35  25.96 +/- 0.28 
 Ca  3305  5.75 +/- 0.35  3.18 +/- 0.19 
 Co  1905  11.22 +/- 0.84  4.23 +/- 0.32 
Total  100.00  100.00  
Table 4. Elemental composition of annealed Co 
thin film on glass substrate. 
Element 
  
 Net 
 Counts 
Weight % 
 
Weight % 
 Error 
Atom % 
 
Atom % 
 Error 
 O  10536  43.65 +/- 1.11  60.13 +/- 1.54 
 Na  3113  6.36 +/- 0.58  6.10 +/- 0.56 
 Mg  574  0.64 +/- 0.13  0.58 +/- 0.12 
 Si  35419  33.35 +/- 0.35  26.17 +/- 0.28 
 Ca  3391  5.91 +/- 0.35  3.25 +/- 0.19 
 Co  1712  10.10 +/- 0.83  3.78 +/- 0.31 
Total   100.00  100.00  
Fig. 9 presents the XRD patterns of 100nm as-
deposited and annealed Co thin films. The XRD 
patterns corresponding to as-deposited film shows a 
remarkable peak around 2θ=44o indicating that the 
as-deposited Co film is mostly microcrystalline in 
nature [16]. XRD patterns of 100nm Co thin film 
annealed at 250oC for 4 hours show 
microcrystalline nature. According to XRD results 
the Co thin films are hexagonal-close-packed (hcp) 
system. The dhkl values are calculated from the 
intensity peak of the XRD spectra for Co thin films. 
The comparison between observed dhkl values and 
the standard dhkl values yields (hkl) values from the 
standard ASTM Card# 00-01-1294 [17].The (hkl) 
values are tabulated in Table-V. Its pattern shows 
the hcp crystal structure. Its pattern corresponding 
to this closely matches with highly oriented cobalt 
film in (002) plane [18-20]. 
Table 5. Data for Co thin films 
dhkl (observed) 
[Å] 
dhkl(ASTM Card# 00-01-
1294) [Å] 
hkl  
Status 
2.05799 2.04 002 As-deposited 
Annealed 
 
Page 711
  
 
Fig.9 XRD patterns of 100nm as-deposited and 
annealed Co thin films on glass substrate. 
 
Variation of resistivity with temperature for a 
typical undoped Co sample of 100nm thickness 
deposited on the silicon substrate as shown in Fig. 
10. As observed in the Fig. 10, the heating and 
cooling are almost reversible after four cycles of 
operation in the investigated temperature range. 
The heating and cooling rate was so manually 
maintained that it keeps a 4K/min for each 
operation with a 9 min of interval in between the 
cycles. During the first step of the heat treatment, 
Co thin film shows increase in resistivity in the 
temperature range. In Fig. 10, AB shows the first 
heating cycle, which represents the increasing of 
resistivity up to 473K. BC represents the first 
cooling cycle in air. In cooling cycle, it is observed 
that the resistivity decreases with decreasing 
temperature but does not follow the heating cycle 
BA. It is also noticed that in cooling cycle, the 
resistivity shows slightly an upward tendency that 
is negligible and after 9min of interval in between 
the cooling of first and heating of second cycle, the 
resistivity is approximately the same point to C.  
 
 
Fig.10 Resistivity vs. temperature curves for a 
100nm thick undoped Co thin film on silicon 
substrate. 
During the second step of the heat treatment, Co 
thin film shows a sharp increase in resistivity in the 
temperature range. In Fig. 10, CD shows the second 
heating cycle, which represents the increasing of 
resistivity up to 473K. The second heating cycle, 
CD goes below the first cooling cycle, CB. DE 
represents the second cooling cycle in air. In 
cooling cycle, it is observed that the resistivity 
decreases with decreasing temperature but does not 
follow the heating cycle DC. It is also noticed that 
in cooling cycle, the resistivity shows slightly an 
upward tendency that is negligible and after 9min 
of interval in between the cooling of second and 
heating of third cycle, the resistivity is 
approximately the same point to E. 
 
During the third step of the heat treatment, Co thin 
film shows a sharp increase in resistivity in the 
temperature range. In Fig. 10, EF shows the third 
heating cycle, which represents the increasing of 
resistivity up to 473K. FG represents the third 
cooling cycle in air. In cooling cycle, it is observed 
that the resistivity decreases with decreasing 
temperature but does not follow the heating cycle 
EF. It is also noticed that in cooling cycle, the 
resistivity shows slightly an upward tendency and 
after 9min of interval in between the cooling of 
third and heating of fourth cycle, the resistivity 
drops to G from H. 
 
During the fourth step of the heat treatment, Co thin 
film shows a sharp increase in resistivity in the 
temperature range. In Fig. 10, HI shows the second 
heating cycle, which represents the increasing of 
resistivity up to 473K. IJ represents the fourth 
cooling cycle in air. In cooling cycle, it is observed 
that the resistivity decreases with decreasing 
temperature but does not follow the heating cycle 
HI. Heating and cooling effect observed that fourth 
cycle resistivity is higher than others cycle.  
 
At the time of heat-treatment in air, it seems that in 
the virgin state of the film, these molecules have an 
empirical binding energy which is then supplied to 
the sample in post deposition. This type of 
observation is also noted in Zinge Oxide (ZnO) and 
Indium Oxide (In2O3)films [21-23]. It may be 
mentioned that the sample Co was the as-deposited 
on the silicon substrate. 
 
3. CONCLUSION 
The XRD patterns corresponding to as-deposited 
film shows a remarkable peak around 2θ=44o. XRD 
results the Co thin films are hcp system. Its pattern 
corresponding to this closely matches with highly 
oriented cobalt film in (002) plane. XRD study 
reveals that 100nm Co films on glass substrate are 
Page 712
  
microcrystalline in nature. SEM study of 100nm Co 
films on silicon and glass substrates indicate that 
there are no sign of grains in as-deposited films, 
and the surfaces are almost smooth and 
homogenous while they are seen to exhibit a 
number of grains in the films after annealing the 
surfaces become rough. The elemental 
compositions of 100nm Co films on silicon and 
glass substrates have been estimated by EDAX 
study. The EDX image of as-deposited 100nm Co 
films on glass substrate is peaks from silicon(Si), 
oxygen(O), sodium(Na), magnesium(Mg), 
calcium(Ca) and cobalt(Co). On the other hand the 
intensity for Co is low. This is due to the fact that 
the volume of the Co materials in the exposed area 
was less than that of glass material. The EDX 
image of as-deposited 100nm Co films on silicon 
substrate peak is very high. On the other hand the 
intensity for Co is low. This is due to the fact that 
the volume of the Co materials in the exposed area 
was less than that of silicon material. The 
interfacial resistance (IR) at the Co/glass interface 
is zero. 
 
REFERENCES 
 
[1]  R.T. Heap, S.J. Greaves, J. Phys. D. Appl. 
Phys. 27 (1994) 1343. 
[2] T. Pan, G.W.D. Spratt, L. Tang, L.L. Lee, Y. 
Feng, D.E. Laughlin, J. Appl. Phys. 81 (1997) 
3952. 
[3] S.P. Murarka, Silicide for VLSI Applications, 
Academic Press, New York, 1983. 
[4]  G.A. Prinz, Phys. Today 48 (1995) 58. 
[5] D. Wang, R. Wu, A.J. Freeman, Phys. Rev. 
Lett. 70 (1993) 869. 
[6]  S. Datta, B. Das, Appl. Phys. Lett. 56 (1990) 
665. 
[7]  S.P. Murarka, Silicides for VLSI Applications, 
Academic Press, New York, 1983. 
[8]  J.M. Poate, K.N. Tu, J.W. Mayer, Thin .lms – 
Interdi.usion and Reaction, Wiley, New York, 
1978. 
[9] D.S. Wen, P.L. Smith, C.M. Osburn, A. 
Rozgonyi, J. Electrochem. Soc. 136 (1989) 
466. 
[10] W. Lur, J.Y. Cheng, C.H. Chu, M.H. Wang, 
T.C. Lee, Y.J. Wann, W.Y. Chao, L.J. Chen, 
Nucl. Instrum. Meth. B 39 (1989) 297. 
[11] Esah Hamzah.1, Agung Purniawan.1, Mohd. 
Radzi Mohd. Toff2, June 2006, No. 21, 16-26, 
Jurnal Mekanikal. 
[12] BENNY JOSEPH* and C S MENON, E-
Journal of Chemistry, Vol. 5, No. 1, pp. 86-92, 
January 2008. 
[13] I Mustata1, A Anghel1, C P Lungu1, O 
Pompilian1, V Kuncser2 and G Schinteie2, 
Journal of Physics: Conference Series 100 
(2008) 082026. 
[14] Ho Yin Kwong, Man Hon Wong, Yuen Wah 
Wong and Kin Hung Wong, 
Rev.Adv.Mater.Sci. 15(2007) 215-219. 
[15] Sang Hyun Park,† Young Chan Son,† William 
S. Willis,‡ Steven L. Suib,*,†,‡,§ and Kenneth 
E. Creasy*,|| Chem. Mater. 1998, 10, 2389-
2398. 
[16] A. Sharma*, P. Bhatt, R. Brajpuriya, S. 
Tripathi, S.M. Chaudhari, Vacuum 78 (2005) 
47-51. 
[17] JCPDS Card# 4-0854, Joint Committee on 
Powder Diffraction Standards, Japan. 1969 
[18] A Kharmouche1,2,4, S-M Cherif2, A 
Bourzami1,A Layadi1 and G Schmerber3, J. 
Phys. D: Appl. Phys. 37 (2004) 2583–2587. 
[19] A. Sharma*, R. Brajpuriya, S. Tripathi, D. Jain, 
R. Dubey, T. Shripathi, S.M. Chaudhari, 
Materials Science and Engineering B 130 
(2006) 120–125. 
[20] S. Abhaya, G. Venugopal Rao, S. Kalavathi, 
V.S. Sastry, G Amarendra*, Surface Science 
600 (2006) 2762-2765. 
[21] Islam MN, Hakim MO, Rahman H. The effects 
of deposition variables on spray-deposited ZnO 
thin film prepared from Zn(C2H3O2)2. J. Mater 
Sci 1984;22:1379-84. 
[22] Ambia MG, Islam MN, Hakim MO, 
Temperature dependent studies on the 
electrical properties of pyrolytic ZnO thin film 
prepared from Zn(C2H3O2)2. J. Mater Sci 
1993;28:2659-63. 
[23] Hakim MO, Carrier compensation and 
activation energy studies in pyrolytic. 
Page 713
*Corresponding Author: Bobby Barua,
E-mail: bobby@aust.edu
        TRANSCIEVER CIRCUITS FOR PULSE BASED ULTRA 
WIDEBAND
   Bobby Barua* and Mohammad Shamim Imtiaz 
              Department of EEE, Ahsanullah University of Science and Technology, Dhaka , 
Bangladesh
Despite the fact ultra-wideband technology has been around for over 30 years, there is a newfound excitement 
about its potential for communications. In this paper we is specifically focused on a software radio transceiver 
design for impulse-based UWB with the ability to transmit a raw data rate of 100 Mbps yet encompasses the 
adaptability of a reconfigurable digital receiver. Here we introduce a transmitter and receiver of pulse based 
ultra wideband modulation. Direct sequence spread spectrum has become the modulation method of choice 
for wireless local area networks, and personal communication systems, because it’s numerous advantages 
such as jammer suppression, code division multiple access, and ease of implementation. Spread spectrum 
systems are most favourable for indoor communication needs and digital radio links, where most of the 
applications are found. We also observe its characteristics and complete the modulation techniques. The latter 
includes bit error rate testing for a variety of modulation schemes and wireless channels using a pilot-based 
matched filter estimation technique. Ultimately, the transceiver design demonstrates the advantages and 
challenges of UWB technology while boasting high data rate communication capability and providing the 
flexibility of a research test bed.
Keywords: ultra-wideband (UWB), Direct sequence spread spectrum (DSSS),wireless local area networks 
(WLAN’s), personal communication systems (PCS), code division multiple access (CDMA).
1. INTRODUCTION
Ultra-wideband is a radio technology that can be 
use at very low energy levels for short-range high-
bandwidth communications by using a large portion 
of the radio spectrum. The concept of UWB was 
formulated in the early 1960s through research in 
time-domain electromagnetic and receiver design, 
both performed primarily by Gerald F. Ross[1]. 
Through his work, the first UWB communications 
patent was awarded for the short-pulse receiver, 
which he developed while working for Sperry Rand 
Corporation. Throughout that time, UWB was 
referred in broad terms as “carrier less” or impulse 
technology. After that UWB was coined in the late 
1980s to describe the development, transmission, 
and reception of ultra-short pulses of radio frequency 
(RF) energy. For communication applications, high 
data rates are possible due to the large number of 
pulses that can be created in short time duration[2-3]. 
Due to its low power spectral density, UWB can be 
used in military applications that require low 
probability of detection. UWB also has traditional 
applications in non cooperative radar imaging, target 
sensor data collection, precision locating and 
tracking applications. 
UWB communications transmit in a way that doesn't 
interfere largely with other more traditional 'narrow 
band' and continuous carrier wave uses in the same 
frequency band[4-6]. However first studies show 
that the rise of noise level by a number of UWB 
transmitters puts a burden on existing 
communications services. This may be hard to bear 
for traditional systems designs and may affect the 
stability of such existing systems. 
In this paper we focused on a software based radio 
transceiver design for impulse-based UWB with the 
ability to transmit a raw data rate of 100 Mbps yet 
encompass the adaptability of a reconfigurable 
digital receiver. Here we also introduce a transmitter
and receiver of pulse based ultra wideband 
modulation. Direct sequence spread spectrum (DSSS) 
has become the modulation method of choice for 
wireless local area networks (WLAN’s), and 
personal communication systems (PCS), because it’s 
numerous advantages, such as jammer suppression, 
code division multiple access (CDMA), and ease of 
implementation. 
Page 714
 CERIE 2011, 11-13 January, Sylhet, Bangladesh
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
Fig. 1: Simulink model of DPSK DSSS  Transceiver.
2. SYSTEM MODEL
The designed model for the transceiver is shown in 
Fig-1, consists of a hierarchical system where blocks 
represent subsystems and oscilloscopes are placed 
along the path for display purposes. The DPSK 
DSSS modulation and dispread techniques are 
mainly use for designing the whole transceiver with 
the exception of receiving the signal using Bi-phase 
modulation. The design for pulse based UWB is 
divided into three parts as DSSS DPSK transmitter 
where transmitter part is separately designed, DPSK
DSSS transceiver where received signal has dispread 
with some propagation delay, DPSK DSSS 
transceiver with Bi-phase modulator and matched 
filter where original signal has recovered. The data 
signal, rather than being transmitted on a narrow 
band as is done in microwave communications, is 
spread onto a much larger range of frequencies (RF 
bandwidth) using a specific encoding scheme. This 
encoding scheme is known as a Pseudo-noise 
sequence, or PN sequence. Direct sequence spread 
spectrum has become the modulation method of 
choice for wireless local area networks, and personal 
communication systems. 
3. DPSK TRANSMITTER
DPSK DSSS transmitter consists of PN Sequence 
generator which generates a sequence of pseudo 
random binary numbers using a linear-feedback shift 
register, XOR used for mixing data, Unite delay 
used for delayed data and oscilloscopes are placed 
along the path for display purposes. Here, PN 
Sequence generator is used as both generating 
message and a sequence of pseudo random binary 
numbers for spreading process. When differentially 
encoding an incoming message, each input data bit 
must be delayed until the next one arrives. The 
delayed data bit is then mixed with the next 
incoming data bit. The output of the mixer gives the 
difference of the incoming data bit and the delayed 
data bit. The differentially encoded data is then 
spread by a high-speed pseudo noise sequence (PN). 
This spreading process assigns each data bit its own 
unique code, allowing only a receiver with the same 
spreading to dispread the encoded data. The 63-bit 
pseudo noise sequences (PN) used in this papers are 
generated by a 6th order maximal length sequence is 
given by,
                       6 5( ) 1g x x x                          (1)
Page 715
The maximal length spreading sequence uses a much 
wider bandwidth than the encoded data bit stream, 
which causes the spread sequence to have a much 
lower power spectral density. The transmitted signal 
is then given by,
                          ( ) ( ) ( )x t m t c t                     (2)
Where is the differentially encoded data, and 
is the 63 chip PN spreading code. For 
recovering of message sequence, we XOR the 
modulated signal with same type of 63-bit pseudo 
noise sequences (PN). Here we also use a unite 
delay to find the original signal. The signal 
recovering process is successfully done with some 
propagation delay which was obvious because of 
some noise & losses.
4. DPSK RECEIVER
Before demodulating the receiving signal is 
modulated by Bi-phase modulation technique then 
signal is split into two parallel paths and fed into two 
identical matched filters with the input to one having 
a delay of 63 chips. The outputs of the two matched 
filters are denoted by   and and are 
given by,
                1 0( ) ( ) ( )cx t d t t R t                         (3)
        2 0( ) ( ) ( )b c bx t d t t T R t T                (4)
Where the data is bit period, and is the 
autocorrelation function of the 63-chip 
pseudorandom sequence. Since there are exactly 63 
chips per data bit the PN sequence is periodic with 
.
( ) ( )c bR t R t T                                (5)        
So the two outputs of the matched filters are then 
mixed and then low pass filtered and the original 
message is recovered.
5. RESULTS AND DISCUSSION
Following the analytical approach presented in
section III and IV, we evaluate the simulation result 
of UWB technology. The simulations are performed 
using matlab, and the proof-of-concept is valid as 
the BER curves are slightly worse than theoretical 
values for a perfectly matched receiver due to the 
imperfections in the template caused by noise and 
aperture delay variation. Fig. 2 shows the original 
input message sequence that is generated from a PN 
sequence generator. Then, the incoming message are 
differentially encoded by using mixer and unite 
delay where each input data bit has delayed with 
Unit delay until the next one arrives where the 
delayed data bit is then mixed with the next 
incoming data bit. Fig. 3 shows such a differential 
output of the original message signal.    
Fig2:  Original  transmitted message signal.
Fig3: Differential output of original message signal.
Fig.4 Output waveforms of Simulink DPSK DSSS Transmitter.
Page 716
Fig5:   Original recovered output signal.
Eventually the mixer will give the difference of the 
incoming data bit and the delayed data bit. The 
differentially encoded data is then spread by a high-
speed 63-bit pseudo noise (PN) Sequence generator 
which is generated by a 6th order maximal length 
sequence. This spreading process assigns each data 
bit its own unique code which is shown in Fig. 4. , 
allowing only a receiver with the same spreading to 
dispread the encoded data.  
For recovering of message sequence in the receiving 
part of DPSK DSSS transceiver, the modulated 
signal has been dispread using  same type of 63-bit 
pseudo noise sequences and also use a unite delay to 
find the original signal. The signal recovering 
process is successfully done with some propagation 
delay which was obvious because of some noise & 
losses. Fig. 5 denoted the differential output of 
receiver side and the recovered messages.
6. CONCLUSIONS
We have analyzed the performance of UWB 
technology using Time Hopping (TH) technique. 
The results from the system simulation were very 
encouraging for the UWB receiver design presented 
in this paper. It was also shown by increasing the 
number of averaged pilot pulses in the pilot-based 
matched filter template, better performance can be 
obtained, although the data rate will suffer. 
Performance for multipath was also examined (albeit 
for perfect synchronization) and was close to the 
theoretical values. Finally, use of the template 
sliding matched filter synchronization routine led to 
worse BER performance when compared with 
perfect synchronization results. Although these 
simulations were specific in terms of data bits and 
number of multipath, other simulations were 
successfully run on a smaller-scale varying these 
two parameters. The results of the system simulation 
give a solid foundation for the design as a whole, but 
also will assist in the future with issues such as the 
implementation of receiver algorithms within the 
FPGA and determining timing limitations when the 
receiver is being constructed.            
7. REFERENCES
1. G. F. Ross, “Transmission and reception 
system for generating and receiving base-
band duration pulse signals without 
distortion for short base-band pulse 
communication system,” US Patent 
3,728,632, April 17, 1973.
2. Authorization of Ultrawideband 
Technology, First Report and Order, 
Federal Communications Commission, 
February 14, 2002.
3. C. R. Anderson, “Ultrawideband 
Communication System Design Issues and 
Tradeoffs,” Ph.D. Qualifier Exam, Virginia 
Polytechnic Institute and State University, 
May 12, 2003.
4. J. R. Foerster, “The performance of a 
direct-sequence spread ultra-wideband 
system in the presence of multipath, 
narrowband interference, and multiuser 
interference,” IEEE Conference on Ultra 
Wideband Systems and Technologies, May 
2002.
5. C. R. Anderson, A. M. Orndorff, R. M. 
Buehrer, and J. H. Reed, “An Introduction 
and Overview of an Impulse-Radio 
Ultrawideband Communication System 
Design,” tech. rep., MPRG, Virginia 
Polytechnic Institute and State University, 
June 2004.
6. J. Han and C. Nguyen, “A new ultra-
wideband, ultra-short monocycle pulse 
generator with reduced ringing,” IEEE 
Microwave and Wireless Components 
Letters, Vol. 12, No. 6, pp. 206-208, June 
2002.
7. S. Licul, J. A. N. Noronha, W. A. Davis, D. 
G. Sweeney, C. R. Anderson, T. M. 
Bielawa, “A parametric study of time-
domain characteristics of possible UWB 
antenna architectures,” submitted to IEEE 
Vehicular Technology Conference, 
February 2003.
Page 717
 
Page 718
This Page is Intentionally Blank  
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
*
 Corresponding Author: P.K. Shadhu Khan,  
E-mail: poritosh_k@hotmail.com 
UNIFIED POWER QUALITY CONDITIONER (UPQC): 
DEVELOPMENT OF HARDWARE USING FACTS 
TECHNOLOGY 
 
 
P.K. Shadhu Khan, M. R. Tanvir Hossain, Md. Rafiqul Alam and A. K. Sen Gupta 
Department of Electrical and Electronic Engineering 
Chittagong University of Engineering & Technology (CUET) 
P.O.: CUET, Chittagong-4349 
BANGLADESH 
 
Unified Power Quality Conditioner (UPQC), a relatively new device, can be used simultaneously in voltage 
or current control mode in power distribution system. But development of hardware with appropriate control 
circuit is a challenging task. In the voltage control mode, the UPQC can force the voltage of a distribution 
bus to be balanced sinusoids. At the same time it can also control perform load compensation resulting in the 
drawing of balanced sinusoidal currents from the distribution system bus in the current control mode. In this 
paper the hardware of the voltage source converter used for UPQC together with details of microcontroller 
based control philosophy has been presented. 
 
Key words: Flexible AC Transmission Systems, Distribution STATCOM, Power Quality, Unified Power 
Quality, Voltage Source Converter. 
 
 
1. INTRODUCTION 
 
The successful development of FACTS devices 
(Flexible AC Transmission System) is promoting 
major changes in controlling power flow in the 
transmission and distribution sectors of electric 
power utilities [1-4]. The voltage of a line can be 
controlled by means of a compensator located at the 
receiver end of the line.  The compensator delivers 
or draws reactive power in order to compensate for 
the unbalance or distortion. Traditionally, these 
compensators have been rotating machines or static 
var compensators that require large capacitors and 
inductors. Today, it is possible to replace these 
machines and devices by a switching converter, a 
dc capacitor, and a group of transformers. This 
static synchronous compensator (STATCOM), has 
numerous advantages over previous compensators. 
First, it acts much faster and can respond to voltage 
fluctuations in a matter of one cycle. Second, it can 
generate far more reactive power when the system 
voltage is low. 
 
In order to maintain constant sinusoidal terminal 
voltage and to meet reactive power demand of the 
rapid perturbations in load, feedback control system 
becomes essential. Recent trends in the 
development of processor technology and use of 
feed back control techniques in power industrial 
environment have helped in growth of newer types 
of integrated computer control strategies for 
utility’s voltage control.  
 
FACTS devices are modified to serve in 
distribution network and, through a modification of 
a unified power flow controller (UPFC) the unified 
power quality conditioner (UPQC) [1]. Such 
solution can solve different power quality 
problems, such as: sags, swells, voltage imbalance, 
flicker, harmonics and reactive currents. 
. 
UPQC usually consists of two voltage-source 
converters (VSC) sharing the same capacitive DC 
link. One of the converters is an active rectifier 
(AR) while other is a series filter (SF) with a LC 
ripple filter and transformer isolation from power 
supply network.  
 
Extensive research has been directed to control the 
Voltage Source Convert (VSC) through easily 
available simple microcontroller in the market. In 
this paper a thorough investigation on the control of 
a VSC of the UPQC has been presented. The 
performance results are also presented in the paper.  
 
 
Page 719ISBN: 978-984-33-2140-4
  
2. POWER AND DRIVER CIRCUITS 
 
The power circuit of the VSC is shown in the Fig.1, 
where RC snubber protections and fuse protections 
are inserted. Although a DC supply is shown at the 
left supply in the test circuit, it would replaced by a 
suitable capacitor in the practical STATCOM. The 
three-phase terminals at the right are connected to 
the supply in parallel and series configurations with 
a DC link capacitor in between to make a UPQC. 
 
Fig.2 shows the driver circuits for all the IGBT 
devices shown in Fig.1. Microcontroller generated 
appropriate pulses are given to the inputs of the 
optocoupler ICs used as isolation from power 
circuit to control circuit. The output of the driver 
circuit is connected to the gate of the respective the 
IGBT as marked in the figures. The pulses, we get 
from the microcontroller are not sufficient to run 
the IGBT. So, these pulses are amplified by the 
driver circuits.  
 . 
 
X11
gnd1
X13 X15
X14 X16 X12
gnd3
gnd5
gnd4 gnd6
gnd2
A
C
B
F6
30A
F5
30A
F4
30A
F3
30A
F2
30A
F1
30A
D6
D5
D4
D3
D2
D1
Q6
IGBT
Q5
IGBT
Q4
IGBT
Q3
IGBT
Q2
IGBT
Q1
IGBT
+ V2
200Vdc
C6
4.7uF
C5
4.7uF
C4
4.7uF
C3
4.7uF
C2
4.7uF
C1
4.7uF
L1
10uH
R6
2.7
R5
2.7
R4
2.7
R3
2.7
R2
2.7
R1
2.7
 
Fig 1 Power circuit with RC snubber and fuse protections 
 
0 0
0 0
0
gnd2
W_BOT
0
U_TOP
X11
gnd1
V_TOP W_Top
X13
gnd3
X15
gnd5
U_BOT
X14
gnd4
V_BOT
X16
gnd6
X12
U6
OP4N35 + V21
9VdcQ6
P2N2222A
Q5
P2N2222A
+ V51
9Vdc
U5
OP4N35
U6
OP4N25 + V61
9VdcQ4
P2N2222A
Q4
P2N2222A
+ V41
9Vdc
U4
OP4N25
Q3
P2N2222A
+ V31
9Vdc
U3
OP4N25U1
OP4N25 + V119VdcQ1
P2N2222A
R21
10
R22
1k
R25
100k
R23
1k
R24
5k
R54
5k
R53
1k
R55
100k
R52
1k
R51
10
R61
10
R62
1k
R65
100k
R63
1k
R64
5k
R44
5k
R43
1k
R45
100k
R42
1k
R41
10
R34
5k
R33
1k
R35
100k
R32
1k
R31
10R1110
R12
1k
R15
100k
R13
1k
R14
5k
 
Fig.2 Driver Circuits 
 
3. MICROCONTROLLER BASED 
CONTROL 
 
For gate pulse generation, easily available popular 
PIC16F72 microcontroller is used. It belongs to the 
Mid-Range family of the PIC micro devices. Its 
program memory contains 2K words, which 
translate to 2048 instructions, since each 14-bit 
program memory word is the same width as each 
device instruction. The data memory (RAM) 
contains 128 bytes. There are 22 I/O pins that are 
user configurable on a pin-to-pin basis [5]. Since 
instruction sets of this microcontroller are unable to 
efficiently handle mathematical operations common 
to many algorithms that are repeatedly executed in 
Page 720
  
time-critical loops, an off-line calculations are 
made and the data are used for PWM pulse 
generation. This gives a good experience on using 
microcontroller based control system. Fig. 3 shows  
the microcontroller used to interface to the gate 
drive circuits of Fig.2. 
 
Fig. 3 Connection diagram of PIC16F72 for six 
phase SPWM signal generation for IGBT gate 
driver circuit. 
4. SPWM SIGNAL GENERATION 
 
4.1 ASSUMPTIONS FOR CALCULATIONS 
 
Let us assume that we have to generate a 50 Hz sine 
PWM. For this we need a triangular carrier wave 
with 10 times the frequency of the desired sine 
wave. For simplicity we denote the factors with 
some symbols whose are listed below. 
Vs = instantaneous voltage of the sine wave 
Vm = maximum amplitude of the sine wave 
f   = frequency of the sine wave (50 Hz) 
t   = time 
T = period of the sine wave (20 ms) 
τ   = half of the period (10 ms) 
Vc = instantaneous voltage of the reference 
triangular wave   
Vcm = maximum amplitude of the reference 
triangular wave 
M = modulating index (0.8 is considered here)  
 
4.2 EQUATIONS AND TIME CALCULATION 
 
We have the equation of the sine wave is- 
Vs = Vm sin ωt                                 (1) 
For determining t1 according to Fig. 4 we get the 
equation for straight line containing t1 is     
Vc  =  (t1 – τ/10)                  (2) 
And the equation for the sine wave remains 
 Vs = Vm sin ωt1                                  (3) 
For determining t1 according to figure 4.1 we get 
the equation for straight line containing t1 is     
Vc  =  (t1 – τ/10)                (4) 
 
Fig.4 Comparison of positive half cycle 
For t1 we can equalize the two equations as below- 
(t1 – τ/10)  =   Vm sin ωt1 
=>       (t1 – τ/10)   =   sin ωt1 
=>       (t1 – τ/10)   =   sin 2pift1 
=>       (t1 – τ/10)   =   sin (2pi×50)t1 
=>       (t1 – 10ms/10)   
 =   sin 100pit1                                                (5) 
 
Solving (5) we get the value of t1  
t1 = 800.8429071 us 
 
Similarly solving the equation considering the 
straight line containing t2 we get the value of t2 
 
 (t2 – 10ms/10)  =   sin 100pit2  
                                                               (6) 
=> t2 = 1.323 ms 
 
Solving the equation considering the straight line 
containing t3 we get the value of t3  
 
(t3 – 5τ/10)  =   Vm sin ωt3 
   (t3 – 30ms/10)  =   sin 100pit3   
                                                                     (7) 
=> t3 = 2.444299507 ms 
Page 721
  
 
Similarly other instants t4 - t10 are calculated and all 
are summarized below. 
t1 = 801us 
t2 =1.323ms 
t3 =2.444ms 
t4 = 3.738ms 
t5 = 4.224ms 
t6 = 5.776ms 
t7 = 6.262ms 
t8 = 7.556ms 
t9 = 8.677ms 
t10 =9.199ms 
 
By subtracting the two consecutive times we find 
out the duration of pulses. This duration together 
with the logic states for 10ms are shown in Table 1. 
These are done only for sinusoidal half wave length 
for 10 ms from where we create the logic states of 
PWM signals. Now for the other phases and their 
logic states we have to calculate the phase shift of 
the subsequent phases in terms of delay in ms or us. 
 
Table 1:  Duration of Pulses 
Amplitude 
States 
No. Durations 
0 1 801us - 0 s   =   801 us 
1 2 1.323 ms - 801us =522 us 
0 3 2.444 ms - 1.323 ms =1.121 ms 
1 4 3.738 ms - 2.444 ms =1.294 ms 
0 5 4.224 ms - 3.738 ms =486 us 
1 6 5.776 ms - 4.224 ms =1.552 ms 
0 7 6.262 ms - 5.776 ms =486 us 
1 8 7.556 ms - 6.262 ms =1.294 ms 
0 9 8.677 ms - 7.556 ms =1.121 ms 
1 10 9.199 ms - 8.677 ms =522 us 
0 11 10 ms - 9.199 ms =801 us 
 
From 0 s to 40 ms (2 cycles) sequentially we get the 
six logic states for every time intervals which are 
shown in Fig. 5 and Fig.6. 
 
Fig.5 1st half logical states of six phase pulses 
 
 
Page 722
  
 
Fig.5 2nd half logical states of six phase pulses 
 
The waveforms of gate pulses for all the devices for 
the duration of 40 ms as mentioned above are 
shown in Fig, 6, 
 
Fig. 6 Three phase waveforms in terms of six gate 
signals 
5. RESULTS AND DISCUSSION 
 
The experimental setup of the hardware based on 
the circuit configurations mentioned before is 
shown in Fig. 7. 
 
Fig. 7 Experimental Setup 
 
Page 723
  
Suitable software has been developed for PIC16F72 
microcontroller using mikroC programming 
language using the logic states and durations as 
mentioned before. The pulses we get from the 
microcontroller is enough to run the driver circuits 
of IGBTs. The high magnitude of the pulse is 4.98 
volts when it is connected to the gates of the 
IGBTs. Output from the driver circuits for different 
phases are shown Fig.8 to Fig.10. 
 
 
Fig 8: Pulses at U_TOP and U_BOT 
 
 
Fig 9: Pulses at V_TOP and V_BOT 
 
 
Fig. 10: Pulses at W_TOP and W_BOT 
 
It is observed that the output obtained from the 
experimental closely matches with those of 
theoretically obtained results. 
 
6. CONCLUSION 
 
FACTS based three phase UPQC system can be 
implemented to address the power quality issues 
such as to eliminate voltage distortions or dips, to 
improve voltage regulation etc with the integration 
of shunt and series active filter etc. Hardware 
details of the VSC used for UPQC have been given 
in this paper. SPWM technique used in this paper 
for improving power quality is more sophisticated, 
reliable, economical and feasible, has the ability to 
suppress certain number of harmonics depending 
on number of pulses per half cycle in the PWM 
wave. They also have compatibility with today’s 
digital microprocessor/microcontroller and lower 
power dissipation. It is observed that as simple 
PIC16F72 microcontroller is able to generate the 
required pulses. Complete system integration of an 
UPQC is of further interest. 
 
REFERENCES 
  
1. Fujita Hideaki and Akagi Hirofumi, (1998), 
The Unified Power Quality Conditioner: The 
Integration of Series and Shunt Active Filters, 
IEEE Transactions on Power Electronics, 
March, pp.315-322. 
2. Jones A.T., Gazaraian A.T., Warne D.F., 
(1999), Flexible AC Transmission Systems 
(FACTS), IEE Power and Energy Series, The 
Institution of Electrical Engineers, UK. 
3. Moran L., Pastorini I., Dixon J.  and Wallace 
R.,(2000), Series Active Power Filter 
Compensates Current Harmonics and Voltage 
Unbalance Simultaneously, IEE Proceedings 
on Generation, Transmission and Distribution, 
Vol.147, No.1, January, pp.31-36. 
4. Jain S.K., Agarwal P.  and Gupta H.O., (2002), 
Fuzzy Logic Controlled Shunt Active Power 
Filter for Power Quality Improvement”, IEE 
Proceedings on Electric Power Application, 
Vol.149, No.5, September , pp.317-328. 
5. MICROCHIP - PIC16F72 Data Sheet 
 
Page 724
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh  
 
 
*Corresponding Author: S. M. Sharif, 
E-mail: sharif-phy@sust.edu 
 
VARIATION OF NONLINEAR REFRACTIVE INDEX AND 
NONLINEAR  ABSORPTION CO-EFFICIENT OF LiNb0 3 CRYSTAL 
DUE TO VARYING WAVELENGTHS 
 
 
S. M. G. Rabbani, S. M. Sharif * 
Department of Physics, Shahjalal University of Science and Technology, Sylhet-3114, Bangladesh. 
 
Y. Haque, S. K. Das, N. Chawdhury and M. M. Parvez   
Department of Physics, Shahjalal University of Science and Technology, Sylhet-3114, Bangladesh. 
 
 
The nonlinear refractive index, n and the absorption co-efficient,  of an undoped z-cut photorefractive LiNbO3 
crystal has been investigated here by the Z-scan technique using a continuous wave (cw) laser beam from a 
multiline argon-ion laser at two different wavelengths. Here both the sign and magnitude of the measured n and 
 are considerably different from each other. In the present work, the Z-scan measurement shows that LiNbO3 
has both negative and positive nonlinear refractive index and its magnitudes are 0.67 × 10	
cmW	  and  
0.64 × 10	
cmW	 at the wavelengths of 514 nm and 488 nm respectively. A fit of the absorption co-efficient 
data gives the value of  to be 6.8 × 10	 cmW	 and −18 × 10	 cmW	 at the 514 nm and 488 nm. 
. 
Key words: Z-scan; LiNbO3; Nonlinear refractive index; Nonlinear absorption co-efficient. 
 
1. INTRODUCTION 
 
Refractive index changes induced by light are 
commonly described by the relationship 
n =  n + nI                              1 
where, n is the linear refractive index, n is the 
nonlinear refractive index coefficient and I is the 
intensity of the light beam. When a Gaussian beam 
impinges on a nonlinear medium, the light intensity at 
the centre of a beam is larger than that of the edge; as 
a result, the refractive index of the medium is 
maximum along its optical axis, and decreases 
radially as a function of distance from the center of 
the beam, which is responsible for the refractive 
index being spatially inhomogeneous. This light-
induced refractive index change can have a 
considerable effect on laser beam propagation in a 
nonlinear medium, which leads to the well known self 
action effect phenomena, such as self-focusing, self 
de-focusing, self-phase modulation, self-bending, 
beam fanning, and multiple ring patterns (Prasad and 
Williams, 1991, Shen, 1984, Brugioni and Meucci, 
2002, Henari and MacNamara, 1993, Khoo and 
Wood, 1997, Abdeldayem and Witherow, 1994). A  
 
 
lot of materials have been found to exhibit laser-
induced refractive index changes, such as liquid 
crystals, solid crystals, fullerenes etc. 
 
The reliable Z-scan technique (Sheik-Bahae et al., 
1989) is a simple sensitive, single beam method to 
determine both the nonlinear refractive index and the 
nonlinear absorption co-efficient of a given material. 
This method has sensitivity comparable to 
interferometric methods. This technique has been 
extended to other measurements such as laser beam 
quality measurement (Agnesi et al., 1990), two color 
time-resolved thermal lensing (Castillo et al. , 1990), 
nondegenerate two photon absorption, and 
nondegenerate nonlinear refractive index (Sheik-
Bahae  et al., 1992). It has also been used for the 
investigation of Gaussian beam propagation 
(Banergee et al., 1991). In the Z-Scan technique, a 
sample is scanned along the optical axis in the focal 
region of a single Gaussian TEM beam. The 
transmission through the sample, with and without an 
aperture in the far field is then recorded.
Page 725
ISBN: 978-984-33-2140-4
  
 
The transmission with an aperture (closed aperture) 
characterizes the sign and magnitude of the nonlinear 
index, while the transmission without an aperture 
(open aperture) characterizes the nonlinear 
absorption. This is a simple and sensitive technique 
for measuring the change in phase induced on a laser 
beam upon propagation through a nonlinear material. 
It gives both the sign and magnitude of this phase 
change, ∆φ, which is simply related to the nonlinear 
refractive index, n.  
 
In 1990, a sensitive measurement of the optical 
nonlinearity was presented using a single beam 
(Sheik-Bahae and Said, 1990). Employing the Z-scan 
technique, a sensitivity of better than λ 300⁄  
wavefront distortion was achieved in n  
measurements of BaF2 using a picoseconds 
frequency-doubled Nd:YAG laser pulse. They 
demonstrated this method for ZnSe at 532 nm where 
two-photon absorption was present and n was 
negative. In 1995, beam waist change in a 
photorefractive LiNbO3 crystal was presented during 
the Z-scan measurement (Henari et al., 1995). Their 
experimental results showed that the minimum beam 
waist had been broadened and they measured the sign 
of the nonlinear refractive index as negative and the 
magnitude was found to be 1.5 × 10	
cmW	. In 
1996, Both the sign and the magnitude of n of 
LiNbO3 with a picoseconds pulsed laser at 532 nm 
was investigated (Li et al., 1996). They observed the 
sign of the n as positive and the magnitude to be 
0.53 × 10	!cmW	.In 2007, Optical nonlinearities 
of periodically poled LiNbO3 crystal was investigated 
by the same technique with a cw beam at 532 nm 
(Chen et al., 2007). They observed the sign nonlinear 
refractive index as negative and the magnitude to be  
0.13 × 10	
cmW	. The nonlinear refractive index 
of LiNbO3 determined using the Z-scan technique,  
with a picoseconds pulsed laser at 532 nm, is 
different in both sign and magnitude from the 
obtained result using a cw laser beam at 514 nm with 
a low laser power. So there is much room for 
investigation of the sign and magnitude of n and  of 
LiNbO3 at different wavelengths. Furthermore, 
LiNbO3 is an important nonlinear optical material 
with a variety of applications. Nonlinear optical 
properties of LiNbO3 have been subjected to 
numerous investigations. Therefore, in order to clear 
the ambiguity of the sign and magnitude of n of 
LiNbO3, an experimental investigation was 
undertaken to find the nonlinear refractive index and 
nonlinear absorption co-efficient of LiNbO3 by the Z-
scan technique using a cw laser beam at 514 nm and 
488nm respectively. 
2. EXPERIMENTAL DETAILS 
 
The geometry of the experiment is shown in Fig.1. 
 
 
 
 
 
 
 
 
 
 
 
                                        
                                          (a) 
 
 
 
 
 
 
 
 
 
 
 
 
                                          (b) 
 
Fig 1: (a) Experimental setup for open aperture Z-
scan measurements. (b) Experimental setup for closed 
Z-scan measurements. 
 
The experiment was performed using an air cooled 
multiline Ar-ion laser operating at the wavelength of 
457-514 nm. A 5276 lines/cm diffraction grating was 
used to separate the wavelengths. Among the various 
diffracted light waves, the wavelength of 514 nm was 
chosen for the measurement. This beam was 
separated into two parts by a beam splitter. The 
reflected part was taken as the reference beam 
representing the incident light and the transmitted 
beam was focused by a convex lens, with a focal 
length of 252 mm, to achieve the focal waist radius of 
~24µm. The sample was mounted on a linear 
translator and was moved with a high degree of 
precision. The c-axis of the sample was set parallel to 
the gradient direction of the Gaussian beam, i.e., the 
z-axis.  This beam was made to pass through the 
LiNb03 sample (thickness of 1 mm). The open 
aperture Z-scan measurement was then performed on 
the crystal. The ratio of the power of two beams was 
determined as a function of the crystal position. The 
               Beam                     
  Laser  Splitter Lens   Sample                 
 
   Detector 1         -z   ← z=0 → +z            Detector 2 
   Detector 1       -z   ← z=0 → +z               Detector 2 
                Beam                     
 Laser    Splitter   Lens   Sample                        Aperture 
 
Page 726
  
 
second detector was used as a reference to control the 
possible temporal variations of the laser power. In 
every position of z, the measurement was made after 
the build-up of the beam distortion. By plotting the 
ratio of the signal of two detectors as a function of z, 
The Z-scan trace was obtained as shown in Fig. 2. For 
the closed aperture Z-scan measurement, an aperture 
was inserted in front of one of the detectors to select 
the central part of the beam. The size of the aperture 
(1 mm in diameter) was much smaller than the beam 
size in the plane of the aperture, and the lens-aperture 
distance was much larger than the scanning range. In 
every position of z, the measurement was made, after 
the build up of the beam distortion. This experiment 
was repeated for the wavelength of 488nm. The Z-
scan method cannot be used to obtain a quantative 
result for the light-induced change in refraction 
because this is only possible through the fitting 
process. If the beam preserves its circular cross 
section, the material parameter, n and β can be 
determined from the fitting of the Z-scan traces. 
 
z in mm
-20 -15 -10 -5 0 5 10 15 20
N
o
rm
al
iz
ed
 
Tr
an
sm
itt
an
ce
 
T(
z
)
0.75
0.80
0.85
0.90
0.95
1.00
 
Fig. 2 Measured open aperture Z-scan trace of a l mm 
thick LiNb03 sample using a multiline Argon-ion 
laser at λ =  514 nm. The solid line shows the 
theoretical fit. 
z in mm
-20 -15 -10 -5 0 5 10 15 20
N
o
rm
al
iz
ed
 
Tr
an
sm
itt
an
ce
 
T(
z)
1.0
1.1
1.2
1.3
1.4
1.5
1.6
1.7
 
Fig. 3 Measured open aperture Z-scan trace of a l mm  
thick LiNb03 sample using a multiline Argon-ion 
laser at λ =  488 nm. The solid line shows the 
theoretical fit. 
 
z in mm
-20 -15 -10 -5 0 5 10 15 20
N
o
rm
al
iz
ed
 
Tr
an
sm
itt
an
ce
 
T(
z)
0.7
0.8
0.9
1.0
1.1
1.2
1.3
 
Fig. 4 Measured closed Z-scan trace of a l mm thick  
LiNb03 sample using a multiline Argon-ion laser at 
 λ =  514 nm indicating the negative nonlinearity.  
The solid curve is a theoretical fit with ∆φ =  −1.05  
and  s =  0.2 
 
 
Page 727
  
 
z in mm
-20 -15 -10 -5 0 5 10 15 20
N
o
rm
al
iz
ed
 
Tr
an
sm
itt
an
ce
 
T(
z)
0.7
0.8
0.9
1.0
1.1
1.2
1.3
 
 
Fig. 5 Measured closed aperture Z-scan trace of a 
l mm thick LiNb03 sample using a multiline Argon- 
ion laser at  λ =  488 nm indicating the positive 
nonlinearity. The solid curve is a theoretical fit 
with ∆φ =  1 and  s =  0.25 
 
 
 
3. RESUTS AND DISCUSSION 
 
For the open aperture Z-scan measurement the 
normalized transmittance can be written as (Henari et 
al., 1995), 
 
Tz = 1 − 
qz
2√2
                                  2 
With 
qz =
IβL)**
1 +
z
z
α
                                   3 
 
where,  is the nonlinear absorption co-efficient of 
the sample, 
           I is the intensity of the laser beam at the focus 
(z = 0), 
           L)** =
	)+α,
α
 is the effective length of the 
sample, 
           z = piω
/λ is the confocal parameter, where 
ω is the Gaussian beam waist radius at the focus,  
           . is the linear absorption coefficient and  is 
the wavelength of the laser . 
Fig. 2 and Fig. 3 show the measured open aperture Z-
scan trace of a l mm thick LiNb03 sample using a 
multiline Argon-ion laser at  and 488 nm 
respectively. The solid lines in these two figures are 
the theoretical curve while the symbol is the 
experimental data. By fitting, the obtained nonlinear 
absorption co-efficient was   and 
 at the 514 nm and 488 nm 
respectively. Fig. 4 shows transmittance changes as a 
function of position of the sample used to measure 
normalized peak-valley transmittance difference, 
 . The normalized transmittance for the closed 
aperture Z-scan is given by (Henari et al., 1995) , 
 
 
 
Here,  and  is the on-axis phase change 
caused by the nonlinear refractive index of the 
sample. The solid line in Fig. 4 and Fig. 5 are 
obtained from fitting the above equation using 
 and  respectively. The value 
of on-axis phase change can also be calculated from 
the peak-valley transmission difference using the 
following equation (Sheik-Bahae et al., 1989): 
 
 
 
where,  is the aperture linear 
transmittance with denoting the aperture radius and 
 denoting the beam radius at the aperture in the 
linear regime. The non linear refractive index,  is 
given by (Henari et al., 1995) 
 
 
 
where is the on-focus intensity inside 
the sample with P the laser power and 
 the linear absorption coefficient. 
The peak-valley sequence of Fig. 4 indicates a self-
defocusing effect, i.e., LiNb03 has a negative 
refractive nonlinearity but the peak-valley sequence 
of Fig. 5 indicates a self-focusing effect, i.e., LiNb03 
has a positive nonlinearity. Using the value of 
operating laser power, the on-axis 
intensity inside the sample, 
 and  
are measured respectively and at this value of , the 
measured value of the refractive index of LiNbO3 
crystal is and 
 at the wavelengths of 514 nm 
Page 728
  
 
and 488 nm respectively. The first result is in good 
agreement with the experimental results reported by 
Fryad. Z. Henary et al. (Henari et al., 1995). It is 
found that the sign of nonlinear refractive index of 
LiNbO3 induced by a cw laser beam at wavelength of 
514 nm is negative and the magnitude is 
 and whereas the sign of  is 
positive and the magnitude is 0  
at the wavelength of 488 nm. This observed 
discrepancy seems to be significant.  
 
4. CONCLUSION 
  
We have presented an investigation of the nonlinear 
refractive index of pure z-cut LiNb03 crystal by the Z-
scan technique using a
 
cw laser beam from an air-
cooled multiline Ar-ion laser at two different 
wavelengths of 514 nm and 488 nm. By fitting, the 
nonlinear absorption co-efficient of LiNbO3 is found 
to be   and  
at the 514 nm and 488 nm respectively, using the 
normalized peak-valley transmittance difference, the 
nonlinear refractive indices  
and  are measured. The first 
result is same in sign to the result observed previously 
using a cw laser beam at the wavelength of 514 nm. 
However the second result exhibits a positive sign at 
the wavelength of 488 nm which is in agreement with 
the result observed by a picoseconds pulsed laser at 
the wavelength of 532 nm. Further investigations are 
in progress in this issue to be done at different 
wavelengths to verify these results. The origins of our 
observed nonlinearities are believed to be attributed 
to the photorefractive effect in the LiNbO3 crystal. 
  
ACKNOWLEDGEMENT 
 
We gratefully acknowledge the Department of 
Physics, SUST for providing the research facilities to 
enable us to carry out the research and we are also 
indebted to Prof. Md. Younus and Prof. S. M. Saiful 
Islam of the Dept. of Chemistry, SUST for their help 
with the experimental setup.  
 
REFERENCES 
 
1.     A.Agnesi, G. C. Reali, and A. Tomaselli,  
        (1990),  Opt. Lett. 17, 1764. 
2.     Fryad. Z. Henari, Karl Cazzini, Fathi El  
        Akkari, and Werner J. Blau, (1995), Appl. Phys.  
        78(2). 
3.     F. Z. Henari, S. MacNamara, O. Stevenson, et  
        al. (1993), Adv. Mater. 5, 930.   
4.     Heping Li, Feng Zhau, Xuejun, Wei ji,  
        (1996), App. Phys. B 64, 659. 
5.     H. Abdeldayem, W. K. Witherow, A. Shields,  
        et al. (1994), Opt. Lett. 19, 2068.  
6.     J. Castillo, V. P. kozich, and A. Marcano  
        (1990), Opt. Lett. 19, 171. 
7.     J. C. Khoo, M. V. Wood, and B. D.  
        Guenther  (1997), MRS Proc. 474, 229. 
8.     M. Sheik-Bahae, A.A. Said, and E.W.  
        Van Stryland (1989), Opt. Lett. 14, 955. 
9.     M. Sheik-Bahae, A.A. Said, T.H. Wei,  
        D.J. Hagan, and E.W. Van Stryland  
        (1990),  IEEE  Journal of  Quantum  
        Electronics, QE- 26, 760. 
10.   M. Sheik Bahae,  J. ang, R. De Savo, J.  
        Hagan, and E.  Van Stryland (1992), Opt. Lett.  
        17,  258. 
11.   P. N. Prasad and D. J. Williams  
        (1991), Introduction to nonlinear Optical  
        Effects  in Molecules and Polymers  
        (Wiely, New York). 
12.   P. P Banergee, R. M. Misra, and m.  
         maghraouri (1991), J. Opt. Soc. Am. B 8, 1072. 
13.   S. Brugioni and R. Meucci (2002), Opt.  
        Comm. 206, 445. 
14.   Y. R. Shen (1984, 1989), The Principles  
        of Nonlinear Optics (Wiley, New York; Nauka,            
        Moscow). 
15.   Yunlin Chen, S. W. Liu, Dongdong  
        Wang, Tianlin Chen, and Min Xiao  
        (2007),  Appl. Opt. 46, 7693. 
 
Page 729
Proceedings of the 
International Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
2 Corresponding Author: M.S.R. Shoaib, 
E-mail: shoaibeee@gmail.com  
VLSI DESIGN OF AN ULTRA-LOW-POWER FUNCTIONAL CHIP 
USING MIRROR-AMPLIFIER FOR PRECISION SENSOR 
APPLICATIONS 
 
 
Imran Chowdhury1, Rumana Amin1, M.S.R. Shoaib1, 2, 3, Dr. Shuza Binzaid4 
 
1Department of Electronics and Communication Engineering 
1University of Information Technology and Sciences (UITS), Dhaka, Bangladesh 
2Bangladesh University of Engineering and Technology (BUET), Dhaka 
3Bioelectric Research Lab, Dhaka, Bangladesh 
4Founder and Director, SERES, seres-usa.com 
 
 
Device density in VLSI today enforces the process of chip designing much more complex; whereas MAGIC 
CAD tools made the IC design in this work, comparatively easier. Study on various amplifiers for sensor 
applications showed that their powers ranged from a few milliamperes to a few hundred milliamperes at the 
submicron fabrication processes by MOSIS, but within the affordable cost. Objectives of lowering the power 
at least by 1000 times in those fabrication processes engaged this research towards completing a new design, 
called the mirror-amplifier. This design is verified for precise functional behavior for the sensor and total 
power consumption, using MAGIC extractor and PSPICE electrical simulation tools. A compact model chip 
layout made silicon area more efficient for MOSIS tiny-chip fabrication in 0.6µm processes. To make even 
more economical, a multi-die placement technique was applied to the chip layout for this tiny-chip in silicon 
area of 1500µmX1500µm. MOSIS design rules for multi-die fabrication was verified for process scribe-lines 
and die packaging. This paper presents details of the key research works, results, completed chip layout and 
packaging of the chip. 
 
Key words: Mirror-Amplifier; Compound Device; Mixed-Signal Chip; Precision Sensor; Chip Package. 
 
1. INTRODUCTION 
 
As MOS Integrated Circuits (ICs) have come to 
dominate analog, digital, and mixed-signal 
electronic circuit designs over the last 15 years [1], 
the pressure to reduce system cost has favored all-
CMOS solutions over systems that mix bipolar and 
CMOS chips or use Bi-CMOS technology [2]. In 
current design practices, bipolar devices are usually 
found only in very-high performance wired and 
wireless designs, where extreme device 
specifications (high ft, low noise, and superior 
matching) require high-yielding, power-efficient 
components [3]. Similarly, compound 
semiconductor devices are used only in the case of 
very high-speed circuits in applications running at 
GHz level with low power [1]. With a continuing 
reduction of MOS transistor channel lengths, 
modern CMOS silicon processes offer transistor 
with a higher cut off frequencies [4]. So as it is 
known that CMOS technology is capable to 
implement radio frequency (RF) transceivers, 
recently many researches on radio frequency (RF) 
ICs in GHz-level-band have been accelerated 
because of the potential Industrial, Scientific, and 
Medical (ISM) band and the wireless vehicular 
radar applications [5-6, etc.]. CMOS processes that 
have been developed primarily for logic are now 
also used as amplifier and sensor [7]. Several 
researchers have presented CMOS amplifiers for an 
optical receiver with external photo detectors [8-10, 
etc.]. Most of these amplifiers depend on analog 
CMOS process technologies. Recently, there have 
been attempts to use standard digital CMOS 
technologies since there are more demands to have 
analog and digital circuits on same chip allowing a 
very high bandwidth and very low power at the 
same time [10]. 
 
Today’s electronics industry is increasingly focused 
on the consumer marketplace, which requires low-
cost high-volume products to be developed very 
rapidly. This, combined with advances in deep sub-
micron technology has resulted in the ability and 
the need to put entire systems on a single chip. As 
more of the system is included on a single chip, it is 
Page 730ISBN: 978-984-33-2140-4
  
very likely the chip will contain both analog and 
digital sections, which make the IC, design 
procedure a lot more complex [11]. The increasing 
complexity and decreasing feature size have made 
the demand of IC products more compact with 
more facilities and low power and fabrication cost. 
With this thought as a goal, this paper presents a 
proposal of ultra low power mixed signal mirror-
amplifier with its VLSI design and packaging that 
can be used as precision sensor. The proposed 
circuit is basically composed of two differential 
amplifiers as mirror-amplifier having a NAND gate 
between them. Hence the designed chip is 
composed of both analog and digital signal 
handling capability with high bandwidth (GHz).In 
science and industry, accuracy is the degree of 
conformity of a measured or calculated quantity to 
its actual, nominal, or some other reference value. 
We cannot have accuracy without precision. Precise 
characterization to the degree of mutual agreement 
requires a series of individual measurements, 
values, or results. Op-amp with high DC open-loop 
gain combined with low input offset voltages and 
offset bias currents can be used as precision sensor 
[12]. In this study CMOS differential amplifiers 
have done this job with mirror architecture. 
 
2. CIRCUIT DESIGN 
 
The figure 1 represents the schematic of the mirror-
amplifier circuit. Construction of this circuit 
consists of two differential amplifiers creating 
mirror architecture and a NAND gate between them 
makes it also digital compatible. It contains total of 
14 MOS transistors in which 6 of them are p-MOS 
(M1-M6), and rest 8 are n-MOS (M7-M14). The 
operation of the circuit is done by total of five input 
terminals (Vsensor, Vbias, Clock, and two ChipEN) 
and one output terminal Vout with constant DC 
supply of 5V. 
 
 
 
 
Fig 1: PSpice schematic of the mirror-amplifier. 
 
3. CIRCUIT LAYOUT 
 
To design the concerned schematic of mirror-
amplifier in VLSI layout structure MAGIC 7.5 is 
used with the process configuration of 0.6µm that is 
supported by MOSIS with a package of 
1500µmX1500µm tiny-chip die. The figure 2 
below represents the VLSI layout of the mirror-
amplifier. The total design of the circuit layout 
consists of 3 portions, where 2 of them are 
differential amplifiers acting as input stage with 
mirror architecture and the rest-one is output stage 
in the form of NAND gate. Dimensions of MOS 
transistors are chosen according to the requirements 
of optimization. Lengths of all MOS transistors are 
same that is 2λ but for the input stage the ratio of p-
MOS to n-MOS widths is 6:3 and for the output 
stage is 12:6. For designing a single transistor, p-
diffusion and n-diffusion are used for p-MOS and 
n-MOS respectively with poly-silicon to make the 
gate. In the whole circuit layout layer-1 and layer-2 
metals are used for connecting nodes (wires), where 
poly contact, p-diffusion contact, n-diffusion 
contact and via-1 contacts are needed as contact 
materials. The layout has area of 126λX59λ or 
37.8µmX17.7µm in 0.6µm CMOS process. 
 
 
 
Fig 2: VLSI layout of the mirror-amplifier. 
 
4. SIMULATION RESULTS 
. 
To verify the circuit operation and get the output 
toggle point for an optimized precision sensing 
operation towards ultra low power dissipation, 
simulation is done in two steps in this study. In the 
1st step, Output is taken with respect to node 4 with 
0.9V DC (threshold) supply at node 5 and 0V to 
2.5V clock pulse at node 3. In this case output 
toggles and get steady at 2.5V (above threshold) 
giving a power dissipation of 8.41 milliwatts. It is 
found that Hysteresis at threshold voltage level 
causes dynamic power loss [13]. This design has 
flexibility of voltages to bias CMOS circuitry. 
 
 
 
Fig 3: 1st step simulation result from the MAGIC 
extraction file of the designed layout using PSpice. 
Page 731
  
In the 2nd step, output is taken with respect to node 
5 with 2.5V DC supply at node 4 that is got in the 
1st step. Clock pulse is still 0V to 2.5V. In this case 
output toggles and get steady at 0.9V that is the 
threshold voltage of MOS transistor. Power 
dissipation is 9.13 nanowatts in this case. Thus 
system is improved for ultra-low-power operation.  
 
 
 
Fig 4: 2nd step simulation result from the MAGIC 
extraction file of the designed layout using PSpice. 
 
One of the goals of this paper is to achieve low-
power circuit designs, which already satisfied in the 
1st step simulation techniques. But it showed sign of 
dynamic power losses due to Hysteresis. Among 
several solution of Hysteresis, one is adding 
external feedback resistor to the chip. The 2nd step 
simulation technique was taken for the better 
operation of the designed circuit. This way the 
output becomes single shot output as the sensor 
voltage ramps from 0V to 5V. 
 
5. CHIP LEVEL DESIGN 
 
The chip level design procedures come with the 
steps of pad frame design, pin configuration, floor 
planning etc. Pad is designed with the dimension of 
90µmX90µm according to the MOSIS 
specifications and 60µmX60µm glass opening over 
the pad for bonding purpose [14]. The pad frame 
consists of 16 pads in total. The designed mirror-
amplifier is set in the pad frame that consumes total 
of 1967λX1967λ or 590.1µmX590.1µm in CMOS 
0.6µm processes. So for multi-die placement for 
economical consideration, the total silicon size 
(MOSIS Tiny Chip at 0.6µm process) of 
1500µmX1500µm is divided into 4 sub-dies with 
the scribe lines of 50µm. Hence the total area 
needed for this multi-die placement is 
1380.2µmX1380.2µm which is very efficient for 
this design. 
 
Floor planning can be done manually by hand, or 
by using interactive tools. In this study floor 
planning is done manually and then implemented 
by MAGIC. Total pin configuration of the multi-die 
placement is given in the table 1, and figure 5, 6 
represent the view of the complete ICs as floor-
planned with single mirror-amplifier and dual 
mirror-amplifier respectively. 
Table 1: Pin configuration 
 
Die Modules Pin 
Name 
Pad # 
Sub-die # 
1,2 
Single 
mirror-
amplifier 
Vdd 
GND 
EN1 
EN2 
Clock 
Bbias 
Vsensor 
Vout 
4 
13 
16 
3 
1 
2 
15 
14 
NAND 
gate 
Vdd 
GND 
In1 
In2 
Vout 
4 
13 
6 
8 
7 
Sense 
amplifier 
Vdd 
GND 
EN 
Q 
Qbar 
Vout 
4 
13 
11 
12 
10 
9 
Sub-die # 
3,4 
Mirror-
amplifier#1 
Vdd 
GND 
EN1 
EN2 
Clock 
Bbias 
Vsensor 
Vout 
4 
13 
16 
3 
1 
2 
15 
14 
Mirror-
amplifier#2 
Vdd 
GND 
EN1 
EN2 
Clock 
Bbias 
Vsensor 
Vout 
4 
13 
10 
7 
11 
6 
9 
8 
Inverter Vdd 
GND 
In 
Vout 
4 
13 
12 
5 
 
Figure 5 represents the chip layout of a single 
mirror-amplifier with an extra NAND gate and a 
Sense Amplifier. This chip is placed in the top sub-
dies (die # 1 and 2). NAND gate is designed with 
larger width for higher current driving purposes. It 
can also be used as inverter by tying two inputs. So 
it can work as inverted output buffer. Also it can be 
connected to the output pin of the mirror-amplifier 
to have halt-run feature. The logical operation of 
this halt-run operation is given in the table 2. The 
output of the amplifier can be halted by logic ‘0’ 
and be running by ‘1’. Both NAND and the Sense 
Amplifier can be used for electrical characterization 
purposes after fabrication. 
Page 732
  
Table 2: Halt-run operation of the sub-die # 1 and 2 
 
Halt Bit 
to 
NAND 
Input1 
Mirror-
Amp Out 
Bit to 
NAND 
Input2 
NAND Output Status 
0 
0 
1 
0 
1 (no-change) 
1 (no-change) 
Halt 
Halt 
1 
1 
0 
1 
1 (inverted) 
0 (inverted) 
Run  
Run 
 
 
 
Fig 5: Sub-die chip layout of a single mirror-
amplifier with a NAND gate and a Sense amplifier 
 
Figure 6 shows the chip layout of dual mirror-
amplifier with an extra inverter. This chip is to be 
placed in sub-die # 3 and 4. The inverter is also 
designed with larger width for higher current 
driving purposes. It can be used when the output of 
the mirror-amplifier needs to be inverted. 
 
 
 
Fig 6: Sub-die chip layout of dual mirror-amplifier 
with an additional inverter 
6. CHIP PACKAGING 
 
The package serves a variety of important needs. Its 
pins provide manageable solder connections. It 
gives the chip mechanical support. It conducts heat 
away from the chip to the environment [15]. The 
package structure corresponding to the designed 
chip layout can be served by MOSIS. For this 
design purpose a plastic compound-molding 
package is chosen from MOSIS in which the pads 
are connected to the package leads by gold bonding 
wire. It is an open cavity (where die sits in and then 
bonded) package with lid. Top of packaged chip 
called the lid and it is loose to be opened. This 
gives advantages to go in the package and complete 
special electrical tests like: die probing (electrically 
connected needles touching components on 
silicon), component thermal tests, microscopic 
visual tests like damage by short circuit, moisture 
effect tests etc. The table 3 below shows the other 
identifications of the chosen package, and the 
figure 7 and 8 show the designed multi-die chip 
after cut along the scribe lines. Those separated 4 
sub-dies are placed in the package individually. 
 
Table 3: Identifications of the chosen package 
 
Package part number OCP_QFN_5X5_16A 
Package manufacturer SEMPAC 
Package size 5mmx5mm 
Die placement cavity 3.1mmx3.1mm 
Pins 16 
 
 
 
 
Fig 7: Bonding diagram of the single mirror-
amplifier sub-die in SEMPAC package 
 
 
Page 733
  
 
 
Fig 8: Bonding diagram of the dual mirror-
amplifier sub-die in SEMPAC package 
 
7. CONCLUSION 
 
The VLSI technology is going to enter in the nano-
tech era. With the practice of designing nano-power 
chip many problems are raised and power 
managing challenge is got tougher. In this study an 
ultra-low-power mirror-amplifier is designed in 
CMOS 0.6µm process for precision sensing 
application, which dissipates power of 8.41 
milliwatts in the 1st experiment and latter 9.13 
nanowatts in the 2nd experiment by choosing the 
correct biasing setups. For economic consideration 
multi-die placement is done with a suitable package 
by SEMPAC. Four sub-dies are designed in two 
groups for characterization purposes. One design 
has a NAND buffer that can provide an additional 
operation for halt and run functions. Further study 
may be focused on more enhanced mirror-amplifier 
design with more efficiency and power reduction. 
 
REFERENCES 
 
1. Rich D. A. and Nestor, J. A., (2003) Analog 
and Mixed-Signal IC Design in a Junior 
Electronics Course Sequence, PA 18042, 
Proceedings of the 2003 American Society for 
Engineering, Education Annual Conference 
and Exposition. 
2. David A. Rich et. al., (2002), “BiCMOS 
Technology for Mixed-Digital, Analog, and RF 
Applications, IEEE Microwave Magazine, Vol. 
3, No. 2, June, pp. 44 – 55. 
3. CHIN H. G., (2003), High Performance 
Current Amplifier, Thesis submitted in 
fulfillment of the requirements for the degree 
of Master of Science, August, 2006. 
4. Ian Gresham, Alan Jenkins, Robert Egri, 
Channabasappa Eswarappa, Frank Kolak, 
Ratana Wohlert, Jacqueline Bennett. J-P 
Lanteri, (2003), Ultra Wide Band 24GHz 
Automotive Radar Front-End, IEEE in MTT-S 
Int. Microwave Symp. Dig., pp. 369-372. 
5. Hiroyo Ogawa, (2006), 24-GHz Ultra-
Wideband Short-Range Impulse Radar for 
Vehicular Applications, IEEE in CCNC, pp. 
696-700. 
6. D. M. Pietruszynski, J. M. Steininger, and E. J. 
Swanson, "A 50-Mbit/s CMOS monolithic 
optical receiver," IEEE J. Solid-State Circuits.  
7. T. H. Hu and P. R. Gray, (1993) A monolithic 
480 Mb/s parallel AGC/Decision/Clock-
recovery circuit in 1.2 µm CMOS, IEEE J. 
Solid-State Circuits, December, pp. 98-99. 
8. M. Ingels, G. V. der Plas, J. Crols, and M. 
Steyaert, (1994), A CMOS 18 THz 240 Mb/s 
transimpedance amplifier and 155 Mb/s LED-
driver for low-cost optical fiber links, IEEE J. 
Solid-State Circuits, vol. SC-29, December, pp. 
1552-1559. 
9. Ken Kundert, Henry Chang, Dan Jefferies, 
Gilles Lamant, Enrico Malavasi, Fred Sendig, 
(2000) Design of Mixed-Signal Systems on 
Chip, IEEE TRANSACTIONS ON CAD, VOL. 
19, NO. 12, December, pp. 1561-1572. 
10. Precision Amplifiers and Sensor Interfacing-
The Need for Precision, National 
Semiconductor-The Sight and Sound of 
Information, pp. 1-45. 
11. JULIANA GJANCI, (2008), On-Chip Voltage 
Regulation for Power Management in System-
on Chip, THESIS, Submitted as partial 
fulfillment of the requirements For the degree 
of Master of Science in Electrical and 
Computer Engineering In the Graduate College 
of the University of Illinois at Chicago. 
12. The MOSIS Services, (2004), MOSIS Scalable 
CMOS (SCMOS) Design Rules, Mosis.org, 
October Revision 8.0. 
13. Wane Wolf, Modern VLSI Design, System-on-
chip Design, 3rd edition, pp. 7, 360-391. 
14. Binzaid, S. and Attia, J. O., (1996), Design of a 
Switched Capacitor SRAM IC, Radiation 
Studies Conference, NASA Center for Applied 
Radiation Research, pp. 55-61 
15. Barr, K., (2007), ASIC Design in the Silicon 
Sandbox: a Complete Guide to Building 
Mixed-Signal Integrated Circuits, ISBN 0-07-
148161-3, pp. 14-34. 
Page 734
 A MODEL ON INDUSTRIAL INFORMATION SYSTEM (IIS) 
 
MD.SIFULLAH KHAN, MD. MEHEDI HASAN 
UNDERGRADUATE STUDENT 
DEPT. OF IPE, SUST, SYLHET. 
saifsust@yahoo.com, mehedi_ipe@yahoo.com 
 
C. A.  ANAM RASHED, MST. NASIMA BAGUM 
ASSISTANT PROFESSOR  
DEPARTMENT OF IPE, SUST, SYLHET 
rashed_sust@yahoo.com, nasimasust@yahoo.com   
 
                                                 ABSTRACT 
In the globalization era , rapid data communication and sufficient information is important to make the right 
decision at the right time . Especially in the apparel  industry , customer orders fluctuate a lot due to rapid 
change of the taste of the customer. This has a significant impact on master production scheduling and 
consequently on time performance (i. e. on-time delivery). On-time delivery also depends on proper information 
sharing among various departments of the garments industry. Furthermore, an inaccurate production plan also 
affects actual production. At present, various organizations/ industries in Bangladesh  are using traditional 
methods for controlling information flow  such as maintaining documentary books, which are time consuming. 
Recently, few organizations have installed computerized system instead of traditional systems.  In this research 
work a software tool has been developed for smooth flow of information from one department to another. This 
software tool captures the information of total production, production date, production rate etc. The software 
tools are built using PHP with My-SQL database. By changing some attributes, majority of apparels  industry 
could apply this software to maintain its resources. 
Key words: - Information sharing, online data flow and store, online data retrieval
INTRODUCTION: -    
                     In most organizations, information 
flows at the heart of workplace activities. The 
effective management of information requires 
information technology, and that technology is 
therefore crucial to organizational success. 
Information technology comes in many forms—
networked personal computers, software 
applications, the Internet, and more—but one thing 
all types of information technology have in 
common is that their effective use depends upon 
human users. People put the technology to work in 
managing information, and people are ultimately 
responsible for whether information technology 
succeeds or fails [1]. Over  the  last 15-20 years the 
apparel sector  has been in  a state of continuous  
restructuring.   A combination of technological and 
socio-economic changes, production cost, 
liberalization , and the emergence  of important   
international competitor  from Asia and the 
Mediterranean region are influencing the  apparel  
manufacturing  sector  of Bangladesh.  Apparel   
Corresponding author  
MD.SIFULLAH KHAN, C. A.  ANAM RASHED 
saifsust@yahoo.com, rashed_sust@yahoo.com 
 
companies  are facing increasing  competition  and 
cost pressures.  Hence efficient information flows  
within inter department  seem to be an important  
key factor for apparel industries in Bangladesh  to  
improving  better coordination  among them.  In 
this paper, we report on our development of a 
conceptual model, based on the IIS Model, which 
considers the specific requirements  for smooth 
flow of information within various department of 
an apparel industry. We explain. how we developed 
our Industrial Information System (IIS) model and 
discuss the characteristics of its success 
dimensions.  
RESEARCH BACKGROUND 
The web based information system has several 
advantage and overcome some traditional 
problems. These includes : (1)single data entry to 
minimize human error ; (2) real-time online 
ordering function; (3) multi-level password 
controls (so that different` functions have different 
access levels controlled by their respective 
authorized people).Some software companies now-
Page 735ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
  
a-days are making software on the basis of 
production information system [2], Human 
resource  information system etc. They make 
software according to companies demand. 
Although that software is very much strong in 
structure, this software are not cheapest and easier 
to maintain. So most of the apparel industry are not 
capable to use these software. Basically the 
research of making this tool is come from current 
production flow processes .PHP language  and  
MYSQL database (XAMPP) is used to develop this 
software. 
 
OBJECTIVE 
 To find out a feasible information flow 
model for an apparel industry of 
Bangladesh. 
 
 To develop a model on Industrial 
Information System (IIS). 
 
 
 
2.1. INFORMATION - A RESOURCE 
Information is ‘live’ as it is required to be updated 
all the time and is renewable. It is substitutable and 
transportable and can be made to travel. The all 
round exponential growth of information makes it 
necessary that information is collected, stored, and 
retrieved in various fields so that it could be 
usefully exploited as and when needed. Information 
is an important driver that companies have used to 
become both more efficient and more responsive. 
The tremendous growth of the importance of 
information technology is a testimony to the impact 
that information can have on improving a 
company. Like all the other drivers , however, even 
with information , companies reach a point when 
they must make the trade-off between efficiency 
and responsiveness . 
Information is considered as the sixth resource, the 
other five being men, machines, materials, money 
and methods. Figure 2.1 illustrates the flow of 
information in a production organization along 
with other resources [3]. 
 
 
 
 
 
 
 
                               Fig 1. Information as a Resource 
2.2  INFORMATION  
Generally information  define as : 
 knowledge communicated or received 
concerning a particular fact or 
circumstance; news: information 
concerning a crime.  
 knowledge gained through study, 
communication, research, instruction, etc. 
 the act or fact of informing[4]. 
According to World English Dictionary  
information  define as[5]: 
 knowledge acquired through experience or 
study. 
 knowledge of specific and timely events 
or situations; news 
 
2.2.1 INFORMATION FLOW 
 Information flow is the graphical representation of 
data collection, data processing, and report 
distribution throughout an organization. [6]  In the 
developing country like Bangladesh, the 
information flow between various department 
within an organization is paper based is shown in 
fig.2.  
Money  People  Material  Facilities  
Information  
Method  
ProcessinInput  Output  
Raw material  
  Feedback control  
Finished goods  
Page 736
  
2.2.2 INFORMATION SYSTEMS 
Beynon-Davies  defines an information system as 
an example of a system concerned with the 
manipulation of signs. An information system is a 
type of socio-technical system. An information 
system is a mediating construct between actions 
and technology . [7] 
An information system can also be considered a 
semi-formal language which supports human 
decision making and action. Information systems 
are the primary focus of study for the information 
systems discipline and for organizational 
informatics [8]. 
The types of information systems are, data 
warehouses, enterprise resource planning, 
enterprise systems, expert systems, global 
information system.[9] 
 
 
2.2.3  INFORMATION TECHNOLOGY 
 
 Information Technology, or IT, is 
basically just studying and developing 
computer systems. IT employees at a 
company are usually in charge of 
troubleshooting computer problems as 
well. 
 Information Technology refers to an entire 
industry. IT is based on using computers 
and software to manage information. It 
performs complex functions required to 
supply information to various 
departments. [10] 
 
2.2.4   IMPORTANCE OF 
INFORMATION TECHNOLOGY  
 Information technology is used for storing, 
protecting, processing, securing, 
transmitting, receiving and retrieving 
information. In business establishments, 
information technology is used for solving 
mathematical and logical problems. 
Information technology helps in project 
management system. Firstly, planning is 
done, then the data is collected, sorted and 
processed and finally, results are 
generated. It helps managers and workers 
to investigations about a particular 
problem, conceive its complexity and 
generate new products and services, 
thereby improving their productivity and 
output[11]. 
 Information technology is important 
because it is used in everyday life to make 
things simpler to do. Information 
technology professionals make difficult 
tasks easier to do and manage.  [12] 
 
 
2.3   INFORMATION FLOW IN APPAREL INDUSTRY 
 
 
 
 
 
 
 
 
 
    Fig 2: information and material flow chart for apparel manufacturing
Page 737
  
At present many software solution are available in 
market for proper flow of information. Some of 
them are 
 
Cantel Systems - Cantel Apparel Management 
System (CAMS) (For Medium-Sized Businesses)  
Complete apparel web solution. Helps you manage 
the entire supply chain from vendors to sales-reps.  
 
PKIM - Adaptive Garment Manufacturing 
Software (For Medium to Enterprise Businesses)  
Designed to provide centralized control to the 
production flow from sales order entry to shipping 
process in garment manufacturing systems.  
 
Dant Software Solutions - Dant Fashion Software 
(For Small to Medium Businesses)  
Software that has been specifically designed to 
utilise the style, colour, and size requirements that 
the apparel industry requires. 
 
Fast React Systems - Fastreact Enterprise (For 
Medium to Enterprise Businesses)  
Specialized professional planning and management 
tool that provides the apparel,  
 
footwear and textile industries with much improved 
visibility, coordination and communication. 
 
Niche Fashion Technology - Niche Garments (For 
Small to Medium Businesses)  
Apparel management software specifically 
designed to meet the needs of the small to medium 
sized clothing manufacturer and wholesaler.  
 
But those software are very costly. So Small and 
medium apparel can’t use those software. We have 
developed  a web based software which can be 
used at low cost. 
 
 
2.4  STEPS OF RESEARCH  
METHODOLOGY  
 Necessary steps of research methodology are 
described in bellow  
2.4.1 Identify scope of the research 
 
  Scope of work and study   related  to theories of 
production  was  identified. 
 
2.4.2 Gather necessary data and user 
requirement 
    Study was performed to identify the problem of 
apparel industry. 
 
 
  Data was gathered by interviewing and 
documentation to find causes of problems. 
   Survey was perfomed  to design the new system 
for solving the problems. 
 Data analysis was done   to design new system. 
 
2.4.3 Design new system 
 In addition, we design functions, input, output, 
user interface and database that using the data from 
collected data. 
2.4.4   Develop the software/program 
 The software was  developed by using XAMPP for 
Windows Version 1.4.16, which  includes MySQL 
version 4.1.14 to create database and PHP version 
5.0.5 as a program tool  .  
  
2.4.5 Testing and debugging each module  
     The software  was tested  as a prototype in a 
specific apparel  industry. 
 
2.5   Organization of software 
 
       In the apparel Industry, the administrative 
internal organizations have been cooperated 
between departments as following: - Human 
Resource Department ,Marketing Department , 
Financial Department , Purchasing Department 
,Store Department, Research and Development 
Department, Production Department consists of 
Cutting, Printing, Embroidery, Sewing, Washing, 
Finishing, Shipping etc. 
 
  In the current production process and information 
flow, related document and interview related 
departments are as following 
 
       
1. Cutting Department 
           Cutting department is responsible for cutting 
process.. They starts from receiving order from 
customer. They needs to keep data about order 
quantity, cutting percentage, balanced quantity, 
cutting quantity, completed quantity, sending 
quantity, sending time and provide these data to 
administrative department. 
2. Printing Department 
        Printing department is responsible for printing 
process. They starts from receiving data and raw 
material from Cutting Department .They needs to 
keep data about  sending quantity, sending date, 
Page 738
  
factory name, received quantity, received date, 
balanced quantity and provide these data to 
administrative department. 
 
3. Embroidery Department 
      Embroidery department is responsible for 
Embroidery process. They starts from receiving 
data and raw material from Printing Department . 
They needs to keep data about  sending quantity, 
sending date, factory name, received quantity, 
received date, balanced quantity and provide these 
data to administrative department. 
4. Sewing Department 
            Sewing department is responsible for 
sewing process. They starts from receiving data 
and raw material from Embroidery Department . 
They needs to keep data about  input quantity, 
output quantity, balanced quantity, and provide 
these data to administrative department. 
5. Washing Department 
            Washing department is responsible for 
washing process. They starts from receiving data 
and raw material from Sewing Department .They 
needs to keep data  about sending quantity, sending 
date, factory name, received quantity, received 
date, balanced quantity and provide these data to 
administrative department. 
6. Finishing Department 
                   Finishing department is responsible for 
finishing process. They starts from receiving data 
and raw material from Washing Department .They 
needs to keep data  about packaged quantity, poly 
quantity, balanced poly, complete quantity, data 
update time and provide these data to 
administrative department. 
7. Shipping Department 
               Shipping department is responsible for 
shipping process. They starts from receiving data 
and raw material from Finishing Department .They 
needs to keep data  ship quantity, shipping date, cut 
short quantity, order short quantity and provide 
these data to administrative department. 
2.6 Application Software (IIS) Overview  
An important task for the purpose of  information 
flow and  storage  is to create database.  A database 
plays an important  role  for  information storage . 
To implement  industrial information system we 
develop application software  and a database 
system. During software development one thing is 
very important to us that software should be 
flexible in use and to be simple to suit existing 
communication system. In  figure we shows layout 
of software .  Due to the page limitation details 
software could not be described. Software is 
developed with the help of PHP and it is linked 
with MYSQL (XAMPP, a combination of) PHP 
and MYSQL) for the purpose of data storage .The 
new system will help to share information among 
various department such as Cutting, Printing, 
Embroidery, Sewing, Washing, Finishing, Shipping 
.  The program will show necessary information in 
planning process for each department functions. 
The developed new system is composed by two 
sections; that are design database and functions of 
programs or user interfaces design.  The button  
given below the company name shows  information  
related to the particular department .After clicking 
any particular type of department the top 
management can see all information available in 
the database(fig 4). The top management retrieves 
the required data from the database.The top 
management can print all information or any 
particular information with respect to that database. 
The particular department can add, remove or 
update this database with particular information 
(fig 5). The new system has multi-level password 
controls so that different` functions have different 
access levels controlled by their respective 
authorized people (fig 1). 
 
 
Snapshot of  industrial information system (IIS) is 
given below : 
 
 
         Fig 3:-Application software overview (01) 
Page 739
  
 
         Fig 4:-Application software overview (02) 
 
Fig 5 :- Application software overview (03) 
 
2.6 Research Equipments and Tools  
  
2.6.1 Hardware     CPU   : Intel Pentium 
Processor IV    RAM   : 128 MB    Hard disk  : 20 
GB    Peripherals  : Monitor, Keyboard, Mouse, 
Diskette and         CD ROM Drive 
  
Operating system : Microsoft Windows  
Design tool  : Dream Weaver Mx 8.0 
Development tool : XAMPP for Windows Version 
1.4.16,  
Conclusion 
A windows-based application software tool related 
to the Industrial Information System has been 
developed. Using this tool management of an 
industry can recognize the different activities and 
information of it various production department . 
Considering all the observations it is significant 
that this tool can play a vital role in any industry.  
This study left several issues to be addressed. the 
study captures a primarily cross-sectional view of 
model constructs. Perceptions will change over 
time as new department introduced in organization. 
 
The areas of future research of this paper are given 
below:  
1. Human resource Management Engaged with 
this database can easily communicate with 
headquarter. 
 
REFERENCE  
1. www.infotoday.com(10/02/2010) 
2. Lee J Krajewiski, Larry P. Ritzman. 
3. https://ecpa.cpa.state.tx.us/empinfo/Employee
Menu.jsp 
4. http://dictionary.reference.com/browse/inform
ation 
5. http://dictionary.reference.com/browse/inform
ation 
6. http://www.answers.com/topic/information-
flow 
7. Beynon-Davies P. (2009). The ‘language’ of 
informatics: the nature of information systems. 
International Journal of Information 
Management. 29(2). 92-103 
8. Beynon-Davies P. (2009). Business 
Information Systems. Palgrave, Basingstoke 
9. http://www.askkids.com/web?q=What+Is+the
+Importance+of+Information+System%3F&qs
rc=2987&o=102341&l=dir 
10. http://answers.ask.com/Computers/Science/wh
at_is_information_technology 
11. http://www.buzzle.com/articles/why-is-
information-technology-important.html 
12. http://answers.ask.com/Business/Management
_and_HR/why_is_information_technology_ 
 
 
 
Page 740
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
Page 741
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Mohammed Mahfuz Hossain; E-mail: rivon33@yahoo.com; Mob: 01811481270  
Md. Shahrul Islam; E-mail: shahrul_ipe@yahoo.com; Mob: 01911613115  
APPLICATION OF FIXED TIME PERIOD MODEL FOR 
OPTIMIZING INVENTORY LEVEL: A CASE STUDY IN A 
PHARMACEUTICAL COMPANY 
 
 
Mohammed Mahfuz Hossain and Md. Shahrul Islam 
Dr. Md. Ariful Islam and Engr. A.B.M Abdul Malek 
Department of IPE 
Shah jalal University of science and technology, sylhet-3114, Bangladesh. 
E-mail: ms.islam2@abedinequipment.com 
 
 
This paper focuses on a case study to determine the optimum levels of inventory of a pharmaceutical 
product.   A fixed time period model was developed with different service levels. It is found from the study 
that a significant amount of inventory investment can saved while providing 99% service level. So the 
capital involved in unnecessary inventory can be used other quality issues and the competitive advantage can 
help the company to increase its market share day by day. 
 
Key words: Inventory; Optimum level; Service level; Fixed Time Period Model; Capital Investment; Stock.  
 
INTRODUCTION  
 
The control and maintenance of inventory is a 
problem common to all organizations in any sector 
of the economy. The problems of inventory do not 
confine themselves to profit making institutions but 
likewise are encountered by social and nonprofit 
institutions. Inventories are common to farms, 
manufacturers, wholesalers, retailers, hospitals, 
churches, prisons, zoos, universities, and national, 
state, and local governments. Indeed, inventories 
are also relevant to the family unit in relation to 
food, clothing, medicines, toiletries, and so forth. 
 
1.2 Significance of the study 
Inventory is very important because it helps the 
company respond quickly to customer demand, 
which is an important element of competitive 
strategy. It also represents one of the largest 
controllable resources in many companies.  
Therefore, inventories of finished goods (that is, 
independent-demand inventories) of the correct 
items, within a reasonable distance of points of 
demand, play an important role in a company’s 
ability to compete in a market for standardized 
products. So we are going to conduct a thesis on 
inventory control of finished goods in a particular 
pharmaceutical industry with some objectives.  
OBJECTIVES  
 
This dissertation focuses on two main objectives:  
 To identify inventory management system 
of selected Pharmaceutical company. 
 To identify optimum level of inventory by 
using fixed time period model. 
 
LITERATURE REVIEW 
 
Inventory is a detailed list of those movable items 
which are necessary to manufacture a product and 
to maintain the equipment and machinery in good 
working order. The quantity and the value of every 
item is also mentioned in the list. [3] 
Inventory is the stock of any item or resource used 
in an organization. 
Inventory is actually money kept in the store room. 
2.1 Inventory system   
An inventory system is the set of policies and 
controls that monitors level of inventory and 
determines what levels should be maintained, when 
stock should be replenished, and how large order 
should be. 
2.2 The purpose of inventory: In a just-
in-time manufacturing environment, 
inventory is considered waste. However, in 
environments where an organization 
suffers from poor cash flow or lacks strong 
control over (i) electronic information 
transfer among all departments and all 
significant suppliers, (ii) lead times, and (iii) 
Page 742
ISBN: 978-984-33-2140-4
 quality of materials received, inventory plays 
important roles. 
2.3 Functions of inventories  
1. Separate different operations from one another 
and make them independent, so that each 
operation (starting from raw material to 
finished product) can be performed 
economically. 
2. Maintain smooth and efficient production flow. 
3. Purchase in desired quantities and thus nullify 
the effects of changes in prices or supply. 
4. Keeps a process continuously operating. 
5. Create motivational effect. A person tempted to 
purchase more if inventories are displayed in 
bulk.[3] 
The inventory may be classified into followings: [3] 
 Raw inventory 
 In-process inventory 
 Finished inventory 
 Indirect inventory 
RESEARCH METHOD 
 
This paper focuses a case study to identify the 
inventory control system and determine the 
optimum levels of inventory of a product in Incepta 
Pharmaceuticals Ltd. by using different service 
level in fixed time period model.  Data are collected 
from different sources at different time by making 
questioner and interview. 
3.3.2 DEVELOPING A CASE STUDY   
Many well-known case study researchers such as 
Robert E. Stake, Helen Simons, and Robert K. Yin 
have written about case study research and 
suggested techniques for organizing and conducting 
the research successfully. This introduction to case 
study research draws upon their work and proposes 
six steps that should be used:  
 Determine and define the research questions   
 Select the cases and determine data gathering 
and analysis techniques   
 Prepare to collect the data   
 Collect data in the field   
 Evaluate and analyze the data   
 Prepare the report 
FINDING FROM THE CASE STUDY 
 
This chapter presents the findings from the case 
study conducted. The case study has been 
conducted in Incepta pharmaceuticals limited. 
The objective of this case study has been to search 
for different aspects of inventory control, more 
specifically their current policy for inventory 
control of particular finished good. 
4.2.1 Incepta pharmaceuticals inventory system 
Usually the company focuses on the raw material 
inventory system among the four types stated above 
(discussed in article 2.4). The reasons behind that 
are raw materials lead time is long and raw 
materials are very expensive. For managing of raw 
material inventory they first collect forecasted 
demand from marketing department. Then they 
follow different methods of inventory control for 
dependent demand system such as MRP І(Material 
Requirement Planning), MRP II(Manufacturing 
Resource Planning), BOM(Bill Of Materials), 
MOQ(Minimum Order Quantity), EOQ(Economic 
Order Quantity) etc. They use well organized excel 
sheet for managing inventory of raw material and 
they review daily the updated information of 
inventory by using internet and by intranet( head 
office and factory ). They keep inventory for 
following materials:   
Fig 4.2.1(a): Materials requirement for final product. 
4.2.2 DEMAND FOR PANTONIX 20 TABLET  
Forecasted and actual monthly demand data for 
PANTONIX 20 TABLET for the year of 2007, 
2008 and 2009(up to July) are shown in figure 
below:  
 
                                       Fig 4.2.2 (a): Forecasted and actual demand in the year 2007 
 
 
 
Product
Raw material
Active Excipients 
Packaging material
Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
Forecasted demand 65 90 90 100 105 115 120 130 130 130 110 105
Actual demand 90 85 95 100 110 115 125 120 120 120 110 105
0
50
100
150
D
em
an
d 
in
 th
ou
sa
nd
 
bo
xe
s
Page 743
  
 
Fig 4.2.2 (b): Forecasted and actual demand in the year 2008 
 
                                        Fig 4.2.2 (c): Forecasted and actual demand in the year 2009 
 
4.3 KEY FINDINGS 
Following key findings are found from case study 
 Company’s current practices for inventory control.  
 Forecasted and actual demand data for Pantonix 20 Tablet.  
 Time required in different phases of production of Pantonix 20 Tablet 
 
ANALYSIS 
 
Analysis on the findings of the case study conducted in the selected company has been presented in this 
chapter. A proposal has been made for developing strategy to find optimum inventory level of Pantonix 20 
Tablet by using the scientific inventory model (Fixed time period model).  
5.3 Assumptions: 
 Demand for the product is constant and uniform throughout the month. 
 The lead time (i.e. time from order to receipt) is constant for finished goods. 
 Cost per unit of product is constant. 
 Raw materials for the product are available for instant supply. 
 All production related resources (e.g. equipment, machineries, labor etc.) are available for meeting 
the demand. 
 Transportation facilities are available without any disturbance. 
Pantonix 20 Tablet is very fast moving product (i.e. high sales volume) and this is one of the major products 
of the company. For this reason, the company does not want to take any risk of stock out for this 
product. So order quantity calculated with service level 100%.  
 
 
 
5.4 Calculations with service level 100%: 
 
Taking into account 12 months (2007) of data  
T= The number of days between reviews = 0.5 month = 15 days 
L= Lead time in days (time between placing an order and receiving it) = 0.33 month = 10 days.  
P = Service level desired expressed as a fraction = 100% = 1.00 
  = Forecasted average monthly demand = 107.50 thousand boxes. 
z   = Number of standard deviations for a specified service level = 4.5 
E(z) = Expected number units short from a normalized table where σ = 1 
 = Standard deviation of demand over the review and lead time =  
  = Standard deviation of the monthly demand. 
Jan Feb Mar Apr May Jun Jul Aug Sep Oct Nov Dec
Forecasted demand 125 120 125 125 150 150 150 170 170 170 150 155
Actual demand 110 110 120 130 130 140 150 160 140 160 150 155
0
100
200
D
em
an
d 
in
 th
ou
sa
nd
 b
ox
es
Jan Feb Mar Apr May Jun Jul
Forecasted demand 150 150 160 170 180 200 200
Actual demand 151 147 161 175 181 183 176
0
200
400
D
em
an
d 
in
 th
ou
sa
nd
 
bo
xe
s
Page 744
  
ߪௗ௠ = ට∑ (ௗ௜ିௗത )మ೙భ ௡   
ߪௗ௠ = ඩ (65− 107.5)ଶ + (90− 107.5)ଶ+ (90− 107.5)ଶ+ (100− 107.5)ଶ+ (105− 107.5)ଶ + (115− 107.5)ଶ(120− 107.5)ଶ+ (130− 107.5)ଶ+ (130− 107.5)ଶ+ (130− 107.5)ଶ+ (110− 107.5)ଶ+ (105− 107.5)ଶ12  
 σdm =  √352.08 = 18.76388 thousand boxes. 
ߪ(்ା௅) = ඥ(ܶ + ߪ(ܮௗ௠ଶ  = 17.09471 thousand boxes. 
ݖ)ܧ) = ௗത ୘(ଵି୮) 
ఙ(೅శಽ)    
ݖ)ܧ) = ଵ଴଻.ହ∗଴.ହ∗(ଵିଵ)
ଵ଻.଴ଽସ଻ଵ     = 0.00 
From table 1 given in appendix B:  z = 4.5 
Order quantity (in thousand boxes):    
q = ݀̅ (T+L) + z ߪ(்ା௅)– I   
q = 107.50* (0.5+0.33) + 4.5 * 17.09471 – I 
q = 166.1512 - I 
With this level, proposed inventory throughout the year is shown graphically.  
 
 Fig 5.4(a): Proposed inventory and replenishment of order for the year 2007. 
Review period and order placed at 1st and 15th of every month. 
Replenishment of order received at 10th and 25th of every month. 
Service level is 100%. 
 
The company maintained inventory for 3 months shown in Fig 5.4(b). Here at 1 January 2007 the inventory 
were 245 thousand boxes. After 15 days it is reviewed and order is placed for the quantity of subtracted 
present inventory from next three months demand. Therefore, at 15 January 2007 the inventory was 200 
thousand boxes. So order is placed for (263-200=) 63 thousand boxes. This is received after 10 days (lead 
time). At 25 January 2007, the inventory level decreased but for replenishment, the inventory becomes from 
170 thousand boxes to 233 thousand boxes. Thus the company maintain inventory in this way throughout the 
year. Detailed calculation is attached in appendix C Table 3. 
Similarly existing practice of company inventory and replenishment of order for the year 2008, 2009(up to 
July) and proposed inventory and replenishment of order for years are calculated next.  
 
 Fig 5.4(c): Existing practice of company inventory and replenishment of order for the year 2008. 
 
 
 
0
50
100
150
200
1/
1/
20
07
15
/1
/2
0…
30
/1
/2
0…
15
/2
/2
0…
30
/2
/2
0…
15
/3
/2
0…
30
/3
/2
0…
15
/4
/2
0…
30
/4
/2
0…
15
/5
/2
0…
30
/5
/2
0…
15
/6
/2
0…
30
/6
/2
0…
15
/7
/2
0…
30
/7
/2
0…
15
/8
/2
0…
30
/8
/2
0…
15
/9
/2
0…
30
/9
/2
0…
15
/1
0/
2…
30
/1
0/
2…
15
/1
1/
2…
30
/1
1/
2…
15
/1
2/
2…
30
/1
2/
2…In
ve
nt
or
y 
in
 
th
ou
sa
nd
 b
ox
es
DateReplenishment Inventory
0
200
400
600
1/
1/
20
…
25
/1
/2
…
15
/2
/2
…
10
/3
/2
…
30
/3
/2
…
25
/4
/2
…
15
/5
/2
…
10
/6
/2
…
30
/6
/2
…
25
/7
/2
…
15
/8
/2
…
10
/9
/2
…
30
/9
/2
…
25
/1
0/
…
15
/1
1/
…
10
/1
2/
…
30
/1
2/
…
In
ve
nt
or
y 
in
 
th
ou
sa
nd
 b
ox
es
Date
Replenishment
Inventory
Page 745
  
 Fig 5.4(d) : Proposed inventory and replenishment of order for year 2008. 
 
 Fig 5.4(e): Existing practice of company inventory and replenishment of order for the year 2009. 
 
This figure shows the company’s inventory level throughout the year 2009. 
Order quantity(For year 2009): q = ݀̅ (T+L) + z ߪ(்ା௅)– I   
                             = 172.86 * (0.5+0.33) + 4.5 * 13.77368 - I  
       = 143.4714 + 61.98156– I 
       = 205.453– I 
 
 
Fig 5.4(f): Proposed inventory and replenishment of order for the year 2009. 
Comparison between company’s inventory level and proposed inventory level is shown next. 
5.5 Compare (for service level 100%): 
From above calculations at every month’s end, 
inventory level is compared for company’s existing 
practice and proposed level of inventory. Average 
inventory level also compared between company’s 
existing practice and proposed level of inventory. 
0
100
200
1/
1/
2…
25
/1
/…
15
/2
/…
10
/3
/…
30
/3
/…
25
/4
/…
15
/5
/…
10
/6
/…
30
/6
/…
25
/7
/…
15
/8
/…
10
/9
/…
30
/9
/…
25
/1
…
15
/1
…
10
/1
…
30
/1
…
In
ve
nt
or
y 
in
 
th
ou
sa
nd
 b
ox
es
Date
Replenishment
Inventory
0
200
400
600
In
ve
nt
or
y 
in
 
th
ou
sa
nd
 b
ox
es
Date
Replenishment
Inventory
0
100
200
In
ve
nt
or
y 
in
 
th
ou
sa
nd
 b
ox
es
Date
Replenishment
Inventory
Page 746
  Fig 5.5(a): Comparison between company’s inventory level and proposed inventory level for year 2007. 
 
 
 Fig 5.5(b): Comparison between company’s and proposed monthly average inventory level (in thousand boxes) for year 2007. 
 
 
 
 
Fig 5.5(c): Comparison between company’s 
inventory level and proposed inventory level 
for year 2008. 
 
 
 
 
Fig 5.5(d): Comparison between company’s and proposed 
monthly average inventory level (in thousand boxes) for year 
2008. 
 
 
 
 
 Fig 5.5(e): Comparison between company’s inventory level and proposed inventory level for year 2009. 
 
 
 Fig 5.5(f): Comparison between company’s and proposed monthly average inventory level (in thousand boxes) for year 2009. 
 
5.6 Monthly capital cost involved at different 
years: 
For 100% service level monthly capital cost 
involved is calculated. 
1 box contain 50 tablets 
0
200
400
600
800
1000
1200
1400
1600
Ja
n
M
ar
M
ay Ju
l
Se
p
N
ov
In
ve
nt
or
y 
in
 th
ou
sa
nd
 b
ox
es
Month
Company
Proposed 
Company,
1165
Proposed,
489
0
200
400
600
800
1000
1200
1400
1600
1800
2000
Ja
n
M
ar
M
ay Ju
l
Se
p
N
ov
In
ve
nt
or
y 
in
 th
ou
sa
nd
 b
ox
es
Month
Company
Proposed
Compa
ny, 156
1
Propos
ed, 554
0
500
1000
1500
2000
2500
Ja
n
Fe
b
M
ar
A
pr
M
ay Ju
n
Ju
l
In
ve
nt
or
y 
in
 th
ou
sa
nd
 b
ox
es
Month
Company
Proposed 
Compa
ny, 109
9
Propos
ed, 313
Page 747
 Total cost/pcs  1.889145 tk. 
For year 2007: 
Companies average inventory: 1165.3472 * 1000 * 
50 = 58267361 pcs/month. 
So capital cost involved, C1    = 110075494 
tk/month. 
Proposed average inventory:   489.1187 * 1000 * 
50 = 24455935 pcs/month. 
So capital cost involved, C2 = 46200807 
tk/month. 
According to company's model extra capital 
involved = (C1-C2) = 63874687 tk/month. 
For year 2008: 
Companies average inventory:  1560.99 * 1000 * 
50 = 78049306 pcs/month. 
So capital cost involved, C1    = 147446455 
tk/month. 
Proposed average inventory:   553.813736 * 1000 * 
50 = 27690687 pcs/month. 
So capital cost involved, C2 = 52311723 
tk/month. 
According to company's model extra capital 
involved = (C1-C2) = 95134733 tk/month. 
For year 2009( up to July): 
Companies average inventory:  1098.7778 * 1000 * 
50 = 54938889 pcs/month. 
So capital cost involved, C1    = 103787527 
tk/month. 
Proposed average inventory:   312.75534 * 1000 * 
50 = 15637767 pcs/month. 
So capital cost involved, C2 = 29542010 
tk/month. 
According to company's model extra capital 
involved = (C1-C2) = 74245517 tk/month. 
 
Fig 5.6: Compare between capital costs 
involved in million tk/month. 
 
Inventory means, “money kept in store room”. This 
Fig. shows that in proposed model, capital cost 
involved is less and it is clearly visible that if 
company’s inventory model is used then large 
amount of capital kept in store room.   
5.7 Benefits from reduced inventory level:  
For inventory huge capital cost is involved. This 
amount of money can be used elsewhere to get 
benefit. Let the money is deposited in Bank with 
7% interest. Using simple interest we calculate the 
benefit.  
Interest, I = principal amount (P) * interest period 
(n) * interest rate (i). 
For year 2007:  P = 63874687 *12 = 766496244 tk; 
i = 7% = 0.07;  n = 1; 
Interest, I =  
Similarly for year 2008: F = 1285438314 tk; 
Benefit = 143821517 tk = 14.38 crore tk; 
For year 2009(upto July): F = 545741371 tk; 
Benefit = 26022752 tk = 2.60 crore tk ;  
5.8 Causes for maintaining huge inventory:   
Pantonix 20 Tablet is very fast moving product (i.e. 
high sales volume) and this is one of the major 
products of Incepta pharmaceutical company. For 
this reason, the company does not want to take 
any risk of stock out for this product. They keep 
one month safety stock in central warehouse.  
Other reasons are:  
 To meet fluctuating demand at different 
depots(16 ). 
 To avoid unexpected problems in 
transportation. 
 To avoid raw materials unavailability. 
 To meet the demands during off 
production.  
If Incepta pharmaceutical company can take some 
risks then inventory can be reduce. So order 
quantity has been calculated with service level 
99.73% which is equivalent to ±3σ standard 
deviation.  
5.9 Calculations with service level 99.73%: 
Taking into account 12 months (2007) of data  
T= The number of days between reviews = 0.5 
month = 15 days 
L= Lead time in days (time between placing an 
order and receiving it) = 0.33 month = 10 days.  
P = Service level desired expressed as a fraction = 
99.73% = 0.9973 
  = Forecasted average monthly demand = 107.50 
thousand boxes. 
z   = Number of standard deviations for a specified 
service level = 1.983684 
E(z) = Expected number units short from a 
normalized table where σ = 1 
 = Standard deviation of demand over the 
review and lead time =  
  = Standard deviation of the monthly demand. 
2007 2008
2009
(Upt
o 
July)
Company 
capital cost 
involved
112.50 147.45 103.79
Proposed 
capital cost 
involved
46.20 52.31 29.54
0.00
20.00
40.00
60.00
80.00
100.00
120.00
140.00
160.00
A
m
ou
nt
 in
 m
ill
io
n 
tk
.
Page 748
  
ߪௗ௠ = ට∑ (ௗ௜ିௗത )మ೙భ ௡   
ߪௗ௠
= ඩ (65− 107.5)ଶ + (90− 107.5)ଶ + (90− 107.5)ଶ + (100 − 107.5)ଶ+ (105− 107.5)ଶ + (115− 107.5)ଶ(120− 107.5)ଶ + (130− 107.5)ଶ+ (130− 107.5)ଶ+ (130− 107.5)ଶ + (110− 107.5)ଶ+ (105− 107.5)ଶ12  
 σdm =  √352.08 = 18.76388 thousand boxes. 
ߪ(்ା௅) = ඥ(ܶ + ߪ(ܮௗ௠ଶ  = 17.09471 thousand 
boxes. 
ݖ)ܧ) = ௗത ୘(ଵି୮) 
ఙ(೅శಽ)    
ݖ)ܧ) = ଵ଴଻.ହ∗଴.ହ∗(ଵି଴.ଽଽ଻ଷ)
ଵ଻.଴ଽସ଻ଵ     = 0.008489 
From table 1 given in appendix B:  z = 1.983684 
Order quantity (in thousand boxes):   q = ݀̅ (T+L) + 
z ߪ(்ା௅)– I   
     q = 
107.50* (0.5+0.33) + 1.983684 * 17.09471 – I 
     q = 
123.1355 – I 
 
With this level, proposed inventory throughout the year is shown graphically.  
 
Fig 5.9(a) Proposed inventory and replenishment of order for the year 2007. 
Review period and order placed at 1 and 15 of every month. 
Replenishment of order received at 10 and 25 of every month. 
Service level is 99.73% (6 σ). 
Fig 5.4(a) shows that at 1st January 2007 the 
inventory was 123 thousand boxes. Now gradually 
inventory is consumed. After 10 days at 10th 
January 2007, the inventory was 93 thousand boxes 
as 30 thousand boxes consumed. Similarly after 5 
days at 15th January 2007 the 78 thousand boxes 
remain and an order placed for (123 - 78=) 45 
thousand boxes. After 10 days (which is the lead 
time) the order is received. At 25th January 2007, 
the inventory level decreased but for replenishment, 
it reached from 78 thousand boxes to 93 thousand 
boxes. In this way inventory is calculated 
throughout the year. Similarly we also calculate 
inventory level of Pantonix 20 Tablet for year 2008 
and 2009(up to July). 
Order quantity (For year 2008):  
q = ݀̅ (T+L) + z ߪ(்ା௅)– I  = 146.67 * (0.5+0.33) + 
1.863089 * 16.35373 - I  = 121.7333 + 30.46845 –I 
                            = 152.2018 – I 
 
 
Fig 5.9(b): Proposed inventory and replenishment of order for year 2008. 
Order quantity (For year 2009): q = ݀̅ (T+L) + z ߪ(்ା௅)– I   
                                = 181.67 * (0.5+0.33) + 1.726444 * 13.77368- I  
          = 143.4714 + 23.77949 – I= 167.2509 – I 
0
20
40
60
80
100
120
140
1/
1/
20
07
15
/1
/2
00
7
30
/1
/2
00
7
15
/2
/2
00
7
30
/2
/2
00
7
15
/3
/2
00
7
30
/3
/2
00
7
15
/4
/2
00
7
30
/4
/2
00
7
15
/5
/2
00
7
30
/5
/2
00
7
15
/6
/2
00
7
30
/6
/2
00
7
15
/7
/2
00
7
30
/7
/2
00
7
15
/8
/2
00
7
30
/8
/2
00
7
15
/9
/2
00
7
30
/9
/2
00
7
15
/1
0/
20
07
30
/1
0/
20
07
15
/1
1/
20
07
30
/1
1/
20
07
15
/1
2/
20
07
30
/1
2/
20
07
In
ve
nt
or
y 
in
 th
ou
sa
nd
 
bo
xe
s
Date
Replenishment
Inventory
0
20
40
60
80
100
120
140
1/
1/
20
08
15
/1
/2
00
8
30
/1
/2
00
8
15
/2
/2
00
8
30
/2
/2
00
8
15
/3
/2
00
8
30
/3
/2
00
8
15
/4
/2
00
8
30
/4
/2
00
8
15
/5
/2
00
8
30
/5
/2
00
8
15
/6
/2
00
8
30
/6
/2
00
8
15
/7
/2
00
8
30
/7
/2
00
8
15
/8
/2
00
8
30
/8
/2
00
8
15
/9
/2
00
8
30
/9
/2
00
8
15
/1
0/
20
08
30
/1
0/
20
08
15
/1
1/
20
08
30
/1
1/
20
08
15
/1
2/
20
08
30
/1
2/
20
08
In
ve
nt
or
y 
in
 th
ou
sa
nd
 
bo
xe
s
Date
Replenishment
Inventory
Page 749
  
  
Fig 5.9(c): Proposed inventory and replenishment of order for the year 2009. 
 
5.10 Compare (for service level 99.73%) 
Now we compare our proposed inventory level (for 
service level 99.73%) with company’s inventory 
level. 
 
 
Fig 5.10(a): Comparison between company’s inventory level 
and proposed inventory level for year 2007. 
 
 
 
Fig 5.10(b): Comparison between company’s 
and proposed monthly average inventory level 
(in thousand boxes) for year 2007. 
 
 
 
Fig 5.10(c): Comparison between company’s 
inventory level and proposed inventory level 
for year 2008. 
 
 
 
 
Fig 5.10(d): Comparison between company’s 
and proposed monthly average inventory level 
(in thousand boxes) for year 2008. 
 
 
 
0
50
100
150
In
ve
nt
or
y 
in
 
th
ou
sa
nd
 b
ox
es
Date
Replenishment
Inventory
0
200
400
600
800
1000
1200
1400
1600
Ja
n
Fe
b
M
ar
A
pr
M
ay Ju
n Ju
l
A
ug Se
p
O
ct
N
ov D
ec
In
ve
nt
or
y 
in
 th
ou
sa
nd
 b
ox
es
Month
Company
Proposed 
Company, 
1165
Proposed, 
317
0
200
400
600
800
1000
1200
1400
1600
1800
2000
Ja
n
Fe
b
M
ar
A
pr
M
ay Ju
n Ju
l
A
ug Se
p
O
ct
N
ov D
ec
In
ve
nt
or
y 
in
 t
ho
us
an
d 
bo
xe
s
Month
Company
Proposed 
Company, 
1561
Proposed, 
385
Page 750
  
Fig 5.10(e): Comparison between company’s 
inventory level and proposed inventory level 
for year 2009. 
 
 
 
Fig 5.10(f): Comparison between company’s 
and proposed monthly average inventory level 
(in thousand boxes) for year 2009. 
 
 
 
5.11 Monthly capital cost involved at different 
years 
For 99.73% service level monthly capital cost 
involved is calculated.  
1 box contain 50 tablets 
Total cost/pcs  1.889145 tk. 
For year 2007: 
Companies average inventory:  1191 * 1000 * 50 = 
59550000 pcs/month. 
So capital cost involved, C1    = 112498585 
tk/month. 
Proposed average inventory:   317* 1000 * 50 = 
15852797 pcs/month. 
So capital cost involved, C2 = 29948232 
tk/month. 
According to company's model extra capital 
involved = (C1-C2) = 80127262 tk/month. 
For year 2008: 
Companies average inventory:  1561* 1000 * 50 = 
78050000  pcs/month. 
So capital cost involved, C1    = 147447767  
tk/month. 
Proposed average inventory:   384 * 1000 * 50 = 
19245702 pcs/month. 
So capital cost involved, C2 = 36357921 
tk/month. 
According to company's model extra capital 
involved = (C1-C2) = 111174871 tk/month. 
For year 2009( up to July): 
Companies average inventory:  1099 * 1000 * 50 = 
97850000  pcs/month. 
So capital cost involved, C1    = 184852838  
tk/month. 
Proposed average inventory:   227 * 1000 * 50 = 
11340033 pcs/month. 
So capital cost involved, C2 = 21422967 
tk/month. 
According to company's model extra capital 
involved = (C1-C2) = 82364560 tk/month. 
 
Fig 5.11: Compare between capital costs 
involved in million tk/month. 
 
Inventory means “money kept in store room”. This 
Fig. shows that in proposed model, capital cost 
involved is less and it is clearly visible that if 
company’s inventory model is used then large 
amount of capital kept in store room.   
5.12 Benefits from reduced inventory level (with 
service level 99.73%)  
For inventory huge capital cost is involved. This 
amount of money can be used elsewhere to get 
benefit. Let the money is deposited in Bank with 
7% interest. Using single payment compound 
amount factor we calculate the benefit.  
Future sum, F = present principle sum * (1 + 
nominal amount interest rate /compounding   
0
500
1000
1500
2000
2500
Ja
n
Fe
b
M
ar
Ap
r
M
ay Ju
n Ju
l
In
ve
nt
or
y 
in
 th
ou
sa
nd
 b
ox
es
Title
Company
Proposed 
Company, 
1099
Proposed, 
219
2007 2008
2009(U
pto 
July)
Company 
capital cost 
involved
112 147 104
Proposed 
capital cost 
involved
25 31 21
0
20
40
60
80
100
120
140
160
A
m
ou
nt
 in
 m
ill
io
n 
tk
.
Page 751
  
periods per year) compounding   periods per year * no of annual 
periods  
= P * (1 + r/m) m*n 
For year 2007:  P = 80127262 *12 =961527144 tk; 
r = 7% = 0.07; m = 12; n = 2.7; 
 F = 1160926509 tk; 
Benefit (F – P) = 199399364.9 tk = 19.93 crore 
tk;  
Similarly for year 2008: F = 1502168915 tk; 
Benefit = 168070463.4 tk = 16.8 crore tk; 
For year 2009(upto July): F = 1037863481 tk; 
Benefit = 49488760.89 tk = 4.95 crore tk ;  
Similarly we calculate with 98% service level for 
reduce more inventory.  
5.13 Benefits from reduced inventory level (with 
service level 98%)  
If the company takes more risk (i.e. calculate 
inventory level with 98% service level in fixed time 
period model) then fluctuating demand can be meet 
without any stock out with more reduced inventory 
level. Increased benefit is shown below.  
For year 2007:  P = 87467414 *12 = 1049608968 
tk; r = 10% = 0.1; m = 12; n = 2.7; 
 F = 1373413016 tk; 
Benefit (F – P) = 323804048 tk = 32.38 crore 
tk;  
Similarly for year 2008: F = 1659430811 tk; 
Benefit = 258440879 tk = 25.84 crore tk; 
For year 2009(upto July): F =  1107360460 tk; 
Benefit = 74564885 tk = 7.45 crore tk ;  
 
RESULTS 
 
From evaluation on the inventory system of 
Pantonix 20 Tablet, it is visual that the company 
holds average 1166 thousand box/month (for 2007) 
as inventory. As this product has high sales volume 
so the company does not want to take any risk of 
stock out of this product. Therefore at first use 
100% service level in fixed time period model for 
calculating the proposed level of inventory. From 
analysis we found that average inventory 490 
thousand box/month (for 2007) is required. For this 
service level there is no stock out occurred. If the 
industry holds this proposed level of inventory then 
58% capital investment could be saved. Then 
conduct cross study for different service level. If 
99.73% (= ±3σ) service level is used then there is 
no stock out and 72% capital investment could be 
saved (for 2007). Similarly for 98% service level 
inventory level can be reduced more without any 
stock out.  
 
CONCLUSION 
 
It is visual that the company keeps huge inventory 
of selected product. This inventory can be reduced 
by applying fixed time period model. 
 
Page 752
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
 
 
 
 
 
 
Corresponding author: A.B.M. Abdul Malek 
Email:abmmalek@gmail.com 
CHANGE OVER TIME REDUCTION IN GARMENTS INDUSTRY 
THROUGH SMED METHODOLOGY. 
  
ABM Abdul Malek1 , Md.Mijanur Rahman 2, Md.Mamunur Rashid3  
 
 
1Assistant Professor, IPE Dept. Shahjalal University of Science & Technology         
               2Manager, IE &  Planning , Masco Industries Ltd., Tongi, Gazipur,Bangladesh  
                  3 Executive, IE & Planning, Masco Industries Ltd., Tongi, Gazipur,Bangladesh 
                                                                
 
Abstract 
 
The Single Minute Exchange of Die (SMED) is one important lean tool to reduce waste and 
improve flexibility in manufacturing processes allowing lot size reduction and manufacturing 
flow improvements. SMED reduces the non-productive time by streamlining and standardizing 
the operations for exchange tools, using simple techniques and easy applications. It provides a 
rapid and efficient way of converting a manufacturing process from running the current product 
to running the next product. This rapid changeover is the key to reducing production lot sizes and 
thereby improving flow. There has a great applicability of SMED method in RMG sector. 
Several implementations have proven that the SMED method really works in practice and 
reductions of even 90% and more are feasible in some situations [1]. As RMG sector is a large 
industrial sector in Bangladesh; Change over time reduction can play a vital role for improving 
productivity as well as economic development for the country. It is found that a significant 
amount of time per style, per month can be minimized by applying this method. The 
implementation has enabled reduction in setup time, through company's internal resources 
reorganizations without the need for significant investment.  
1.Introduction:                                        
Single-Minute Exchange of Die (SMED) is 
one of the many lean production methods for 
reducing waste in a manufacturing process[1] 
that has a great impact of any Manufacturing 
Industries such as Garments Manufacturing 
Industries. In Bangladesh garment Industries 
carry on a maximum economic growth of whole 
economic development but most of the garment 
industries is lacking behind to a great extent in 
concern of Productivity, Efficiency, Customer 
satisfaction level etc.  so to cover up some of the 
lacking, it must be developed a standardized 
process of minimizing change over time to 
increase productivity, Efficiency, Customer 
service level and profit via waste elimination.  
Today’s garment industries are continuously 
reached in highly competitive environment of 
Page 753ISBN: 978-984-33-2140-4
 
 
 
 
 
Corresponding author: A.B.M. Abdul Malek 
Email:abmmalek@gmail.com 
fashion and technology among to fill the 
customer satisfaction where Lean Manufacturing 
tools have a great excellence.    
                                                                            
SMED is that it has a lot of other effects which 
come from systematically looking at operations; 
these include stockless production, inventory 
freeing floor space, reduce production time, 
elimination setup error and setup time, 
Elimination of unusable stock. [2] 
2. Problem Formulation: 
Garments manufacturing system is a techno 
logical process of making a complete part by 
arranging several man and machine 
according to these sequential operations 
where that’s have some of term and 
condition to maintain the customer 
satisfactory level e.g. quality. When 
manufacturing products is in large scale, 
some of Internal & External activities & 
several tool exchanges take place for the 
same product where changeover time always 
play a vital role for slow production. A rapid 
changeover is widely acknowledged as an 
essential prerequisite to flexible, responsive 
production. The SMED system is a method 
that make possible to perform equipment 
setup and changeover operations under 10 
minutes. 
 
3. Methodology: 
 Survey and screening the situation of 
implementation area. 
 Activity classification. 
 Transforming internal into external 
activities. 
 Improvement, internal activities 
minimization. 
 External activities improvement. 
 Standardization and forming the 
SMED procedures. 
 
3.1. Survey and screening the situation of 
implementation area: 
Initial & final surveying have been done into 
the sewing floor to find out the feasibility of 
SMED method implementation. All 
activities have to be recorded in detail; some 
of the activity contributes to obtaining even 
worse result. So that SMED method 
implementation has a great significant in 
sewing section.    
 
3.2. Activity classification: 
This step is comprised of recorded activities 
divided into two groups: the internal and 
external ones. 
External activities are all the set up activities 
that can be preformed while machine is in 
operation. Internal set up activities are the 
ones that can be performed only if the 
machine is not in operation. 
 
3.2.1. The Internal Activities are: 
 Layout preparation 
 Trial production 
 Cleaning Machine surface 
 Cleaning work surface 
 Needle change 
 Stitch adjustment 
 Stitch measurement 
 Guide adjustment 
 Nose change 
 Looper adjustment  
 Tension adjustment 
 Thread change 
 Needle positioning 
 Trim adjustment 
Page 754
 
 
 
 
Corresponding author: A.B.M. Abdul Malek 
Email:abmmalek@gmail.com 
 Fixing new tools 
 
3.2.2. The External Activities are: 
 
 Pre Production Meeting. 
 Provision of trim card. 
 Getting cut panel from cutting section. 
 Getting threads & accessories from 
store. 
 Giving instruction about new style from 
supervisors. 
 Provision of Layout and line balancing 
sheet. 
 Provision of production sheet. 
 Getting instruction for next job. 
 Getting material for the next job from 
stores. 
 Getting tools for the next job from tool 
stores. 
 Returning tools for the last job to tool 
stores. 
3.3. Transforming internal into external 
activities: 
3.3.1. Needle change: 
To reduce the change over time Needle 
clamping system should be more reliable & 
less time consuming event. According to 
existing system Needle is push into upper 
position to hold it the needle holder then 
tighten the supporting screw. 
 
                        
 
Pic-1. Needle changing system 
 
Redesign system will be Electromagnetic 
clamping when machine is started or switch 
on an electromagnetic field will be create 
around the Needle holder then Needle is 
positioning into the seated position for left 
turn. But when it will need to change then 
just power off the machine and right turn to 
remove the Needle. 
 
3.3.2. Trial Production: 
 Trial production is done for the purpose of 
checking mainly product quality & some of 
product special specification such as size 
measurement, sewing quality, and stitch 
tension etc. During trial production 
instruction is given that what’s wrong and 
what’s right. If somewhat will wrong of any 
process then supervisors & in charge gives 
them proper specification.  Production 
managers, Quality manager, Floor in charge, 
supervisors are responsible for trial 
production. 
Page 755
 
 
 
 
 
Corresponding author: A.B.M. Abdul Malek 
Email:abmmalek@gmail.com 
Redesign system will be production 
manager and quality manager will have 
provide proper product specification, quality 
specification and others necessary 
specification for the responsible persons 
Quality controller, floor in charge, line 
Chief, and supervisors at least 2 or 3 days 
ago before final production. 
3.3.3. Layout preparation:                                  
In previous system the production peoples 
are responsible for layout preparation. In 
their layout there were some of problems for 
consuming more time. That was:  
 No process sequence. 
 Product not smooth flow.  
 Products are not totally forward 
flow. 
 Straight layout 
 Product transportation waste was 
high 
 Consume more space 
 Manpower & Machine allocation 
was not limited way 
 Process layouts are frequently 
changed. 
Redesign system will be Layout preparation 
must be done according to PMTS analysis which 
will totally helpful for SMV calculation, Man & 
Machine allocation, Target setting & Efficiency 
calculation & also preventive for these problems 
of process sequence, space, product 
transportation, man & machine allocation, layout 
change. 
 
3.3.4. Thread Change:                                                
It’s one of the most common internal 
activities in sewing line. Each sewing 
Machine have required only one thread 
stand with one running style color thread 
and the thread stand is attached in front of 
the sewing table with a handle. When a new 
style is introduced into the sewing line then 
thread stand is filled by another color thread 
in the basis of style color.      
 Redesign system will be that each thread 
stand must be separated into two sections. 
One section will contain running style color 
thread and another section contains 
upcoming style color thread. When running 
style production will be finished then it will 
not need to change thread stand, just move 
the thread stand to the sewing machine with 
a suitable operating length. 
3.3.5. Cleaning Machine Surface:                   
Cleaning Machine surface is an internal 
activity which also be performed frequently 
because of removing dust from machine 
surface. When it will be done machine must 
be switched off and this operation is 
performed by hand brush that’s not reliable 
and quick cleaning operation. 
Redesign cleaning procedure must be more 
effective by using portable vacuum hand 
cleaner without stopping machine. A 
portable vacuum cleaner is also a 
mechanical device that uses a draft of air to 
remove dust from a short distance of 
machine surface very quickly with 
adjustable pressure which will be more 
effective to change over time reduction such 
as lean implementation. 
Page 756
 
 
 
 
 
Corresponding author: A.B.M. Abdul Malek 
Email:abmmalek@gmail.com 
 
Pic-2. Portable hand vacuum cleaner [1]. 
 
 
4. Improvement, internal activities 
minimization: 
Some of internal activities can be improved 
by using 5S method. These are: 
 Stitch adjustment 
 Stitch measurement 
 Trim adjustment 
 Fixing new tools 
 Guide adjustment 
 Nose change 
These above internal activities have a great 
effect to change over time minimization. in 
the way of: 
– Visually set the tools, at hand of operator 
(5S) 
– Using connectors that may be rapidly 
exchanged for all tool power sources (5S) 
– Using as many locating pins for accurate      
    tool positioning as possible (SMED) 
– Cranes with sliding transporters (SMED) 
– Using cranes for heavy tools only (SMED) 
– Using standard tools as possible (SMED) 
 
5. External activities improvement 
All of the external activities (mention above) 
are possible to improvement by 5S 
implementation. 
– Placing visual markings for easier and    
   faster identification (5S) 
– Using check list to prevent unpredictable  
   events in resources preparation (5S) 
– “At hand” tool organization (5S) 
– Work place organization that decreases      
    tool search time (5S) 
5.1. Pre-Production Meeting:                         
Before starting test cutting & sewing  Pre-
Production Meeting will held to make sure 
everyone is aware of all about the style and 
execute the style respecting all quality points 
and to minimize communication gaps and to 
get  a know how of the order starting from 
cutting section to finishing section. The 
meeting will attended by Quality Assurance 
Manager, Cutting & sewing-In-Charge and 
respective line Mechanic. During the 
meeting following points will have 
discussed as per the agenda mentioned the 
following. 
 Introduction of the style - Assistant 
General Manager / Factory Manager  
 Fabric & Accessories status – Store-
In-Charge  
 Pattern, Cut marks etc – Pattern In 
Charge  
 Quality points – QA Manager  
 Special Operations – Technical 
Manager  
 Line Layout, Allocation of workers, 
Target setting, Line balancing – IE 
Dept. 
Page 757
 
 
 
 
 
Corresponding author: A.B.M. Abdul Malek 
Email:abmmalek@gmail.com 
 Ironing, Folding & Packing – 
Finishing-In-Charge  
Meeting minutes are recorded & circulated 
to all concerns. 
5.2. Cleaning work surface: 
Cleaning work surface is an External 
activity which must be performed frequently 
in garment production floor with manual 
brush that’s have a great effect to lean 
implementation such as change over time. 
By using tradition cleaning system huge dust 
would not possible to clean at a time. so that 
cleaning time is not totally improved. 
 
Redesign procedure of cleaning will be more 
reliable & less time consuming event than 
traditional system by using vacuum cleaner. 
A vacuum cleaner is a mechanical device 
that uses a draft of air to remove dust or 
other particulate matter from dry surfaces so 
easily & quickly. An electrically powered 
fan is used to produce a zone in which the 
air pressure is below atmospheric pressure, 
causing a draft of air to flow through the 
material to be cleaned, carrying the small 
practices with it. 
 
Pic-3. Vaccum cleaner [3]. 
 
6. Data Table:  
Here data are collected for basic T-shirt from 
one production line (style-Henze Basic T-shirt). 
 
Table-1. Layout preparation.  
Existing scenario of 
Layout preparation 
Redesign scenario of 
Layout preparation 
Associated 
activities  
Total 
Time(sec) 
Associated 
activities 
Time 
(sec) 
Sample 
Introduced 
 
 
 
 
 
 
 28800 
Sample 
Introduced 
1500 
Layout 
preparation 
Operation 
Breakdown 
 600 
Man & 
M/C 
allocation 
 
PMTS analysis 
 
900 
Verificatio
n of each 
process 
Layout 
preparation & 
Man & M/C 
allocation, 
Target setting 
 
 
5400 
 Finalization 
Total 28800 Total 8400 
 
Page 758
 
 
 
 
 
Corresponding author: A.B.M. Abdul Malek 
Email:abmmalek@gmail.com 
 
 
 
 
 
 
 
 
Table-2. Trial production. 
Process Fre
q. 
Total 
Time 
Process Fre
q. 
Actual 
Time 
(sec) 
Back & 
Front match 
1 7 Back & Front 
match 
 6 
Shoulder 
joint 
2 50 Shoulder joint  20.4 
Rib joint 2 18.6 Rib joint  15.6 
Rib open 1 22 Rib open  19.8 
Rib tack 1 9 Rib tack  6.6 
Rib close 2 46 Rib close  12 
Bk nk pipng 
& lebel 
place mark 
2  
48 
Bk nk pipng 
& lebel place 
mark 
  
12.6 
Piping close 
with label 
& lebel 
make 
3  
104.6 
Piping close 
with label & 
lebel make 
  
32.4 
Sleeve Hem 3 102.5 Sleeve Hem  20.4 
Sleeve 
Match 
1 16.2 Sleeve Match  14.4 
Sleeve Join 3 110.6 Sleeve Join  31.8 
Care & 
Name label 
make 
2  
15 
Care & name 
label make 
  
12.6 
Side seam 2 112.3 Side seam  40.8 
Sleeve open 
& close 
Tack 
 
3 
 
125 
Sleeve open & 
close Tack 
  
34.8 
Body Hem 2 51.5 Body Hem  16.8 
Total 838.3 Total 285 
 
Table-3. Needle change. 
 
Existing System 
 
Redesign System 
 
Process 
 
Time/change 
 
Process 
 
Time 
Plain M/C 112 Plain M/C 66 
F/L M/C 75 F/L M/C 38 
O/L M/C 92 O/L M/C 48 
Total 279 Total 152 
 
Table-4.Thread Change. 
             
                Existing System 
 
    Redesign system 
 
M/C 
No. of 
thread 
stand 
Time/ 
change 
Total 
time 
No. of 
thread 
stand 
A.T/ 
change 
Ttl 
time 
Plain 7 261  1827 7 81  567 
O/L 9 432  3882 9 192  1728 
F/L 3 780  2340 3 660  1980 
Total 8049   Total 4275 
 
 
Table-5. Cleaning Machine Surface:  
Existing system Redesign system 
M/C 
type 
No of 
M/C 
Cleanin
g 
Time/M
/c 
Total 
Time 
No of 
M/C 
Cleanin
g 
Time/M
/c 
Total 
Time 
Plain 7 118 826 7 40 280 
O/L 9 175 1575 9 65 585 
F/L 3 124 372 3 50 150 
Total 2773 Total 1015 
 
Table-6. Cleaning work surface: 
    Existing System   Redesign System 
Cleaning 
Time/Line 
Total Time Cleaning 
Time/M/c 
Total Time 
640 640 140 140 
 
Total 640 Total 140 
 
Table-7. External Activities improvement.                
External Activities Improvement (through 5S) 
 
PP meetings 
-Develop a systematic away to 
concern at about every stage of GMT 
manufacturing process. 
Page 759
 
 
 
 
 
Corresponding author: A.B.M. Abdul Malek 
Email:abmmalek@gmail.com 
-Develop an effective Instruction 
about production peoples. 
Getting cut 
panel from 
cutting section 
-Cut panel are distributed according to 
sewing line capacity. 
-Lead time reduction. 
-Accumulation of Bundle Quantity. 
Getting thread & 
accessories 
-Reduction of Lead time. 
-Reduction of manpower. 
Getting 
Instruction about 
new style 
-production people have already 
concern about new style from PP 
meeting. 
 
Arranging tools 
 
-Necessary tools are fixing in right 
place for quick operation such as 
Needle, scissor, thread, measurement 
tape, screw driver etc.  
Layout & Line 
Balancing 
-Reduction of excessive manpower. 
-Allocated man & machine in every 
sewing line. 
-Improve operation. 
-combined operation. 
 
7. Result: 
Table-8. Activities duration before and after       
              Implementation and time savings. 
 
Internal 
Activities 
Duration 
Before 
Improvement 
(SMED)  
Duration 
After 
Improvement 
(SMED) 
Time 
Saving 
Layout 
Preparation 
28800 8400 20400 
Trial 
production 
838.3 285 553.3 
Needle 
change 
279 152 127 
Thread 
change 
8049 4275 3774 
Cleaning M/C 
surface 
2773 1015 1758 
Cleaning 
work surface 
640 140 500 
Total Time 
(in Sec) 
41379.3 sec 14267 sec 27112.3 
sec 
Total Time 
(in Hour) 
11.494 Hrs 3.96 Hrs 7.53 
Hrs 
 
Table-9. External Activities improvement after 
implementation. 
External Activities Improvement      (Through 
5S) 
 
PP meetings 
Systematic, time saving & 
greater attention, accurate 
timing. 
Getting cut panel Sort, sustain, and lead time 
improvement. 
Getting thread & 
Accessories 
Lead time improvement, 
advanced functioning 
Arranging Tools Sort, standardized & 
sustain 
Line Balancing Advanced approach, better 
accuracy. 
 
8. Conclusion: 
Only one change over time has been 
considered including Internal and External 
activities and change over saving time has 
found 7.5 hours per Style. It’s carry on a 
better savings with higher productivity & 
sustainable manufacturing procedure for 
garment industries. 
9. Reference: 
[1] Shingo, S., 1985, A revolution in 
manufacturing – The SMED system, 
Productivity Press. 
 [2] Wikipedia free encyclopedia-single minute 
Exchange of die. 
 [2], [3] http://www.y920.com  
 
Page 760
Proceedings of the Conference on Engineering Research, Innovation and Education 2011 CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh  
CONSTRUCTION AND VISUALIZATION OF A DIGITAL FACTORY  
USING 3D MODELING SOFTWARE 
Abdul Awal Md. Saiful Islam*, Nayeem Ahmad and M. Iqbal 
Department of Industrial and Production Engineering 
Shahjalal University of Science & Technology, Sylhet-3114, Bangladesh 
ABSTRACT 
The interactive visualization of 3D objects has revolutionized such fields as engineering, medicine, entertainment 
and education. In fact there are a board range of applications including CAD, visual simulation and multimedia 
presentations where 3D model are used to give virtual world more realistic detail. Digital manufacturing is a 
technology to facilitate effective product developments & agile productions by digital environments representing the 
physical & logical schema & the behavior of real manufacturing system including manufacturing resource, process 
& products. A digital factory as a well designed & integrated environment is essential for success applications of 
this technology. In this research, we constructed a sophisticated digital factory of a toy company’s general assembly 
shop by measuring & modeling using parametric methods. It is expected that this method is very much useful for 
construction of a digital factory, & helps to manage diverse information & re-use 3D models. 
Key words: digital factory; modeling; software; manufacturing   
1. INTRODUCTION 
As customer demand diversify & global competition 
among toy companies become fierce, the companies 
are striving to discover new paradigms & 
technologies for rapid development of products. 
Digital manufacturing is a technology to facilitate 
effective product development & agile productions 
by digital environments representing the physical & 
logical schema & the behavior of real manufacturing 
system including manufacturing resource, process & 
products. A digital factory as a well designed & 
integrated environment is essential for success 
applications of this technology. In this research, we 
constructed a simple production facility of a toy 
factory’s general assembly shop by measuring & 
modeling using parametric methods. It is expected 
that this method is very much useful for construction 
of a digital factory, & helps to manage diverse 
information & re-use 3D models. 
At the design stage of a production system at a 
factory, designer can evaluate the feasibility design 
environment, detect the factory & it can be used for 
factory management. The development of virtual 
engineering factory is expected to be valuable by 
means of a 3-dimentional modeling system & 
animation based simulation package by taking into 
account the real data of a factory. A 3D model of a 
factory has been modeled by using 3D studio max 
software. Participant can navigate through virtual 
factory & examine the virtual factory from different 
points. Thus 3D modeling & animation based 
simulation technique provides a fast, effective 
method of visualizing & experiencing new designs 
which can be easily modified. Designer can design & 
see different types of layout of factory before making 
final decision to choose the best one. The animations 
of different machines were also successfully done. 
Virtual reality (VR) started from an unknown science 
& progressed into a highly exclusive, yet known 
science. The technology was born from the merging 
of many disciplines including psychology, 
cybernetics, computer graphics, database design, 
electronics, robotics & telepresence. There are many 
emerging and evolving concepts and definitions of 
virtual reality. Any representation that emulates 
reality (i.e. a drawing, a photograph, a movie, an 
audio recording) is, in a sense, a virtual reality. The 
term Virtual Reality (VR) is used by different people 
with many meanings. Virtual Reality (VR) is the 
computer aided simulation of a 3D model that one 
can interact with in order to get a better sense of 
object [1]. Virtual reality can also be defined as a 
synthetic computer generated (and hence virtual) 
environment within which a person can navigate & 
Page 761ISBN: 978-984-33-2140-4
interact with the virtual objects as the person would 
in the real world (reality) [1]. 
2. LITERATURE REVIEW 
VR originated in 1960’s,the person accredited with 
pioneering the concept of VR is Dr. Ivan Sutherland, 
who made ground breaking contribution  to the 
computer graphics & immersive interaction at 
Harvard & University of Utah [2]. He showed that, a 
person with the aid a light pen could interact with the 
computer via a display surface. Engineering based 
applications within all areas of academic, commercial 
& industrial life are increasing. It is generally 
acknowledged that most of the growth in the VR 
industry has been due to the demands for VR in the 
entertainment sector. 
Virtual environments are made up of 3D graphical 
images that are generated with the intention between 
the user & the objects in that environment. The term 
virtual environment (VE) describes a computer-based 
generation of an intuitive perceivable & experience 
able scene of a natural or abstract environment [2]. 
VE application will contribute to enhancing the 
qualities of human-computer interaction, the 
importance of which, in view of increasing complex 
information and communication applications, is 
constantly rising. 
In the 1917’s, Hollywood started to realize the power 
of VR in the film industry due to its potential to 
create extra ordinary visual scenarios. Films such as 
‘Star Wars’, followed by ‘Terminator’ and ‘Jurassic 
Park’ are just some of the films that benefited 
immensely from VR and computer graphics. 
Recently Pentagon has conducted a Virtual Nuclear 
War Game to predict its consequence. 
3D digital models can be freely constructed in this 
virtual environment [3]. The precise measurement of 
the digital model in size and forms is close to the real 
architecture. From a great deal of digital modeling 
research in color, material, lighting by Sasada [4], 
Lui [5] and etc., we can find that the simulation is 
nearly real. This not only enables to receive more 
feedbacks in the designing process, but also helps 
non-professionals to fully understand the designing 
content. 
 
3. CONSTRUCTION OF A DIGITAL 
FACTORY 
A digital factory is integrated infra-structure for 
digital manufacturing including CAD &  simulation 
models of machines, equipments, work cells, lines & 
plants. Fig.1 has shown a general procedure to 
construct a digital factory. It takes much time, cost, & 
resources, so effective action plans & objectives are 
essential. To construct a digital factory, 3D CAD & 
simulation model must be implemented. Both 
modeling works need considerable time, cost, & 
efforts. So technologies developments for an 
effective measuring & geometric modeling, a 
knowledge based CAD & simulation, & reuse models 
are essential. In addition to this technologies, 
systematic planning, determinations of detailed 
scopes & model maintenance are also very important. 
 
Figure 1: Procedure to construct a digital factory. 
Areas & effects of digital manufacturing for toy 
companies are as below: 
 Environments for digital engineering 
 Design  & operation of a factory 
 Validation & evaluation of products & processes 
 Line simulations 
 Inspections & quality managements 
 Visualization of product, process & resources 
3.1 Geometric Modeling 
3D geometry modeling CAD system such as 
AutoCAD is widely used in engineering design.  
AutoCAD   is very suitable as a graphics editor for 
geometric modeling, especially for 3D geometric 
EFFECTS ANALYSIS & EXTENSION
APPLICATION
VALIDATION & MODIFICATION
DIGITAL FACTORY CONSTRACTION
3D CAD MODELING & SIMULATION MODELING
DESIGN & PREPARATION OF DIGITAL FACTORY
ANALYSIS OF OBJECT FACTORY
PLANNING
Page 762
 
modeling. Although AutoCAD is powerful for 
geometry modeling, it can’t be used as the tool for 
complex system motion verification. AutoCAD do 
not have the dynamic simulation capabilities. 
AutoCAD provides some primary 3D objects, such as 
box, cone, wedge ball etc., which are often used in 
3D modeling. In order to create a realistic virtual 
model of the studio as a 3DS file .Similarly virtual 
model for modification, the virtual model was 
imported into AutoCAD as a DXF (Data Interchange 
Format) file. A DXF file is an ASCH (American 
Standard Code for Information Interchange) coded 
file, of an AutoCAD drawing for importing and 
exporting to and from other software packages [2]. 
Fig 1 illustrates the process of converting a realistic 
AutoCAD MODEL INTO 3D Studio virtual model.  
Create 3D studio model(object) 
 
Export as a AutoCAD (DXF) file Model(object) 
 
 
Figure 2(a): Conversion process of a 3D studio 
                    virtual model to an AutoCAD model. 
 
Export as a AutoCAD (3DS) file Model(object) 
 
Import AutoCAD (DXF) file Model(object) 
 
Create AutoCAD model (object) 
 
Figure 2(b): Conversion process of an AutoCAD 
                     model. 
 
3.2 Application of Virtual Engineering Factory 
Planning: 
The typical applications of virtual factory planning 
are: 
i. Planning and verification of machine setup. 
ii. Determination of production sequence of 
workshop machines. 
iii. Analysis of different alternatives of layout 
of workshop. 
iv. Planning and verification of material 
logistics. 
v. Aisle planning. 
3.3 Advantages of Virtual Workshop Planning: 
The typical advantages of virtual workshop planning 
are as follows: 
a. More precise planning results compared to 
conventional tools. 
b. Exchange of knowledge among different experts 
in the planning team. 
c. Taking into account various influential factor 
such as workplace safety, accessibility and 
production tools. 
d. Reduction of planning time and errors. 
e. Planning results can be used for the purpose of 
training and education. 
f. Documentation of company know-how. 
g. Planning results can be used for the purpose of 
training and education. 
3.4 Requirements for Digital Factory Modeling: 
In order to build the virtual workshop, which is 
similar to a real workshop, there might be many 
requirements in modeling the elements of 
manufacturing system. Among a number of 
requirements, the authors emphasize that the 
following three ones are most important to develop a 
modeling system for virtual factories [6]: 
a. Visualization: The most important requisite is that 
a virtual workshop should be visualized with reality 
.with good visualization, one can easily and observe 
how each system elements works in the 
manufacturing systems. 
b. Detailed descriptions: Each elements needs its 
detailed description, not only for its visualization, but 
also for calculating a number of its attributes, for 
example, when you want to put a work piece into a 
box, you have to know the shapes and dimensions of 
the work piece and the box in order to check whether 
the box can contain the work piece or not.  
Import AutoCAD (DXF) file Model(object) 
Page 763
 
c. Flexibility: The modeling system should present a 
flexible way of modifying a virtual workshop in 
order to cope with the change of machines, layout 
and other facilities. Any facility to create computer-
generated models of virtual objects and environments 
that can be interactively explored in 3D and modified 
and recreated in offers enormous potential for 
concurrent engineering and for integration of 
manufacturing activities generally [7]. The designer 
would be able to quickly visualize the product 
concept and represent alternative design solution. 
The basic requirement for virtual engineering 
workshop facilities planning is, first of all, the 
availability of all objects in virtual environment. If 
this requirement is fulfilled simple production 
facilities planning are possible. 
The system development was divided into two main 
parts [7]: 
i. Construction of a virtual environment: This part 
provides experience of creating virtual object and 
placing them in the virtual environment with 
associated real world. Properties in order to illustrate 
how models are created. 
ii. Use of virtual environment: This part encourages 
exploring different attributes of the virtual 
environment within two broad categories which are 
factory walk through and visualization of different 
sections of the factory.   
4. SIMULATION USING 3D  
STUDIO MAX 
 
Modeling and editing panel: The cornerstone of 3D 
Studio MAX is an advanced 3D modeling and 
animation environment.  One can perform 2D 
drawing, 3D modeling, and splinebased animation 
within the unified workspace.  Modeling, editing and 
animation tools are always available in the command 
panels and tool bar. 
Lights & Camera: Designer can create light objects 
using the light category of creating a panel. Ambient 
light is found in the Environment dialog by choosing 
Rendering/Environment. The lights can cast shadows, 
project images, and create volumetric effects for 
atmospheric lighting. 3D Studio Max also supports 
real-world camera controls for lens length, field of 
view, and motion control such as truck, and pan. 
Materials: 3D Studio Max contains a sophisticated 
Material Editor that floats in its own window above 
the scene. One can use the Material Editor to create 
highly realistic materials by defining hierarchies of 
surface characteristics. 
Animation: The user can begin animating his scene 
at any time by clicking the animation button. This 
button can be clicked again to move back and forth 
between modeling and animation. The users can 
extensive control over his animation with the 3D 
Studio Max Track View. This is a window into time 
where one can edit animation keys, set up parametric 
animation controllers or display and adjust motion 
curves for all of your animated effects. 
Rendering: The 3D Studio Max render includes 
advanced features such as analytical, motion, 
volumetric, lighting, and environmental effects [8]. 
Modeling objects in 3D Studio Max: The latest 
technology in modeling is utilized in this project by 
combining 3D Studio Max software and AutoCAD 
with Supers cape VRT for object drawing. 3D Studio 
Max is a three-dimensional modeling and animation 
based package. It has the facilities to add, subtract, 
combine, and can add material to object, to perform 
2D drawing, 3D modeling, and splinebased 
animation within the unified workspace. Modeling, 
editing and animation tools are always available in 
the command panels and toolbars. 
The designer can draw 2D and convert it to 3D by 
using tool bars and can view in front view, top view, 
and in perspective view. This software helps the 
designer to change an initial profile of a model, thus 
updating the previous model and its current drawing. 
Moreover it helps viewing the model at the same time 
in different ways. 
5. CONCLUSION 
This paper presents a parametric method for effective 
construction of a digital factory. For a toy general 
assembly shop, we defined object-oriented schema 
for diverse objects, & define modeling parameters. 
Finally the digital general assembly shop is made by 
integrations of 3D models of diverse equipments. 
 
 
Page 764
    REFERENCES 
1. Tusher H. Dani, Marwan Fathallah, and 
Rajit Gadh, “COVIRDS: An Architecture 
for a conceptual Virtual design System”, in 
proceeding of the 1994 Design for 
Manufacturability Conference, Chicago,IL, 
(1994), USA, pp 19-26. 
2. Gavriel ,” Handbook of Human Factors And 
Ergonomics ”, published by John Wiley, 
New work, (1997), pp.1726. 
3. Mitchell W., McCullough M., 1997, Digital 
design media, New York. 
4. Sasada, T.:2000, Computer Graphics and 
design: Presentation Taiwan. 
5. Liu, Y.T., Eisenman, P.: 2001, Emergence 
of digital architecture, Hu’s, Taipei. 
 
6. M. Onosato and K. Iwata, “Virtual Works:  
              Building a Virtual Factory with 3D  
              Modelling and Object Oreinted  
              Programming Technuique”, proceeding of  
              The1992 IFAC-INCOM, Toronto, Canada,  
             (1992), pp.281-286. 
7. Tompkins A. James, “Facilities planning”, 
published by John Wiley & Sons Inc. New 
York, (1996), pp.103. 
8. D. Fan, Felger, W. G. and Global, M.,  
       “Applying Virtual Reality to Electronic  
       Prototyping- Concepts and First Results”,  
       Proceeding of the IFIP WG 5.10 Workshop  
       On Virtual Environments and Their  
       Applications and Virtual Prototyping,  
       Stuttgart, Germany, (1994), pp. 326-336. 
 
Page 765
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
* Corresponding Author: Shuza Binzaid, PhD,  
E-mail: shuza00@yahoo.com 
DEICING TECHNOLOGY FOR MODERN MILITARY AND 
COMMERCIAL AIRCRAFT WING SURFACES 
 
Shuza Binzaid1*, Shamshul A. Al-Tomal2, Dara Zaid3, 
Mahamudul H. Rosen4 
 
1Founder and Director, SERES-BD, Dhaka, Bangladesh  
2Department of Mechanical Engineering 
University of Texas at San Antonio, Texas, USA 
3Department of Civil Engineering 
University of Bangladesh, Dhaka, Bangladesh 
4Department of Electrical and Electronic Engineering 
University of Information Technology and Sciences  
 
An airplane wing ice detector has been designed and found to have some extra advantages over many 
commercially available snow/ice detectors on airplane wings. The system has been tested extensively and 
has proved to be accurate and reliable. A new type of graphite sensor has been designed which is self-
cleaning; very low power, easily mountable and replaceable. This graphite sensor is implemented in the 
system to detect the presence of ice and measure ice thickness accurately. A comparative discussion of this 
system with some of the commercial systems will be presented in this paper. A novel technique using DSP-
based real-time application of the system will be discussed in this paper. This paper discusses about better 
safety to both modern military and commercial aircrafts and the advancements of the future technology.  
 
Key words: Sensor; DSP; Real-Time Application; Differential Amplifier, Threshold Detection  
 
1. INTRODUCTION 
 
Water particles from atmosphere deposit as ice on 
aircraft wing surfaces at lower altitude below 25000 
feet during operation of an aircraft in flight. Thus it 
makes the military missions imperative to achieve 
effective flight mission. Also for commercial 
aircraft’s safety requires knowing risk of icing 
condition to avoid catastrophic situation. For 
aircraft in the take-off mode, the FAA has ruled 
that no ice is to be present on critical flight surfaces 
[1]. Recent study has shown that ice roughness 
heights of as little as 0.005 inches can reduce 
maximum lift capability by 20% and roughness of 
0.03 inches will decrease lift by 40% [2]. Such 
tremendous degradation of aerodynamic efficiency 
occurs as a result of ice accumulation with possible 
consequences of stalling, problem of drag and loss 
in performance to the airplane. As a vital part of 
flight safety, the flight crew must be informed of 
ice and icing conditions.  
 
Technical literatures about ice detection and 
information of commercially available deicing 
systems have been reviewed to understand 
functionality, advantages and disadvantages of 
those systems [3]. Some systems employ 
mechanical apparatus such as cylinders to collect 
ice, with light path sensing, vibration or resonance 
variation, stiffness sensing, hot rod for specific heat 
sensing etc. These systems have some limitations. 
An airplane wing ice detector/deicing system has 
been designed and found to have some extra 
advantages over many commercially available 
snow/ice detectors placed on airplane wing surfaces 
[4]. In this paper we describe a new design of an 
ultra low-power, easily replaceable graphite sensor 
which is self-cleaning, thus making the sensor 
virtually maintenance free. A larger model of this 
graphite sensor has been tested extensively. It has 
proved to be very accurate and reliable to detect the 
presence of ice and measure the ice thickness.  
 
2. SYSTEM DESIGN AND SETUP 
 
An amplifier consisting two op-amp circuits is 
designed to process very low power signal 
information from sensors. The dangerous level of 
icing condition is detected with the processed signal 
voltage that is proportional to ice thickness by TI 
DSP system (TMS3206711 DSK). A computer 
setup with DSP system simulates and computes the 
Page 766
ISBN: 978-984-33-2140-4
  
actual thickness of ice detected on the sensor. The 
system requires calibration only once at amplifier 
stages during initial setup of DSP for signal capture 
and thus digital conversion of ice-thickness that 
becomes proportional to resistance of the sensor. 
As a part of calibration, the computer also 
calculates the multiplier factors for sensor values.  
Figure 1 shows the block diagram of system setup.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 1: Block diagram of the system 
 
The ice sensor should be placed on upper front 
surface of the airplane wing at airflow transition 
area where ice buildup occurs. This area is very 
important for airplane lift factor. Any roughness on 
this area can cause loss of flight efficiency. Such 
loss of flight efficiency results in turbulence and 
drag thus flight safety degrades tremendously. The 
sensors are placed along the path of airflow in 
parallel thus there is no issue of airlift due to the 
sensor placement. Also this placement can maintain 
minimum force on the sensor caused by airflow. 
This system also needs a temperature monitoring 
capabilities.  The temperature sensor allows system 
to detect lower temperature for ice buildup 
conditions only. Thus preventing any false 
detection of water accumulation i.e. rain drops on 
i.e. sensor or wing surface of airplane while on 
ground. Figure 2 shows the deicing system sensors 
placed on the aircraft wing surface. The transition 
area is indicated by ice buildup region.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 2: Sensors on aircraft wing surface  
3. BASIC PRINCIPLES OF THE 
SENSOR 
 
The sensor unit uses two probes that are electrically 
conductive using a very low current ranging 
between few micro amps only at low voltage. These 
probes are non-corrosive by environmental effects 
on the wing surface. The resistive medium at steady 
state condition is considered as air. In this 
condition, sensor read the resistance of air was 
about 4 M.  Figure 3 represents the equivalent 
electrical circuit diagram for initial test setup of 
sensor. The resistance of the sensor drops to about 
20 K, when probes conduct through water making 
about 0.01-inch thick film. 
 
In this deicing application, the sensor is very small 
in size. The detection process occurs by water 
particles between the probes creating a low current 
path. Water particles at very low temperature freeze 
and thus the aerodynamic quality of an airplane 
wing degrades. Also it creates a similar current path 
between the sensor probes. It continues with low 
current path between probes until the ice is melted 
away and break the path.  
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 3: An equivalent sensor circuit. 
 
This small sensor can detect only a localized area 
where detection is important. The size of the sensor 
probes can be made longer for different aerospace 
applications where continuous detection process is 
required for distributed area.  There are three 
resistors associated with this circuit. Rprotection is 
used to prevent the system from short circuit 
situations. Value of the resistor is about 200  and 
it can easily be ignored for calculation, as the other 
resistance values are so large. Vsense is measured 
when Vsupply value is non-zero.  A shunt resistor 
with value above 3 M can be placed in parallel 
with Virtual Rsesnsor for checking sensor’s proper 
connection as an option. This resistance value can 
be ignored also as the ice detection resistance is 
 
 
Ice buildup 
region 
Turbulence Ice Sensor 
Temperature Sensor 
Aircraft Wing 
 
 
 
 
Ice and 
Temperature
Sensors on Wing
Signal Amplifier
Stages
TI DSP
TMS3206711 DSK
System
 
 
V sense V supply R sensor 
R reference 
R protection 
Sensor Probe 
Sensor Probe 
l  
 
Page 767
  
much lower than this value. This circuit in figure 3 
forms a potential divider network and the resistance 
of the sensor can be expressed as:  
 
Rsensor = (Rref*Vsense)/(Vsupply-Vsense) 
 
The logical conditions are determined from the 
equivalent circuit of the sensor. Table 1 determines 
these conditions. The threshold can be adjusted 
within a very wide range of sensed medium from 
 
Table 1: Condition of monitored zone 
 
Rsensor Logical 
Resistance Condition 
< 2 K Sensor line short circuit 
< 30 K (Ice Ice detected 
threshold adjustable)  
>30 K and <2.5 M No ice detected 
> 2.5 M Sensor open circuit 
 
30 K to 2.5 M. So this type of sensor can be 
used to determine presence of non-icing conditions 
also. The Rsensor values are changed when in the 
presence of ice from very high values of air 
resistance to few thousand times smaller values of 
water resistance.   
 
4. REAL-TIME TESTS AND RESULTS 
 
Figure 4 shows the actual circuit implemented and 
tested. The sensor had about 0.9 inches long and 
0.1 inches wide graphite probes.  It was used to 
detect water and ice. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 4: A practical sensor and circuit system. 
This small width is adequate as the critical 
thickness for the presence of ice is very small 
during flight. Also the sensing threshold stays 
within the smaller voltage range. 
 
Increasing the length of probes can increase 
accuracy of ice thickness measurement. The Csensor 
is negligible for deicing application, as the length of 
probes is very small to create air-gap capacitance. 
In most cases this capacitance can be ignored if 
only to detect ice.  
 
Cref is an optional capacitor used in parallel in order 
to help stabilizing the DC effect of the Rref in the 
circuit.  This circuit used high frequency input 
signal to the sensor.  
 
The input high frequency applied to the sensor 
prevents ionized contaminants to attach on the 
surface of the sensor probes. The polarity of the 
probes switch at the same rate of the input 
frequency and ionized contaminants are always 
repelled thus the sensor maintenance is reduced and 
also longer life of this sensor can be obtained.  
The localized sensor data showed linearity of the 
curve in figure 5. This linearity also determines that 
the capacitance between the probes is negligible.  
 
Localized Sensor Curve
1.5
2.5
3.5
4.5
5.5
6.5
7.5
-1 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16
Ice Thickness (Unit  = 0.05 Inch)   
Se
ns
or
 C
ir
cu
it 
O
ut
pu
t V
ol
ta
ge
 
Figure 5: Plot of data from the localized sensor 
system shows voltage linearity with ice thickness. 
 
The threshold shift at amplifier output was from 
1.94 volts to 6.12 volts in localized sensor as 
expected. The detection of ice was done easily with 
this threshold variation. The linear curve shows the 
linearity of ice resistance with thickness. Then the 
slope of the curve was determined from collected 
data. With the amplifier and the sensor setup, the 
experiment results showed that 12.267 mV of 
threshold changed for every 0.01 inches of ice 
thickness.     
 
 
V R ref 
Signal 
Amplifier 
Differentia
l Amplifier 
Threshold 
Detection 
DSP System 
C ref R sensor 
C sensor 
R protection 
l 
 
tial 
 S 
e 
n 
s 
o 
r 
 
 
Page 768
  
5. ADVANTAGES AND DIS-   
ADVANTAGES 
 
There are a number of advantages of this sensor and 
circuit setup over some other sensors found on 
aircraft.  They are: 
1. The design is very practical and sensor can be 
easily placed on wing surface. Then the circuit 
can be easily adjusted and calibrated for steady 
state condition.  
 
2. The system is associated with temperature 
sensing capabilities increase system accuracy to 
determine presence of ice.  
 
 3. This sensor can be driven at high frequency with 
a very low current rectification circuit. 
 
4. The system has built-in short-circuit protection 
where electrical burnout does not occur and thus 
safety is increased. 
 
5. The sensor probes are capable of self- cleaning 
and removes ionized contaminants increasing 
life of sensor and making it maintenance-free. 
 
6. In continuous distribution sensor setup, the 
sensor probes can be connected in series to 
increase the coverage of sensing length or area 
on aircraft surface. 
 
7. A number of ice sensors can be connected in 
parallel to a single sensing node of network to 
increase the number of sensing zones. 
 
There are some disadvantages of the system that 
can also be avoided carefully:  
 
1. Steady state conditions need to be recalibrated if 
numbers of sensors are changed. 
 
2. Graphite sensors in this system were brittle 
under pressure. Other conductive, non-corrosive 
materials may need to be identified.  
 
3. Increasing the sensor length reduces value of 
Rsensor and increases value of Csensor and thus 
increasing non-linear function of ice thickness.  
 
6. THE SYSTEM OPERATION 
 
The system has been tested and found to operate 
without any error for detecting ice buildup. The 
system does not have any effect on its operation 
due to flow of air and air pressure through airplane 
wing surface. Also there is no capacitive effect on 
the sensor because of its small sized probes. So the 
system’s measurement of ice thickness stays linear. 
The electronic circuit was designed for sensor 
signal amplification. A logical operation flow for 
the system was implemented for ice detection and 
deicing actions. Figure 6 represents the logical flow 
of the system operation. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig 6:  The logical flow of the system operation 
 
When temperature is above the icing condition, the 
system disregards the presence of water particles 
between the sensor probes. So rain water particles 
flowing over wing surfaces is completely ignored. 
This feature gives an extra advantage over some 
other systems used on many aircrafts today as the 
chance of erroneous sensing is avoided.  
 
 
 
 
 
 
System 
Initialize
Activate
Ice Sensor Input
Signal 
Start
No
Yes
Ice
Present on
Sensor? 
Wing 
Surface Temp
T<0 ?
No
Detect for Critical
Threshold of Ice 
Thickness 
Yes
DSP 
Measure Ice 
Thickness
Interrupt 
Deicing System
to Activate
Ice
Present on
Sensor? 
Yes
No  
Page 769
  
When temperature of water at freezing point, the 
system sends signal for ice detection. Also this 
signal is used for repelling the ionizing 
contaminants from the sensor probes for cleaning. 
The DSP system generates information about 
thickness of ice buildup on wing surface and the 
computer system computes the thickness. System 
simulates notification to the airplane crew’s 
display. Also the system is activates deicing system 
in the wing when it detects ice thickness reaching 
the critical threshold.  
 
7. FUTURE ADVANCEMENTS 
 
First, we need to place this system on commercial 
airplane wing surface. The probes in this case 
should be made with durable graphite or other 
electrically conductive material like carbon fiber 
materials. Then test the system during actual flight 
and also on ground in very cold weather.  
 
This system can be improved for future high-speed 
avionic transports where space flights will be 
initiated. The wing concepts are different with 
smaller wing areas to obtain high-speed transports 
in future. For such transports at low altitude below 
25000 feet, it will become absolutely crucial to 
achieve precision system for deicing. Sensors must 
be designed smaller and their materials should be 
very strong to withstand high pressure and 
temperature. Today’s technologies for military 
combat airplanes are already implementing such 
smaller wing concepts for achieving high-speed. 
Deicing technology for such aircrafts can be 
developed using this design concept.   
 
To increase airplane safety standards, a number of 
ice sensors can be placed on known areas of each 
wing where ice accumulation occurs. This way the 
accuracy of the deicing system can also be 
increased. To improve airplane’s technical 
standards, this new approach will apply less 
number of wires for sensors. This will implement a 
logical array technique that can allow very less 
number of wiring harnesses needed for these 
sensors. An algorithm for such mixed signal 
technique is currently being investigated and a 
suitable design approach of a control circuitry is 
under consideration for future deicing system.   
 
Other design considerations include redesign of 
sensors where they can be very small. Currently a 
design idea is being implemented where the sensor 
probes will be 0.06 inch thick and also they will be 
less than 0.25 inch long. These sensor probes will 
be tested on airplane when ready. For its smaller 
resistive surface area and thus reduced 
conductance, it becomes an ultra-low power sensor. 
Also it can easily be mounted and replaced on the 
wing surfaces at multiple locations. 
 
As the system uses very low power sensor, it may 
suffer from induced noise and capacitance due to 
long wires running in the wing from the deicing 
system to the sensor during a real flight. The future 
high-speed transports can have low power 
embedded circuitry on sensor probe module on 
wing surface and thus cancel the effects of induced 
noises. This approach can also increase the 
bandwidth for high-speed signal generation 
between the sensor and the deicing system. 
 
7. CONCLUSION 
 
Design of localized sensor is implemented for 
airplane deicing system that can detect icing 
conditions accurately. The results from the 
experiments verify that this deicing system can help 
avoid the critical icing accumulation causing 
impairment of military, aerospace missions and 
commercial flights. The results found from the 
experiments also show that the sensor is very linear 
with the thickness of ice and it was 12.267mV per 
0.01 inch of ice thickness. The sensor principle and 
circuitry is described here. Also the block diagram 
and the logical flow of the system are presented 
here. The advantages and disadvantages of the 
system are discussed here. The improvements 
including implementation of smaller, very sensitive, 
0.06-inch thick and 0.25-inch long ice sensors for 
the future flights of military, space and commercial 
flights are also discussed. 
 
REFERENCES  
 
1. Lightfoot, F.M. and Milligan, R.E., (1997), 
Aircraft Ice Accretion Measurement: A Phase 
I, SBIR Study Using Millimeter Wave Radar 
(MMWR), IEEE AES Systems Magazine, 
August, pp. 3-9.   
2. Valarezo, W.O. (1993), Aerodynamic 
Performance Effects due to Small Leading-
Edge Ice (Roughness) on Wings and Tails, 
Journal of Aircraft, November-December, 
30(6). 
3. Federal Aviation and Aeronautics, (1992), 
Aircraft Ice Detectors Related Technologies for 
Onground and Inflight Applications, FAA, 
New Jersey, USA.  
4. Binzaid, S. and Biney, P.O. (1994), 
Development of Snow/Ice Detector for 
Airplane Wing Surface, E&A Proceedings, 
Texas, USA, (2), pp. 577-581. 
5. Kelly Aerospace, (2006), Thermawing, Kelly 
Aerospace Thermal Systems. 
 
Page 770
Proceedings of the
Conference on Engineering, Research, Innovation and Education 2011
11-13 January, 2011, Sylhet, BANGLADESH
*Corresponding Author Mohammad Mahmudur Rahman, Department of Industrial Engineering and Management, Khulna
University of Engineering and Technology, email- rochy.kuet@gmail.com
Design, Construction and Testing of an Earth Tube Heat Exchanger (ETHE)
Md. Fahad Hossain 1, Mohammad Mahmudur Rahman 2*,, Mohammad Rezwan Sheikh 1, Khandkar Aftab Hossain 1,
1 Department of Mechanical Engineering, Khulna University of Engineering & Technology, Khulna-9203, BANGLADESH
2 Department of Industrial Engineering & Management, Khulna University of Engineering & Technology, Khulna-9203,
BANGLADESH
ABSTRACT
In this project, attempts have been made to determine the soil temperature below the ground level. It was expected that the
temperature would fall with the depth and after a certain level there would be no fluctuation of earth temperature. The
purpose of this investigation was to find out if the environment prevailing at a reasonable depth could be used for
supplementing the design of heating or cooling processes. A design for such a system has been presented using the data
collected in the experiments. The system does both provide cooling in summer and warming in winter. In winter the system
warms up the ambient (cold) air by as much as 100C at night. In summer cools the ambient (hot) air also by as much as 120C
during the day. The constructed ETHE has been tested and the COP obtained for both cooling and warming mode is much
higher than that of the conventional air conditioning system. The COP of an ETHE depends on the temperature difference
between ambient and comfortable temperature. With the increase of this temperature difference COP is also increased.
Initial installation cost of an ETHE is much lower than that of a conventional air conditioning unit. Also electric costs and
greenhouse gases and other pollutants are considerably reduced and maintenance costs decreased.
Keywords: ETE, COP, Temperature Difference, Cost Analysis.
1. INTRODUCTION:
Earth-Tube Heat Exchanger (ETHE) is a device that
enables transfer of heat from ambient air to deeper
layers of soil and vice versa. The idea is that as the air
travels through the pipes, it gives up some of its heat to
the surrounding soil, entering the house as cooler air.
This will occur only if the earth is at least several
degrees cooler than the incoming air. During cold
season when air is slowly drawn using a small fan
through plastic pipes buried at this depth, it will be
heated providing natural climate control with much less
energy than conventional heating and cooling. The soil
serves as a heat sink in the summer and as a heat source
in the winter, thus giving almost year round temperature
modification.
2. DESIGN OF THE SETUP
There are basically three configurations, an open 'fresh
air' system, a closed loop design, or a combination. An
attempt has been made for designing an open loop
system in which following design parameter were
considered.
Tube diameter: Optimum tube diameter varies widely
with tube length, tube costs, flow velocity, and flow
volumes. Diameters between (2 and 18 inches) 15.2
and 45.7 centimeters appear to be most appropriate.
Tube Location: Earth temperatures and, consequently,
cooling tube performance vary significantly from
sunny to shady locations. Where possible, the inlets in
open loop systems and the cooling tubes themselves
should be placed in shady areas.
Tube Depth: Tubes should be buried at least (6 feet)
1.8 meters below ground level. Only rarely is burying
them more than (12 feet) 3.7 meters justifiable. When
digging trenches at these depths, cave-ins are an
extreme hazard, and appropriate precautions should be
taken.
Earth Temperature: The temperature of the earth at
depths of (20–100 feet) 6.1–30.5 meters remains about
two to three degrees higher than the mean annual air
temperature. At depths less than (10–12 feet) 3.1–3.7
meters, earth temperatures may be strongly influenced
by air temperatures and may vary during the year,
depending on the location. Near the surface, earth
temperatures closely correspond to air temperatures.
Tube Length: There is no simple formula for
determining the proper tube length in relation to the
amount of cooling desired. Local soil conditions, soil
moisture, tube depth, and other site-specific factors
should be considered to determine the proper length.
Soil Properties: The amount of heat conducted and how
widely it is diffused varies from one soil type to another.
The moisture content of the soil is a major influence on
conductivity and diffusivity, and accounts for large
variations on how heat moves through the earth.
3. EXPERIMENTAL SETUP FOR INITIAL
DATA ACQUISITION
For placing the thermocouples in order to measure
temperature of different ground levels a suitable site is
selected at north side of Mechanical Engineering
Building, KUET campus. Deep hole with about 6 inch
diameter and about 11 feet depth was prepared to place
the pipe with thermocouples at different level.
Page 771
ISBN: 978-984-33-2140-4
Fig. 1: Thermocouple placement into the tube at
different ground level.
Figure 2: Temperature measuring setup
Temperatures at different ground level at different days
were recorded. Then these data were analyzed to
determine the exact ground position for the placement
of earth tube heat exchanger (ETHE). To observe the
seasonal effect data for both summer and winter season
were collected.
For winter season the data of 23rd December 2008 has
been shown on the fig 3.
Fig. 3: Soil temperature at various depths and ambient
Temperature at KUET campus, Khulna at 23rd
December, 2008.
From the figure it is seen that the temperature difference
occurs maximum at the lowest level of the ground
where we have determined to experiment. For summer
season the data of 4th April, 2008 has been shown on the
fig.4
Fig. 4: Soil temperature at various depths and ambient
temperature at KUET campus, Khulna at 19th April
2008.
From these data the deepest position at 3m were
selected for placing the ETHE as there is little
fluctuation and wide difference of temperature was
noticed.
4. FINAL INSTALLATION
According to the design proposed the arrangement was
installed at a depth of 3 m under the ground level.
Fig 5: Three Dimensional Concept of the ETHE.
Data were taken during both summer and winter season.
Temperature was measured at different distance of the
tube to observe the change in air temperature with tube
length. To do this several temperature sensor were
placed at a certain distance on the tube. The sensors
were calibrated properly before taking the data.
Fig 6: Final installation of ETHE
Page 772
Table 1: Air Temperature inside ETHE and Soil Temperature at 21.01.09
Table 2: Air Temperature inside ETHE and Soil Temperature at (26.03.09)
Time T+1m
(°C)
T0m
(°C)
T-1m
(°C)
T-2m
(°C)
T-3m
(°C)
T Room
(°C)
TA
(°C)
To
(°C)
T18.5
(°C)
T34.3
(°C)
T55.2
(°C)
T60.4
(°C)
T82
(°C)
10:30am 23.5 24 24 25 26 29 34 26 32 28 26 25 25
11:30am 23.5 24 24 25 26 29 35 27 32 29 27 26 25
12:30pm 23.5 25 24 25 26 29.5 36 28 33 30 28 26 24
01:30pm 23.5 25 24 26 27 30 37 30 33 31 29 26 24
02:30pm 23.5 25 24 26 27 31 36 32 32 30 29 25 24
These results can be more accurately illustrated by
plotting a graph.
Fig. 7: Air Temperature inside ETHE and Under
Ground Temperature under 3m depth at 3:00 AM (21
January 2009) at different length of ETHE.
Fig. 8: Air Temperature inside ETHE and Under
Ground Temperature under 3m depth at 11:30 AM (26
March 2009) at different length of ETHE.
5. RESULT AND DISCUSSION:
The design was made for a single room placed at the 1st
floor of ME building in which the cooling load was
calculated as 4496.6 watt. To meet this cooling load
requirement with the obtained temperature difference
between the ETHE and room the mass flow rate
requirement was found 0.319 kg/s. The required length
and diameter of the tube was calculated by using
various empherical heat transfer relations and the
diameter was taken as 1.5 inch and the length 82 m
including the inlet and outlet pipe. PVC pipe was used
for the inlet and outlet pipe to reduce heat loss in the
surrounding while passing through it. This air flow can
be supplied by using a blower of 0.5 hp (373 Watt).
Therefore the Coefficient of Performance (COP) at
cooling mode for the designed ETHE is
COP= 4496.6/373 So, COP=12.1
But there was some heat loss occurred at the outlet pipe
and therefore the actual heat transferred was found as
2569.5 and hence the COP was found as 6.95 which is
also a very good result because to meet the cooling load
of the proposed room with conventional air conditioning
system, the COP was calculated as 3.17.
Again the heating load for the same room during winter
season was found as 2758 watt. To satisfy this heating
load with the obtained temperature difference between
room and ETHE the mass flow requirement was
calculated as 0.304 kg/s. This air flow can be supplied
by using a blower of 0.5 hp (373 Watt). Therefore the
Coefficient of Performance (COP) at cooling mode is
COP= 2758/373 So, COP=7.4
Time T+1m
(°C)
T0m
(°C)
T-1m
(°C)
T-2m
(°C)
T-3m
(°C)
T Room
(°C)
T0
(°C)
T18.5
(°C)
T34.3
(°C)
T46.7
(°C)
T55.2
(°C)
T60.4
(°C)
T82
(°C)
12:00pm 23.5 24 24 25 26 23.5 23.5 23 24 24 25 25 25
01:00am 23.5 24 24 25 26 24 23.5 23 24 24 25 25 25
02:00am 23.5 25 24 25 26 24.5 23.5 23 23 24 25 25 25
03:00am 23.5 25 24 26 27 25 23.5 24 24 25 25 26 26
06:00am 22.5 24 24 25 26 25 22.5 22 23 24 25 25 25
07:00am 22.5 24 23 25 26 25 22.5 22 23 24 24 25 25
08:00am 23 24 23 25 25 25 23 23 23 24 24 25 25
Page 773
But due to heat loss occurred at the outlet pipe and the
actual heat transferred was found as 765.3 and hence the
COP was found as 2.07 which is also a good result.
6. CONCLUSION
From this study, it came to the conclusion that this
system is not suitable for sole preheating or cooling of
air .Due to its limitation of cooling or heating air up to a
limited temperature, its capacity is limited. It can be
used as a secondary system in order to reduce load from
the primary and costly cooling system in order to save
energy and cost. It has important potential for cooling as
it is investment competitive with air-conditioning.
During summer it can be used as bypass heat exchanger
on exhaust air. From Bangladesh perspective, Earth
Tube Heat Exchanger can be used in places where lands
are available. In rural places where Air conditioning
facilities are not common and there are large fields
available, ETHE can be employed there for
conditioning room for both human and livestock
buildings. It can also be used for grain storages in the
locality.
7. REFERENCES
[1] Arora, C.P., ‘Refrigeration and Air Conditioning’,
Tata McGraw-hill Publishing Company Limited, New
Delhi, 2nd Edition.
[2] Ozisik, M.N., ‘Heat Transfer: A Basic Approach’,
McGraw-hill Publishing Company Limited, New York,
International Edition.
[3] Girja Sharma, R.K Sahu, Ratan Jadhav, Air cooling
and Heating System for Tiger in Zoo using Earth Tube
Heat Exchanger, February 2002.
[4] Girja Sharma, Ratan Jadhav, Soil Temperatures
Regime at Ahmedabad, November 2002.
[5] G. Sharma, H. Prakash, R. Jadhav, Performance of
Greenhouse Coupled to Earth-Tube-Heat-Exchanger in
Closed-Loop Mode, March 2004.
[6] Girja Sharan, Earth Tube Heat Exchangers for
Environmental Control of Farm Buildings in Semi-arid
Northwest India, W.P. No.2008-01-02, January 2008
[7] Girja Sharan, Development and Some Applications
of Earth Tube Heat Exchanger in Gujarat, May 2005.
[8] Didier Thevenard, Bibliographic Search on the
Potential of Earth Tubes, September 6, 2007.
[9] F.A. Ansari , A.S. Mokhtar, K.A. Abbas and N.M.
Adam , A Simple Approach for Building Cooling Load
Estimation, American Journal of Environmental
Sciences 1 (3): 209-212, 2005.
[10] Girja Sharan, Ratan Jadhav, Performance of Single
Pass earth-Tube Heat Exchanger: An Experimental
Study, July 2003.
[11] M.K.Ghosal, Sujata Nayak, G.N.Tiwari and
N.Sahoo, Modeling and Experimental Study for Winter
Performance of an Earth to Air Heat Exchanger: An
Alternative Energy Source for Greenhouse, Agricultural
Engineering International: the CIGR Ejournal.
Manuscript EE 07 012. Vol. X. January, 2008.
[12] ASHRAE Handbook, fundamentals 2001.
[13] F. C. McQuiston, J. D. Parker, J. D. Spitler,
Heating, Ventilating, and Air Conditioning, Analysis
and Design, 5th ed, John Wiley & Sons, Inc, 2000.
[14] C. O. Pedersen, D. E. Fisher, J. L. Richard,
Development of a Heat Balance Procedure for
Calculating Cooling Loads, ASHRAE Transactions, v
103, n 2, 1997.
Page 774
Proceedings of the
Conference on Engineering, Research, Innovation and Education 2011
11-13 January, 2011, Sylhet, BANGLADESH
* Corresponding author. Mohammad Rezwan Sheikh, E-mail : rezwansk@gmail.com
DEVELOPMENT OF SIMULATION SOFTWARE FOR DESIGNING DUCT OF AIR
CONDITIONING SYSTEM
Mohammad Rezwan Sheikh 1, Mohammad Mahmudur Rahman 2, Mihir Ranjan Halder 1 ,
1 Department of Mechanical Engineering, Khulna University of Engineering & Technology, Khulna-9203, BANGLADESH
2 Department of Industrial Engineering & Management, Khulna University of Engineering & Technology, Khulna-9203,
BANGLADESH
ABSTRACT
The optimal layout and sizing of duct systems has become more and more a concern for HVAC system designers. Although
most duct systems are designed either by an HVAC contractor or a consulting engineer, many plant designers often find it
necessary to alter a duct system design to correct obvious flaws. Not only duct system modifications are made to clear
obstructions, but also they are sometimes made for obvious economic reasons. The original design may include high cost,
unnecessary transitions and special fittings. An experienced sheet metal person can quickly spot these anomalies in a duct
design. However, modifications to a duct design must be made carefully to ensure that the system will work as intended.
Rather than performing initial design or modifying someone else's design, it is a good idea to analyze proposed duct systems
with simulation software to ensure that they will work properly. So in this project simulation software is developed to
design an economic air conditioning duct system. This software is helpful to determine the duct sizes and pressure losses in
each duct section both in main duct sections as well as branch duct sections by following equal friction method and static
regain method. It is also used to determine pressure required at blower/fan exit and the capacity required for the blower.
When duct-sizing calculations are done manually, it needs a big amount of money and time but by using this software a
designer can design a duct system in a fraction of the time required by analytical method.
Keywords: HVAC, Duct Design, Equal Friction Method, Static Regain Method.
1. INTRODUCTION
The purpose of heating, ventilation and air
condition (HVAC) system is to provide occupants
with thermal comfort, controlled humidity, proper
ventilation, and air filtration. Ducts are used in
HVAC systems to deliver and remove air. It also
delivers a part of the supply air, ventilation air. As
such, air ducts are one method of ensuring
acceptable indoor air quality as well as thermal
comfort. However, a poorly designed or
constructed HVAC duct system may result costly
system, uncomfortable, noisy and contaminated
environment inside the room. A duct system is
often called ductwork. Planning ('laying out'),
sizing, optimizing, detailing, and finding the
pressure losses through a duct system is called
duct design. The strategic placement of the fan and
the optimal routing of ductwork help to create a
system that is both economical and easily balanced.
However, system layout is a task that requires
experience and engineering judgment. At present,
the layout stage of duct design cannot be aided
much by the computer. The best solution is the use
of simulation software’s in these situations to help
the designer in performing interference checks.
Simulation software’s are based on the process of
imitating a real phenomenon with a set of
mathematical formulas. It is essentially, a program
that allows the user to observe an operation through
simulation without actually performing that
operation. Simulation software’s are widely to
design equipment so that the final product will be as
close to design specs as possible without expensive
in process modification.
Proposed software is developed with Microsoft
Visual C# which is a programming environment
used to create graphical user interface (GUI)
applications for the Microsoft Windows family of
operating systems. It is an object-oriented
programming (OOP) language.
2. DESIGN FACTORS OF AIR DUCT
SYSTEM
A well designed air duct system, either commercial
or industrial, must consider most of the following
system design factors [3]:
i. Space Availability;
ii. Space Air Diffusion;
iii. Noise Levels;
Page 775
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
iv. Duct Leakage;
v. Duct Heat Gain and Losses;
vi. Balancing;
vii. Fire and Smoke Control;
viii. Initial Investment Cost;
ix. System Operating Cost.
3. DUCT DESIGNING METHODS
The most common methods of air duct system
design are:
a. Equal Friction Method,
b. Static Regain Method, and
c. Velocity Reduction Method.
The principle of the Equal Friction Method is to
size a system’s ductwork for a constant pressure
loss per unit length of duct. At the higher air flow
rates, however, it may be necessary to limit the
velocity so as not to generate objectionable noises.
Once the system is sized, the total pressure losses
for the main and branch sections from junction-to-
junction /fan/terminal may be calculated and the
total pressure grade line plotted.
The static regain method is a design procedure in
which the ducts are sized so that the increase in
static pressure (static regain) at each take-off
offsets the pressure loss of the succeeding section
of ductwork. This method is especially suited for
high velocity installations having long runs with
many take-offs or terminal units.
The Velocity Reduction Method consists of
selecting the velocity at the fan discharge, and
designing for progressively lower velocities in the
main of each junction or branch duct. The return
air ductwork is sized similarly, starting with the
highest velocity at the fan suction and decreasing
progressively in the direction of the return intakes.
With the ducts sized and the fittings known, the
total pressure losses can be calculated, the
pressure gradients plotted, and the minimum
pressure loss or critical path of the system
established.
4. GENERAL RULES OF DUCT DESIGN
i. Study the plans of the building and
arrange the supply and return outlets to
provide proper distribution of air within
each space. Adjust calculated actual air
quantities for duct heat gains or losses and
duct leakage. Also, adjust the supply,
return, and/or exhaust air quantities to
meet space pressurization requirements.
ii. Select outlet sizes from manufacturers’
data.
iii. Sketch the duct system, connecting the
supply outlets and return intakes with the
central station apparatus, taking
recognizance of the building construction,
and avoiding all structural obstructions and
equipment. The space allocated for the
supply and return ducts often dictates the
system layout and the shape of the ductwork.
iv. Determine the size of main and all branches
by the selected design method.
v. Calculate the total pressure requirements of
all duct sections, both supply and return, and
then plot the total pressure grade line.
vi. To design a system with the minimum
owning and operating costs, repeat steps 4
and 5 with different duct sizes. It is
necessary to estimate the cost of the initial
design and the incremental cost variations
due to the redesigns.
vii. Layout the system in detail. If significant
duct routing and fitting variations have
occurred from the original design,
recalculate the pressure losses.
viii. Redesign the duct branches to minimize the
balancing necessary by dampers.
ix. Analyze the design for objectionable noise
levels and specify sound attenuators as
necessary.
x. Select the fan.
5. METHODOLOGY FOR SOFTWARE
DEVELOPMENT
Object-oriented programming (OOP) is based on the
scientific classification principles of ordering and
naming groups within subject fields. In this software
the concepts of classes and objects are applied with
graphical user interface (GUI). Some tool such as
label, text box, button, radio button, tab control,
group box and data grid view are used in this
software to provide the friendly input and output
environment for the user. There are options to select
the duct designing method and then to calculate the
duct sizes and pressure losses by providing the
required input in this software. The inputs and
outputs of the software for the different method are as
follows:
Table 1: Inputs & Outputs for Equal Friction Method
Inputs Outputs
 No. of main duct section
 Friction Rate
 Loss co-efficient
 Static Pressure at each
outlet
 Aspect Ratio (for
rectangular duct)
 Length of each section
 Discharge through each
section
 Diameter of each
section
 Velocity pressure
 Frictional Pressure
drop
 Total Pressure drop
in each section
 Rectangular duct
sizes.
 Capacity of blower
Page 776
Table 2: Inputs and Outputs of Static Regain
Method
Inputs Outputs
 No. of main duct
section
 Static Regain Factor
 Velocity at Blower Exit
 Static Pressure at each
outlet
 Aspect Ratio (for
rectangular duct)
 Length of each section
 Discharge through each
section
Diameter of each
section
Velocity pressure
Frictional Pressure
drop
Pressure Loss in
each section
Pressure Regain in
each section
Rectangular duct
sizes.
Capacity of blower
And the flowchart for developing the software is:
Fig 1: Flowchart for developing the software
6. FEATURES OF THE SOFTWARE
The steps required to use the software are: If the
software is opened, then the interface as shown in
Fig 2 will be displayed from which the method
can be selected for calculation.
Fig 2: Duct designing method interface
Upon choosing the method of calculation by
clicking ‘Start’ button the following interface
appears which asks for some input according to the
method used.
Fig 3: Equal Friction Method interface for circular
duct
After giving the required inputs in the respective
fields the ‘Calculate’ button is pressed and the
desired outputs are obtained.
Fig 4: Equal Friction Method interface after giving
all inputs for main duct.
Start Method
Selection
Calculation
Output Data End
Input Data
Duct Cross-
Section Selection
Page 777
After pressing the calculate button, the software
may provide the output as shown in Fig 5.
Fig 5: Equal Friction Method interface with inputs
& outputs for main duct
Similarly the specification for the branch duct and
sub-branch ducts can be obtained by putting input
required data at the specified field and pressing
calculate button.
7. DISCUSSION AND CONCLUSION:
A real problem has been formulated and analyzed
both manually and by using software with both
methods. From the comparison, there are very
small differences between the results obtained by
the software and the results obtained analytically
(due to round up values are taken). Therefore the
software is able to provide the accurate results. If
the calculation of static regain method is done
manually, then so much iteration is avoided. But
in this software, it is programmed for more
iteration for accurate results. The manual
calculation may take so much time to give results.
On the other hand, the software may give the
results immediately after giving the required
inputs.
The software is developed for designing any air
conditioning duct by using two conventional duct
designing methods such as equal friction method
and static regain method. The software gives the
accurate results in comparison to manual method.
It is also useful for economical duct designing,
which not only reduces the cost of designing duct
but also reduces the cost of fabrication. It also
reduces the time for designing air conditioning
duct. Generally, static regain method gives duct
sizes more than the duct sizes obtained by equal
friction method and the software provides the
same requirements. Comparing the two methods,
users can make decision to choose the required
duct designing method.
In the present state of the software, a duct designer
can easily design air conditioning duct with the help
of this software. This software can be developed in
such a way that, it will show the 3D or 2D duct
layout graphically with the numerical output. This
software can be developed for other modern duct
designing methods. This software can be also used
for cost analysis for the designed duct.
REFERENCE
 C P Arora, Formerly Professor, Department of
Mechanical Engineering, Indian Institute of
Technology, New Delhi, ‘Refrigeration and Air
Conditioning’, 2nd Edition, Tata McGraw-Hill
Publishing Company Limited, New Delhi, India.
 ‘HVAC Systems Duct Design’, 3rd Edition,
Sheet Metal & Air Conditioning Contractors
National Association (SMACNA)’.
 Sam A. Abolrous, Learn C# (Includes the C#
3.0 features), Wordware Publishing Company,
Inc.
 ‘Design of Air Conditioning Duct’, Lecture 38
on Refrigeration & Air Conditioning, Version 1,
ME, IIT, Kharagpur, India.
 http://elitesoft.com
 http://wikipedia.org/duct(HVAC)
Page 778
Effect of EGR ratio to control particulate matter emission from diesel engine 
combustion by using High –Speed combustion model. 
 
A.S.M Sayem1*, Tilok Kumar Das 1  
1 Lecturer, Department of Mechanical Engineering, Chittagong University of 
Engineering and Technology(CUET)  
 
Abstract: Diesel engine attract market attention due to its high thermal efficiency 
among other IC engine. To design diesel engines adapted to future exhaust gas 
regulations, it is important to develop a driving mode simulator to estimate vehicle 
performance and exhaust emissions. For the driving mode simulator with simple and 
high-speed calculation characteristics, the authors use a diesel combustion model based 
on the Hiroyasu model. In this study, we examine the effect of EGR on particulate 
matter emission , like: Ethylene, CO, NOx, etc. For this we are varying EGR ratio 
during operation cycle. We use Tsurushima reduced kinetic model together with 
characteristic mixing time scale.  Direct introduction of the reaction model to the basic 
combustion model did not give good simulation result for experimental data.  However 
by introducing mixing time scale to take into account local heterogeneity of the mixture, 
the simulation accuracy was significantly improved. The result shows possibility of 
simulating the rates of heat release and emissions including ethylene and CO for the 
different EGR ratio.  
 
Key word: EGR, Combustion model, Ethylene, CO, NOx ,Diesel engine 
 
 
 
 
* Corrosponding author,  E mail: yessayem@yahoo.com , Contact: 01713109874 
 
Page 779
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
N.Tamanna: tamanna0541@gmail.com 
M.A.Ialam:  aminulislam@mme.buet.ac.bd 
EFFECT OF MICRON SIZE PARTICLE CONTENT ON 
TRIBOLOGICAL BEHAVIOURS OF POLYMER MATRIX 
COMPOSITES 
 
N. Tamanna1 and M.A. Islam2 
1 Final Year Student and 2 Professor 
 Materials and Metallurgical Engineering Department, BUET, Dhaka-1000 
 
 
The use of polymers and polymer matrix composites, in various tribological applications, has become state 
of the art because of their many attractive properties such as high strength to weight ratio, low friction, self 
lubricating behaviours, low noise under service, corrosion resistance, etc. As a result, in many applications, 
metallic components are replaced day by day. In this study polyester based composites have been developed 
by adding various inorganic micron size filler materials such as graphite, silica, silicon carbide, etc. of 
varying proportions (1, 2.5, & 5 wt%). The developed composites were then characterized by wear & tensile 
tests. Initiative has also been taken to investigate the wear mechanisms of the developed composites by 
optical microscope and SEM. Experimental results, for all composites, showed a decrease in tensile strengths 
with increase in the filler contents. However, the wear rate has been found to decrease for graphite and 
silicon carbide particle reinforced composites. In this paper, experimental results that have been obtained 
will be presented and underlying reasons of property variations will be discussed.  
 
Keywords: Polymer Matrix Composites, Micron size particles, Inorganic filler, Wear, Wear mechanism.  
 
1.  INTRODUCTION 
Over the past decades, thermoplastic composites 
are numerously used in the tribological purposes 
such as seals, gears, bearings, etc. Various features 
makes the polymer matrix composites so promising 
in practical applications, e.g. high strength to 
weight ratio pre-requisite for the aircraft body, self 
lubricating behaviours necessary in bearings, cages, 
rotating nuts, gears, etc. It has been found that short 
fiber reinforcement, e.g. reinforcement by carbon, 
glass and steel fibers, can generally improve the 
creep resistance and compressive strength of the 
polymer composites and result in enhanced wear 
resistance [1]. A number of materials mostly 
inorganic (graphite, molybdenum disulphide, talc, 
silicon fluid, etc.) are used as lubricant. It has been 
mentioned earlier that polymers, in general, are self 
lubricating because of their layered lattice structure 
and they are usually anisotropic. Their structure 
allow them to be easily sheared, and therefore they 
lower the friction when placed between sliding 
metal surfaces and provide a shear plane of lower 
strength than those of the two sliding surfaces [2-3]. 
The use of graphite as a particulate filler has been 
reported to improve tribological behavior in 
composites. 
The use of inorganic fillers is increasing not only to 
reduce the cost of the composites but also to meet 
several requirements, which could not been 
achieved by using reinforcement and resin 
ingredients alone. In order to improve the friction 
and wear properties many researcher modified 
polymers using different ingredient. The Wear rate 
of high density polyethylene was reduced by CuO 
and Pb3O4 and for polytetrafluroethylene was 
reduced by ZrO2 and TiO2 [4-5]. Bahadur et al. 
found that the compounds of copper such as CuO 
and CuS were very effective in reducing the wear 
rate of PEEK, PTFE, Nylon and HDPE [6-8]. 
The objective of this research work is to develop 
polyester based composites reinforced with various 
inorganic fillers with their varying proportions and 
also to characterize the friction and wear properties 
of the developed composites. In this paper, 
initiative will be taken to present and discuss 
various tribological features observed in the 
research work for the developed composites. 
 
 
Page 780
ISBN: 978-984-33-2140-4
  
2.  MATERIALS USED AND 
EXPERIMENTAL PROCEDURE 
 
2.1 Materials Used 
Polyester resin was used as the matrix system, 
which is thermosetting. There are two parts in 
matrix system, one is the polyester resin itself and 
other is the hardener (MEKP: methyl ethyl ketone 
peroxide). Various micron size inorganic particles 
such as graphite, silicon carbide and silica were 
used as reinforcing particles. 
 
2.2 Resin Preparation 
The micron size particles (graphite, silicon carbide 
and silica) were mixed with the polyester by 
varying 1 to 5 wt%. For mixing the particle in the 
resin, a mechanical mixture was used. During 
mixing air bubbles were formed. If the bubble is 
present in the resin after mixing, it induces 
detrimental effects on the properties of the 
composites. For that reason, vacuum was applied to 
the mixture of polyester and micron size particle for 
about 30 minutes. Once the bubbles were 
completely removed from the mixture, hardener 
(1.5%) was added in it. The mixture was then 
mechanically stirred for about 2 minutes and 
vacuum was again applied for 10 minutes to 
remove the bubble produced during the hardener 
mixing. 
 
2.3 Composite Fabrication 
Hand lay-up process was used to manufacture all 
composites in this study. A mould releasing agent 
was used to the mould surface before casting for 
removing the composites from the mould easily. A 
level gauge was also used to ensure the uniform 
thickness of the sample. After de-molding, the 
composites were treated for post curing, which was 
done at 70oC for 2 hours in an oven. The size of the 
laminate was 125mm X 125mm X 10mm. Then the 
samples for testing were prepared from the 
laminate. The details of composites are shown in 
Table 1. 
 
 
Table 1. Details of composites developed. 
 
Sample 
Code 
Matrix Filler Wt% 
 
P(P) Polyester Nil  
P(C) Polyester Graphite 1, 2.5 & 5 
P(SiC) Polyester SiC 1, 2.5 & 5 
P(SiO2) Polyester Silica 1, 2.5 & 5 
 
2.4 Test Procedure 
 
2.4.1:  Tensile test: Tensile tests were carried out 
using the Instron Universal testing machine 
accordance to ASTM D3039 standard (rectangular 
specimens). The gauge length was 25 mm and the 
cross head speed was 5 mm/min. The tensile load, 
stress and modulus were computed from the stress-
strain curves of the composites. 
 
2.4.2 Fractography: The fracture surfaces of the 
tensile test specimens were analyzed. For observing 
the fracture surface, scanning electron microscope 
(SEM) was used, which was operated at 30 kV. 
Samples were mounted with carbon tape on stubs. 
In order to improve the electrical conductivity of 
the fracture surface of the composites, gold coating 
was applied by sputtering technique. 
 
2.4.3 Wear test: A pin-on-disc type wear test setup 
(Fig. 1) was used for experiment. The dimension of 
the pin is 5 mm diameter and 12 mm length. The 
counter surface disc was also made from the same 
material of the pin itself. The pin was initially 
weighed using a digital electronic balance. The test 
was conducted under 5.7 N load, where the disc 
rotation was 1050 rpm. After conducting the test, 
final weight was measured in the same balance. A 
minimum of three trials were conducted to ensure 
repeatability of test data. 
 
 
 
 
 
                                                               
 
 
 
 
 
 
 
3.  RESULTS AND DISCUSSION 
 
3.1 Macrostructure 
The cast samples of polymer matrix composites 
containing various types of fillers (graphite, silicon 
carbide and silica) are shown in Fig. 2(a) and the 
close-up views of these discs are shown in Fig. 
2(b). These close-up views show the dispersion of 
particles, which is observed in the matrix from the 
macrostructures.  
 
 
Applied load 
 Pin 
 Wear disc 
sc 
Fig. 1: Pin-on-disc type wear test. 
 
Page 781
  
 (a) 
 
 (b) 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
3.2 Tensile Test 
The load vs. % of filler graph is shown in the Fig. 
3. It shows the effect of reinforcement particles on 
the load bearing capacity of the developed 
composites. It is observed that addition of any 
reinforcement particle improved the tensile strength 
of the pure polyester to a certain limit. After certain 
percentage of filler, the load bearing capacity of the 
composites is tremendously decreased. Because, 
initially when particle is added, it occupies the 
interstitial of resin molecules and causes 
mechanical bonding. For that reason, the strength of 
composites is increased. But when more and more 
particle is added, resin particles are separated by the 
reinforced particles as shown in Fig. 4. Only 
reinforced particles can not give enough strength. 
So, the strength of composites decreases above an 
optimum level of filler materials. From the Fig. 3, 
the load bearing capacity of the reinforced 
composites increases around 1 wt. % of the filler 
content and then decreases. So, it can be said that 
the optimum level of reinforcement is around 1 
wt%. 
 
 
 
 
 
 
 
 
 
 
 
Fracture characteristics of the composites depend 
on the bonding at the interface of the fillers and 
matrix. In this system, only mechanical bonding is 
present at the interface of the filler and matrix. The 
SEM fractographs of the fracture surface of tensile 
specimens the developed composites are shown in 
Fig. 5. The fiber/matrix debonding can contribute to 
the failure process. In this study, transgranular 
fracture is occurred for all samples. For P (SiC) and 
P (SiO2) composites crack initiations may be 
occurred from coarse particles (Figs. 5c & 5d). 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
P(C) 
P(SiC) 
P(SiO2) 
Fig. 2. Macrographs of cast composites are shown in first column (a) and close-up 
views (micrographs) of these cast samples are shown in the second column (b). 
Note: Particle dispersion in the polymer matrix seems to be more or less uniform.  
 
% of filler 
Lo
ad
 
Fig. 3: The load vs. % of filler curves of the composites. 
 
Page 782
  
 
 
 
 
 
 
   
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
3.3 Wear test 
The graph of wt. loss vs. % of filler content is 
shown in Fig. 6. Composite reinforced with silica 
resulted lowest wear resistance and that wear 
resistance further decreased with increase in the % 
of particle. The graphite particles work as self 
lubricating media [14]. As a result, wear rate of the 
graphite reinforced composite decreased gradually 
with increase in the filler content and then became 
to be fixed. Although, SiC reinforced composites 
showed slightly more wear rate, however, the trend 
of wear rate was found to be similar to that of 
graphite reinforced composites. Similar observation 
has also been made by other investigators [9]. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig.  4: Schematic diagram showing the effect of increasing amount of 
reinforcing particles in the composites. 
  
1 % 
 
2.5 %  5 % 
Resin  
Particles 
200 µm  200 µm  
200 µm  200  µm  
(a) (b)
(c) (d) 
Fig. 5: SEM micrographs on tensile fracture surfaces of (a) polyester, (b) P(C), 
(c) P(SiC) and (d) P(SiO2). 
 
Fig. 6: The wt. loss vs. % of filler graph 
of the composites 
% of filler 
W
t. 
lo
ss
(m
g)
 
P(C) 
P(SiC) 
P(Silica) 
Page 783
 Fig.  7: Counter faces in wear test are shown in first column in figure (a) 
and close up view of these disc are shown in second column in figure (b). 
 
 (a) 
 
 (b) 
 
The worn surfaces of the counter face parts resulted 
due to wear tests are shown in Fig. 7(a) and close-
up views of worn faces are shown in Fig. 7(b). The 
effect of particles in the matrix can be observed 
from these figures. Particles are detached from the 
matrix and deformed the matrix severely which is 
called stress whitening. Stress whitening refers to 
the phenomenon where polymer materials are 
deformed to a certain extent and become visually 
white in color and at the same time their 
transparencies are decreased. The graphite particles 
are coherent with the matrix for its structure. As a  
result, the wear rate and stress whitening in  P(C)  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
are lower than the other composites. But in the case 
of P(SiO2) composite, the silica particles cause 
more localized deformation in the matrix because 
of its severe abrasive nature. Silica particles restrict 
the plastic deformation zone and increase the 
intensity of the localized deformation. As a result 
the stress whitening is also increased in the case of 
silica particle reinforced composite. In the case of 
the P(SiC) composite, the wear rate also decreases, 
but wear rate is greater than the P(C).     
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Page 784
  
4.  CONCLUSIONS 
In this study polyester matrix graphite, silicon 
carbide and silica micron sized particle reinforced 
composites wear developed and their tensile and 
wear resistance were characterized. Experimental 
results suggest that the tensile and wear properties 
did not follow similar trends for all composites. 
Initially, tensile strengths for all composites were 
found to increase; however, for higher amount of 
filler contents, tensile strengths were decreased. On 
the other hand, wear rates of graphite and silicon 
carbide particle reinforced composites were found 
to decrease gradually and then it became fixed. 
However, silica reinforced composite resulted 
higher wear rate with increase in the filler content 
from the beginning.  
 
5.  REFERENCES 
1. Friedrich, K, Zhang, Z, Schlarb, A.K., (2005).  
“Effects of various fillers on the sliding wear 
of  polymer composites”. Compos Sci. Techno; 
65, pp. 2329-43. 
2. M.A. Zamzam, (1989), “Wear resistance of 
agglomerated and dispersed solid lubricants in    
aluminium”. Materials Transactions, JIM, 
30(7), pp.  516 to 522. 
3. Bahadur, S., (2000). “The development of 
transfer layers and their role in polymer 
tribology”. International Journal of Wear, 245, 
pp. 92-9 
4. Briscoe, B.J., Pogosion, A.K.and Tabor, D., 
(1974), “The friction and wear of high density 
polyethylene: the action of lead oxide and 
copper oxide fillers”, International Journal of 
Wear, 27, pp. 19-34. 
5. Tanaka, K., (1986), “Effect of various fillers on 
the friction and wear of PTFE-based 
composites", In: Friction and Wear of Polymer 
composites.” Vol.205, pp.137-174, (Friedrich 
K editor), Elsevier, Amsterdam. 
6. Bahadur, S., Fu, Q., and Gong, D., (1994), 
“The effect of reinforcement and the synergism 
between CuS and carbon fiber on the wear of 
nylon.”, International Journal of Wear, 178, pp.  
123-130. 
7.  Bahadur, S., and Tabor, D., (1985), Role of 
fillers in friction and wear behavior of HDPE 
In: Polymer wear and its control, 287, pp. 268-
74, (L.H. Lee (ed.) ACM) symposium series, 
Washington DC. 
8. Bahadur, S., and Tabor, D., Anderegg, J. W., 
(1992), “The role of copper composites as 
fillers in the transfer film formation and wear 
of Nylon”. International Journal of Wear, 154, 
pp. 207-223. 
9. Kazuaki, Y., (2007), “Abrasive properties of 
nano silica particles prepared by a sol–gel 
   method for polishing silicon wafers” Springer 
on-line Publication on Science and Business: 8 
May 2007. 
10. B. Suresha, Chandramohan, G., Prakash, J.N., 
Balusami, V. and Sankaranarayansamy, (2006) 
“Role of fillers on friction and slide wear 
characteristics in glass-epoxy composites 
system”. J. Minerals & Materials 
Characterization & Eng., 5(1), pp. 87-101. 
11. Basavarajappa, S., Chandramohan, G.C. 
(2005), “Wear studies on metal matrix 
composites: A taguchi approach.” J. of 
Material Sci. and Tech., 21(6), pp. 348-350 
12. Chang, L., Zhang, Z., Ye, L., Friedrich, K. 
(2007), Tribological properties of high  
temperature resistant polymer composites with 
fine particles”, Tribology International, 40, pp. 
1170-1178. 
13. Hossain, M.K., Hossain, M.E., Hosur, M. and 
Jeelani, S., (2009), “Mechanical and Thermal 
Characterization of CNF-filled Polyester Nano-
phased Composites Filled Polyester Nano-
phased Composite”, Tuskegee University, 
Tuskegee, USA. ICME (09)-AM-12. 
14. Robert, L.F., (1990), Self –Lubricating 
Polymer Composites and Polymer Transfer 
Film Lubrication for Space Applications. 
NASA Technical Memorandom 102492, Lewis 
Research Center Cleveland, Ohio. February. 
15.  Wang, P.I., Hutchings, M., Duncan, S. J., 
Jenkins, L., Woo, E. (2006), Strain whitening 
of a thermoplastic olefin material. J Mater Sci.,  
41, pp. 4847–4859. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Page 785
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
                                                                      
*Corresponding author: Muhammad Abdus Samad 
E-Mail: ASamad_ipe@yahoo.com 
ERGONOMICS AND THE PREVENTION OF MUSCULO-
SKELETAL STRAIN AND BACK INJURIES. 
 
 
Muhammad Abdus Samad 
Department of   Industrial and Production Engineering, ShahJalal University of Science and 
Technology, Sylhet-3114, Bangladesh. 
E-Mail: ASamad_ipe@yahoo.com 
 
 
ABSTRACT  
As technology becomes more complex, so ergonomics is undoubtedly destined to play an increasingly 
important role in industrial production and industrial health and safety. At the workplace, ergonomics places 
equal emphasis upon greater system efficiency and improved health of the individual.  Ergonomics must be 
involved in fitting the tool and machine to the worker by design, fitting the worker to the machine by 
selection and training, and the optimization of the ambient environment to suit the man or the adaptation of 
the man to tough environmental conditions. Ergonomics aims to promote efficiency, safety and comfort at 
work situation in industry through better relationship between man, his tools and the work environment.  
This paper deals about the injuries such as backaches, neck aches, and other muscular strains due to bad 
seating and incorrect working posture and how to prevent them by designing of workstation that will be very 
comfortable and convenient to work at. The paper also discusses the optimal conditions for the workers, 
reduction of physical workload, improvement of working postures and facilitating psycho-sensorial 
functions in instrument handling, and so on. 
 
Key words:  Back injury, Workstation design, Human factor, Productivity and Anthropometry. 
 
1. INTRODUCTION:
The word ergonomics comes from the Greek ergo 
means work and nomos means law [1]. So 
Ergonomics means laws of work. Ergonomics is 
used to fit the job to the worker. In the USA, it is 
called human factors. Human factors focuses on 
human beings and their interaction with products, 
equipment, facilities, procedures, and environments 
used in work and every day living. The emphasis is 
on human beings and how the design of things 
influences people. Human factors, then, seeks to 
change the things people use and the environments 
in which they use these things to better match the 
capabilities, limitations, and needs of people. 
Human factors has two major objectives. The first 
is to enhance the effectiveness and efficiency with 
which work and other activities are carried out. 
Included here would be such things as increased 
convenience of use, reduced errors, and increased 
productivity. The second objective is to enhance 
certain desirable human values, including improved 
safety, reduced fatigue and stress, increased 
comfort, greater user acceptance, increased job 
satisfaction and improved quality of life. The 
approach of human factors is the systematic 
application of relevant information about human 
capabilities, limitations, characteristics, behavior, 
and motivation to the design of things and 
procedures people use and the environments in 
which they use them.  In many industries 
ergonomics is implemented primarily as a means of 
reducing high injury rates and high insurance 
premiums. In the USA, a worker’s compensation 
premiums often amount to 15% of the salary. This 
is because there are many back injuries due to 
materials handling and injuries to the joints in the 
arms, shoulders and neck due to poor work posture. 
The scope for the application of ergonomics in our 
working environment is tremendous. The correct 
matching of man, technology, task and organization 
to form a total entity capable of higher job 
performance is now an important function of 
management, and the ergonomic approach can go a 
long way to help meet this objective. 
  
Page 786
ISBN: 978-984-33-2140-4
  
1.1 Ergonomics aspects 
  Ergonomics has two distinct aspects: Firstly 
study, research, and experimentation, in which 
determine specific human traits and characteristics 
that need to know for engineering design; Secondly 
application and engineering, in which design tools, 
machines, shelter, environment, work tasks, and job 
procedures to fit and accommodate the human and 
equipment in the environment to assess the 
suitability of the designed human-machine system 
and to determine possible improvements [2]. 
 
1.2 Man- machine- environment 
interaction: 
At the workplace, ergonomics places equal 
emphasis upon greater system efficiency and 
improved health of the individual. Ergonomics 
must be involved in fitting the tool and machine to 
the worker by design, fitting the worker to the 
machine by selection and training, and the 
optimization of the ambient environment to suit the 
man or the adaptation of the man to tough 
environmental conditions. To fulfill the general aim 
of ergonomics in integrating man-machine and 
man-environment relations, the interaction between 
these elements must be optimized. This approach 
has to consider (1) the operator’s interaction with 
the tool, (2) the immediate workplace around him, 
and (3) the work environment in which he has to 
work. 
 
2. WORKPLACE AND 
ANTHROPOMETRY 
Backaches, neck aches and other muscular strains 
due to bad seating and incorrect working posture 
are common in industry, where many jobs require 
people to remain sitting or standing in a fixed 
posture for a long period of time. It is common to 
find in many industries and offices glaring 
examples of poor work design. Chairs, tables, 
workbenches, tools and machines are introduced 
without any consideration of their relationship to 
one another. Incorrect and awkward postures 
associated with either the level of working height or 
with the poor design of the machine could result in 
discomfort and fatigue. In addition, neglect of 
ethnic and anthropological differences through the 
unthinking importation of foreign technology 
developed in a different cultural and social 
framework can have a generally negative effect.  
Workplace design and layout should conform to 
ergonomic principles, while both physical and 
physiological aspects of the working environment 
should be considered. The use of ergonomics is 
essential in such areas as working posture, tool 
design and workplace layout, together with 
environmental factors such as ventilation and 
lighting. Temperature and humidity should be kept 
at a comfortable level through the use of ventilation 
systems. The noise level should be low enough not 
to cause interference with communication and 
distraction from work. Lighting has to be adequate 
and glare should be minimized. 
Work organization is an important factor to be 
considered for reducing musculo skeletal strain at 
the workplace. Measures such as reducing the work 
rate in paced operations, reducing shift length, and 
the provision of extra rest breaks have proved 
helpful in repetitive operations. Tasks consisting of 
lifting, pushing, or pulling objects without the 
assistance of mechanical devices are referred to as 
“manual material handling”. Manual material 
handling tasks carry a high risk of injury not only 
because of the interaction between the worker and 
the object itself but also because there is a potential 
for overloading the body’s supporting structure, the 
musculo- skeletal system. Lifting of heavy objects 
presents a high risk of over-exertion injuries and 
cumulative damage to the soft tissues around the 
spine. These injuries to the back constitute the 
largest single category of worker’s compensation 
claims in many developed countries, amounting to 
25% of all disability cases. 
A workstation may be defined as a place within the 
workplace where equipment or instrumentation is 
positioned in such a convenient way that users can 
perform their tasks properly [3, 4]. Workstation 
design deals with choosing and arranging 
equipment, machinery, tools, and accommodations 
for users so that workflow and organization are 
optimized. Workstation design is the object of 
several recent developments in ergonomics, 
particularly regarding increasing level of 
competition and technological development in 
modern enterprise environments among others. In 
the design of workstations, designers are often 
faced with the task of eliciting components to be 
included in the project Workstation components 
(WCs) may be divided into two major groups [5]: 
a) functional such as work seats, worktables, 
machinery, and accessories, and b) environmental, 
related to psychological, social, and climatic inputs 
that affect worker’s behavior. The best choice takes 
into consideration ergonomic criteria, such as 
anthropometric and biomechanical characteristics, 
and commercial criteria, such as warranty length 
and service level provided by manufacturers.  
 
2.1 Anthropometry in workstation design 
The basic philosophy of ergonomics is to design 
workstations that are comfortable, convenient and 
productive to work at. Ideally, workstations should 
be designed to fit both the body and the mind of 
workers. By the use anthropometric design 
principles it is possible for a variety of people to 
Page 787
  
find physical comfort at workstation.  On the other 
hand, by not taking into consideration these 
physical requirements, one may create bad work 
postures, which lead to fatigue, loss of productivity 
and sometimes injury. Anthropometry is not only a 
concern about appropriate working height, but also 
about how the operator can easily access controls 
and input devices. Typically the normal reach area 
(NRA) dimensions are presented as 5th, 50th and 
95th percentile curves. In theory, using the 5th 
percentile curve results in a design within which the 
majority (95 %) of operators could comfortably 
perform the intended tasks. 
 
3. ERGONOMICS AND THE 
PREVENTION OF MUSCULO-
SKELETAL STRAIN 
Musculo - skeletal problems have been reported as 
occurring in a wide range of industries. The 
National Institute for Occupational Safety and 
Health (NIOSH) in the USA reported that 15-20% 
of workers employed in construction, food 
preparation, the electronic industry, clothing and 
bag manufacturing, and clerical work are at risk for 
cumulative trauma disorders.  Cumulative musculo 
skeletal problems are not the result of single events; 
they stem from (a) the repeated performance of 
certain tasks (b) bad working posture (c) 
application of force, and (d) inadequate rest. There 
are two major factors that can affect the health and 
performance of industrial operators through their 
musculo-skeletal system: static load and awkward 
posture.  
(1) static muscle load: when tools or equipment are 
used in situations where the arms have to be held 
for extended periods, such as during grinding 
operations, muscle of the shoulders, arms and hand 
may be loaded statically. This loading can result in 
fatigue and reduced capacity to continue the work, 
and it may produce soreness in the muscles. The 
primary strategy to prevent musculo-skeletal 
trauma is the use of ergonomic principles to modify 
hand tools and to improve workstation design and 
work practices. Workload should be distributed 
between hands and feet wherever feasible. The 
following ergonomic rules are suggested for 
repetitive use: The tool should be designed for 
operation with a straight wrist-bend the tool handle, 
not the wrist. Use power tools whenever feasible. 
Make tool light- heavy tools should be suspended 
or otherwise counterbalanced. Handle surfaces 
should be so shaped as to contact the largest 
possible surface of the inner hand and fingers, 
distributing the forces evenly and not creating 
power points. 
(2) Awkward posture: the necessity to adopt one 
posture, or a very limited range of awkward work 
positions, may result in wrist and hand fatigue, and 
difficulty in sustaining a proper work position. The 
primary strategy to prevent cumulative trauma 
disorders is the use of ergonomic principles (a) to 
modify hand tools, (b) to improve workstation 
design, and (c) to improve work practices.  
 
3.1 Back injuries at work 
Back pain is one of the most common work-related 
injuries and is often caused by ordinary work 
activities such as sitting in an office chair or heavy 
lifting. Applying ergonomic principles - the study 
of the workplace as it relates to the worker - can 
help prevent work-related back pain and back 
injury and help maintain a healthy back. The goal 
of an ergonomics program in industry is to adapt 
the workplace to a specific worker, dependent on 
the job description, required tasks and physical 
make up of the employee performing those tasks. 
Two types of situations typically cause people to 
begin having back pain or to sustain a back injury 
while on the job: (a) Non-accidental injury, where 
pain arises as a result of normal activities and 
requirements of the task. Poor body mechanics 
(such as slouching in an office chair), prolonged 
activity, repetitive motions, and fatigue are major 
contributors to these injuries. This may occur from 
sitting in an office chair or standing for too long in 
one position. (b) Accidental injury results when an 
unexpected event triggers injury during the task. A 
load that slips or shifts as it is being lifted, and a 
slip and fall or hitting one’s head on a cabinet door 
are typical examples. These accidents can jolt the 
neck, back and other joints with resulting muscle 
strain or tearing of soft tissue in the back  
 
3.2 Back injury from physically demanding 
jobs 
Occupations that are physically demanding and 
require repetitive lifting (such as in nursing or 
heavy industry) are at greatest risk for both non-
accidental and accidental back injury. For example, 
many healthcare workers have back problems 
because patients are of different stature and weight 
with varying needs. Often, the patients need help 
changing position, rising from a chair and walking. 
Similarly, the physical effort needed on an accident 
or fire scene to release a trapped person or save a 
life is unpredictable. The same problems occur in 
the construction industry where consistencies of 
tasks are a challenge.  
 
3.3 Office chair back injuries 
People who sit most of the day, such as those who 
work at a computer while sitting in an office chair, 
is also at high risk for non-accidental back injury. 
Office ergonomics, or computer ergonomics, can 
help minimize the risk of repetitive injury, such as 
carpal tunnel syndrome, and the risks associated 
Page 788
  
with prolonged sitting in an office chair, such as 
neck strain, lower back pain and leg pain. 
 
4. PREVENT BACK INJURY 
There are certain basic ergonomic guidelines that 
may help an employee avoid back pain or back 
injury:  
 Develop a job description based on the 
forces present in a particular work 
environment; the time spent performing the 
task and the biomechanics (which define 
human motions and seated posture in an 
office chair) used in the task.  
 Use body posture as a tool that can be 
changed to meet the job demands with 
minimum stress on the muscles, ligaments, 
bones and joints. 
 Learn and use appropriate body mechanics 
to limit extra mechanical stress in completing 
the task.  
 Maintain fitness and flexibility and 
develop a reserve of strength. 
4.1 Identifying poor posture and risks 
Many potentially harmful situations that lead to 
back injury can be identified and avoided by 
following four basic rules of thumb:  
1. Prolonged static posture is the enemy. The 
healthy body can only tolerate staying in one 
position for about 20 minutes. That is why 
sitting on an airplane, at a desk in an office 
chair, or at a movie theatre becomes 
uncomfortable after a short time. Standing in 
one place, such as standing on a concrete 
floor at an assembly line for extended periods 
of time tends to cause back pain. Holding the 
same position slowly diminishes elasticity in 
the soft tissues (muscles ligaments and 
tendons in the back). Then, stress builds up 
and causes back discomfort and/or leg 
discomfort. 
The solution is simple. Whether you're sitting 
in an office chair or standing in a line, change 
positions frequently. Just move. Stand or sit, 
stretch, take a short walk. After returning to 
the standing or sitting posture, use an alternate 
posture for just a few moments and some of 
the tissue elasticity needed to protect the 
joints will return. 
2. Frequent or repetitive stretching to the end 
range of motion or awkward, angled postures 
can bind the joints. Unlike jobs that require 
long-term seating in an office chair, jobs that 
require frequent repetitive motion can cause 
great discomfort. Such jobs involve lifting 
from the floor, lifting overhead, moving bulky 
loads, or using rotational force or twisting 
while handling material and which signal 
back injuries might be on the way. 
3. Heavy loads offer greater risk. If the job 
requires moving heavy or bulky objects, it is 
important to have the proper tools or get help. 
4. Fatigue from sitting in an office chair for 
days, from work or from insomnia can make 
people move more awkwardly. If one is 
overtired or feels fatigued, it is advisable to 
avoid lifting heavy objects alone or quickly. 
If following these ergonomic rules of thumb is a 
frequent problem, the worker is at risk of sustaining 
or aggravating a back injury. 
 
4.2 Manual Material Handling to Prevent 
Back Injury 
Any job that involves heavy labor or manual 
material handling may be in a high-risk category. 
Manual material handling entails lifting, but also 
usually includes climbing, pushing, pulling and 
pivoting, all of which pose the risk of injury to the 
back. Lifting from the floor places strain on the 
structures in the lumbar spine. Ergonomic lifting 
techniques involve the use of a diagonal foot 
position, and getting as close to the load as 
possible. The load should be kept as close to the 
body as possible when standing up. 
It is easier to move loads that are waist high than 
ones that are on the floor. Stacking pallets to raise 
the height of the load is one ergonomic solution. A 
scissors lift will mechanically raise the load to a 
comfortable lifting level. Repetitive lifting from the 
floor is particularly risky, so try to get the material 
off the floor. Keep all loads as close to one’s center 
of gravity as possible. Carrying loads on one 
shoulder is safer for long and narrow material. This 
would include construction material or rolls of 
carpet. When lifting anything with a handle, place 
one hand on one knee to get additional leverage and 
use a diagonal foot position. Carrying two objects 
of the same weight will balance the load as long as 
the weight of the load is reasonable.  
When climbing with a load, “three-point” contact is 
important for safety. This means two hands and a 
foot or both feet and a hand must be in contact with 
the ladder or stairs at all times. If the load is bulky, 
get another person or a mechanical device to assist.  
Manual material handling may require pushing or 
pulling. Pushing is generally easier on the back than 
pulling. It is important to use both the arms and legs 
to provide the leverage to start the push. 
 A handle would ideally be waist high for 
ease of pushing  
 If it is necessary to pull, avoid twisting the 
lower back 
 Sometimes, for very large loads, turning 
around and using the back to push against 
Page 789
  
an object allows the legs to provide 
maximum force while protecting the low 
back from strain or twisting.  
The opposite of twisting is pivoting. Pivoting 
means moving the shoulders, hips and feet with the 
load in front at all times. The lower back is not 
designed to torque or repetitive twisting. Whether 
using a shovel or moving material or products, 
always avoid twisting the back. Practicing these 
techniques, both at work and at home, will go a 
long way to help prevent back injury and protect 
the structures in the low back. 
 
IMPLENTATION: This ergonomics 
approaches has been implemented in a local 
Ceramic factory and found that their employee 
turnover has been reduced to 20 percent and 
productivity has been increased to 10 percent. 
Although the company has to spend some money 
for the implementation of the ergonomics approach 
but this cost is very small compared to their benefit. 
 
 
CONCLUSION: 
Occupational ergonomics is a part of industrial 
medicine, and is essentially applied to reduce work 
injuries and discomfort. The discipline deals with 
the body size of the workers, strength and stress 
while at work. Recent studies have suggested that 
many of the occupational diseases are connected to 
poor design of tools, machines and workplace. To 
prevent unnecessary error and overt and cumulative 
injuries, ergonomics has an essential role to play in 
increasing work efficiency and productivity by 
making the tool or machine fit the users and the 
worker’s capability. 
 
 
REFERENCES: 
[1] Helander, Martin. A Guide to the Ergonomics 
of Manufacturing. 
[2]. Kroemer, K. (1994). Egonomics: How to 
Design for Ease and Efficiency. Englewood Cliffs, 
NJ: Prentice Hall 
[3] Eklund, J. (1997). Ergonomics, quality and 
continuous improvement— conceptual and 
empirical relationships in an industrial context, 
Ergonomics, Vol. 40, 982–1001 
[4] Bunning, T. (1998). Designing ergonomically 
sound assembly workstations, Occupational 
Hazards, Vol. 60, No. 8, 63–65 
[5] Bullinger, H. J. (1986). Systematische 
montageplanung, Hanser, Munich (in German) 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Page 790
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
* Corresponding Author: T.H. Mahdi,  
E-mail: tanjheel.m@gmail.com 
 
Experimental Analysis on the Heat Transfer Performance of an 
Ammonia-charged Pulsating Heat Pipe 
 
 
T. H. Mahdi, S. Ahmed, M. A. Y. Khan, M. M. Razzaque and C. M. Feroz 
Department of Mechanical Engineering  
Bangladesh University of Engineering and Technology 
Dhaka, Bangladesh 
 
 
An experimental analysis on the heat transfer performance of an ammonia-charged pulsating heat pipe 
(PHP) system is presented here. The experimental apparatus consists of a 8.382m long 3mm inner diameter 
closed loop aluminium pipe meandering back and forth into an electrically heated block of aluminium. The 
other end of the PHPs is cooled with air by natural convection. Heat transfer characteristics of PHPs are 
determined experimentally, based on the principle of phase change of the working fluid. Response curves in 
terms of temperature and heat transfer rate are obtained for different inclinations and liquid charge fill ratios. 
The experiment is conducted at constant heat input. The overall heat transfer coefficient of the system is 
determined to show the heat removing capability of the PHPs. The results show that, the performance of the 
heat pipe varies substantially for different inclinations and different liquid charge fill ratios. 
 
Key words: Pulsating heat pipes, heat transfer coefficient, heat transfer rate. 
 
1. INTRODUCTION 
 
A heat pipe is a heat transfer device that employs 
both conduction and phase transition to efficiently 
manage the transfer of heat between two solid 
surfaces. It generally uses the gravitational force as 
the driving force for the flow of the working fluid. 
Pulsating Heat Pipe (PHP) is a special kind of heat 
pipe where slug-plug motion of the working fluid 
plays the most important role not the gravitational 
force. It is considered as being a potentially useful 
option in the thermal management and control of 
electrical and electronic devices [1]. Mainly, PHPs 
consist of a capillary tube meandered in several 
curves to form parallel passages. The vapor plugs 
generated by the evaporation of the working fluid 
push the liquid slugs toward the condensation 
section and this motion causes flow pulsations that 
guide the operation of the device [2]. There are 
several applications of PHPs, from electronics and 
structural thermal control to microgravity thermal 
control. Due to simple construction, light weight 
and low cost, PHPs have gained attention to be 
used in space radiators, in order to give a more 
isothermal characteristic for this component. 
Integrating such a device is not a big problem and it 
could be easily used in many other applications. 
 
A PHP has no moving parts, no wick structure and 
its construction is very simple. It possesses a 
relatively long but small diameter pipe meandering 
in a serpentine fashion between a heat source and a 
heat sink. The pipe is sealed, evacuated and charged 
with a working fluid [3]. Considering the sections 
of a PHP, it consists of evaporation and 
condensation sections and an optional adiabatic 
section in-between. Like in other two-phase passive 
thermal control devices, heat is acquired from the 
source through the evaporation section and is 
transferred to the working fluid undergoing slug-
plug pumping action. The fluid then flows through 
the adiabatic section towards the condensation 
section. Provided the diameter is small enough the 
fluid forms a system of discrete liquid plugs and 
vapor bubbles that move in a seemingly random 
fashion back and forth between the heat source and 
the heat sink. There are two types of PHPs, one is 
closed loop and other is open loop. In the open loop 
configuration, one end of the tube is pinched off 
and welded, while the other end may have a service 
valve for evacuation and charging. On the contrary, 
the closed loop configuration has both ends 
connected and the fluid is allowed to circulate. 
Figure 1 shows a typical arrangement of a closed 
loop PHP. The PHP operation has some unique 
characteristics and a very interesting thermal 
behavior. One peculiarity of PHP operation is that it 
exhibits thermo-hydrodynamic instabilities related 
to the plug-slug dynamics. The vapor plugs form 
and collapse in such a chaotic fashion that is 
Page 791
ISBN: 978-984-33-2140-4
  
difficult to model. During its operation, metastable 
conditions of the working fluid (at both liquid and 
vapor phases) are present [4-6]. The plug-slug flow 
is directly dependent on the thermal power 
delivered to the evaporation section, tilt angle and 
amount of non-condensable gases [7]. 
 
 
Fig. 1: Working principle of a closed loop PHP. 
 
This paper presents the experimentally found 
thermal characteristics of an aluminum made 
pulsating heat pipe charged with ammonia. The 
experiments were done for different fill ratio of the 
working fluid (0.4, 0.6, and 0.8) and for different 
angular setting of the setup. The condenser section 
was cooled naturally by air and the evaporator 
section was heated electrically. Such results will be 
useful as ammonia is a known efficient heat 
transfer fluid and not much published results of its 
usage in a PHP are available. Aluminum was 
selected as heat pipe material because of its high 
heat transfers coefficient and flexibility to be 
meandered. 
 
 
2. HEAT TRANSFER THEORY 
 
The thermal circuit of the PHP is shown in figure 2. 
The heat transfer rate as well as the heat transfer 
coefficient between the working fluid (ammonia) 
and the inside wall of the PHP will vary as a 
function of position and time. At times there will be 
liquid, at other times vapor and yet at other times 
some two-phase combination of liquid and vapor in 
the same position. However, it is imagined that 
there is some average characteristic of heat transfer 
which is the same for the evaporator, the condenser 
and the rest portion of the PHP. Considering hei= 
hci= hPHP, heat transfer coefficient can be defined by 
equation 1. 
 
   (1) 
Where, 
Aei = Area of evaporating section of PHP = πdiLe  
Aci = Area of condensing section of PHP = πdiLc 
And, QPHP is the heat transfer rate of the pulsating 
heat pipe which can be calculated by equation 2. 
 
 (2) 
 
elec  =electric energy input =  
Block  =Heat absorbed by the block at unit time 
ea  =Heat loss from the evaporator  
w =Heat transferred though the wall. 
 
The heat transfer rate will depend on a number of 
independent variables; heat flux, liquid charge fill 
ratio, inclination angle and working fluid 
temperature as well as the liquid-vapor two-phase 
flow pattern. 
  
 
Fig. 2: Thermal circuit of the setup. 
 
3. EXPERIMENTAL SETUP 
 
To study the thermal characteristics of ammonia 
charged pulsating heat pipe, a setup was designed 
and fabricated. The experimental setup consists of 
an aluminum pipe, an aluminum block, 
thermocouples, selector switches, a pressure gauge 
and a wooden frame. 
 
The aluminum pipe with outer diameter 4mm and 
inner diameter 3mm was bent and supplied with 
two charge/discharge valves to form a closed-loop. 
One end of the closed-loop is embedded in 
matching grooves in an aluminum block 
(350x210x35 mm3). To ensure good thermal 
conduction between the block and the pipe, the 
grooves were cut with precision milling machine. 
The block is supplied with a groove in which an 
electric heating wire insulated with ceramic beads 
is fixed. The condenser section was cooled with air 
by natural convection. The aluminum pipe and the 
block in evaporator and adiabatic sections are 
completely insulated with 20.0 mm thick foam 
rubber. The setup is mounted on a wooden stand in 
such a way that it can be tilted at any angle desired. 
The temperature of the block and the PHP is 
Page 792
  
measured by thermocouples; 7 in evaporator 
section, 2 in adiabatic section and 5 in condenser 
section (Fig. 3). 
 
 
Fig. 3: Schematic diagram of the heat pipe system.  
 
The important dimensions of the PHP set-up are 
given in table 1. 
 
Table 1: Dimensions of the set-up 
Total Length of pipe LPHP 8.382m 
Evaporator Length Le 2.496m 
Condenser Length Lc 4.346m 
Pipe Diameter (inner) di 0.003m 
Pipe Diameter (outer) do 0.004m 
Radius of each turn R 0.013m 
Length of block L 0.35  m 
Width of block  W 0.21  m 
Thickness of block B 0.035m 
Mass of block m 7.5   kg 
 
4. TEST PROCEDURE 
 
The PHP set-up is charged with a known volume of 
ammonia. After charging, the PHP is sealed and 
Alternating Current (AC) is supplied to the 
nichrome wire heater via a variac. The heat input is 
kept constant by providing a constant voltage by 
the variac. Wall temperatures of the PHP are 
recorded at an interval of 10 to 20 minutes for each 
heat input until steady values are attained. The 
entire procedure is repeated for different tilt angles 
of the set-up. Then the working fluid is discharged. 
 
The procedure is repeated by charging the PHP at 
other fill ratio.  
5. RESULTS & DISCUSSION 
 
As heat load is applied to the evaporator section, 
the temperature of the evaporator rises and results 
in vaporization of the working fluid. This 
vaporization of the working fluid absorbs heat from 
the evaporator section. From equation 2, we get, 
 
 (2) 
 
The heating value i.e. the electric energy input is 
determined from the voltage indicated by the variac 
and the resistance of the heating wire. The heat loss 
to the environment from the evaporator block Qea is 
determined by assuming a thermal circuit 
consisting of conduction from aluminum block to 
glass wool and then from glass wool to air and 
overall heat transfer coefficient for this circuit is 
3.27 Wm-1K-1.  
 
 
   (3) 
 
Heat absorbed by the block per unit time is 
calculated by equation 4, where the weight of 
aluminum block is 7.5 kg and the heat capacity of 
aluminum is 900J/kg-K.  
 
 
    (4) 
 
 
The heat transferred though the wall of the PHP 
between the heating and cooling blocks was not 
experimentally determined. However, it is small 
and is calculated using simple theory as, 
 
 
    
    
    =0.0687     (5) 
 
In this study, the heating value was kept same 
throughout the experiments; the variables were the 
fill ratio and inclination angle. These parameters 
have no direct relation with the performance which 
can be observed from the equations. So, 
experiments are obvious to find out the influence of 
these parameters on the performance of ammonia 
charged pulsating heat pipe. 
 
The temperature of different sections was measured 
until steady state was obtained. Some sample 
temperature profiles with time are shown in Fig. 4, 
5 and 6. In all these settings, heat source was at 
Page 793
  
lower position or leveled with the heat sink. From 
graphs it can be observed that for 0.4 fill ratio time 
needed to reach steady state is about 180 to 200 
minutes (Fig. 4). For 0.6 fill ratio time required is 
little longer, about 200 to 230 minutes (Fig. 5). But 
for 0.8 fill ratio, it is even longer, more than 250 
minutes (Fig. 6). For 0.4 and 0.6 fill ratio, the 
temperature profiles are almost identical for all 
angles. For 0.8 fill ratio when the setup is 
horizontal, the difference between evaporator and 
condenser temperatures is high and the condenser 
temperature stays almost constantly close to the 
atmospheric temperature (Fig. 6). 
 
Fig. 4: Temperature vs. time for 0.4 fill ratio and 
vertical setup.  
 
Fig. 5: Temperature vs. time for 0.6 fill ratio and 
setup at angle 45˚ with vertical. 
 
Fig. 6: Temperature vs. time for 0.8 fill ratio and 
setup at angle 90˚ with vertical. 
 
Fig. 7: Temperature vs. time for 0.8 fill ratio and 
vertical setup.  
 
Fig. 8: Heat transfer coefficient vs. time for 
different fill ratio (0.4, 0.6 and 0.8) at vertical 
setup. 
 
Fig. 9: Heat transfer rate vs. time for different fill 
ratio (0.4, 0.6 and 0.8) at 45˚ from vertical setup. 
 
But for the same fill ratio when the setup is vertical 
the condenser temperature rises significantly closer 
to the evaporator temperature (Fig. 7).  
 
Figures 8 and 9 show the heat transfer rates and 
heat transfer coefficients, respectively, of the PHP 
using ammonia as working fluid. For the inclination 
angle 0˚ to 45˚ from vertical 0.8 fill ratio seems to 
be the best fill ratio. Because the heat transfer rates 
and heat transfer coefficients are high for 0.8 fill 
ratio almost from the beginning throughout the 
Page 794
  
experiments. Though the heat transfer rate for 0.6 
and 0.4 fill ratio approaches near to that of 0.8 fill 
ratio as steady state occurs, heat transfer coefficient 
of the system always show better result for 0.8 fill 
ratio. For any specific fill ratio heat transfer rate 
decreases as the setup angle is increased from 0˚ to 
90˚ (Fig. 10). For the 90˚ vertical setup the 
efficiency of the system decreases for all fill ratios, 
but especially for 0.8 fill ratio it becomes very 
inefficient and shows chaotic behavior (Fig. 11) 
 
The pressure is an important parameter for 
ammonia, as its pressure rises vigorously with 
temperature. The fill ratio affects the pressure 
significantly. For 0.4 fill ratio, the pressure remains 
lower than atmospheric pressure (Fig. 12) at the 
first hour of the experiments. It is because that at 
lower temperature for lower fill ratio there is not 
enough ammonia to be vaporized to take the 
pressure higher than atmospheric. So, some portion 
inside PHP remains vacuum. As the temperature 
 
Fig. 10: Heat transfer rate vs. time for 0.6 fill ratio 
at different angles (0˚, 45˚, 90˚) of setup. 
 
 
Fig. 11: Heat transfer coefficient vs. time for 0.8 
fill ratio at different angles (0˚, 45˚, 90˚) of 
setup. 
 
Fig. 12: Pressure vs. time for different fill ratio at 
angle 45˚ of setup. 
 
 
 
Fig. 13: Pressure vs. time for 0.4 fill ratio at 
different angles of setup. 
 
increases the pressure increases and finally reaches 
up to 6 to 7 psi. For 0.6 fill ratio the pressure stays 
increases up to 24 psi. Inclination angle seems to 
have no influence on the performance of PHP (Fig. 
13).  
 
6. CONCLUSION 
 
The following conclusions can be drawn from the 
experimental studies: 
 Tilt Angle and fill ratio play significant role 
on the performance of PHP. 
 
 The pressure of Ammonia-charged pulsating 
heat pipe increases vigorously with 
temperature. So sturdy and robust setup is to 
be ensured. 
 
 For tilt angles between 0˚ to 45˚ from the 
vertical, higher fill ratio (0.8) shows better 
performance. 
 
 For horizontal setup, lower fill ratio (0.4 or 
0.6) is better. 
Page 795
  
NOMENCLATURE 
 
A   area, m2 
d   diameter, m  
h   heat transfer coefficient, W/m2K  
L   length, m  
m   mass, kg  
Q heat transfer rate, W  
R   thermal resistance, °C/W  
T   temperature, °C  
t    time, s  
U overall heat transfer coefficient, W/m2K  
B   thickness, m 
Ө angle, degree  
 
SUBSCRIPT  
c   condenser, cold  
e   exit, environment, evaporator 
a ambient, adiabatic 
ea Evaporator to ambient 
 
REFERENCES  
 
1. Polášek, F. and Zelko, M. Thermal control of 
electronic components by heat pipes and 
thermosyphons; A historical overview. Proc. 
10th Int. Heat Pipe Conf., Stuttgart, Germany, 
21-25 September 1997. 
 
2. Zhang, Y., Faghri, A., “Heat Transfer in a 
Pulsating Heat pipe with an Open End”, 
International Journal of Heat and Mass 
Transfer, Vol. 45, 2002, pp. 755-764. 
 
3. R.T. Dobson and G. Graf, “Thermal 
Characterisation of an Ammonia-charged 
Pulsating Heat Pipe”, Int. Heat Pipe 
Symposium, 2003. 
 
4. Charoensawan, P., Khandekar, S., Groll, M., 
Terdtoon, P., “Closed Loop Pulsating Heat 
Pipes Part A: Parametric Experimental 
Investigations”, Applied Thermal Engineering, 
2003, Vol. 23, pp. 2009-2020.  
 
5.  Khandekar, S., Charoensawan, P., Groll, M., 
Terdtoon, P., “Closed Loop Pulsating Heat 
Pipes Part B: Visualization and Semi-
Empirical Modeling”, Applied Thermal 
Engineering, 2003, Vol. 23, pp. 2021-2033.  
 
6.  Khandekar, S., Dollinger, N., Groll, M., 
“Understanding Operational Regimes of 
Closed Loop Pulsating Heat Pipes: An 
Experimental Study” , 2003, Applied Thermal 
Engineering, Vol. 23, pp. 707-719. 
 
7. Qu, W., Ma, T., “Experimental Investigation 
on Flow and Heat Transfer of Pulsating Heat 
Pipes”, Proceedings of the 12th International 
Heat Pipe Conference, 2003, Moscow-
Kostroma-Moscow, 19-24 May, pp. 226-231 
 
 
 
 
 
 
 
Page 796
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
* Corresponding author: M. Iqbal 
E-mail address: iqbalm_ipe@yahoo.com 
1
FLEXIBLE WORKSTATION DESIGN 
M. Iqbal1 and Salma Akhter2 
1Department of Industrial and Production Engineering 
2Department of Chemical Engineering and Polymer Science 
Shahjalal University of Science & Technology, Sylhet-3114, Bangladesh 
 
ABSTRACT 
 
A workstation is a place a worker occupies when performing a job. The work station may be occupied all the 
time or it may be one of several places where work is done. Some examples of workstation are work stands 
or work tables for computer operator, worktable for machine operation, assembly or inspection, control table 
where operator controls. A well designed workstation is important for preventing diseases related to poor 
working conditions, as well as for ensuring that work is productive. Every workstation should be designed 
with both the persons working and the task in mind so that work can be performed comfortably, smoothly 
and efficiently. Ergonomics is a multi-disciplinary science comprising subjects like anatomy, physiology, 
psychology, sociology, physics, engineering and medicine. The application of all these science is necessary 
in order to identify and optimize all the factors which may affect a person in his working environment. The 
modern science of ergonomics is concerned with relationships between man, machines and the environment 
which has created, and serves to make man-machine systems more efficient and safer. A poor environment 
can lead to many social problems. Up to the present, most ergonomists have been concerned more with 
industrial situations than with the office. Extended work with computers can lead to muscular fatigue and 
discomfort, usually in the back, arms, shoulders and neck. As well, if the computer is used for prolonged 
periods in awkward postures, there is a risk of musculoskeletal injury (MSI). This risk increases as the 
intensity of computer work increases recently there has been a significant increase in the number of injuries 
due to over–exertion and repetitive strain. In this paper an attempt has been made to give deep insight of the 
office environment ergonomics and workstation design applicable to flexible office work. The paper gives 
the readers a broad overview of the different aspects of Ergonomics issues applicable to office work and 
health and safety of working persons relating to work performed using a computer as a workstation. 
 
    Key words: Office, environment, workstation, human and design. 
 
1. INTRODUCTION 
 
Ergonomics can be defined as the application of 
knowledge of human’s characteristics to the 
design of systems. Many companies have 
contested the established view of office design and 
office work since the beginning of the 1990’s. 
Most of the offices nowadays are based on the 
concept of non-territorial or free address offices in 
which a given desk, office or workstation is 
intended to be used by different people at different 
times. It is important that the management has a 
clear understanding that when transforming the 
office to support flexible work practices the 
primary focus must be on people’s needs and 
behavior rather than on actual interior design. 
Based on experience from research performed in 
the United States [1] and Sweden [2], some critical 
factors for success of the office design process 
have been identified. These include: A clear 
identification of the project owner, projects that 
are productivity driven and not cost driven, 
identification and realization of benefits for the 
office staff, staff involvement in the process, all 
aspects of the project considered as a whole 
including the available space, interior design, 
information technology, organization, and 
working practices, good interior design and 
openness and flexibility to meet future 
requirements. 
 
To succeed with an office design concept based on 
flexibility and openness requires a new and 
different way of looking at offices. The office 
must be regarded more as a tool, like any 
computer or telephone system, with the main 
purpose of supporting the business tasks. The 
organization of computer-based tasks has proven 
to have an essential impact on the comfort of the 
user. The environmental factors in the office 
Page 797
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
 environment also play an important role in 
ensuring comfort and efficiency in task 
performance. Reflections in video display terminal 
(VDT) screens, high indoor temperature, and 
disturbing noise levels are factors that could occur 
in cases of bad office planning. The negative 
impact of those factors must not be overlooked. 
Even though the computer hardware is designed 
according to the latest ergonomic findings, 
extensive keyboard input work could still cause 
muscular problem such as repetitive strain injury 
(RSI). Flexibility in work practices and work 
positions is essential to minimize health and safety 
risks. 
 
The problem of more efficiency and fatigue also 
exist in the workstations of office i.e. the working 
environment of offices. If the workstations are 
properly designed, the persons working should be 
able to maintain a correct and comfortable body 
posture. Uncomfortable work posture can cause a 
variety of problems, such as back injury, 
circulatory problems in the legs. The main cause 
of these problems are poorly designed seating, 
standing for long periods, reaching too far, 
inadequate lighting forcing the workers to get too 
close to the work. 
This paper presents a review of the effects of 
business process analysis approach to ergonomic 
aspects of office design and workstation design 
tools. 
Extended work with computers can lead to 
muscular fatigue and discomfort, usually in the 
back, arms, shoulders and neck. As well, if the 
computer is used for prolonged periods in 
awkward postures, there is a risk of 
musculoskeletal injury (MSI). This risk increases 
as the intensity of computer work increases. 
Frequently, the source of muscular fatigue and 
discomfort is the operator’s posture while working 
at the terminal, and this posture is due in turn to 
the layout of the computer workstation and the 
furniture provided. The specific tasks and the 
intensity of the work are also factors. Computer 
operators may experience visual as well as 
muscular fatigue and discomfort. Symptoms 
include eyestrain, burning eyes, blurred vision and 
headaches. The layout of the computer 
workstation can increase the visual demands on 
operators, as can lighting levels and glare. 
 
2. FLEXIBLE OFFICE AND WORK 
PRACTICES 
 
One of the most important factors when carrying 
out a flexible office designs or redesign project is 
the awareness that it is a project of changes that 
primarily affects staff and organization and only 
secondarily a building project. One cannot easily 
transfer an existing office design from one 
organization to another. Instead every office must 
be created by and for its own staff organization. 
The business process analysis is therefore a 
fundamental element in the design of the flexible 
office. This emphasizes the need for a master plan 
– an office design process (ODP). This process 
could be described in several steps [3]. The staff 
members working in flexible and traditional office 
designs were asked to report the sensation of body 
strain. The “standard” report for people working in 
an office environment concerning the presence of 
body strain in neck and shoulders between 30 to 
35 percent. In this case, the reported level in the 
traditional office design meets the expected value. 
The reported value from the flexible office design 
is much lower. There are no reports concerning 
strain in elbow, forearms, wrist, hands, or fingers 
from the personnel working in the flexible office 
design. One explanation is the increased flexibility 
in working positions that the furniture and work 
organization offer in this type of office. A flexible 
office design offers more than just a nice interior. 
The changes in work organization/work behavior 
made possible by portable phones, client server 
computing, open plan office design, group work 
and telecommuting have made higher efficiency 
and better quality in office work possible [4]. 
Companies that have adopted this working style 
can present figures and facts that clearly 
demonstrate the advantages [5]. These include: 
More satisfied employees, decrease in sick leave 
time, decrease in staff turnover, up to 47 percent 
increase in working time availability, increase of 
net income (33 percent) and less costs for office 
space (50 percent). Five major activities, mainly 
standout for bringing out the significant 
organization changes that result in such numbers: 
A strong management encouraged staff 
involvement in the change process, a clear setting 
of objectives, a business idea in line with the 
change process, taking advantage of the 
organizational force that comes with the 
enthusiastic people, a change in management style 
from control to support and coaching. There are 
some prerequisites for this transformation, with 
modern information technology playing a vital 
part. Central storage of all common information, 
digital communication between staff members, 
strict routines for computer usage and ways of 
cooperation is factors that must be considered. 
Page 798
  
 
Fig: 1 Ideal workstation [20] 
 
3. WORKSTATION DESIGN 
 
There is no such thing as an “ergonomic working 
position”. Workplaces and work organizations that 
support flexibility also support good ergonomics. 
The ability to alter one’s position by sitting, 
standing, walking, and even lying down in a 
working situation is healthier than sitting 
continuously with 90 degree angles in knees and 
hips. Tables that are adjustable to meet working 
height of both sitting and standing positions; 
telephone and computer systems accessible all 
over the office; and comfortable, lie-down chairs 
in quiet areas are examples of designs that support 
good ergonomics [6,7]. Instead of referring to 
measurements regarding width and depth of tables 
and other office furniture, the basis for furniture 
requirements in this paper is the user and the 
user’s task to perform.  
 
3.1 Working Surface 
 
Working surface will then be defined as the width 
a user needs to accomplish a certain task. The 
width requirement is based on working on the task 
working with VDT (Visual Display Terminals) 
using a keyboard and an input mouse. It is 
important to have space available for the 
mouse/input device on both sides of the keyboard. 
The depth of the work surface will then be based 
on the required viewing distance in relation to the 
screen size. For displays based on the CRT 
technique there is a relationship between screen 
size and the depth of the housing. There is also a 
relationship between character size and the size of 
the screen. In both cases this means that for a 
bigger screen a greater depth is required. 
Fig. 2: VDT Workstation [8]. 
 
Basic ergonomics principles for workstation 
design are as follows:  
Screen Height: The height between the floor and 
centre of screen. 
Table Height: The vertical distance between the 
floor and table. 
Viewing Angle: The center of the screen should 
be lower than the eye height, so as to obtain a 
viewing angle of about 25–35° below the 
horizontal. In particular, looking up with the head 
bent back is a common cause of strain and muscle 
fatigue in the neck. It prevent the muscle fatigue in 
the neck. 
Thigh Clearance: A person sitting at a desk has 
limited space for the keyboard and the table top. 
Thigh clearance is the free space between seat and 
table board. 
Angle of screen: The angle between the vertical 
line and screen of computer.  
Elbow angle: The elbow angle should be 70-90. 
This makes quite a difference in design. 
Seatback Angle: A seatback angle of greater than 
110 reduces the pressure on the spine. 
Footrest: A footrest can be helpful for short 
operators, so that they can support their feet. 
Experience from flexible office environments and 
flexible workstation shows that some types of 
furniture are more suited types than others to 
encourage and facilitate flexible work practices [9].  
Examples of such furniture follow- 
(i) Balanced Tables: The balanced table is very 
appropriate for use as a worktable, since it can 
easily be adjusted to different heights. 
To work well, balanced tables must be able to be 
adjusted; so that they balance the load placed on 
them. The desk surface can be designed so that 
Page 799
 size and shape will specially accommodated the 
equipment and tasks to be performed. 
(ii) Chairs: To meet the requirements of 
flexibility, one chair per person is not enough even 
though certain chair is fully adjustable regarding 
sitting height, width and so forth experience shows 
that people very seldom change the initial settings 
[10]. To offer each employee a set of different 
chairs that support differences in sitting style will 
contribute to increased health and safety. 
Chairs should have the following features: 
a. Seat height: Must adjust to allow the user to 
place the feet firmly on the floor or a supportive 
footrest; assuming an adjustable work surface 
height, an adjustment range of 380-520 mm (15 - 
20.5") will allow 90% of potential users to find a 
comfortable sitting height while wearing shoes. 
b. Seat pan depth: Must be such that the user can 
maintain contact with the backrest in the lumbar 
area and avoid increased pressure on the back of 
legs and behind the knees; seat pan depth should 
be less than 430 mm (17") and there should be 
space, about the width of a clenched fist, between 
the front of the seat pan and the back of the knees 
horizontal adjustment of the backrest is an 
excellent feature to permit changing the effective 
seat pan depth – a good range of seat pan depth is 
380-430 mm (15 - 17") – a backrest like this will 
permit all but the shortest 5% of users to have 
adequate back support while seated. 
c. Seat pan: Should have a "waterfall" or rounded 
front edge to minimize pressure on the back of the 
legs. 
d. Backrest: Should provide good contact and 
support for the lumbar region of the user's back; 
the backrest should be vertically adjustable the 
backrest should have a height of 380-540 mm 
(15"-21") and a width of 350-480 mm (14" -19") 
the backrest tilt angle may be fixed, adjustable or 
spring-tensioned; if fixed, an angle of 103 +/-1 
degrees is suitable; if adjustable, a range of 95-110 
degrees is usually sufficient; the force of a spring-
tensioned reclining backrest should be adjustable 
to suit the user's needs. 
e. Adjustable armrests: Adjustable in both the 
horizontal and vertical planes which can provide 
light arm support are recommended for moderate 
and intensive computer users - armrests should not 
impede access to the work station or arm 
movement. 
f. Five-pronged chair base with casters: For 
stability and easier mobility; the ability to swivel 
360 degrees and move the chair around improves 
access to work materials, eases sitting down and 
standing up and reduces twisting stresses on the 
spine; appropriate casters for the surface (hard 
casters for soft floors or soft casters for hard 
floors). 
g. Seat cushion: Should have minimal contouring 
to allow easy shifting of position and there should 
not be any local pressure points such as buttons or 
prominent seams. 
 
4. WORKSTATION SUPPORTING 
FURNITURE 
 
The rolling cabinet is appropriate to use when the 
work is characterized by flexibility and when the 
staff person does not have a fixed workstation. 
The surface area of the rolling cabinet is often 
used as an extension of existing table surfaces, 
which means that the “desk” height is controlled 
by the work height. This is naturally not good 
from an ergonomic point of view, and therefore 
the table surface of the cabinet should be 
introduced as an unloading area. 
 
A. Display 
 
The evolution of “office ergonomic” has been due 
largely to the rapid growth of information 
technology [11]. Factors concerning display 
ergonomics are related to the physical design of 
(VDT’s) as well as user interface design aspects of 
the software. The software should be based upon 
usability factor. One of the main factors that affect 
performance and comfort is the image quality of 
monochrome as well as multicolor displays. Good 
image quality is a multi-factorial issue, dependent 
on character design, phosphorus quality (for CRT-
based displays), and overall technical quality of 
the display. 
Flat panel technology will enhance the 
possibilities to arrange work places using proper 
ergonomics. The easier positioning of the flat 
display gives more flexibility both regarding the 
use of the furniture and for the user. 
The guidelines for use display unit in office 
environment: 
•The work surface should be chosen to 
complement the task being performed and be able 
to accommodate the tools and space required. 
•Moderate and intensive computer users should sit 
directly in front of the monitor and 
keyboard/mouse. 
•Lateral viewing boundaries should not exceed 30 
degrees either side of the body centre-line. 
•The mouse or pointing device should be located 
next to the keyboard (as close as possible and at 
the same height) to minimize reach. 
•The keyboard and mouse (or other pointing 
device) should be located at a height that allows 
the user's forearms, wrists and hands to be parallel 
to the floor (the surface of the keyboard should 
generally be lower than a typical writing surface in 
order to permit the best posture).  
Page 800
  
•Under desk adjustable height keyboard/mouse 
arms should be used to accommodate this need 
when the work surface height cannot be altered to 
accommodate this posture. 
•An adjustment range of 600-730 mm (24-29") 
will allow most people to adopt a suitable arm 
posture for repetitive keying; if a single fixed 
surface is used, a work surface height of 720 mm 
(~28") is commonly recommended. 
•Work surface height should provide adequate 
clearance for the operator's legs when seated in his 
or her most comfortable sitting position. 
•Monitor viewing distance should be about arm's 
length away when seated comfortably in front of 
the keyboard. 
•The computer screen should be positioned such 
that the top of the screen is about eye level or 
slightly lower (0 to 60 degrees below eye level is 
usually suggested). 
•Individuals who wear bifocals and trifocals may 
need to place the monitor lower than this to 
maintain comfortable (neutral) neck posture. 
•Frequently used items should be stored close to 
the user but should only be on the work surface if 
they are in constant use. 
•Store heavy items close to minimize lifting, 
reaching, twisting or carrying. 
•The screen height should be easily adjustable to 
accommodate gender height differences and the 
operator’s personal preferences throughout the day. 
Further, the viewing height should allow the 
operator to view the monitor screen within an 
orthopedically correct “viewing cone” to minimize 
musculoskeletal stress disorders (MSD’s). 
 
B. Keyboard 
 
Keyboard layout, key functionality and design are 
all essential factors that contribute to user 
productivity and comfort. Other factors such as 
thickness of the work surface supporting keyboard 
and overall layout of the workstations have 
implications on the comfort of the users. Low-
profile keyboards with a proper tactile feedback 
are suitable for most users. However extensive 
keyboard work, (i.e. several hours per day) is not 
recommended due to the fact that even limited 
muscular stress could cause muscular problems if 
exaggerated. Keyboards should be placed at a 
height that allows the operator to operate the 
keyboard with the forearms level and hands 
sloping slightly downward. A negatively tilting 
keyboard, allowing the operator to “keep the 
wrinkles out of the top of the wrists” is ideal. Fore 
and aft positioning of the keyboard should be 
consistent with allowing the hands to move easily 
over the keyboard with forearms level and elbows 
at the sides, maintaining a 90 ° - 120 ° angle 
between upper and lower arms. 
 
       
 
Fig: 3 Keyboards [21] 
 
C. Portable Computers 
 
Since the keyboard and screen on a portable 
computer (also called a laptop computer) are 
attached, it is often difficult to position the 
computer to get a comfortable posture for both 
keyboarding and viewing. Either the keyboard is 
too high or the screen is too low. The importance 
of optimum posture increases as the duration and 
frequency of computer use increases. Awkward 
postures can be tolerated for short periods of time. 
Laptops are not ideal for extended periods of use; 
however, they are increasingly used in this manner. 
Laptop computers have several advantages for 
users in terms of being lightweight and highly 
portable, but these desirable design features 
present inherent ergonomic problems when 
moderate and intensive computer users use these 
devices extensively. Because the keyboard/pointer 
and the screen are attached, postural compromises 
are unavoidable. Short-term, infrequent use of 
laptops is not problematic but if a laptop is being 
used in one location for extended periods of time, 
then it is not the right tool for the job. If a laptop 
needs to be used in one location regularly for any 
length of time, a separate monitor or keyboard and 
mouse should be provided at that location. In 
addition, moderate and intensive laptop computer 
users need to be very aware of their keyboarding 
posture (avoid bending and resting wrists on the 
edge of the laptop, for example). Below are some 
good practices. For general use, place the laptop 
on a flat surface with the screen tilted back 110-
150°. If desk use is extended some additional 
equipment should be used. As the keyboard and 
screen are attached it makes it difficult to 
optimally position the computer for suitable typing 
and viewing conditions. Ideally, a docking station 
or port replicate with a separate monitor, keyboard 
and mouse should be used. However, another 
option is to use a separate keyboard and mouse, 
then raise the laptop such that the screen is in an 
optimal position for viewing to avoid excessive 
neck bend (viewing angle of not more than 15° 
down). Bifocal users should take extra care to 
position the screen to allow viewing without 
awkward head positions. Take short "micro-
breaks" frequently. Focus on a distant object for a 
few seconds. Avoid prolonged periods of use. 
Page 801
 Optimize viewing conditions. Maintain a 
comfortable viewing distance (in the range of 40-
74 cm). Font size can be adjusted to allow the 
laptop to be placed for both good viewing and a 
comfortable body position. Place laptop to 
minimize glare from lights and windows Adjust 
brightness and contrast to suit lighting conditions. 
 
D. Keep Screen Clean 
 
Have regular eye examinations and inform your 
eye care provider of your computer use. The 
Health and Safety Guide provided with the 
computer should be referenced. 
 
E. Mouse and Other Input Devices 
 
The WIMP-concept (Windows, Icon, Menus, and 
Pointing Device) is commonly used today. It is 
easier task to choose an object than to remember a 
certain action command- especially human 
computer communication tends to become more 
intense and time consuming. Ergonomic aspects of 
pointing devices (mouse, trackball, joystick, 
tablets) have been well studied. The most common 
input device, the mouse, could, in a bad workplace 
design, give the user muscular stress problems. 
This problem has been addressed in a number of 
technical studies as a substitute to using shortcut 
commands on the keyboard. Different input 
devices present different characteristics regarding 
speed, accuracy, and preference. The right 
approach is not to attempt to identify the best input 
device in general, but to classify input devices 
based on the task to be performed. Common 
activities are “choose objects, drag objects, change 
orientation of objects – rotate and data input.” 
 
           
 
Fig: 4 Mouse [22]. 
 
Classification can also based on “learn-ability, 
effectiveness, speed, accuracy, attitude, benefits 
versus cost (in terms of fatigue, stress, frustration, 
discomfort and flexibility).”The usage of input 
devices can cause muscular stress in the 
hand/arm/shoulder regions. These effects are the 
combined results of the design of the input device, 
workstation layout task, and individual 
applications. Input devices such as computer 
mouse, trackballs and digitizing tablets are used to 
perform a variety of types of computer work 
ranging from word processing to computer aided 
design (CAD). There are a number of types and 
styles of devices. For example, some mouse now 
has scroll buttons. Mouse settings can also be 
adjusted for left handed users and to change the 
speed and distance of mouse travel and clicking 
actions required. It is important that users and 
purchasers of computers are aware of the range of 
devices and settings available, to determine which 
are most appropriate for their application and use. 
Even with the appropriate device, poor positioning 
can lead to problems. Users may hold the arm they 
use to control the device in a fixed, raised or 
outstretched position. This results in static loading 
of the shoulder and in bent wrist postures that 
contribute to discomfort and risk of injury. A 
mouse or a tablet should be placed as close to the 
worker’s side as possible at a height that allows 
the upper arm to hang relaxed from the shoulder 
with a "neutral" wrist position, with the hand in 
line with forearm. This position causes the least 
physical stress. The mouse should be also placed 
so the cord and items on the desk do not limit 
movement. If a keyboard/mouse platform is used, 
take care that it allows the mouse to be placed as 
close to the keyboard as possible (at the same 
height and in the same plane), and that it provides 
a stable surface of sufficient size. At CAD and 
other workstations where work is done with one 
arm for long periods, the forearm should be 
supported by a desk surface to the side of the 
operator or by adjustable armrests on the desk or 
the chair. This support is necessary to reduce static 
loading. The mouse or other hand-held input 
device should not contribute to cramped hand 
postures. This may require consideration of 
different-sized devices for different hand sizes. 
The device should be shaped so as to minimize 
bent wrist postures, or, failing that, the forearm 
should be supported on a raised smooth surface to 
allow a comfortable wrist posture. The mouse 
buttons should be located so as to avoid awkward 
finger and hand postures. The activation force (the 
force needed to make a button click) should not be 
so great as to cause fatigue. But it should not be so 
little that buttons can be clicked inadvertently 
since users will then tend to hold their fingers up 
away from the buttons, causing static loading of 
the muscles. Users should be encouraged to hold 
the mouse in a relaxed way, not to grip it tightly, 
and to move it from the shoulder rather than just 
the wrist. This better distributes muscular demands 
and reduces wrist movements and static loading. 
Ergonomics studies [12] have also shown that 
anthropometric difference related to gender are 
factors relating to muscular stress. The conclusion 
is that it is not possible to choose “the right input 
device” without taking the context of use into 
consideration [13], [14].  
 
Page 802
 5. OFFICE ENVIRONMENT 
ERGONOMICS 
 
There is a continuous and dynamic interaction 
between people and their surroundings that 
produces physiological and psychological strain 
on the person. This can lead to discomfort, 
annoyance, subtle and direct affects on 
performance and productivity, affects on health 
and safety, and death. Discomfort in offices can be 
due to glare, noisy equipment, draughts, or smells. 
In the cold people experience frostbite and die 
from hypothermia. In the heat they collapse or die 
from heat stroke. People exposed to vibrating tools 
encompass damage to their hands. Performance 
can be dramatically affected by the loss of manual 
dexterity in the cold, noise interfering with speech 
communication or work time lost because the 
environment is unacceptable or distracting. 
Accidents can occur due to glare on displays, 
missed signals in a warm environment or 
disorientation due to exposure to extreme 
environment [15]. 
 
5.1. Office Lighting 
 
Office lighting should meet a number of 
requirements to provide high-quality illumination. 
Low-quality lighting is tiring both physically and 
mentally. Even though inadequate lighting in most 
cases does not make vision impossible, the signals 
from the eyes to the brain can result in 
interpretation problems. Unsuitable lighting can 
lead to difficulty in concentration as well as in 
poor working performance. In addition it can also 
cause muscular strain as a result of the worker 
being forced to sit or stand in awkward positions.  
Lighting in offices must ensure sufficient high 
levels of illumination in requested areas, such as 
reading areas and computer operation areas. There 
must be no distracting reflections within the 
normal field of view, and specific requirements in 
respect to luminance levels should be met. Beside 
visual conditions, energy efficiency and 
environmental implications must be considered 
[16]. Visual conditions to be considered are- 
Illumination, placement of accessories in relation 
to workstation, glare luminance and luminance 
distribution, contrast reduction, color rendering 
and color temperature, reflecting factors, 
flickering, installation and electric and magnetic 
fields. For energy efficiency, special high-
frequency operation lights, installed wattage and 
the total use of energy are of interest. Research 
work has shown that an installed wattage level of 
as low as < 10 W/m2 still can maintain good 
ergonomics light quality.  
Glare is caused by large differences in light levels 
within the visual field. The eyes try to adapt to 
these large differences and visual fatigue and 
discomfort may result. In addition, the computer 
operator may adopt a poor posture while trying to 
reduce the glare by changing his or her orientation 
to the screen. This may result in neck and back 
pain. There are three types of glare: direct, indirect 
and masking. Direct glare occurs when there are 
bright light sources directly in the operator’s field 
of view. Windows are often a source of direct 
glare. Indirect glare occurs when light from 
windows or overhead lighting is reflected off 
shiny surfaces in the field of view, such as 
terminal screens, desks and other office equipment. 
Light from sources directly overhead causes 
masking glare on the screen, partly obscuring what 
the operator is trying to focus on. Ways of 
reducing both direct and indirect glare include the 
use of light-absorbing blinds or curtains. Every 
workstation should have a task light. Because 
harsh light spots increase eye strain and fatigue, 
the lamp needs to have an antiglare screen that 
does not impede the lamp’s ability to deliver a 
broad area of uniform low glare light across the 
immediate work surface. The lamp should have an 
adjustable arm that permits both height and angle 
adjustments. Lamps can be purchased using 
halogen, fluorescent, or incandescent bulbs. In 
general, the halogen lamps allow the user to better 
focus the light’s energy on the work, but the light 
is harsh and generates more heat. The fluorescent 
lamp offers the greatest potential for providing the 
necessary light. Special considerations for the 
workstations in a new office are that the 
workstations (desks with monitors) can be pointed 
in different directions within the same area, and 
that they can also be placed at different heights. 
This influences the choice of light fixtures. It can 
often be difficult to shade ordinary fluorescent 
lights with lighting turned down to avoid direct 
glare from occurring at any angle. In this 
environment it is therefore appropriate to have 
well-shaped fittings, either turned down with a 
deep-lying light source or a fitting with 100 
percent upturned light. In a good light 
environment, a combination of these fitting types 
is recommended. It is also appropriate to use 
fixtures capable of high-frequency operation, so 
that light flickers do not arise. 
 
5.2 Sound Level 
 
Ambient sound levels should not be higher than 55 
decibels (dBA). Sounds from conversation 
between colleagues and telephone conversations 
are the largest cause of disturbances in this type of 
environment, it is important in both the cases to 
apply a certain amount of telephone discipline. 
Page 803
 Simultaneously, great efforts are made to create an 
interior design equipped with the prerequisites for 
a good sound environment. The recommended 
reverberation time for office space is 0.4 to 0.6 
seconds, and one method to manage this is to 
create many surfaces using sound absorbent 
material [8]. 
Examples of this are textiles on the walls and the 
ceiling, perforated slabs as an esthetic element in 
the office environment, plant arrangements, and so 
forth. It is especially important to have curtains in 
front of glass walls, since glass surfaces have low 
sound absorbency. The sound of steps is another 
source of disturbance, and one should consider 
using floor material with a muffling effect in the 
passage areas. Another method that has been tried 
is to use “white noise”, that is, barely detectable 
music that reduces the worker’s comprehension of 
what others on the premises are discussing. 
 
5.3 Climate 
 
Temperature and humidity should be within 
comfortable ranges. A relative humidity level 
between 40% and 60% is generally desirable for 
most workers in office environments. Under no 
circumstances should the temperature and 
humidity be allowed to vary by an amount greater 
than 20% over a one hour time period. A positive 
aspect that has emerged is that large air volumes in 
these types of premises create the environment for 
a good indoor climate. A necessity, however, is 
that all heat-producing devices such as printers 
and copying machines are placed in their own 
location, which should be well ventilated so that 
the heat from these does not have a negative effect 
on the overall climate. This is also advantageous 
in noise suppression, since these devices are often 
very loud. 
 
5.4 Office Layout 
 
The premises that make up the flexible office 
environment should not be planned so that they 
become too large when connected. Experience 
points to a group size of 15 to 18 employees per 
workstation, area of approximately 200 to 250 m2 
(2.150 to 2.700 ft2 ) as being appropriate [5]. 
Within an area of this size one can still feel certain 
closeness and have a good general overview. It 
must be emphasized that several factors affect 
floor space accessibility per workstation or 
individual. Different businesses have different 
requirements, and and other out-of-office activities 
affects this. An analysis of business processes 
should be the basis for the planning of floor space 
utilization, and therefore one generally cannot 
determine a specific number of square meters 
(feet) per person. The design of the workstation is 
especially vital in a flexible office, where the 
adjustment of furniture to suit multiple users must 
be accomplished in a simple way. For instance, 
adjusting table heights must be extremely easy to 
accomplish. 
 
5.5 Telephone Work 
 
Increasingly, workers are required to use a 
keyboard while on the telephone. This often 
results in awkward head, neck and back postures 
with the receiver cradled between the shoulder and 
head to leave both hands free. Workers required to 
use a computer while on the telephone for long 
periods tend to experience discomfort, particularly 
in the head and back. In such cases, headsets 
should be used. Hands-free phones are also an 
option, where the office space and task are 
appropriate. 
 
5.6 Personal 
 
The office environment should be comfortable to 
the person utilizing the office. By comfortable, we 
mean mentally as well as physically. Pictures, 
plants, knick-knacks, etc., all have an important 
role to play in a proper work environment. An 
office worker’s potential to obtain an ergonomic 
injury is affected by their attitude toward their job 
and their surroundings [17]. Pictures reflect light. 
Watering plants near electrical outlets or devices is 
unsafe. 
However, it is a good thing that needs to be 
managed with both individual and group safety as 
the ultimate arbitrator. Office workers should be 
encouraged to take rest / exercise / change of task 
breaks. A common recommendation is 2 to 3 
minutes off every 30 minutes. Keep in mind that 
sitting in a chair is a repetitive task. 
 
 
 
 
Fig: 5 Modern workstation designs [23]. 
 
Page 804
 6. STANDARDS AND GUIDELINES 
IN THE OFFICE ERGONOMICS 
DOMAIN 
 
Standardization plays an important role in the field 
of ergonomics, as it is an important channel to 
bring knowledge of ergonomics and human factors 
to industry. There is a difference between 
technical standards that must deal with a dynamic 
technical development and ergonomic standards 
that are based on human abilities and limitations, 
factors that are more constant over time. Among 
standards regarding the aspects of ergonomics in 
an office environment, ISO 9241 and ANSI/HFS 
100-1988 could be referred. Standards and 
guidelines are useful, but there are limitations. 
They are helpful in making designers and 
technicians aware of the ergonomic and human 
factors aspects of product design and in providing 
support in solving ergonomic requirements 
established in the process. While the workstations 
described above the recommended adjustable 
mounting hardware are designed to address the 
average range of workers, with some modification 
the suggested workstation designs can provide a 
satisfactory workspace environment for the 5% 
female to 95% male range of seated office workers. 
Addressing the average male to 95% male range 
of office workers who are typically 68.3” (173cm) 
to 72.8” (185cm) tall and who have 48.6” (123cm) 
to 52.1” (132cm) sitting eye heights [18]. 
Addressing the average Range of operator’s 
workstation design provides an optimum 
ergonomic computer work environment for a 
minimum of 50% and perhaps up to 60% of all 
workers in a typical office at an extremely low 
cost [19]. Design a sit/stand workstation for 
employees who require this type of work 
environment. Anthropometric Data can be used; to 
design a sit/stand workstation to address the 
average range of female to male operators requires 
a vertical adjustment range of 20” (508mm).  To 
address the 5% female to 95% range of operators 
requires a vertical adjustment rage of 27.8” 
(706mm). However, standards and guidelines are 
by nature relatively limited and general. This gives 
a wide range for interpretation, and designers must 
use their own judgment, based on previous 
experience, when addressing ergonomic principles 
in a given design task [19]. 
 
7. CONCLUSIONS 
 
Flexible office (i.e. offices where people, 
employees, and consultants work sporadically) 
and  flexible workstation (a place a worker 
occupies when performing a job) will increase in 
number from the year 2020 onwards. Mobility of 
the labor market, less rigid terms of employment, 
and work carried away from the office in different 
forms will create such demands for changed office 
design and changed working methods that the 
traditional office structure of today will no longer 
be able to compete. From an ergonomic point of 
view, this puts demands on development of new 
furnishing systems. The furniture produced in 
recent years and used in flexible office today is not 
sufficiently well developed for future needs, either 
in terms of function or quality. Future Systems 
illustrates a sit/stand workstation that can be 
designed as a free standing system or integrated 
into an office cubicle or other office or call center 
work environment. This system features a 20” 
(508 mm) vertical lift system which has the 
capacity to lift a work surface, monitor mount and 
keyboard mount designed as an integrated unit and 
can be dynamically adjusted to address the entire 
range of average sit/stand workers. Reductions in 
weight and size of computer display equipment, 
along with advances in lift technology will allow 
creation of optimized office computer work 
environments that are substantially lower in cost 
and easier to set up in the future. These advances 
will create a new era of office ergonomics that will 
provide significant health and cost benefits to 
computer users who work anywhere from homes, 
schools, and clinics to the largest of corporations 
(offices). The development of the flexible work 
and flexible workstation will be accentuated 
during the coming years and it is therefore of great 
importance that this line of development is 
allowed to take place based on ergonomic 
knowledge and principles. 
 
REFERENCES 
 
1. Becker, F., and F. Steele, Workplace by 
Design: Mapping the High-Performance 
Workscape, Jossey  Bass Publishers, san 
Francisco, (1994). 
2. Berns, T., L., Klussell, and T. Rosenblad, 
Utvardering av Framtidens, Kontor 
(Evaluation of “Office of the Future”),Nomos 
Management AB, Stockholm, (1997). 
3.  Berns, T., L. Klushell, and T. Rosenblad, 
AlternativeOffice Environments for Flexible 
working: A Project Handbook, Nomos 
Management AB, Stockholm, (1997). 
4. Duffy, F., A. Laing, and V. Crisp. The 
Responsible Workplace: The Redesign of 
Work and Offices, Butterworth Architecture, 
Oxford, (1993). 
5. Andersson, M., Work Where you Want: 
Experiences and Economical Consequences 
by Flexible Work Practices, Canon Svenska 
AB, Stockholm, (1997). 
Page 805
 6. http: //www.ergoweb.com 
7. Ontario, Computer Ergonomics: Workstation 
layout and Lighting, Health and Safety 
Guidelines, (2005). 
8. Martin Helander, ”A Guide to Ergonomics of                 
Manufacturing ”, First East-West Press 
Edition 1996. ISBN  81-85938-77-6 
9. Marcone, Luigi, Ergonomic Office Furniture 
Standard & Information Resource Guide 
Procedure S-116, Western Conneticut State 
Univ., (2001). 
10. Jaimes, A., Liu, Jianyi, "Sit Straight (and 
tellme what I did today): A Human Posture 
alarm and Activity Summarization System”. 
CARPE’05, November 11, 2005, 
Singapore,( 2005). 
11. Office ergonomic Standard: Ergonomic 
Requirements for Moderate and Intensive 
Computer Users, May 2000, University of 
Toronto, (2000). 
12. Karlqvist, L., Assessment of Physical work 
Load at Visual Display Unit Workstations: 
Ergonomic Applications and Gender Aspects, 
National Institute for Working Life, 
Stockholm, (1997). 
13. Smith, W.J., ISO and ANSI: Ergonomic 
Standard for Computer Products, Prentice 
Hall, (1996). 
14. Baber, C., Beyond the Desktop: Designing 
and Using Interaction Devices, Academic 
Press, (1997). 
15. Parsons, K.C., “Environmental ergonomics: a 
review of Principles, methods and models”, 
Applied   ergonomics, vol. 31, pp. 581-594, 
(2000). 
16. Anon., Office Lighting: Requirements for 
Good and energy- efficient Office Lighting, 
Swedish National Board for Industrial and 
Technical Development, Stockholm, (1994). 
17. http://www.ergonomicsinhealthcare.org 
18. Sweere, C.H., “Office Ergonomics in the Era 
of Flat Panel Monitors”, constant Force 
Technology, (2003). 
19. Mallick, Z. et al., “Ergonomic evaluation of 
data Materials Engineering, vol. 2, pp. 161-
172. 
20. http://www.indoarch.com 
21. http://www.davidnaylor.co.uk/microsoft-
keyboard-or-1.jpg 
22. http://www.tweaknews.net/reviews/logitech-
g7/img/conclude.jpg 
23. http://www.ehsokstate.edu/modules/ergo/stati
on.htm. 
Page 806
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Corresponding author: A.B.M. Abdul Malek  
Email:  abmmalek@gmail.com  
OPTIMIZATION OF SUPPLY CHAIN INVENTORY FROM 
CUSTOMER SERVICE LEVEL PERSPECTIVE 
 
A.B.M. Abdul Malek, Dr. M. Iqbal , Muhammad Abdus Samad 
 
Department of Industrial and Production Engineering 
Shahjalal University of Science and Technology (SUST), Sylhet, Bangladesh 
 
 
Dr. M. Ahsan Akhtar Hasin 
Professor 
Department of Industrial and Production Engineering 
Bangladesh University of Engineering and Technology (BUET), Dhaka-1000, Bangladesh 
 
This research aims to find out an optimal inventory policy for a multi echelon supply chain. Interactive 
multi-echelon inventory management model is a complex one that associates integration of the trading 
partners. This integration requires real time sharing of inventory related data so that replenishment policy 
can be set for all the echelons involved. This approach reduces the bullwhip effect along with minimize the 
total supply chain cost, through trade off between responsiveness and efficiency. Heuristics give a better 
result for this type of optimization problems. This paper tries to develop a generalized heuristics in order up 
to level for a DRC (Distributor, retailer and customer) network. A periodic review base stock policy is used 
in the development of the mathematical model. Heuristics applied on the inventory parameters for the 
generation of optimal solution sets. The set which meet target service level are selected as the optimal one 
and the associated cost for the set is tested against known one. 
 
Key words: Multi echelon inventory, bullwhip effect, optimal inventory, order up to level, base stock policy. 
 
1. INTRODUCTION 
The control and maintenance of inventory is a 
problem common to all organizations in any sector of 
the economy. The problems of inventory do not 
confine themselves to profit making institutions but 
likewise are encountered by social and nonprofit 
institutions. Inventories are common to farms, 
manufacturers, wholesalers, retailers, hospitals, 
churches, prisons, zoos, universities, and national, 
state, and local governments. Indeed, inventories are 
also relevant to the family unit in relation to food, 
clothing, medicines, toiletries, and so forth. 
1.1 Significance of the study 
Inventory is very important because it helps the 
company respond quickly to customer demand, 
which is an important element of competitive 
strategy. It also represents one of the largest 
controllable resources in many companies.  
Therefore, inventories of finished goods (that is, 
independent-demand inventories) of the correct 
items, within a reasonable distance of points of 
demand, play an important role in a company’s 
ability to compete in a market for standardized 
products. So we are going to conduct a thesis on 
inventory control of finished goods in a particular 
pharmaceutical industry with some objectives.  
 
2. LITERATURE REVIEW 
Inventory is a detailed list of those movable items 
which are necessary to manufacture a product and to 
maintain the equipment and machinery in good 
working order. The quantity and the value of every 
item is also mentioned in the list. [3] 
Inventory is the stock of any item or resource used in 
an organization. 
Inventory is actually money kept in the store room. 
2.1 The purpose of inventory  
In a just-in-time manufacturing environment, 
inventory is considered as waste. However, in 
environments where an organization suffers from 
poor cash flow or lacks strong control over (i) 
electronic information transfer among all departments 
and all significant suppliers, (ii) lead times, and (iii) 
quality of materials received, inventory plays 
important roles. Some of the more important reasons 
for obtaining and holding inventory are: [5]  
Page 807ISBN: 978-984-33-2140-4
  
• Predictability: In order to engage in capacity 
planning and production scheduling, we need to 
control how much raw material, parts, and 
subassemblies we process at a given time. Inventory 
buffers what we need from what we process. 
• Fluctuations in demand: A supply of inventory on 
hand is protection: we don’t always know how much 
we are likely to need at any given time, but we still 
need to satisfy customer or production demand on 
time. If we can see how customers are acting in the 
supply chain, surprises in fluctuation in demand are 
held to a minimum. 
• Unreliability of supply: Inventory protects us from 
unreliable suppliers or when an item is scarce and it 
is difficult to ensure a steady supply. Whenever 
possible unreliable suppliers should be rehabilitated 
through discussions or they should be replaced. 
Rehabilitation can be accomplished through master 
purchase orders with timed product releases, price or 
term penalties for nonperformance, better verbal and 
electronic communications between the parties, etc. 
This will result in a lowering of your on-hand 
inventory needs. 
• Price protection: Buying quantities of inventory at 
appropriate times helps avoid the impact of cost 
inflation. Note that contracting to assure a price does 
not require actually taking delivery at the time of 
purchase.  
• Quantity discounts: Often bulk discounts are 
available if we buy in large rather than in small 
quantities. 
• Lower ordering costs: If we buy a larger quantity 
of an item less frequently, the ordering costs are less 
than buying smaller quantities over and over 
again(The costs of holding the item for a longer 
period of time, however, will be greater). In order to 
hold down ordering costs and to lock in favorable 
pricing, many organizations issue blanket purchase 
orders coupled with periodic release and receiving 
dates of the SKUs called for. [5] 
2.2 Functions of inventories  
1. Separate different operations from one 
another and make them independent, so that 
each operation (starting from raw material to 
finished product) can be performed 
economically. 
2. Maintain smooth and efficient production 
flow. 
3. Purchase in desired quantities and thus 
nullify the effects of changes in prices or 
supply. 
4. Keeps a process continuously operating. 
5. Create motivational effect. A person 
tempted to purchase more if inventories are 
displayed in bulk.[3] 
 
2.3 Types of inventory  
 
Raw material inventories: 
They include raw materials and semi finished 
products supplied from another firm and which are 
raw items for the present industry. 
In-process inventories: 
They are semi-finished goods at various stages of 
manufacturing cycle. 
Finished inventories: 
They are finished goods lying in stock room and 
waiting dispatch. 
Indirect inventories: 
They include lubricants and other items like spare 
parts needed for proper operation, repair and 
maintenance during manufacturing cycle.  
 
2.4 Inventory cost   
Holding cost: 
This includes the cost for storages facilities, handling 
cost, insurance cost, breakage cost, depreciation cost, 
taxes and opportunity cost of capital. High holding 
costs tend to favor low inventory levels and frequent 
replenishment.  
Set up cost: 
To make each different product involves obtaining 
the necessary materials, arranging specific equipment 
setup, filling out the require papers, appropriately 
charging time and materials, and moving out the 
previous stock of material. 
If there were no costs or loss of time in changing 
from one product to another, many small lots would 
be produced. This would reduce inventory levels, 
with a resulting savings in cost.  
Ordering cost: 
This cost refers to the managerial and clerical costs to 
prepare the purchase or production order. Ordering 
cost include all the details such as counting items and 
calculating item quantities.  
Shortage cost: 
When the stock of an item is depleted, an order for 
that item must either wait until the stock is 
replenished or be canceled. There is a trade-off 
between the carrying stocks to satisfy the demand 
and the costs resulting from stock out. This balance is 
sometimes difficult to obtain, because it may not be 
possible to estimate lost profits, the effect of lost 
customers, or lateness penalties. Frequently, the 
assumed storages cost is little more than a guess, 
although it is possible to specify a range of such cost. 
[4] 
2.5 Inventory models  
Inventory model determines when and how much 
inventory to carry. 
Inventory model handles chiefly two decisions- 
1. How much to order at a time; 
2. When to order this quantity to minimize 
total cost; 
Simple inventory models assume no delivery delay 
and that demand is known. [3] 
Page 808
  
There are two general types of inventory systems for 
independent demand:  
- Fixed order quantity model (also called 
economic order quantity, EOQ, and Q 
model) 
- Fixed time period models(also referred to 
variously as the periodic system, periodic 
review system, fixed order interval system 
and P model) 
The basic distinction is that fixed order quantity 
models are “event triggered” and fixed time period 
models are “time triggered”.  
The choice of system influenced by  
- The fixed time period model has a large 
average inventory because it must also 
protect against stock out during the review 
period ,T; the fixed quantity model has no 
review period.  
- The fixed order quantity model favours 
more expensive items because average 
inventory is lower. 
- The fixed order quantity model is more 
appropriate for important items such as 
critical repair parts because there is closer 
monitoring and therefore quicker response 
to potential stockout.  
- The fixed order quantity model requires 
more time to maintain because every 
addition or withdrawal is logged. [4] 
2.6 Fixed-order quantity model with specific 
service level 
A fixed-order quantity system perpetually monitors 
the inventory level and places a new order when 
stock reaches some level, R. The danger of stockout 
in this model occurs only during the lead time, 
between the time an order is placed and the time it 
received.  
The amount of safety stock depends on the service 
level desired. The quantity to be ordered, Q, is 
calculated in the usual way considering the demand, 
shortage cost, ordering cost and so forth. A fixed 
order quantity model can be used to compute Q. The 
reorder point is then set to cover the expected 
demand during the lead time plus a safety stock 
determined by the desired service level. Thus the key 
difference between a fixed-order quantity model, 
where demand is known and one where demand is 
uncertain is in computing the reorder point. The order 
quantity is the same in both cases. The uncertainty 
element is taken into account in the safety stock. The 
reorder point is [4] 
                                            R= ࢊഥ L +  z σL  
z  = number of standard deviation for a specific 
service level.  
σL  = standard deviation of usage during lead time.  
z σL = safety stock. 
 
Fig 2.6: Fixed order quantity model [4] 
R = Reorder point in units, B = Base stock level, Q = 
Quantity to be ordered, L = Lead time. 
2.7 Fixed time period model with specified service 
level  
In a fixed-time period system, reorders are placed at 
the time of review (T), and the safety stock that must 
be reordered is  
  Safety stock = z ߪ(்ା௅) 
Fig shows a fixed time period system with a review 
cycle of T and a constant lead time of L. In this case, 
demand is randomly distributed about a mean ݀̅. 
 
Fig 2.7: Fixed time period inventory model. 
 
The quantity to order, q, is  
q = ࢊഥ (T+L) + z ߪ(்ା௅)– I 
Where,  
ࢊഥ (T+L)  = Avg. demand over the review period,  
 z ߪ(்ା௅)= Safety stock,  
 I = Inventory currently on hand (plus on order) 
T=  The number of days between reviews 
L=  Lead time in days (time between placing an 
order and receiving it) 
݀̅  =  Forecasted average daily demand 
z   =  Number of standard deviations for a 
specified service level 
ߪ(்ା௅) =Standard deviation of demand over the 
review and lead time  
 I=  Current inventory level (includes items on 
order) 
Note: the demand, lead time, review period, and so 
forth can be any time units such as days, weeks, or 
years so long as it is consistent throughout the 
equation.  
Page 809
 In this model, demand (  ) can be forecast and 
revised each review period if desired, or the yearly 
average may be used if appropriate. We assume that 
demand is normally distributed. 
The value of z can be obtained by solving the 
following equation for E(z) and reading the 
corresponding z value from table 1 appendix B: [4] 
 
    
Where, 
E(z) = Expected number units short from a 
normalized table where σ = 1 
P = Service level desired expressed as a fraction 
(e.g., satisfying 95% expressed as the fraction .95 of 
demand from items in stock) 
  = Demand during the review period where  is 
daily demand and T is the number of days = 
Standard deviation over the review period and lead 
time. [4] 
According to the nature of the selected case we are 
using fixed time period model with specified service 
level. Benefit is calculated by using single payment 
compound amount factor on capital involvement for 
inventory of finished goods. 
 
OBJECTIVES  
 
The study of inventory optimization in any supply 
chain is a must. The purpose of this paper is to find 
out an optimal ordering policy for a cost effective 
supply chain inventory system that will significantly 
minimize the total supply chain inventory cost with 
specific service level. Analytical techniques are used 
to obtain quantity of demand and safety stock at 
different stages.  
 
The objectives of the thesis are as follows: 
 To construct as echelon serial supply chain 
inventory model 
 To find the appropriate safety stock in for 
each echelon at target service level. 
 To find an appropriate order up to level with 
specific service level for each echelon. 
 To obtain an optimal total cost of inventory 
for a cost effective supply chain. 
 To verify the optimal order set against 
historical data.   
 
3. METHODOLOGY 
 
3.1. Model Construction  
 In our model, we consider one manufacturer, one 
distribution center and retailers shop of three 
categories (low volume retailers, medium volume 
retailers and high volume retailers). 
We assumed that manufacturer can provide infinite 
products to the distribution center without any delay. 
So we identity order up to level and safety stock 
during lead time for distribution center and retailers 
stage. The construction of model given below: 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 3.1  Three echelon supply chain network. 
 
3.2  Notations and Parameters 
di= Monthly forecasted demand of ith retailer 
L=replenishment Lead time in days 
n = desired average number of review intervals 
between consecutive replenishment. 
qi= quantity to be ordered for ith retailer. 
µ=average demand in a unit time interval 
= standard deviation of demand in a unit time interval 
CV= σ/ µ= Coefficient of variation of demand in a 
unit time interval 
P2= desired value of filled = service level 
Q= Size of a replenishment 
τ = a random variable representing time from when 
the inventory position hits reorder point 
until the next review instant. 
E(τ) =the mean value of τ 
Var (τ) = the variance of τ 
I= Current inventory level (includes items on order) 
s= Order up to level 
x = total demand in  τ+L 
x= the standard deviation of x 
K[ ]= safety factor 
C i= average cost per unit purchased 
H= h *C=Holding cost per year 
LVR= low volume retailer 
MVR= medium volume retailer 
HVR= high volume retailer 
For retailer stage: 
Reorder point at retailer = 
*σ 
Order up to level S= s  +       
 
Quantity to be demand at retailer’s stage,,qr = S-I      
Total OUL at retailer stage= OUL at LVR+ OUL at 
MVR + OUL at HVR. 
Manufa
cturer  
Distributi
on center 
Low 
volume 
retailer  
Medium 
volume 
retailer 
High 
volume 
retailer 
Page 810
 Annual cost of inventory = material cost + holding 
cost + ordering cost. 
 
 Total Cost of Supply Chain Network 
                   3 
TC= DC +          RX.   
                  x=1 
Where, TC= Total cost. 
Dc= cost of distribution center. 
 Rx= Cost of retailer shop. 
 
Total supply network cost for service level 96% 
4. DATA COLLECTION 
4.1 Data Collection:  
Data is collected from various retailer shops of 
cement sellers and distribution centre of specific 
cement manufacturing company at sylhet zone. These 
retailer shops are well known at the sylhet zone. We 
have collected data from 91 retailer shops and 1 
distribution center. Data’s are shows in appendix C.  
4.2 Descriptive Analysis: 
A number of variables have been included in the 
questionnaires in order to describe the sample 
characteristics. For retailer shop, we divided our data 
into three categories according to their demand 
volume. 
4.3 Analysis of the Results 
 In this section, the study and analysis of the results 
are presented. The study has been conducted in 
various retailers and a distribution center of Lafarge 
Surma Cement Ltd.  The objective of this case study 
has been to search for different aspects of inventory 
control, more specifically their current policy for 
inventory control of particular finished good, cement.  
 4.3.1 Inventory System of Retailer Shops: 
The retailers shop focus on finish goods inventory. 
They forecast their demand from previous sales data. 
They don’t follow any scientific method for 
controlling inventory.. They control inventory of 
finished goods by setting target for a month’s 
forecasted demand which is collected from their 
previous sale experience. For this cause, supply 
network can’t optimize their inventory level and 
network carry large amount of inventory cost. At 
retailer level, we divide the retailer demand 
according to their demand volume. These are: 
1. Low volume retailer shop         0<x<500                                                    
2. Medium volume retailer shop     500x<1000 
3. High volume retailer shop           x>1000 
 
Retailers 
Fig.4.3.1. Actual demand versus forecasted demand 
at low volume retailers 
 
 
 
Fig.4.3.2. Actual demand versus forecasted demand 
at medium volume retailers 
 
Fig.4.3.3 Actual demand versus forecasted demand at 
high volume retailers 
 
0
100
200
300
400
500
1 8 15 22 29 36 43 50
Forecasted 
demand 
Actual 
demand
Page 811
  
4.3.2 Inventory System of Distribution Center:  
 
 At sylhet zone there is one distribution center for 
supercrete brand cement named Kibria Complex. 
These DC has a capacity of 80,000 bags of cement. 
This inventory is carried to fulfill the retailers 
demand.   
 
 
 
 
Fig.4.3.4 Forecasted demand vs. actual demand at 
DC  
 
5.  ANALYSIS 
 
5.1 Assumptions:  
 Demand for the product is constant and 
uniform throughout the month.  
 The service level is constant (96%) for 
finished goods.  
 Cost per unit of product is constant.  
 Raw materials for the product are available 
for instant supply.  
 All production related resources (e.g. 
equipment, machineries, labor etc.) are 
available for meeting the demand.  
 Transportation facilities are available 
without any disturbance. 
5.2 Calculation of Order Up to Level for Retailer  
Calculation of low volume retailer data considering 
96% service level. 
P=0.96 
n = 2 
L=2 
= 76 
µ=376 
CV= / µ= 96/376=0.255 
From the fractional polynomial approximations in 
tables 8 and 9 , E(τ)= 0.54202 and Var (τ)=0.0782  
From appendix A  
 
x/ µ=  {(0.54202+2)*(0.255)2}+0.0782 
 
        =0.4935 
 
  
 
            = (1-.96)*2/0.4935 
            =0.162 
K[12]= 
s={ 
}*µ 
  =(0.54202+2-0.1325*.4252)*376  bags 
 
Calculation of medium volume retailer considering 
96% service level. 
P=0.96 
n = 2 
L=2 
= 76 
µ=376 
CV= / µ= 151/722=.209 
From the fractional polynomial approximations in 
tables 8 and 9 , E(τ)= 0.54202 and Var (τ)=0.0782  
From appendix A  
 
 
x/ µ=  {(0.54202+2)*(0.209)
2}+0.0782 
 
        =0.4350 
 
  
 
            = (1-.96)*2/0.4350 
            =0.184 
K[12]= 
s={ 
}*µ 
  = 
  =bags 
 
Calculation of high volume retailer considering  96% 
service level. 
P=0.96 
n = 2 
L=2 
= 76 
µ=376 
CV= / µ= 574/1507=0.380 
 
From the fractional polynomial approximations in 
tables 8 and 9 , E(τ)= 0.54202 and Var (τ)=0.0782  
From appendix A  
 
x/ µ=  {(0.54202+2)*(0.380)
2}+0.0782 
 
        =.667 
  
 
            = (1-.96)*2/0.667 
Page 812
             =0.119 
K[12]= 
s={ 
}*µ 
  =(0.54202+2-0.1325*.4252)*376 
  =bags 
 
T-1 order up to level for l of retailer with different 
lead time considering target service level 
Number 
of period 
between 
replenish
ment 
n 
Reor
der 
point 
 In 
bags  
 
Order up 
to level 
at  low 
volume 
retailer 
S= s+ 
 
Order up 
to level 
at  low 
volume 
retailer 
S= s+ 
 
Order up 
to level 
at  low 
volume 
retailer 
S= s+ 
 
2  417 962 1619 
3  919 1961 3074 
4  1429 2877 5272 
5  1884 3689 6758 
 
We found out average on hand inventory (I) for 
getting order quantity (q) from the 51 LVR, 25 MVR 
and 15HVR (total 91 retailers) 
Average on hand inventory for low volume retailer 
shop = 50 
Average on hand inventory for medium volume 
retailer shop = 120 
Average on hand inventory for high volume retailer 
shop = 180 
Order quantity (in bags) q = Order up to level – Avg. 
on hand inventory (I) 
 
 
 
 
 
Fig.5.2.1  demand for LVR retailer 
 
Calculation of Retailer Inventory Cost: 
 
Total cost= material cost + ordering cost+ holding 
cost. 
    
 
                                   
   Here, C=cost per unit 
             D= demand of jth retailer per year. 
 q= quantity to be ordered         
 S = ordering cost. 
 SS= safety stock. 
Assume, 
 1track load =300 bags. 
 Cost per track= 240 tk 
For lead time 3 days with service level 96%  
 
Low volume retailer shop inventory cost: 
 
Annual material cost= CD 
            =245*(12*376) 
            =1105440  
Annual holding cost =    
 
  
   =(242/2+67)*24.5 
   =4606 TK 
 
Annual ordering cost, 
Number of order per year=12*(376/242) 
        =19 
Truck load per order= 242/350=.691=1 
Annual ordering cost=1*19*240=4560 
     
 Total cost = 1105440+4606+4560= 1114606tk  
 
 
Medium volume retailer shop cost: 
 
Annul material cost=CD  
        =245*12*722=2,122,680tk 
Annual holding cost =    
 
  
   = (405/2+92)*24.5 
   =7215 TK 
 
Annual ordering cost, 
 
No of order =12*(722/405) =22 
Truck loaded per order= 405/350 
    =1.16=2 
Annual ordering cost= 2*22*240 
            =10,560 tk 
 
Total cost =2122680+7215+10560=2140455tk 
 
High volume retailer shop cost: 
 
Annul material cost= 245*12*1507=4430580tk 
 
Annual holding cost =    
    =(1218/2+493)*24.5 
   =26999TK 
0
100
200
300
400
3 4 5 6
on hand 
inventory
quantity to be 
ordered
Page 813
 Annual ordering cost, 
No of order =12*(1507/1218) =15 
Truck loaded per order= 1218/350 
    =3.48=4 
Annual ordering cost= 4*15*240 
            =14400 tk 
   
Total Cost= 4430580+26999+14400 = 4471999TK  
 
Total cost with 3 days lead time and target service at 
retailer stage 
TC=1114606+2140455+4471999=7727060 TK 
  
Total Cost of Supply Chain Network 
 
              3 
TC= DC +         RX.   
                  x=1 
 
Where, TC= Total cost. 
Dc= cost of distribution center. 
 Rx= Cost of retailer shop. 
 
Total supply network cost for service level 96% 
 
= (7727060+363580) =80, 90,640 TK 
 
Table 6 Total supply chain inventory cost with 
different lead and 96% service level 
 
 
 
Fig.5.2.2 Total inventory cost per year with lead time 
considering target service level 
 
 
 
Fig16 change of inventory cost with lead time 
considering target service level 
T -2 Lead time variation  and total inventory cost 
 
 
 
6. RESULT, DISCUSSION AND CONCLUSION 
 
6.1 Result:  
From the 16, the change of lead time has a effect on 
changing the rate of inventory cost. If lead time is 
increase, the inventory holding cost is increase due to 
large amount of finished goods hold. Figure 16 
shows, if lead time increase 1 days, inventory cost 
increase .13% due to increase of finish good. But if 
increase lead time from 4 to 5, then inventory cost 
increase 0.29%. The inventory cost increase 
sequentially due to holding and ordering cost if lead 
time is increase. Above the calculation shows 
inventory cost is optimum to meet the service level, 
when any chain keeps 4 days lead time.        
6.2 Discussion 
To optimize inventory at different stages of supply 
network, first needed coordination with all member 
of the network. Due to lack of coordination wrong 
information passes through the network, customer 
demand is fluctuated because of this wrong 
information. It s creates bullwhip effect that increase 
inventory level at supply network. For this reason 
supply network carry large amount of inventory cost. 
So, coordination is an important factor for inventory 
optimizing at supply chain net work. Another 
important factor is service level. If service level is 
low customers show dissatisfaction about product 
and chain can lost the sale of product. But if chain 
will carrying large amount of inventory cost due to 
maintain high level of service level then chain can 
successfully run. So it is necessary to built up a good 
relation between service level and inventory control 
8060000
8080000
8100000
8120000
8140000
3 4 5 6
inventory cost per year
inventory cost 
per year
0
0.2
0.4
0.6
4 5 6
% increase of inventory cost
% increase of 
inventory cost
Number of period between 
replenishment , n 
Inventory cost per 
year (taka)  
2 7720896 
3 7756844 
4 7802462 
5 7834986 
Page 814
  
policy. In our thesis we built up a relation between 
service level and order up to level. It is shown how 
much of the finished product is needed for the target 
service level and what is the effect of lead time on 
inventory cost.       
               
6.3 Limitations: 
Due to lack of available resources especially the 
relevant information, the case study has not reached 
the perfection level that was expected. The demand 
distribution is found based on historical data, but no 
seasonal effect and other abnormal conditions were 
included. This type of analysis needs de-seasonalized 
demand data, but it was ignored. The other 
limitations are as follows: 
 It was assumed that manufacturer has 
ample capacity but it is impossible. 
 The manufacturer can instantly back 
up the distribution center, it is not 
possible. 
 Back order cost is not calculated. 
6.4 Scope of future work: 
 This model will develop for 
distributor and multi retailer supply 
chain inventory optimization. 
 This model can be generalized for 
any other supply chain network. 
 6.5 Conclusion 
 In this thesis, only inventory optimization was used 
as objective and it is proved that inventory level can 
be significantly minimized by setting up optimal 
levels at every stage and at the same time a higher 
level customer service can be maintained.   The thesis 
identified order up to level and safety stock for each 
stage of network to optimize inventory of the whole 
chain. Service level is an important parameter for 
performance measure of any supply chain and it is 
proved that a high service level target can be ensured 
by setting appropriate inventory policy. 
It is usually optimal for only a few stages to hold 
inventory and other stages operate as pull systems 
and hold very little inventory. 
 
 
REFERENCES 
 
1. Rintiya Arkaresvinum (2008), 
“0ptimization Inventory In Retailer 
Multiecholon Environment”, M 
Sc.Engg.thesis, Sloan School of 
Management, MIT. 
 
2. Dilworth James B;1993.  “Production 
and Operation Management”, Fifth 
Edition, Mc-Graw Hill  p.216-252. 
 
3. O.P Khanna (1992), “Industrial 
Engineering and Management”, 
Revised and   Enlarged Edition, 
publisher- Ish Kapur,partner, Dhanpat 
Rai & sons.  
 
4. Chopra,Meindl(2007),” Supply Chain 
Management(Strategy, Planning, 
Operation)”,second edition, Pearson 
Education p.345-347 
 
5.   Eugenio Cornacchia ( 2004), “Recent 
Trends In Inventory 
Optimization”p.3-12 
 
6. Calvin B. Lee, (2004)“Multi-Echelon 
Inventory  Optimization”, Ivan Inc, 
white paper series, p.2-13 
 
7. Chase, Aquilano, Jacobs  (1999), “ 
Production and Operations 
Management    ”, Eighth Edition, 
Tata McGraw-Hill Publishing 
              Company Limited, p.580-623. 
8. Liana Napalkova(2006)” Development 
of Simulation-Based  
Environment for Multi-echelon Cyclic 
Planning and Optimization” PhD 
thesis, Riga Technical University. 
 
9. Kathryn E. Caggiano, Peter L. Jackson 
z and John A. Muckstadt(2001)” A 
Multi-Echelon, Multi-Item Inventory 
Model for Service Parts Management 
with Generalized Service Level 
Constraints” Xelus, Inc., and the 
National  Science Foundation (Grant 
DMI0075627) 
 
 
Page 815
Corresponding Author: Khondoker Rezwan Tanvir
E-mail: rezwantanvir32@yahoo.com
Title: PROBLEMS AND PROSPECTS OF SPECIAL ECONOMIC ZONE 
IN SYLHET
Khondoker Rezwan Tanvir*
Department Of Business Administration
Shahjalal University of Science and Technology, Sylhet-3114
ABSTRACT: The present business world has become so much competitive as well as diversified
due to huge globalization. In this context, the Special Economic Zone (SEZ) has got potentials as an 
important and the most appropriate way to improve the economic condition and develop the 
relationship between neighboring countries. For this reason, it becomes a time demand to carry on a 
research initiative in this regard. The core objectives of the study include identifying the prospects,
possibilities and constraints within the region and also determining the investment and financial 
viability. Methodology applied for the study includes field survey, case studies, desk interview and 
reassert, personal interview of key information, focused group discussions, analysis of current scenario 
of local and industrial trends. The main prospects found are the abundance of huge idle money, 
availability of raw materials as well as large land areas in Sylhet. The main drawbacks are the lack of 
sufficient value-added SEZ services and infrastructure facilities, inefficient skill and technological 
inability. So the bottom line may be as -investment or attracting investors is one of the most competitive 
businesses in the world. Each and every country in the world is looking to attract investors to their 
shores.  Besides foreign direct investment, the proposed Sylhet economic zone will bring in tens of 
millions of dollars in numerous investments.
           Key words:  prospect, constraints, expatriate, investment, employment
1. INTRODUCTION
It is said that Sylhet, the northeastern 
metropolitan city, is the ‘London of 
Bangladesh’ we know a huge amount of 
remittance flows in form non-resident 
Bangladeshis (NRB), whose origin is the 
greater Sylhet region. From most families, at 
least one person lives in Europe, America or 
in the Middle East. It is natural that their 
relatives enjoy a better life. Though SEZs 
have become a buzzword among advocates 
of Bangladesh economic liberation in recent 
years, they are not entirely a new concept 
and are basically modeled on the export
Page 816
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
Corresponding Author: Khondoker Rezwan Tanvir
E-mail: rezwantanvir32@yahoo.com
processing zones (EPZ) that came up nearly 
five decades ago. The government is 
conducting a feasibility study on the 
establishment of a special economic zone in 
Sylhet, eying private capital for the set-up 
especially from the overseas Bangladeshi 
nationals. The government has selected 
Beani bazaar in Sylhet as the most suitable 
site for creating a special economic zone that 
could draw substantial private capital, 
especially from Bangladeshi expatriates. The 
pioneering SEZ in Sylhet area will be 
establish on 300 acres of land, which will be 
linked to international market. Officials at 
the board of investment (BoI) said that the 
Sylhet economic zone will be built on the 
basis of public-private partnership and the 
government wills development of such 
zones. It will create opportunities for local 
entrepreneurs and expatriate Bangladeshis, 
who have been sending a huge amount 
foreign Currencies.
2. OBJECTIVES
The study work of the seminar paper has     
been undertaken with the following 
objective views include identifying 
prospects and constraints within the region, 
availabilities of resources in this region, 
availabilities of external support required, 
investment and financial viability, Socio 
economic background of the region, location 
advantages regarding international business 
and other relevant aspects, problems existing 
in Sylhet about the SEZ, contrast between 
SEZ and EPZ(Export Processing Zone) and 
prove the superiority of SEZ over our 
economy, some recommendations on how to 
solve the problems and improve the 
atmosphere for SEZ for a better and 
stabilized economy.
3. LITERATURE REVIEW
Bangladesh is developing country. One of 
the main goal of our government is poverty 
reduction by the meant of employment 
generation’s achieve the national goal 
industrialization is one of the key factors. In 
order to establish economically prospective 
industries; the government of Bangladesh 
has a plan to set up Special Economic Zone 
(SEZ). The SEZ, the first of its kind in 
Bangladesh, will be modeled after similar 
"successful" zones located in China, 
Vietnam, South Korea, the United Arab 
Emirates and Jordan. 
Bangladesh is expected to establish a 
Special Economic Zone (SEZ) to speed up 
local and foreign investments in the country. 
According to the Bangladesh's Board of 
Investment (BoI) country's former caretaker 
government approved principles for the 
creation of a SEZ. The office of the former 
chief advisor was scrutinized the final draft 
of a proposed "Special Economic Zone 
Ordinance-2008", under which a Special 
Economic Zone Authority would be 
established. In Bangladesh, the electronics 
industry hardly existed before the SEZ
program was put in place—SEZs created 
Page 817
Corresponding Author: Khondoker Rezwan Tanvir
E-mail: rezwantanvir32@yahoo.com
new job opportunities in this sector (Modal 
2003).
The BoI official told the FE. Once 
developed, the proposed Sylhet Special 
Economic Zone will be the first of its kind 
in Bangladesh. The establishment of such 
new generation zones may also signal the 
country's radical shift toward modernizing 
its zone regime, now subsidized by the 
government, BoI officials say. Unlike the 
existing publicly owned and managed export 
processing zones (EPZs), an SEZ will be 
larger in scale and be linked to the domestic 
market. The Sylhet economic zone will be 
built on the basis of public-private 
partnership and the government will no 
longer finance the development costs of such 
zones, the officials added. In another 
development, the BoI is close to finalizing 
the Bangladesh Economic Zone Policy 
aiming to allow the establishment of 
economic zones, which are conceptually 
different from the traditional industrial zone. 
4. METHODOLOGY
Methodology applied for the study includes 
field survey, case studies, desk interview and 
reassert, personal interview of key 
information, focused group discussions, 
analysis of current scenario of local and 
industrial trend as well as recent 
international trade related events and 
initiatives of SAARC, WTO, ASEAN, etc. 
SEZ Policy aiming to allow the 
establishment of economic zones, which are 
conceptually different from the traditional 
industrial parks. As a result to do a research 
project in this specific sector is not only 
interesting but also complex and 
challenging.
The research is based on some documents 
and also some practical observations. Both 
primary and secondary data are used in this 
report. Since SEZ is at the developing phase 
in Sylhet, study has been performed on the 
SEZ in Sylhet to generate an idea about their 
present condition. Survey has also been
conducted on the condition of SEZ. The 
main focus was on the understanding of 
basic difference between SEZ and EPZ.
5. KEY FINDINGS & ANALYSIS
5.1. FINDINGS OF KEY 
INFORMANTS INTERVIEWS (KII):
 Road and rail network is in excellent 
conditions and easy access to country’s 
seaport with insignificant distance. 
Airport is having direct flight from 
abroad.
 People are ready to invest if there is 
SEZ. While cautioning about land 
ownership, people want easy investment 
to ensure the land ownership.
 Scope of regional integration with 
Northeast in trade and investment.
 Availability of huge idle money in the 
bank. And Abundance of natural 
resources in the region.
Page 818
Corresponding Author: Khondoker Rezwan Tanvir
E-mail: rezwantanvir32@yahoo.com
 A large number of NRS entrepreneurs 
living abroad who can be moralized for 
investment.
 Finally, most respondents emphasized 
on identification of real stakeholders 
and entrepreneurs who are capable, 
solvent and ready to take risk.
5.2. SWOT ANALYSIS
5.2.1. Strengths of such economic zone in 
Sylhet:
In response to the question on strength of a 
special economic zone in Sylhet, the 
respondents replied the followings:
 Road and rail infrastructure are in 
good condition.
 Abundance of idle money.
 Large land area available.
 Raw materials are available.
5.2.2. Weakness of such economic 
zone in Sylhet:
While inquiring about the weakness, the 
respondents replied the followings:
 High transportation cost from 
Sylhet to the principle seaport is a 
major weakness.
 Lack of urban facilities and 
amenities discourage official to 
work in Sylhet.
 Lack of skilled man power. 
People are having tendency to go 
abroad but not to work in 
industry.
5.2.3. Opportunity of such economic 
zone in Sylhet:
While inquiring about the 
opportunities, the respondents replied 
the followings:
 Growing consumers class in 
Sylhet and neighboring 
districts.
 Scope of enhancing production 
of agriculture and non-
agriculture outputs.
 Presence of SUST and Scope 
of borrowing its “Research and 
development” facilities.
5.2.4. Threats for economic zone in 
Sylhet:
 Confining the SEZ only for 
NRS or local Sylheties.
 Lack of government political 
will and favorable policy to set-
up SEZ in Sylhet.
 Lack of professional 
management.
5.3. The entrepreneur 
willingness to       invest in SEZ
percent
Yes 80%
No 20%
100%
Page 819
Corresponding Author: Khondoker Rezwan Tanvir
E-mail: rezwantanvir32@yahoo.com
5.4. Reason behind supporting the 
proposed SEZ: The study has revealed the 
reason supporting the SEZ as follows:
Reason Count
Industrial 
employment
218
Economic 
development 
of the region
195
Enhance 
local income 
level
161
Development 
of  
infrastructure
135
Greater 
investment in 
the region
111
Development 
of linkage 
107
Skill 
Enhancement
of local 
workforce 
98
Percent 
of 
responses
18.00%
16.10%
13.30%
11.10%
9.20%
8.80%
   8.10%
Development 
of service 
industries
Local 
Education 
development
Total 
responses
            Figure: willingness to invest in SEZ
Figure: Percent of Reason
supporting SEZ
0%
50%
100%
percent
0%
50%
100%
Count Percent of 
responses
95 7.80%
93 7.7.%
     
1213
       
100.00%
s behind 
Yes
No
Total responses
Local Education 
development
Development of 
service industries
Skill Enhancement 
of local workforce 
Development of 
linkage 
Greater investment 
in the region
Development of  
infrastructure
Enhance local 
income level
Economic 
development of the 
region
industry Industrial 
employment
Page 820
Corresponding Author: Khondoker Rezwan Tanvir
E-mail: rezwantanvir32@yahoo.com
6. CONCLUSION
We can say that SEZ is a complete code of 
Business life. Here, all of the acceptable 
ways of business and other financial 
institutions are mention. These institutions 
are very much potential. 
The main challenge of these industries is to 
maintain compliance with the SEZ
principles. A major concern in this 
connection is the lack of enough trained 
manpower that has knowledge of SEZ. This 
problem can be solved establishing enough 
training centers about SEZ principles. The 
SEZ will be developed in such a way that it 
can really cater to the needs of investors. 
Otherwise, it is sure to face the same fate as 
BSCIC-built industrial estates, many of 
which are lying unutilized.
Investment or attracting investors is one of 
the most competitive businesses in the 
world.  Each and every country in the world 
is looking to attract investors to their shores.  
It is no different for Sylhet and Bangladesh 
as it competes with the likes of India, 
Pakistan, Sri Lanka, Malaysia, Thailand, 
Vietnam and China.  It is imperative for any 
investments to take place it is important that 
the right conditions are in place to attract 
potential investors. So, everyone encourages 
the Government of Bangladesh, the Sylhet 
Region and the Board of Investment to 
continue their work in enhancing Sylhet’s 
infrastructure – roads, rail, 
telecommunications and utilities for 
establishing special economic zone in 
Sylhet.
The upgrading of the airport is a positive 
step in the right direction.  Infrastructure is 
the responsibility of government and is key 
to attracting new investors.  Countries and 
regions that have accessible, fast and 
efficiency transport links will benefit in the 
long term of Special Economic Zone.
Finally, besides foreign direct investment, 
officials believe, the proposed Sylhet 
economic zone will bring in tens of millions 
of dollars in numerous investments, thereby 
generating substantial jobs and boosting the 
local economy.
7. REFERENCES
The references to complete this report are:
1. www.thefinancialexpres
s-bd.com
2. www.cpiml.orgliberatio
nyear_2006August
3. www.positivebanglades
h.wordpress.com
4. www.topix.com.bd
5. www.banglalink.co.uk
6. www.liaoning-
gateway.comgateway
7. www.scci.org.bd
Page 821
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Md. Mosharraf Hossain,  
E-mail: mosharraf80@yahoo.com 
PRODUCTION SCHDULING IN A GARMENTS MANUFACTURING 
COMPANY: A CASE STUDY 
 
 
Md.Mohibul Islam 
Comfit Composite Knit Limited, Mirzapur, Tangail, Bangladesh 
 
Md. Mosharraf Hossain*, Khan Md. Ariful Haque, Md. Ariful Islam and 
Md. Mahabub Islam 
Department of Industrial & Production Engineering, Rajshahi University of Engineering & 
Technology, Rajshahi-6204, Bangladesh 
 
Sazedul Karim 
Avery Dennison, 3/F Uday Tower, Gulshan Avenue, Gulshan 1, Dhaka, Bangladesh 
 
 
Scheduling plays an important role in any manufacturing system. It is a core element of value-addition in 
chain of production system. Optimal Production Schedule plays an important role for minimizing lead time 
where penalty like as reduction of price, reduction of order quantity, sometimes rejection of whole lot occur 
for late deliveries. For this reason sometime products of garments’ industries are sold in the local market in 
reduced price, hampering the export, which is a great economical loss of the company. To minimize the total 
completion time to make production schedule is proposed. Generally garments manufacturing faces a job 
shop scheduling problem however in reality for mass production this may turns into flow shop scheduling 
problem. In this study, production scheduling model based upon the Binary Integer Programming (BIP) 
technique is proposed to solve the flow shop scheduling problem where single operation is done by a single 
machine (SOSM). The BIP model is implemented by using software (Xpress-MP). This paper compares the 
results of the existing schedule of a typical Knitwear manufacturing Industry with a proposed schedule and it 
is found that the proposed schedule is better than the existing schedule. 
 
Key words: Production Scheduling, BIP Model, SOSM, Garments 
 
1. INTRODUCTION 
 
The knitwear manufacturing industry is quite large 
and important sector in Bangladesh in terms of 
output, export and employment. The export items 
are shirt, trousers, jackets, T- shirt, sweaters and 
others. Uddin and Jahed (2007) informed that the 
knitwear manufacturing industry has been leading 
the Bangladesh economy since the early 1990s. 
Knitwear manufacturing industries are the 
country’s biggest export making up about three 
quarters of total exports, and the industry is a 
symbol of the country’s dynamism in the world 
economy. The industry is also the main non-farm 
formal sector creating employment opportunities 
for the poor. The greater part of the workforce is 
female; less educated, and has migrated from rural 
areas. The main characteristics of international 
business in this area is its tough competition among 
several developing countries, such as China, India, 
Vietnam, Sri Lanka etc. Apart from this, free trade 
market opened up a new dimension for a search of 
other tools for getting upper edges over others. 
Logically, the main focus for such a search will be 
concentrated around the optimization of supply 
chain system. 
 
In the apparel industry, a successful manufacturer 
must make efficient use of limited resources to 
meet dynamic customer demand as customer 
preference change on a seasonal or monthly basis. 
Production schedule is the key area to meet this 
demand.  
 
According to Hasin et al (2005), [4] in the context 
of Bangladesh the garments industry apply a mix of 
two strategies: First, they try to apply Earliest Due 
Date (EDD) priority rule, and then they sometimes 
Page 822ISBN: 978-984-33-2140-4
  
apply “Privileged or Priority Customer” concept. 
However this concept is old dated for the current 
competition in the market. Islam et al (2010) 
mentioned that in most cases the garments’ 
industries are doing their production schedule based 
on general knowledge without taking advantages of 
available modern techniques. 
 
To develop this most export oriented field, an 
advanced scheduling technique, which may 
perform much better under this aspects, is needed. 
The general problems in the knitwear industry are 
considered and a study is carried out to propose a 
schedule to meet their challenges. 
 
2. PROBLEM STATEMENT 
 
Green Life Clothing Lt. is a typical knitwear 
manufacturing company. It is a renowned, well 
equipped and one of the most modern 100% export 
oriented Knit Garments project in Bangladesh. This 
Factory is BSCI approved factory and it is in a 
process of “WRAP” certificate. The factory is 
equipped with most modern machinery, having 
production capacity of 22,000 pieces Garments per 
day. This factory manufactures two types of cloth 
as basic T-shirt & Polo Shirt. Annual Production 
Capacity is 4.68 Million. Moreover, this factory is 
capable to manufacture T-Shirt, Polo Shirt, Tank 
Top, Singlet, Ladies Shorts, Pajama Set, Hooded 
Sweat Shirt, All Kind of Lingerie Items, Boxer 
Shorts, Trousers and all kinds of Knitted Children 
Wear (Moniruzzaman (2010)).  
 
Various problems are an impartial phenomenon in 
the knitwear industry of Bangladesh. Like others, 
there are also some problems in the green life 
clothing limited even though they have highly 
positive response from the workers. Sewing section 
is a dominating one to control the efficiency of this 
factory but scheduling problem in this section is 
very visible. They meet their customers demand 
with very simple assembly line production. They 
have no specified time table for performing sewing 
operation. It creates bottle neck in this section 
because if an operation is completed to go next 
operation but find it busy. If they have a specified 
schedule to perform sewing operation, the 
production would not be delayed. It will be capable 
to earn time and can manufacture more quantities 
and capacity utilization will be higher. 
 
The objectives of this study is to generate a 
schedule, for the sewing section of the mentioned 
factory, which will minimize the total completion 
time to make a T-Shirt in the sewing section and to 
determine the starting and ending time of each 
operation. 
 
3. MODEL FORMULATION 
 
For definition purpose flow shop scheduling system 
is appropriate for manufacturing all types of T- 
shirt at their present system. To formulate this 
scheduling problem model Binary Integer 
Programming (BIP) is used. In this model assigning 
the machines is ignored but precedence relationship 
of operation of job is considered. This model 
contains of two parts like as objective function and 
system constraints. 
 
Mathematical model is presented to minimize the 
total completion time in the single operation by a 
single machine (SOSM) scheduling. 
The set of tasks = {1…N} where N is the fictitious 
end task.  
Let, DURi be the duration of task i (the sewing time 
of a single part for making a T-shirt). To establish 
the precedence relationships between tasks, 
Precedence graph G = (TASKS, ARCS) where ARCS 
stands for the set of arcs (an arc (i, j) symbolizes 
that task i precedes task j) is used. 
Variables are introduced as STARTi to represent the 
earliest start time of tasks i. The only constraint, 
that is used, is the precedence relationship. A task j 
may only start if all of its predecessors have 
finished, which translates into constraints.  if there 
is an arc between i and j, then the completion time 
of i (STARTi + DURi) must not be larger than the 
start time of j. 
ARCS: STARTi + DURi ≤ STARTi 
 
The objective is to minimize the completion time to 
make a T-shirt that is the start time of the last, 
fictitious task N.  
 
Objective Function: Minimize STARTN  
                 subject to 
                 ARCS: STARTi + DURi ≤ STARTi 
 
                TASKS: STARTi ≤ 0 
 
3.1 Model Execution for Existing Schedule 
 
The existing operations and their durations are 
provided in Table 1. 
 
 A computer program for the the existing schedule 
is written using the Binary Integer Programming 
technique. Xpress-MP student version software is 
used to run the program. 
 
Page 823
  
Table 1: Existing operations and their durations 
Sl 
No. 
Name of the 
Operations 
Sewing time 
(Sec) 
1 Shoulder Joining 15 
2 Rib Tug 12 
3 Neck Joining 17 
4 Neck Piping 24 
5 Size level attaching 18 
6 
Shoulder to Shoulder 
back Top stitching 18 
7 Main Label 32 
8 Sleeve Joining 36 
9 Side joining 40 
10 Body hem 20 
11 Sleeve hem 20 
 
The written computer program which is used is 
given here: 
 
model "Scheduling to make a T-Shirt" 
uses "mmxprs" 
declarations 
N = 12 ! Number of tasks in the project! (last = 
fictitious end task) 
TASKS=1..N 
ARC: array(range,range) of real ! Matrix of the 
adjacency graph 
DUR: array(TASKS) of real ! Duration of tasks 
start: array(TASKS) of mpvar ! Start times of the 
tasks 
end-declarations 
initializations from 'existing.dat' 
ARC: DUR 
end-initializations 
! Precedence relations between tasks 
forall (i,j in TASKS | ARC(i,j)=1) 
start(i) + DUR(i) <= start(j) 
 
! Solve the first problem: minimize the total 
duration 
minimize(start(N)) 
end-model 
 
After running the program it is found that the cycle 
time for existing system is 252 second. 
 
3.2 Model Execution for Proposed Schedule 
It is observed that some of the elements can be 
done in parallel without hampering the main 
production line. According to that observation the 
work elements are restructured. The operations 
times for each element are shown in table 2. The 
operations times for the elements, which are done 
in parallel, are shown as 0. 
Table 2: Proposed operations, their durations and 
their precedence relationship 
Sl  
Name of the 
Operations 
Sewing 
time (Sec) Predecessor 
1 
Shoulder 
Joining 15 None 
2 Rib Tug 12 None 
3 
Neck 
Joining 17 1,2 
4 Neck Piping 24 3 
5 
Size level 
attaching 0 None 
6 
Shoulder to 
Shoulder 
back Top 
stitching 18 4,5 
7 
Sleeve side 
stitching 32 None 
8 
Sleeve 
Joining 36 6,7 
9 
Main level 
attaching 0 None 
10 Side joining 40 8,9 
11 Body hem 20 10 
12 Sleeve hem 20 11 
 
 
A computer program for the the existing schedule is 
written using the Binary Integer Programming 
technique. Xpress-MP student version software is 
used to run the program. The written computer 
program which is used is given here: 
 
model "To make a T-Shirt" 
uses "mmxprs" 
declarations 
N = 13 ! Number of tasks in the project! (last = 
fictitious end task) 
TASKS=1..N 
ARC: array(range,range) of real ! Matrix of the 
adjacency graph 
DUR: array(TASKS) of real ! Duration of tasks 
start: array(TASKS) of mpvar ! Start times of the 
tasks 
end-declarations 
initializations from 'proposed.dat' 
ARC: DUR 
end-initializations 
! Precedence relations between tasks 
forall (i,j in TASKS | ARC(i,j)=1) start(i) + DUR(i) 
<= start(j) 
Page 824
  
! Solve the first problem: minimize the total 
duration 
minimize(start(N)) 
end-model 
 
After running the program it is found that the cycle 
time for proposed system is 190 second. 
 
4. RESULT 
 
The completion time of the existing schedule based 
on the assignment of task is 252 second. where as 
the proposed schedule requires 190 second to 
complete the jobs. This result shows that the proper 
production schedule can save their time and can 
meet the demand relatively quickly. 
 
5. CONCLUSION 
 
Now a day, it is a great challenge for the knitwear 
manufacturing Industry of Bangladesh to deliver 
shipment to buyer on due date meeting varieties 
risks. As knitwear manufacturing Industry is mostly 
based on the human performance and little chance 
to develop the technical aspect. For this reason time 
is the major constraint to utilize the workforce with 
limited resource. This problem may be alleviated 
by using a better schedule. In this sense the Binary 
Integer Programming (BIP) model is noble idea and 
implementation of this model by using computer 
software is satisfactory. In this case study existing 
schedule is studied and a schedule is proposed. The 
essence of this study is recommended that this 
approach is working well for the Green Life 
Clothing Limited and should implement at their 
factory and may be suggested to other knitwear 
manufacturing industries of Bangladesh. 
 
REFERENCES 
 
1. Gueret C., Prins C. and Sevaux M., (2002), 
“Applications of optimization with Xpress-
MP” Chap. 7, no. 1, pp. 82-85.and chap. 3, 
pp.30-46 
2. Haider M. Z., (2007), “Competitiveness of the 
Bangladesh Ready-made Garment Industry in 
Major International Markets”, Asia-Pacific 
Trade and Investment Review, Vol. 3, No. 1. 
3. Hasin M. A. A., Elias R. U. S., Khwaza L., and 
Fatema J., (2005), “Production Scheduling In 
A Garments Manufacturing Company: A Case 
Study,” International Journal of Mechanical 
Engineering. 
4. Islam M. M., Md. Mahabub Islam M. M. and 
Karim S., (2010), “Production Scheduling in a 
Knitwear Manufacturing Industry of 
Bangladesh-A Case study”, Unpublished B.Sc. 
Engg. Thesis, Rajshahi University of 
Engineering & Technology, Rajshahi. 
5. Jones A. and Rabelo L. C., “Survey of Job 
Shop Scheduling Techniques”, National 
Institute of Standards and Technology & 
Massachusetts Institute of Technology. 
6. Moniruzzaman M. (Rusel), (2010),” The 
Company Profile of The Green Life Clothing 
Limited .” 
7. Panneerselvam R., (2006), “ Production and 
Operations Management,” Management 
Studies, vol. 12, pp. 283-284. 
8. Tomastik R. N., Luth P. B. and Liu G., (1996), 
“Scheduling Flexible Manufacturing System”, 
IEEE Transactions on Robotics and 
Automation, vol. 12, no. 5. 
9. Uddin M. S. and Jahed M. A., (2007), 
“Garments Industry: A Prime Mover of the 
Socio Economic Development of Bangladesh” 
An International Journal Of The Cost And 
Management, vol. 35,  no. 1,  pp. 59-70. 
10. Vaidyanathan B. S., Miller D. M. and Park Y. 
H., (1998), “Application of Discrete Event 
Simulation in Production Scheduling ” 
International Journal of winter simulation 
conference. 
 
Page 825
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Second B. Author,  
E-mail: somebody@somewhere.com 
Productivity improvement through cellular manufacturing in RMG:  
BANGLADESH PERSPECTIVE 
Engr. A.B.M. Abdul Malek 
                                                           Assistant professor 
                                     Department of Industrial & Production Engineering 
Shahjalal University of Science & Technology, Sylhet-3114, Bangladesh 
Email:abmmalek@gmail.com  
                                                            Robin Bhuiyan 
                                   Department of Industrial & Production Engineering 
Shahjalal University of Science & Technology, Sylhet-3114, Bangladesh 
  Email: robinbhuiyan03@yahoo.com 
A.K.M. Sirajun Nuha 
                                   Department of Industrial & Production Engineering 
Shahjalal University of Science & Technology, Sylhet-3114, Bangladesh 
Email : nohaipe@yahoo.com 
Abdullah Al Mamun 
                                  Department of Industrial & Production Engineering 
Shahjalal University of Science & Technology, Sylhet-3114, Bangladesh 
Email :alipe13@yahoo.com 
 
Shorter product life-cycles, unpredictable demand, and customized products have forced manufacturing 
firms to operate more efficiently and effectively in order to adapt to changing requirements. There are seven 
wastages in RMG industry. For removing seven wastages different lean tools are used. Cellular 
manufacturing which is considered as a lean tool is widely used in RMG. Cellular manufacturing, which 
incorporates the flexibility of job shops and the high production rate of flow lines, has been seen as a 
promising alternative for such cases. Here existing framework of traditional layout , different graphs of 
traditional layout & cellular layout is discussed & productivity can be improved by cellular manufacturing is 
also shown. For establishing cellular layout some recommendation also included. 
 
Key words: seven wastages; cellular manufacturing; traditional layout; productivity improvement; value 
analysis. 
 
1. INTRODUCTION 
    Lean Manufacturing is an operational strategy 
oriented toward achieving the shortest possible 
cycle time by eliminating waste. It is derived 
from the Toyota Production System and its key 
thrust is to increase the value-added work by 
eliminating waste and reducing incidental work. 
The technique often decreases the time between a 
customer order and shipment, and it is designed to 
radically improve profitability, customer 
satisfaction, throughput time, and employee 
morale. The benefits generally are lower costs, 
higher quality, and shorter lead times.  The term 
"lean manufacturing" is coined to represent half 
the human effort in the company, half the 
manufacturing space, half the investment in tools, 
and half the engineering hours to develop a new 
product in half the time. The characteristics of 
lean processes are: Single-piece production, 
Repetitive order characteristics, just-In-Time 
materials/pull scheduling, Short cycle times, 
Quick changeover, Continuous flow work cells, 
Collocated machines, equipment, tools and 
people, Compressed space, Multi-skilled 
employees, Flexible workforce, Empowered 
employees, High first-pass yields with major 
reductions in defects [ref: 1] 
2. Literature Review 
 
2.1 Overproduction: Production more than is 
needed, faster than needed or before needed. The 
results of overproduction are; Products being 
produced in excess of what’s required, Products 
being made too early ,Excess inventory carrying 
Page 826ISBN: 978-984-33-2140-4
  
costs[Ref:2] Example: Units which were produced 
in anticipation of future demand are often scrapped 
due to configuration changes [ref.3]  
 
2.2 Waiting: Idle time that occurs when 
codependent events are not fully synchronized Also 
known as queuing, waiting refers to the periods of 
inactivity in a downstream process that occur 
because an upstream activity does not deliver on 
time. Idle downstream resources are then often used 
in activities that either don’t add value or result in 
overproduction. [Ref: 2] 
 
2.3 Transportation: This is unnecessary motion 
or movement of materials, such as work-in-process 
(WIP) is being transported from one operation to 
another. Ideally transport should be minimized for 
two reasons: It adds time to the process during 
which no value-added activity is being performed, 
handling damage could be incurred. [Ref: 2] 
 
2.4 Extra Processing: This term refers to extra 
operations, such as rework, reprocessing, handling 
or storage that occurs because of defects, 
overproduction or excess inventory. [Ref: 2] 
Example: Time spent manufacturing product 
features which are transparent to 
the customers or which the customer would be 
unwilling to pay for. [ref.3]    
 
 2.5 Inventory: This refers to inventory that is not       
directly required to fulfill current Customer orders. 
Inventory includes raw materials, work-in-process 
and finished goods. Inventory all requires 
additional handling and space. [Ref: 2] Examples: 
Large lot purchases of raw material which must be 
stored while production catches up. [ref.3]     
                            
2.6 Motion: This term refers to the extra steps 
taken by employees and equipment to 
accommodate inefficient process layout, defects, 
reprocessing, overproduction or excess inventory. 
Motion takes time and adds no value to the product 
or service. “To move and add value is called work. 
To move and not add value is called motion. 
Motion, then, means moving without working, 
moving and adding cost”. [Ref: 2] 
2.7 Defects These are products or services that do 
not conform to the specification or Customer’s 
expectation, thus causing Customer dissatisfaction. 
[Ref:2] 
 
 
3. LEAN MANUFACTURING TOOLS: 
 
3.1 Continuous improvement:'5S' is the name 
of a workplace organization methodology that uses 
a list of five Japanese words which are sere, seiton, 
seiso, seiketsu and shitsuke. 
Sorting (Seiri) Eliminate all unnecessary tools, 
parts, instructions. Go through all tools, materials, 
etc., in the plant and work area. Keep only essential 
items & eliminate what is not required, prioritise 
things as per requirements and keep them in 
approachable place & everything else is stored or 
discarded. [Ref.4] 
Straightening (Seiton): There should be a place 
for everything and everything should be in its place. 
The place for each item should be clearly labeled or 
demarcated. [Ref.4] 
Sweeping or Systematic Cleaning (Seiso): Keep 
the workplace tidy and organized. At the end of 
each shift, clean the work area and be sure 
everything is restored to its place. 
Standardizing (Seiketsu): Work practices should 
be consistent and standardized. Everyone should 
know exactly what his or  her responsibilities are 
for adhering to the first 3 S's. [Ref.4] 
Sustaining the discipline Or Self Discipline 
(Shitsuke): Maintain and review standards. Once 
the previous 4 S's have been established, they 
become the new way to operate. Maintain focus on 
this new way and do not allow a gradual decline 
back to the old ways. While thinking about the 
new way, also be thinking about yet better ways. 
When an issue arises such as a suggested 
improvement, a new way of working, a new tool or 
Page 827
  
a new output requirement, review the first 4 S's and 
make changes as appropriate. [Ref.4] 
 
 3.2 Just-in-time (JIT): This is defined in the 
APICS dictionary as “a philosophy of 
manufacturing based on planned elimination of all 
waste and on continuous improvement of 
productivity”.  It also has been described as an 
approach with the objective of producing the right 
part in the right place at the right time (in other 
words, “just in time”).  Waste results from any 
activity that adds cost without adding value, such as 
the unnecessary moving of materials, the 
accumulation of excess inventory, or the use of 
faulty production methods that create products 
requiring subsequent rework. 
3.3Kanban Production Control System: A 
kanban or “pull” production control system uses 
simple, visual signals to control the movement of 
materials between work centers as well as the 
production of new materials to replenish those sent 
downstream to the next work center.  Originally, 
the name kanban (translated as “signboard” or 
“visible record”) referred to a Japanese shop sign 
that communicated the type of product sold at the 
shop through the visual image on the sign (for 
example, using circles of various colors to indicate 
a shop that sells paint).  As implemented in the 
Toyota Production System, a kanban is a card that 
is attached to a storage and transport container.  It 
identifies the part number and container capacity, 
along with other information, and is used to provide 
an easily understood, visual signal that a specific 
activity is required. [ref.5] 
3.4 Push vs pull: A kanban system is referred to 
as a pull-system, because the kanban is used to pull 
parts to the next production stage only when they 
are needed.  In contrast, an MRP system (or any 
schedule-based system) is a push system, in which 
a detailed production schedule for each part is used 
to push parts to the next production stage when 
scheduled.  Thus, in a pull system, material 
movement occurs only when the work station 
needing more material asks for it to be sent, while 
in a push system the station producing the material 
initiates its movement to the receiving station, 
assuming that it is needed because it was scheduled 
for production.  The weakness of a push system 
(MRP) is that customer demand must be forecast 
and production lead times must be estimated.  Bad 
guesses (forecasts or estimates) result in excess 
inventory and the longer the lead time, the more 
room for error.  The weakness of a pull system 
(kanban) is that following the JIT production 
philosophy is essential, especially concerning the 
elements of short setup times and small lot sizes, 
because each station in the process must be able to 
respond quickly to requests for more materials. 
[ref.5] 
3.5 Design for manufacturability (DFM): 
DFM leads to low manufacturing cost without 
sacrificing product quality.  
3.6 Cellular Manufacturing (CM): refers to a 
manufacturing system wherein the equipment and 
workstations are arranged in an efficient sequence 
that allows a continuous and smooth movement of 
inventories and materials to produce products from 
start to finish in a single process flow, while 
incurring minimal transport or waiting time, or any 
delay for that matter. [ref.8] 
4. CALLULAR LAYOUT:       
Productivity is improved by cellular manufacturing 
which is given below: 
4.1. A cell consists of the people and the machines 
or workstations required for performing the steps in 
a process or process segment, with the machines 
arranged in the processing sequence. 
4.2. Arranging people and equipment into cells 
helps companies achieve two important goals of 
lean manufacturing  one-piece flow and high-
variety production 
One Piece Flow: One-piece flow is the state that 
exists when products move through a process one 
unit at a time, at a rate determined by the needs of 
the customer. The goals of one-piece flow are to 
make one part at a time all the time, without 
unplanned interruptions, and to achieve this without 
lengthy queue times.                                     
High-Variety Production: Given the fact that 
customers expect variety and customization, as well 
as specific quantities delivered at a specific time, it 
is necessary to remain flexible enough to serve their 
needs. Cellular manufacturing offers companies the 
flexibility to give customers the variety they want. 
It does this by grouping similar products into 
families that can be processed on the same 
equipment in the same sequence. It also encourages 
companies to shorten the time required for 
changeover between products. 
4.3. Converting a factory to cellular manufacturing 
means eliminating waste from processes as well as 
from operations. 
Page 828
  
4.4 Cellular manufacturing can help make your 
company more competitive by cutting out costly 
transport and delay, shortening the production lead 
time, saving factory space that can be used for other 
value-adding purposes, and promoting continuous 
improvement by forcing the company to address 
problems that block low-inventory production. 
4.5 Cellular manufacturing helps employees by 
strengthening the company's competitiveness, 
which helps support job security. It also makes 
daily production work go smoother by removing 
the clutter of WIP inventory, reducing transport and 
handling, reducing the walking required and 
addressing causes of defects and machine problems 
5. WHY CELLULAR 
MANUFACTURING IN RMG 
SECTOR OF BANGLADESH 
Job shops are designed to achieve maximum 
flexibility such that a wide variety of products with 
small lot sizes can be manufactured. Products 
manufactured in job shops usually require different 
operations and have different operation sequences. 
Operating time for each operation could vary 
significantly. Therefore, to make processing more 
economical, parts are moved in batches. Each part 
in a batch must wait for the remaining parts in its 
batch to complete processing before it is moved to 
the next stage. This leads to longer production 
times, high levels of in-process inventory, high 
production costs and low production rates. [ref.11] 
In contrast to job shop, cellular manufacturing has 
U–shaped cell for which change over time is very 
easy according to product variety. For that reasons 
product variety can be meet very easily. Here 
teamwork is available and that’s why if anyone are 
unable to fill his target another person help him to 
fill her/his target. 
6.NECESSITY OF CELLULAR 
LAYOUT IN RMG SECTOR:                             
1. Reduce production wastages: utilizing the 
different method for producing finished goods 
which reduces 7 wastages.                                                                                                                                         
2. Establish strong layout: This layout is made in 
such a way so that workstations are close to one 
another.                                                                                    
3. Appropriate controlling the line: in this layout 
operators & machines are arranged in such a way 
that supervisor or line leader can easily control the 
line.                                                                                         
4. Direct impact of product quality in line:   
1.Every worker are trained to maintain quality for 
his own work , for that reasons they directly  
control & enhance the quality. 
2.Every worker are concerned by never take a alter 
from before worker , never produce alter, never 
give a alter to anyone. That’s why there are no 
quality problem in line. 
3.Although some quality problems can arise ,then 
inform the line supervisor so that he take the 
action in such a way that never it happen. 
5. Effective line balancing:   
1.The main vision of every worker is that 
maintaining quality, doing job in a short time & 
develop teamwork.  
2.In this layout working hour of every worker is 
utilized which is used to establish effective  line 
balancing. 
 
7. METHODOLOGY: 
 
Material Flow: Cells are arranged in relation to 
each other so that material movement is minimized. 
Capital Proximity: Large and/or expensive 
machines which cannot be easily relocated to cells 
that use them (Point-of- use). 
Assembly Line: The layout of machines within 
each cell should resemble a small assembly line. 
Mobility: Quick positional adjustments should be 
used to arrange/rearrange the machines within a cell 
.Layout Proximity:  Sequential processes need to 
be placed side by side. 
Unified Management Structure: The productive 
resources need to answer to the same voice. 
Quality Checking: Quality must be checked in 
every work station which reduces wastes. 
Skilled Operator: Skilled operator must be 
provided to make up the allowances time of other 
operator as an efficient manner.
Team Work: Team work must be provided for 
productivity improvement. 
Information Shearing: Everyone should be 
informed about 7 wastes. 
Training: Training facilities should be provided.   
8.SUPPORTIVE SYSTEM FOR 
CELLULAR LAYOUT: 
8.1.Develop production planning system.  
8.2Establish industrial engineering / work study 
team. 
Page 829
  
8.3Must be concern about lean culture 
8.4Every method must be standard          
8.5Appropriate PMTS must be introduced for 
conducting cellular layout 
8.6Different method of lean just like kanban , 
Supermarket, visual control must be introduced for 
maintaining a good communication among sewing, 
cutting & finishing department. 
8.7For maintaining quality right & effective 
method must be introduced. 
8.8For improve working environment 5s must be 
introduced 
8.9Enhancing team work 
8.10Member of different class of department must 
have a same goal. 
8.11Must avoid spreading scandal among worker 
& find out the problem & the solution 
8.12The member  in cellular layout must have 
team working  & leadership tendency. 
 
 
9. BANGLADESH RMG SECTOR 
AND CELLULAR MANUFACTURING 
 
9.1 Setup time is reduced. A manufacturing cell is 
designed to handle parts having similar shapes and 
relatively similar sizes. For this reason, many of the 
parts can employ the same or similar holding 
devices (fixtures). Generic fixtures for the part 
family can be developed so that time required for 
changing fixtures and tools is decreased.  
 
9.2 Lot sizes are reduced. Once setup times are 
greatly reduced in CM, small lots are possible and 
economical. Small lots also smooth production 
flow.  
 
9.3 Work-in-process (WIP) and finished goods 
inventories are reduced with smaller lot sizes and 
reduced setup times, the amount of WIP can be 
reduced. Askin and Standridge showed that the 
WIP can be reduced by 50% when the setup time is 
cut in half. In addition to reduced setup times and 
WIP inventory, finished goods inventory is 
reduced. Instead of make-to-stock systems with 
parts either being run at long, fixed intervals or 
random intervals, the parts can be produced either 
just-in-time (JIT) in small lots or at fixed, short 
intervals.  
 
 
9.4 Material handling costs and time are reduced. 
In CM, each part is processed completely within a 
single cell. Thus, part travel time and distance 
between cells is minimal.  
 
9.5 A reduction in flow time is obtained. Reduced  
material handling time and reduced setup time 
greatly reduce flow time. 
 
9.6 Tool requirements are reduced. Parts 
produced in a cell are of similar shape, size, and 
composition. Thus, they often have similar tooling 
requirements. 
 
9.7 A reduction in space required Reductions in 
WIP, finished goods inventories, and lot sizes lead 
to less space required.  
 
9.8 Throughput times are reduced. In a job shop, 
parts are transferred between machines in batches. 
However, in CM each part is transferred 
immediately to the next machine after it has been 
processed. Thus, the waiting time is reduced 
substantially.  
 
9.9 Product quality is improved. Since parts travel 
from one station to another as single unit, they are 
completely processed in a small area. The feedback 
is immediate and the process can be stopped when 
things go wrong.  
 
9.10 Better overall control of operations. In a job 
shop, parts may have to travel through the entire 
shop. Scheduling and material control are 
complicated. In CM, the manufacturing facility is 
broken down into manufacturing cells and each part 
travels with a single cell, resulting in easier 
scheduling and control. 
 
9.11.  Shorter production cycle times.[8] 
9.12. Higher effective manufacturing capacity. 
[8] 
9.13.Improved customer response time. [8] 
9.14. Improved team work & communication  
9.15. Changeover time is reduced 
9.16. Reduced lead time : time required from input 
to finished good is reduced. 
 
10. CURRENT SCENERY OF 
TRADITIONLA LAYOUT:   
 
Page 830
  
 
SMO 23 
Helper  9 
Workstation  32 
Tack time  .18 
Target pieces  3592 
Efficiency  59% 
Loss per worker 171.09(min) 
 
 
 
 
 
 
 
Fig: traditional layout [ref. 12] 
 
 
 
11. PRODUCTIVITY 
IMPROVEMENT BY CELLULAR 
MANUFACTURING: 
 
SMO  15 
Helper  0 
Workstation  15 
Tack time .34 
Target pieces  1744 
Efficiency  72% 
Loss per worker  25.05(mins) 
 
 
Fig: cellular layout [ref.12] 
 
 
 
 
 
 
 
 
0.00
0.10
0.20
0.30
0.40
0.50
0.60
Sl
ee
ve
 h
em
Tr
im
m
in
g
Si
ze
 L
ab
el
 S
ew
in
g
Bo
dy
 M
ar
k 
fo
r 
M
ai
n 
la
be
l
Tr
im
m
in
g
Series1
0.00
0.10
0.20
0.30
0.40
0.50
0.60
0.70
Series1
Page 831
  
12. DATA ANALYSIS OR 
COMPARISION OF TRADITIONAL 
LAYOUT AND CELLULAR LAYOUT: 
 
Fig: comparison [ref.12] 
13. CONCLUSION : 
From the above discussion we can say that cellular 
layout is very fruitful in competitive market. So for 
successful implementation of cellular layout 
company must concern different aspects of cellular 
layout. 
REFERENCES 
1.  http://rockfordconsulting.com/lean-       
manufacturing.htm 
2.  http://www.leaninnovations.ca/seven_types.html 
3.  The manufacturing pocket handbook by 
Kenneth W Dailey 
4.  en.wikipedia.org/wiki/5S_(methodology) 
5.  www.ashland.edu/~rjacobs/m503jit.html 
6.  www.systems2win.com/solutions/lean.htm 
7.  Product design & development by KARL T. 
ULRICH, STEVEN D EPPINGER 
8.  http://www.siliconfareast.com/cellular-
manufacturing.htm. 
9.http://www.mamtc.com/lean/building_cellularMf
g.asp 
10.   http://www.epa.gov/lean/thinking/cellular.htm 
11.  http://scholar.lib.vt.edu/theses/available/etd-
09132000-14380054/unrestricted/Etd.pdf 
12.  interstoff apparels ltd 
 
 
 
 
 
 
 
 
                                                        
 
 
 
 
 
 
 
 
 
0
10
20
30
40
50
60
70
80
90
100
Ef
fic
ie
nc
y …
Q
ua
lit
y 
A
lte
r …
W
IP
 (P
ie
ce
s)
Li
ne
 B
al
an
ci
ng
…
Ch
an
ge
ov
er
 ti
m
e…
Traditional 
Line
Modular Line
Page 832
                                                                                                                                                          Proceedings of the 
                                                                                         Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh  
 
Md.Ashrafuzzaman & Abdullah Al Maruf 
ashrafuzzaman.ipe@gmail.com 
almarufipe@gmail.com 
QFD APPROACH TO STUDY CUSTOMER REQUIREMENTS, 
CRITICAL SUPPLY CHAIN FACTORS AND A SYSTEM FOR                                                          
SUPPLY CHAIN PERFORMANCE MEASURE  
Md. Ashrafuzzaman* and  Abdullah Al Maruf* 
Department of Industrial & Production Engineering 
Shahjalal University of science & Technology 
A.B.M. Abdul Malek  and  A.M.M. Mukaddes 
Department of Industrial & Production Engineering 
Shahjalal University of science & Technology 
 
 
In the increasingly competitive markets, effective management of supply chain is a very crucial factor for the 
better performance of the organization and realization of customer expectation. In the modern era, performance 
measure has significant role get competitive advantage. This dissertation explores and investigates how 
Garments Accessories Industries (GAI) use supplies chain management to gain competitive advantage and 
increase the supply chain factors performance in the customer point of view. This dissertation objective is to 
determine critical customer requirements and prioritize them to determine the success factors to improve 
performance. In this paper we also show a system of SCM performance evaluation using transformation matrix 
called QFD. This paper also shows how to improving customer satisfaction by QFD approach and identify 
performance gapes from the customer viewpoint in SCM. Actually this dissertation measures and evaluates 
supply chain performance of manufacturing industry. Findings can be used for selection of GAI supply chain 
strategies. 
Key words: QFD, Supply chain, Performance measure, Critical supply chain factors, Performance gap 
1.INTRODUCTION
The comprehension of business processes interactions 
along supply chain is an important factor to succeed in 
the fast changing and competitive business arena[21]. 
In the era of globalization of markets and business 
process outsourcing, many firms realize the importance 
of continuous monitoring of their supply chain’s 
performance for its effectiveness and efficiency. It 
provides the management important feedback to 
monitor performance, reveal progress, diagnose 
problems and enhances transparency among the several 
tiers of the supply chain thus making a phenomenal 
contribution to decision making particularly in re-
designing business goals and strategies and 
reengineering processes [6].in this dissertation we show 
a system of performance evaluation using QFD 
SPECIALLY for the Garments Accessories industries 
in Bangladesh. 
2. OBJECTIVES 
 
Consolidating the concerns discussed in the previous 
section, the objectives of the summarize- 
 Determine the critical success factors in 
supply chain management that can provide 
competitive advantage. 
 Identify supply chain factor performance as 
well as overall supply chain performance as 
service perceived by the firm’s customers. 
 To define a customer-based improvement 
strategy based on the critical elements 
identified by surveyed needs and wants of the 
customer‘s. 
 
3. LITERATURE REVIEW 
 
Effective supply chain management (SCM) is treated as 
a key to building a sustainable competitive edge 
through improved inter-firm and intra-firm 
relationships (Gunasekaran et al. 2001; Webster 2002). 
A magnitude of benefits has been attributed to SCM, 
including increased market share, reduced cost, and 
Page 833
ISBN: 978-984-33-2140-4
  
enhanced customer relationship (Ferguson 2000). 
However, there is evidence to suggest this may be 
hyperbole rather than organizational reality (Thomas 
1999). Additionally, an international study of modern 
manufacturing practices reported only a moderate 
perceived effectiveness of SCM (Clegg et al. 2002). 
Thus, it is critical to develop an effectual measurement 
system for supply chain performance since it can 
facilitate a deeper understanding of the supply chain 
and improve its overall performance (Chen and Paulraj 
2004; Sharma and Bhagwat 2007)[13]. Following are 
some of the discussion about key terms of this 
dissertation 
Critical factors: Critical factors are those few things 
that must go well to ensure success for a manager or 
organization, and therefore may represent those 
managerial or enterprise areas that must be given 
continual attention. CFs include issues vital to an 
organization’s current operating activities and to its 
future success (Boynton and Zmud, 1984). 
Performance gap: This is a gap between the perceived 
performance and the expected importance of a factor 
(in this dissertation it is a supply chain factor). The 
performance gap provides an indication as to whether 
executives and managers are successful in translating 
their vision to their employees and hence such 
perception may give an indication regarding the degree 
of employees’ alignment with the organization’s vision. 
If a factor is critical and has a negative value of factor 
alignment (perceived performance is less than the 
expectation), then the organization may have a 
potential problem with that factor. Information on 
factor alignment allows executives to develop a 
strategy to overcome the challenges associated with the 
gaps between importance and performance. (Martilla 
and James, 1977). 
Quality Function Deployment (QFD): QFD is a 
comprehensive quality tool that can be used to uncover 
customers spoken and unspoken needs, and convert 
these needs to product or service design targets and 
processes (Akao, 1990). 
Performance measurement in SCM: Performance 
measurement can provide important feedback 
information to enable managers to monitor 
performance, reveal progress, enhance motivation and 
communication and diagnose problems. In SCM, 
performance measurement can facilitate inter-
understanding and integration among the supply chain 
members. It also provides insight to reveal the 
effectiveness of strategies and to identify success and 
potential opportunities. It makes an indispensable 
contribution to decision making in SCM, particularly in 
re-designing business goals and strategies and re-
engineering processes. [11] 
4. RESEARCH METHODOLOGY  
A research methodology has been developed in this 
section to form and guide the research activity in a 
structured way in order to carry out the dissertation. 
The case study has been carried out on Garments 
Accessories industries (GAI) in Bangladesh. In this 
dissertation we considered the Garments industry or 
Garments buying house as a customer of GAI in 
Bangladesh. We construct our QFD table or house of 
Quality according to our desired goal of this 
dissertation. 
4.1 The process to construct the QFD table 
A QFD relationship table or house of quality was 
prepared based on the model from Akao, 1990. Refer to 
Figure -1, below, which shows the structure of the QFD 
table. [14]: 
Step 1: Developing Customer needs 7 importance 
(refer to steps in Figure A6-1). The column on the left 
lists the ‘WHATs” or customer needs, These customer 
needs were obtained from the sources of data mentioned 
earlier in this appendix. In preparing the customer’s 
voice in the QFD table, it is important to distinguish 
between secondary and primary needs of the customer 
(Akao, 1990). In many case the customer’s need is a 
secondary item, and the primary need has to be imputed. 
For example, Ease of Returns was a secondary need, 
while the Primary need was After Sales Support. Next 
to the WHAT’s column, is the importance column. This 
state the importance of each customer need with a score 
of 1 to 5. The information is extracted from Table-1. 
Step 2: Developing the How’s: The row at the top of 
Table-1 shows the ‘HOWs” or important supply chain 
factors that would meet customer needs. These factors 
are the top gaps in supply chain management, from 
Table -5. 
Step 3: Interpretation of the information provided 
by the completed QFD table: The next step is to 
interpret the information in the QFD table. This is done 
by preparing a relationship matrix within the QFD table 
by identifying the performance gaps which are most 
crucial in meeting customer needs. The relationship 
matrix is prepared by indicating the strength of the 
relationship at each intersection of the customer needs 
and performance gaps. Refer to Table-1, below. The 
relationships are given based on the capability of each 
supply chain factor from the Literature Review and on 
this researcher’s experience. The ratings are as follows: 
1 -for very weak relationship, 2- for weak 
relationship, 3- for medium relationship,4- for 
Page 834
  
strong relationship,5- for extreme relationship, no 
relationship was given a rating of 0,and left blank. 
Indicated sign are shown figure by ل ,ن ,م , ,و  
However, the relationship at each intersection point is 
insufficient to make a decision on good opportunities 
for the GAI. Also crucial is the importance score of 
each customer need. Hence, a weighted scoring for 
each gap comprising importance and relationship was 
required. 
Step 4: Compute weighted score for each 
relationship: The weighted score for each relationship 
or cell is computed by multiplying the relationship score 
by the importance score. Refer to Figure 
Step 5: Select important How’s or critical supply 
chain factors: We identify critical supply chain factor 
by determining the absolute weight using following 
equation: Absolute weight=∑   (Each customer need 
importance score X relationship score at intersection). 
Highest value of absolute weight indicates as the most 
critical supply chain factor. Finally, the weighted scores 
are ranked, with the highest score being ranked as 
number 1, and so on. From the ranked list, it is possible 
to decide which supply chain factor, or critical gap, is 
most important to implement the completed QFD table, 
with the ranked critical supply chain gaps is shown in 
Table -5, below. 
 
Fig. 1: Model for House of Quality specially developed 
for this study. Guidelines:[14],[12] 
 
Step6: Develop house for the overall supply chain 
performance measure: Here we put value of 
impotence and performance data collected from 
Garment accessories industry as studied firm. In the 
house importance for row for actual and performance 
for performance row.  
Step 7: Determine the performance gap: we 
determine the gap by subtract the importance from 
performance and put this value into the table. 
5. DATA COLLECTION & ANALYSIS: 
  
Technique of Data collection: Data collection 
technique based on research attributes that will be 
measured and depend  on the attributes characteristic.  
So that, there are some tools that can be used to collect 
data, e.g.:[4]  
• Focus Group Discussion: This research used FGD 
as methodology to do analysis based on focus 
discussion from some  point of  view  that do really 
understand  about customer requirement toward  
successive supply chain factor  selection to make 
the supply chain management more efficient and 
responsive for Garments accessories industries of  
Bangladesh.  
• Documentation: This research needed document 
to get overall condition of supply chain 
management is it focus on externally or internally 
in the organization and the performance of the 
supply chain factors. And we also use this in the 
transformation matrix.  Besides that, 
documentation is also in physical evidence of 
activity, such as observation picture, interview, and 
others that related to research. 
• Observation: This research used observation to 
get data about field condition and  to assess 
perception and behavior toward to make the supply 
chain more competitive than other by evaluation of  
supply chain performance in GAI Bangladesh.  
• Questionnaire: This research used questionnaire 
to assess the requirement of Garments industry and 
buying house for Garments, performance 
evaluation for Garments accessories industries in 
Bangladesh, and make the relationship between 
supply chain factor and customer requirements.    
• Interview: This research used interview to know 
the perception, conception, information, 
suggestion, and expectation about overall condition 
of supply chain management of GAI of 
Bangladesh and performance of this organization. 
5.1 Analysis 
In the section of data analysis for this research first we 
developed the matrix for determine the rank of supply 
factors using absolute weight which is shown in table 1. 
Our main analysis for this research is under the 
following fundamental section of SCM figure 2. We 
analyzed the data which area studied from focused 
(internal & external) to their supply chain. 
 
Page 835
  
Fig. 2: Three fundamental section of supply chain 
management. Guidelines :[2][3].   
 
We also analyzed the data with respect to style of 
supply chain focusing area this theory developed by S. 
Soin(2003). The term Traditional ‘old style’ 
manufacturing company is used to describe a company 
that focuses its supply chain management activity (that 
is, considers them more important) on manufacturing-
type efforts (including quality), and other activity that 
occur prior to manufacturing such as supplier 
management, and procurement. This traditional 
manufacturing or internal focus is given priority by the 
company over supply chain activity that looks forward 
and allows closer connection with customers. Such a 
company can be termed as Traditional ‘old style’ 
manufacturing company or an internally focused 
company. .[14] 
The term progressive manufacturing company is used 
to describe a company that focuses its supply chain 
management activity (that is, considers them more 
important) on customer relationships type activity and 
information systems that connect with the customers 
(such as business to business Internet commerce). This 
external, or customer, focus is given priority by the 
company over supply chain efforts that look backward 
into the manufacturing process - these efforts can be 
construed as the company reaching out to connect and 
communicate better with customers. Such a company 
can be termed as a progressive manufacturing company 
or an externally focused company. [14]  
5.2 Supply chain factors Performance: 
Supply chain factor Performance for the studied firm 
‘MA, RP, MO’ is calculated in terms of quantitative 
value by dividing the total expected (importance) SCM 
factors performance level to the total actual SCM 
factors performance level. Here we followed the 
following steps to calculate the overall supply chain 
performance. These steps have been adapted and 
modified from Arditi and Lee (2003)[17]. Expected 
(importance) SCM factors performance & actual SCM 
factors performance is identified from the 
questionnaires administered to the studied firm ‘MA, 
RP, MO’ selected personnel those are related to the 
dissertation field we concern. 
 
Actual SCM factors performance = final importance 
weight of each customer requirements X Σ relationship 
value between WHAT and HOW for the Supply chain 
factors X actual SCM factors Performance………. (1) 
 
Expected (importance) SCM factors performance = 
final importance weight of each customer requirements 
X Σ relationship value between WHAT and HOW for 
the Supply chain factors X Expected (importance) SCM 
performance ………………………………………..(2) 
 
Total Actual SCM factors performance level = Σ Actual 
SCM factors performance………………………… (3) 
 
Total Expected (importance) SCM factors performance 
= Σ Maximum service performance……………… (4) 
 
Supply chain factors Performance = Total Actual SCM 
factors performance level / Total Expected 
(importance) SCM factors performance………….. (5) 
 
Referring to Figure ‘MA’, ‘RP’ and ‘MO’ which has 
been adapted from the overall QFD matrix structure 
(Figure 1) and build three matrix indicated by table 
2,3,4. and following steps provided by Arditi and Lee 
(2003), the Supply chain factors  Performance can be 
calculated by using Equation (5): 
Supply Chain Factors Performance of the firm, ‘MA’ 
= 6240.72 /11233.32 
= 0.555554 
= 55.55 %.( calculated from table 2) 
Supply Chain Factors Performance of the firm, ‘RP’  
= 8673.99/ 10870.07 
= 0.797970 
= 79.79 %.( calculated from table 3) 
Supply Chain Factors Performance of the firm ‘MO’  
= 9462.28/ 11240 
= 0.8418398 
= 84.18 %.( calculated from table 4) 
The result from the calculation shows the current 
quality service performance of the firm ‘MA’ is about 
55.55%. ‘MA’ is performing lower than ‘RP’, but 
greatly lower than ‘MO’. Therefore, it is very critical 
for the firm ‘MA’ to further improve its Supply chain 
factors  performance to higher level in order to ensure 
their customers are satisfied, thus provide long term 
sustainability and growth. 
 
 
 
  Supplier                    Enterprise              Customer   
SRM                        ISCM CRM 
      Source                          Strategic planning       Market 
 Negotiate                     Demand planning        Price 
 Buy                              Supply planning         Sell 
 Design collaboration    Fulfillment                 Call center 
 Supply collaboration    Field Service               Order 
management 
Page 836
  
Page 837
  
 
 
Page 838
  
 
Page 839
  
 
Page 840
  
 
Page 841
  
6. RESULTS AND DISCUSSION: 
Now we can make decision and set up a comment 
under the three section of supply chain management 
and the definition of old style manufacturing company 
and progressive manufacturing company. Here we also 
discussed about focusing area external or internal. 
6.1 Analysis and interpretation of SCM areas for 
company ‘MA’: This Company mainly gives priority 
on the procurement, accounting and the technology 
management over customer relationship management 
(CRM).  It also give priority to ICT &agile practice 
over HRM. Its important ranking on categories is 
followings: 
Procurement & Accounting-1, Technology 
Management-2, Customer Relationship Management-3, 
Information & Communication Technology-4, Lean & 
Agile practice-5. 
It is possible to make some conclusions and  
observations about company ‘MA’s behavior. 
Company ‘MA’ behaves like a Traditional ‘old style’ 
manufacturing company and its supply chain activity is 
internally focused. This company focused on the ISCM 
among the three section   of  SCM. 
 
6.2 Analysis and interpretation of SCM areas for 
company ‘RP’: Here this company give highest 
priority on customer relationship management(CRM). 
It’s important ranking  on categories are followings: 
Customer Relationship Management-1, Technology 
Management-2, Lean & Agile practice-3, Human 
Resource Management-4, Transportation-5. 
It is possible to make some conclusions and 
observations about company ‘RP’s behavior. Company 
‘RP’ behaves like almost a progressive manufacturing 
company and its supply chain activity is externally 
focused. This company focused equally on the ISCM 
& CRM among the three  section  of  SCM. 
 
6.3 Analysis and interpretation of SCM areas for 
company ‘MO’: Here this company also gives highest 
priority on customer relationship management (CRM). 
It’s important ranking on categories are followings: 
Customer Relationship Management-1, Procurement & 
Accounting-2,, Information & Communication 
Technology-3, Technology Management-4, Human 
Resource Management-5. 
It is possible to make some conclusions and 
observations about company ‘MA’s behavior: 
Company ‘MO’ behaves like a fully progressive 
manufacturing company and its supply chain activity is 
externally focused. This company focused on the ISCM 
among the three section   of SCM. For this reason 
performance of  SCM factors 84.18% for this company 
which is better than ‘MA’ &’RP’.All of this three 
company have give more attention on the highest  
performance gap which value is 5 or more than 2. 
6. Implications for practice: Based on the research 
findings, below is the summary of the suggestions to 
senior management at Garments accessories in 
Bangladesh on how they can enhance the efficiency 
and effectiveness of their supply chain management 
program: 
 There is a need for better supply chain knowledge, 
as many employees may be unaware of their 
company’s supply chain performance and its 
relationship to business performance.  
 Management needs to select strategies that focus 
on supply chain management externally to achieve 
competitive advantage and business success.  
 Management needs to analyze and understand their 
perceived critical gaps (and opportunities) in 
performance. After that they need to link these 
gaps to customer requirements using quality 
function deployment (QFD) methodology.  
7. CONCLUSION  
QFD is an effective technique that helps both 
manufacturing and non-manufacturing industries to 
improve their quality, overall supply chain 
performance, customer satisfaction, understanding the 
customers’ needs, benchmarking against competitors, 
and clear vision of customer, market intangible 
requirements, and other quality and business 
characteristics by integrating the voice of customer 
with the firm’s processes. The critical supply chain 
factors that need to be enhanced by the company 
according to their importance with respect to customer 
requirements      which is found by absolute weight 
table . This study had achieved its aims to identify the 
critical supply chain factors and determine the overall 
supply chain factors performance of Garments 
accessories industry in Bangladesh using QFD 
technique.  
It is recommended that future research should test this 
theory using a more quantitative research method for 
the purpose of statistical generalization. Future research 
can also try to understand if there are different behavior 
and characteristics of companies, such as traditional 
and progressive manufacturing companies. If the 
difference can be confirmed, it can lead to 
recommended strategies on how companies can 
improve performance. Most importantly, future 
research can try to understand if specific critical supply 
chain factors can contribute to competitive advantage 
and business success. 
Page 842
  
8. REFERENCES: 
1. Gunasekarana,*, C. Patelb, Ronald E.          
McGaugheyc  “A framework for supply chain                                
performance measurement”  Int. J. Production 
Economics 87 (2004) 333-347 
2. Heriberto Garcia, “A capability maturity 
model to assess supply chain performance”, 
Florida International University, 2009 
3. Sunil Chopra & Peter Meindl ,“Supply Chain 
Management(Strategy, planning,& 
Operation)”. Third Edition 2008 
4. Dr. Aries Susanty, Arfan Bakhtiar ST, 
Sriyanto ST. MT. “Customer preferences 
analysis for developing creativity in batik 
industry” International Seminar on Industrial 
Engineering and Management ,Diponegoro 
University, Semarang, Indonesia. 
5. Dr. Amihud Hari, Prof. Joseph E. Kasser,  
Prof. Menachem P. Weiss, “Lessons Learnt 
From the Applications of QFD to the 
Definition of Complex Systems”(System 
Engineering Evaluation Center (SEEC), 
Australia( the 16th International Symposium 
of the INCOSE, Orlando, FL., 2006) 
6. Nukala, S. and Gupta, S. M., "Performance 
Measurement in a Closed-Loop Supply 
Chain Network", Proceedings of the 2007     
Northeast Decision Sciences Institute 
.Conference,   Baltimore, Maryland, pp. 474-
479, March 28-March 30, 2007. 
7. D.li,*A.Mckay,**A.Depennington**and C. 
Barnes “A Web-based tool and a heuristic 
method for cooperation of manufacturing 
Supply chain decisions” Journal of Intelligent 
Manufacturing, 12, 433±453, 2001 # 2001 
Kluwer Academic Publishers. Manufactured 
in The Netherlands.**School of Mechanical 
Engineering, University of Leeds, Leeds LS2 
9JT, UK. 
8. Larry Lapide, “What About Measuring Supply 
Chain Performance?”  AMR Research 
               http://lapide.ASCET.com. 
9.  Felix T S Chan; H J Qi; H K Chan; Henry C 
W Lau; Ralph W. L. Ip “A conceptual model 
of performance measurement for supply 
chains.” Management Decision;[2003]41/7; 
pg.635-642                               
10. C. K. kwongand H. Bai “A fuzzy AHP 
approach to the determination of importance 
weights of customer requirements in quality 
function deployment”  Journal of intelligent 
Manufacturing , 13, 367-377,2002. 
11. I. Nakhai Kamalabadi, 1A. Bayat, 1P. Ahmadi, 
2A.Ebrahimi and 3M. Safari 
Kahreh,“Presentation a New Algorithm for 
Performance Measurement of Supply Chain by 
Using FMADM Approach” World Applied 
Sciences Journal 5 (5): 582-589, 2008. 
12. Akao, Yoji. "Development History of Quality 
Function Deployment". The Customer Driven 
Approach to Quality Planning and 
Deployment. Minato, Tokyo 107 Japan: Asian 
Productivity Organization. pp. 339. 
13. Lie-Chien Lin • Tzu-Su Li “An integrated 
framework for supply chain performance 
measurement using six-sigma metrics” 
Springer Science+Business Media, LLC 
2010.Software Qual J (2010) 18:387-406 
14. Sarvnandan S. Soin (2003) “Critical success 
factors in supply chain management  at high 
technology companies.” 
15. Kenneth Crow DRM Associates article “ 
customer focused development with QFD”. 
16. Arditi, D. and Lee, D.E. (2003). Assessing the 
corporate service quality performance of 
design build contractors using quality function 
deployment, Construction Management and 
Economics. 21: 175-185. 
17. Baba Md Deros, Norashikin Rahman, Mohd 
Nizam Ab. Rahman, Ahmad Rasdan Ismail 
and Ahmed Husam Said(2009),  “Application 
of Quality Function Deployment to Study 
Critical Service Quality Characteristics and 
Performance Measures.” European Journal of 
Scientific Research  ISSN 1450-216X Vol.33 
No.3 (2009), pp.398-410 
18. “Quality function deployment”  From 
Wikipedia, the free encyclopedia.  
19. Jong- Seok shin1 and Kwang-jae Kim(2000) 
“Complexity reduction of a design problem in 
QFD using decomposition” Journal of 
Intelligent Manufacturing (2000) 11, 339±354 
20. Marvin E. Gonzalez, Gioconda Quesada, Kent 
Gourdin and Mark Hartley(2008)”Designing a 
supply chain management academic 
curriculum using QFD and 
benchmarking”Quality Assurance in 
Education .Vol. 16 No. 1, 2008  pp. 36-60  
Emerald Group Publishing Limited 
21. Dr inŜ. Bogusław Śliwczyński( 2008) 
“Controlling in supply chain - tool for process 
integration” LogForum Vol. 4 Issue 2 No 3. 
22. Glenn H. Mazur ( June, 1994) “QFD for Small 
Business A Shortcut through the Maze of 
Matrices” Japan Business Consultants, Ltd. 
The Sixth Symposium on Quality Function 
Deployment Novi, Michigan. 
Page 843
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Md. Mosharraf Hossain,  
E-mail: mosharraf80@yahoo.com 
REDESIGNING CYCLE RICKSHAW WHEEL TO MINIMIZE 
ACCIDENT PROBABILITY AND SEVERITY 
 
 
Khairun Nahar 
Otobi Ltd., Gulshan 1, Dhaka 1212, Bangladesh 
 
Md. Mosharraf Hossain*, Khan Md. Ariful Haque, Md. Ariful Islam and Kh Safayet 
Hossain 
Department of Industrial & Production Engineering, Rajshahi University of Engineering & 
Technology, Rajshahi 6204, Bangladesh 
 
Md. Altaf Khan 
Akij Cement Company Ltd., Kadam Rasul, Narayongonj, Bangladesh 
 
 
This paper reviews the possible problem areas of non-motorized means of travel in Rajshahi city, 
particularly cycle rickshaw, with respect to the view of rickshaw pullers and passengers; and severity 
analysis. Accidents are more frequent now a day mainly caused by lack of rickshaw pullers’ adequate 
training and design of rear wheels; according to market analysis and reviews. Violent accidents are occurred 
while the rickshaws drive beside one another and it is observed that they made collisions and ultimately 
accident causes human injuries as well as cut off several spokes of the wheel. Additionally spokes are 
generally broken down frequently during riding on the rough roads. Redesigning of the wheel has been done 
on the basis of measured maximum load. The dimension of the new model was decided after studying the 
carried load of each spoke of the wheel. As five spokes were being used instead of forty two spokes, the 
reliability of the wheel is being increased considerably due to increased rigidity of the spokes.  Hub was 
designed in such a manner that the extension portion of the wheel is no longer responsible to make frequent 
accidents. As a result of changing design the problems are being solved.  
 
Key words: Redesign; Rickshaw; Accident Probability; Bearing life 
 
1. INTRODUCTION 
Cycle rickshaw is an important & major means of 
travel, particularly in small cities and amongst the 
urban areas (For short journey lengths) in 
Bangladesh. These are light weighted environment 
friendly vehicle. The people of certain class have 
these vehicles with affordable price as a principal 
income source. The mechanism of cycle rickshaw 
is served as a technical platform that encapsulates 
fundamental of problems in mechanics, vehicle 
dynamics, stability, motive power, etc. However in 
Bangladesh most rickshaws are assembled based on 
the general ideas without investigating the loads 
and the load bearing capacities. This causes 
frequent technical failure of rickshaws and due to 
lack of knowledge the rickshaw pullers are also 
involved in enhancing the accident probability. 
There are not many researches related to rickshaw. 
Chowdhury et al (1996), Vikhashu (2007) and 
Nahar et al (2010) addressed some technical 
problems related to rickshaw. However those are 
not adequate. This paper examines the mechanics 
of the cycle rickshaw by considering the possible 
factors. Major problem area is identified as the 
wheel of the cycle rickshaw. All dimensions and 
specifications of new model are then developed 
with computation of mechanics.  
 
2. PROBLEM SELECTION 
2.1 Need Analysis 
Market research is conducted to understand the 
present condition. To meet customer needs for the 
product survey is done. During the survey some 
basic questions (See Appendix A) are asked to the 
rickshaw pullers and as well as passengers. Based 
on the survey, problem related to wheels are 
identified as major problems and minor problems 
Page 844ISBN: 978-984-33-2140-4
  
and shown in table 1. Customer needs and their 
priority are provided in table 2. 
 
Table 1: Major (A) and Minor (B) problems 
A 
Rear 
Wheel 
Axle 
rim spoke Seat 
Chain-
spro-
cket 
B Light hood Driver seat packing 
Foot 
rest 
 
Table 2: Customer needs and their priority 
Customer Needs No. of Customer Priority 
Light Weight 11 3 
Less Cost 16 1 
High Endurance Limit 9 4 
Long Life 13 2 
Reliability 7 6 
Aesthetic 5 7 
Comfort 8 5 
 
Through this analysis it is identified that the major 
problem area is wheel with hub, spoke and ball 
bearing.  
 
2.2 Process Analysis 
Another type of analysis is Cause Effect Diagram 
(CE Diagram) that depicts defects, errors, or 
problems which has been identified and begins to 
analyze potential causes of this undesirable effect. 
Among the types of CE diagram the followings are 
being used to identify the problem region with their 
respectable causes- (i) Cause Enumeration and (ii) 
Process Analysis. 
 
 
 
Fig. 1: Requirements for rim design 
 
This diagram provides the information of the 
process of making the wheel from idea generation 
to final product development. 
 
3. DESIGN ANALYSIS & SELECTION 
To redesign the existing product, the cycle 
rickshaw wheel, for reducing accident severity &  
probability, the initial need is expressed in semantic 
language as a verbal request or requirement of the 
customers, in this case the rickshaw pullers & the 
passengers. Through graphical and analytical 
analyses; a physical model is being established. 
Some drawings are initially constructed considering 
possible problems & resolving techniques. Material 
selection is done on the basis of some design 
criteria such as yield strength, ultimate strength, 
elongation, density, modulus of elasticity, cost etc. 
Through mechanical analysis the design 
specifications are developed & correction over the 
layout is made. 
 
Measurements for mechanical property analysis 
consist of different dimensions of lengths, weight 
of different parts and rickshaw self weight. Then 
the reaction/supporting loads at both rear and front 
wheels are determined according to the law of 
mechanics. By using the reaction loads at each of 
the rear wheel’s the dimensions of the spokes are 
being calculated, i.e., the length and width of each 
spoke. Length of each spoke is found from the 
dimension of outer diameter of the hub. Outer 
diameter of the hub is determined by calculating the 
thickness of the hub according to the law of 
mechanics as the inner diameter is known from 
selected bearing’s outer diameter. 
 
3.1 Developing Ideas with Drawing 
Initially several rough drawings are made to figure 
out the ideas of resolving problems of cycle 
rickshaw wheel. 
 
 
 
Fig. 2: Initial drawing of wheel 
 
The drawing shown in fig. 2 is done by only 
considering the ideas of defined problems of 
extended portion of axle that causes the distortion 
of spokes of the wheels of other rickshaws. In that 
case the hub is designed in such a way (in fig. 2) 
that the axle extension is no longer visible. After 
that the spokes are replaced by five equally spaced 
spokes that are more reliable than spoke and are 
little subject to distortion. 
 
Page 845
  
But after developing this primary idea in the 
drawing the mechanical properties such as the 
material selection, static and dynamic load carrying 
capacities, bearing life etc. are being considered to 
compute the specifications of the spokes used in 
wheel and the hub’s required dimensions as well. 
The calculations show that the hub is not properly 
designed shown in the fig. 2, because it uses only 
one bearing that reduces the bearing life much less 
than the existing one and also caused by the 
increased bending moment with spokes at one end 
of the hub and only one bearing at another end of 
the hub.  
 
 
 
Fig. 3: Redesigned wheel 
 
Redrawing of the wheel is prepared by taking into 
account the mechanics for rickshaw wheels and 
finalized the drawing with specifications to 
generate physical model of wheels at fig. 3. The 
specifications of the modified model are developed 
by calculating different force calculations according 
to the laws of mechanics. The area of each spoke is 
calculated for the selected material from load 
applied to each wheel. The outer diameter of the 
hub is determined by computing the thickness of 
the hub assuming the inner diameter as the outer of 
the bearings used with hub. By getting two of the 
bearings in the hub which retains the bearing life 
more than the existing one and the maximum 
bending moment for the eccentric placement of the 
spokes the thickness of the hub is being calculated. 
 
3.2 Material Selection 
After that the material selection is done considering 
some significant properties of different possible 
materials. Possible materials those are nearly 
suitable for the wheel manufacturing purpose are 
selected and then prioritized them according to the 
required material property for rim. 
Priorities are given under score of 20 for each 
materials property. Over total priority of each 
material i.e. 200 score the % of priority is 
calculated. Amongst three competitive materials 
Aluminium Alloy with certain composition, which 
is conventionally used for rim manufacturing, is 
being selected in cycle rickshaw wheel 
manufacturing. 
 
 Properties of selected materials are provided in 
Appendix B in detail.    
 
3.3 Mathematical Calculation 
3.3.1 Design of Spoke                 
The testing result from universal testing machine 
for yield and failure of existing wheel shows that it 
can sustain about 14000 N loads. On behalf of this 
capacity the new design of wheel is made. 
 
 
Fig. 4: Sketch of load on each spoke 
 
The wheel is designed with five equally spaced 
spokes because more than five bars it causes 
reduction of cross-section area of each; thus the 
reliability of each spoke. And for less than that 
number the cross-section area is increased and thus 
the weight is also increased. 
 
At equilibrium, 
    + ∑Fy=0 so F' =3908.79 N 
Now, 
F' = σA = σbt, thus bt=15.39 mm2.  Where, A=area 
of the wheel bar & σ=254 N/mm2 
If the breadth of each spoke, b=25.4 mm than the 
thickness of each spoke, t= 1.82 mm. 
Having FS=3 for mild shock of ductile material and 
with trial & error basis the breadth of each spoke is 
determined as, b=25.4 mm and the thickness of 
each spoke, t= 1.82 mm. 
 
3.3.2 Hub Design 
 
 
 
 
Fig. 5: Redesigned hub 
Page 846
  
 
As the bearing is of the same number 6204, the 
designed wheel’s hub diameter (inner) is known.  
The designed wheel’s hub diameter (inner) is 
known from bearing number. The minimum length 
of hub is determined by required spaces for two 
bearings, one nut and clearance between two 
bearings. To determine the thickness of hub it is 
required to calculate the forces on different point of 
the hub (Fig. 6), applied forces are F1 and F2 and 
supporting loads are R1 and R2. Where the distances 
are AB=0.014m, BC=0.007m, CD=0.027m, 
DE=0.007m.  
 
 
 
Fig. 6: Forces on hub 
 
 
 
Fig. 7: Reaction forces on hub 
 
By determining the value of R1 from the figure of 
right most corner (Fig. 7), the unknown loads over 
the hub i.e F1 & F2 are calculated. Formulating with 
laws of mechanics, R1=6015 N, F1=5503.7N, 
F2=8694.29N. 
 
By using those values the thickness of hub is being 
determined with the established formula of 
maximum bending moment. In the Figure 8 the 
lower portion of the hub is considered as simply 
supported beam with breadth as same as the spokes 
breadth. Having maximum moment and with the 
known values of material strength and breadth the 
part thickness of the hub is being determined. The 
formula is- Maximum bending moment, M= σI /C= 
σbh2/6. By putting the known values, the unknown 
value i.e thickness of the hub, h, is determined as 
7.2mm.   
 
 
 
Fig. 8: Shear & Moment diagram for hub 
 
3.3.3 Impact of the loads 
Bearing life is calculated on basis of the loads that 
are practically applied to the wheel, that is, the load 
those are calculated in earlier section. In this case 
existing bearings of number 6204 ball bearing are 
used. 
 
Fig. 9: Forces on Bearing 
 
Where, 
      Applied forces on each wheel bearings, 
F=194.32 kg 
      Sprocket weight, W=0.5 kg 
      Rickshaw puller’s pulling force, P=465kg 
      Distances, d1=d2=0.5715 
      Vertical reaction forces on bearings are, RV1 & 
RV2         
      Horizontal reaction forces on bearings are, RH1 
& RH2 
According to law of mechanics, over vertical & 
horizontal forces we get RV1=194.32 kg, 
RV2=194.57 kg, RH1=232.5 kg & RH2 =232.5 kg. At 
point B of the Fig. 9 there are two bearings so that 
the forces on the bearing are needed to calculate 
with respect to practically applied load. Practically 
applied loads are computed for each bar i.e F′ 
=620.3N & spoke support R1=954.54 N.  
 
In the Fig. 10, F=F1+F2 and F1 & F2 are the loads 
applied through the bearings at point C and D. 
again from laws mechanics we get F1=948.555N & 
F1=955.780N, where F= 194.32 kg is a calculated 
value of applied load on bearings.   
 
Page 847
  
 
 
Fig. 10: Forces on Bearing 
 
By using the forces on bearings the reaction forces 
of bearings are computed to determine the radial 
load of the bearings.  
 
 
 
Fig. 11: Forces on Bearing 
 
Here the calculated values are Rv1=953.87N, 
Rv2=952.90N, Rh1= 1689.05N & Rh2=589.4N.  
Now, Reaction at bearing D, 
Rd=√(Rh12+RV12)=1788.93N 
Reaction at bearing C, Rc=√ (Rh22+RV22)=1120.45N 
Basic load rating for 6204 ball bearing, 
C= 12700N, Co=6200N 
With no axial thrust, X=1 & Y=0 
and Frd=Fad = Rd=1788.93N 
The equivalent dynamic load, 
P = XFrd+YFad= 1788.93N 
Bearing life at C, 
Ld = (C/1.5P)3= 106.01 million rev 
and Lhd = L*106/60*60= 40.9 months 
With no axial thrust, 
X=1 & Y=0, Frc=Fac = Rc=1120.45N 
The equivalent dynamic load, 
P = XFrc+YFa = 1120.45N 
Bearing life at D, Lc= (C/1.5P)3  = 431.5 million rev 
and Lhc = L*106/60*60= 166.6 months.               
The life of the bearings is 40.9 months and 166.6 
months at points D and C respectively. 
 
4. COST OF WHEEL 
By considering monthly production 2400 Pcs, all 
fixed costs and variable costs per product is 
calculated, thus the total cost is calculated.     
Total fixed cost of redesigned product: TK 4.587 
Total variable cost: TK 380.66  
Total cost of redesigned product: TK 385.24 per 
unit. 
 
5. RESULTS 
The redesigned wheel is shown in Fig. 3. 
Specifications of the wheel, hub, bearings are as: 
number of spokes, 5; thickness of each spoke, 1.82 
mm; breadth of each spoke, 25.4 mm; rim is same 
as the existing one; hub diameter (inner) is same as 
6204 ball bearing’s outer diameter; hub thickness, 
7.2 mm, the expected life of the bearings are 40.9 
months and 166.6 months. 
 
6. DISCUSSION AND CONCLUSION 
Redesigned wheels are constructed at the university 
lab. It is tested for functionality. At the initial stage 
it is found that the wheels are performing well with 
comfort to the rickshaw puller. This hub design 
does not have any extended portion as the existing 
extension of rear axle. This will prevent the 
collision with the other rickshaws while overtaking 
each other. It is beyond this study to investigate the 
reliability, longevity, product life cycle and 
accident probability due to long cycle time or 
product life cycle. However it is believed that due 
considering the engineering design criteria, this 
redesigned wheel will serve the following purposes: 
 Redesigned wheel will reduce the accident 
severity. 
 This will minimize the problem of spoke 
distortion and axle position. 
 Wheel longevity will be comparatively 
high. 
 Wheel cost is reasonable. 
 Outlook is good enough. 
Overall it can be said that the redesigned wheel 
with accessories are good enough to prevent the 
accident severity and the maintenance cost will be 
reduced. 
 
REFERENCES 
1. Ullman D. G., The Mechanical Design Process, 
Second Edition, PP 293-308, McGraw-Hill, 
Inc. 
2. Beer F. P. and Johnston E. R. Jr., Vector 
Mechanics For Engineers (Statics & 
Dynamics), third Edition, Tata McGraw-Hill, 
Inc. 
3. Chowdhury A. R., Prahan, C. K. and 
Mukherjee A. K., (1996), Evaluation of 
occupational health problem of cycle rickshaw 
pullers and redesign of cycle rickshaw on 
economical principles, Redesign of cycle 
rickshaw. 
4. Vikhashu S., (2007), Cycle Rickshaw Project 
Research and Finding Product design 
Department, Srishti School of Art Design and 
Technology. 
5. Edwards, K. S. Jr. and Mckee R. B., (1991), 
Fundamentals of Mechanical Component 
Design, EWD., McGraw-Hill, Inc. 
Page 848
  
6. Nahar K, Khan M. A. and Hossain K. S., 
(2010), “Redesigning Cycle Rickshaw Wheel 
to Minimize Accident Probability and 
Severity”, Unpublished B.Sc. Engg. Thesis, 
Rajshahi University of Engineering & 
Technology, Rajshahi. 
7. Pytel A. and Singer F. L., Strength of 
Materials, Fourth Edition, Harper & row. 
8. Hasin M. A. A., Quality Control and 
Management, pp 40-48, 84-86, 102-112, 
Bangladesh Business Solutions. 
9. Montgomery D. T., Introduction to Statistical 
Quality Control, Third Edition, pp 154-156, 
John Wiley & Sons. 
10. Allen J. S., Kirskna D. and Wilson D. G., 
(2002), Human Power, Technical Journal of 
the IHPVA, Number 53, Spring 2002. 
11. Mondal B.N., Green Solution to the Urban 
Transport System, Research planning & 
business Dept), Central Mechanical Research 
Institute India. 
12. Gadepalli S, (2006), Rickshaw in the new 
millennium, daily star june 30, 2006 
13. http://www.nariphaltan.virtualave.net/MAPRA
.pdf (17/10/2010) 
14. http://www.alibaba.com/showroom/cycle-
rickshaw.html (17/10/2010) 
15. http://www.injuryjournal.com/article/S0020-
1383(05)00516-4 (17/10/2010) 
16. http://www.cmse.ed.ac.uk/MSE3/Topics/MSE
3-nonferrous.pdf (17/10/2010) 
17. http://www.cyclerickshaw 
wikipedia,_33_4_06.pdf                   
18. http://www.Rickshaw/Bicycle%20Components
,Bicycle%20Saddles 
19. http://www.Rickshaw/Pedicab%20Rickshaws.
mht 
20. http://www.Rickshaw/Rickshaw%20Manufact
uring.mht 
21. http://catalog.indiamart.com/cat_ifmare.htm 
22. http://www.tntech.edu/me/courses/Zhang/ME3
0103110/Chap11pt4.ppt 
 
Appendix A (Questionnaire) 
To identify the problems related to cycle rickshaw, 
some basic questions were asked to the rickshaw 
puller, passengers and vendors. The questions are 
provided here. 
1. What are the major problems that you face 
with your rickshaw? 
2. How longer the rickshaw give service? 
3. How much reliable it is?  
4. What about the failure rate?  
5. How much load you can carry? 
6. Do you feel that the maintenance cost is ok 
with you? 
7. Do you think rickshaw need improvement? 
8. What parts should be modify and why? 
Many other effective questions are done to clarify 
exact needs during market research. 
 
APPENDIX B (Priority to Materials)  
 
 Materials Property Stainless 
steel 
Given 
priority 
1 Tensile strength, MPa 500 12 
2 Yield strength, MPa 200 5 
3 Endurance limit, GPa 280 14 
4 Elongation, % Not found 0 
5 Modulus of elasticity,  200 GPa 15 GPa 
6 Density, g/cc 7.5-8.5 12 
7 Melting temp., ºC 2500 5 
8 Cost per lb 0.8-2.5 12 
9 Hardness, BHN 52 2 
10 Corrosion  10 
 Total priority  101 
 % over total priority  40.5 
SI Materials Property Al Alloy 
(Conv.) 
Given 
priority 
1 Tensile strength, MPa 373 8 
2 Yield strength, MPa 254 12 
3 Endurance limit, GPa 200 10 
4 Elongation, % 39.9% 5 
5 Modulus of elasticity,  200 GPa 14 GPa 
6 Density, g/cc 7-8 11 
7 Melting temp., ºC 550 14 
8 Cost per lb .2-.5 15 
9 Hardness, BHN 150 16 
10 Corrosion  7 
 Total priority  111 
 % over total priority  55.5 
SI Materials Property Al Alloy Given 
priority 
1 Tensile strength, MPa 200 5 
2 Yield strength, MPa 300 8 
3 Endurance limit, GPa 100 7 
4 Elongation, % 15-25% 8 
5 Modulus of elasticity,  90 GPa 10 GPa 
6 Density, g/cc 3 5 
7 Melting temp., ºC 700 10 
8 Cost per lb 3-4 7 
9 Hardness, BHN 52-100 12 
10 Corrosion  14 
 Total priority  86 
 % over total priority  43 
 
Page 849
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
Corresponding Author:  Mamunur Rashid 
Email: raskinipe@gmail.com 
. 
SOFTWARE BASED EVALUATION OF OVERALL LINE EFFECTIVENESS 
(OLE) OF A GARMENT’S INDUSTRY 
 
Mamunur Rashid*, A.B.M Abdul Malek  
Department of Industrial and Production Engineering. 
             Shahjalal University of Science and Technology, Sylhet-3114, Bangladesh.  
 
Abstract: 
Competition is worldwide and markets are fast becoming price sensitive. These challenges are forcing 
companies to implement various productivity improvement efforts to meet the needs of ever changing 
market demand. The total productive maintenance (TPM) has provided quantitative metric overall 
equipment effectiveness (OEE) for measuring the productivity of individual production equipment. In 
future, an extremely important objective is to improve the performance of the whole process or line 
instead of concentrating only on a single machine. The traditional metrics like throughput and utilization 
rate measures, only the part of the performance of manufacturing equipment. They are not helpful in 
identifying the problems underlying improvements needed to increase productivity. In this paper, an 
attempt is made to use overall line effectiveness (OLE) as an index of performance evaluation in the 
production line of a garment’s industry. Overall Line Effectiveness (OLE) is the common machinery and 
Process metrics utilized through a Lean manufacturing Initiative. OLE= Availability X Performance X 
Quality. A detailed methodology for determining the overall line availability, overall line performance 
and overall line quality is presented, and also OLE.  
Development Platform: User Interface: Visual Studio (C#). Backend Database: SQL Server 2005 
 
Key Words: Plan Production Time, Operating Time, Down Time, Availability, Performance, Quality. 
 
 INTRODUCTION: 
Overall Line Effectiveness (OLE) is the common 
machinery and Process metrics utilized through a 
Lean manufacturing Initiative. OLE is a "best 
practices" way to monitor and improve the 
effectiveness of garment’s industry. OLE is simple 
and practical. It takes the most common and 
important sources of manufacturing productivity 
loss, places them into three primary categories and 
distills them into metrics that provide an excellent 
gauge for measuring the position of the garments 
industry- and how to  improve!  OLE is frequently 
used as a key metric in TPM (Total Productive 
Maintenance) and Lean Manufacturing programs and 
gives a consistent way to measure the effectiveness 
of TPM and other initiatives by providing an overall 
framework for measuring production efficiency.OLE 
is a tool that combines multiple manufacturing issues 
and data points to provide information about the 
process. It is an all-inclusive benchmarking tool that 
serves to gauge the various sub-components of the 
manufacturing process (i.e., availability, 
performance and quality)—and used to measure 
Page 850
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
 Corresponding Author:  Mamunur Rashid 
Email: raskinipe@gmail.com 
actual improvements on 5S, WCM, Lean 
Manufacturing, TPM, Kaizen and Six Sigma. When 
using OLE with these management systems the 
benefits become tangible and noteworthy.  After all 
factors are taken into account, the OLE result is 
converted in percentage. The results (in %), 
therefore, can be regarded as a preview of the 
existing production efficiency of a particular line, 
cell or machine.  As we all know, manufactured 
goods are a result of a complex production process—
and without the proper measuring tools and formula, 
expect your business to run blindly even in the light 
of day. Having the right metrics, OLE provides a 
window to analyze out-of-the-ordinary issues and 
gives an established framework for improving the 
whole manufacturing process. There are dozens of 
formulas, systems and metrics being used to improve 
the whole manufacturing process, but only OLE 
correctly reduces complex production problems into 
simple, easy-to-follow steps in handling data and 
information. The OLE tool helps to methodically 
improve the process using basic measurements. OLE 
is a very simple metric that immediately indicates the 
current status of a manufacturing process. Somehow 
it also becomes a multifaceted tool allowing 
understanding the effect of the various issues in the 
manufacturing process and how they affect the entire 
process. The biggest advantage of OLE is that it 
allows companies to have separate business 
functions by applying/using a single, easy-to-
understand formula. OLE is by far the most effective 
benchmarking tool in making sound management 
decisions.  
OBJECTIVES: 
 To measure Overall Line Effectiveness 
(OLE) of a Garment’s Industry 
 To measure Overall Line Availability 
 To measure Overall Line Performance 
 To measure Overall Line Quality 
 To identify bottleneck  
 To store data for future use 
RESEARCH BACKGROUND: 
Software Based Evaluation of Overall Line 
Effectiveness (OLE) of a Garment’s Industry has 
several advantages and overcome some traditional 
problems. 
 Minimized calculating time  
 Monitoring data any time  
 Minimized human endeavor 
 Real time production information visibility    
Now a day’s some software companies are making 
software on the basis of production information 
system and human resource information system etc. 
They make software according to companies 
demand. Although that software is very much strong 
in structure, that software is not cheapest and easier 
to maintain, so most of the garment industries are not 
capable to use this software. Basically the research of 
making this tool is come from current production 
information.  
USEFUL FORMULAS:  
OLE =Overall Line Availability x Overall Line 
Performance x Overall Line Quality 
 Overall Line Availability: 
 Overall Line Availability is a general term that is 
used to describe the amount of time over a specific 
period that the system resources are available in the 
wake of component failures in the system. 
Availability refers to the machine being available for 
production when scheduled (and only when 
scheduled). Overall Line Availability takes into 
account Down Time Loss, which includes any events 
that stop planned production for an appreciable 
length of time- the ratio of the actual production time 
to the planned production time. All planned stops 
and breakdowns will reduce the availability ratio, 
including set-up times, preventive maintenance, 
breakdowns and lack of operators, material 
shortages, and changeover time. While it may not be 
possible to eliminate changeover time, in most cases 
it can be reduced. The remaining available time is 
called Operating Time.  
 
Page 851
 Corresponding Author:  Mamunur Rashid 
Email: raskinipe@gmail.com 
Overall Line Performance:  
The performance measure identifies production lost 
when the machine is running at less than optimal 
speed, by comparing actual cycle times against the 
ideal. Overall Line Performance takes into account 
Speed Loss, which includes any factors that cause 
the process to operate at less than the maximum 
possible speed, when running. Loss of production 
due to underutilization of the machinery. In other 
words, losses are incurred when the equipment is not 
run with full speed.  Examples include machine 
wear, substandard materials, misfeeds, and operator 
inefficiency. The remaining available time is called 
Net Operating Time. Short, unregistered, stops may 
affect the performance ratio as well.  
Overall Line Quality:  
Finally, quality takes account of the time wasted by 
producing something that does not meet quality 
standards (rejects and rework). The percentage of 
good pieces to total pieces made, becomes the 
quality measurement. The amount of the production 
that has to be discharged or scrapped. Quality takes 
into account Quality Loss, which accounts for 
produced pieces that do not meet quality standards, 
including pieces that require rework. The remaining 
time is called Fully Productive Time. Our goal is to 
maximize Fully Productive Time. 
How do I calculate OLE for my entire industry? 
 Here are two reasonable options for calculating 
garment’s industry OLE:  
 Calculate OLE Using a Straight Average 
 Calculate OLE Using a Weighted 
Average  
Calculate garment’s industry OLE Using a 
Straight Average: 
 The simplest method of calculating OLE scores of 
single line by averaging OEE of all machines in that 
line.  
The simplest method of calculating OLE scores of a 
garment’s industry by averaging OLE of all line in 
that industry. 
 If in a garment’s industry there are 6 lines and every 
line has 70 machines then the calculation would be:  
Overall Line Availability(OLA): 
Overall Line Availability can be measured by 
straight average of the availability of all machines in 
that line. 
OLA= ( (Availability1+Availability2+Availability3+ 
…………+Availability70) /70) *100% 
Overall Line Performance(OLP):  
Overall Line Performance can be measured by 
straight average of the performance of all machines 
in that line. 
OLP= ((Performance1 +Performance2 
+Performance3+………. + Performance70)/70) 
*100% 
Overall Line Quality(OLQ):  
OLQ= (Good Pieces / Total Pieces) *100% 
Overall Line Effectiveness (OLE): 
OLE = (Overall Line Availability x Overall Line 
Performance x Overall Line Quality) *100% 
 
Overall Line Effectiveness (OLE) for industry 
would be: 
OLE= ((OLE1 + OLE2 + OLE3+ OLE4 + OLE5 + 
OLE6)/6) *100% 
Calculating Availability, Performance, and 
Quality for single machine:  
Page 852
 Corresponding Author:  Mamunur Rashid 
Email: raskinipe@gmail.com 
The Formulas for single machine:  
Availability: 
Availability takes into account Down Time Loss, and 
is calculated as: 
Availability = (Operating Time / Planned Production 
Time)*100% 
Performance: 
Performance takes into account Speed Loss, and is 
calculated as: 
Performance = ((Total Pieces / Operating Time) / 
Ideal Run Rate)*100% 
Quality: 
Quality takes into account Quality Loss, and is 
calculated as: 
Quality = (Good Pieces / Total Pieces) *100% 
Effectiveness of single machine would be:  
Effectiveness takes into account all three Factors, 
and is calculated as: 
Effectiveness of single machine = (Availability x 
Performance x Quality) *100% 
OEE Glossary: 
Term  Definition  Implication  
Actual Cycle Time  The actual time to produce one 
piece. In OEE, calculated as 
Operating Time divided by Total 
Pieces.  
Used in calculating OEE 
Performance. A variation of the 
calculation uses Actual Run Rate 
instead.  
Actual Run Rate  The actual rate of production, 
when it is running. In OEE, 
calculated as Total Pieces 
divided by Operating Time.  
Used in calculating OEE 
Performance. A variation of the 
calculation uses Actual Cycle 
Time instead.  
Adjustment Time  Productive time lost while 
tweaking equipment. See Setup 
and Adjustments.  
Can be a significant loss factor, 
and in many factories is not 
directly measured.  
Availability  One of the three OEE Factors. 
Takes into account Down Time 
Loss (events that stop planned 
production for an appreciable 
amount of time).  
Must be measured in an OEE 
program, usually by recording 
the duration of Down Time 
Events.  
Breakdowns  Lost time due to equipment 
failure. One of the Six Big 
Losses.  
Contributes to OEE Down Time 
Loss (reduces OEE 
Availability).  
Changeover Time  Lost time due to swapping of 
equipment, connections or 
materials. See Setup and 
Adjustments.  
A prime candidate for 
improvement for most 
companies.  
Cycle Time  The time to produce one piece.  Inverse of Run Rate.  
Design Cycle Time  See Ideal Cycle Time.  See Ideal Cycle Time.  
Down Time Loss  Production time lost to 
unplanned shutdowns.  
One of the three OEE Losses 
(reduces OEE Availability).  
Major focus area for 
improvement.  
Event  In OEE, a production loss which 
must be categorized.  
OEE’s purpose is to clarify the 
nature and effect of Events.  
Fully Productive Time  Actual productive time after 
ALL losses are subtracted.  
What OEE measures – the true 
bottom line of your facility's 
efficiency.  
Page 853
 Corresponding Author:  Mamunur Rashid 
Email: raskinipe@gmail.com 
Good Pieces  Produced pieces that meet 
quality standards (without 
rework).  
Used in calculating OEE Quality.  
Ideal Cycle Time  Theoretical minimum time to produce one 
piece. The inverse of Ideal Run Rate.  
Used in calculating 
OEE Performance. A 
variation of the 
calculation uses Ideal 
Run Rate instead.  
Ideal Run Rate  Theoretical maximum 
production rate. The inverse of 
Ideal Cycle Time.  
Used in calculating OEE 
Performance. A variation of the 
calculation uses Ideal Cycle 
Time instead.  
Lean Manufacturing  Quality philosophy that strives to 
minimize consumption of 
resources that add no value to 
the finished product.  
OEE can be a key tool and 
metric in Lean Manufacturing 
programs.  
Nameplate Capacity  The design capacity of a 
machine or process.  
Used to determine Ideal Cycle 
Time or Ideal Run Rate.  
Net Operating Time  True productive time before 
product quality losses are 
subtracted.  
Equipment time losses normally 
are much larger than defect 
losses.  
OEE (Overall Equipment 
Effectiveness)  
Framework for measuring the 
efficiency and effectiveness of a 
process, by breaking it down into 
three constituent components 
(the OEE Factors).  
OEE helps you see and measure 
a problem so you can fix it, and 
provides a standardized method 
of benchmarking progress.  
OEE Factors  The three constituent elements of 
OEE (Availability, Performance, 
and Quality).  
Often it is more important to 
focus on the three OEE Factors 
than the consolidated OEE 
metric.  
OEE Losses  The three types of productivity 
loss associated with the three 
OEE Factors (Down Time Loss, 
Speed Loss, and Quality Loss).  
The goal is to relentlessly work 
towards eliminating OEE Losses.  
Operating Time  Productive time available after 
Down Time Losses are 
subtracted.  
Operating Time increases as 
Down Time Losses are reduced.  
Performance  One of the three OEE Factors. 
Takes into account Speed Loss 
(factors that cause the process to 
operate at less than the 
maximum possible speed, when 
running).  
Must be measured in an OEE 
program, usually by comparing 
Actual Cycle Time (or Actual 
Run Rate) to Ideal Cycle Time 
(or Ideal Run Rate).  
Planned Production Time  Total time that equipment is 
expected to produce.  
Benchmark that OEE is 
measured against.  
Planned Shut Down  Deliberate unproductive time.  Excluded from OEE 
calculations.  
Plant OEE  Consolidated OEE calculation as 
applied to an entire plant.  
There are different methods of 
calculating Plant OEE. Pick the 
one that makes sense for your 
company.  
Plant Operating Time  The time the factory is open and 
capable of equipment operation.  
Planned Shut Down is subtracted 
from Plant Operating Time to 
reach the OEE start point – 
Planned Production Time.  
Page 854
 Corresponding Author:  Mamunur Rashid 
Email: raskinipe@gmail.com 
Process  A sequence of activities that 
starts with some type of input 
(e.g. raw materials) and ends 
with some type of output (e.g. a 
product).  
OEE can be used across a wide 
range of different processes, 
although it is most often 
associated with discrete 
manufacturing.  
Production Rejects  Rejects produced during steady-
state production. One of the Six 
Big Losses.  
Contributes to OEE Quality Loss 
(reduces OEE Quality).  
Quality  One of the three OEE Factors. 
Takes into account Quality Loss 
(parts which do not meet quality 
requirements).  
Must be measured in an OEE 
program, usually by tracking 
Reject Pieces.  
Quality Loss  Percentage of pieces which do 
not meet quality requirements.  
One of the three OEE Losses 
(reduces OEE Quality). OEE 
views defects in terms of lost 
time.  
Reduced Speed  Cycle where the process is truly 
running (as opposed to a Small 
Stop), but is slower than 
“expected”. One of the Six Big 
Losses.  
Contributes to OEE Speed Loss 
(reduces OEE Performance).  
Reject Pieces  Produced pieces that do not meet 
quality standards.  
Used in calculating OEE 
Quality.  
Rework Pieces  A subset of Reject Pieces, that 
can be reworked into Good 
Pieces.  
OEE does not make a distinction 
between pieces that can be 
reworked and pieces that are 
scrapped.  
Root Cause Analysis  A method of resolving a non-
conformance, by tracing back 
from the end failure to its 
original (root) cause.  
The basic tool for understanding 
and eliminating the sources of 
productivity losses.  
Run Rate  The production rate when 
actually producing (running).  
Inverse of Cycle Time.  
Setup and Adjustments  Time lost configuring 
equipment. One of the Six Big 
Losses. See also Adjustment 
Time and Changeover Time.  
Contributes to OEE Down Time 
Loss (reduces OEE Availability). 
Tracking Setup Time is critical 
to reducing this loss.  
Six Big Losses  Six categories of productivity 
losses that are almost universally 
experienced in manufacturing:  
Breakdowns, Setup and 
Adjustments, Small Stops, 
Reduced Speed, Startup Rejects, 
and Production Rejects.  
Drill down into the three OEE 
Factors, and you will reach the 
Six Big Losses. Measure your 
process with OEE, and improve 
your process by addressing the 
Six Big Losses.  
Small Stop  A brief pause in production, but 
not long enough to be tracked as 
Down Time. One of the Six Big 
Losses.  
Contributes to OEE Speed Loss 
(reduces OEE Performance).  
SMED (Single Minute 
Exchange of Dies)  
Program for reducing setup time. 
Named after the goal of reducing 
setup times to under ten minutes 
(representing time with one 
digit).  
Often a part of programs to 
improve OEE Availability.  
Speed Loss  Production time lost to 
equipment running below 
maximum rated speed.  
One of the three OEE Losses 
(reduces OEE Performance). 
Usually the most difficult of the 
Page 855
 Corresponding Author:  Mamunur Rashid 
Email: raskinipe@gmail.com 
OEE Losses to analyze.  
Startup Rejects  Rejects produced while 
equipment is adjusted for 
production. One of the Six Big 
Losses.  
Contributes to OEE Quality Loss 
(reduces OEE Quality).  
Takt Time  Production rate needed to meet 
customer demand.  
Where sales and business 
planning meets the factory floor.  
Theoretical Cycle Time  See Ideal Cycle Time.  See Ideal Cycle Time.  
Total Pieces  Total of all produced pieces.  Used in calculating OEE Quality.  
TPM (Total Productive 
Maintenance)  
Maintenance system covering 
the life of all equipment: 
planning, manufacturing, 
maintenance and improving 
performance.  
OEE is a metric for defining 
equipment effectiveness in a 
TPM program.  
Visual OEE™  Plant floor real-time display of 
live OEE data for maximum 
team involvement.  
Visual OEE™ displays make 
improvement everyone's job.  
World Class OEE  90.0% Availability  
95.0% Performance  
99.9% Quality  
85.0% OEE  
A composite OEE number means 
very little without the total 
context.  
 
  
 
 
WHY OLE? 
OLE is used for 
 Lean implementation 
 Root Cause Analysis 
 Motivation 
 Identify bottle neck  
 Real time production information 
 Productivity improvement  
 Measuring the efficiency of decision making 
units 
 Optimized production technology(OPT) 
 
Lean implementation: 
It is important in a lean manufacturing implementation 
to use the correct tools at the right time. Many lean 
implementations have failed because organizations 
failed to grasp a deep understanding of all lean 
concepts.  
OEE is a powerful lean manufacturing tool, especially 
when combined with other tools using an integrated 
approach.  
Steps to achieve lean systems-  
 Design a simple manufacturing 
system 
 There is always room for 
improvement 
 Continuously improve 
 Measure (Overall Line 
Effectiveness (OLE) is a set of 
performance metrics that fit well in 
lean environment because it helps 
to identify the waste.) 
Root Cause Analysis: 
 is applied starting with the most severe loss 
categories. 
Page 856
 Corresponding Author:  Mamunur Rashid 
Email: raskinipe@gmail.com 
Cause & Effect Diagram- 
The cause & effect diagram is the brainchild of Kaoru 
Ishikawa, who pioneered quality management. The 
cause and effect diagram is used to explore all the 
potential or real causes (or inputs) that result in a 
single effect (or output). Causes are arranged 
according to their level of importance or detail, 
resulting in a depiction of relationships and hierarchy 
of events. This can help you search for root causes, 
identify areas where there may be problems, and 
compare the relative importance of different causes. 
The C&E diagram is also known as the fishbone 
diagram because it was drawn to resemble the 
skeleton of a fish, with the main causal categories 
drawn as "bones" attached to the spine of the fish, as 
shown below. 
 
 
 
Figure: Cause & Effect Diagram 
 
 
 
 
Real time production information: 
Real-time data denotes information that is delivered 
immediately after collection. There is no delay in the 
timeliness of the information provided. Real-time data 
is often used for navigation or tracking the process. It 
helps management to monitor the effectiveness of the 
industry. It is easy to take immediate decision based 
on information. It is very easy to identify strength and 
weakness of the process.  
Productivity Improvement: 
One of the major causes of company's decline is low 
productivity. Failure to meet targeted productivity can 
result to high costs per unit, hence higher prices, and 
services, not competitive enough on the market. Many 
businesses try very hard to remain competitive in the 
market. Therefore, it is important for businesses to 
implement strategies to make improvements in 
productivity levels. Businesses can make productivity 
improvement by improving OLE. 
Optimized Production Technology (Opt): 
An objective of OPT is to maximize utilization of the 
bottlenecks……………….. 
The OPT principles  
1. Balance flow not capacity 
2. …………………………….. 
3. ………………………………. 
4. ………………….. 
5. ……………………….. 
6. Bottleneck’s govern both throughput and 
inventories 
7. ……………………………………. 
Application of opt principals: 
1. Identify bottlenecks   
2. ……………….. 
3. …………… 
CONCLUSION:  
The OLE solution gives us good intelligence about 
how many of each type of product we can put through 
this machine in a given timeframe. An overall OLE 
figure emerges when the three elements are multiplied 
together, and a world class OLE is generally accepted 
to be 85 percent. That doesn’t sound too strenuous 
until we realize how the multiplier works. If all three 
elements were 90 percent, the overall OEE would be 
only 72.9 percent (90 percent of 90 percent of 90 
percent). In practice the accepted world class 
standards are not uniform across the three factors, with 
world class availability being recognized as 90 
percent, speed 95 percent and quality 99.5 percent to 
achieve an overall 85 percent. OEE provides data 
specifically about the manufacturing line, and as such 
is but a tool to identify the current state. Where overall 
line effectiveness really comes into its own is when 
Page 857
 Corresponding Author:  Mamunur Rashid 
Email: raskinipe@gmail.com 
the results of OLE calculations are used to compare 
the performance of manufacturing lines, an assembly 
line involving a number of machines, or individual 
production shifts, as a part of a continuous 
improvement program. The first hand experience of 
companies that have implemented OLE technology 
solutions demonstrates its effectiveness. 
 
 
 
 
 
REFERENCES: 
1. www.vorne.com 
2. www.oee.com 
3. www.emeraldinsight.com 
4. Womack, James P.; Daniel T. Jones, and Daniel 
Roos (1990). The Machine That Changed the 
World.  
5. Holweg, Matthias (2007). "The genealogy of lean 
production". Journal of Operations Management 
25 (2): 420–437. doi:10.1016/j.jom.2006.04.001. 
6. wordnetweb.princeton.edu/perl/webwn 
7. Ishikawa, Kaoru (1990); (Translator: J. H. 
Loftus); Introduction to Quality Control; 448 p; 
ISBN 4-906224-61-X OCLC 61341428 
8.  Hankins, Judy (2001). Infusion Therapy in 
Clinical Practice. pp. 42.  
Page 858
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: M.A. Islam,  
E-mail: aminulislam@mme.buet.ac.bd  
TENSILE AND ELECTRICAL PROPERTIES OF WOOD SAW DUST 
REINFORCED POLYMER MATRIX COMPOSITES 
 
M. Faruk Hossain1 and M.A. Islam2 
 
1 Postgraduate Student and 2 Professor 
Materials and Metallurgical Engineering Department, BUET, Dhaka-1000 
 
 
 
 
Polymer matrix composites, reinforced with various types of fibers, are being widely used to reduce the 
overall weight of structures because of their good combination of various properties such as high strength to 
weight ratio, good fatigue properties, corrosion resistance, etc. However, most of the polymeric materials are 
not bio-degradable. As a result, demands of natural fiber reinforced composites are increasing day by day. 
Considering this, initiative was taken to develop wood saw dust reinforced polyester matrix composites with 
varying proportions (0, 5 and 10% by weight) and sizes (coarse and medium size particles) of wood saw 
dust. The developed composite samples were tested in Instron Universal Testing Machine to characterize 
their tensile behaviours and breakdown voltages were measured using 100 kV capacity high voltage testing 
machine. Experimental results showed a gradual decrease in tensile strengths with increase in both the fiber 
content and particle size. Similar to tensile strength, breakdown voltages were also found to decrease, 
however, the effect of fiber contents or particle sizes on breakdown voltages was not so pronounced. 
 
Keywords: Polymer matrix composites, Wood saw dust, Reinforcement, Fiber size, Tensile properties, 
Breakdown voltage.    
 
1. INTRODUCTION 
 
Wood is a combination of cellulose fiber and lignin. 
The cellulose fiber provides strength and the lignin 
acts as glue that bonds and stabilizes the fiber. With 
the growing economic competition and the 
ecological pressure, the past decade has seen a 
renewed interest in developing more efficient 
reinforcements along with relatively lower overall 
production cost. Cellulose based fibers are 
relatively cheaper and can meet many requirements 
for making the products to be economical. They are 
made from recoverable resources and thus may add 
bio-degradability to plastics [1]. So, throughout the 
whole world, there is also a good potential for the 
use of natural fibers/particles as reinforcing fillers 
in polymeric materials. Short-fiber, i.e. wood saw 
dust reinforced polymeric composites have gained 
importance due to considerable processing 
advantages and improvement in certain mechanical 
properties. The utilization of ligno-cellulosic 
materials in the production of polymeric 
composites is attractive particularly because of low 
cost/high volume applications. Bio-degradable 
ligno-cellulosic fillers possess several advantages 
compared to inorganic fillers, such as lower density, 
greater deformability, lower abrasiveness and cost 
[2–4]. The use  of  saw dust as a  reinforcement  for  
unsaturated  polyester resins has been limited 
compared to mineral  glass  fibers  or  calcium  
carbonate.  The main drawbacks of wood particles 
are their relative low degradation temperature and 
their hygroscopicities, which weaken their adhesion 
with hydrophobic polymers. However, wood fibers 
show very good mechanical properties such as 
tensile strength and Young’s moduli [5]. To 
improve mechanical, thermal, electrical properties 
of saw dust reinforced polymer matrices, soft wood 
and hard wood fiber can be used.   
 
Because of various attractive properties, polymer 
composites filled with natural ligno-cellulosic 
fibers have attracted the attention of many 
researchers and technologists [6-9]. As a result, 
both polymer matrices and natural filler systems 
have been widely investigated [10]. As a matter of 
fact, Oksman and Lindberg [11] as well as the team 
of Liao [12] studied the mechanical behaviours of 
composites based on polyethylene and wood flour 
samples [11,12]. On the other hand, Zaini et al. [13] 
and Kaci et al. [14,15] investigated the mechanical 
behaviours of polypropylene/wood flour 
composites. Some authors examined also the 
Page 859
ISBN: 978-984-33-2140-4
  
mechanical behaviours of various polymer based 
flour reinforced composites [16]. The electrical 
properties of this type of composites with 
chemically treated wood flour have been 
investigated by the team of Mansour [17]. 
 
Improvement in mechanical, electrical and thermal 
properties have resulted interest in wood saw dust 
polymer matrix composite materials in many 
industrial applications, including light weight, high 
strength parts for the automotive and aerospace 
industries, containers, sporting goods, thermal and 
electrical insulators, switch board and circuit board. 
Many studies have been published concerning the 
properties and processing conditions of various  
thermoplastics with wood fibers/particles, but there 
is not much literature available on the reinforcing 
of thermosetting polymers with  those fillers. These 
fillers might reduce the tendency of the resin to  
crack during cure and reduce resin  shrinkage [18]. 
The current study deals with the evaluation of the 
mechanical and electrical properties of composite 
materials of unsaturated polyester filled with wood 
saw dusts. 
 
2. EXPERIMENTAL   
 
2.1  Materials 
The matrix was polyester resin and the reinforced 
materials were wood saw dusts obtained from 
sawing of three types of trees available in 
Bangladesh (Kerosin, Garjon and Gamari). The 
proportions of saw dust in test samples were 0%, 
5% and 10% by weight. In order to know the 
effects of particle sizes on various properties of the 
developed composites, saw dusts of medium (250 
to 500 µm) and coarse (above 500 µm) particle 
sizes were selected for this research work. The 
initiator was methyl ethyl keton peroxide, which 
was taken 1.5% by weight with respect to the total 
weight of the mixture. Before additing saw dust in 
to the liquid polyester, they were dried at 100oC in 
an oven for 2 hours. The apparent density (DA) and 
true density (DT) of various wood raw dusts are 
presented in Table 1. 
 
        Table1. Densities of the wood saw dusts. 
 
 
 
 
 
 
 
 
 
2.2  Compounding and Moulding 
The composite mixtures of polyester with sawdust 
(without chemical treatment) were prepared directly 
in a beaker (volume capacity 250 cm3) for about 5 
minutes. The compositions of the composite mixtures 
are given in Table 2. Before casting of the composite 
mixtures into moulds, vacuum-degassing was carried 
out to remove bubbles or any sort of dissolved gases 
inside the mixtures for 12 minutes. After vacuum-
degassing peroxide (hardener) was mixed with the 
polyester-saw dust mixture. At last stage, the mixture 
was taken for degassing for another 2 minutes. The 
paste was filled in a metal mold (50 mm diameter 
and about 3 mm thickness) for electrical breakdown 
voltage test. In another batch, mixtures prepared 
following the above mentioned procedure were 
filled in a mould of dimensions 115 mm length, 10 
mm width and 7 mm thickness for making tensile 
test specimens. Each sample was cured at room 
temperature for 24 hours. 
 
Table 2. Compositions of polyester-wood saw dust 
composites. 
 
Sample 
Code 
 
Matrix Filler (Wood saw 
dust) 
Filler 
(wt%) 
 
P(0) Polyester Nil (virgin 
polyester) 
0 
GMM Polyester Gamari  medium 5 & 10 
GMC Polyester Gamari  coarse 5 & 10 
GRM Polyester Garjon  medium 5 & 10 
GRC Polyester Garjon  coarse 5 & 10 
KRM Polyester Kerosin  medium 5 & 10 
KRC Polyester Kerosin  coarse 5 & 10 
 
2.3  Electrical Properties 
Breakdown voltages were measured using 100 kV 
capacity high voltage testing machine to 
characterize their insulation behaviours. The size of 
the specimen was 50 mm diameter and 3 mm 
thickness. 
 
2.4  Mechanical Properties 
Three samples of each group were used to 
determine tensile properties. The tensile test was 
performed in Instron Universal Testing Machine to 
characterize their tensile behaviours at a cross-head 
speed of 2 mm/min according to ASTM D3039 
standard (rectangular specimens). The tensile load, 
stress and modulus were computed from the stress-
strain curves of the composites. The size of the 
specimen was 114×10×6 mm. 
 
 
 
Types of 
Wood 
DA(g/cc) DT(g/cc) 
Kerosin  0.40 1.33 
Gamari  0.35 0.86 
Garjon  0.70 1.34 
Polyester  - 1.40 
Page 860
  
3. RESULTS AND DISCUSSION 
 
3.1  Macrostructures 
The macrostructures of the as-cast samples of 
polymer matrix composites containing various 
types of fillers (Gamari, Garjon and Kerosin saw 
dusts) are shown in Fig. 1. In these macrographs, 
dispersions of particles inside the matrix are clearly 
visible. 
 
 
 
 
 
 
 
 (a)                                 (b) 
 
                                     
 
 
 
 
 
(c)                            (d) 
 
 
 
 
 
 
 
      (e)                                    (f) 
 
 
 
 
 
 
      (g) 
Fig. 1. Macrographs of cast samples (a) P(0), (b) 
GMM, (c) GMC, (d) GRM, (e) GRC, (f) KRM and 
(g) KRC. 
3.2  Electrical Test 
The breakdown voltages for polyester reinforced  
with different concentrations of untreated wood 
saw dusts were measured at a fixed frequency (50 
Hz) in high voltage testing machine (100 kv). The 
effects of proportions of wood saw dusts on 
breakdown voltages of the composites are 
illustrated graphically in Figs. 2 & 3. From these 
figures, it is clear that a gradual decrease in 
breakdown voltage is resulted with increase in both 
the fiber content and particle size of the wood saw 
dusts used. The reason of deterioration in 
breakdown voltages of the wood saw dust 
reinforced polyester based composites is that wood 
saw dust exhibits polar nature, whereas the nature 
of the polyester is non-polar [19]. So, in polyester-
saw dust composites, adhesion between the two 
materials is expected to be rather poor. Besides this, 
the breakdown voltage of wood is significantly 
lower than that of polyester. Increase in the fiber 
contents also decreases matrix material in the 
composites. So, the breakdown voltage also 
decreases for all wood saw dust reinforced 
composites.  
 
 
 
Fig. 2. Breakdown voltage (kV) versus %fiber 
curves of medium saw dust reinforced composites. 
 
 
 
Fig. 3. Breakdown voltage (kV) versus %fiber 
curves of coarse saw dust reinforced composites. 
 
 
 
 
 
 
 
 
0
5
10
15
20
25
0 5 10 15
B
re
ak
do
w
n 
vo
lt
ag
e
% fiber particles
Gamari 
medium
Garjon 
medium
Kerosin 
medium
0
5
10
15
20
25
0 10 20
B
re
ak
do
w
n 
vo
lt
ag
e
% fiber particles
Gamari 
coarse
Garjon 
coarse
Kerosin 
coarse
Page 861
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
From Figs. 2 & 3, it is seen that  the effect of 
particle size on breakdown voltage  of  medium size 
(250 µm to 500 µm) saw dust  reinforced 
composites are comparatively higher than that of 
coarse size saw dust (500 µm to above) reinforced 
composites. Because adhesion between medium 
size particles and polyester are better than that 
between coarse size particles and polyester, which 
is shown in Fig. 4. Woods were easily burned and 
created pores (marked by arrows) when they were 
tested. But this is not occurred when virgin 
polyester was tested is shown in Figs. 5 and 6. 
 
 
 
 
 
 
 
 
(a) Gamari                  (b) Garjon 
 
 
 
 
 
 
 
 
(b) Kerosin              (d) Virgin polyter 
 
 
 
 
 
 
 
 
 
 
 
 
 
(a) Gamari                 (b)  Garjon                                                     
 
 
 
 
 
 
 
 (c) Kerosin           (d) Virgin polyester 
 
 
 
 
 
3.3  Tensile Test 
The tensile strength vs. % of filler graphs are 
shown in the Figs. 7 & 8. It shows that the effect of 
proportion of the reinforcement particles, i.e. wood 
saw dusts on the load bearing capacity of the 
composites developed. From this tensile test results 
it is observed that there is a gradual decrease in 
tensile strengths with increase in both the fiber 
contents and particle size used for making the 
composites. Because, with increase in saw dust 
contents, mismatch areas between polyester matrix 
and reinforcing particles increased, which 
ultimately caused formation of early cracks with 
subsequent decrease in the maximum tensile tensile 
load bearing capacity before failure. For the same 
reason, coarse particle reinforced composites were 
also showed inferior tensile strengths. 
 
 
 
Fig. 7. Tensile strength (MPa) versus %fiber curves 
of medium size saw dust reinforced composites. 
 
0
20
40
60
0 10 20Te
ns
ile
 s
tr
en
gt
h
% fiber particles
Gamari 
mediu
m
Garjon 
mediu
m
(a) 
(b) 
Fig. 4. Micrographs showing (a) medium 
and (b) coarse grain saw dust reinforced 
composites. Note: Coarse saw dusts caused 
poor dispersion.  
Fig.  5. Photographs showing different types of   
wood and virgin polyester before electrical test.            
Note: No porosity/crack is visible in wood/pure 
polyester samples 
 
Fig.  6. Photographs showing different types of   
woods and virgin polyester after electrical test.            
Note: Pores are formed in the pure wood 
sample (marked by arrows, whereas polyester 
sample remained unaffected. 
 
Page 862
  
 
 
Fig. 8. Tensile strength (MPa) versus % fiber 
curves of coarse saw dust reinforced composites. 
When more and more particle is added, resin 
particles are separated by the reinforced particles. 
Only reinforced particles cannot give enough 
strength. So, the strength of composites gradually 
decreases.  From Figs. 7 & 8 it is seen that  the 
tensile strength of  medium size (250 µm to 500 
µm) saw dust  reinforced composites are 
comparatively higher than that of coarse size saw 
dust (500 µm to  above) reinforced composites. 
Because, adhesion between medium size particles 
and polyester are better than that between coarse 
size particles and polyester is shown in Fig. 4. It is 
also seen that the density of the fiber content in 
composites has a very small effect on the tensile 
strength. Tensile strength depends on both 
reinforcement particle size and its percentage. 
4. CONCLUTIONS 
The experimental results lead to the following 
conclusions:  
 
Addition of wood saw dust in polyester causes the 
tensile strength of the virgin polyester to decrease 
significantly. However, the electrical property, i.e. 
breakdown voltage of the virgin polyester is very 
similar to that of the 5% wood dust polyester 
composites. So, untreated 5% wood saw dust 
polyester composites can be used as an insulating 
material, i.e. switch board, circuit board, etc. 
 
5. REFERENCES 
1. Bledzki Andrzej, K. and Faruk, O. (2006), 
Injection moulded microcellular wood fiber-
polypropylene composites,  37(1), pp. 1358-1367.  
2. Takase, S. and Shiraishi N. (1989), Studies on 
composites from wood and polypropylenes, Journal 
of Applied Polymer Science, 37(2), pp. 645–659. 
3.  Felix, J.M. and Gatenholm, P. (1991), The 
nature of adhesion in composites of modified 
cellulose fibers and polypropylene, Journal of 
Applied Polymer Science, 42(1), pp. 609–620. 
4. Rozman, H.D., Ismail, H. and Jaffri, R.M., 
Aminullah, A. and Mohd Ishak, Z.A. (1998), 
Mechanical properties of polyethylene-oil palm 
empty fruit bunch composites,  37 (4), pp. 495–507. 
5.  Hill, C.A.S. and Abdul Khali, H.P.S. (2000), 
Effect of fiber treatments on mechanical properties 
of coir or oil palm fiber reinforced polyester 
composites, Journal of  Applied Polymer Science, 
78(1), pp. 1685–1697. 
6. Rozman, U.D., Tay, G.S., Abukar, A. and 
Kumar, R.N. (2001), Tensile properties of oil palm 
empty fruit bunch-polyrethane composites, Journal 
of polymer Science, 37(1), pp. 1759–1765. 
7.  Chtourou, H., Riedl, B. and Ait-Kadi, A. (1992), 
The surface modification of cellulose, Journal of 
Reinforced  Plastic Composites, 11(1), pp. 372. 
8.  Marcovich, N. E., Reboredo, M. M. and 
Aranguren, M. I. (2005): Lignocellulosic materials 
and unsaturated polyester matrix composites, 12(1), 
pp. 3–24. 
9.  Belgacem, M. N. (2005), Surface modification 
of cellulose fibres, 15(1), pp. 114–121. 
10.  Ferreira, F. C., Curvelo,  A. A. S., Mattoso,  L. 
H. C. (2003),  Preparation and characterization of 
benzylated sisal fibers, Journal of Applied Polymer 
Science, 89(1), pp. 2957– 2965. 
 11. Oksman K. and Lindberg H. (1998), Influence 
of thermoplastic elastomers on adhesion in 
polyethylene-wood flour composites, Journal of 
Applied Polymer Science, 68(1), pp. 1845–1855. 
12.  Liao, B., Huang, Y. and Cong, G. (1997), 
Influence of modified wood fibers on the 
mechanical properties of wood fiber-reinforced 
polyethylene, Journal of Applied Polymer Science, 
66(1), pp. 1561–156. 
13.  Zaini, M. J., Fuad, M. Y. A., Ismail, Z., 
Mansor,  M. S. and Mustafah, J. (1996), The effect 
of filler content and size on the mechanical 
properties of polypropylene/oil palm wood flour 
composites, Polymer International, 40 (1), pp. 51–
55. 
14.  Kaci, M., Cimmino, S., Silvestre, C., Duraccio, 
D., Benhamida, A. and Zaidi,L.(2006),  Ethylene 
butyl acrylate glycidyl methacrylate terpolymer as 
an interfacial agent for isotactic 
poly(propylene)/wood flour composites,  291, pp. 
869–876. 
0
10
20
30
40
50
0 10 20
Te
ns
ile
 s
tr
en
gt
h 
 
% fiber particles
Gamari 
coarse
Garjon 
coarse
Kerosin 
coarse
Page 863
  
15.  Kaci, M., Zaidi, L., Benhamida, A., Cimmino, 
S. and Duraccio, D. (2006), Ethylene n-butyl 
acrylate glycidyl methacrylate terpolymer as 
compatibilizer for isotactic polypropylene/wood 
flour composites, 103(1), pp. 251–256. 
16.  Xu, B., Simonsen, J. and Rochefort, W. E. 
(2001), Creep resistance of wood-filled 
polystyrene/high-density polyethylene blends, 
Journal of Applied Polymer Science, 79(1), pp. 
418– 425. 
17.   Mansour, S. H., Asaad, J. N., Abd-El-Messieh, 
S. L. (2006), Synthesis and characterization of 
brominated polyester composites. Journal of 
Applied Polymer Science, 102(1), pp. 1356–1365. 
18.  Paauw, M. and Pizzi, A. (1993), Journal of 
Applied Polymer Science, 50(1),  pp. 1287. 
19.  Miguez Suarez, J.C. (2003), studies of tensile 
fracture surfaces of polypropylene sawdust 
composites, Polymer Testing, 22, pp.  821-827. 
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Page 864
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: M.S.J. Hossain,  
E-mail: shahriar.jahan.hossain@gmail.com 
 
THE TRENDS OF ENVIRONMENT FRIENDLY PRODUCT DESIGN 
IN BANGLADESH 
 
 
M.S.J. Hossain* 
Rajshahi University of Engineering and Technology, Rajshahi 6204, Bangladesh. 
Ph. +8801713403546, E-mail: shahriar.jahan.hossain@gmail.com 
 
M. Iqbal  
Shahjalal University of Science and Technology, Sylhet, Bangladesh. 
Ph. +8801552428379, E-mail: iqbalm_ipe@yahoo.com 
 
 
Environmental awareness continues to rise, and customers of all types are realizing the importance of eco-
friendly products which are essential to protect our planet. Eco-designer creates designs that are demanded 
by markets. Green design rules are needed to support the implementation of environmental features in the 
practical design situation. Green design or Design for Environment (DfE) is a field of product design 
methodology that includes tools, methods and principles to help designers reduce environmental impact. The 
main objective of this work is to compile a set of DfE principles that are useful during the design process. 
Later the trends of environment friendly product and process design in Bangladesh are studied. Today, many 
industries in Bangladesh are aware of green design and implementing DfE principles. The present situations 
about the Green Design trends in some of the leading consumer goods manufacturers, Unilever Bangladesh, 
PRAN-RFL Group and Rahimafrooz were studied. Moreover the Government’s recent initiatives concerning 
DfE are discussed in this article. This article may help the product designers a lot during eco-friendly design 
and to compare them with some market leaders. Though the list of compiled DfE principles is based on best 
practices, further work is needed to expand the list. 
 
Key words: Green Design; Environment; Design Guidelines; DfE 
 
1. INTRODUCTION 
 
Environmental issues are becoming more and more 
important and Design for Environment (DfE) seems 
to be the most effective way of dealing with 
environmental concerns. Design for environment 
(DfE) is defined as systematic consideration of 
design performance with respect to environmental, 
health, and safety objectives over the full product 
and process life cycle (Ray and Guzzo 1993, 
Jeganova et al. 2004). Only in recent years, people 
have realized the importance of environmental 
protection. People are concerned about the context 
they are living in and the way people make use of 
resources. An important entrepreneurial challenge 
is to match products and services not only to the 
requirements of the market, but also to those of the 
environment. When products are being planned, the 
relevant ecological requirements and risks must be 
determined by considering both the needs of the 
market and the technologies available. Key 
requirements at the product planning stage are 
energy and material efficiency, and the 
environmentally compatible disposal of individual 
components. During product design, environmental 
aspects are taken into account with respect to 
material preparation, manufacturing, installation, 
operation, maintenance and dismantling (Schindler 
Group 2002). While environmental considerations 
have always been part of the design process, 
environmental awareness continues to become a 
more pressing imperative. 
 
1.1 Objectives 
The main objective of this research is to review the 
literature related to Design for Environment and 
hence compile the DfE rules, so that Eco-designers 
can easily take advantage of getting DfE principles 
at a glance.  
 
Page 865
ISBN: 978-984-33-2140-4
  
A lot has been written about Design for 
Environment, but less has been said about how it 
should be implemented. This paper presents few 
case studies about how Design for Environment is 
currently being implemented. That is the next target 
of this research is to study and observe the present 
scenario of implementing DfE principles in some 
leading industries as well as during creating 
environmental laws in Bangladesh. 
 
1.2 Literature Review 
 
A great number of researches are being going on 
for compiling the product design guidelines for 
protecting the environment. A growing number of 
managers believe that there are tangible advantages 
to incorporating environmental concerns into 
product design decisions. The research of Murray 
(2005) is about the issue of industrialization and the 
environment and the role of product design in the 
supply of products which do not have a negative 
environmental impact, in their production, use or 
disposal.  
 
Some studies are concerned about the trends of 
using DfE guidelines in different industries. One of 
these studies demonstrates the application of Eco-
Design techniques in the re-design of a fish tank air 
compressor. This application aims the reduction of 
components, the minimization of raw materials and 
the manufacture processes and tends as main focus 
the minimization of environmental impact in the 
development of new products. This air compressor 
was awarded the first prize in the Product Project 
category in the ECODESIGN Award – 
FIESP/CIESP 2004 (Platcheck, 2008). Lenox, in 
his Doctoral thesis (Lenox et al. 1999) explores the 
efforts by four electronics firms to implement 
Design for Environment (DfE) practices within 
product development teams. 
 
Many of the articles focus on the selection of raw 
materials which may be recyclable or collected 
from sustainable sources. In 2006 Medina discussed 
the role of eco-design tools in materials selection 
presenting some results of a six-month case study 
on Eco-design and Recycling Strategy. The 
different groups in charge of different automobile 
sectors worked together in simultaneous 
engineering at the design, prototyping and assembly 
line and achieved a recycling rate of 95% and 
incorporated over 18 Kg of recycled plastic 
(Medina, 2006). 
 
Some research papers are based on life-cycle 
assessment of the product and concerned about the 
end-of-life strategies. Jeganova researched and 
proposed how to integrate Life Cycle Design in 
product design and development process at Alfa 
Laval industry. The study investigated external and 
internal driving forces and implementation barriers 
around life cycle design at Alfa Laval (Jeganova et 
al. 2004). Rose, in his doctoral thesis (Rose, 2000) 
developed methodologies that aid in formulating 
the end-of-life strategies across a wide range of 
products. The analysis of current end-of-life 
practices identifies improvements to product design 
that reduce the impact of manufactured goods on 
the environment. The product end-of-life strategies 
include reuse, service, remanufacture and recycle. 
The research compares the strategies these 
companies have taken in implementing new 
environmental policies and to discover the most 
streamlined and cost-effective method for moving 
towards environmentally friendly product designs. 
On the other hand, reducing the quantity of waste 
for disposal and saving natural resources are main 
drivers for the introduction of the European 
Directive on waste electrical and electronic 
equipment (Walther et al. 2010). This policy 
focuses on an extension of the producer 
responsibility (EPR) to the end-of-life-phase of 
their products. 
 
In a paper (Bras 1997), a number of options and 
environmental issues were illustrated which 
companies and organizations seeking to incorporate 
in product design. A brief overview and 
classification of a number of approaches for 
reducing the environmental impact has been given 
in this paper. In 1996 Kaila and Hyvarinen 
described the way of environmental issues that are 
being integrated into the product design of the 
Switching Platforms unit of Nokia 
Telecommunications. Switching Platforms is 
implementing Design for Environment by 
integrating environmental issues into its product 
design through influencing points found in the 
product process (Kaila and Hyvarinen, 1996). 
 
Today, the world’s community is very concerned 
about shearing of the knowledge on DfE. In 2009 
Pitt and Lubben develops a framework for 
Education for Sustainable Development (ESD) that 
includes a ‘concentric’ view of Sustainable 
Development (SD). It is used to evaluate an 
intervention aimed at including sustainability, 
particularly the social dimension, in design tasks in 
the subject Design & Technology (D&T) in 
England and Wales, and in the Netherlands (Pitt 
and Lubben 2009). 
 
Research of Jeswiet and Hauschild deals with three 
sections: Green House Gas emissions and 
environmental impacts, Design for Environment 
(DfE) and toxic substances to be avoided in design. 
All three parts must be addressed by the Eco-
Designer in any design situation. Second and third 
Page 866
  
sections give the eco-designer rules, which can be 
applied in many design situations (Jeswiet and 
Hauschild, 2008). 
 
Environmental awareness continues to rise among 
customers of all types. Consumer, SMB, and 
enterprise are realizing that the IT products they 
acquire and use on a daily basis need to be designed 
with a different set of criteria in mind. IT users 
expect reduced operating costs as well as more 
predictable disposal costs at the end of the product 
life cycle. Creative product design is the first step 
in a product life-cycle strategy with the goal of 
developing environmentally friendly products for 
customers of all types (Eastwood, 2007). To protect 
the environment researches are running not only for 
the sustainability but also for economies of 
redesign. With the rapid development of electronics 
and semiconductor technology, the life cycle of 
personal computers is getting shorter. To solve the 
problem, a study has been employed on economic 
benefit analysis of disassembling personal 
computers to reduce the cost of product upgrading 
and to help to protect environment and save 
resources (Tseng and Chen, 2004). At Dell, 
environmental opportunities and challenges are 
considered at every stage of the product life cycle 
from design and development, manufacturing and 
operations, to product use and recovery (Dell, 
2010). 
 
 
 
Fig. 1: Product life cycle (Source: Eastwood 2007, 
adapted from HP) 
 
Not only product design but also all sectors of 
modern technology are going to be concerned about 
the environment. For example, Cools tried to 
express the method of shifting towards 
environment-friendly modes of transport. In the 
study, he adopted Q-methodology as the technique 
to segment people, and to ascertain which 
approaches and determinants matter to medium 
distance travel (Cools, 2009). 
 
2. RESEARCH METHODS 
 
When incorporating an environmental viewpoint 
into the design of materials and structures of a 
product, the entire context of the design process 
must be reconsidered in order to integrate 
environmental aspects into a set of other design 
aspects. This kind of process is known as 
“Integrated Life Cycle Design” (Sarja et al. 1999). 
The eco-designer creates designs that are demanded 
by markets. A designer cannot control market 
forces but must be cognizant of them. To enable the 
designer to work with market demands, and 
translate them into product characteristics in an 
environmentally friendly way, DfE rules are needed 
to support the implementation of environmental 
features in the practical design situation. 
 
In this paper different DfE guidelines have been 
compiled from many articles and internet websites, 
and summarized into seven basic principles. The 
last principle is totally a new concept in DfE which 
has been introduced based on the present scenario 
and requirement of environment awareness 
programs. 
 
The case study of this research is based on 
observation of three leading industries in 
Bangladesh, how they are introducing the DfE 
principles in their production system. These are, 
PRAN-RFL Group, which is an agro based 
consumer goods manufacturer; Rahimafrooz, which 
is basically a wet battery manufacturer and 
Unilever Bangladesh, a world’s leading consumer 
goods manufacturer. Information has been collected 
from the internet websites and some med-level 
management personals of these manufacturers. 
3. RESULTS & DISCUSSION 
 
Different researchers provide DfE guidelines in 
different ways. But all of these guidelines can be 
classified into main seven principles which are 
summarized in table 1. Six of them are compiles 
from different articles (Telenko et al. 2008, Jeswiet 
and Hauschild 2008, Eastwood 2007) but the 
Principle G is a new concept in this area.  
Table 1. The Seven DfE Principles 
Principle A Ensure sustainability of resources 
Principle B Ensure healthy inputs and outputs 
Principle C Ensure minimal use of resources in 
production and transportation phases 
Principle D Ensure minimal use of resources 
during use 
Principle E Ensure appropriate durability of the 
product and components 
Principle F Enable disassembly, separation, and 
purification 
Principle G Ensure appropriate training program 
for all stages of individuals in the 
value chain in order to enhance 
consciousness about environment 
 
Page 867
  
The Government of Bangladesh (GOB) is taking 
necessary initiatives to regulate the industries to 
follow the DfE principles by creating or modifying 
the environmental regulations. For example, 
recently the GOB banned Polyethylene shopping 
bags, Asbestos as building construction material, 
Two-stroke baby taxi etc. All of these are harmful 
to environment and violets DfE Principles A & B.  
 
Next the authors describe what the industries in 
Bangladesh are doing for protecting environment. 
Rahimafrooz believes in promoting individual 
environmental responsibility through commitment 
to 3R (Reduce, Reuse, Recycle), a globally 
recognized concept and practice to address 
Environmental Issues. This ensures to follow DfE 
principles A, B, C and D. Every year, Rahimafrooz 
celebrates the International Environment Day with 
“RSF Poribesh Utshab”. In year 2010, Rural 
Services Foundation (RSF), a Social Development 
Initiative of Rahimafrooz, organised quiz 
competition covering 30 upazillas of Bangladesh 
and gave awards to 450 students. The quiz 
competition is aimed for candidates of SSC 
examination and the topics include climate change, 
renewable energy technology and 3R issues to 
promote greater environmental responsibility and to 
encourage the students to increase their knowledge 
on environment as well as to make them conscious 
about the climate change (Rahimafrooz, 2010). 
This program is the basic theme of DfE principle G. 
 
PRAN-RFL Group was born in 1980 and over the 
years they diversified their activities. Today they 
are the largest processors of fruits & vegetables in 
Bangladesh. They encourage farmers and help them 
to grow quality crops with increased emphasis to 
source all their key agricultural raw materials 
sustainably and hence follow DfE principle A. The 
management is conscious about environment 
(PRAN-RFL, 2010). 
 
2009 saw the launch of a new vision for Unilever, 
to double the size of the company while reducing 
overall impact on the environment. They are 
embarking on a long-term program of work with 
the suppliers, customers and other partners to 
realize this goal. From the year 1995 the company 
has significantly improved the eco-efficiency of its 
network of factories. In 2008 they developed a set 
of metrics for four priority environmental impact 
areas: greenhouse gas emissions, water, waste and 
sustainable sourcing. Their target is to source 100% 
raw material sustainably by year 2015. Some 
remarkable works can be listed as: 
 
 15% of palm oil now sourced sustainably via 
Green-Palm certificates 
 15% of the tea globally now sourced from 
Rainforest Alliance Certified farms 
 Reduced environmental impacts of the 
manufacturing operations by 41% for CO2 
from energy, 65% for water use and 73% for 
total waste 
 Lifebuoy promoted Global Hand-washing Day 
in 23 countries (Unilever, 2009) 
 
Unilever observes the impacts of a product on 
environment in every stage of its lifecycle: in 
sourcing raw materials, packaging, manufacture, 
distribution, consumer use and disposal. 
Sustainability is now central to their business 
strategy. So it is clear that Unilever follows almost 
all of the DfE principles.  
 
4. CONCLUSIONS 
 
In general, environmental impact comes from 
excessive consumption of natural resources and 
emissions of pollutants to air, water, and land. If the 
DfE principles are followed properly in every 
stages of product life cycle then environmental 
impact will definitely become lesser. Then it would 
become a Green Product. From this study it is 
evident that just like other countries the leading 
industries in Bangladesh as well as GOB are very 
conscious about this fact. 
 
All of the DfE principles may not be followed in a 
structured way but main principles like Principle A, 
B & G are strictly maintained during creating 
Government Regulations and Product Design in the 
manufacturing industries. It is expected that this 
trend will continue in following all of the DfE 
principles. In this article Design for Environment, 
for reducing environmental impacts, has been 
discussed, and a list to which a designer can refer 
has been included. It may help the related personals 
to make greater number of eco-friendly products. 
The eco-designer must be cognizant of all DfE 
principles. 
 
DfE principles are still being discovered. Further 
work is needed to expand the list as new principles 
become available. Finally, the list of principles 
based on best practices but rigorous, quantitative 
validation of some of these principles is still 
lacking. 
 
5. ACKNOWLEDGEMENT 
 
The authors express their sincere gratitude to the 
Authority of Unilever Bangladesh, PRAN-RFL 
Group and Rahimafrooz who provided the 
necessary information and suggestions during the 
study. 
Page 868
  
 
6. REFERENCES 
 
1. Bras, B. (1997), Incorporating Environmental 
Issues in Product Design and Realization, 
United Nations Environment Programme 
Industry and Environment (UNEP/IE), Vol. 20, 
No. 1-2, pp 1-19. 
2. Cools, M., Moons, E., Janssens, B. and Wets, 
G. (2009), Shifting towards environment-
friendly modes: profiling travelers using Q-
methodology, Transportation, Vol. 36, pp. 
437–453. 
3. Dell Design for Environment White Paper, 
(2010), 
i.dell.com/sites/content/corporate/.../design-for-
environment.pdf 
4. Eastwood, M. (2007), The Environmental 
Product Life Cycle: Environmentally Friendly 
Design, IDC February 2007, Sponsored by: 
HP. 
www.dell.com/downloads/.../secure_exchange
_idc_white_paper_final.pdf 
5. Jeganova, J., Ford, D., Karlsson, M., Boks, C. 
(2004), Product Life Cycle Design: Integrating 
Environmental Aspects into Product Design 
and Development Process at Alfa Laval, 
Unpublished M.Sc. thesis,  Lund University, 
Sweden, November 2004. 
6. Jeswiet, J. and Hauschild, M. (2008) ‘Market 
forces and the need to design for the 
environment’, Int. J. Sustainable 
Manufacturing, Vol. 1, Nos. 1/2, pp.41–57. 
7. Kaila, S., Hyvarinen, E. (1996), Integrating 
Design for Environment into the Product 
Design of Switching Platforms, IEEE, pp 213-
217. 
8. Medina, H. V. (2006), Eco-design for 
Materials Selection in Automobile Industry, 
13th CIRP International Conference on Life 
Cycle Engineering (LCE), Proceedings of LCE 
2006, pp. 299-304. 
9. Michael Lenox, Andrew King, John Ehrenfeld, 
(1999), Incorporating Environmental 
Considerations into Product Design Decisions, 
Unpublished PhD thesis, Technology 
Management & Policy Mass. Institute of 
Technology, Cambridge, March 30, 1999. 
10. Murray, T. (2005), A Conceptual Examination 
of Product Design, Appropriate Technology 
and Environmental Impact, June 2005, 
www.ruadesign.org/ourbiblio/index.php. 
11. Pitt, J. and Lubben, F. (2009), The Social 
Agenda of Education for Sustainable 
Development within Design & Technology: 
The Case of the Sustainable Design Award, 
International Journal of Technology and 
Design Education, Vol.19, pp.167–186. 
12. Platcheck, E.R., Schaeffer, L., Kindlein, Jr. W. 
and L.H.A. (2008), EcoDesign: case of a mini 
compressor re-design, Journal of Cleaner 
Production, Vol. 16, Issue 14, pp. 1526-1535. 
13. PRAN-RFL Group (2010), 
http://www.pranrflgroup.com/index.php 
14. Rahimafrooz (2010), 
3R (Reduce, Reuse, Recycle), Poribesh Utshab, 
http://www.rahimafrooz.com/SocialInitiatives/
PoribeshUtshab/tabid/76/Default.aspx 
15. Rose, C. M. (2000), Design for Environment: 
A Method for Formulating Product End-of-Life 
Strategies, Unpublished PhD thesis, 
Department of Mechanical Engineering, 
Stanford University, USA, November 2000. 
16. Sarja, A., Fukushima, T., Kummel, J., Muller. 
C., Alexander, S., Odeen, K. and Lepoivre, J.P. 
(1999), Environmental design methods in 
materials and structural engineering – Progress 
Report of RILEM TC 172-EDM/CIB TG 22, 
Materials and Structures, Vol. 32, pp. 699-
707, December 1999. 
17. Schindler Group (2002), Systematic 
development of environmentally-friendly 
Products, Annual Report of Schindler Group, 
2002. 
18. Telenko, C., Seepersad, C.C. and Webber, 
M.E.  (2008), A Compilation of Design for 
Environment Principles and Guidelines, ASME 
2008, Proceedings of International Design 
Engineering Technical Conferences & 
Computers and Information in Engineering 
Conference, IDETC/CIE, August 3-6, 2008, 
New York, USA, pp. 1-13. 
19. Tseng, H.E. and Chen, W.S. (2004), A 
replacement consideration for the end-of-life 
product in the green life cycle environment, 
International Journal of Advanced 
Manufacturing Technology, Vol. 24, pp. 925–
931. 
20. Unilever Bangladesh (2009), Sustainable 
Development Overview 2009, 
http://www.unilever.com.bd/Images/sd_Unilev
erSDReport170310_amended_tcm61-
212972.pdf 
21. Walther, G., Steinborn, J., Spengler, T.S., 
Luger, T., Herrmann, C. (2010), 
Implementation of the WEEE-directive— 
economic effects and improvement potentials 
for reuse and recycling in Germany, 
International Journal of Advanced 
Manufacturing Technology, Vol. 47, pp. 461–
474. 
22. Ray, D. L. and Guzzo, L. (1993), 
Environmental Overkill; Whatever Happened 
to Common Sense? Harper Collins, New York 
Page 869
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: M. S. Islam  
E-mail: mdsaifulislam@iict.buet.ac.bd 
An Effective Bayesian Personalized E-mail Spam Filter Using Word 
Tokenization Method 
 
 
M. Z. Hoque1 and M. S. Islam2 
1Pubali Bank Limited   
Head Office, Motijheel, Dhaka, Bangladesh 
mzh_pbl@yahoo.com 
2Institute of Information and Communication Technology 
 Bangladesh University of Engineering and Technology 
mdsaifulislam@iict.buet.ac.bd 
 
 
A personalized e-mail spam filter is designed and developed using word tokenization based on the Bayesian 
enumerated method. The spammacity or legitimacy of the incoming mails is calculated using pre-created 
spam and ham databases with respect to particular user domain. The filter is self-adapting by learning from 
new spam- or legitimate words of the incoming mail as well as with the outgoing e-mails. It is found that a 
well trained Bayesian spam filter is very effective and efficient with a minimum number of false positive and 
false negative in filtering the incoming e-mails. 
 
Key words: Baye’s theorem, legitimate mail, Internet, spam filters and token dictionary. 
 
 
1. INTRODUCTION 
 
Spam stands for short pointless annoying 
messages, although they may or may not be always 
short. Unsolicited bulk e-mail or unsolicited 
commercial e-mail is the practice of sending 
unwanted e-mail messages, frequently with 
commercial content, in large quantities to an 
indiscriminate set of recipients [1]. With the 
exponential growth of the Internet, it is harder to 
classify useful information from spam mail. The 
number of spam mails is increasing daily - studies 
shows that over 50% of all current e-mails are spam 
mail [2]. As spammers are becoming smarter and 
are constantly trying and updating themselves to 
outsmart conventional static methods such as 
keywords, blacklist, whitelist, collaboration 
filtering and so on. In the last few years, lot of 
research work has been carried out for the detection 
and filtering of e-mail spams [3]-[8].  Schneider 
[9], describe experiments with a Naïve Bayes text 
classifier in the context of anti-spam e-mail filtering 
using two models and found that multinomial 
model achieves higher accuracy than the 
multivariate Bernoulli model. Androutsopoulos et 
al. [10], developed a networked based Bayesian 
spam filter, which only considers the incoming mail 
contents into consideration.  These technologies are 
not obsolete but cannot be relied effectively to face 
the today’s’ e-mail spam problem . 
 
In this paper, we have presented Bayesian 
enumerated technique and developed a personalized 
e-mail filter considering both the incoming and 
outgoing e-mail contents which will overcome the 
limitations of the existing spam filtering techniques. 
 
2. BAYE’S THEOREM AND 
ENUMERATION METHOD 
 
Bayes' theorem relates the conditional and 
marginal probability distribution of random 
variables. It describes how to update or revise 
beliefs in light of new evidence a posteriori. The 
conditional and marginal probabilities of 
stochastic events A and B, 
   P(A|B) =  (B|A) * P(A)/P(B)                          (1) 
                                               
where, P(A) is the priori probability or marginal 
probability of A, P(A|B) is the conditional 
probability of A, given B. P(B|A) is the 
conditional probability of B given A. P(B) is the 
prior or marginal probability of B and acts as a 
normalizing condition.   
Page 870
ISBN: 978-984-33-2140-4
  
 The Bayes’ probability function operates on 
counts and frequencies rather than on 
probabilities. The most basic and intuitive 
method for computing P(A|B) is the set 
enumeration method. Using this method, P(A|B) 
can be computed by counting the number of 
times A and B occur together {A & B} and 
dividing by the number of times B occurs {B} 
 
                P (A |B) = {A & B} / {B}                               
(2) 
   The enumeration method might still be 
regarded as the most basic and intuitive method 
for computing a conditional probability. 
 
 
A. Bayesian Filter Design Principles 
 
 Using the set enumeration method as 
mentioned above, a Bayesian spam filter is 
designed which acts as personalized spam filter. 
By applying this method, we calculate how many 
times a specific word occurs in spam mails 
dividing by the total number of times overall 
(spam and ham mails) is the spamming 
probability of the regarding word. The same 
method is applied in defining the hamming 
(legal) probability of any specific word. In 
designing the spam filter we have considered the 
following points: 
 
a) To calculate spammacity or legitimacy of 
each word of the whole message. 
 
b) To learn from the all new incoming and 
valid outbound E-mails and thus 
constantly updates it. 
c) To make it sensitive to a user or particular 
domain of interest. 
 
 
 
 
 
Figure 1 shows the basic architecture of a 
personalized e-mail spam filter. To construct the 
Bayesian filter, first we have to create two 
databases with individual words and tokens 
gathered from two representative samples of spam 
e-mails (spam word list) and legitimate e-mails 
(ham word list) the words occurring in the e-mail 
messages. The probability value designated to each 
word or token is commonly known as spammacity 
and ranges from 0.0 and 1.0. 
 
 
If the total probability lies between 0.0 and 1.0 
then the mail is defined as spam mail and if greater 
then 1.0, the mail is defined as ham (legal) mail. 
The range of values that determine the legitimacy 
and spammacity of the incoming mails is shown in 
Fig.2. 
  
 
 
 
                     HAM                                 SPAM 
 
 
                    Spammacity value 
 
        
            0                                               1.0                                      
 
 
B. Database Design and Tokenization 
 
 
The database schema of the proposed personalized 
spam filter is shown in Fig. 3. For each incoming 
mail, the associated words of each mail are stored 
in in_mail and in_mail_wordlist table respectively. 
Then the outgoing mail contents are also stored in 
the out_mail database and the outgoing mail 
contents is tokenized in out_mail_wordlist table. 
The calculation is processed in the token_dic table. 
The whitelist and blacklist filter maintained by 
whtblcklst  table. Then spam table is used for 
storing all the spam words and ham is used for 
storing all the legitimate words previously found in 
the incoming and outgoing ma 
 
Those words found in the spam table that is 
match is found between token_dictionary and spam 
table, their spammacity is calculated as follows:  
 
wordlistmail
intheinwordthefoundtimesmanyHow
SPAMCOUNTofvaluemailspam
theinfoundtimesmanyhoweviously
spamP
__
)_(
Pr
)( =    (3) 
wordlistmailout
theinwordthefoundtimesmanyHow
HAMCOUNTofvaluemailham
theinfoundtimesmanyhoweviously
hamP
__
)_(
Pr
)( =   (4) 
For the new words those will not be found in 
spam or ham table, their spammacity or 
legitimacy value will be zero. When all the words 
of the token_dictionary table probability 
calculation will be completed, then the final result 
will be as follows:  
Fig. 1: The architecture of a personalized e-mail spam filter 
Fig .2:  Determination of legitimacy and spammacity 
 
Page 871
  
 
 
 
))((
))((
Re
hamP
spamP
sultFinal
∑
∑
=
         (5)                      
If the 0.1Re >sultFinal , the mail is more likely to 
be spam otherwise ham. After calculation, if the 
message is spam, for all the matched word as well 
as for new words of the spam table, COUNT_SPAM 
values will be increased by 1. Thus the spam table 
is updated with the words which mail was decided 
finally with spam mail. 
 
C. Process Flowchart of the Filter 
 
The Bayesian approach is a content-based 
personalized e-mail spam detection and filter. We 
already mentioned that after an initial learning 
process the filter will be able to distinguish 
between ‘legal’ and ‘spam’ mail respectively. The 
working process flowchart of the filter is depicted 
in Fig 4. When a new mail received, its address is 
verified from the stored whitelist and blacklist 
addresses. If it matches with the whitelist address, 
the spammacity of the mail will not be calculated. 
On the other hand, if the address matches with the 
backlist, its spammacity also will not be 
calculated. If none of the above occurs, then the 
Bayesian filter will start its process to calculate its 
spammacity of each word of each incoming mail 
with associated learning and training process.  
 
Finally the result of the overall spammacity 
calculated, if the spammacity value lies in the 
ranges 0.0 and 1.0, the incoming mail is legal and 
hence the white list will be updated with the new 
address. If ranges be greater then 1.0, it will be 
regarded as spam mail and the blacklist will be 
updated with the new address. 
 
 
 
3. TRAINING AND TESTING OF BAYESIAN 
FILTER 
 
There is a need for training to the developed 
Bayesian filter before using it. Training is 
important to prove the filters capability of spam 
detection. We have added the pre-classified e-
mails to the input of the filter. During the testing 
Fig. 3: The database schema of personalized spam filter 
 
Fig.4: Process flowchart of the personalized Bayesian e-mail 
spam filter 
Page 872
  
process the values of the tokens are changed time 
to time in the token dictionary of the filter in order 
to achieve higher accuracy. The filter uses the 
knowledge base from the training part to decide 
for every e-mail, whether it is spam or legitimate. 
It is worth to mention that the learning process 
does not stop after finishing training; it continues 
every time when the filter is used. Moreover, the 
filter gets more and personalized and related to 
our needs during usages. 
 
 Table 1: Number of e-mails set to the Bayesian filter 
 
Test  No. Total number of e-mails 
1 19 (3 non-spam + 16 
spam) 2 18 (all spam) 
3 32 (all spam) 
4 25 (all spam) 
5 20 (2 non-spam + 18 
spam) 6 39 (4 non-spam + 35 
spam) 7 56 (5 non-spam + 51 
spam) 8 46 (3 non-spam + 43 
spam) 9 106 (9 non-spam + 97 
spam) 10 96 (6 non-spam + 90 
spam) 
 
 
 
Fig.5:    Spammacity and legitimacy calculations 
 
Table 2: Number of spam detected by the Bayesian filter 
 
sl Total number of e-mails Legitimate 
detected 
Spam detected White list Black list 
 
1 19 (3 non-spam + 16 spam) 17 2 0 0 
2 18 (all spam) 12 4 0 0 
3 32 (all spam) 20 9 0 0 
4 25 (all spam) 9 16 1 1 
5 20 (2 non-spam + 18 spam) 3 16 1 0 
6 39 (4 non-spam + 35 spam) 7 30 2 3 
7 56 (5 non-spam + 51 spam) 6 48 0 2 
8 46 (3 non-spam + 43 spam) 3 41 2 0 
9 106 (9 non-spam + 97 spam) 8 95 1 3 
10 96 (6 non-spam + 90 spam) 5 89 1 1 
To
tal 
457 90 350 8 9 
 
The initial results indicated that filter is not very 
effective in blocking spam at the beginning of the 
testing process. The first test comprised 19 e-mails 
messages (3 non-spam and 16 spam) and it is 
evident that in this first trial the Bayesian filter 
detected only 2 spam message out 16 spam 
messages sent. This is due to the filter is not being 
trained fully trained. Table 2, demonstrates that as 
training progressed filter results improved 
significantly. False positive is defined as a non-
spam legitimate e-mail recognized as spam. False 
negative is defined as a spam e-mail recognized as 
non-spam e-mail  
Figure 5 shows the snapshot of spammacity and 
legitimacy probability calculation window of a 
typical e-mail. As shown in the Fig. 5, the first 
column shows the word, the second row shows the 
spammacity meaning that previously how many 
times the word found in the mails those were spam 
mail, the third column shows legitimacy meaning 
Page 873
  
that previously how many times the word found in 
the mail those were legal mail with respect to this 
particular user or organization. With these two 
values, spammacity probability and legitimacy 
probability is calculated. Thus the summation of 
spammacity and legitimacy probability of all the 
tokens is taken and the final result is achieved.  If 
the result is between 0.0 and 1.0 the messages is 
regarded as legal mail and if greater then 1.0, 
regarded as spam mail. Fig.6 shows the graphical 
representation of the testing result of the Bayesian 
filter. 
 
 
 
4.  CONCLUSION 
 
Spam or unsolicited email has become a major 
problem for companies and especially for private 
users. The techniques currently used by most anti-
spam software are static and it is often fairly easy to 
evade filters by changing the message a little and 
making the technique fool and failed. To effectively 
combat spam, we have developed a personalized 
adaptive spam e-mail filter by the use of Bayesian 
enumerated method as well as fast and accurate 
word tokenization process to overcome the 
limitations of existing spam detection techniques. 
The filter distinguishes between legal and illegal 
mails with respect to the particular users domain 
based on the spam and ham pre-created trained 
database.  It has the capability to adapt and learn 
continuously by itself resulting very high spam 
detection rates and become more personalized day 
by day. 
REFERENCES 
 
1. Cranor, L. and  LaMacchia, D. ( 1998), “Spam!” 
Communications of the ACM, 41(8), pp. 74–83. 
2.  Garcia, F. D.  Hoepman, J. –H. and Van 
Nieuwenhuizen, J. (2004), “Spam filter 
analysis”, Proc. of 19th IFIP International 
Information Security Conference (WCC2004-
SEC). 
3.   P. Cunningham, P., Nowlan, N.,  Delany, S. J. 
and Haahr,  M. (2003), “A case-based 
approach to spam filtering that can track 
concept drift”, Proc. of ICCBR'03 Workshop 
on Long-Lived CBR Systems, Trondheim, 
Norway. 
4.  Levy,  E. (2003), “The making of a spam 
zombie army: Dissecting the sobig worms,” 
IEEE Security & Privacy Magazine,  1(4),  pp. 
58–59. 
5.  Yerazunis, W. (2004),  “The spam filtering 
plateau at 99.9% accuracy  and how to get past 
it,”  Proc. of the MIT Spam Conference, 
Cambridge, MA, USA.  
6. S. Pfleeger, S. and  Bloom, G. (2005), “Canning 
spam: Proposed solutions to unwanted e-mail,” 
IEEE Security & Privacy Magazine, 3(2),  pp. 
40–47. 
7.  Cormack, G. v.  and  Bratko, A. (2006), “Batch 
and on-line spam filter evaluation,” Proc. of 
the Third Conference on E-mail and Anti-Spam 
(CEAS), Mountain View, CA, USA. 
8.  Segal, R., Crawford, J., Kephart, J. and Leiba,B. 
(2004), “Spamguru: An enterprise anti-spam 
filtering system,”  Proc. of the First 
Conference on E-mail and Anti-Spam (CEAS), 
Mountain View, CA, USA. 
9. Schneider,K. –M (2003), “A comparison of event 
models for naive Bayes anti-spam e-mail 
filtering,” Proc. of 10th Conference of the 
European Chapter of the Association for 
Computational Linguistics (EACL 03), 
Budapest, Hungary,  pp. 207–314. 
10. AndroutsopoulosJ,  Koutsias, K. V., 
Chandrinos, G.,  Paliouras, G. and  
Spyropoulos, C. D. (2000), “An evaluation of 
naïve Bayesian anti-spam filtering”,  Proc. of 
the Workshop on Machine Learning in the New 
Information Age. 
 
 
Fig. 6:  Number of different types of e-mail detection by 
the Bayesian spam filter 
Page 874
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh  
* Corresponding Author: Ahsan Habib,  
AN EXPLORATORY STUDY OF VISION 2021: STATUS AND 
CHALLANGES 
 
Ahsan Habib* and Atikur Rahman Baizid 
*Metropolitan University, Sylhet, Bangladesh 
Leading University, Sylhet, Bangladesh 
 
The government has declared vision 2021 for establishing Bangladesh as a knowledge based developed 
country through the effective use of Information and Communication Technology. The government has 
already taken some proactive steps to fill up this target.  The paper reviews some of the initiatives and 
achievements of Vision 2021 – a program to further a Digital Bangladesh. The paper then reviews and 
discusses some of the challenges and then provides some recommendations to further some of the Vision 
2021 initiatives and then additional recommendations to strengthen the foundation and environment for 
Vision 2021 in Bangladesh. 
 
Key words: Digital Bangladesh, E-governance, ICT, Vision 2021, Knowledge Base Society. 
 
1. INTRODUCTION 
 
The use of information and communication 
technology has been playing a vital role in the 21st 
century due to globalization. The democratic 
government has declared the “Vision 2021” termed 
as “Digital Bangladesh” which comprises ensuring 
people’s democracy and rights, transparency, 
accountability, establishing justice and ensuring 
delivery of government services in each door 
through maximum use of technology-with the 
ultimate goal to improve the daily lifestyle of 
general people. Government’s “Digital 
Bangladesh” includes all classes of people and does 
not discriminate people in terms of technology. 
Hence, government have emphasized on the four 
elements of “Digital Bangladesh Vision” which are 
human resource development, people involvement, 
civil services and use of information technology in 
business. 
 
2. ELECTRONIC GOVERNMENT 
INITIATIVES 
 
The Government has taken many initiatives for 
developing the country to make knowledge based 
society through information and communication 
Technology. 
 
2.1 In Mobile Sector 
Bill payment through mobile, port automation, e-
centre, introducing e-governance (partially), 
establishing computer labs in 128 educational 
institutions, getting public examination results 
through short message service (SMS) and 
introducing university admission process through 
SMS are some other significant moves taken by the 
government in its first year. 
 
Fig. 1: Digital Bangladesh at a glance 
[Habib/Baizid © ACM 2010]. 
 
2.2 In Bangladesh Bank 
Bangladesh Bank, being the monetary authority of 
the country, is at the forefront of government’s firm 
commitment to be digitized. They have already 
formulated a 5-year strategic plan for the financial 
sector based on advanced technological 
applications to deliver services with utmost 
efficiency. The ultimate goal is to make Bangladesh 
Bank a world class Central Bank with high 
Page 875ISBN: 978-984-33-2140-4
  
applications of technologies. This should, in fact, 
transform itself into a paperless organization within 
this plan period [4]. 
 
Bangladesh Bank has achieved a historic milestone 
in trade and business arena, departing from 
conventional banking with the introduction of e-
commerce recently; a giant stride towards digital 
Bangladesh. Banks have been allowed to make 
online money transactions; payment of utility bills 
through internet, transfer of funds (account to 
account), payments for trading goods and services, 
and facilitate online credit card payments in local 
currency. Indeed, the electronic payments will be 
considered as cash transactions, which will be 
regulated under the ‘Anti-Money laundering Act’ 
as well as other relevant rules and regulations. A 
national payment gateway, connecting all banks for 
inter-bank transactions (ebanking) is expected to be 
established soon. Electronic Fund Transfer will also 
be possible in near future [4]. 
 
Installation of ‘Bangladesh Automated Clearing 
House (BACH)’ is another remarkable event in the 
history of financial sector in Bangladesh; will ease 
the remittance channel and payment system, and 
therefore, bring dynamism in business activities. 
The system has been started in early November 
2009 on experimental basis, participated by some 
well prepared banks; will be inaugurated formally 
soon. Applying sophisticated technological method, 
the system needs only images and corresponding 
information of the submitted cheque leaves instead 
of physical one; will send them to the BACPS ( 
Bangladesh Automated Cheque Processing System) 
using a secured communication link. New 
cheques/clearing instruments (standardized) will 
contain Magnetic Ink Character Recognition 
(MICR) line that encompasses information 
regarding the amount, transaction code, clients 
account details, routing number (numeric code 
assigned to bank branches for easy identification of 
origin and destination of the instrument), cheque 
leaf’s serial number and so on. The system will 
support both intra-regional and inter-regional 
clearings based on a centralized processing centre 
in Dhaka and designated clearing regions; conforms 
to the international best practices, cost effective 
solution for cheque processing [4]. 
 
Therefore, after getting customers’ cheques for 
collection in the bank-branch, collecting banks will 
check the prima facie information of the submitted 
cheques, capture images and information, and send 
them to BACPS electronically. BACPS will then 
process and send the images and information to the 
paying banks for validation. Paying banks will 
examine the pertinent images and information, and 
send back to the BACPS for payment (further 
examination if any inconsistency like fund 
insufficiency or mismatch of signature etc.) Then 
BACPS will accumulate all the information; 
workout a single net amount for each bank, and 
send back to the collecting banks. As such, cheque 
clearing time is expected to be turned down to a 
single day for countrywide payment. In other cases, 
this will be a matter of couple of hours only. 
Disaster centre for retrieving data [4]. 
 
2.3 In Submarine Cable 
The government has already taken initiatives to 
connect Bangladesh with the second Submarine 
Cable Network to have secured connectivity with 
the information superhighway. The latest statistics 
(ITU 2007) revealed that internet penetration is 
only 0.3% in Bangladesh, whereas the rate is 7.3 
and 5.3% respectively in India and Pakistan [4]. 
 
2.4 In E –commerce 
BB has achieved a historic milestone in the trade 
and business arena, departing from conventional 
banking with the introduction of e-commerce 
recently; a giant stride towards digital Bangladesh. 
Banks have been allowed to make online money 
transactions, payment of utility bills through 
internet, transfer of funds (account to account), 
payments for trading goods and services, and 
facilitate online credit card payments in local 
currency. 
 
2.5 In ICT policy 
The government passed the national ICT policy 
with guidance from the access to information 
program of the Prime Minister's Office [6]. Under 
this policy, 306 work plans have been drawn up 
with a specific time frame. At the end of 2009, 
within the scope of this plan, the short-term projects 
were achieved. Among these projects, services like 
utility bill payment using mobile phone in Dhaka, 
Chittagong, Sylhet, Pabna, Cox's Bazar and the Hill 
Tracts, finding out the timetable, fare, seat 
availability of trains, and receiving advance 
warning of disasters via mobile phone are already 
available. DCs and upazila nirbahi officers have 
been trained and connected via laptops and internet. 
The government has taken initiatives to promote 
ICT among all spheres of people, including the 
hard-to-reach areas; tax and duty cut on computers, 
promoting ISP services etc. 
 
2.6 In Education 
In 2009 SSC and HSC results were made available 
via mobile and internet, and were also emailed to 
the educational institutions. The work for providing 
laptop and internet connectivity was started in 
various schools and colleges. Using the data from 
the education boards, Shahjalal University 
Page 876
  
completed its admission registration process via 
mobile phone-based applications. For the first time, 
results of medical college exams and primary 
exams were available through sms[6]. To make 
high speed internet more affordable for students of 
Shahjalal University and Dhaka University, special 
free wi-fi zones have been created. To ensure 
timely availability of textbooks to students, they 
have been published online. The science and ICT 
ministry has not only set up computer labs in 128 
schools in 64 districts, but has also appointed IT 
professionals there.  
 
2.7 In Health 
The country's 800 health centres have been given 
internet and mobile connectivity. Several 
telemedicine centres have been built. Along with 
mobile health services by the private sector, upazila 
health complexes have started offering similar 
services. To ensure equal access to technology for 
all, the government is setting up community e-
centres/ tele-centres all across the country -- there 
are more than 2,300 of them now. The Registrar of 
Joint Stock Companies and Firms has digitalised its 
registration process.  
 
2.8 Machine Readable Passport 
Prime Minister Sheikh Hasina on Wednesday (3rd 
June, 2010) launched the much - desired Machine 
Readable Passport (MRP) and Machine Readable 
Visa (MRV) taking the country a step forward 
towards Digital Bangladesh[2]. 
"From today we have entered into the digital era 
and the country's passport and visa system has been 
raised to international standard with the 
introduction of MRP and MRV," she said while 
inaugurating the MRP and MRV at the Osmani 
Memorial Hall here[2]. 
 
2.9 Others 
Besides the government initiatives, various private 
initiatives have started to bloom as well. "Digital 
festivals" and "IT festivals" have been held in 
various parts of the country. Even as remote a place 
like Bagerhat organized a knowledge festival. BCS, 
Basis and Bangladesh Open Source Network took 
active part in these festivals, which have increased 
people's interest towards computers. 
 
3. IDENTIFICATION OF CRITICAL 
FACTORS  
 
Although there are many good initiatives like these, 
these are all right.  Among the disappointments, the 
most important non-starter has been the automation 
process of Chittagong Custom House, even though 
the work had been completed and the finance 
minister had inaugurated it. VoIP has not been 
properly liberalized and the long distance 
telecommunication policy has not been modified 
even after initiatives were taken to do so. Neither 
has the work been started for the backbone network 
of the secretariat. Work on the government's own 
network, "banglagov.net," has not resumed [6]. 
 
Experts say that government websites, launched 10 
years ago as part of the e-governance initiative, 
were intended to make it easier for citizens to 
interact with public agencies. It meant no longer 
wait in queues in government offices to make 
complaints, pay bills or apply for special 
programmers. Instead, the websites are merely 
Windows dressing, say experts. 
 
A 2010 United Nations survey showed Bangladesh 
had improved its e-government but still ranked 134 
out of 184 countries. That was above Pakistan, but 
below the Maldives, Sri Lanka and India. The 
ranking was based on criteria such as the presence 
of web pages, information on public policy and 
whether citizens could give immediate feedback. 
Government officials admit their websites are 
unattractive, clunky and a flop among citizens. 
They blame the lack of techno-savvy people to look 
after the websites, which require at least half an 
hour a day to update and maintain. So the task falls 
to administrators who work on the home pages in 
addition to their official duties. The result is that 
many websites are lagging behind. When the nation 
was on a swine flu alert last August, a review 
showed the websites for the health ministry and 
other government offices carried nothing on the 
scare.  
 
Even for more mundane matters--paying taxes or 
making an appointment to get a car fitness 
certificate--government websites fall far short, say 
experts. The portals for the 64 districts launched in 
January are not interactive, and mostly contain a 
collection of barebones information [8].  
 
Many of the websites are also not available in 
Bangla, making them nearly useless to the bulk of 
the population. "The government needs to realize 
when they are providing content for the general 
people," said Jabbar, adding, "They need to do it in 
the language of the general people. They need to 
post contents for 150 million people, not just the 
five or six lakh who use Internet [8]".  
 
But even the five or six lakh regular Internet surfers 
may find the cyber waves to be choppy. The 
website of the Ministry of Chittagong Hills Tracts 
Affairs, for one, has been dead for some time now 
[8]. 
 
Page 877
  
Under the Ministry of Health there are medical 
universities, colleges and hospitals in big cities. In 
addition, there are a large number of rural 
hospitals/clinics/healthcare service centers at 
district, upazila, and thana levels. However, most of 
these hospitals and clinics are not well equipped 
and their services are not of desirable quality. The 
number of qualified doctors and nurses is much less 
than required. Nor do they have required type of 
diagnostic equipment and operating theatres. 
Reportedly, the available facilities and medicines 
are often misused.  
 
4. WHAT TO DO? 
 
4.1 The Political Commitment  
All the political parties of Bangladesh must be 
committed to make a digital Bangladesh. Our 
government must take proactive steps to reach the 
technology to rural citizens so that the access of 
information might become very easier to the grass 
root levels citizens. 
 
4.2 ICT infrastructure   
A broadband infrastructure is needed with access 
for all Bangladeshis from their homes, work places, 
schools and tele-centres with Wimax and 3G 
network. We also need a digitally literate 
population and workforce, digital business 
development, and a legal framework that assures 
freedom of expression while protecting the rights of 
creators and innovators towards building an 
indigenous knowledge and technological base. 
 
 To make this infrastructure the Government has to 
take the following initiatives: 
 
  The Govt. has to implement the TNT line up to 
each village so that ICT might reach at the door 
step of the villagers. 
   The internet connectivity should be free so that 
the citizens can access easily and can understand its 
necessity first. After then the people can access it 
giving charge implemented by the Govt. 
 
4.3 Increase Connectivity   
Connectivity options to the rural areas can be 
improved, by using wireless access. A PC in 
Bangladesh costs around 12-15 months of average 
per-capita income as compared to China’s 4 months 
and USA’s 12 days. Hence, the govt. should 
 
Reduce the cost of taking PC. 
Reduce the tariff levels of ICT equipment and 
accessories to    bring even a bigger population 
under Internet coverage.  
Connect the rural people by using wireless 
access. 
4.4 Set up Talent Managerial   
We must have the local experts to control the 
system of digital Bangladesh. To install the DB we 
need foreign help but to maintain its sustainability 
we must need local experts. So the Govt. must take 
initiative to promote of Science and Technology 
and management education. So,  
 
The Govt. must install a separate plan to produce 
sufficient number of scientists, computer and 
communication engineers, software engineers, 
technology management experts, etc.  
The Govt. needs to make a separate university for 
the fulfillment of such vision. 
 
4.5 Health Sector  
ICT can help bring medical expertise to Upazilla 
and District headquarters. Tele-medicine, for 
instance may link healthcare centers in remote 
locations, through satellites, with super specialty 
hospitals at major towns / cities. Thus it can bring 
connectivity between patients at remote end, with 
specialist doctors, for medical consultations and 
treatment.   
 
By this way decisions can be implemented very 
quickly. This will ease out management problems. 
Because the entire information and data set will 
flow back and forth electronically they will be 
relatively more transparent and in turn the 
probability of indulgence in corruption will 
decrease.  
 
  The Govt. should implement Video conference 
systems between doctors in major clinics. 
The Govt. should take initiatives to recruit 
doctors with TNT line through which from the 
remotest corner of the country the villagers can take 
serve through Massage or call. 
The Govt. should encourage other mobile 
companies so that they must implement it cheapest 
rate. 
 
4.6 Private Sector  
To make Digital Bangladesh the Govt. have to 
develop the private sector for efficiency and 
reduction of corruption and citizen harassment, in 
areas such as railway ticketing, tracking of Hajis 
etc. Services such as utility billing should be 
outsourced to the private sector. The ICT sector has 
to be utilized for efficiency in domestic 
organizations, particularly the government, which 
will ultimately lead to better services for citizens.   
Private companies and NGOs can partner, in order 
to enhance awareness and utilization of ICT at the 
grass-roots level. For instance, NGO’s can work to 
bring elementary computer literacy to the people of 
rural Bangladesh. They can make arrangements so 
Page 878
  
that IT professionals and educators visit rural 
schools and help students get familiar with 
technology.  
 
4.7 Village Sector  
The villages are situated at a long distance from the 
digital society; scholars, professors, face book 
users. There are about 80% of  citizens live in 
village where students are not well dress up, have 
no money to take Tiffin, the teachers are often bare 
footed is a elderly bearded wearing a purple and 
white hat, have a stick to manage his students. In 
many villages there exists no electricity, no clean 
drinking water, and no computer in school. So to 
make digital Bangladesh we must develop the rural 
people of Bangladesh. 
 
  For the developing the village sectors through 
ICT the Govt. have to reach the electricity as well 
as the internet connection by reaching the TNT line 
to all the villages of Bangladesh. 
The schools, Hospitals and Union board must be 
brought under the internet connections. 
The villagers should have the opportunity to 
communicate with the Govt. electronically. 
 
4.8 The Garments Factories  
About 79.1% income of export has come from 
readymade garments in 2008-2009 amounted 
67257.1 core taka [12]. To make digital Bangladesh 
we must digitize the garments factories for the 
connection with government digitally. By this way 
the Govt. can take care of the garments factories 
which will be the best source of revenue. The Govt. 
must take necessary steps to implement the 
followings 
 
 Every Garments factory must have a website 
where there will have the list of all employees with 
their status and salaries. 
  There will have a linkage between the Got, and 
the Garments factories through which the Govt. can 
monitor these factories. 
The Govt. can make pressure to the Authorities 
of the Garments factories so that the living standard 
of the employees of garments factories must 
increase by increasing their salary and other 
facilities. 
 
4.9 Agriculture Sector  
Since more than half of our population is employed 
in agriculture; our planner should put ICT to good 
use in agriculture. For example, India has led the 
use of remote sensing satellite information for 
locating irrigation projects. The Internet has been 
effectively used in some of the villages to ensure 
effective dissemination of agricultural commodity 
price information. 
 
Fig 2: E-Agriculture [Habib/Mustafij © ACM 
2009] 
 
The above solution is proposed by [1] named ‘E-
Agriculture’ to show how a farmer will be 
benefited from digital Bangladesh. 
 
4.10 E-Democracy  
The Prime Minister's Office (PMO) should 
introduce video conferencing in the administration 
level so that the prime minister can talk to officials 
at district and upazila levels through it. The mass 
people must have opportunity to share views with 
the government officials’ electronically. 
 
4.11 Greener Bangladesh  
To make DB, Bangladesh should turn into a greener 
country which will change our climate into a better 
position. So engineers should play their role for a 
greener energy based digital Bangladesh.   
 
To make green Bangladesh quickly, the Govt. 
can make awareness of the green environment 
through TV and teleconferencing in such a way that 
if we transfer the country into a greener country 
through tree plantation then the country will be 
save from natural calamities quickly. 
  The Govt. can encourage all the mobile 
companies for marking the people to be aware of 
green environment through SMS. 
 
4.12 Paperless Office  
All the offices government and private should be 
paperless. The offices should be automated through 
network. The officers should use digital signature. 
 
Page 879
  
4.13 Inter Departmental Cooperation 
There must be a sense of balanced cooperation 
among the departments of the government as an 
example, the procedure to convey a passport to a 
citizen is done with the cooperation of passport 
office and the police department [1]. If the 
relationship between both departments is cordial 
and mutually beneficial in their interactions, 
providing service to the stakeholders will become 
smooth. 
 
4.14 Others  
The Govt. should promote IT systems in all 
government offices, trade and business to alleviate 
poverty, create more jobs and eradicate corruption. 
The government should keep in mind at least the 
following considerations.  
 
 Priority should be given to automating 
government services that benefit a large section 
of the population, such as land record 
digitization.  
 Development of web, radio and TV content that 
is comprehensible by large sections of the 
population should be emphasized and 
encouraged.  
 Special incentives should be given to the private 
sector and NGOs to develop ICT-based services 
specifically targeted towards the under-served.  
 
5. RECOMMENDATIONS 
 
Latest statistics reveal that Bangladesh faces a 
power deficit of up to 2000 MW against a demand 
of 5000 MW daily. It may be noted that for proper 
ICT development an uninterrupted power supply is 
a must. 
 
From different sources, it has been learnt that, 
English literacy rate in Bangladesh is less than one 
percent. There is a strong correlation between 
English literacy and ICT development in the 
present context of globalization. In the arena of ICT 
English has become the Lingua-Franca. Hence, 
English literacy is a must for our ICT development.  
 
For making a digital Bangladesh by 2021, the 
government must address the above stated issues 
effectively and efficiently in transparent manners. 
In many cases we need to reformulate our national 
policy (e.g. education policy, ICT policy) in 
accordance with the Millennium Development 
Goals. In reformulating the ICT policy, we will 
need to take a pragmatic and visionary approach so 
that it can curb the prevailing digital gap in the 
society. Moreover, the journey towards a digital 
Bangladesh needs the incorporation of the 
technologically solvent innovative younger 
generation. If the leaders of our country objectively 
guide this generation, they can do wonder for the 
nation. After all, the young generation always looks 
forward and they can help bring about positive 
changes in the society. 
 
6. REFERENCES 
 
1. Ahsan Habib, Mustafijur Rahman Faysal, Paperless 
Office: First Step to Digital Bangladesh, 
Proceedings of the International Conference of E-
Governance (ICEGOV) 2009, Bogota, Colombia. 
[doi>10.1145/1693042.1693130] 
2. BSS, Dhaka, Hasina launches Machine Readable 
Passport. The Daily New Nation Online Edition, 3rd 
June 2010. Accessed at: 
http://ittefaq.com/issues/2010/06/03/news0253.htm  
3. Forum-The Daily Star, Visioning Digital 
Bangladesh, 8th September, 2009. Accessed at: 
http://www.digitalopportunity.org/comments/visioni
ng-digital-bangladesh  
4. Atiur Rahman, ‘Vision 2021: Challenges for 
Engineering Profession’, 3rd January, 2010. 
Accessed at: http://www.bangladesh-
bank.org/mediaroom/speech/jan032010gs.pdf  
5. Jamilur Reza Chowdhury, TURNING All UETs AS 
LABORATORY OF SKILLED HUMAN 
RESOURCES, 9th March, 2010. Accessed at: 
http://gurumia.com/tag/prof-jamilur-reza-
chowdhury/  
6. Munir Hasan, What need to be done for Digital 
Bangladesh, 18th February, 2010. Accessed at: 
http://voipbangladesh.com/bangladesh-
internet/what-need-to-be-done-for-digital-
bangladesh-287.html  
7. MD Hasan, Digital Bangladesh- More said than 
done, the daily star online, 6th January, 2010. 
Accessed at: 
http://www.thedailystar.net/suppliments/2010/01/al_
oneyear/11_said.htm  
8. Rizanuzzaman Laskar, 'Digital Bangladesh' down, 
10th may, 2010, Accessed at: 
http://www.asianewsnet.net/home/news.php?id=118
32&sec=1 
9. Syed Ahsanul Alam, Digital Bangladesh: Prime 
Minister Dream Vs Understanding the Present, 
www reference. Accessed at: 
http://www.goodgovernancebd.org/Events_of_CGG/
new_article/digital_bang.html  
10. Delwar Hussain, Digital Bangladesh: Virtual 
dreams, real lives, 6th May 2009. Accessed at:   
http://southasia.oneworld.net/opinioncomment/digit
al-bangladesh-virtual-dreams-real-lives 
11. Syed Ahsanul Alam, Dream vs reality,The 
Independent onlne edition, Accessed at: 
http://www.goodgovernancebd.org/web_publication
s/digital/-%20The%20Independent%20-
%20Internet%20__%20Edition.htm 
12. Annual Review of Export Receipts (2008-2009). 
Accesses at: http://www.bangladesh-
bank.org/pub/annual/expreceipt/exp0809/review.pdf  
Page 880
 Proceedings of the 
International Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, SUST, Sylhet, Bangladesh 
*
 Corresponding Author: Md. Safaet Hossain,  
E-mail: safayeth@gmail.com 
COST BENEFIT ORIENTED ANALYSIS FOR DESIGNING 
OPTIMUM QUALITY ASSURANCE PRACTICES 
 
 
Md. Safaet Hossain 
Department of Electrical Engineering and Computer Science 
North South University, Dhaka Bangladesh 
Email: safayeth@gmail.com 
 
 
ABSTRACT: Quality assurance is a planned and systematic pattern of all actions necessary to provide 
confidence that an item or product conforms to established technical requirements. In a competitive market, 
quality assurance is essential to reduce unwanted cost of rework. Reducing cost by detecting and preventing 
defects at earlier stages of Software development phases, Software Companies can maximize benefits in 
different stages of software development life-cycle. This paper focuses on detection and prevention of 
defects at earlier stages of software development and designing optimum quality assurance practices to make 
tradeoff between the quality and the cost. Resource wastage and rework in software production can be 
visible and analyzed thus organization can reach the objective of the best balance between software quality 
vs cost and maximize net benefit.  
Key words: Software quality assurance, Defect Prevention, Process Improvement, Gross Benefit, Net 
Benefit 
 
1.0 INTRODUCTION 
 
To get the real scenario about the software quality 
assurance [21] practices we visited some software 
outsourcing company in Bangladesh. These 
companies are offshore software development and 
information and communication technology (ICT) 
consulting firm which develops software product, 
provides application and web 
development/solutions and performs IT consultancy 
in various fields for many businesses in Europe and 
other parts of the world. These companies define 
itself by emphasizing central focus on providing 
best services to valued customers. They offer 
efficient solutions to valued customers by 
integrating solutions into their businesses' strategy, 
practices and tools. Their main focus is to help 
customers add value to their businesses through the 
services provided by them. They believe in 
mutually beneficial long term partnership with their 
customers and they significantly invest their 
resources on learning & implementing new 
technologies in the most innovative manner to 
enhance performance, promote efficiency and 
finally, add tangible values to the businesses of our 
customers. 
The focal point of all services provided by these 
software companies is customer satisfaction and the 
foundation is quality assurance [21] policy. They 
believes and practices in creating long term 
mutually beneficial relationship with customers by 
establishing close partnership at both technical as 
well as management level and by understanding the 
customers’ business focus, values, practices, and 
processes. Their quality assurance policy ensures 
that all deliverables are provided on time, kept 
within scopes, delivered with quality as agreed 
upon by both customers and the outsourcing 
companies; and thus ensuring value addition to the 
business of our customers. Since they have the 
vision “Value Added Off-shore Services” is to add 
measurable business value for their customers in 
addition to integrating technology to Off-shore 
Software Development, they should emphasis on 
improving research methodology to ensure software 
quality. 
 
1.1 PURPOSE 
 
The purpose of this document is adhering to defect 
detection and defect prevention techniques to 
enhance quality of the product. Pro-active Defect 
Prevention (DP) is to create an environment for 
controlling defects and reduce cost. Defects that can 
be captured with the ratio of inspection and testing 
are only 80%. Cost required for rework is found to 
be more expensive than the cost incurred in 
adhering to DP strategies. The focal point of quality 
cost investment is to invest in right DP activities 
rather than investing in rework which is seen as an 
outcome of un-captured defects  
 
Page 881
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
  
1.2 SCOPE 
  
This document describes an analysis based on data 
obtained from leading software companies of 
varying software production competence. Defect 
prevention (DP) is a process of identifying defects, 
their root causes and corrective and preventive 
measures taken to prevent them from recurring in 
future. Identified defects are classified at two 
different points in time 1) time when the defect was 
first detected and 2) time when defect got fixed. If a 
defect dwells for a longer time in the product, it is 
more expensive to fix it. Therefore, it is necessary 
to reduce defect injection and boost defect removal 
efficiency. The cost of rework for 1% of defect 
when identified at the customer’s site is 10 times 
the cost required for fixing the same defect when 
identified in-house. As a matter-of fact, companies 
adapting to DP strategies over a period of time, 
quality of the product is enhanced while the cost of 
quality is reduced. This document covers all of the 
activities and support required to reduce cost and 
reduce rework from the software requirements 
analysis phase through completion of the system 
test phase of the software life-cycle.   
 
2.0 Methodology of data gathering and 
analysis 
2.1 Characteristics of Software Quality 
Software has both external and internal quality 
characteristics. External characteristics are 
characteristics that a user of the software product is 
aware of including,  
 Correctness- The degree to which a system 
is free from faults in its specification, 
design, and implementation. 
 Usability - The ease with which users can 
learn and use a system.  
 Efficiency - Minimal use of system 
resources, including memory and 
execution time.  
 Reliability - The ability of a system to 
perform its required functions under stated 
conditions whenever required—having a 
long mean time between failures.  
 Integrity - The degree to which a system 
prevents unauthorized or improper access 
to its programs and its data. The idea of 
integrity includes restricting unauthorized 
user accesses as well as ensuring that data 
is accessed properly—that is, that tables 
with parallel data are modified in parallel 
that date fields contain only valid dates, 
and so on.  
 Adaptability - The extent to which a 
system can be used, without modification, 
in applications or environments other than 
those for which it was specifically 
designed.  
 Accuracy - The degree to which a system, 
as built, is free from error, especially with 
respect to quantitative outputs. Accuracy 
differs from correctness; it is a 
determination of how well a system does 
the job it’s built for rather than whether it 
was built correctly.  
 Robustness - The degree to which a 
system continues to function in the 
presence of invalid inputs or stressful 
environmental conditions. Some of these 
characteristics overlap, but all have 
different shades of meaning that are 
applicable more in some cases, less in 
others.  
External characteristics of quality are the only kind 
of software characteristics that users care about. 
Users care about whether the software is easy to 
use, not about whether it’s easy for us to modify. 
They care about whether the software works 
correctly, not about whether the code is readable or 
well structured.  
Programmers care about the internal characteristics 
of the software as well as the external ones, and it 
focuses on the internal quality characteristics. They 
include  
 Maintainability - The ease with which we 
can modify a software system to change or 
add capabilities, improves performance, or 
correct defects.  
 Flexibility - The extent to which we can 
modify a system for uses or environments 
other than those for which it were 
specifically designed. 
 Reusability - The extent to which and the 
ease with which we can use parts of a 
system in other systems.  
 Readability - The ease with which we can 
read and understand the source code of a 
system, especially at the detailed-
statement level.  
 Testability - The degree to which we can 
unit-test and system-test a system; the 
degree to which we can verify that the 
system meets its requirements.  
 Understandability - The ease with which 
we can comprehend a system at both the 
system-organizational and detailed-
statement levels.  
The difference between internal and external 
characteristics isn’t completely clear-cut because at 
some level internal characteristics affect external 
ones. Software that isn’t internally understandable 
or maintainable impairs our ability to correct 
defects, which in turn affects the external 
characteristics of correctness and reliability. 
Software that isn’t flexible can’t be enhanced in 
Page 882
  
response to user requests, which in turn affects the 
external characteristic of usability. The point is that 
some quality characteristics are emphasized to 
make life easier for the user and some are 
emphasized to make life easier for the programmer.  
The following chart shows only typical relationship  
2.2 Finding a Defect 
Debugging consists of finding the defect and fixing 
it. Finding the defect (and understanding it) is 
usually 90 percent of the work. Debugging by 
thinking about the problem is much more effective 
and interesting than debugging with an eye of newt.  
2.3 The Scientific Method of Debugging 
Here are the steps we go through when we use the 
scientific method:  
i. Gather data through repeatable experiments.  
ii. Form a hypothesis that accounts for the relevant 
data.  
iii. Design an experiment to prove or disprove the 
hypothesis.  
iv. Prove or disprove the hypothesis.  
v. Repeat as needed.  
 
This process has many parallels in debugging. 
Here’s an effective approach for finding a defect: 
i. Stabilize the error.  
ii. Locate the source of the error (the “fault”).  
     a. Gather the data that produces the defect.  
     b. Analyze the data that has been gathered and 
form a hypothesis about the defect.  
     c. Determine how to prove or disprove the 
hypothesis, either by testing the program or by 
examining code.  
     d. Prove or disprove the hypothesis using the 
procedure identified in ii(c).  
iii. Fix the defect.  
iv. Test the fix.  
v. Look for similar errors.  
 
 
 
among the quality characteristics. On any given 
project, two characteristics might have a 
relationship that’s different from their typical 
relationship. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
2.4 BENEFITS OF EARLY 
DETECTION AND PREVENTION 
Table 2.4: Cost of Defects/ Price of quality 
Phase Relative Cost to Correct defect 
Definition  $1 
High-Level Design  $2 
Low-Level Design  $5 
Code  $10 
Unit Test  $15 
Integration Test  $22 
System Test  $50 
Post-Delivery  $100+ 
 
3.0 Analysis of Action, Description and 
Responsibility 
 
As special technical skills are needed, such as those 
of database administrators, quality assurance [21] 
specialists, human factors specialists, and technical 
writers, it becomes more and more important to 
plan organization structures carefully. Indeed, 
among the hallmarks of the larger leading-edge 
corporations are measurement specialists and 
measurement organizations. One of the useful by-
products of measurement is the ability to judge the 
relative effectiveness of organization structures 
such as hierarchical vs. matrix management for 
software projects and centralization vs. 
decentralization for the software function overall. 
Here too, measurement can lead to progress and the 
lack of measurement can lead to expensive 
mistakes.  
Page 883
  
Table 3.1: Overview of Software Estimation Steps 
 
Action 
 
Description 
 
Responsibility 
 
Output Summary 
 
Step 1: Gather and  
Analyze Software 
Functional & 
Programmatic  
Requirements  
 
Analyze and refine 
software requirements, 
software architecture, and 
programmatic constraints.  
 
Software manager, system 
engineers, and cognizant 
engineers.  
 
• Identified constraints  
• Methods used to refine 
requirements  
• Resulting requirements  
• Resulting 
architecture hierarchy  
Step 2: Define the  
 Work Elements and 
Procurements project.  
 
Define software work 
elements  and procurements 
for specific  
 
Software manager, system 
engineers, and cognizant 
engineers.  
 
• Project-Specific 
product based software 
WBS  
• Procurements  
• Risk List  
Step 3: Estimate  
Software Size  
 
Estimate size of software in  
logical Source Lines of 
Code (SLOC).  
 
Software manager, 
cognizant engineers.  
 
• Methods used for 
size estimation   
• Lower level and total 
software size  estimates 
in logical SLOC   
Step 4: Estimate  
Software Effort  
Software manager, 
cognizant  
 
Convert software size 
estimate in SLOC to 
software development 
effort.  Use software 
development effort to 
derive effort for all work 
elements.  
 
engineers, and software 
estimators.  
 
• Methods used to 
estimate effort for all  
work elements  
• Lower level and 
Total Software 
Development Effort in 
work-months (WM)  
• Total Software Effort 
for all work  elements 
of the project WBS in 
work-months  
• Major assumptions 
used in effort estimates  
Step 5: Schedule the  
effort  
 
Determine length of time 
needed to complete the 
software effort.   
Establish time periods of 
work elements of the 
software project WBS and 
milestones.  
Software manager, 
cognizant engineers, and 
software estimators.  
 
• Schedule for all work 
elements of project’s  
• software WBS   
• Milestones and 
review dates  
• Revised estimates 
and assumptions made  
Step 6: Calculate the  
Cost  
 
Estimate the total cost of 
the  
software project.  
 
Software manager, 
cognizant  
engineers, and software  
estimators.  
 
• Methods used to 
estimate the cost   
• Cost of procurements  
• Itemization of cost 
elements in dollars  
• across all work 
elements  
• Total cost estimate in 
dollars  
Step 7: Determine  
the Impact of Risks  
 
Identify software project 
risks, estimate their impact, 
and revise estimates.  
Software manager, 
cognizant  
engineers, and software  
estimators 
• Detailed Risk List  
• Methods used in risk 
estimation  
• Revised size, effort, 
and cost estimates   
•  
Step 8: Validate and  
Reconcile the  
Estimate Via Models  
and Analogy  
 
Develop alternate effort, 
schedule, and cost 
estimates to validate 
original estimates and to 
improve accuracy.    
Software manager, 
cognizant engineers, and 
software estimators.  
 
• Methods used to 
validate estimates  
• Validated and 
revised size, effort, 
schedule, and cost 
estimates.   
 
Page 884
  
Step 9: Reconcile  
Estimates, Budget,  
and Schedule  
 
Review above size, effort,  
schedule, and cost 
estimates and  
compare with project 
budget and  
schedule.  Resolve  
inconsistencies.  
 
Software manager, 
software  
engineers, software 
estimators,  
and sponsors.  
 
• Revised size, effort, 
schedule, risk and  
• cost estimates  
• Methods used to 
revise estimates  
• Revised functionality  
• Updated WBS  
• Revised risk 
assessment  
Step 10: Review and  
Approve the Estimates  
 
Review and approve 
software size effort, 
schedule, and cost  
Estimates 
The above personnel, 
software engineer with 
experience on similar 
project, line and project 
management.  
 
• Problems found with 
reconciled estimates  
• Reviewed, revised, 
and approved size, 
effort, schedule, and 
cost estimates  
• Work agreement(s), 
if necessary  
Step 11: Track,  
Report, and Maintain  
the Estimates  
  
  
 
Compare estimates with 
actual data.  Track estimate 
accuracy.  Report and 
maintain size, effort, 
schedule, and cost 
estimates at each major 
milestone. 
Software manager, 
software engineers and 
software estimators   
• Evaluation of  
comparisons of actual 
and  
• estimated data   
• Updated software 
size, effort, schedule, 
risk and cost estimates  
• Archived software 
data  
 
4.1 OBSERVATIONS ON THE OUTPUT OF ANALYSIS 
Table 4.1: Current Capability Assessment about REQUIREMANTS  
 
Table 4.2:  Current Capability Assessment about DESIGN 
 
Page 885
  
 
Table 4.3:  Current Capability Assessment about CODING 
 
 
Table 4.4:  Current Capability Assessment about TESTING 
 
 
Table 4.5: Current Defect Detection Assessments 
Page 886
  
 
 
5.0 Suggestions for improving better balance between quality and cost based on analysis 
In the previous tables we have certainly observed that prevention of defects and detection of early defects is 
the major requirement to improve software quality. If the error is detected at later stages the cost is also 
increasing proportionally in order to fixing the bugs. Even the quality decreases if the errors are detected at 
later stages because fixing a bug at later stages may add another bug and cause system malfunctioning. 
Based on the scenario we shall propose for improving better balance between quality and cost based on 
analysis are as follows:  
Table 5.1: Proposed Capability Assessment about REQUIREMANTS 
 
Table 5.2: Proposed Capability Assessment about DESIGN 
Page 887
  
 
Table 5.3: Proposed Capability Assessment about CODING 
 
 
Table 5.4 Proposed Capability Assessments about TESTING 
 
Table 5.5: Quality and Cost Benefit Based Analysis of proposed capability: 
Page 888
  
 
 
 
 
 
 
 
 
 
 
 
 
 
Page 889
  
6.0 Recommendation to improve  
 
6.1 Improve project SQA processes  
 
The SQA activity for process improvement 
requires:  
 
I) Understanding project and SQA processes 
II) Determining where inefficiencies or 
defects occur (root causes of defects) 
III) Recommending changes to project 
processes to improve efficiency or reduce 
defects 
IV) Recommending improvements to 
eliminate the root causes of defects 
V) Recommending training courses for the 
project team 
The purpose of this activity is for SQA to review 
existing project and SQA processes and report on 
efficiencies and areas for improvement and identify 
processes that need to be defined.   To improve 
project SQA processes, SQA needs to review and 
audit both project processes and SQA processes.   
This will ensure that project processes and project 
SQA processes are   
 
 
consistent and compatible with one another.  
Process improvement may result in changes to the 
policy, processes, and/or procedures. 
 
 
6.2 Measurements for Defect Analysis 
 
In some sense the goal of all methodologies and 
guidelines is to prevent defects. For example, a 
design methodology gives a set of guidelines that if 
used will give a good design. In other words, the 
design methodology aims to prevent the designer 
from introducing design defects by guiding him 
along a path that produces good and correct 
designs. 
However, by defect prevention (DP) we mean 
learning from actual defect data from a project with 
the goal of developing specific plans to prevent 
defects from occurring in the future. As the main 
goal of DP is reduction in defect injection and 
consequent reduction in rework effort, it is best if 
suitable measurements are made such that impact of 
DP can be quantitatively evaluated. That is, a 
project employing DP should be able to see the 
impact of DP in the injection rate and on the rework 
effort on the project. For both of these proper 
metrics have to be collected. Furthermore, suitable 
data needs to be collected to facilitate the root cause 
analysis for DP. 
The measurements needed for evaluating the 
effectiveness are defects and effort. For defects, 
data on all the defects found and their types is 
needed. 
This data is easily available if projects follow the 
practice of defect logging, as is the case in most 
mature organizations. To facilitate defect analysis, 
for each defect, its categorization in a fixed set of 
categories should also be recorded. A classification 
like the one proposed by the IEEE standards [23], 
or by the orthogonal-defect classification scheme 
[22] can be used. 
Frequently, organizations log information like 
detection stage, injection stage, etc to facilitate 
different types of analyses. Details about the 
different parameters recorded during defect logging 
are given in [9]. For understanding the impact of 
DP on rework, the effort spent on the project needs 
to be recorded with suitable granularity such that 
rework effort can be determined. Specifically, for 
each quality control activity, the rework effort 
should not be clubbed together with the activity 
effort but must be recorded separately. Effort 
logging generally requires that each member of the 
project team record the effort spent on different 
tasks in the project in some effort monitoring 
system Frequently, different codes are used for 
different categories of tasks and for most of the 
major tasks the effort is divided into three separate 
categories – activity, review, and rework. With this 
type of categorization, rework effort for each phase 
can be determined. Details about the system and 
codes used for effort reporting are given in [9]. 
These measurements about defects and effort are 
sufficient to do defect analysis and prevention, as 
well as quantify the impact of DP. Note that DP can 
be done, and its impact on the defect injection rate 
can be determined, even if the effort data is not 
available. However, without the effort data, the 
impact of DP on rework cannot be determined. 
 
7.0 Cost benefit analysis 
 
Costc of Practicing Current Process 
Costim of Practicing improved Process 
  
Cost increase = Costim - Costc  
                          = $1000 - $1500  
                          = $500 
   
Gross Benefit = [CDFc – CDFim + MCc – MCin + 
CPim - CPc] 
         = $2500- $500+$2500-$500+$1000-
$2000 
                        = $3000  
 
Net Benefit = Gross Benefit - Costin - Costc 
                    = $3000- $500-$1500 
      =$1000 
Page 890
  
 
 
Process Improvement(in thousand $) 1000 5000 10000 15000 20000 
Net Benefit($ ) 5000 25000 50000 25000 5000 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 7.0: Net Benefit vs Process 
Improvement Graph 
 
 
8. Conclusion and recommendations 
 
Defect prevention can improve both quality and 
productivity. If the number of defects injected 
reduces, then the quality improves as the number 
of residual defects in the delivered software 
reduces. Furthermore, if we inject fewer defects, 
fewer defects need to be removed at earlier stage, 
leading to a reduction in the effort required to 
remove defects. The subjectivity of Net benefits 
vs process improvement graph measures the 
visibility on defection and prevention of defects 
at earlier stages. Optimum Software quality 
assurance practices and reduce rework for cost 
benefit oriented analysis can be visible and 
analyzed thus organization can reach the 
objective of the best balance for improving 
quality product and cost reduction process. 
 
9. References 
 
[1]. V. R. Basili and A. Turner, Iterative 
enhancement, a practical technique for software 
development, IEEE Transactions on Software 
Engg., 1(4), Dec 1975. 
[2]. V. R. Basili, Ed., Tutorial on Models and 
Metrics for Software Management and    
Engineering, IEEE Press, 1980. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
[3]. V. R. Basili and H. D. Rombach, The 
experience factory, The Encyclopedia of 
Software Engineering, John-Wiley and Sons, 
1994. 
[4]. K. Beck, Extreme Programming Explained, 
Addison Wesley, 2000. 
[5]. E. J. Chikofsky, Changing your endgame 
strategy, IEEE Software, Nov. 1990, pp. 87, 112. 
[6]. Cockburn, Agile Software Development, 
Addison Wesley, 2001. 
[7]. Collier, T. DeMarco, and P. Fearey, A 
defined process for project postmortem review, 
IEEE Software, pp. 65-72, July 96. 
[8]. J. L. Hennessy and D. A. Patterson, 
Computer Organization and Design, Second 
Edition, Morgan Kaufmann Publishers, Inc., 
1998. 
[9]. P. Jalote, CMM in Practice – Processes for 
Executing Software Projects at Infosys, SEI 
Series on Software Engineering, Addison 
Wesley, 2000. 
[10]. C. Jones, Strategies for managing 
requirements creep, IEEE Computer, 29 (7): 92-
94. 
[11]. P. Kruchten, The Rational Unified Process – 
An Introduction, Addison Wesley, 2000. 
[12]. W. W. Royce, Managing the development 
of large software systems, IEEE Wescon, Aug. 
1970, reprinted in Proc. 9th Int. Conf. on 
Software Engineering (ICSE-9), 1987, 
IEEE/ACM,  pp. 328 
Page 891
  
[13]. Software Engineering Institute, The 
Capability Maturity Model for Software: 
Guidelines for Improving the Software Process, 
Addison Wesley, 1995. 
[14]. C. Larman, Applying UML and Patterns, 
2nd Edition, Pearson Education, 2002. 
[15]. C. Larman and V. R. Basili, "Iterative and 
Incremental Development: A Brief History", June 
2003, IEEE Computer. 
[16]. D. N. Card, “Learning from our mistakes 
with defect causal analysis”, IEEE Software, Jan-
Feb 1998. 
[17]. D. N. Card, “Defect causal analysis drives 
down error rates”, IEEE Software, July 1993. 
[18]. R. Mays et al., “Experiences with defect 
prevention”, IBM Systems Journal, 29:1, 1990. 
[19]. P. Jalote et. al., “Timeboxing: A process 
model for iterative software development”, 
Journal of Systems and Software, 2004, 70:117-
127. 
[20]. P. Jalote et. al., “The Timeboxing process 
model for iterative software development”, in 
Advances in Computers, 2004, Vol 6, pp 67-103. 
[21]. International Standards Organization, 
ISO900-1, Quality Systems – Model for Quality 
Assurance in Design/Development, Production, 
Installation, and Services, 1987. 
[22]. R. Chillarege et. al. Orthogonal defect 
classification – a concept for in-process 
measurements. IEEE  Transactions on Software 
Engineering, 18(11):943:956, Nov 1992. 
[23]. IEEE, Std. 1044-1993. IEEE standard 
definition, classification for software anomalies, 
IEEE 
 
 
 
 
---------------------------------------- 
Page 892
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Akkas U. Haque,  
E-mail: akkasuddin@gmail.com 
1. Speech Application Programming Interface (by Microsoft)  
DEVELOPMENT OF A VOICE CONTROLLED ROBOTIC ARM 
 
 
Humayun Kabir1, Akkas U. Haque1*, S. C. Banik2 and M. T. Islam3 
1Student, Department of Mechanical Engineering, CUET, Bangladesh 
2Assistant Professor, Department of Mechanical Engineering, CUET, Bangladesh 
3
 Professor, Department of Mechanical Engineering, CUET, Bangladesh 
Chittagong University of Engineering & Technology, Chittagong-4349, Bangladesh 
1
rajume06@yahoo.com, *akkasuddin@gmail.com,2baniksajal2yahoo.com,3tazul2003@yahoo.com 
 
This paper describes a robotic arm with 5 degrees-of-freedom (DOF) which is controlled by human voice 
and has been developed in the Mechatronics Laboratory, CUET. This robotic arm is interfaced with a PC by 
serial communication (RS-232). Users’ voice command is captured by a microphone, and this voice is 
processed by software which is made by Microsoft visual studio. Then the specific signal (obtained by signal 
processing) is sent to control unit. The main control unit that is used in the robotic arm is a microcontroller 
whose model no. is PIC18f452. Then Control unit drives the actuators, (Hitec HS-422, HS-81) according to 
the signal or signals to give required motion of the robotic arm. At present the robotic arm can perform a set 
action like pick & pull, gripping, holding & releasing, and some other extra function like dance-like 
movement, and can turn according to the voice commands.  
 
Key words: Speech recognition; Artificial Neural Networks; PWM; Serial communication; Microcontroller 
interfacing; SAPI. 
 
1. INTRODUCTION 
 
Nowadays industries, service centers(Hospital), 
shopping centers, and house hold works are fully 
dependent on  robotics & automation. For example, 
in a surgery, there are very few people besides the 
surgeon who actually contribute to the surgery. 
Most of the other people are there just to hand 
different tools and instruments to the surgeon, who 
is the one who actually does the surgery. Or, take 
the example of a mechanic. A mechanic almost 
always encounters situations in which he is forced 
to use a helper or assistant to do different things 
like holding two pieces of a machine together while 
welding, etc. It is thus seen that extra workforce is 
required, workforce that could otherwise be set to 
do other tasks. This is where the voice controlled 
robotic arm comes in. A robotic arm that is voice 
controlled enables the user to have more control 
over whatever task he is doing and also eliminates 
the need of unnecessary workforce. Also, the 
amount of stability and precision offered by the 
robot will be an added advantage over human 
assistants.  
 
That is why, we think about a robot which will be 
controlled by human voice command that is 
versatile and can be used in a variety of different 
atmospheres and scenarios. We have successfully 
completed the first step in achieving our goal. That 
is, our robot can now listen to vocal commands 
given to it and respond accordingly. The final plan 
involves the robot understanding common phrases 
from natural speech and acquiring the ability to 
work seamlessly and in perfect coordination with a 
person. 
 
2. THE ROBOTIC ARM 
 
To investigate the feasibility of a robot that 
operates on the basis of natural speech processing, 
we built a robotic arm that responds to basic 
commands given to it. 
 
2.1 Working 
A microphone receives the voice commands and 
feeds them to the computer. The SAPI1 engine 
detects the commands given and matches the 
commands with the dictionary created before. Once 
the commands are decoded, the necessary 
coordinates are fed to the function that calculates 
the angles required at each joint by the inverse 
kinematics mode of mechanics. These angles are 
then converted to the corresponding on-times 
required for the Pulse Width Modulation (PWM) 
for the servos. This information is then fed to the 
microcontroller via the USART mode of 
communication. The microcontroller used is an 8-
Page 893
ISBN: 978-984-33-2140-4
  
bit microcontroller, PIC16F852 from the microchip 
family.  
 
The microcontroller then sends the required pulses 
to the servos attached to the each of the joints of the 
robot. 
 
2.2 Flow of Control 
 
 
 
 
 
 
 
 
 
 
Fig. 1: Flow of control
 
2.3 Arm Overview 
The robotic arm we used in this exploratory 
research is a small hobbyist device called the Lynx 
6 by Lynxmotion. The arm has a total of five 
degrees of freedom (DOF): shoulder rotation, 
shoulder bend, elbow bend, wrist rotate, and wrist 
bend. A simple 2-prong gripper at the end of the 
arm is used to hold small objects. Figure 5 
demonstrates these controllable features. Although 
the arm has no feedback or sensors, it is still 
sufficient as a prototype arm for use in this proof of 
concept exploration. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 2: Lynxmotion Lynx 6
 
The circuit board provided along with the package 
was replaced by one that we designed specifically 
for our purpose. 
 
2.4 Speech Recognition 
The Speech Application Programming Interface
SAPI is an API developed by Microsoft to allow 
the use of speech recognition and speech synthesis 
 
 
 or 
within Windows applications. The SAPI engine is 
incorporated as a part of the Visual basic program
developed by us, which is responsible for decoding 
the vocal commands and sending the coordinates to 
the microcontroller. The SAPI engine is also 
responsible for the computer responding by means 
of speech. The version used in our research is 
SAPI4.0 which has features that include
Command, Voice Dictation, Dire
Recognition, Direct Text To Speech etc.
 
2.5 Artificial Neural Network 
An Artificial Neural Network (ANN) is an 
information processing paradigm that is inspired by 
the way biological nervous systems, such as the 
brain, process information. Artificial neural 
networks are made up of interconnecting artificial 
neurons (programming constructs that mimic the 
properties of biological neurons). Artific
networks may either be used to gain an 
understanding of biological neural networks, or for 
solving artificial intelligence problems without 
necessarily creating a model of a real biological 
system. The real, biological nervous system is 
highly complex and includes some features that 
may seem superfluous based on an understanding 
of artificial networks. 
 
Every neural network possesses knowledge which 
is contained in the values of the connections 
weights. Modifying the knowledge stored in the 
network as a function of experience implies a 
learning rule for changing the values of the weights.
 
 
 
 
 
 
               Fig. 3: Artificial Neural Network
Information is stored in the weight matrix W of a 
neural network. Learning is the determination of 
the weights. Following the way learning is 
performed, we can distinguish two major categories 
of neural networks: 
, 
 Voice 
ct Speech 
 
ial neural 
 
 
Page 894
  
Fixed networks in which the weights cannot be 
changed. In such networks, the weights are fixed a 
priori according to the problem to solve.
Adaptive networks which are able to change their 
weights. 
All learning methods used for adaptive neural 
networks can be classified into two major 
categories: 
Supervised learning which incorporates an 
external teacher, so that each output unit is told 
what its desired response to input signals ought to 
be. During the learning process global information 
may be required. Paradigms of supervised learning 
include error-correction learning, reinforcement 
learning and stochastic learning. 
Unsupervised learning uses no external teacher 
and is based upon only local information. It is also 
referred to as self-organization, in the sense that it 
self-organizes data presented to the network an
detects their emergent collective properties. 
Paradigms of unsupervised learning are Hebbian 
learning and competitive learning. 
The SAPI engine uses the adaptive ANN of the first 
type i.e. Supervised Neural Learning. The computer 
uses the engine to collect a large amount of speech 
data from the user and trains itself to recognize the 
sounds that it receives and interpret the words 
correctly. The training generates a dictionary of 
words and phrases that are continually updated with 
more training. Once ample training is given to the 
SAPI engine, it is then able to recognize the words 
or commands given to it easily. After training the 
engine, we then wrote a program in Microsoft 
Visual Basic that uses this engine to communicate 
with the user. At present, our 
recognize around 100 different commands and 
respond vocally as well as do the work it was 
designed to do, i.e. control the robotic arm.
 
2.6 Serial Communication 
We chose serial communication (RS
interface our robotic arm with the comp
communication was chosen because most of the 
computers have the necessary hardware and also 
because, it can be used over long distances without 
much loss in signal strength. 
 
Serial communication is the process of sending 
data one bit at a time, sequentially, over a 
communication channel or computer bus
(Recommended Standard 232) is a standard for 
serial binary single-ended data and control
 
d 
program can 
 
-232) to 
uter. Serial 
. RS-232 
 signals 
connecting between a DTE (Data Terminal 
Equipment) and a DCE (Data Circuit
Equipment). It is commonly used in computer
ports. The standard defines the electrical 
characteristics and timing of signals, the meaning 
of signals, and the physical size and pin out of 
connectors. The signals of RS-232 
suitable for use in TTL(Transistor
logic) compatible digital logic circuits. So,
MAX232 integrated circuit is used to convert 
signals of RS-232 to make suitable signals for use 
in TTL(Transistor–transistor logic)
digital logic circuits. The MAX232 is a dual 
driver/receiver and typically converts the RX, TX, 
CTS and RTS signals. It is helpful to understand 
what occurs to the voltage levels. When a MAX232 
IC receives a TTL level to convert, it changes a 
TTL Logic 0 to between +3 and +15
changes TTL Logic 1 to between -3 to 
vice versa for converting from RS232 to TTL. 
232 Voltage Levels are given below: 
Table1: Voltage levels 
RS232 Line Type & 
Logic Level 
         
RS232 
Voltage 
Data Transmission 
(Rx/Tx) Logic 0 
+3 V to 
+15 V 
Data Transmission 
(Rx/Tx) Logic 1 
-3 V to  
-15 V 
Control Signals 
(RTS/CTS/DTR/DSR) 
Logic 0 
-3 V to 
 -15 V 
Control Signals 
(RTS/CTS/DTR/DSR) 
Logic 1 
+3 V to 
+15 V 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
  
Fig. 4: Serial Communication(PC- microcontroller)
-terminating 
 serial 
serial are not 
–transistor 
 
 compatible 
 V, and 
-15 V, and 
RS-
TTL 
Voltage 
to/from 
MAX232 
0V 
5V 
5V 
0V 
 
Page 895
  
2.7 Pulse-Width Modulation 
Pulse-width modulation (PWM) is a commonly 
used technique for controlling power to inertial 
electrical devices, made practical by modern 
electronic power switches. We used PWM to 
control Servo motor (HS-422 & HS81). PWM, as 
the name suggests, is a method of controlling 
devices by varying the length of the pulse in a 
given time period.  
 
 
 
 
 
 
Fig. 5: Duty cycle 
 
Duty Cycle describes the proportion of 'on' time to 
the regular interval or 'period' of time; a low duty 
cycle corresponds to low power, because the power 
is off for most of the time. Duty cycle is expressed 
in percent, 100% being fully on. 
Duty Cycle,   =            
Where,    
t = on state or high state 
Τ = the period of the function. 
 
We chose the servos because they have the control 
circuits built in, and they have the highest torque to 
weight ratio and also because they can be precisely 
controlled by PWM. On the other hand, stepper 
motors and DC motors were both out of question 
due to weight constraints. 
In Servo Motor Control, the time period of 
oscillation is 20ms. And the on-time varies from 
1ms for 0 degrees to 2ms for 180 degrees. 
 
 
 
 
 
 
 
 
 
 
                      
 
 
 
Fig. 6: Servomotor control PWM diagram 
 
2.8 Inverse Kinematics 
The kinematics solution of any robot manipulator 
consists of two sub problems, forward and inverse 
kinematics. Forward kinematics determines where 
the robot’s manipulator hand will be if all joints are 
known whereas inverse kinematics is used to find 
out where each joint variable must be if the desired 
position and orientation of end-effector is pre-
determined. 
 
The kinematics that we applied in this research was 
Inverse Kinematics. As shown in the diagram, the x 
and y coordinates of the end effector on the plane 
along a specified angle of the base is known. The 
angles at each joint are then calculated based on the 
equations derived by IK method.  
 
2.8.1 Geometric Solution for IK Equations 
of the Arm 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 7: Geometric Solution for IK equations 
 
Let the coordinates of the end effector be (a,b, ) 
where a,b are the coordinates of the effector in the 
plane which is offset at an angle of from the xy 
plane. 
 
From the figure,  
 a = lcosθ + lcosφ b = lsinθ + lsinφ 
Rearranging, we get, 
cosθ − φ = a
 + b − l + l2ll  
 
 
Taking γ = θ − φ, we get, 
γ = arccos a + b − l + l2ll  
 
Taking, 
α = arctan ba 
 
Now applying sine rule for the triangle OAB,  
we get, 
Page 896
  
 sin θ − αl =
sin α− φ
l =
sin θ
√a + b 
 
Solving we get the values of θ , θ and θ as, 
 
θ = α+ arcsin  lsin γ√a + b 
θ = pi− γ 
θ = pi+ arcsin  lsin γ√a + b − α 
 
3. CONCLUSIONS 
 
The robotic arm was tested with different users and 
with sufficient training was able to respond to 
commands with an accuracy of almost 90 percent. 
Based on our study, we were able to conclude that 
it is possible to create robots for industrial 
applications that could interact with humans 
verbally and also help users to do their required 
tasks quickly and efficiently. At present our robotic 
Arm can perform griping, holding & releasing 
object and dancing according to user voice 
command. It can also perform the conversation 
with users. This robotic can be developed without 
PC interfacing by using DSP(digital signal 
processing) module or HM-2007 & SPO-256 IC’s.  
 
REFERENCES 
 
1. Sporka, A. J., and Slavik, P. Vocal control of a 
radio-controlled car. ACM SIGACCESS 
Accessibility and Computing, 91 (2008), 3–8. 
2. Igarashi, T., and Hughes, J. Voice as sound: 
usingnon-verbal voice input for interactive 
control. In UIST(2001), pp. 155–156. 
3. Kim, S.-P., Simeral, J. D., Hochberg, L. R., 
Donoghue, J. P., AND BLACK, M. J. Neural 
control of computer cursor velocity by 
decoding motor cortical spiking activity in 
humans with tetraplegia. Journal of Neural 
Engineering 5, 4 (2008), 455–476. 
4. Li, Y., Wang, C., Zhang, H., and Guan, C. An 
eeg-based bci system for 2d cursor control.  
IEEE Int’l Joint Conf. on Neural Networks 
(June 2008), 2214–2219. 
5. Roman M. Balabin, Ekaterina I. Lomakina 
(2009). "Neural network approach to quantum-
chemistry data: Accurate prediction of density 
functional theory energies". J. Chem. Phys. 131 
(7): 074104. doi:10.1063/1.3206326. 
PMID 19708729] 
6.  Hertz, J., Palmer, R.G., Krogh. A.S. (1990) 
Introduction to the theory of neural 
computation, Perseus Books. ISBN 0-201-
51560-1  
7. Lawrence, Jeanette (1994) Introduction to 
Neural Networks, California Scientific 
Software Press. ISBN 1-883157-00-5 
8. SHENOY, P., KRAULEDAT, M., 
BLANKHERTZ, B.,RAO, R., AND 
MUELLER, K.-R. Towards adaptive 
classification for BCI. J. Neural Eng. 3 (2006), 
R13–R23. 
9. Electronics Industries Association, "EIA 
Standard RS-232-C Interface Between Data 
Terminal Equipment and Data Communication 
Equipment Employing Serial Data 
Interchange", August 1969, reprinted in 
Telebyte Technology Data Communication 
Library, Greenlawn NY, 1985 
10. Paul Horowitz and Winfield Hill, The Art of 
Electronics Second Edition, Cambridge 
University Press, Cambridge MA, 1989, ISBN 
0-521-37095-7 
11. WON, S. Y., LEE, D.-I., AND SMITH, J. 
Humming control interface for hand-held 
devices. In ASSETS(Oct. 2007), pp. 259–260. 
12. Reichenspurner, H., ET AL. Use of the voice-
controlled and computer-assisted surgical 
system ZEUS for endoscopic coronary artery 
bypass grafting.J. Thoracic and Cardiovascular 
Surgery 118 (1999), 11– 16. 
13. Wang, L.-C., and Chen, C. A combined 
optimization method for solving the                                  
inverse kinematics problem of mechanical  
manipulators. IEEE Trans. On Robotics and 
Automation 7, 4 (1991), 489–499. 
14. Welman, C. Inverse kinematics and geometric 
constraints for articulated figure manipulation. 
Master’s thesis, Simon Fraser University, 
Burnaby, BC, 1993. 
15. Mihara, Y., Shibayama, E., and TAKAHASHI, 
S. The Migratory Cursor: Accurate speech-
based cursor movement by moving multiple 
ghost-cursors using non-verbal vocalization. In 
ASSETS (Oct. 2005). 
16. Harada, S., Wobbrock, J., and Landay, J. 
VoiceDraw: A hands-free voice-driven 
drawing application for people with motor 
impairments. In ASSETS (Oct. 2007), pp. 27–
34. 
17. Choi, Y. S., Anderson, C. D., Glass, J. D., and 
Kemp, C. C. Laser pointers and a touch screen: 
intuitive interfaces for autonomous mobile 
manipulation for the motor impaired. In 
ASSETS (Oct. 
2008), pp. 225–232. 
 
 
 
 
 
 
 
Page 897
  
 
 
 
Page 898
 Proceedings of the 
International Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: S. S. Azmiri Khan,  
E-mail: shermin03@yahoo.com 
DISPERSION AND DISPERSION SLOPE COMPENSATION USING 
LINEARLY CHIRPED APODIZED FIBER BRAGG GRATING 
 
 
S.  S. Azmiri Khan* and M. S. Islam 
 
Institute of Information and Communication Technology 
Bangladesh University of Engineering and Technology 
Dhaka, Bangladesh 
 
 
In this paper, we have proposed an analytical model to compensate both dispersion and dispersion slope in 
an optical transmission system using linearly chirped apodized fiber Bragg grating (FBG). We have 
developed an analytical formulation to calculate the value of linearly decreasing grating period and 
demonstrated an accurate selection of the apodization strength factor of Sinc apodization profiles of linearly 
chirped FBG based dispersion compensation. It is found that a proper choice of the apodization strength 
factor results in minimum deviation of the dispersion from the required level and maximum reflection 
bandwidth. Thus using a linear chirped Sinc apodized FBG can compensate dispersion and dispersion slope 
simultaneously. 
 
Key words: Fiber Bragg Grating, Sinc apodization, strength factor, dispersion slope 
 
1. INTRODUCTION 
 
With the rapid increase of information industry in 
the world, high speed and big capacity 
communication networks become more and more 
insistent. Optical fiber communication system has 
this speed and capacity. But dispersion becomes the 
major obstacle for up-gradation to this system. 
Dispersion slope is particularly troublesome when 
increasing the system’s bit rate. Fiber Bragg grating 
(FBG) is proving compensation to the dispersion 
and dispersion slope in this regard. Dispersion is 
the time domain spreading or broadening of the 
transmission signal light pulses as they travel 
through the fiber. The optical pulse is made of more 
than one component. Each component travels at 
slightly difference speed. Therefore different 
components will arrive at receiver at different 
times. This result of the spreading of the output 
pulse is called chromatic dispersion [1]. The use of 
higher bit rates for single channel propagation is of 
interest in WDM systems. The dispersion slope is 
particularly troublesome when increasing the bit 
rate of the system. 
 
FBG is proving to be one of the most important 
developments in the field of the optical fiber 
technology especially because of the absence of 
nonlinear effects [2]. In recent years, many research 
and development projects focused on the study of 
FBG and these are used in optical communication 
links in different applications such as all-optical 
routers, selective filters, gain equalizers, sensors 
and dispersion compensators [3-4]. Some previous 
work on grating demonstrated that the apodization 
sharpness parameter plays a more important role in 
the behavior of the mean dispersion than the type of 
apodization profile itself [5]. But various 
apodization profiles can be used in order to make 
the reflection spectrum more smooth and linearized 
the dispersion characteristics [6-7]. 
 
Recently phase-samples FBGs have been proposed 
for compensating the dispersion by chirping both the 
grating period and sampling period [8-9]. 
Simultaneous dispersion and slope compensation 
has been done by using phase only sampled FBG 
[10-11]. Works on apodized FBG carried out when 
operated in transmission [12-13]. Tunable dispersion 
compensation using a chirped apodized FBG in 
transmission was demonstrated both experimentally 
and numerically in [14]. In our previous paper [15] 
we have shown the chromatic dispersion 
compensation by using linearly chirped apodized 
FBG. 
 
 In this research an analytical model was developed 
to compensate the dispersion and dispersion slope 
simultaneously in an optical transmission system 
using linearly apodized fiber FBG. 
 
Page 899ISBN: 978-984-33-2140-4
  
2. SYSTEM MODEL 
 
In order to evaluate the effects of our proposed 
FBG, we have considered the system as shown in 
Fig. 1. The input pulses are launched to a link of 
standard single mode fiber. The output broadened 
pulses are then fed to a linearly chirped apodized 
grating through the optical circulator to get the 
recompressed pulse. This component extracts the 
restored pulse and that is reflected by the grating 
 
 
Fig. 1: System model of dispersion compensation 
 
 
3. THEORETICAL ANALYSIS 
 
The apodized and linearly chirped FBG structure 
with a refractive index modulation along the 
propagation direction of the core is given by 
2( ) 1 ( ) cos ( )
eff
B
n z n n z m z
pi ϕ
    
= + ∆ + +    Λ    
 ; 
2 2
g gL L
z− ≤ ≤                     (1) 
The equation is defined in the z axis from -Lg/2 to 
Lg/2, where Lg is the whole length of the fiber 
Bragg grating.  
where            ( )( )
eff
nT z
n z
n
∆∆ =                              (2) 
is the refraction index modulation depth and T(z) is  
the apodization profile/function.  
where       1 2( ) sin
2
B
A
g
zT z c
L
   
  =        
                  (3) 
ΛB is reference Bragg grating period at the center of 
the structure. The parameter m is the fabrication 
process penalty as a dc index change. For linearly 
chirped gratings, the chirp can be defined through 
the parameter F (chirp factor) which determines the 
variation in the phase term is expressed as  ( )zϕ  = 
grating phase,    
                      
2
2( ) 2 g
Fz
z
L
ϕ =                                      (4) 
The parameter take are A=1, B=2   The main 
spectral functions under the study is the reflection 
coefficient, r=|ρ2| where ρ is the reflectivity 
coefficient [2] and given by  
2
2
2
2
sinh ( ( ) )( )
ˆ ( )
cosh ( ( ) ) ( )
z L
r z
z
z L
z
γ
σγ
κ
=
−
                (5) 
where ( 2 2ˆ( ) ( ( ) ( ) )z z zγ κ σ= −  ) and the coupling 
coefficient ĸ(z) is related to the amplitude of the 
envelope function of the induced changes by  
                   ( ) ( )( )B eff
n
z T z
z n
pi
κ λ
∆
=                        (6) 
As λB is the Bragg wavelength, if we vary grating 
period linearly then λB will also vary as well as ĸ 
will also varies linearly with grating period. And 
general ‘dc’ self coupling coefficient   define as  
1
ˆ ( ) ( ) ( )
2
z z F zσ δ σ= + −                         (7) 
where, δ is detuning parameter and σ is dc coupling 
coefficient, which is independent on z. 
The delay time τp for light reflected off of a grating 
is 
2
2
p p
p
d d
d c d
θ θλ
τ
ω pi λ= = −
                 (8) 
Thus we find the delay time τp  as shown in the 
equation (18) 
{ }
3
2 2 2
3/2
2
ˆ ( )( )
ˆ ( ) ( ) coth( ( ) ) ( )
coth( ( ) )
ˆ( ) ( ) coth( ( ) )
ˆ ( )
( ) csc ( ( ) )
ˆ ( )
eff
p
g
g
g
g g
z n
z
z z z L z c
z L
z z z L
z
z L h z L
z
σ
τ
σ γ γ γ
γ
γ σ γ
σ
γ γ
σ
−
= ×
+
 
− 
 
 
 
− 
 
(9)    
Second order dispersion is calculated as equation 
(19)                            
2
2 2
2p p
p
d dcd
d d
τ θpi
λ λ ω= = −
                 (10) 
Third order or dispersion slope is calculated as rate 
of change of dp with respect to dλ. That is  
p pdd dd
d d d
τ
λ λ λ
 
=  
 
                           (11) 
 
4. RESULTS AND DISCUSSION 
 
To design a linearly chirped apodized FBG we vary 
grating period Λ linearly. As shown in our previous 
work [15]. We divided grating length Lg into many 
small segments. We have design a linearly 
negatively chirped fiber brag grating structure by 
Page 900
  
using geometric series. As we varied grating period 
ΛB linearly then the Bragg wavelength λB also 
varied, as shown in Fig. 2, where different 
wavelength is reflected from different length of 
grating period.  
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 1.1
500
1000
1500
2000
2500
3000
Grating period (mm)
Br
ag
g 
w
av
ele
ng
th
 
(nm
)
 
Fig.2: Linearly chirped grating period (with 200segment, 
length of 1st period is 1.6 mm, and linearly decrease by a 
factor of 0.99 mm) versus Bragg wavelength 
 
The Fig. 3 shows the plot of grating length Lg 
against the apodization factor strength aeff. Sinc 
grating length Lg is a major constraint in terms of 
mask length availability and exposure times. We 
got the maximum value of grating length is 10cm 
for the aeff grater than 0.6. 
 
 
Fig. 3: Time trend of temperature data 
 
The second order dispersion dp (in ps/nm) is the 
rate of change of delay with respect to wavelength. 
Third-order dispersion compensation refers to the 
compensation over several WDM channels of both 
the second order pp
dd d
τ
λ
 
= 
 
 and third-order 
pdd
dλ
 
 
 
 dispersion effects. For such an operation, 
the compensator is required to have a different 
dispersion value for each of the channels. 
 We have calculated the rate of change of delay    
(express in ps/nm) numerically by using Centred 
Finite Divided Difference formula. We found that 
dp changes linearly for all reflected wavelengths as 
shown in Fig. 4 (c). 
 
1554 1554.5 1555 1555.5 1556 1556.5 1557 1557.5 1558 1558.5
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
Wavelength(nm)
Re
fle
ct
iv
ity
(a) 
1554 1554.5 1555 1555.5 1556 1556.5 1557 1557.5 1558 1558.5
-400
-300
-200
-100
0
100
200
300
400
Wavelength(nm)
De
la
y(p
s
)
 (b) 
1553.5 1554 1554.5 1555 1555.5 1556 1556.5 1557 1557.5 1558 1558.5
1050
1100
1150
1200
1250
1300
Di
sp
er
si
on
 
co
ef
fic
ie
nt
 
(ps
/n
m
)
Wavelength (nm)
 
(c) 
Fig. 4: (a) Reflectivity and (b) Delay spectra of an 8-
channel WDM system by using proposed dispersion 
compensation grating. The bullet in the graph (c) gives 
the dispersion values obtained. 
 
In Fig. 4 (a) and (b) graphs shows the plot of 
reflectivity and delay versus wavelength of an 8-
channel WDM system, and the third one graph (c) 
shows the plot of dispersion coefficient versus 
wavelength for an 8-channel WDM system. We 
found that dispersion is linearly decreasing for 
every channel, so as the dispersion slope 
decreasing.  We can say that apodized grating with 
Page 901
  
a chirped in the grating period can compensate the 
both second and third order dispersion. 
 
The Fig. 5 shows the plot of pulse regeneration we 
obtain from linearly chirped FBG. If the initial 
pulse width is 100 ps (solid curve). The pulse is 
broadened to 190 ps (dashed dot curve) after it 
propagates over fiber length Lf =100km, FBG then 
recompressed the pulse (dashed curve) about the 
same as input pulse.
 
 
−60 −40 −20 0 20 40 60
−0.6
−0.4
−0.2
0
0.2
0.4
0.6
0.8
1
Time in ps
A
m
pl
itu
de
 
 
input pulse
boardened pulse
recompressed pulse
 
Fig. 5: Pulse regeneration with linearly chirped FBG 
having input pulse width=100ps  
 
 
7. CONCLUSION 
 
Dispersion compensation management plays a 
critical role in the overall performance of an optical 
transmission system. We have developed the 
analytical formulation that can effectively 
compensate the both second and third order 
chromatic dispersion. In summary, we have 
demonstrated that by using linearly chirped Sinc 
apodized FBG of apodization strength factor in the 
ranges of 0.7 - 0.8 can compensate both second and 
third order dispersion for a 8-channel WDM 
system. 
 
REFERENCES 
 
1. Djafor K.Mynbaev, Lowell L. Scheiner, Fiber 
optic communication technology, India, 2001. 
2. Raman Kashyap, , Fiber bragg gratings, 2nd 
ed., USA, 2010. 
3. P. I. Reyes,N.Litchinister,M.Sumetsky,Paul S. 
Westbroob, “160-Gb/sTunable dispersion slope 
compensator using a Chirped fiber bragg 
grating and a quadratic heater,” IEEE 
Photonics Technology Letters, vol. 17, no. 4 
pp. 831–833, Apr. 2005 
4. sabelle Raint, “Fiber Bragg grating for optical 
telecommunications,” Comptes Rendus 
Physique , vol. 4, pp. 41-49, 2003 
5. Jin Chai, Zhongyuan Yu, Yumin Liu, 
“Analysis of the apodization parameter of 
linearly chirped bragg gratings for dispersion 
compensation,” in IEEE,  pp. 1263–1276, Jun. 
2006 
6. O. Mahran, Taymour A. Hamdallah, Moustafa 
H. Aly and Ahmed E. El-Samahy, “Apodized 
Chirped Fiber Bragg Gratings for Wavelength 
Shift Compensation under Sea Level,” Journal 
of Applied Sciences Research , vol. 5, no. 10, 
pp. 1592-1603, 2009 
7. P.F ernandez, J.C. Aguado, J. Blas, R. Duran, 
et al, “Optimization of the apodization strength 
of linearly chirped Bragg gratings for span 
dispersion compensation,” in Optical and 
Quantum Electronics, vol.36, pp. 57-66, 2004. 
8. H. Lee and G. P. Agrawal, “Purely phase-
sampled fiber Bragg gratings for broad-band 
dispersion and dispersion slope dispersion,” in 
IEEE Photon. Technol. Lett. vol.15, pp.1091-
1093, 2003 
9. H. Lee and G. P. Agrawal, “Bandwidth 
equalization of purely phase sampled fiber 
Bragg gratings for broadband dispersion and 
dispersion slope compensation,”  Fiber optics 
communication, vol. 12, no. 23,  pp. 5595-
5602, Nov 2004 
10. Ming Li, Hougpu Li, “Reflection equalization 
of the simultaneous dispersion and dispersion 
slope compensator based on a phase only 
sampled fiber bragg gratings,” Optics Express, 
vol. 16, no. 13, pp. 9821-9828,  Jun 2008 
11. E. J. Gualda, L. C. Gomez-Pavon, J. P. Torres, 
“Compensation of Third order dispersion in a 
100Gb/s single channel system with in line 
fiber bragg gratings,” Journal of modern optics, 
vol. 52, no. 9,15, pp. 1197-1206, Jun 2005 
12. D.Vanden Brone, V. Veljanovski, E. 
Gottwarld, H. de Waardt, “Fiber bragg gratings 
for in line dispersion compensation in cosr 
effective 10.7Gbit/s long haul transmission,” 
Peoceedings Symposium IEEE/LEOS benelux 
chapter,  pp. 177–180, 2006 
13. Morten Ibsen, Ricardo Feced, “Fiber bragg 
gratings for pure dispersion slope 
compensation,” Optics Letters, vol. 28, no. 12,  
pp. 980–982, June. 2003 
14. Mohamed Hany, Moustafa H. Aly1, M. Nassr 
“Dispersion compensation using tunable 
chirped apodized far off resonance fiber bragg 
gratings in transmission,” Journal of Applied 
Science Research, 2009Paul, M.K. and Quader, 
A.K.M.A.,(2002), A study of the air pollution 
of Dhaka city, Proceedings of CHEMCON 
2002, India, December 19-22, 2002. 
15. S. S. Azmiri Khan and M. S. Islam, 
“Chromatic Dispersion Compensation Using 
Linearly Chirped Apodized Fiber Bragg 
Grating,” Proc. of ICECE, Dec. 2010, pp. 9-12. 
Page 902
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Shovan Roy,  
E-mail: shovan_bd@yahoo.com  
INTRODUCING GREEN ICT FOR DIGITAL BANGLADESH 
 
Shovan Roy*and Ahsan Habib 
Metropolitan University, Sylhet, Bangladesh 
 
Green computing or green ICT refers to environmentally sustainable computing or ICT. It is the study and 
practice of designing, manufacturing, using, and disposing of computers, servers, and associated 
subsystems—such as monitors, printers, storage devices, and networking and communications systems—
efficiently and effectively with minimal or no impact on the environment [1]. This paper shows some green 
initiatives towards digital Bangladesh and also shows some challenges towards green DB. 
 
Key words: Green ICT, Green Computing, Digital Bangladesh, Environmentally Sustainable Computing, 
Energy Saving ICT. 
 
1. INTRODUCTION 
 
Information and communication technology (ICT) 
drives the technological and economic 
advancement of the developed as well as emerging 
economies. The government of Bangladesh wants 
to make Bangladesh fully digitized by 2021 through 
application of third generation ICT. Energy crisis is 
a burning issue for most of the countries in the 
world including Bangladesh. ICT systems consume 
significant amount of energy so energy saving ICT 
systems should be introduced. Environmental 
impact should have to be considered, while 
deploying ICT towards Digital Bangladesh. 
Introducing green ICT policies in the ICT sector 
and creating awareness among ICT professionals 
and government about energy consumption and 
subsequent carbon dioxide emissions from 
commercial ICT equipment will help reducing 
emission impact from ICT and will boaster 
Bangladesh to be a Green Digital Bangladesh. 
 
1.1 Digital Bangladesh 
 
The concept of Digital Bangladesh should be 
termed as a “knowledge-based society,” in which 
creation and exchange of “knowledge” becomes an 
increasingly key factor of production, and in the 
process reducing the relative importance of 
traditional factors of production such as land, labor 
and capital. Information and communication  
technologies (ICTs) are a critical component for 
building this knowledge-society. So, Digital 
Bangladesh, in that sense, is the crucial platform, 
the enabler for such a vision. 
 
1.2 Green ICT 
 
Green ICT is defined as ICT, which as a result of 
usage, produce comparatively low levels of carbon 
emissions while having the potential to 
exponentially reduce emissions in other areas by 
catalyzing technological, institutional and 
behavioral change, while bringing forth socio-
economic benefits. 
 
1.3 Why Green ICT for DB 
 
ICT has a significant and emerging impact on 
carbon emissions and climate change. Use of ICT 
in Bangladesh is increasing day by day. Bangladesh 
is a remarkable buyer of ICT equipments and its 
ICT sector fully dependent on the import of ICT 
equipments. Not only new equipments but also 
huge volume of used ICT hardware equipments are 
imported every year which might cause a threat for 
Bangladesh to be a dumping station of e-waste. So, 
it is the responsibility of the Bangladesh 
Government how ICT could be used to attain 
environmental sustainability, limiting power 
consumption and protecting Bangladesh against the 
dumping station of e-waste. Following an effective 
Green ICT strategy will improve organizational 
efficiency in lowering energy costs, reducing 
carbon emissions and enhanced services. 
Page 903
ISBN: 978-984-33-2140-4
  
 
Fig. 1: CO2 emissions by ICT equipments [2] 
 
1.3.1 How big is the carbon footprint of 
the ICT sector? 
 
On a global scale, some analyst reports have 
calculated that ICT represents 2 percent to 2.5 
percent of the total global carbon emissions, which 
is equivalent to the global aviation industry. [3] 
 
In 2008, The Climate Group and the Global e-
Sustainability Initiative (GeSI) issued SMART 
2020: enabling the low carbon economy in the 
information age. The study highlighted the 
significant and rapidly growing footprint of the ICT 
industry and predicted that because of the rapid 
economic expansion in places like India and China, 
among other causes, demand for ICT services will 
quadruple by 2020 [2]. 
 
SMART 2020 also found that: 
• PC ownership will quadruple between 2007 and 
2020 to 4 billion devices, and emissions will 
double over the same period, with laptops 
overtaking desktops as the main source of global 
ICT emissions (22%). 
 
• Mobile phone ownership will almost double to 
nearly 5 billion accounts by 2020, but emissions 
will only grow by 4%. Broadband uptake will 
treble to almost 900 million accounts over the 
same period, with emissions doubling over the 
entire telecoms infrastructure. 
 
The Smart 2020 study also made a compelling case 
for ICT’s significant potential to deliver climate 
and energy solutions, estimating that ICT 
technologies could cut 7.8 GtCO2 of global 
greenhouse gas emissions by 2020, a 15% 
reduction over business-as-usual projections. The 
study posits that innovations from the ICT sector - 
when combined with increased use of renewable 
energy - can put the world on a more sustainable 
path and help keep global temperature increase 
below the 2°C threshold scientists say is needed to 
hold off the worst effects of climate change. 
Page 904
  
 
Fig. 2: CO2 emissions throughout the world [2]. 
 
2. INITIATIVES 
 
Bangladesh is one of the most severely affected 
countries of the world due to climate change and 
global warming effects. Bangladesh Government is 
concerned with these issues. Green energy program 
already introduced in Bangladesh to find a 
sustainable solution. Private and public both sector 
have taken some initiatives to implement energy 
saving ICTs. 
 
a) Leading mobile phone operator Grameenphone 
(GP) installed 14 renewable energy solutions at 
base stations, including a windmill, in 2008. 
GP is set to supply solar generated power in 
bulk to 140 of its sites that are currently run by 
diesel generators by the yearend. The 
generators consume nearly 1.15 million litres 
of diesel a year -- an amount enough to irrigate 
nearly 13.77 acres of land overall. The diesel 
consumed by GP accounts for 3,062 tonnes of 
carbon omissions a year. Currently, the 
telecom operator has 7,500 sites with 12,000 
base stations [4].  
b) Clean Development Mechanism (CDM) 
projects being implemented in Bangladesh by 
the Ministry of Environment and Forest with 
support from the UNDP. 
c) In public procurement energy saving ICT 
equipments are being encouraged.  
d) Bangladesh power development board 
encouraging green power energy by 
implementing a new strategy: when a 
consumer apply for getting a new power supply 
it is required to implement own financed solar 
power to an extent to get it. 
e) Solar power system has been installed at the 
Prime Minister’s Office (PMO) of Bangladesh 
in a move to encourage green energy 
expansion. The move followed a government 
decision for establishing solar power units in 
all public and semi-government offices to 
promote expansion of renewable energy from 
the sun, wind, biomass, and biogas — with an 
aim to meet 5 percent of the country’s total 
power demand by 2015, and 10 percent by 
2020 [5]. 
f) Bangladesh's central bank has switched over to 
solar-powered lighting, in a move to encourage 
green energy. 
g) The government also focused on use of energy 
saving light bulbs. The power division of 
Bangladesh government has been 
implementing the free distribution of Compact 
Flurescent Lamp (CFL) to save power 
consumption. The bulbs are also durable and 
environment friendly as those emit a very low 
carbon to atmosphere. 
h) Government encouraging the use of 
Compressed Natural Gas (CNG) driven public 
transport to minimize CO2 emission. 
Page 905
  
3. NEEDS 
 
It is impossible to conceive digital Bangladesh 
without “Energy”. Energy crisis is one of the major 
issues for Bangladesh. Government of Bangladesh 
is working towards achieving “Power i.e. 
Electricity for All” by the year 2020. Densely 
populated country like Bangladesh can only sustain 
and progress if only latest energy saving 
technologies can be used efficiently.  
 
The main challenge to using solar energy is in 
running the air-conditioners that are used to remove 
the heat generated by electric equipment. As air 
conditioners consume more power, replacing the air 
conditioners with direct-current fans that can save a 
huge amount of power. 
 
ICT professionals can play a vital role to introduce 
green energy saving technologies towards digital 
Bangladesh. To support Green ICT campaign here 
are a few best practices. 
 
a) Data center optimisation: Effective optimisation 
and utilisation of servers is important because of 
the level of energy used to power and cool them. 
Increased utilisation can lead to server 
rationalisation saving energy and cutting carbon 
[6]. 
b) Server Virtualisation: using virtualisation 
technology to reduce the number of servers in 
use [6]. 
c) Desktop Virtualisation: Implement desktop 
virtualisation using ultra-small, secure clients on 
the desktop and linking the thin clients to their 
own virtual desktop machines residing on 
servers. With desktop environment consolidated 
within the data centre, firms can deliver secure, 
isolated desktops that consume less energy [6]. 
d) Recycling: Break down computers into 
components and components into raw materials 
for reuse. 
e) Deploying innovative information technology 
solutions, such as Cisco’s SmartGrid, 
Energywise, and TelePresence. 
f) Moving to blade servers that use less power and 
require much less cooling. 
g) Configuring power management settings on new 
computers to reduce power consumption e.g. put 
PCs into low power modes after specified 
periods of inactivity.  
h) Turning off PC overnight, at weekends and 
during holiday periods. 
i) Switched off printers and other peripheral 
equipment after use.  
j) Refrain from printing emails whenever possible  
k) Removing active screen savers. 
l) Double-sided printing is a simple way to 
conserve thousands of pages of paper. 
m) Using gray scale to reduce the amount of 
maintenance and transport required and 
electricity, paper and toner used. 
n) Versatile multifunction devices can streamline 
workflows, boosting efficiency.  
o) Encouraging network printer instead of one desk 
one printer approach.  
p) Using software to run multiple operating 
systems on one device rather than using a 
separate device for each OS 
q) Reducing travel requirements through the use of 
video-conferencing. 
r) Flexible/mobile working.  
s) Reducing waste. 
t) Encouraging paper less office. 
 
4. RECOMMENDATIONS 
 
Government has a significant role to play in 
introducing green ICT towards digital Bangladesh. 
Government should: 
a) Introduce environmental concern in the national 
ICT policy including GHG emissions reduction. 
b) Make political commitment and national 
consensus to effectively encounter the energy 
ehallenges. 
c) Increase awareness of the importance of green 
ICT. 
d) Introduce new public procurement rules and 
regulations to purchase energy saving and eco-
design ICT equipments eliminating hazardous 
goods. 
e) Encourage green ICT procurement by the public 
and private sector. 
f) Create a Green ICT Stimulus Package that can 
assist departments to hire expert advice to 
address and enable its key recommendations to 
ensure and accelerate delivery of Green ICT in 
Government. 
g) Positively setup examples of green ICT 
initiatives it has successfully implemented and 
clarify what energy as well as CO2 savings were 
achieved. 
h) Support ICT Managers enabling them to create 
and better measure consistent green ICT 
strategies including measuring carbon and being 
responsible for energy bills. 
i) Impose high tax on importing energy inefficient 
equipments or anyway discourage energy 
inefficient ICTs. 
j) Discourage import of used ICT hardware that 
may prevent Bangladesh from e-waste dumping. 
k) Support green ICT pilot projects. 
l) Provide incentives to encourage private sectors 
to introduce or invent green technologies. 
m) Introduce provision for CO2 emission audit. 
  
Page 906
  
5. REFERENCES 
1. Green computing, Wikipedia – the free 
encyclopedia, accessed at: 
http://en.wikipedia.org/wiki/Green_computing    
2. Greenpeace International, Make IT Green- Cloud 
computing and its contribution to climate change, 
March 2010. Accessed at: 
http://www.greenpeace.org/international/Globa
l/international/planet-2/report/2010/3/make-it-
green-cloud-computing.pdf 
3. Gartner, 2007 Press Release 
4. Iqramul Hasan, GP lunches green emmision . The 
Daily Star, 24 October 2010. Accessed at: 
http://www.thedailystar.net/newDesign/news-
details.php?nid=159642  
5. Sohel Parvez, PMO thrives on green energy. The 
Daily Star Online Edition, 26 November 2010. 
Accessed at: 
http://www.thedailystar.net/newDesign/news-
details.php?nid=115612 
6. Policy Statement on Green ICT, Australian 
Computer Society, accessed at: 
http://www.acs.org.au/acs_policies/docs/2007/
greenictpolicy.pdf   
 
Page 907
 Proceedings of the 
International Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
1Corresponding Author: M.S.R. Shoaib,  
E-mail: shoaibeee@gmail.com 
MATHEMATICAL MODELING OF BLOOD FLOW 
 
 
M.S.R. Shoaib1, 2, 3, Md. Asaduzzaman2 and M.A. Haque2, 3 
1Bioelectric Research Lab, Dhaka, Bangladesh 
2Department of Electrical and Electronic Engineering 
2University of Information Technology and Sciences (UITS), Dhaka, Bangladesh 
3Bangladesh University of Engineering and Technology (BUET), Dhaka 
 
 
This paper presents a new mathematical model of the blood flow and the blood pressure. The main fluid 
component of the cardiovascular system is the blood which flows through the different blood vessels in the 
body. Although blood is the non-Newtonian fluid, in many cases it behaves like a Newtonian fluid which is 
governed by the Navier–Stokes equations. With the help of continuity equation and the Navier–Stokes 
equations, a simple differential equation was derived under some assumption which is called as the master 
equation. Then by applying the logical assumption on this master equation, the general mathematical model 
of the normal blood flow was developed. Then this model was extended for normal blood pressure using the 
Poisuelli’s equation. At the end of this study, some analysis had been performed to determine the validity of 
the proposed model. The analysis showed that the model can satisfy both the different properties of blood 
flow and blood pressure. 
 
Key words: mathematical model; cardiovascular system, non-newtonian fluid; differential equation; blood 
pressure; Navier–Stokes equation; continuity equation; Poisuelli’s equation 
 
1. INTRODUCTION 
 
A mathematical model uses mathematical language 
to describe a system in the real world. The process 
of developing a mathematical model is termed as 
mathematical modeling or modeling. 
Cardiovascular system is the blood distribution 
network in the body. The cardiovascular system in 
the body consists of three components: blood, heart 
and blood vessels. When blood flows through the 
vessels, pressure is detected on the wall which is 
termed as the blood pressure. Blood pressure 
depends mainly on flow rate and size of the vessels 
and on the pressure gradient. There are three major 
types of blood vessels: arteries, capillaries and 
veins [1]. Arteries are large blood vessels that carry 
blood away from the heart to all regions of the body 
[1]. The arterioles further divide into smaller 
vessels called capillaries. Capillaries are the 
anatomic units that connect the arterial and venous 
circulatory system. The veins form a low-pressure 
collecting system to return the oxygen-poor blood 
to the heart [1]. In this analysis, all the vessels are 
assumed to be same in nature excluding their size, 
length and cross-sectional area.  
Many studies have been published in this field. 
There is an important literature on the functional 
imaging and modeling of the heart [2] - [4]. Some 
studies have been performed on the measurement of 
electrical activity, deformation, flows, fiber 
orientation [5]–[10], and on the modeling of the 
electrical and mechanical activity of the heart [11]–
[13]. This study gives the mathematical modeling 
of the blood flow and also represents some 
simulation results based on the developed model. 
To develop the model of the blood flow and blood 
pressure, some assumptions have been considered. 
These include that the blood vessels are the 
cylindrical, deformable components with circular 
cross-sections. They change their size as the blood 
flows through it. The blood is considered to be the 
Newtonian fluid which is governed by the Navier-
Stokes equation and by the continuity equation. 
Although the blood needs the help of the lungs for 
the supply of oxygen, its properties remain 
unchanged by the addition of that oxygen. Another 
assumption is required and that is the blood has 
both the radial and axial flow in only one direction 
i.e. z-direction in a three dimensional system. So, 
the other two components (x-direction and y-
direction) are vanished. 
 
2. MATHEMATICAL MODELING 
 
2.1 Developing the master equation 
The velocity components in the x, y, and z 
directions are typically named u, v, and w 
Page 908
ISBN: 978-984-33-2140-4
  
respectively. Let ρ be the density of blood, P be the 
blood pressure and µ is the kinematic viscosity of 
blood. Then neglecting the orientation of gravity 
inside the body, the Navier-Stokes equation in the 
Cartesian co-ordinates is given by the following 
equations: 
 
  + 

 + 

	 + 


 
= − +  

 +

	 +

 
 
(1) 
 
 
  + 

 + 

	 + 


 
= −	 +  

 +

	 +

 
 
(2) 
 
 
 
 + 


 + 


	 + 



  
= − +  


 +


	 +


  (3) 
 
       
With the assumption of no tangential velocity and 
no x and y components of velocity, a change of 
variables on the Cartesian equations will yield the 
following system of equation in the cylindrical co-
ordinate system [14]: 
 

 + 


 + 



  
= −1

 +  


 +
1



 + 


  
 
(4) 
 
 
 + 

 + 


  
= −1

 +  

 +
1


 + 

 +

 
 
(5) 
 
 
 1

  +


 = 0 
(6) 
 
 
where , ,  be the radial flow component, 
, ,  be the axial flow component in z-
direction. 
 
And the continuity equation reads:  
 
 +


 = 0 
(7) 
 
 
Now, define a new variable γ as 
 = ,  , Error!  Bookmark not de-ined. where 0,  is the radius of the blood vessels, obviously 
the cylindrical coordinate , ,  is now replaced 
by coordinate , ,  
Again, the velocity profile in the axial direction, 
1, , , is assumed to have the expression in the 
polynomial form:[15] 
 

, ,  = 2344 − 1
5
467
 (8) 
 
 
where, q(z,t) is a another variable which to be 
determined later. For simplification let, N=1. Then 
 
, ,  = 3,  − 1 (9) 
 
And the velocity profile in the radial direction, 
w(η,z,t), is assumed to have the expression in the 
polynomial form: [15] 
 
, ,  = 0  +
0
 
− 0

82
1
9 4 − 1
5
467
 (10) 
 
 
Again for simplification let N=1,  
 
, ,  = 0  +
0
  −
0
 4 − 1 (11) 
 
Using the help of equations of axial and radial 
velocity profile, radial coordinate and the continuity 
equation, the Navier – Stokes equations get the 
forms as below to determine the variable 3,  
and 0, : 
 3
 −
43
0
0
 −
23
0
0
 +
4
0 3 +
1


 = 0 
 
(12) 
 
 
20 0 +
0
2
3
 + 3
0
 = 0 
 
(13) 
 
 
 
Now, let to introduce the desired variable, the 
cross-sectional area of the blood vessel as   
 = = >0 (14) 
 
where R is the radius of the blood vessels.  
 
And blood flow rate is given as the surface integral 
of w and  γ∂  [16]. Thus 
 
2
2
1
RqwQ piγ =∂= ∫∫  (15) 
From (14) and (15) 
z
R
and
t
R
z
q
t
q
∂
∂
∂
∂
∂
∂
∂
∂
,, can be 
found.  
Page 909
  
After inserting the value of 
z
R
and
t
R
z
q
t
q
∂
∂
∂
∂
∂
∂
∂
∂
,,  in 
(12) and (13), another two differential equations are 
obtained as: 
 ?
 +
3?
=
?
 −
2?
=
=
 +
4>
= ? +
=
2

 = 0 
 
(16) 
=
 +
?
 = 0 (17) 
 
After combining (16) and (17) a simple differential 
equation is obtained as follows: 
 ?
 −
3?
=
=
 −
2?
=
=
 +
4>
= ? +
=
2

 = 0 (18) 
 
Equation (18) is now called as the ‘master 
equation’. The model of the blood flow rate and 
blood pressure can be now got by applying some 
assumptions on this master equation which is 
performed in the next sections. 
 
2.2 Modeling of the Blood Flow Rate 
To develop the model of the blood flow it is 
assumed that the cross-section area of the blood 
vessel remains unchanged with time and it is also 
assumed to be constant over distance and the 
pressure gradient is assumed to be constant over the 
distance.  
Applying these assumptions on (18), the master 
equation reduces to: 
 ?
 +
4>
= ? +
=
2

 = 0 (19) 
 
This is the one dimensional mathematical model of 
the blood flow rate.  The required boundary 
condition and the values of the other parameters to 
solve this equation can be obtained from the past 
works in this field. Such as: 
Pressure gradient, ABAC =100 to 40 mmHg [16] 
Initial value of Q = 1 to 5.4 liter/minute [17] 
Kinematic viscosity of blood, µ = 0.035 cm2/s [18] 
Density of blood, ρ = 1.043 to 1.057 g/cm3 [18] 
 
2.3 Modeling of the Blood pressure 
To develop the mathematical model of the blood 
pressure Poisuelli’s equation is considered. 
Poisuelli’s equation determines the relation 
between blood flow rate and the pressure which is 
given as:  
 
? = >0D8F  (20) 
 
where, L is the length and R is the radius of vessel. 
After inserting (20) into (19), the new equations are 
obtained as follows: 
 >0D
8F
G
G +
4>
=
>0D
8F  +
=
2

 = 0 
 
(21) 
 
G
G +
4
0  +
4F
0

 = 0 (22) 
 
Equation (22) is the mathematical model of the 
blood pressure in the body. The required boundary 
condition and the values of the other parameters to 
solve this equation can be obtained from the past 
works in this field. Such as: 
Pressure gradient, ABAC =100 to 40 mmHg [16] 
Kinematic viscosity of blood, µ = 0.035 cm2/s [18] 
Density of blood, ρ = 1.043 to 1.057 g/cm3 [18] 
L varies for arteries, capillaries and veins, i.e. L is 
different for different types of blood vessels. 
 
3. RESULTS 
 
In this section of this paper, some analysis has been 
performed to verify the validity of the proposed 
model. 
 
3.1 Analysis of Blood Flow Rate 
The equation of the mathematical model of blood 
flow rate can be solved using the MATLAB 
function ‘dsolve’. Fig. 1 represents this solution for 
different cross-sectional area. The significance of 
this plot is that the blood flow rate increases with 
the cross-sectional area. This result supports fig. 2 
which is derived from the Poisuelli’s equation.  
 
 
Fig. 1. Blood flow rate for different cross-sectional 
area (from 0.1 to 2 cm2) 
Page 910
  
 
Fig. 2. Variation of blood flow rate with vessel 
radius using Poisuelli’s equation 
 
In fig. 3, the solution is plotted for various pressure 
gradients. Accordingly, pressure is higher at the 
beginning than at the end of vessel, establishing a 
pressure gradient. The greater the pressure gradient 
forcing bloods through a vessel, the greater the rate 
of flow through the vessel [19]. Fig. 3 also shows 
that for a given pressure gradient, the blood flow 
rate decreases with time and as the pressure 
gradient increases the blood flow rate also 
increases. 
 
 
Fig. 3. Blood flow rate for different pressure 
gradients (from 40 to 100mmHg) 
 
3.2 Analysis of Blood Pressure 
The equation of the mathematical model of blood 
pressure can be solved using the MATLAB 
function ‘dsolve’. Fig. 4 represents this solution for 
different cross-sectional area. The significance of 
this plot is that the blood pressure decreases with 
the cross-sectional area. This result supports fig. 5 
which is derived from the Poisuelli’s equation.  
 
Fig. 4. Blood pressure for different cross-sectional 
area of vessels 
 
 
 
Fig. 5. Variation of blood pressure with vessel 
radius using Poisuelli’s equation 
 
In fig. 6, the solution is plotted for various length of 
the blood vessel. This analysis indicates the 
increment of blood pressure with the increment of 
length of the blood vessels. Higher pressure at the 
beginning and lower pressure at the end and the 
difference between this two highly varies with 
length of the blood vessels. This result supports fig. 
7 which is derived from the Poisuelli’s equation. 
Page 911
  
 
Fig. 6. Blood pressure for different length of 
vessels 
 
 
 
Fig. 7. Variation of blood pressure with vessel 
length using Poisuelli’s equation 
 
Systolic (maximum) blood pressure in the normal 
adult is in the range of 95 to 140 mm Hg, with 120 
mm Hg being average. These figures are subject to 
much variation with age, climate, eating habits, and 
other factors. Normal diastolic blood pressure 
(lowest pressure between beats) ranges from 60 to 
90 mm Hg, 80 mm Hg being about average. This 
pressure is usually measured in the brachial artery 
in the arm [20]. Fig. 4 and fig. 6 show that the 
blood pressure ranges support the normal values for 
the artery in the arm with corresponding cross-
sectional area and length. 
 
 
4. CONCLUSIONS 
 
The design of computational models of human 
organs is a new research field which opens new 
possibilities for medical image analysis and therapy 
simulation [21]. The goal of this paper was to 
represent a mathematical model of the blood flow. 
A limited number of internal parameters were 
considered in developing the model. So, possible 
improvements of the study would include the 
integration of more anatomical structure (valve, 
exact size of the heart chambers), more realistic 
model and a more complex constitutive law. 
However, the objective of this research was not to 
build the more complex and faithful heart model 
ever. Instead, we want to adapt the complexity of 
the model but can show the sensitivity of the 
change in cross-sectional area, pressure gradient 
and length of blood vessel on the blood flow rate 
and on the blood pressure. 
Although a large numbers of assumptions have 
been considered, the model can be treated as a valid 
one, because, this model is able to show that the 
blood flow rate is influenced by the change of 
cross-sectional area and the pressure gradient. The 
model can also show that the blood pressure is 
influenced by both of the cross-sectional area and 
the length of the blood vessel. 
 
 
REFERENCES 
 
1. Ehrlich, A., Schroeder, C.L., “Medical 
terminology for health professions ”, 5th ed., 
Thomson Delmar Learning, 2004, pp-131 – 
132. 
2. Shoaib M.S.R., Asaduzzaman Md., 
“Mathematical modeling of the heart” IEEE 
Internatinal Conference on Electrical and 
Computer Engineering, pp.626-629, 
December 2010. 
3. T. Katila, I. Magnin, J. Montagnat, and J. 
Nenonen, Eds., “Functional imaging and 
modeling of the heart (FIMH’01)”, in Lectur 
Notes in Computer Science. Berlin, Germany: 
Springer-Verlag, 2001, vol. 2230. 
4. Magnin, J. Montagnat, J. Nenonen, and T. 
Katila,  Eds., “Functional imaging and 
modeling of the heart (FIMH’03)”, in Lectur 
Notes in Computer Science. Berlin, Germany: 
Springer-Verlag, 2003, vol. 2674. 
5. S. Masood, G. Yang, D. Pennell, and D. 
Firmin, “Investigating intrinsic myocardial 
mechanics: the role of MR tagging, velocity 
phase mapping and diffusion imaging,” J. 
Magn. Reson. Imag., vol. 12, no. 6, pp. 873–
883, 2000. 
Page 912
  
6. K. Rhode, M. Sermesant, D. Brogan, S. 
Hegde, J. Hipwell, P. Lambiase, E. Rosenthal, 
C. Bucknall, S. Qureshi, J. Gill, R. Razavi, 
and D. Hill, “A system for real-time XMR 
guided cardiovascular intervention,” IEEE 
Trans. Med. Imag., vol. 24, no. 11, pp. 1428–
1440, Nov. 2005. 
7. R. MacLeod, B.Yilmaz, B. Taccardi, B. 
Punske, Y. Serinagaolu, and D. Brooks, 
“Direct and inverse methods for cardiac 
mapping using multielectrode catheter 
measurements,” J. Biomedizinische Technik, 
vol. 46, pp. 207–209, 2001. 
8. P. Kilner, G. Yang, A. Wilkes, R. Mohiaddin, 
D. Firmin, and M. Yacoub, “Asymmetric 
redirection of flow through the heart,” Nature, 
vol. 404, pp. 759–761, 2000. 
9. O. Faris, F. Evans, D. Ennis, P. Helm, J. 
Taylor, A. Chesnick, M.Guttman, C. Ozturk, 
and E. McVeigh, “Novel technique for cardiac 
electromechanical mapping with magnetic 
resonance imaging tagging and an epicardial 
electrode sock,” Ann. Biomed. Eng., vol. 31, 
no. 4, pp. 430–440, 2003. 
10. D. Noble, “Modeling the heart,” Physiology, 
vol. 19, pp. 191–197, 2004. 
11. L. Xia and M. Huo, “Analysis of ventricular 
wall motion based on an electromechanical 
biventricular model,” in Computers in 
Cardiology. Piscataway, NJ: IEEE, 2003, pp. 
315–318. 
12. P. Hunter, A. Pullan, and B. Smaill, 
“Modeling total heart function,” Annu. Rev. 
Biomed. Eng., vol. 5, pp. 147–177, 2003. 
13. McCulloch, J. Bassingthwaighte, P. Hunter, 
D. Noble, T. Blundell, and T. Pawson, 
“Computational biology of the heart: from 
structure to function,” Prog. Biophy. Mol. 
Biol., vol. 69, no. 2/3, pp. 151–559, 1998. 
14. D.J. Acheson, “Elementary fluid dynamics” 
New ed., Clarendon (Oxford University 
Press), August, 1990 
15. Yang, B H., Asada, H H., Zhang, Yi., 
“Cuffless Continuous Monitoring of Blood 
Pressure using Hemodynamic Model, The 
Home Automation and Healthcare 
Consortium” Progress Report No. 2-3., 1999 
16. Labadin, J, Ahmadi, A, “Mathematical 
Modeling of the Arterial Blood Flow” 
Proceedings of the 2nd IMT – GT Regional 
Conference on Mathematics, Statistics and 
Applications, Universiti Sains Malaysia, 
Penang, June 13 – 15, 2006 
17. Liu C H., Niranjan S C., Clark J W., San K 
Y., Zwischenberger J B., Bidani A.,”Airway 
mechanics, gas exchange, and blood flow in a 
nonlinear model of the normal human lung”, 
Journal of Applied Physiology 84: 1447-1469, 
1998 
18. Hinghofer-Szalkay, H.G. and Greenleaf, J.E., 
“Continuous monitoring of blood volume 
changes in humans”, Journal of Applied 
Physiology. Vol. 63 (1987): 1003-7. 
19. Lauralee Sherwood, “Fundamentals of 
physiology: a human perspective”, 3rd ed., 
Thomson Brooks/cole, 2005, pp – 276 
20. L. Cromwell, Fred J. Weibell and Erich A. 
Pfeiffer, “Biomedical instumentation and 
measurement”, 2nd ed., Pearson Education: 
Singapore, 2004, pp. 84–95. 
21. M. Sermesant, H. Delingette, and N. Ayache, 
“An electromechanical model of the heart for 
image analysis and simulaiton”, IEEE Trans. 
Med. Imag., vol. 25, no. 5, pp. 612–625, May. 
2006. 
Page 913
 Proceedings of the 
International Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
1Corresponding Author: M.S.R. Shoaib,  
E-mail: shoaibeee@gmail.com 
MATHEMATICAL MODELING OF EYE MOVEMENT 
 
 
M.S.R. Shoaib1, 2, 3, Md. Asaduzzaman2, and M.A. Haque2, 3 
1Bioelectric Research Lab, Dhaka, Bangladesh 
2Department of Electrical and Electronic Engineering 
2University of Information Technology and Sciences (UITS), Dhaka, Bangladesh 
3Bangladesh University of Engineering and Technology (BUET), Dhaka 
 
 
This paper presents a model of the eye movement. Using the natural process of seeing any object by the eye, 
a simple block diagram was considered. From this block diagram the mathematical model of eye movement 
was developed. The developed model was then converted into state equations which were used to draw the 
signal flow diagram. This diagram was simulated using simulink of MATLAB. An electrical circuit of the 
model was developed using the signal flow diagram. Finally, the condition of the stability of the model and 
the steady state error were determined from the different simulations. The model can describe the normal 
operation of the eye and can also describe the eye diseases like hypermetropia and myopia. This model also 
suggests the cure of hypermetropia and myopia. 
 
Key words: state equation; signal flow diagram; simulink; MATLAB; stability; steady state error  
 
1. INTRODUCTION 
 
A mathematical model uses mathematical language 
to describe a system in the real world. The process 
of developing a mathematical model is termed as 
mathematical modeling or modeling [1]. It is often 
difficul to identify the appropriate level of 
modeling for a particular problem [2]. A crucial 
part of the modeling process is the evaluation of 
whether a proposed mathematical model describes 
a system accurately or not. When we face any 
problems with any real world task, then we convert 
the task into mathematical model, apply assumption 
if required, solve this and interpret for real world to 
see whether the developed model is correct for the 
system or not.  
 
Eye is one the most important organs of the body. 
The human eye is an organ which reacts to light for 
several purposes. The visual system in the brain is 
too slow to process information if the images are 
slipping across the retina at more than a few 
degrees per second [3]. Thus, for humans to be able 
to see while moving, the brain must compensate for 
the motion of the head by turning the eyes. Another 
complication for vision in frontal-eyed animals is 
the development of a small area of the retina with a 
very high visual acuity. This area is called the 
fovea, and covers about 2 degrees of visual angle in 
people. To get a clear view of the world, the brain 
must turn the eyes so that the image of the object of 
regard falls on the fovea. Eye movements are thus 
very important for visual perception, and any 
failure to make them correctly can lead to serious 
visual disabilities. Some works on human-machine 
interaction [4] - [8] and eye position [9] - [10] have 
been published. This study represents the model of 
eye and eye movement. 
 
2. MATHEMATICAL MODELING 
 
A model for eye movement consists of the closed-
loop system shown in fig. 1, where an object’s 
position is the input and the eye position is the 
output. As the brain detects any object, the brain 
sends signals to the muscles that move the eye. 
These signals consist of the difference between the 
object’s position and the position and rate 
information from the eye sent by the muscles 
spindles. In these process two types of delays 
should be considered: delay due the signal 
processing in the brain and the propagation delay of 
the signals through the nervous system [11]. 
 
Each eye has six muscles that control its 
movements: the lateral rectus, the medial rectus, the 
inferior rectus, the superior rectus, the inferior 
oblique, and the superior oblique. When the 
muscles exert different tensions, a torque is exerted 
on the globe that causes it to turn, in almost pure 
rotation, with only about one millimeter of 
translation. Thus, the eye can be considered as 
undergoing rotations about a single point in the 
center of the eye. 
Page 914
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
  
 
Muscle spindles are sensory receptors within the 
belly of a muscle, which primarily detect changes 
in the length of this muscle. They convey length 
information to the central nervous 
system via sensory neurons. This information can 
be processed by the brain to determine 
the position of body parts. The responses of muscle 
spindles to changes in length also play an important 
role in regulating the contraction of muscles, by 
activating motoneurons via the stretch reflex to 
resist muscle stretch. 
 
Fig. 1. Block diagram of eye movement 
 
Let, r(t) represents the object position, y(t) 
represents the eye position, k1, k2, k3 and k4 are 
the gain constants, a1 and a2 determine the time 
constant of eye and muscle spindle respectively. 
 
Using the block reduction techniques, the above 
figure is converted to its simplest form which 
results the determination of the transfer function as 
follows: 
 ()
() = 	(
	)
(
	)	
(	
	)
		
	               
                                                                             (1) 
Taking cross multiplication 
  + ( + ) + ( + )+  + () =  + () (2) 
 
Let,  
  =  +  (3a)  =  +  (3b)  =  +  (3c)  = ,  =  (3d) 
 
Thus,  
  + ( + ) + ( + )+  + () =  + () 
 
  ! 
 
 () + () + () + () = () + () (4) 
 
Applying inverse Laplace Transformation assuming 
zero initial condition to the above equation 
 "#($)"$ + "
#($)"$ + "#
($)"$ + #($) 
=  "!($)"$ + !($) (5) 
 
This differential equation represents the 
mathematical model of the eye movement. 
 
3. STATE SPACE REPRESENTATION 
 
Separating the transfer function of the system into 
two cascaded blocks, the system looks like as 
shown in fig. 2. 
 
 
 
Fig. 2. Simplified transfer function 
 
For first block, the corresponding differential 
equation 
 %&+ %' + %( + % = !  (6) 
 
Choosing the state variables as successive 
derivatives 
 ) = % (7a) ) = %(  (7b) ) = %'  (7c) 
 
Differentiating both sides and equating equivalent 
values, the state equations are obtained. Since the 
output is % = ), the combined state and output 
equations are: 
 )( = ) (8a) )( = ) (8b) )( = −) − ) − ) + ! (8c) 
 
In vector-matrix form, 
 
,)()()( - = ,
0 1 00 0 1− − −- ,
)))- + ,
001- ! (9) 
 
From second block of fig. 2, 
 () = ( + )0() (10) 
 
Taking inverse Laplace Transform with zero initial 
condition, 
Page 915
  
 # = )( + )  (11) 
      
But,  )( = ) 
 # = ) + ) (12) 
 
Thus the second block of figure.2b collects the 
states and generates the output equations as shown 
below: 
 
# =   1))2  (13) 
 
Using eq.9 and eq.13, the signal flow diagram [12] 
is constructed and is shown in fig. 3. 
 
 
Fig. 3. Signal flow diagram 
 
 
4. ELECTRICAL EQUIVALENT 
CIRCUITS 
 
The signal flow diagram in fig. 3 can be replaced 
by electrical circuit components: integrators, 
inverting amplifiers and summing amplifiers [13]. 
The electrical circuit realization of the eye 
movement is given in fig. 4. The integrator consists 
of an op-amp, resistor and capacitor; an amplifier 
consists of an op-amp and resistors. 
In the figure below: 
 
     34 = ,                         
3
5
= , 
 
 
3
6
= ,                         
3
7
= 1 
 
 =  =  = 1 
 


= ,                 


= , 
 
 
8

= 1 
 
 
 
 
Fig. 4. Electronic equivalent circuit 
 
5. STABILITY OF MODEL 
 
A system is said to be stable if there is no poles in 
the right half plane in s-domain. Recalling the 
transfer function, the Routh-Hurwitz table is 
created using the denominator of the transfer 
function.  
 
Denominator, () =  +  +  +  
 
Table 1. Stability test of the model 
 
 1  
   
 
 − 

 
0 
8  0 
 
According to Routh-Hurwitz criteria for stability, 
each term of the second column must have same 
sign to ensure all the poles in the left half side of 
Object  
Position 
Eye 
Position 
Page 916
  
the s-plane. The following conditions must be 
satisfied to ensure the stability of the system. 
 
1. Condition 1: 
 > 0  
 !,  +  > 0  
 
2. Condition 2: 
( − )/ > 0  
 !,  −  > 0  
 !,  >   
 !,  > /  
 !,  +  >
		
	

	
  
 !,  >
		
	

	
−   
 !,  >
	;	

	
  
 !,  >
	(;)

	
  
 !,  <
	(
	)
(;)
  
 
3. Condition 3: 
  > 0 
  !, 1232 + 124 > 0  
  !, 2 > −4/3  
 
To make the model stable all of the three conditions 
described above must be satisfied. 
 
6. RESULTS 
 
Fig. 5 and fig. 6 show the eye response to an object 
position. The object position or the input is 
considered as the unit step function in fig. 5 and the 
sine wave in fig. 6. The figures show that the eye 
can detect the position of the object after a certain 
time. This certain time includes the rise time 
resulted from delay of signal processing in the 
brain, propagation delay in the nervous system and 
from time constant determining factor of the eye.  
 
 
Fig. 5. Normal eye response to unit step function 
 
 
 
Fig. 6. Normal eye response to sine wave 
 
If the eye suffers from diseases, the object position 
is not detected accurately. Eye disease means the 
changes of the different parameters in the model. 
When it occurs, the model suffers from instability 
and the eye cannot detect the actual position of the 
object which is described below. 
Fig. 7 shows that when the eye suffers from myopia 
then there is a steady state error. This error means 
that the eye cannot reach to the actual object 
position. Myopia occurs due to increment of 
convex power of the eye which is determined by 
the decrement of gain constant of the muscle 
spindle. As the muscle spindle works as the 
negative feedback network, an increment means the 
decrement of power and vice versa. 
 
 
Fig. 7. Response of eye suffering from myopia 
 
As myopia occurs due the increment of convex 
power of the eye, it is required to reduce the convex 
power of eye to get removed from this eye disease. 
A concave lens is used to reduce the power. In the 
model, the value of gain constants is increased so 
that the effect reduces by the negative feedback. 
Fig. 8 shows the response of the eye suffering from 
Page 917
  
myopia with a concave lens of suitable power. This 
response is same as normal eye response. 
 
 
Fig. 8. Response of eye suffering from myopia with 
suitable concave lens 
 
Fig. 9 shows that when the eye suffers from 
hypermetropia then there is a steady state error. 
This error means that the eye cannot reach to the 
actual object position. Hypermetropia occurs due to 
decrement of convex power of the eye which is 
determined by the increment of gain constant of the 
muscle spindle. As the muscle spindle works as the 
negative feedback network, an increment means the 
decrement of power and vice versa. 
 
 
Fig. 9. Response of eye suffering from 
hypermetropia 
 
As hypermetropia occurs due the decrement of 
convex power of the eye, it is required to increase 
the convex power of eye to get removed from this 
eye disease. A convex lens is used to increase the 
power. In the model, the value of gain constants is 
decreased so that the effect increases by the 
negative feedback. Fig. 10 shows the response of 
the eye suffering from hypermetropia with a convex 
lens of suitable power. This response is same as 
normal eye response. 
 
Fig. 10. Response of eye suffering from 
hypermetropia with suitable convex lens 
 
Muscle and eye gain constants determine the rise 
time to detect the object position. The rise time 
increases as the gain constants decrease. It is due to 
aging effect, when the power of the eye muscle 
reduces. Rise time increases means it will take 
more time to detect the position of the object fully. 
Fig. 11 shows the variation of rise time for various 
gain constants. 
 
Fig. 11. Eye response to various gain constants 
 
 
Fig.12. Eye response to various time constant 
determining factor of eye 
 
Time constant determining factor of eye affects 
both the rise time and clearness of the object 
Page 918
  
detection. As the factor decreases, rise time 
increases but clearness of the object reduces. This 
phenomenon is described in fig.12. 
 
Time constant determining factor of muscle spindle 
affects the initial clearness of the object detection 
but does not affect the rise time. A change in this 
factor can lead a normal eye, eye with myopia and 
eye with hypermetropia as described in fig.13. 
Hypermetropia is significant than that of the 
myopia. 
 
 
Fig. 13. Eye response to various time constant 
determining factor of muscle spindle 
 
7. CONCLUSIONS 
 
The goal of this paper is to represent a model of the 
eye movement. The mathematical model is 
presented in two forms: differential equation form 
and space state representation. This model is 
replaced by electronic circuits to develop an 
electrical model of eye movement. 
 
A limited number of internal parameters are 
considered in developing the model. So, possible 
improvements of the study would include the 
integration of more sophisticated, more realistic 
model and a more complex constitutive law. 
Although some assumptions have been considered, 
the model can be treated as a valid one, because, 
this model is able to show the normal eye response 
to an object position, can describe the aging effect 
on eye. The model can also show the diseases of 
eye and the treatment of those diseases using 
convex or concave lens with suitable power. 
 
 
REFERENCES 
 
1. M.S.R. Shoaib, Md. Asaduzzaman, 
“Mathematical modeling of the heart” IEEE 
Internatinal Conference on Electrical and 
Computer Engineering, pp.626-629, 
December 2010. 
2. P. Dayan and L.F. Abbott, Theoretical 
neuroscience: Computational and 
mathematical modeling of neural systems, 9th 
ed. 
3. T. Katila, I. Magnin, J. Montagnat, and J. 
Nenonen, Eds., “Functional imaging and 
modeling of the heart (FIMH’01)”, in Lectur 
Notes in Computer Science. Berlin, Germany: 
Springer-Verlag, 2001, vol. 2230. 
4. J. Hornof, “Visual search and mouse pointing 
in labeled versus unlabeled two-dimensional 
visual hierarchies” ACM  Transactions on  
Computer-Human Interaction, volume 8, issue 
3, pp. 171-197, 2001 
5. J. Hornof,  T. Halverson, “Cleaning up 
systematic error in eye tracking data by using 
required fixation locations” Behavior  
Research  Methods, Instruments, and 
Computers, 34(4), pp. 592-604, 2002 
6. D.D. Salvucci, J.R. Anderson, “Automated 
eye-movement protocol analysis”. Human-
Computer Interaction, 16, pp. 39-86, 2001 
7. G.L. Lohse, “A cognitive model for 
understanding graphical perception” Human -
Computer Interaction, 8,  pp. 353-388, 1993 
8. J. MacGregor, E. Lee, “Menu search: Random 
or systematic?” International Journal of Man-
Machine Studies, 26(5),  pp. 627-631, 1987 
9. D. D. Salvucci, “An integrated model of eye 
movements and visual encoding” Cognitive 
Systems Research, 1(4),  pp. 201-220, 2001 
10. Laurent Itti, “Quantitative modelling of 
perceptual salience at human eye position” 
visual cognition, 14 , pp.  959_984, 2006 
11. N.S. Nise, Control system engineering, 4th 
edition, John Wiley, ISBN 9812-53-060-6, 
2003 
12. R. Dorf, R. Bishop, Modern control systems, 
11th edition, Pearson Education, 2007 
13. R.F. Coughlin, F.F. Driscoll, Operational 
amplifiers and linear integrated circuits, 6th 
edition, Prentice Hall India, 2001 
 
Page 919
 Proceedings of the 
International Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, SUST, Sylhet, Bangladesh 
*
 Corresponding Author: Md. Safaet Hossain,  
E-mail: safayeth@gmail.com 
METHODOLOGY FOR COST EFFECTIVE WEB TESTING FOR 
ECOMMERCE WEB APPLICATIONS 
 
 
Md. Safaet Hossain 
Department of Electrical Engineering and Computer Science 
North South University, Dhaka Bangladesh 
Email: safayeth@gmail.com 
 
 
ABSTRACT: In the emerging global economy, electronic commerce (e-commerce) has increasingly 
become an indispensable component of business strategy and a strong catalyst for economic development. 
The World Wide Web has grown at an extravagant rate as a medium for promoting and marketing products 
and services. A web application is referred to as a system which consisted of many different functional 
modules. From the user point of view quality of services, predictable response services, response time, 
availability, reliability is the key factor to compete with others. Poor quality implies that the customer will 
not visit the site and the company loose business. The issues that affect the quality are broken links, broken 
images, broken pages, error messages, server faults etc. Software testing is primary way to improve software 
reliability and assuring software quality. This research generates methodology to improve quality of services 
for web based software applications 
Key words: Web Application, Web Testing Methodology, Performance Testing, Website Design  
 
 
1. INTRODUCTION 
 
Internet and the web based applications are 
emerging and the WEB application creates a 
paradigm in the field of Ecommerce. And it is 
consisted of many autonomous and heterogeneous 
frameworks. As they are different in the modality, 
performance, functionality, usage and service, and 
the system is usually dominate in the market. 
Website is a combination of different hypermedia. 
Server Side Scripting Language and Client Side 
Scripting language make the web dynamic. There 
are several aspects to evaluate a website and its 
rank. The popularity depends on the contents and 
the way it designed and maintained. As a result, it 
is more difficult to carry out the development and 
maintenance for web site than the desktop based 
software. 
As an important method to ensure the quality of 
Ecommerce web site, the testing obtains more and 
more attentions from researchers and users, and 
many important researching methods. Testing aims 
at finding errors in the tested object and giving 
confidence in its correct behavior by executing the 
hypermedia and its objects with selected objects. 
However, web applications raise important and 
challenging test issues that cannot be solved 
directly by existing methodology unlike desktop 
software’s. The presentation details of the web, 
such as size, position and color of page elements, 
although they are also of importance to the business 
factor.  
 
2. RELATED WORK 
 
The testing process for traditional software is 
generally consisted of different steps: firstly 
determine the testing objects and targets, such as 
the required testing coverage ratio; next, generate 
the testing input, and this input is generated by the 
specification and structure of the software; then 
produce the expected output results; subsequently, 
execute the test cases and validate output; This 
series of steps and flows are suitable for the general 
software testing, and the differences, which can 
directly influence the ultimate testing effect.    
At present, the research on how to carry out the 
analysis and comparison of Web application testing 
results is not prevalent, for the current Web 
application testing is short of necessary criterion 
and strict process, and the testing for Web 
applications and the testing results judgment are 
often executed by testers manually. In order to be 
suitable for the specialties of numerous contents 
and heavy tasks of Web application testing, and 
further improve the testing precision and efficiency, 
researchers have done a lot in such aspects as 
assistant tool development and testing automation. 
Correspondingly, the automatic analysis and 
comparison are still needed for the testing results. 
Page 920ISBN: 978-984-33-2140-4
  
However, there are many difficulties in the 
automatic analysis and comparison of the testing 
results, and the main reasons are: many Web pages 
are dynamically generated, so it is difficult to gain 
the determined expected results before executing 
testing; the outputs of Web applications are graphic 
interfaces, and the comparing method for graphics 
is scanning and comparing each pixel in turn, but 
due to the influences of client environments to the 
displaying of Web application, such as the system 
resolution, browser type and version, this method is 
very numerous and fallible, thus it is necessary to 
separate the data and displaying so as to compare 
the related contents directly. 
In order to evaluate the quality of Web application 
and the efficiency of testing process, the 
quantitative analysis and metrics to the testing 
results are still needed so as to obtain some 
evaluating indexes and form the criterion. Then we 
can measure and evaluate a lot of testing results for 
Web applications and give the guidelines to the 
development of Web applications. In the existed 
research work, P.Warren [10,11] mainly focused on 
the Website evolution and Web application 
maintenance, and they pointed out that all kinds of 
problems occurred in the Website development, 
usage and maintenance are caused by disobey the 
rules of software engineering, and they put forward 
the metrics to indicate the evolvement of Websites; 
Devanshu Dhyani presented the origins, 
measurement functions, formulations and 
comparisons of well-known Web metrics for 
quantifying Web graph properties, Web page 
significance, Web page similarity, search and 
retrieval, usage characterization and information 
theoretic properties [9]. However, there are short of 
the related metrics criterions and indexes to the 
testing, so it is difficult to directly evaluate the 
testing effect.  
After we obtain the Web application indexes by the 
metrics in multiple aspects, the modification and 
maintenance to the Web application are needed due 
to the testing results, so as to eliminate the 
influences caused by the faults in the system, 
satisfy all kinds of actual demands of users, 
improve the system quality actual demands of 
users, improve the system quality and the degree of 
users’ satisfactions. We can use the control theory 
[8] and the feedback mechanism, and feed back the 
related testing information into the Web 
applications themselves, thus we can know the 
existed problems in Web applications and the 
difficulties of their modifications and 
improvements, then we can guide the development 
and evolvement of Web applications directly and 
exactly especially in the aspects of system 
reliability, usability and safety. 
3. WEB TEST MODEL 
 
As more and more services and information are 
made available over the Internet and intranets, Web 
applications have become extraordinarily complex. 
As time progresses the volume of information and 
web contents increase and update. Although 
traditional software testing is time consuming and 
difficult to maintain. Therefore new approach and 
new methodology is required for quality 
improvement. 
Faults are obtained through a process similar to one 
defined and used in previous research in testing 
techniques [2,3,4] whereby faults are inserted, 
which are as realistic as possible and based on user 
experience. The following fault types are 
considered: 
• Web page faults: This includes addition, 
deletion, or modification of name-value 
pairs. 
• HTML faults: This includes HTML tag 
opening and closing error. 
• Database query faults: This includes 
modification of a query expression, which 
may possibly affect the type of operation. 
 
4. Reason for WEB Site Evaluation  
 
Once the web application is set up, the challenge is 
to have users access the site and behave like typical 
users of this type of e-commerce site. And also 
continue the performance for the user and provide 
speed for simultaneous business transaction.  
The repercussions of having a poorly operating 
website are staggering, and even affect the brick 
and mortar stores that the websites are enabling 
online. A recent study showed that when errors are 
found on an e-commerce website, 28% of the 
people stopped shopping at the site, 23% stopped 
buying from the site, and 6% of the people were so 
upset, that they stopped buying at brick and mortar 
store. One can only deduce that the customers feel 
that if the company cannot provide a quality 
website, then they may not be able to sell a quality 
product from their stores. 
 
Table 1: Effects of poorly operating websites 
 
Effects of poorly operating Websites Percentage 
People stopped shopping at the site 28% 
Stopped buying from the site  23% 
of the people were so upset 6% 
Page 921
  
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 1: Effects of poorly operating websites 
[chart based] 
 
 
5.  Cost-Effective Methodology 
Like any complex piece of software there is no 
single, all inclusive quality measure that fully 
characterizes a WebSite (by which we mean any 
web browser enabled application). 
 
The process of website designing can be divided 
into different stages. The stages are Information 
Gathering, Apply methods, Website evaluation, 
Result Analysis.   
 
 
Figure 2: Web Evaluation Procedures 
 
 
 
 
 
5.1 Dimensions of Quality: 
 
There are many dimensions of quality; each 
measure will be appropriate to a particular WebSite 
in varying degrees. Here are some common 
measures: 
• Timeliness: WebSites change often and 
rapidly. How much has a WebSite changed 
since the last upgrade? How do we highlight 
the parts that have changed? 
• Structural Quality: How well do all of the 
parts of the WebSite hold together? Are all 
links inside and outside the WebSite 
working? Do all of the images work? Are 
there parts of the WebSite that are not 
connected? 
• Content: Does the content of critical pages 
match what is supposed to be there? Do key 
phrases exist continually in highly-
changeable pages? Do critical pages 
maintain quality content from version to 
version? What about dynamically generated 
HTML (DHTML) pages 
• Accuracy and Consistency: Are today's 
copies of the pages downloaded the same as 
yesterdays? Close enough? Is the data 
presented to the user accurate enough? How 
do you know? 
• Response Time and Latency: Does the 
WebSite server respond to a browser request 
within certain performance parameters? In 
an e-commerce context, how is the end-to-
end response time after a SUBMIT? Are 
there parts of a site that are so slow the user 
discontinues working? 
• Performance: Is the Browser --> Web --> 
webSite --> Web --> Browser connection 
quick enough? How does the performance 
vary by time of day, by load and usage? Is 
performance adequate for e-commerce 
applications? Taking10 minutes -- or maybe 
even only 1 minute -- to respond to an e-
commerce purchase may be unacceptable! 
 
 
5.2 Impact of Quality.  
 
Quality remains is in the mind of the WebSite user. 
A poor quality WebSite, one with many broken 
pages and faulty images, with Cgi-Bin error 
messages, etc., may cost a lot in poor customer 
relations, lost corporate image, and even in lost 
sales revenue. Very complex, disorganized 
WebSites can sometimes overload the user. 
 
28%
23%
6%
People stopped
shopping at the
site
Stopped buying
from the site 
of the people
were so upset
Page 922
  
The combination of WebSite complexity and low 
quality is potentially lethal to Company goals. 
Unhappy users will quickly depart for a different 
site; and, they probably won't leave with a good 
impression. 
Some access to information from the database may 
be appropriate, depending on the application, but 
this is typically found by other means.
 
• Navigation. Users move to and from pages, 
click on links, click on images (thumbnails), 
etc. Navigation in a WebSite is often 
complex and has to be quick and error free.
• Object Mode. The display you see changes 
dynamically; the only constants are the 
"objects" that make up the display. These 
aren't real objects in the OO sense; but they 
have to be treated that way. So, the quality 
test tools have to be able to handle URL 
links, forms, tables, anchors, buttons of all 
types in an "object like" manner so that 
validations are independent of 
representation. 
• Server Response. How fast the WebSite 
host responds influences whether a user (i.e. 
someone on the browser) moves on or gives 
up. Obviously, InterNet loading affects this 
too, but this factor is often outside the 
Webmaster's control at least in terms of how 
the WebSite is written. Instead, it seems to 
be more an issue of server hardware capacity 
and throughput. Yet, if a WebSite becomes 
very popular -- this can happen overnight! 
Loading and tuning are real issues that often 
are imposed -- perhaps not fairly 
WebMaster. 
 
5.3 Interaction & Feedback.  
For passive, content-only sites the only real quality 
issue is availability. For a WebSite that interacts 
with the user, the big factor is how fast and how 
reliable that interaction is. 
 
5.4 Concurrent Users.  
Do multiple users interact on a WebSite? Can they 
get in each others' way? While WebSites often 
resemble client/server structures, with multiple 
users at multiple locations a WebSite can be much 
different, and much more complex, than complex
 
5.5 Performance Testing Illustration
 
To illustrate how the cost effective methodology 
measures timing we have built a set some 
measurement that have these features:
 
 
 
-- on the 
 
.  
 
• Top 20 Web Portals. We selected 20 
commonly available WebSites on which to 
measure response times.  
• User Recording. We recorded one user's 
excursion through these suites and saved that 
keysave file (playback script). 
• User Recording. We played back the scripts 
on a 56 kbps modem so that we had a 
realistic comparison of how long it would 
take to make this very-full visit to our 
selected 20 portals. 
• P4 Timings. We measured the elapsed time 
it took for this script to execute at various 
times during the day. The results fr
typical day's executions showed a playback 
time range of from 457 secs. to 758 secs (i.e. 
from -19% of the average to +36% of the 
average playback time). 
• Second Layer Added. We added to the base 
script a set of links to each page referenced 
on the same set of 20 WebSites. This yielded 
the P4+ suite that visist some 1573 separate 
pages, or around 78 per WebSite. The 
testsuite takes around 20,764 secs (~5 Hrs 45 
mins) to execute, or an average of 1038 secs 
per WebSite. 
• Lessons Learned. It is relatively
configure a sophisticated test script that 
visits many links in a realistic way, and 
provides realistic user-perceived timing data.
 
Table 2: Cost-effective Testing Result
 
 
 
 
 
 
 
om one 
 easy to 
 
 
 
Page 923
  
6. COST EFFECTIVE WEB T
EVALUATION MODEL 
 
To find out the result about different criteria we 
need to visit different web based testing site. Since 
we need to find out the values against the criteria 
from different ecommerce validation testing site 
which is time consuming and not cost effective. 
Thus we can develop tool which can generate 
unified testing result and moderate the content.    
 
The URL-Driven Methodology is a novel use of 
Data-Driven Methodologies for Web
A URL specifies the protocol that is used in 
accessing the resources that includes a Web server's 
domain name and the specific file name. Every part 
of the domain name indicates where you want to 
go, what type of data you are requesting, and where 
 
The Following result produces by an online web testing site
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
7. Expected Outcome 
Web-based analysis and test tools have been also 
developed that model the underlying structure for 
web applications. White box testing approach build 
system models from inspection of code, identify 
test requirements from those models, and require 
extensive human participation in the generation of 
test cases to fulfill those requirements. These 
approaches focus on the internal structural aspect 
and involve in the details of a web application. 
 
Develop a prototype tool allowing users to run the 
test cases to test the functionality, security and find 
faults in the web application. The test cases should 
 
ESTING 
 
-based testing. 
you can find the information within the server site 
that you want. 
URLs are most frequently used in Web pages. 
However, other types of URLs are: Web addresses, 
E-mail addresses, FTP hosts. Newsgroup addresses, 
Telnet hosts, Finger hosts, Gopher addresses, Wais 
hosts and Query URLs.  
It will cause a long time to finish testing 
have hundreds or thousands of URLs to be checked.
However, the URL-Driven Testing Methodologies 
help us to build a friendly, cost-
maintainable system. We can use a common or 
selected web browser and a well-
matrix. The user can easily navigate through 
directories of pre-defined test cases, configure the 
test system, execute tests and view detailed test 
results. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
specify the input conditions and expected output of 
each test as specified. It should be generated to be 
extensible and allow enhancements to be made for 
more complex and customizable tests. Load test the 
newly generated test cases to test the performance 
of the web application and generate a test report.
 
The system to be developed will need a web 
application used by many that resembles as closely 
as possible to those found in the real world. An 
open source web application will be used to capture 
relevant user sessions to generate a test suite. 
 
 
when we 
 
effective, and 
designed data 
 
 
 
 
Page 924
  
7. CONCLUSIONS 
 
The cost effective testing methodology for web 
application can improve the performance testing of 
web application. The approach is based on formal 
specification of the web applications functionality, 
security and performance. The results of an 
evaluation indicate that effectiveness of these 
approaches is better than conventional techniques 
and reduces required tester intervention. 
 
 
REFERENCES 
 
1. C. Kallepalli, J. Tian, “Measuring and 
Modeling Usage and Reliability for Statistical 
Web Testing”, IEEE Trans Software 
Engineering, 2001,27(11): 1023-1036. 
2. L. Xu, B. W. Xu, and Z.Q. Chen, “Survey of 
Web Testing”, Computer Science (in Chinese), 
2003, 30(3): 100-104. 
3. Xu L, Xu BW, Chen HW. “Website Evolution 
based on Statistic Data”, Proceedings of the 
Ninth IEEE International Workshop on 
FutureTrends of Distributed Computing 
Systems (FTDCS 2003), Page(s):301-306. 
4. J. Gao, C. Chen, Y. Toyoshima and D. Leung, 
“Engineering on the Internet for Global 
Software Production”, IEEE Computer, 1999, 
32(5):38-47. 
5. F. Ricca and P. Tonella, “Web Site Analysis: 
Structure and Evolution”, Proc. of International 
Conference on Software Maintenance 
(ICSM'2000), 2000, pp. 76-86. 
6. Rohit Dhand, “Web Services: A Trend Shift 
from conventional Distributed Computing 
Model” IEEE Computer, 2009, DOI 
10.1109/ICCEE.2009.26:313-317. 
7. Bo Song and Huaikou Miao, “Modeling Web 
Applications and Generating Tests: “A 
Combination and Interactions-guided 
Approach”, IEEE Computer, 2009, DOI 
10.1109/TASE.2009.54:174-181. 
8. K. Y. Cai, “Optimal software testing and 
adaptive software testing in the context of 
software cybernetics”, Information and 
Software Technology, 2002, 44, pp. 841-855. 
9. D. Dhyani, W. K. Ng, and S. S. Bhowmick, “A 
survey of Web metrics”, ACM Computing 
Surveys, 2002, 34(4): 469-503. 
10. P. Warren, C. Boldyreff, and M. Munro, “The 
Evolution of Websites”, Proc. of the Int. 
Workshop on Program Comprehension, 1999, 
pp. 178-185. 
11. P. Warren, C. Gaskell, C. Boldyreff. Preparing 
the ground for website metrics research. Proc 
of the 3rd International Workshop on Web Site 
Evolution, 2001, pp. 78-85. 
 
Page 925
 Proceedings of the 
International Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
3 Corresponding Author: M.S.R. Shoaib,  
E-mail: shoaibeee@gmail.com 
MICROWAVE ANALYSIS OF A MEMS SWITCH 
 
 
Md. Asaduzzaman1, 2, Soren Peik2, and M.S.R. Shoaib1, 3, 4 
1Department of Electrical and Electronic Engineering 
1University of Information Technology and Sciences (UITS), Dhaka, Bangladesh 
2Bremen University of Applied Sciences, Bremen, Germany 
3Bangladesh University of Engineering and Technology (BUET), Dhaka 
4Bioelectric Research Lab, Dhaka, Bangladesh 
 
Micro electro mechanical systems (MEMS) have experienced an explosive growth over the past few years 
driven mainly by its physical properties and its promising technological applications in many different fields, 
particularly in space and RF systems. MEMS technology exhibits greater advantages over the existing 
semiconductor switches. In this paper, Radio Frequency (RF) performances of a two hot arms actuator 
MEMS switch have been investigated. The switch is designed and simulated using CST Microwave Studio. 
To get different parameters of transmission line, AWR Microwave Office has been used. The simulated 
results show that the designed MEMS switch performed well at high frequency. At OFF state the return loss 
S11 drops nearly to zero dB and the isolation S21 become lower than -50 dB at 1 GHz and -35 dB at 10 GHz 
which indicates the high isolation. At ON state position the simulation exhibits very low insertion loss, S21 < 
-0.16 dB at 10 GHz and return loss S11 <-19 dB at 10 GHz. Even at more high frequency insertion loss is 
very low as S21 < -0.22 dB and return loss S11 < -18 dB at 39.5 GHz. 
 
Key words: MEMS, RF, Actuators, Insertion loss, Isolation  
 
1. INTRODUCTION 
 
MEMS technology has exhibited numerous 
advantageous properties that helped this technology 
to compete in the microelectronics market. MEMS 
technology allows miniaturizing the device while 
performance also boost up. Personal 
communication devices with miniaturized high 
frequency and high integration have been possible 
with the advent of fabrication technology which is 
using MEMS technology to fabricate the integrated 
RF circuits. MEMS (Micro-Electro-Mechanical 
Systems) is the integration of mechanical elements, 
sensors, actuators, and electronics on a common 
silicon substrate through microfabrication 
technology. 
 
RF switches are the most common and basic circuit 
elements. Current solid-state RF technologies (PIN 
diode- and FET- based) are utilized for their high 
switching speeds, commercial availability, low 
cost, and ruggedness [1]. This technology reached 
its maturity in areas such as device design, 
fabrication, packaging, applications/system 
insertion and, consequently, high reliability and 
well-characterized performance. Some parameters, 
such as isolation, insertion loss, and power 
handling, can be adjusted via device design to suit 
many application needs. In spite of this great design 
flexibility, there are two major bottlenecks with 
solid-state switches: breakdown of linearity and 
frequency bandwidth upper limits, and the 
degradation of insertion loss and isolation at signal 
frequencies above 1-2 GHz. The advantage of low 
insertion loss, high isolation, extremely high 
linearity together with the potential for high 
reliability, low power consumption, low mass and 
long lifetime operation, make RF MEMS switches 
a promising solution to existing low-power RF 
technology limitations [2]. Various researches have 
been done on MEMS switches including metal-to-
metal contact switch [3, 4], capacitive contact shunt 
switch [5], Ti/Gold switch [6, 7], push-pull series 
switch [8, 9] and DC-contact switch [10] - [13]. 
Nowadays, more MEMS switch, capacitors, 
inductors are reported to be integrated to make 
various RF devices. Devices such as phase array 
phase shifter, switching and reconfigurable 
networks and low power oscillator and varactors 
are actively pursued and manufactured for wireless 
communication industries [14, 15]. 
 
In this research, a MEMS switch had been 
developed for Radio Frequency (RF) application. 
The switch contains two hot arm actuators and was 
designed and simulated using CST Microwave 
Studio.  
Page 926ISBN: 978-984-33-2140-4
  
2. DESIGN METHOD AND ANALYSIS 
 
 
The NB Technology Company at Hamburg in 
Germany proposed a mechanical MEMS switch. 
Fig. 1 shows the design sequences of two hot arms 
actuator MEMS switch which was developed. The 
purpose of this study is to analyze microwave 
performance of this switch. 
 
 
 
 
       
    (a)   (b)       (c)       (d) 
 
 
 
(e) 
 
Fig. 1 Design of the switch (a) substrate with etching (b) actuators (c) contact tip (d) clip for actuators (e) 
complete switch 
 
Substrate is made of quartz material with height of 
50 µm. An etching process has been performed on 
the quartz substrate to make a specific shape on the 
substrate and to create an air gap between the 
actuators and substrate material as shown is fig.1 
(a). The two hot arms actuators are made by nickel 
with surface micromachining technology. The 
width and height of the actuator is 50 µm and 13 
µm respectively as shown in fig.1 (b).  To connect 
the actuators end, two contact tips have been made 
of gold as shown in fig.1 (c) and attached them with 
the end of each actuator. To avoid contact between 
etched substrate and actuators, three clips are made 
of SU8 material as shown in fig.1 (d). Finally two 
microstrip lines have been created on the substrate 
to make input and output port as shown in fig.1(e). 
 
The microwave signal travels from port 1 to port 2 
through the microstrip lines and actuators. The 
equivalent electrical circuit of this transmission line 
is given in fig.2. When voltage is applied, the two 
actuators are connected with each other and the 
signal transmitted from port 1 to port 2 forming a 
complete transmission line. In this case the total 
Page 927
  
transmission line length L=1.44mm. The 
characteristics impedance of the line Z0 has been 
calculated using AWR Microwave Office. For the 
physical characteristics of the transmission line of 
Length, L=1.44 mm, Width, W = 50 µm, Height, 
H=50µm and Thickness, T=13µm, characteristics 
impedance of the transmission line Z0=70.05Ω, 
Electrical Length βl=0.4947rad have been 
calculated at 10 GHz. B=0.12776mm-1 thus 
l=3.89mm. 
 
     
 
             
Fig.2 Equivalent circuit upon voltage applied 
 
 
 
 
Fig.3 Equivalent circuit upon voltage turned off 
 
 
When there is no voltage applied to the actuators, 
the transmission line is not connected as two 
actuators are separated by a distance of 0.003976 
mm. An equivalent circuit is shown in fig.3 of this 
situation. In this case if a signal excited at port 1, it 
will try to travel from port 1 to port 2, but when as 
the actuators are disconnected the signal travels 
back from the end of the actuator with port 1. As 
two actuators are separated by some distance, there 
will be a capacitive effect between the two 
actuators. This capacitance C=0.000076pF. The 
impedance due to this capacitance is –j209414 
ohm. From the AWR Microwave Office, the 
electrical length is calculated as 0.24736 rad. 
Therefore clll == 21 =1.93mm. 
 
3. RESULTS 
 
Fig.4 shows the simulated scattering parameters 
11S  and  21S  when the MEMS switch is in OFF 
state. As shown, the return loss 11S  drops nearly to 
zero for the signal transmission was interrupted. On 
the other hand, the isolation 21S  become lower 
than -50 dB at 1 GHz and -35 dB at 10 GHz which 
indicates the high isolation created by the gap 
between two actuators.  
 
 
 
Fig.4 S-parameters with switch is in OFF state 
 
Fig.5 shows the simulated scattering parameters 
11S  and  22S  when the MEMS switch is in ON 
state. When MEMS actuator is connected means 
the switch is in ON state the signal transmitted from 
port 1 to port 2. At ON state position the simulation 
exhibits very low insertion loss, 21S  < -0.16 dB at 
10 GHz and return loss 11S < -19 dB at 10 GHz.  
 
 
 
Fig.5 S-parameters with switch is in ON state 
 
1l
 
2l
 
C 
βα ,,0Z  Port1 Port2 
 
Port1 Port2 
Page 928
  
At higher frequencies the switch exhibits also good 
performance as shown in fig.6 when the actuators 
are connected upon voltage applied, the simulation 
shows us that  the insertion loss is very low as 21S
< -0.22 dB  and return loss 11S < -18 dB  at 39.5 
GHz.  
 
 
Fig.6 S-parameters at higher frequencies 
 
From the fig.7 we can notice that in frequency 
range of 0 to 20 GHz, the scattering parameters 21S  
decays as the frequency increased. This is because 
the impedance of the transmission line also 
increased with frequency. On the other hand in the 
frequency range of 20 GHz to 40 GHz, the 
scattering parameter 21S  rise up. This may happen 
due to the structure of the transmission line and can 
be explained as filtering effect. In this range of 
frequencies the impedance of the transmission line 
has matched due to the shape of the transmission 
line. Fig.8 shows an example of this effect. 
 
 
Fig.7 S-parameters 21S  at higher frequency 
In fig.8 (a) a microwave filter has been considered 
to understand the situation of fig.7.  The microstrip 
line designed here has two different widths as 
shown. When a signal excited at input port, a 
portion of the signal will travel through the line and 
a portion will be reflected back because of the 
different width of the structure exhibits different 
impedance of the transmission line. From fig.8 (b), 
we can see that the structure filtered out some 
frequencies and allow some specific range of 
frequencies.  
 
 
 
Fig.8 (a) A microwave filter (b) filtered output 
 
The same phenomenon has caused to the MEMS 
switch designed here. Since the actuators are made 
of different width and different material, the 
impedance throughout the transmission line is not 
equal and mismatches of the impedances causes 
different values of scattering parameters at different 
frequencies. 
 
4. CONCLUSIONS 
 
High frequency performance analysis of a two hot 
arms thermal actuator has been attempted in this 
paper. The 3D design of the structure is designed 
and simulated using CST Microwave Studio. RF 
analysis of this MEMS switch has shown that at 
low frequency the isolation is very high as -50 dB 
at 1 GHz and at higher frequency the isolation is 
also quite high as achieved -35 dB at 10 GHz.  ON 
state simulation results revealed that very low 
insertion loss is achieved ( 21S < 0.16 dB) and the 
return loss 11S < -19 dB at 10 GHz. Even at more 
high frequencies (40 GHz) the performances of this 
switch is reasonably remarkable. The S-parameters 
simulation shows that a low insertion loss 21S <- 
Signal 
output 
Signal 
input 
(a) 
(b) 
Page 929
  
0.22 dB and low return loss 11S < -18 dB have been 
achieved at 39.5 GHz. 
 
 
REFERENCES 
 
1. Thomas H. Lee, “The Design of CMOS 
Radio-Frequency Integrated Circuits”, 
Cambridge University Press, 1998. 
2. Héctor J. De Los Santos, “RF MEMS Circuit 
Design for Wireless Communications”, 
Artech House,    Massachusetts, 2002 
3. Md. Asaduzzaman, M.S.R. Shoaib, “Electro-
thermal and Mechanical Analysis of a MEMS 
Switch”, IEEE Internatinal Conference on 
Electrical and Computer Engineering, pp.388-
391, December 2010.  
4. J. J. Yao and M. F. Chang, “A surface 
micromachined miniature switch for 
telecommunications applications with signal 
frequencies from DC to 4 GHz”, International 
Conference on Solid State Sensors and 
Actuators Digest, Stockholm, Sweden, June, 
1995. pp. 384-387.  
5. C. Goldsmith, J. Randall, S. Eshelman, T. H. 
Lin, D. Dennistor, S. Chen, and B. Norvell, 
“Characteristics of micromachined switches at 
microwave frequencies”, IEEE MTT-S 
International Microwave Symposium Digest, 
San Francisco, CA, June, 1996, pp. 1141- 
1144.  
6. J.B. Muldavin and G. M. Rebeiz, “High 
isolation MEMS shunt switches; Part 1: 
Modeling”, IEEE Trans., Microwave Theory 
Tech., Vol. 48, No. 6, pp. 1045-1052, June 
2000. - 10 
7. J.B. Muldavin and G. M. Rebeiz, “High 
isolation MEMS shunt switches; Part 2: 
Design”, IEEE Trans., Microwave Theory 
Tech., Vol. 48, No. 6, pp. 1053-1056, June 
2000.  
8. J. C. Chiao, Y. Fu, L.-Y. Lin, and D. 
Choudhury, “MEMS millimeter-wave 
components”, IEEE MTT-S Microwave 
Symposium Digest, Anaheim, CA, June, 
1999, pp. 1515-1518.  
9. D. Hah, E. Yoon, and S. Hong, “A low 
Voltage activated micromachined microwave 
switch using torsion springs and leverage”, 
IEEE MTT-S International Microwave 
Symposium Digest, Boston, MA, June, 2000, 
pp.157-160.  
10. L.E. Larson, R.H. Hackett, M.A. Melendes, 
and R. F. Lohr, “Micromachined microwave 
actuator (MIMAC) technology- a new tuning 
approach for microwave integrated circuits”, 
Microwave and Millimeter-Wave Monolithic 
Circuits Symposium Digest, Boston, MA, 
June 1991, pp. 27-30.  
11. C. Goldsmith, J. Randall, S. Eshelman, T. H. 
Lin, D. Dennistor, S. Chen, and B. Norvell, 
“Characteristics of micromachined switches at 
microwave frequencies”, IEEE MTT-S 
International Microwave Symposium Digest, 
San Francisco, CA, June, 1996, pp. 1141- 
1144.  
12. John Maciel, Sumit Majumder, Richard 
Morrison, James Lampen, Lifetime 
“Characteristicsof Ohmic MEMS Switches”, 
SPIE 2004. 
13. S. Duffy, C. Bozler, S. Rabe, J. Knecht, L. 
Travis, P. Wyatt, C. Keast,and M. Gouker, 
“MEMS microswitches for reconfigurable 
microwave circuitry”, Microwave and 
Wireless Comp. Lett., Vol. 11, No. 3, pp 106-
108, March 2001. 
14. Balasundaram Elamaran, Iao-Mak Chio, 
Liang-Yu Chen and Jung-Chih Chiao, “A 
Beam steerer using reconfigurable PBG 
ground plane” IEEE MTT-S Digest, 2000, pp 
835-838. 
15. K.J. Vinoy, Hargsoon Yoon, Taeksoo Ji and 
Vijay K. Varadan, “RF MEMS and 
Reconfigurable Antennas for Communication 
Systems, MEMS Components and 
Applications for Industry, Automobiles, 
Aerospace, and Communication II”, 
Proceedings of SPIE Vol. 4981 (2003), 2003. 
Pp.164-175 
 
Page 930
Proceedings of the
Conference on Engineering Research, Innovation and Education 2011
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh
     Corresponding Author: A. R. M. Jalal Uddin Jamali
       E-mail: armjamali@yahoo.com, 
                                                   
POPULATION BASED HEURISTIC APPROACH FOR PACKING 
IDENTICAL CIRCLES IN A MINIMIZED CIRCULAR CONTAINER
A. R. M. Jalal Uddin Jamali *, M. Asadul Alam 
Dept. of Mathematics, Khulna University of Engineering & Technology, Khulna 9203, Bangladesh.
A. Grosso, M. Locatelli, 
Dept. of Computer Science, University of Turin, Italy
Packing problems have mathematical as well as practical application point of interest. We present, here,   
Population based Basin Hopping rather than monotonic heuristic search approach to solve the problem of 
packing identical circles within a minimum size of circular container. For the evolution among the population 
we also present two dissimilarity measures. Extensive computational experiments have been performed for 
analyzing the problem as well as for choosing an appropriate way the parameter values for the proposed 
methods. Several improvements with respect to the best results reported in the literature have been detected.
Key words: Circle Packing, Monotonic Basin Hopping, Population, Dissimilarity Measure.
1. INTRODUCTION
The problem of optimally placing N non 
overlapping and possibly of different size objects 
belonging to Rd within a smallest container is a 
classical mathematical problem and have a 
spectrum of application including production and 
packing for the textile, apparel, naval, automobile, 
aerospace and food industries, news paper, web 
pages design, in particular, to problems related to 
cutting and packing [Dyckhoff, 1990]. They are 
bottleneck problems in Computer Aided Design 
(CAD) and Computer Aided Manufacturing (CAM) 
where design’s plans are to be generated for 
industrial plants, electronic modules, nuclear and 
thermal plants, etc. In particular, we consider in this 
paper, the Identical Circle Packing in a Circular 
Container (ICPCC) problems. The ICPCC 
problems can be described by the several equivalent 
problems [Dyckhoff, 1990]. One of the settings is 
given bellow:
Problem: To find the minimum circular container 
radius Dn which contains n identical and non-
overlapping circles of radius one. Mathematically, 
rmin                                                                 (1)
Subject to 
Iirryx ii  ;21 222                           (2)
jiIjiyyxx jiji  ,;4)()( 22    (3)
 r1                                                            (4)
This formulation has 2n + 1 variables, one of which 
is the radius r of the container, to be minimized (1); 
2n variables for the coordinates of the n circles 
(note that center of the container assume without 
loss of generality to be the origin). Equation (2) 
states that any circle Ci of radius one is totally 
contained within container C. There are N of these 
constraints, one for each circle Ci. While 
constraints (3) force circles Ci and Cj not to 
overlap. There are n(n − 1)/2 of these non overlap 
constraints. Equation (4) provides a positive lower 
bound for the radius of the containing circle. It 
substitutes the non-negativity constraint whose 
elimination from the model makes NICPCC
unbounded. Although the objective (equation (1)) is 
linear and constraints (2) define a convex region, 
whereas constraints (3) are non convex (and, in 
particular, they correspond to reverse-convex 
constraints). It is pretty easy to see that, because of 
the non convexity, this problem is extremely hard 
to solve; even local optimization, in presence of 
reverse-convex constraints, becomes a hard task. 
Indeed, there exists no any algorithm that is both 
rigorous and fast. Hence researchers are searching 
for the efficient heuristic approximation algorithms 
to solve the problems. There is a long history of 
solving packing problems in literature. A survey 
about this problem can be found in a recent book 
[Johnson et al. 2007] that has been dedicated to the 
subject.. Benchmark results for the problem of 
packing equal circles in a container whose shape is 
a square, a circle or an equilateral triangle are 
reported and continuously updated in Specht’s web 
site [Specht, 2009]. Finally, we also refer to the 
papers [Castillo et al. 2008, Hifi  and Hallah, 2009 ]
where a detailed survey about methods and 
applications of packing problems can be found. 
There are very few papers considered population 
based approaches for dealing packing problems. 
Authors [Jain and Gea, 1998] use genetic 
algorithms for solving two-dimensional packing 
problems. In [Shahookar and Mazumder, 1990], 
authors also proposed genetic approach to standard 
cell placement using meta-genetic parameter 
ISBN: 978-984-33-2140-4
Page 931
optimization.  Evolutionary based heuristic 
approach was used, in [ Stawowy 2008], to the 
one-dimensional bin packing problem.
Authors in [ Grosso, et al., 2009], implements
monotonic basin hopping heuristic approaches for 
equal circles packing in circular container 
problems. But when instances are hard monotonic 
basin hopping (single search) approach frequently 
fail to obtain optimal solution.
In this paper we investigate a related problem: 
packing circles with unit radius into a circular 
container of minimum radius. For solving the 
problems we will propose an evolutionary based 
Basin Hopping approach. For the presence of 
population we will introduces a new parameter 
called dissimilarity measures for the selection 
mechanism. The basic idea is to maintain a 
sufficient dissimilarity gap among the individuals 
in the population in order to explore a wide part of 
the solution space.  In [Cassioli et. al , 2010] , 
author proposed several dissimilarity measures are 
for the field of Molecular Cluster Optimization. 
2. PROPOSED POPULATION BASED 
BASIN HOPPING ALGORITHM
As the problem is a NP-hard global optimization 
one, the number of local minimizers tends to 
increase quite quickly with the number n of circles. 
When dealing with global optimization problems 
for NP-hard problem, an obvious and simplest 
single point search approach is the Multistart (MS) 
one. In such an approach we simply start different 
local searches from randomly generated initial 
points and return the best local minimizer. 
However, the rapid increase in the number of local 
minimizers suggests that Multistart can not be an 
efficient method for this problem. One efficient 
single search approach is Monotonic Basin 
Hopping (MBH) approach [Jamali et al.,2009,. This 
approach is quite close to Multistart (they are both 
based on multiple local searches and they only 
differ in the mechanism for the generation of the 
initial points) but at the same time it is also 
dramatically more efficient than Multistart. In the 
field of global optimization, such method has been 
(to the authors’ knowledge) first applied to 
molecular conformation problems (see [Jamali et 
al.,2009]) under the name of Monotonic Basin 
Hopping (MBH). 
It was experimentally shown [Jamali ,2009] for the  
problem of ICPCC, when the instance is simple 
one, MBH approach coup the problem efficiently ; 
but, for the hard instances,  MBH often fail to find 
out optimal solution (minimized container).  In the 
field of Evolutionary Computations, it is shown 
that, for the very hard NP-Hard problems, multi-
search approaches often able to coup the problems.    
As MBH approach successfully applied for circles 
packing problems when instance are relatively 
simples, so we will propose a population based 
Basin Hopping (PBH) approach rather than 
monotonic search to coup the hard instances 
problems as well as other problems. As proposed 
method will be develop upon MBH approach so we 
would like to present the pseudo code of MBH 
approach  given bellow 
:
Monotonic Basin Hopping 
Step 1 :Let X0 be randomly generated 
initial solution 
                      // Initialization procedure
Step 2: Let X := τ (X0) be a local 
minimum 
                    // local search procedure
While SR not satisfied 
       Step 3 : Let Y := ξ (X)
                   // perturbation procedure
       Step 4: Let X := τ (Y) 
                   // local search procedure
       Step 5: If  f (X ' )  < f(X), then X:= X '
                  // acceptance rule
      EndIf 
EndWhile 
Return X 
For retail authors would like to refer Jamali et al.  
2009. 
2.1 Population Basin Hopping 
Each run of MBH follows a single path through the 
space of local minimizers. An alternative to MBH 
is Population Basin Hopping, inspired by the 
Conformational Space Annealing algorithm [Lee et 
al. 1997], in which the single path search is 
substituted by a multiple path search. During this 
search, members of the population collaborate with 
each other in order to guarantee diversification of 
the search and to avoid the greediness which might 
characterize a single path search. All components of 
MBH are present in PBH. The new ingredient in 
PBH is the dissimilarity measure D and new 
parameters are Np (the size of the population) and 
dcut (a threshold dissimilarity value). If we denote 
by S the space of the solutions at which we are 
interested (in ICPCC basically the local 
minimizers), the dissimilarity measure can be 
defined as the following function :
D : S ×S →R+
which, for a given pair of solutions, quantifies the 
diversity between them. Ideally, given two 
solutions    X, Y∈ S, D(X, Y ) should be close to 
zero only if X, Y∈S are very “similar ”and, in 
particular, equal to 0 only if they represent (modulo 
symmetries, rotations, translations, numbering of 
circles, and so on) the same solution. We allow the 
Page 932
concept of similarity to be problem-specific; the 
only essential requirement we impose is that for 
similarity of a solution X ∈ S with itself, it must 
hold that D(X, X) = 0 [Cassioli et al., 2010]. Given 
the dissimilarity measure, the pseudo-code for PBH 
is the following.
Step 1(Init): Let X0 be a set of Np randomly 
generated solutions
Step 2(LS): Compute X = τ(X0) 
While the stopping rule SR is not satisfied
Step 3(PM): Compute X/i := ζ(Xi) : Xi∈ X,
        i = 1, 2, . . .,Np
Step 4(LS): let Y := τ(X/) : X/i∈ X/,
i = 1, 2, . . .,Np (pert. pop.)
Sequential Replacement:
    Repeat Yi∈ Y, ∀ i = 1, 2, . . .,Np
Step 5 let Xh ∈ X  D(Yi,Xh) is 
minimum
Step 6 (AR): if D(Yi,Xh) < dcut and 
f(Yi) < f(Xh) then
set X := X/ {Xh} ∪ {Yi} 
EndIf
else if D(Yi,Xh) ≥ dcut then
select Xs ∈ X   f(Xs) is maximum, 
and
if f(Yi) < f(Xs) then
set X := X/ {Xs} ∪ {Yi} EndIf
EndRepeat
   EndWhile
Return X
Basically, at each iteration: a set Y of new 
candidates is generated through the application of
the perturbation move to each member of the 
population; each new candidate Yk, k = 1, . . .,Np, 
competes either with the member Xh of the current 
population X most similar to it with respect to the 
dissimilarity measure D (if D(Xh, Yk) ≤ dcut), or 
with the worst member Xs of the population (if 
D(Xh, Yk) > dcut, i.e., Yk is dissimilar enough with 
respect to all members of the current population); if 
it wins (i.e., if it has a better function value), it 
replaces Xh (or Xs) in the population for the next 
iteration. Note that MBH is, in fact, a special case 
of PBH where Np = 1. There is a trade off between 
two conflicting objectives in choosing Np. We have 
already outlined above the (possible) advantages of 
PBH: increasing Np increases diversification and 
decreases greediness. On the other hand, increasing 
Np also increases the computational effort per 
iteration. Later, we will discuss appropriate choices 
for Np. The local search procedure and 
perturbations techniques of the PBH approach are
the same as those for the MBH approach. Each 
individual is independently perturbed and a local
search starts at the perturbed point. The real 
difference in PBH is represented by the acceptance 
rule. A candidate replaces the member of the 
population with which it competes only if it has a 
better function value as in MBH, but the member 
with which it competes is not necessarily (and, in 
fact, often it is not) the member of the population 
whose perturbation led to the candidate. Formally, a 
candidate Yi does not necessarily compete with its 
“father” Xi.. This means that Yi could enter the new 
population even if f(Yi) > f(Xi) (a backtracking 
move which is not allowed in MBH), but also that
Yi might not enter the new population even if f(Yi) < 
f(Xi) (this is called hesitation and might be 
profitable in order to avoid the drawbacks of a too 
greedy approach). The stopping rule SR is basically 
the same employed for MBH: we stop if the best 
member of the population does not change for a 
fixed number MaxNonImp of iterations. In the 
following subsection we discuss our choices for the 
dissimilarity measure and the dcut value.
2.2 Dissimilarity measure
Since the dissimilarity measure D is the core 
component of the proposed PBH approach, we will 
discuss below a couple of possible choices of such 
measures for packing problems. Note that in 
[Cassioli et al., 2010] there are several dissimilarity 
measures proposed for molecular conformation 
problems. For what concerns the choice of the dcut 
value, we adopted in our PBH algorithm a simple 
definition: it is equal to half the average 
dissimilarity within the initial randomly generated
population.
(a) Distance dissimilarity measure
Let X = {(αi1, αi2)} and Y = {(βi1, βi2)}; i =1,...,n be 
two distinct local minimizers. Let ρh(X) be the 
distance of circle h from the barycenter of the
centers of all circles in the local minimizer X, i.e., if 
we move the barycenter to the origin
2
2
2
1)( hhh X  
and define ρh(Y ) in a similar way; let δX be the 
vector whose components are the distances ρh(X) ∀
h = 1,. . , n ordered in a non-decreasing way, i.e.,
δX[1] ≤ δX[2] ≤ . . . ≤ δX[k] ≤ . . . ≤ δX[n] where δX[k] 
denotes the k-th component of the vector δX. 
Similarly for the local minimizer Y. Then, the 
distance dissimilarity measure is defined as follows
   .)(
1



n
k
YX kkX,YD 
(b) Objective-distance dissimilarity measure
The objective-distance dissimilarity measure is very 
similar to the distance measure dissimilarity but 
also takes into account the difference between 
objective function values. More precisely, we 
define the objective-distance dissimilarity measure 
as follows
   ..)()()(
1



n
k
YX kkYfXfX,YD 
Page 933
The reason for this slight modification is due to free 
circles. When a configuration X has free circles, 
then we can move them around thus obtaining 
different configurations with a positive distance 
dissimilarity but a null objective-distance one with 
respect to X.
3. COMPUTATIONAL EXPERIMENT 
AND DISCUSSION
3.1 Experiments on hard instances
In the first experiment we compare the behavior of 
PBH and MBH on the Hard Instances for MBH 
[Jamali,2009,Jamali et al., 2009] where MBH is 
often failed to obtain optimal value. We might think 
that the difficulty of such instances is due to the 
existence of different funnels [Jamali, 2009,, Leary, 
2000], so that many runs of MBH are needed 
before hitting the (putative) global optimum. In this 
case the multi-path search performed by PBH
should allow to detect the solution more easily, 
though at a higher computational cost 
(approximately, a single run of PBH has a cost 
which is Np times larger than a single run of MBH, 
where Np denotes the size of the population). We 
will compare MBH(FJ) [Jamali et al. 2009] and 
PBH(FJ) by setting ∆ = 0.8 and MaxNonImp = 500 
in both cases, setting Np = 10 and employing the 
distance dissimilarity measure in PBH. In order to 
have a comparable overall computation time, we 
perform 50 runs of MBH and 5 of PBH. The results 
are displayed in Table 1, where for each instance 
we report the percentage of successes. The results
reported in the table suggest that PBH with a 
relatively large Np value is certainly a robust 
approach, able to detect with a high percentage of 
success (often 100%) the solution of the hard
instances. On the other hand, we should recall the 
higher computational cost of a PBH run.
      
For this reason, we compare the two approaches on 
the basis of the elapsed time per success. Figure 1
displays the average elapsed time per success of
MBH(FJ) and PBH(FJ) on the hard instances. The 
figure shows that, with the remarkable exception of 
the n = 31 case, where PBH strongly outperforms
MBH, the two approaches are often comparable but 
PBH is, usually, slightly superior but a bit more 
computational time.
3.2 Impact of population size in PBH
In the previous experiments we considered PBH 
(FJ) with Np = 10. Now we would like to 
investigate more thoroughly the impact of the 
population size in PBH. In these experiments we 
consider PBH (FJ) with population sizes Np = {1, 2, 
4, 8, 10}. We set MaxNonImp = 100, ∆=0.8, and 
employ the distance dissimilarity measure. The 
experiments are performed on the large instances 
n= 80. . . 100. Note that Np = 1 corresponds to the 
MBH approach. In order to have a comparable 
computation time, the number of runs is R = 50, 25, 
13, 6, 5 for Np = {1, 2,, 8, 10} respectively. The 
results are reported in Table 2 in form of percentage 
of successes.  The results somehow confirms those 
in the previous subsection: indeed, in spite of one 
or two failures, the largest tested Np values, say Np
∈ {8, 10}, usually guarantee the highest 
percentage of successes (very often 100% 
successes), confirming that for large Np values PBH 
turns out to be a quite robust approach. On the other 
hand, in many cases also small Np values (even Np
= 1, i.e. MBH, although this is also the case with 
the largest number, 4, of failures) quite often
guarantee a high percentage of successes (at a lower 
computational cost per success with respect to large 
Np values). Basically, it seems that for these
problems single or few path searches are often 
already quite efficient and that the benefits coming 
Fig. Comparison between MBH and PBH regarding 
average elapsed time per success in some hard 
instances
Table 1: Comparison between MBH and PBH with 
Np =10 approaches in some hard instances
n OurBestResult
s
Success (in %)
(in PBH)) PBH MBH
31 6.291502622 100 2
68 9.229773747 100 42
78 9.8577099 100 42
79 9.905063468 60 4
80 9.968151813 80 8
83 10.11685788 100 42
92 10.68464585 60 10
95 10.84020502 80 38
98 10.97938313 100 82
31 6.291502622 100 2
68 9.229773747 100 42
Page 934
from the greater diversification guaranteed by PBH 
with larger Np values are overridden by the larger 
computational cost per iteration. It is worthwhile to 
remark that PBH approach able to obtain two 
further improvements at n = 96, 99 compare to  
MBH approach as well as literature [by  Specht,  
2009] (see table 2).
3.3 Impact of different dissimilarity 
measures
Since we have previously proposed two 
dissimilarity measures, we would like to perform a 
final experiment to compare the performance of 
PBH(FJ) with the two dissimilarity measures 
Distance Dissimilarity (DD) and Objective-
Distance Dissimilarity (ODD). For this experiments 
we consider the instances n = 80. . . 100  plus the 
hard instances with n < 80, set MaxNonImp = 200 
and 500, ∆ = 0.8. We also consider three population 
sizes Np = {2, 5, 10} and always perform R = 5 
runs. The results are displayed in Table 3. We 
notice that the differences between the two 
dissimilarity measures are not particularly 
significant, although, with the only exception of Np
= 10 and MaxNonImp=200, DD usually has a 
slightly lower number of failures and higher 
number of improvements. As a final remark, we 
point out that DD and ODD are reasonable 
measures but certainly not the only possible ones. A 
possible aim for future researches is that of 
proposing and testing new measures.
3.4 Comparison with Literatures
Finally we would like to compare our experimental 
result with the literature, basically with [Specht, 
2009] in which latest optimal values are updated.  
The table 4 shows the overall improved solution 
obtained by our proposed PBH approach as well as 
MBH approach [Jamali et al. 2009]. Our approach 
able to obtain 21 improvements compare to the best 
known values available in [Specht,  2010]. On the 
other hand the PBH approach also able to obtain 
other optimal value reported in [Specht, 2010]. 
Moreover as mention earlier PBH approach able to 
further improve for number of circles n = 96 and 
99.  It is also worthwhile to mention here that our
improved solutions are also now available on the 
web http://www.packomania.com/.
Table 4 Overall improved value compare to the 
Best Known Result available in Literature.
  
n radii
66 9.0962794269
67 9.1689718818
70 9.3456531941
71 9.4157968969
73 9.5403461521
74 9.5892327643
75 9.6720296319
77 9.7989119245
78 9.8577098999
83 10.1168578751
86 10.2987010531
87 10.3632085051
88 10.4323376927
89 10.5004918146
92 10.6846458479
93 10.7333526003
94 10.7780321603
96 10.8832027597
97 10.9385901101
99 11.0331411514
100 11.0821497243
Table 2 Impact of number of Individuals
n OurBestRes. Success (in%) for Np
(in PBH) =1 =2 =8 =10
80 9.968151813 4 8 50 100
81 10.01086424 38 68 100 100
82 10.05082422 58 92 100 100
83 10.11685788 4 4 67 60
84 10.14953087 100 100 100 100
85 10.16311147 100 100 100 100
86 10.29870105 72 100 100 100
87 10.36320851 18 100 100 100
88 10.43233769 74 100 100 100
89 10.50049181 28 68 50 100
90 10.54606918 68 100 100 100
91 10.56677223 64 100 100 100
92 10.68464585 2 0 17 20
93 10.73335260 18 12 17 20
94 10.77803216 36 28 50 60
95 10.84020502 0 40 100 60
96 10.88320276 0 4 0 50
97 10.93859011 14 4 67 100
98 10.97938313 4 100 100 100
99 11.03314115 0 16 83 100
100 11.08214972 18 64 100 100
Total No. of Failure 4 1 1 2
No. of 100% success 2 8 12 15
Page 935
4. CONCLUDING REMARKS   
In this paper we have proposed population (based)
Basin Hopping (PBH) approach to solve the 
packing identical circles in a circular container.  For 
the presents of population we proposed two simple 
dissimilarity measures in order to guarantee
diversification of the search and to avoid the 
greediness which might characterize a single path 
search. Extensive experiments have been performed 
to investigate the impact of the population. Also 
some experiments have been carried out about the 
impact of the two primarily proposed dissimilarity 
measures. The proposed PBH approach is certainly 
more robust but as the same time computationally it 
is a bit costly with respect to MBH (single search 
base) approach. But in the case of Hard Instances
population based (basin hopping) approach is much 
more efficient because of existence of large number 
of funnel of attraction. The proposed PBH approach 
able to improve a large number of optimal solutions 
with in the range of, number of circles, n =50 to 
n=100.
5. REFERENCES
1. Cassioli A. , Locatelli M. and Schoen F., 
“Dissimilarity measures for population-based 
global optimization algorithms”, 
Computational Optimization and Applications, 
Springer , Vol.  45(2), DOI: 10.1007/s10589-
008-9194-5, 2010, pp. 257-281
2. Castillo I., Kampas F. J., Pinter J. D., “Solving 
circle packing problems by global 
optimization: numerical results and industrial 
applications”, European Journal of 
Operational Research, vol. 191 (3), Elsevier,  
2008, pp. 786-802 .
3. Dyckhoff , H., “A typology of cutting and 
packing problems”, Eur. J. Oper. Res, Elsevier, 
vol. 44,  1990, pp.  145-159. 
4. Hifi M. and R. Hallah M’, “A Literature 
Review on Circle and Sphere Packing 
Problems:” Models and Methodologies, 
Advances in Operations Research,   Hindawi 
Publishing Corporation, Volume 2009, Article 
ID 150624, doi:10.1155/2009/150624, pp. 1-22
5. Jain S. and Gea H.C., “Two-dimensional 
packing problems using genetic algorithms ”, 
Engineering with computers, Springer-Verlag, 
vol. 14,1998, pp. 206-213.
6. Jamali A. R. M. Jalal Uddin,  “Heuristic 
approaches  for maximin distance and packing 
problems”, Ph.D. Dissertation, University of 
Turin, Italy, 2009.
7. Jamali A. R. M. Jalal Uddin, A. Grosso, M. 
Locatelli, F. Schoen, Packing Identical Circles 
in a Minimized Circular Container by 
Monotonic Basin Hopping Heuristic Approach, 
Proceedings of 12th International Conference 
on Computer and Information Technology 
(ICCIT 09), Dhaka, Bangladesh.
8. Johnson  M. C. , Csendes  T.  , Specht  E.., 
Casado L. G., , . Garcia P. G, Mark I. “New 
approaches to circle packing in a square, 
optimization and its applications”, Springer, 
2007. 
9. Lee J., Scheraga H. A., and Rackovsky S., 
“New optimization method for conformational 
energy calculations on polypeptides”: 
conformational space annealing, J Comput. 
Chem., vol. 18(9), pp. 1222-1232 (1997).
10. Leary R. H, , “Global optimization on 
funneling landscapes”, J. Global Optim, vol. 
18, 2000,  pp. 367-383 
11. Specht, E Packomania web site maintained by  
www.packomania.com , 2010.
12. Shahookar K., Mazumder P., “Genetic 
approach to standard cell placement using 
meta-genetic parameter optimization”, IEEE 
Trasns. On Computer Aided Design, Vol. 9(5), 
1990, pp. 500-511.
13. Stawowy Adam , “Evolutionary based heuristic 
for bin packing problem”, Computers and 
Industrial Engineering, Pergamon Press, Inc.
USA , Vol. 55(2), 2008, pp. 465-474.
Table 3 Comparison between different dissimilarity measures  in PBH approach.
No. of Success for Run=5 & MNI=200 No. of Success for Run=5 & MNI=500
Np=2 Np=5 Np=10 Np=2 Np=5 Np=10
DD
OD
D DD
OD
D DD ODD DD ODD DD ODD DD ODD
Total Failure 6 9 2 3 4 5 2 3 0 2 2 2
Total Improvement 8 7 11 9 9 11 10 10 13 10 11 11
Tot. Elapsed  
Time(hrs)
45 44 62 78 117 107 120 111 132 179 297 260
Page 936
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
*
 Corresponding Author: A. S. M. Iftekhar Uddin,  
E-mail: horrorfan72@yahoo.com  
PATTERN OPTIMIZATION OF A LINEAR DIPOLE ANTENNA 
THROUGH IMPROVING DIRECTIVITY AND REDUCING SIDE 
LOBES 
 
 
A. S. M. Iftekhar Uddin* 
Assistant Professor, Dept. of Electronics & Communication Engineering 
Sylhet International University, Shamimabad, Bagbari, Sylhet – 3100, Bangladesh 
 
Md. Muzibul Kamal and Md. Masud Parvez 
Sylhet International University, Shamimabad, Bagbari, Sylhet – 3100, Bangladesh 
 
 
This paper deals with a keen analysis of antenna measurement and propagation of information through air 
media. Antennas have practical uses for the transmission and reception of radio frequency signals (radio, 
TV, etc.). In air, those signals travel very quickly and with a very low transmission power. The signals are 
absorbed when moving through more conducting materials, such as concrete walls, rock, etc. When 
encountering an interface, the waves are partially reflected and partially transmitted through. Antenna 
radiates energy in all direction in free space where some energy radiated in a preferred direction and if the 
amount of directed energy is high then it would be said a better and efficient energy transmission. In this 
research we have developed a new scheme by which an antenna’s performance can be improved to an 
acceptable level and we have considered linear dipole antenna as reference model. The proposed scheme is 
developed in three steps – firstly we have set the best dipole arrangement by varying the elevation angles 
above the horizon and adjusted the feed point impedance, then an optimization technique is applied to 
achieve the low outer as well as low inner side-lobe levels and finally shielding mechanism (reducing 
surface resistance) have been deployed. The main goal of this research is to improve the gain of the 
reference antenna and reduce noise to a sustainable level and ultimately preferable effectiveness and greater 
efficiency have been achieved.   
 
Key words: Directivity; Dipole; Side lobe; Pattern synthesis and surface resistance. 
 
1. INTRODUCTION 
 
Generally, an antenna is a transducer designed to 
transmit or receive electromagnetic waves that 
converts electromagnetic waves into electrical 
current and vice versa in the process of 
transmission and reception[1][2]. Physically, an 
antenna is an arrangement of conductors that 
generate a radiating electromagnetic field in 
response to an applied alternating voltage and the 
associated alternating electric current, or can be 
placed in an electromagnetic field so that the field 
will induce an alternating current in the antenna and 
a voltage between its terminals. All antennas radiate 
some energy in all directions in free space but 
careful construction results in substantial 
transmission of energy in a preferred direction and 
negligible energy radiated in other directions. By 
adding additional elements and carefully arranging 
their length, spacing and orientation, an antenna 
with desired directional properties can be 
created[2][11]. Several critical parameters affect an 
antenna's performance that can be adjusted during 
the design process. These are resonant frequency, 
impedance, gain, aperture or radiation pattern, 
polarization, efficiency and bandwidth. Transmit 
antennas may also have a maximum power rating, 
and receive antennas differ in their noise rejection 
properties. All of these parameters can be measured 
through various means. In this paper we tried to 
present a new scheme to improve the effectiveness 
and performance of the antenna by improving the 
directivity and reducing side lobes. Directivity is 
the measure of the power density in the direction of 
its strongest emission, related to the power density 
radiated by an ideal isotropic radiator antenna 
radiating the same amount of total power and side 
lobe is the pattern distortion of the signal during 
beam steering. If the directivity is improved and the 
side lobes are reduced than desired transmission 
Page 937ISBN: 978-984-33-2140-4
  
and reception can be achieved. This paper shows 
how directivity can be improved and a pattern 
synthesis method has developed to reduce side 
lobes. 
 
2. DIRECTIVITY AND GAIN 
 
In electromagnetic, directivity is a figure of merit 
for an antenna[8] . It measures the power density an 
actual antenna radiates in the direction of its 
strongest emission, relative to the power density 
radiated by an ideal isotropic radiator antenna 
radiating the same amount of total power. 
Mathematically, the directivity is defined as the 
maximum of the directive gain[10]: 
 






=
pi
ϕθ
4/
),(
max
powerradiatedTotal
densitypowerRadiated
D  equn (1) 
where 
• θ and φ are the standard spherical coordinates  
angles 
• Radiated power density is the power per unit 
solid angle such that  
• Radiated power density = 
ϕθθθϕpiϕϕ
piθ
θ dddensitypowerRadiated∫ ∫
=
=
=
=





2
0 0
sin),(  
• 4pi is the total solid angle for a sphere (also the 
surface area of a unit sphere, similar to 2pi being 
the total angle for a circle and the perimeter of a 
unit circle). 
• The denominator, Total radiated power/4pi, 
represents the average radiated power density 
 
The directivity is rarely expressed as a unitless 
number. Usually, the directivity is expressed in dBi 
, so that 














=
pi
ϕθ
4/
),(
maxlog10 10 powerradiatedTotal
densitypowerRadiated
Ddbi                           
                                                                      equn (2) 
 
The reason the units are dBi (decibel relative to an 
isotropic radiator) is that for an isotropic radiator, 
the radiated power density is a constant, and 
therefore equals the average radiated power density 
(the denominator). This isotropic radiator is not 
directive at all but has nevertheless a directivity 
strict sensor equal to 1[9][10]. This can be misleading 
and is much better described in dBi. 
 
       dbunitlessD adiatorisotropicr 01 ==        equ
n
 (3) 
 
The word directivity is also sometimes used as a 
synonym for directive gain. This usage is readily 
understood, as the direction will be specified, or 
directional dependence implied. Later editions of 
the IEEE Dictionary specifically endorse this usage; 
nevertheless it has yet to be universally adopted. 
The peak directivity of an actual antenna can vary 
from 1.76 dB for a short dipole, to as much as 50 
dB for a large dish antenna[3]. 
 
Again gain as a parameter measures the 
directionality of a given antenna[9]. An antenna with 
a low gain emits radiation in all directions equally, 
whereas a high-gain antenna will preferentially 
radiate in particular directions. Specifically, the 
Gain, Directive gain or Power gain of an antenna is 
defined as the ratio of the intensity (power per unit 
surface) radiated by the antenna in a given direction 
at an arbitrary distance divided by the intensity 
radiated at the same distance by a hypothetical 
isotropic antenna. 
                      
isosp
antspG )/(
)/(
=    equn (4) 
 
3. PATTERN OPTIMIZATION 
 
In the field of antenna pattern synthesis, the side-
lobe level of an array radiation pattern can be 
reduced by appropriately changing inter-element 
spacing, namely, by applying a non-uniformly 
spaced array[4][5][6] and directivity can be improved 
by shielding. The desired low side-lobe level can be 
achieved by optimizing the amplitudes and phases 
of excited array elements with uniform spacing. 
However, this method degrades total radiation 
power efficiency due to amplitude tapering. The 
non-uniform linear array can reduce inner side-
lobes, whereas it may increase outer side-lobe 
levels[4]. To overcome this problem, an 
optimization technique is adopted to reduce both 
the inner side-lobes and the unwanted outer side-
lobes simultaneously. In this pattern synthesis 
method both the inner side-lobes and the outer side-
lobes are reduced to a sustainable level and at the 
same time directivity of the antenna also degrades. 
To overcome this problem and to improve the 
directivity best dipole setup and a shielding 
mechanism are also developed in this work. The 
research procedure of the optimal gain and reduced 
side lobes of a linear dipole antenna are described 
in three steps as follows,  
Step 1: Best dipole arrangement by varying the 
elevation angles above the horizon and adjusting 
feed point impedance.  
Step 2: Optimization technique is applied to 
achieve the low outer side-lobe levels as well as 
low inner side-lobe levels.  
Step 3: Shielding mechanism (reducing surface 
resistance). 
 
4. DIPOLE SETUP AT AN EXACT   
    ELEVATION 
 
Generally a linear dipole antenna in free space 
exhibits a feed impedance of 72 Ω and has a 
Page 938
  
doughnut shaped radiation pattern. But, as the 
dipole is brought close to the earth, the radiation 
pattern changes and the feed point impedance also 
changes. Careful selection of position and setting 
up a dipole above the ground can make its 
impedance exactly match the impedance of the feed 
line used that help to improve the directivity of the 
antenna. In this part we have developed a better 
possible setup of wavelengths above a standard 
earth ground model through which significant 
amount of side lobes are reduced and a directed 
vertical lobe is gained. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
All the figures showing a sequence to the patterns 
and that is if the antenna get lower, the lobes move 
higher, combine and disappear. The energy being 
directed at the horizon, the peak of the pattern is 
elevated at about a 30o angle (actually 28o). Thus, 
for a quite broad range of elevation angles and for a 
correspondingly broad expanse of geographical 
area covered by the signal reflected off the 
ionosphere, there is substantial signal strength. If 
lowering the dipole continues, familiar raising and 
combining of the lobes will continue until at 0.25 
wavelengths and will produce a single broad peak, 
aimed straight up. Moreover, below a certain 
critical frequency (which depends on the density of 
the ionization in the ionosphere), a signal directed 
straight upward will be reflected back down into an 
area near the transmitter. This can allow 
communications within a 100-200 mile radius of 
the transmitter – the area normally skipped over by 
signals transmitted from the dipole at lower 
radiation angles (generated by higher positions 
above ground). Fig. 5 shows that this pattern has 
both the low-angle lobes and a broad vertical lobe. 
The vertical lobe is about 2 dB below the low-angle 
lobes and has an almost insignificant difference in 
signal strength. This section shows that dipole at 
0.75 wavelength height over ground is the best of 
all possible setups and this setup has been selected 
for the next procedure of this research. 
 
5. LINEAR ANTENNA PATTERN  
    SYNTHESIS 
 
This section presents a pattern synthesis method of 
non-uniform linear antennas for simultaneous 
reduction of the side-lobe level and pattern 
distortion during beam steering. To achieve these 
two requirements, the positions of linear array 
elements are adjusted using the Gauss–Newton 
method. It is shown that the proposed method can 
significantly reduce pattern distortion as well as the 
side lobe level of a linear dipole antenna. 
 
For an odd number of elements, if isotropic array 
elements are uniformly distributed along the x axis 
and are assumed to be symmetric about the array 
 
Fig. 5: Dipole at 0.75 wavelength elevation. 
 
Fig. 1: Dipole at 1.75 wavelengths elevation.  
 
 
Fig. 2: Dipole at 1.5 wavelengths elevation. 
 
 
Fig. 3: Dipole at 1.25 wavelengths elevation. 
 
 
Fig. 4: Dipole at 1.0 wavelength elevation. 
 
Page 939
  
center, the radiation field pattern over the set of 
angles θ1, θ2, θ3… θL can be described as follows: 
N
M
n
oikdxN
N
n
oijkdxNip
1
1
)]sin(sincos[2
1
0
)]sin(sinexp[1)(
+∑
=
−=
∑
−
=
−=
θθ
θθθ
        
                                                                    equn (5)  
 
where N is the number of element antennas, k is 
free space propagation constant, dx is the inter-
element spacing, θo is the maximum radiation 
angle, and M is given by (N -1)/ 2. 
 
Then, the normalized pattern of the non-uniform 
linear antenna is given by 
N
dxenk
N
p
M
n
oininu
1)]sin(sin)(cos[2)(
1
+−+= ∑
=
θθθ  
                                                                     equn (6) 
      
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Thus the procedure for the pattern synthesis of the 
NULA using the proposed algorithm is summarized 
as follows. 
duunSupupnNe anuo
o
n )())()(( ⋅−= ∫
pi
pi
       equn (7) 
                              n = 1, 2, 3, ……. M.  
Where )(
)sin()(
un
un
unSa
⋅
⋅
=⋅
 
Iterate the following relative error (RE) , 
γθθ <−= ∑
=
+
2
1
1 )()(
2
1 L
i
i
k
nui
k
nu ppN
RE      equn (8) 
Fig. 6 shows the comparison of array pattern shape 
of a 13-element uniform linear antenna (ULA) of 
isotropic elements spaced every half-wavelength 
with the non-uniform linear antenna (NULA) on the 
basis of Fourier-transform. In comparison with the 
ULA, an amount of about 5-dB reduction of the 
first side-lobe level is achieved with the NULA. 
However, when the main beam of NULA is steered 
to 30°, some large outer side-lobes higher than the 
first side-lobe are observed within the visible 
region, as shown in Fig. 7. Furthermore, their levels 
in the vicinity of an angle of - 60° are also higher 
than the first side-lobe level of the ULA. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
In order to reduce the undesirable side-lobe levels 
above, we now apply the algorithm to pattern 
synthesis of the NULA with beam steering. For the 
pattern synthesis algorithm, we have set the 
iteration gain to )
40
9exp(5.1 k⋅−=η , the maximum 
allowable error,  γ to 10-4 and 2δ  to 0.001 
respectively. The resulting radiation pattern is 
shown in Fig. 8.  
 
•  Case 1 :   NULA pattern via the formula on 
the basis of the Fourier transform method. 
•  Case 2 :   NULA pattern via the proposed 
Gauss–Newton method.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
As shown in fig. 8, the proposed algorithm causes 
the undesirable large side-lobes near -60° to be 
significantly reduced to smaller levels than the first 
side-lobe level of Case 1. 
 
Fig. 6: Radiation pattern of non-uniform linear 
antenna using the Fourier-transform-based formula; 
the maximum radiation angle is 0° 
 
Fig. 8: Improvement of the non-uniform radiation 
pattern in Fig. 7 using the optimization method 
 Fig. 7: Comparison of the two radiation patterns with 
uniform or non-uniform spacing when the maximum 
radiation angle is steered to 30° 
Page 940
  
Again we have considered an equally excited 15-
elements and 17-elements linear array with the 
same uniform spacing and scanning angle, as in the 
previous one. Using the pattern synthesis algorithm, 
the optimized positions of the NULA are given in 
Table 1.  
 
Table 1:   Position of the optimized non-uniform 
antenna elements 
 
 
 
 
 
 
 
 
 
 
6. COVER SHIELDING TO 
INCREASE ANTENNA DIRECTIVITY 
 
Very thin conducting layer has a much higher 
resistivity than a bulk layer because of electron 
scattering from the layer surface. If the layer 
thickness is very large compared to the electron 
mean-free-path, the resistivity is expected to be 
nearly the same as that of a bulk conducting 
material. In the far field, high attenuation occurs in 
a structure made of material having high 
conductivity and low permeability. In this paper, 
we have used the intrinsic properties of a two-
dimensional copper lattice material to design a 
cover antenna so that an optimal amount of 
radiation is attenuated by the antenna and to 
achieve this we have matched a lower resistance of 
the antenna surface. Mathematically, 
 
      
tw
l
widththickness
lengthyresistivitspecificR ρ=
×
×
=      equn (9) 
When the length and width are chosen to have 
equal magnitude then the equation becomes, 
        square
tt
R
f
f
S /
1 Ω==
σ
ρ
    equn (10) 
where ρ is the resistivity, t is the thickness of the 
cover shield, fσ is the conductivity of the shielding 
material and can be denoted as,   






+= 4228.0)ln(
4
3
t
p
p
t
f
σ
σ    for t << P     equn (11) 
Where σ is the conductivity of the bulk material 
and P is the electron mean-free-path. 
 
Hence the attenuation becomes, 
Attenuation = Absorption loss (A) + Reflection loss   
                      (R) + Correction term (C)    equn (12) 
Absorption loss: 
 
eteA t 1010 log)(20log20 αα ==  
    ffet µσpilog20=               equn (13) 
 
Reflection loss: 
 
dBf
R
f
sa
a
fs
s
fa
f
)log(1029
222
log20
µ
σ
ηη
η
ηη
η
ηη
η
+=








+
×
+
×
+
−=
        
                                                   equn (14) 
where fη  = intrinsic impedance of the copper 
sη  = intrinsic impedance of the antenna material 
aη  = intrinsic impedance of the free space 
      
Correction term: 
 










−−=
−
)sin(cos101log20 10 θθρ jC
A
 
    [ ]fft µσlog2011 +=      equn (15) 
 
So the Eq. (12) becomes as follows,  
Attenuation, 
[ ]fff ftffetA µσµσµσpi log2011log1029log20 ++





++=  
                         sRlog2040 −=             equ
n
 (16) 
 
This leads to the gain of the copper shielded dipole 
antenna,  
 
               
SS
antf RAR
S
P
G 120=






=        equn (17) 
 
 
 
 
 
 
 
 
 
 
 
 
The actual value of the linear dipole resistance is 
about 73.1296 Ω and in most cases the gain of a 
dipole antenna is 2.15 dBi. By using the copper 
shield (thick layer) the surface resistance can be 
Element Non-uniform pattern 
Uniform 
pattern 
13 1.182 λ 2.0 λ 
15 2.941 λ 3.0 λ 
17 4.066 λ 4.0 λ 
 
Fig. 9: Comparison of the directivity of the (i) antenna 
without shielding (ii) antenna with a 2-D copper 
shielding. The cover has increased the directivity from 8 
to 12.5 dB 
 
Page 941
  
reduced up to 10 Ω that results a gain of 10.80 dBi. 
The fig. 9 shows the comparison of the directivity 
between the general dipole antenna and copper 
shielded dipole antenna (proposed model). 
 
7. CONCLUSION 
 
For antennas used as receivers, side lobes make the 
antenna more vulnerable to noise from nuisance 
signals coming far away from the transmit source 
and transmit antennas communicating classified 
information, side lobes represent security 
vulnerability, as an unintended receiver may pick 
up the classified communication. For these reasons 
reduced side lobes and improved directive gain are 
essential for efficient data transmission and 
reception. In this research we tried to pick up the 
best positioning of the antenna’s placement for 
getting effective function. At the same time we 
have used a pattern synthesis method and at last we 
have used shielding mechanism over the reference 
model and finally we have got a maximum gain of 
8 – 12.5 db which is an improved model upon the 
previous existing models. In the shielding 
mechanism we have used copper material (thick 
layer) due to some limitations. If anyone uses better 
material other than copper, he/she may get better 
performance. Our next research leads to the three 
dimensional thick layer (better than copper) 
shielding over the proposed model.  
 
REFERENCES 
 
1. C. Balanis, Wiley, Antenna Theory, 3rd edition, 
2005, ISBN 0-471-66782-X. 
2. W. Stutzman and G. Thiele, Wiley, Antenna 
Theory and Design, 2nd edition, 1997, ISBN 0-
471-02590-9. 
3. Institute of Electrical and Electronics 
Engineers, “The IEEE standard dictionary of 
electrical and electronics terms”; 6th ed. New 
York, N.Y., Institute of Electrical and 
Electronics Engineers, c1997. IEEE Std 100-
1996. ISBN 1-55937-833-6. 
4. R.F. Harrington, Side lobe reduction by non-
uniform element spacing, IRE Trans Antennas 
Propagat (1961), 187–192.  
5. F. Hodjat and S.A. Hovanessian, Non-
uniformly spaced linear and planar array 
antennas for side lobe reduction, IEEE Trans 
Antennas Propagate AP-26 (1978), 198–204. 
6. R.E. Wiley, Space tapering of linear and planar 
arrays, IRE Trans Antennas Propagate (1962), 
369–377. 
7. Van Valkenburg, M. E. Network Analysis, 3rd 
edition, pp. 383-384, ISBN 0-13-611095-9. 
8. Hecht, Eugene Optics, 4th edition, 2001, 
Pearson Education, ISBN 0-8053-8566-5. 
9. A. Raymond, Serway, Jewett and W. John, 
Physics for Scientists and Engineers, 6th 
edition, 2004, ISBN 0-534-40842-7. 
10. W. H. Freeman, Tipler and Paul, Physics for 
Scientists and Engineers: Electricity, 
Magnetism, Light and Elementary Modern 
Physics, 5th edition, 2004, ISBN 0-7167-0810-
8. 
11. J. Kraus and R. Marhefka, McGraw Hill 
Antennas, 3rd edition, 2001, ISBN 0-072-
32103-2. 
 
Page 942
Proceeding of the  
Conferences on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
 
 
*Corresponding Author: Md. Alomgir Hossain  
E-mail: jibon_04@yahoo.com   
 
A Review of the Numerical Solutions of Dimensionless Radial Flow 
Diffusivity Equation Using Laplace Transforms 
Md. Alomgir Hossain* and Md. Jakaria 
Department of Petroleum and Georesources Engineering, Shahjalal University of Science and 
Technology, Sylhet-3114, Bangladesh  
Solutions of the radial flow diffusivity equation are essential in computation of fluid flow through porous 
media. Based on Darcy’s law, this paper re-produced an unsteady state flow equation and a set of data is 
generated through the solution of the equation for unsteady state flow of slightly compressible fluid డ
మ௉ವ
డ௥ವమ
+
ଵ
௥ವ
డ௉ವ
డ௥ವ
= డ௉ವ
డ௧ವ
  two sets of solutions of this equation are redeveloped for the constant terminal pressure case 
and the constant terminal rate case. Here the diffusivity equation is re-produced based on some assumptions 
and its solutions for both cases according to A.F. Van Everdingen and W. Hurst solutions. Most of the 
information is obtained with the help of the Laplace transformations, complex inversion formula, modified 
Bessel function which proved to be extremely helpful for analyzing the problem encountered in fluid flow. 
With the help of Laplace transformations, some original developments were obtained which could not have 
been easily foreseen by the earlier methods. Some curves are developed from this solution and the 
dimensionless values are reproduced from the curve. The final solution of diffusivity equation is handy for 
water influx calculation which is essential for reservoir simulation and well test analysis.   
 
Keywords: Darcy’s law, Diffusivity equation, Laplace transforms, Dimensionless numbers, Water influx 
1. INTRODUCTION: 
Fluid flow through porous media covers an 
important part in Petroleum Engineering. This 
phenomenon is based on diffusivity equation 
which is a highly nonlinear partial differential 
equation. Nonlinearity of this equation arises due 
to pressure dependency of fluids properties. 
Generally this equation is formulated for slightly 
compressibility fluids for fluid flow calculation. 
On the other hand from the operating point of 
view this equation is solved for constant terminal 
rate and constant pressure cases.  
This paper represents the review of numerical 
solution of the dimensionless radial flow 
diffusivity equation from Darcy’s law and 
numerical calculation of the unsteady state flow 
which is used to calculate the fluid flow through 
porous media generally water influx modal. The 
study is limited to conditions where the flow of 
fluid obeys the diffusivity equation. Multi-phase 
fluid flow has not been considered. This paper 
exposes the sequential description of some steps.  
At first there is a discussion of Darcy’s law, then 
diffusivity equation for slightly compressible 
fluid, dimensionless analysis of the diffusivity 
equation, solution of the diffusivity equation 
using Laplace transformation, numerical value of 
the dimensionless diffusivity equation and the 
representation of curve which is used to 
reproduce the dimensionless water influx value 
and used to calculate water influx model which is 
essential for reservoir simulation and wall test 
analysis.   
This approach is useful academically, for it is 
relatively easy to do, and it also is useful to give 
insight into the nature of aquifer flow. For these 
reasons it will be discussed here in some detail. 
Unfortunately, it is "not" very useful for real 
reservoir problems, for typically we cannot define 
the inner boundary condition for the oil 
reservoir/aquifer system in any meaningful way. 
This work is applicable to the flow of fluids to a 
well whenever the flow conditions are such the 
diffusivity equation is obeyed. 
Page 943
ISBN: 978-984-33-2140-4
  
2. OBJECTIVES OF THIS STUDY:  
 Reproduces the dimensionless water influx 
value and dimensionless pressure value. 
 Understanding the Bessel function term which 
is used into the solution of the radial flow 
diffusivity equation.  
 Clearly understanding reservoir estimation 
model. 
 Easily calculation nonsteady state flow 
equations. 
3. PROCEDURE: 
Some basic terms are used to solve the 
dimensionless radial flow diffusivity equation 
and some assumptions are considered to calculate 
the dimensionless water influx value and 
dimensionless pressure value. This basic terms 
definition and assumptions are given below  
3.1Definitions of the Various Terms: 
3.1.1 Boundary condition: The location of the 
interior and exterior boundaries and the 
specification of pressure and/or flow at these 
boundaries at a given instant of time. 
3.1.2 Boundary variation: The changes in the 
boundary conditions of a reservoir system 
undergoing exploitation. 
3.1.3 Continuous succession of steady state: A 
method of solving flow problems in a reservoir 
system that suffers boundary variations but 
fulfills instantaneous steady state conditions. The 
history of such a system is divided into an 
appropriate number of stages, each of which is 
treated by steady state analysis.   
3.1.4 Darcy’s law: The Darcy’ law which is 
defined by the following relation 
ܳ = ݇ܣ(ℎଵ −ℎଶ)
ܮ
 
3.1.5 Dimensionless pressure: The 
dimensionless pressure ratio defined by the 
following relation 
݌஽ = 0.007082݇ℎ(݌௜ −ߤܤݍ(݌  
3.1.6 Dimensionless radius: The dimensionless 
radius ratio defined by the following relation 
ݎ஽ = ௥௥ೢ  
3.1.7 Dimensionless time: The dimensionless 
time ratio defined by the following relation 
ݐ஽ = 0.0002637݇ܿߤ∅ݐ௧ݎ௪ଶ  
3.1.8 Fluid influx terms: Terms that appears in 
the Hurst Van Everdingen equation which treats 
the pressure case. Such a term, denoted by qD(tD), 
is a dimensionless , numerical quantity 
representing the total volume of fluid per unit 
thickness that passes the interior boundary of a 
reservoir system over the time span t=tM-ti, which 
is caused by a unit pressure drop at this boundary 
at time t. 
3.1.9 Infinite reservoir system: A reservoir 
system analyzed over a period of time during 
which the presence of an exterior boundary is not 
felt.  
3.1.10 Non steady state flow: In reservoir 
systems undergoing exploitation, fluid flow that 
is characterized predominates by time variations 
and necessitates the formal introduction of time 
as an explicit variable in the basic flow equation.  
3.1.11 Pressure case: In the analysis of a 
reservoir system the situation that presumes 
knowledge of the pressure history and predicts 
the cumulative fluid influx. 
3.1.12 Radial reservoir system: A system 
defined by two concentric circular cylinders, 
which serve as boundaries, over which pressure 
and flow are specified according to prescribed 
conditions and whose physical propertied of 
interest vary only with the distance r from the 
axis of symmetry.  
3.1.13 Rate case: In the analysis of a reservoir 
system the situation that presumes knowledge of 
the production or fluid-influx rate history and 
predicts the cumulative pressure drop for a 
reservoir at its interior boundary. 
3.2 Assumption: 
Page 944
  Uniform pressure pi throughout the reservoir 
before production. 
 Constant rate production q from a single well 
of a radius rw centered in a cylindrical 
reservoir. 
 No flow across the reservoir outer boundary 
at reservoir re. 
 Homogeneous and isotropic porous medium 
of uniform thickness. 
 Pressure independent rock and fluid 
properties. 
 Small pressure gradients. 
 Radial flow. 
 All flow through reservoir systems is 
assumed macroscopically laminar and thus 
governed by Darcy’s law. 
 The effects of gravity on the fluid flow are 
neglected totally 
3.3 Darcy’s Law: 
 It is believed Petroleum Engineering starts from 
Darcy’s law. So, Darcy’s is a hallowed name in 
this discipline. Darcy’s law is a relationship that 
explains fluid flow in porous media, such as often 
seen in geological formulations. According to 
Darcy’s law, fluid velocity or flow rate is directly 
proportional to the hydraulic conductivity, 
inversely proportional to the length of the flow 
path, directly proportional to the energy loss in 
terms of head loss. Which is state that  
 
 
 
 
 
 
 
 
Figure 01: Show the vertical cross section of 
groundwater flow with linear parallel stream line.  
 
Darcy’s law is a relationship that explains fluid 
flow in porous media, such as often seen in 
geological formulations. The basic formula to 
calculate the flow rate Q is 
 
A is the cross sectional area. Finally, Darcy’s law 
provides the concept of absolute permeability 
which is a rock property and driving force 
(gradient of fluid potential or pressure gradient) 
essential to move fluid from one place to another. 
3.4 Basic Theory of the Diffusivity 
Equation: 
3.4.1 Diffusivity equation for flow of slightly 
compressible fluids:  
Considering this Figure  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 02: Control volume radial coordinate 
system. 
-(ρ 
ur
) 
h 
r+
Ѳ 
r 
Δ
Ѳ 
 
 
1 
2 
L
h
z
h
z
Page 945
  
We assume that this element is a porous media 
fixed in space and that flow is radial in the –r 
direction. Assuming that the net generation of 
matter is zero. We can write a mass balance on 
the element as  
௜ܹ௡ − ௢ܹ௨௧ = ݍ௠                                        (3.4.1.1) 
We solve this equation according to the Fig.02, 
we get    
 ଵ
௥
ቀ
డ(௥ఘ௨ೝ)
డ௥
ቁ = −ቂడ(ఘ∅)
డ௧
 ቃ                               (3.4.1.2) 
This equation is called the continuity equation. 
An equation of motion or flux law relates 
velocity and pressure gradient within the control 
volume. Liquid flow generally is modeled by 
Darcy’s law, which state that velocity is 
proportional to the negative of the gradient of the 
potential. 
In radial co-ordinates, with flow in the radial 
direction only  
 ݑ௥ = −0.0002637 ௞ఘఓ డ∅డ௥                             (3.4.1.3) 
Total compressibility of the rock and fluid 
ܿ௧ = ܿ + ௙ܿ                                                   (3.4.1.4) 
Combination the above equation we can solved  
∂ଶp
∂rଶ  + 1r ∂p∂r = ∅ܿߤ௧0.0002637݇ ∂p∂t                (3.4.1.5) 
This equation is called the diffusivity equation for 
liquid flow. The term       ଴.଴଴଴ଶ଺ଷ଻௞
∅ఓ௖೟
       is called 
the hydrolic diffusivity.  
3.4.2 Dimensionless form of the diffusivity 
equation: 
From the diffusivity equation and considering 
some boundary condition, the diffusivity equation 
is converted to dimensionless diffusivity equation 
for solving any fluids flow in the porous media.   
The initial condition is 
ݎ)݌, ݐ = 0) = 0                                          (3.4.2.1) 
The inner boundary condition (constant rate 
production) r=rw, t>0 is  
ݍ = 0.007082݇ℎ
ߤܤ
 ൬ݎ ߲݌
߲ݎ
൰
௥ୀ௥ೢ                   (3.4.2.2) 
 The outer boundary condition, r=re ,t>0; is 
q=0, 
൬
߲݌
߲ݎ
൰
௥ୀ௥௪
= 0                                              (3.4.2.3) 
Using the dimensionless terms i.e. dimensionless 
radius, dimensionless time, dimensionless 
pressure ratio, we can get the dimensionless form 
of the diffusivity equation 
డమ௣ವ
డ௥ವమ
 + ଵ
௥ವ
డ௣ವ
డ௥ವ
= డ௣ವ
డ௧ವ
                                 (3.4.2.4)
  
And the initial condition is  
݌஽൫ݎ஽ ,ݐ஽ = 0൯ = 0                                   (3.4.2.5) 
The inner boundary and outer boundary 
conditions are 
൬
߲݌஽
߲ݎ஽
൰
௥ವୀଵ
= −1                                        (3.4.2.6) 
And  
൬
߲݌஽
߲ݎ஽
൰
௥ವୀ௥೐ವ
= 0                                       (3.4.2.7) 
 Respectively.    
3.4.3 Laplace transforms formulation:  
Dimensionless diffusivity equation is the second 
order partial differential equation so this equation 
is easily calculated by the Laplace transforms for 
two independent variables (dimensionless radius 
and dimensionless time).  
Taking the Laplace transform of Eq. (3.4.2.4) 
gives, 1
ݎ஽
߲
߲ݎ஽
ቆݎ஽
߲݌஽
߲ݎ஽
ቇ = ݌ݏ஽ −݌஽(ݐ஽ = 0)   (3.4.3.1) 
[ʆ ቄడ௣ವ
డ௥ವ
ቅ = డ௣ವ
డ௥ವ
  and    ʆ ቄడ௣ವ
డ௧ವ
ቅ = ݌ݏ஽ −
݌஽(ݐ஽ = 0)] 
Page 946
  
At initial condition, 
or, ݌஽(ݐ஽ = 0) = 0                                    (3.4.3.2) 
So the Eq. (3.4.3.1) is 1
ݎ஽
߲
߲ݎ஽
ቆݎ஽
߲݌஽
߲ݎ஽
ቇ = ݌ݏ஽                          (3.4.3.3) 
Taking the Laplace transform of the inner 
boundary condition gives 
ቆ
߲݌஽
߲ݎ஽
ቇ
௥ವୀଵ
= − 1
ݏ
                                   (3.4.3.4) 
Taking the Laplace transform of the outer 
boundary condition gives 
݌஽(ݎ஽ → 0, ݏ) = 0                                    (3.4.3.5) 
Multiply  rୈଶ by both sides 1
ݎ஽
rୈଶ ߲߲ݎ஽ ቆݎ஽ ߲݌஽߲ݎ஽ ቇ = ݏrୈଶ݌஽ 
or,  ݎ஽  డడ௥ವ ቀݎ஽ డ௣ವడ௥ವቁ = ݏrୈଶ݌஽              (3.4.3.6) 
We define a variable of substitution, z, as 
ݖ = √ݎݏ஽    or,     ݎ஽ = ୸√ୱ  ; డ௭డ௥ವ = √ݏ 
Put the substituted value into the upper equation z
√s  ߲߲ݖ ߲ݎ߲ݖ஽ ቆ z√s߲݌஽߲ݖ ߲ݎ߲ݖ஽ቇ = ݖଶ݌஽ 
or, z డ
డ௭
ቀz డ௣ವ
డ௭
 ቁ = ݖଶ݌஽  
or, ݖଶ డ
మ௣ವ
డ௥ವమ
 + ݖ డ௣ವ
డ௥ವ
= ݖଶ డ௣ವ
డ௧ವ
                    (3.4.3.7) 
The general equation of the Bessel function is 
ݖଶ
߲ଶݕ
߲ݖଶ
 + ݖ ߲ݕ
߲ݖ
= (ݖଶ + ݒଶ)3.4.3.8)             ݕ) 
The general solution of Eq. (3.4.3.8) is given by 
ݕ = ܫܣ௩(ݖ) + ݇ܤ௩(ݖ)  
Where  ܫ௩  and  ݇௩  are the modified Bessel 
function of the first & second kinds, respectively, 
there “v” is the order & “z” is the argument. 
Compare the Eq. (3.4.3.7) & (3.4.3.8), let v=0; 
݌஽(ݖ) = ܫܣ଴(ݖ) + ݇ܤ଴(3.4.3.9)                        (ݖ) 
3.4.4 Constant terminal rate case: 
The boundary conditions for the constant rate 
case in an infinite medium are that (1) the 
pressure drop ݌஽൫ݎ஽ ,ݐ஽ = 0൯ = 0  initially at 
every point in the formation (2) at the radius of 
the field ݎ஽ = 1 we have ቀడ௣ವడ௥ವቁ௥ವୀଵ = −1 
The general solution of Eq.(3.4.3.9) is given by  
݌஽(ݎ஽ , ݏ) = ܫܣ଴൫√ݎ ݏ஽൯ + ݇ܤ଴൫√ݎݏ஽൯    (3.4.4.1) 
Now considering the boundary condition we can 
determine the constant value of A and B and put 
this value into equation we can get  
 ݌஽(ݎ஽ , ݏ) = ௞బ൫√௦௥ವ൯௦√௦ ௞భ൫√௦ ൯                               (3.4.4.2) 
The term  ௞బ൫√௦௥ವ൯
௦√௦ ௞భ൫√௦ ൯    cannot be inverted directly, 
now the residue methods are applied from 
complex variable. 
3.4.5 The complex inversion formula: 
Complex inversion formula is used for transfer 
general Bessel function from modified Bessel 
function.  
݌஽(ݏ) = ʆ{݌஽(tୈ)} , then ʆିଵ{݌஽(s)} is given by  
݌஽(ݐ஽) = 12݅ߨ න ݁௦௧݌஽(ݏ݀(ݏ ఊା௜∝ఊି௜∝         (3.4.5.1) 
This result is called the complex inversion 
integral or formula is also known as Bromwich’s 
integral formula. The result provides a direct 
means for obtaining the inverse Laplace 
transform of a given function P(s). 
The integration in Eq.(3.4.5.1) is to be performed 
along a line ݏ = ã   in the complex plane where 
S=x+iy. The real number ã  is chosen so that S= ã   
lines to the right of all the singularities. To 
develop the explicit solution for the constant 
terminal rate case, it is necessary to invert the 
Laplace transforms equation (3.4.4.2) by the 
complex inversion formula. The path of 
integration for this transform is described by the 
cut along the negative real axis Fig.03 which 
Page 947
 gives the single value function on each side of the 
cut. 
 
              
 
 
 
 
 
 
Figure-03: Contour integration in establishing 
the constant terminal rate case for infinite extent. 
That is to say that path AB which is equal to the 
path AD & CB both of which are described by a 
semi-circle of radius infinity. Since its integration 
is zero in the second & third quadrant, this leaves 
the integration along path DO & OC equal to AB. 
Modification of both Bromwich’s contour in case 
of Branch point 
 
Where   is the transform , where this 
report is concerned with pressure drops, the 
above can be written as  
 
The integration on the upper portion of the cut 
can be obtained by making  , which 
yields equation ( ) 
 
 
Modified Bessel functions of the first and second 
kind of arguments      can be expressed by 
the regular Bessel functions as complex values as 
follows 
 
Where, the imaginary term has been dropped. 
Likewise, the integration along the under portion 
of the negative real “cut” is expressed by 
 and  
 
The integration along paths DO & OC is the sum 
of the relation Eq.( ) & Eq.( ) 
 
Initially that is at time zero       
at Eq.( ) 
 
This is the explicit solution of constant terminal 
rate for an infinite medium. 
To determined the cumulative pressure drop for a 
unit rate of production at the wellbore or field 
radius        The Eq. (3.4.5.8) changes to 
 
For regular Bessel function  
 
 
A 
B 
y 
C 
D 
r
,
0 
z 
Page 948
  
ܬ଴(ݑ) ଵܻ(ݑ)− ଴ܻ(ܬ(ݑଵ(ݑ) = − 2ݑߨ 
So the Eq. (3.4.5.9) is changed to 
݌஽(ݐ஽) = 4ߨଶ න (1− ݁ି௨మ௧ವ) ݀ݑݑଷ(ܬଵଶ(ݑ) + ଵܻଶ(ݑ))∝଴    (3.4.5.10) 
3.4.6 Constant terminal pressure case:  
As already shown, the transform of the pressure 
drop in an infinite medium  
݌஽(ݏ) = ݇ܤ଴൫√ݏ൯  Or, ܤ = ଵ௦௞బ൫√௦൯ 
݌஽(ݎ஽ , ݏ) = ݇଴൫√ݎݏ஽൯݇ݏ଴൫√ݏ൯                            (3.4.6.1) 
Considering Fig.03, we can get the path line 
pressure drop 
݌஽(ݎ஽ , ݐ஽ଵ)− ݌஽(ݎ஽ , ݐ஽ଶ)= 2
ߨ
 න (݁ି௨మ௧ವభ − ݁ି௨మ௧ವమ)(ܬ଴(ݎݑ஽) ଴ܻ(ݑ) − ଴ܻ(ݎݑ஽)ܬ଴(ݑݑ݀ ((ݑଶ൫ܬ଴ଶ(ݑ) + ଴ܻଶ(ݑ)൯                            (3.4.6.2)∝଴  
If we are interested in the cumulative fluid influx 
at the field radius   ݎ஽ = 1 , then the relationship 
is  
ܳ஽(ݐ஽) = න (߲݌஽߲ݎ஽ )௥ವୀଵ௧ವ଴ ߲ݐ஽                   (3.4.6.3) 
The determination of the transform of the 
gradient of the pressure drop at the field’s edge is 
as follows— 
ቆ
߲݌஽(ݏ, ݎ஽)
߲ݎ஽
ቇ
௥ವୀଵ
= − ݇ଵ(√ݏ)
√݇ݏ଴൫√ݏ൯
        (3.4.6.4) 
Since the pressure drop  ݌஽(ݎ஽ , tୈ)   corresponds 
to the difference between the initial & actual 
pressure is given by 
ቆ
߲݌஽
߲ݎ஽
ቇ
௥ವୀଵ
= −ቆ߲݌஽(ݏ, ݎ஽)
߲ݎ஽
ቇ
௥ವୀଵ
 
or, ቀ
డ௣ವ
డ௥ವ
ቁ
௥ವୀଵ
= ௞భ(√௦)
√௦௞బ൫√௦൯
                          (3.4.6.5) 
Taking the Laplace transforms in Eq.(3.4.6.3) 
ʆ{ܳ஽(ݐ஽)} = ʆ{න (߲݌஽߲ݎ஽ )௥ವୀଵ௧ವ଴ ߲ݐ஽} 
or, ܳ஽(ݏ) = ቀడ௣ವడ௥ವቁ௥.ୀଵ ଵ௦  
or. ܳ஽(ݏ) = ௞భ(√௦)√௦௞బ൫√௦൯ ଵ௦                                (3.4.6.7) 
The application of the Mellin’s inversion formula 
the above equation follows the path  
ܳ஽(ݐ஽) = 4ߨଶන (1 − ݁ି௨మ௧ವ) ݀ݑݑଷ(ܬ௢ଶ(ݑ) + ௢ܻଶ(3.4.6.8)     ((ݑ)∝଴  
4. COMPUTATION OF  ࡰ࢚)ࡰࡽ) AND 
ࡰ࢚)ࡰࡼ) 
From Chatas A.T (1953), A practical treatment of 
nonsteady state flow problems in reservoir 
systems, he expressed an infinite series of 
exponentials and Bessel function in terms of 
dimensionless pressure evaluated as a function of 
dimensionless radius and dimensionless time.  
Some important characteristics of this tabulation 
include the following. 
1. When tD<.01, ݌஽(ݐ஽) can be approximated by 
the relation   
  ݌஽(ݐ஽) = ଶ√௧ವ√గ                                           (4.1) 
2. For tD >100 ; ݌஽(ݐ஽) can be extended by use 
of the equation                                                        ݌஽(ݐ஽) = .5(݈݃݋ ݐ஽ + .80907)               (4.2) 
 
101 102 103
10
1
Dimensionless time tD
D
im
en
si
on
le
ss
 w
at
er
 in
flu
x 
pD
Dimensionless pressure value for infinite aquifer
Page 949
  
Figure 04: Dimensionless pressure value for 
infinite reservoir in several of dimensionless 
time. 
Computation of ܳ஽(tୈ), some important 
characteristics of this tabulation include the 
following for infinite reservoir  
1. When tD<.01, ܳ஽(ݐ஽)can be approximated by 
the relation    Qୈ(tୈ) = ଶ√୲ీ√஠                             (4.3) 
2. For tD >200 ; ܳ஽(tୈ) can be extended by use 
of the equation                                                        ܳ஽(ݐ஽) = ିସ.ଶଽ଼଼ଵାଶ.଴ଶହ଺଺௧ವ௟௢௚ ௧ವ                             (4.4) 
 
Figure05: Dimensionless water influx value for 
infinite reservoir in small value of dimensionless 
time. 
 
Figure 06: Dimensionless water influx value for 
infinite reservoir in large value of dimensionless 
time. 
 
5.DISCUSSION AND CONCLUSION: 
To determine the fluid flow rate in any reservoir, 
some conditions are applied and which is very 
important. This paper shows that solutions of 
differential equation describing flow in a 
petroleum reservoir for given initial and 
boundary condition can be expressed compactly 
using dimensionless variables and parameters. 
This solution of the diffusivity equation, models 
radial flow of a slightly compressible liquid in a 
homogeneous reservoir of uniform thickness 
reservoir at uniform pressure (pi) before 
production and no flow boundary and production 
at constant rate q from the single well at radius 
rw. 
Two sets of solutions of diffusivity equation are 
developed namely for "the constant terminal 
pressure case" and " the constant terminal rate 
case". In the constant terminal pressure case, the 
pressure at the terminal boundary is lowered by 
unity at zero time, kept constant and the 
cumulative amount of fluid flowing across the 
boundary is computed as a function of time. In 
the constant terminal rate case, a unit rate of 
production is made to flow across the terminal 
boundary and the ensuring pressure drop is 
computed as a function of time. 
Some curves can be employed to reproduce the 
effect of any pressure or rate history encounter in 
practice. 
This paper is useful to understand the Darcy’s 
law, how diffusivity equation is developed from 
the Darcy’s law, and the development of the 
dimensionless variable from the diffusivity 
equation and finally the numerical solution of the 
diffusivity equation using Laplace transform. The 
final solution of diffusivity equation is handy for 
dimensionless water influx calculation well test 
analysis. 
References: 
1.  ABRAMOWITZ and STEGUN, Handbook of 
Mathematical Functions 
10
-2
10
-1
10
0
10
1
10
2
10
3
10
4
10
-1
10
0
10
1
10
2
10
3
10
4
Dimensionless t ime tD
D
im
en
si
on
le
ss
 w
at
er
 in
flu
x 
Q
D
Dimensionless water influx value for infinite aquifer
10
4
10
5
10
6
10
7
10
8
10
3
10
4
10
5
10
6
10
7
10
8
Dimensionless time tD
D
im
en
si
on
le
ss
 w
at
er
 in
flu
x 
Q
D
Dimensionless water influx value for infinite aquifer
Page 950
  
2. Chatas, A.T.: (1953) A Practical treatment of 
nonsteady state flow problem in reservoir system, 
Pet, Eng B-44- through B-56. 
3. CRAFT, B. HAWKINS (1991) Applied 
Petroleum Reservoir Engineering (prentice-Hall) 
4. DAKE, L. P (1978) Fundamentals of Reservoir 
Engineering (Amsterdam: Elsevier) 
5. FETKOVICH, M.J (1971) A Simplified 
approaches to water influx calculation finite 
aquifer systems. J. Pet. Technol. July, 814-828 
6. GEORGE A ARTICOLO(1998) Partial 
Differential Equations and Boundary Value 
Problems with maple V, 
7. IKOKU, C (1984) Natural Gas Reservoir 
Engineering (New York: John Wiley & Sons) 
8. KAMRAN, BIOT (1940) Mathematics 
methods in engineering p-403(McGraw-Hill) 
9. LEE, J.(1982) Well Testing ( Dallas, TX 
Society of Petroleum Engineers of AMIE) 
10. LEE, J. A WATTENBARGAR R.(1996) Gas 
Reservoir Engineering, SPE textbook Series 
chapter 05. 
11. SPIEGEL MURRAY R(1965) Laplace 
transformations (Tata McGraw-Hill) 
12.TAREK AHMED PAUL D. 
MCKINNEY(2005) Advanced Reservoir 
Engineering (Elsevier) 
13. T.A BLASINGAME (1994) Real domain 
solution vai Inversion of the Laplace transform 
solution, course no-Petroleum Engineering 620, 
lecture-2a. 
14. VAN EVERDINGEN, A F HURST, M 
(1949) The application of the Laplace 
transformation to flow problems in reservoirs. 
Trans. AMIE,186305-324 
15. WATSON, C (1944) A Treatise on the theory 
of Bessel Functions (Cambridge Univ) 
16. WILLIAM E. BRIGHAM (1997) Water 
influx, Its effect on oil recovery part 1 aquifer 
flow (Work Performed Under Contract No. DE-
FG22-93BC14994). 
 
 
Page 951
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Authors: Dr. M.R. Islam and M.O. Faruque  
E-mail: dmrislam74@gmail.com; faruque_pge@yahoo.com 
AN OVERVIEW OF GEOLOGY, HYDROGEOLOGY, AND OPEN 
PIT MINING PERSPECTIVE OF THE PHULBARI GONDWANA 
COAL DEPOSIT, NW BANGLADESH 
 
Mohammed Omar Faruque1*, Dr. Md. Rafiqul Islam 2*, Engr. Salma Akhter3, and 
Dr. Mohammad Iqbal4, 
 
1, 2 Department of Petroleum & Georesources Engineering 
3 Department of Chemical Engineering & Polymer Science 
4 Department of Industrial & Production Engineering 
Shahjalal University of Science & Technology 
Sylhet-3114, Bangladesh 
 
 
The Phulbari coal deposit is one of the largest coal reserves in NW Bangladesh. The country requires 
exploring this resource to overcome the present energy crisis. Two types of mining methods-open-pit and 
underground, might be considered for the exploration of coal worldwide.  However, depths of the coal seam, 
geological, and hydrogeological circumstances of the Phulbari area vigorously disfavor open-pit mining. In 
this article, geology and hydrogeology of the area have been reviewed first, and then Boundary Element 
Method (BEM) numerical modeling has been applied to recognize in situ stress state around the proposed 
open pit mine of the Phulbari coal deposit. The modeling result reveals that the tensional rock failure state 
would be created around the proposed open-pit excavation. The major focus of the article is to explain the 
geological and hydrogeological problems linked to the in situ stress state of the surroundings open-pit 
dimension and how long distance the groundwater table would be affected because of the mine dewatering. 
 
Key words: Coal, Geology, Hydrogeology, and Mining 
 
1. INTRODUCTION 
Bangladesh needs coal as a major alternative 
energy source to overcome the present critical 
situation in the power sector. The Phulbari coal 
basin in northwestern Bangladesh has over 572 Mt 
of bituminous ranks of coal. The geographical 
location of the basin is shown in Fig.1. The 
existence of the Phulbari basin was first discovered 
by the Geological Survey of Bangladesh (GSB) to 
investigate a negative gravity anomaly identified by 
geophysical exploration for oil and gas, confirmed 
the existence of a sequence of Gondwana coal-
bearing sediments. In 1992, GSB established a 
negative gravity anomaly map and it was assumed 
that about 13 Gondwana coal-bearing basins 
remains in the NW Bangladesh [1].  
Australia-based Broken Hill Proprietary (BHP) 
worked in Bangladesh for about eight years, spent 
millions of dollars on the geological and 
geophysical exploration and discovered a large- 
 
 
scale coal deposit at the Phulbari area in 1997. 
Because of location of coal at a deeper depth, BHP 
realized that open-pit mining at a depth of more 
than 130m would be inconceivable at the Phulbari 
basin. Considering the unconsolidated overburden 
and thick unconfined aquifer, open-pit mining was 
problematic even at a depth of 130m. Finally, BHP 
decided not to proceed open-pit mining due to 
environmental reasons and for geological, 
hydrogeological, and economic reasons [2].   
The Government of Bangladesh signed a 
contract with BHP through an open tender. While 
BHP determined not to continue for open-pit 
mining, at that juncture, Asia Energy, a UK-based 
company without any mining experiences 
elsewhere made contract with BHP in 1998 [3]. Asia 
Energy took license of the Phulbari basin from 
BHP and was planning to submit an underground 
mining proposal to the government. However, 
instead of submitting an underground mining  
Page 952ISBN: 978-984-33-2140-4
  
 
Fig.1. Location of the Phulbari coal basin in NW Bangladesh (modified after GHD Pty.Ltd, Australia4) 
 
proposal, Asia Energy is now trying to overlook the 
devastating consequence of open-pit mining [2]. 
Regarding the aforesaid state of situations, the 
Government of Bangladesh is concerned to get a 
decision for the selection of mining method, i.e. 
either open-pit mining or underground mining. 
Before selection of a mining method the technical 
information- such as, geology, coal distributions 
and hydrogeology of the basin are earnestly 
required. However, necessary data concerning 
geology and hydrogeology of the Phulbari basin are 
not available to the scientific community of the 
country and abroad. The two major objectives of 
the present article are- (i) to provide an overview of 
the geological setting and hydrogeological 
conditions of the area associated with open-pit 
mining outlook, and (ii) safety measures of the 
regional groundwater table regarding the mining 
method selection of the Phulbari coal deposit. 
Safety measures of the regional hydrogeology have 
been focused on the basis of BEM numerical 
simulation. 
 
 
2. GEOLOGY OF THE DEPOSIT 
The Phulbari Coal Basin is located in the 
Dinajpur Shield of Bangladesh and is surrounded 
by Himalayan Foredeep to the north, the Shillong 
Shield/Platform to the east, and the Indian 
Peninsular Shield to the west. The Garo–Rajmahal 
gap lies between the exposed Peninsular Shield and 
the Shillong Shield [1].  
The geology and structure of the Phulbari coal 
deposit were illustrated by GHD of Australia [4]. 
According to the geological data of the basin, the 
sedimentary strata of the deposit are nearly 350 m 
thick. In general, the area is characterized by the 
horizontal occurrence of the sedimentary rocks with 
large-scale tectonic disturbances. The Phulbari 
basin preserved in two faults controlled basins 
surrounded by Archaean basement at shallow 
depth. BHP drilling recognized two giant faults 
having vertical displacement about 150m. From a 
cross-section (N-S) of the basin, as prepared by 
GHD, it is observed that one fault is located toward 
the south of the basin and another to the central part 
[4]
. 
Page 953
  
 
Fig.2. Stratigraphic cross-section (see location of boreholes in Fig.1) of the Phulbari coal basin (modified 
after GHD Pty.Ltd, Australia4) 
 
The geological features of the rock mass structure 
suggest that there are large-scale tectonic forces in 
the area of the Phulbari coal deposit. Existence of 
two major faults reveals the basin is a part of the 
tectonically high-disturbed zone within the 
continental Indian plate, where convergence and 
subduction of Indian plate is continuing beneath the  
Eurasia plate at 55 mm per year. It means there are 
numerous faults, fractures, joints, and fissures 
within the Phulbari basin [6]. The stratigraphic 
sequence (Figs.2,3) of the Phulbari coal deposit is 
identical to that of the Barapukuria basin and it is 
divided into four formations on the basis of age and 
lithology: 
● Madhupur clay from the recent Holocene era, 
● A water-bearing Dupi Tila aquifer of Late  
   Miocene-Middle Pliocene age, 
● Permian coal-bearing Gondwana Group rock       
    sequences, and 
● Pre-Cambrian Archean basement [4,7, 8, 9]. 
The sedimentary stratum contains the Madhupur 
Clay, Upper Dupi Tial (UDT), Lower Dupi Tila 
(LDT), Gondwana coal-bearing rock series. About 
3m thick Madhupur Clay Formation composed of 
clay, mostly silty. The Tertiary sediments occur in 
two distinct sequences- the UDT and LDT. The 
UDT Formation is almost 80m thick, which is an 
unconfined mega-aquifer that extends entire 
northern districts of the country. The host rocks are 
sand- unconsolidated to partly consolidated, 
medium to coarse-grained, occasionally gravelly 
with bands of silt. The Lower Dupi Tila Formation, 
approximately 30m thick, consists of sandstone, silt 
and white clay. 
The Permian-Carboniferous coal-bearing 
sequence is subdivided into three unit- an upper 
unit of mudstone and sandstone; a middle unit 
represented by a carbonaceous mudstone and well 
developed coal sequence and a lower unit 
consisting of quartz rich sandstones and 
interbedded carbonaceous mudstone, siltstone and 
sandstone. Total coal sequence thickness is up to 
45m with one or more partings up to 5.5m thick 
identified. The depths of the two proposed 
mineable coal seams of the Phulbari basin range 
between 120m-350m [4, 7, 8, 9]. 
 
3. HYDROGEOLOGY 
Belonging to the same geological belt, the 
hydrogeological characteristics of the Phulbari 
basin would be identical to that of Barapukuria 
basin. The both upper and lower seams of the 
Phulbari basin lie beneath an unconfined aquifer.  
In the Barapukuria, there is a proven potential for 
groundwater flow from the Upper Dupi Tila into 
the Gondwana sandstones. All Gondwana 
sandstones are typically jointed, although the joints 
are frequently mineralised or infilled which reduces 
the secondary permeability of the aquifer. The Dupi 
Tila deposits are comprised of poorly consolidated 
to unconsolidated sands with high permeability 
ranging from 4.81 mD to 558 mD [1, 7, 8, 9].  
Permeability within the Gondwana is 
considerably less (3.67 mD to 75 mD) than that of 
the overlying Dupi Tila aquifer. The upper coal 
seams have permeability between 9.8 mD and 
137.8 mD because these seams are comparatively 
soft and, to a varying extent, are in hydraulic 
continuity with the Upper Dupi Tila aquifer. In the 
Dupi Tila aquifer, the estimated hydraulic 
continuity results range from 160–260 m/d for the 
entire thickness of about 110m Estimated hydraulic 
conductivity for the Gondwana aquifer is 31 m/d 
for the entire thickness of about 100 m. The 
permeability value of the Lower Dupi Tila 
aquiclude is about 0.15 mD [1, 7, 8, 9].  
 
4. OPEN-PIT MINING OUTLOOK  
Four important factors that have major impacts on 
the mining method selection include- (i) physical 
and mechanical characteristics of the overburden  
Page 954
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig.3. Upper and lower coal seams (see location of boreholes in Fig.1) of the Phulbari coal basin (modified 
after GHD Pty.Ltd, Australia4). 
 
rock of the deposits, (ii) technical factors, (iii) 
economic factors, and (iv) productivity factors [10]. 
Usually, an open-pit mining is considered for large 
tonnage, high rates of production while overburden 
rock is thin, not greater than 120m. On the contrary, 
underground mining is beneficial while the coal 
deposit is deep, greater than 120m; ore body is 
steep and grade is high enough to cover costs [11]. 
Asia Energy Corporation (AEC) is committed to 
open-pit mining in the Phulbari coal basin based on 
the economic and productivity factors.  
 
5. SIMULATION RESULTS 
Boundary Element Method (BEM) numerical 
simulation of the Phulbari proposed (Fig.4) open-
pit mine has been carried out to assess tensional 
strength factor within the surrounding rock 
sequences. The two-dimensional BEM model 
covers a length of the pit ground line of about 4 km, 
length of the pit bottom is about 2.5 km, and a 
depth of it is about 400 m (Fig.5a). The simulation 
result reveals that high tensional failure within rock 
strata would be extended upto 27 km towards the 
both sides from the center of the open pit. The 
lateral and vertical tensional effect within the strata 
would be around 54 km, and 1.25 km, respectively. 
 
6. DISCUSSION 
Two types of mining methods- open-pit and 
underground, have been practiced for a long time 
worldwide. The depth of coal deposits beneath the 
surface and nature of the overburden determine the 
mining method employed. The seam thickness and 
continuity influence the specific mining practices as 
well as the resource recovery attainable for a given  
deposit. The open-pit mining method is usually 
selected based on the geology, hydrogeology, depth 
of overburden of coal, and topographic locations of 
the basin. Most of the open-pit coalmines in 
Australia, for example, Surat Basin, Galilee Basin,  
Page 955
  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig.4. Design of the proposed open pit coal mine of the Phulbari coal basin, NW Bangladesh (modified after 
AEC [5]). Note that the coal basin is located under a town with many densely populated villages around the 
town. Line AA/ shows the position, along which BEM simulation (Fig.5) has been considered. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig.5. Distribution contours of tensional strength factor within the UDT, LDT, and Gondwana rock sequences. 
Page 956
  
Fig. 6. Aerial photograph of an open-pit mining in a hilly region of Australia
 
Washpool open-pit coal project, the Red Hill open-
pit coal project, the Burton, Ellensfield and 
Wallanbah open-pits, etc, are found in and around 
the hilly regions (for example, Fig.6) and the  
depths of these open-pit mines in that area are 
shallower than 120m [11]. 
The first problem for open-pit mining in the 
Phulbari basin is connected to the depth of coal 
seams that lie beneath an unconsolidated 
overburden associated with unconfined regional 
aquifer, the Upper Dupi Tila Formation. The depth 
of coal seams of the basin ranges from 150 to 
350m. The deeper depth (greater than 120m) 
relevant dilemma for open pit mining in the 
Phulbari basin was first detected by BHP in 1997. 
The company recognized very high water inflow 
within the overburden Dupi Tila aquifer which is 
connected to the coal-bearing Gondwana Group 
rock sequences by different faults and joints. BHP’s 
target was to have coal seams under a depth of 
maximum 100m below the surface. However, the 
company could not find a shallow coal deposit 
around 100m depth. After the pre-feasibility study, 
BHP abandoned the open pit mine project in the 
Phulbari coal basin because the company did not 
want to create another environmental disaster as 
they have bitter experience in Papua New Guinea 
[6]
. 
The second problem is associated with regional 
hydrogeology of the area. From the BEM numerical 
simulation result (Fig.5) it is revealed that the 
safety of the regional groundwater table would be 
damaged because of high tensional factor within the 
rock strata up to about 27 radius from center of the  
 
pit. Extensive tensional failure into the rock strata 
up to 54 km would create numerous fractures and 
tensional shear stress that will enhance porosity and 
permeability. In a rational sense, when a mine 
dewatering is continued, groundwater is released 
continuously from geological formations and the 
water level doesn’t rebound. Recovery of 
surroundings water level due to continuous 
dewatering from an open pit mine is impossible. 
The present study clarify that the cone of 
depression (Fig. 5b) will be extended up to 54 km 
and local tube-wells, shallow machines, and deep 
tube-wells will not get groundwater for agriculture 
and domestic purposes within a radial distance up 
to 27 km from the center of the mine [10].  
 
7. CONCLUSIONS 
The disagreement for open-pit mining of the 
Phulbari deposit hinges upon only coal recovery 
rate (over 90%). The ultimate goals of a mining 
method selection are to- (i) maximize company 
profit, (ii) maximize recovery rate of the mineral 
resources, and (iii) provide a safe environment by  
selecting the method with the least problems among 
the feasible alternatives. From the reviews, it seems 
that AEC interest was only the first two factors; 
apart from the technical, physical, and mechanical 
properties of the overburden rock stratum. 
Therefore, expert’s opinions regarding mining 
geologists and engineers are disparate from that of 
AEC’s information. However, the present study 
illustrates a serious technical issue regarding 
Page 957
  
geological and regional hydrogeological aspects of 
the northwest Bangladesh. 
 
ACKNOWLEDGEMENTS 
The basic geological data, (Fig.1,2.3) and open 
pit mine sketch (Fig.4) outlook, published in this 
article has been extracted from the technical report 
of Australia-based GHD Ply. Ltd, and AEC’s 
presentation that were available to their websites 
(2005-2009). Authors have also taken assist from 
the important articles of the daily newspaper that 
were written by different scholars of the concerning 
fields.  
The authors are also grateful to Dr. Md. 
Khalequzzman, Professor of Lock Haven 
University, USA; Professor Dr. Badrul Imam, 
Department of Geology, D.U; Md. Nazrul Islam, 
Ex. Geological Consultant of BHP’s Bangladesh 
Coal Project; and Engr. A.K.M. Samsuddin for 
their scholarly achievements in the Daily Star. 
Thanks to Mr. Nurul Kabir, the Editor in chief of 
the Daily NEW AGE who published some 
important articles of Dr. M.R. Islam. 
 
REFERENCES 
1. Islam and Hayashi (2008), Geology and 
coal bed methane resource potential of the 
Gondwana Barapukuria coal basin, 
Dinajpur, Bangladesh. International 
Journal of Coal Geology 75, 127–143, 
ELSEVIER. 
2. The Daily Star May 30, 2010.  Open-pit 
mining revisited ( by Nazrul Islam). 
3. The Daily Star, August18, 2006.Open pit 
mining for coal. 
4. GHD Pty. Ltd, Australia. Competent 
Person's Report, Phulbari Energy Project, 
Technical Outline, March, 2004. 
5. Asia Energy Plc, The Phulbari Coal 
Project, Bangladesh, Presentation to 
Coaltrans Asia Conference, Bali, 
Indonesia, June 05, 2006. 
6. The daily New Age, 6th Anniversary 
Special, January 19, 2010. Problems for 
open pit coal mining in northwest 
Bangladesh (by Dr. Md. Rafiqul Islam). 
7. Wardell Armstrong (1991), Techno-
economic feasibility study of Barapukuria 
Coal Project, Dinajpur, Bangladesh. 
8. Bakr et al. (1996), Geology and coal 
deposits of Barapukuria Basin, Dinajpur 
District, Bangladesh, Records of 
Geological Survey of Bangladesh. 8, pt 1. 
9. Islam et al. (2009). Finite element 
modeling of stress distributions and 
problems for multi-slice longwall mining 
in Bangladesh, with special reference to 
the Barapukuria coal mine. International 
Journal of Coal Geology 78, 91–109, 
ELSEVIER. 
10. The daily New Age (Editorial), October 
28, 2010. No reason for Bangladesh to go 
for open pit mining (by Dr. Md. Rafiqul 
Islam). 
11. The daily New Age (Editorial), August 
26, 2009. Coal deposits, mining 
perspective in northwest Bangladesh (by 
Dr. Md. Rafiqul Islam) 
Page 958
* Corresponding Author: Tahmilur Rahman  
E-mail: mukto.sust@gmail.com   
COAL BED METHANE (CBM) PROJECT, HOW FAR TO MINIMIZE THE 
ENERGY CRISIS OF BANGLADESH 
 
 
Tahmilur Rahman* and S M Jahangir Alam 
Shahjalal University of Science & Technology, Sylhet-3114, Bangladesh 
 
 
 
At North West of Bangladesh there are five major Gondwana coal fields of Permian age contains 4744 
million tons of coal (Barapukuria, Phulbari, Khalaspir, Dighipara, Jamalganj). The depths of coal seams 
below surface lie in range 118-118m including 29 coal seams in average thickness range of 38.4-64m.  
These coals are high to medium volatile bituminous with high FC including a little sulphur 0.54-0.77%. 
Porosity and permeability is respectively 1.6-3.2% and 9.80-137.8mD, including temperature gradient 32-
36®C/km. These characteristics show how prospective the CBM project could be in Bangladesh. Gondwana 
coal consists of 90% methane, calorific value of 10450-11876 Btu/lb and average estimate in-situ CBM 
resource is 9.56m³/ton. Through the empirical formula given by Meinser and Kim (direct method) CBM 
reserve is estimated. Bangladesh requires 5000MW of electricity but generating only 3200MW. Coal 
provides 40% of total electricity produced in the world. So, CBM project can minimize this energy crisis of 
Bangladesh within half time required for mining. Large amount of water will be produced due to production 
of CBM which contains high amount of total dissolved solids (TDS) can cause salinity problems of soil, 
decrease the ground water level as well as affect the environment. Proper treatment and management of 
process can ensure the safety and risk. 
 
Key words: Coal, CBM extraction, Estimation, Energy, Environment 
 
1. INTRODUCTION:  
 
Bangladesh is a developing country. As a 
developing country, we are facing many problems. 
Moreover, we have very limited natural resources 
like gas, coal, crude oil, limestone, pit etc. Like the 
whole world, Bangladesh is also facing energy 
problem due to the lack of gas and other natural 
resources. But electricity is the key ingredient of 
socio-economic development of the country. 
Adequate and reliable supply of electricity is an 
important pre-requisite for attracting both domestic 
and foreign investment. The Government has given 
top priority to the development of the sector and 
has set the goal of providing electricity to all 
citizens by 2020. 
 
Reliable supply of electricity is a pre-condition for 
poverty reduction and economic development. In 
Bangladesh, 47% of total populations have access 
to electricity but reliable and quality power is still a 
faraway. To alleviate poverty in the face of 
resource limitations and high population density, 
Bangladesh requires an economic growth rate of 
more than 7% p. a. In order to achieve this growth 
rate, electricity growth needs to be achieved by 
10%. By best utilizing the natural, human and 
agricultural resources the desired pace of GDP 
growth could be attained by increasing electricity 
generation at much higher rate, which is the key 
target for development. 
 
2. BANGLADESH POWER SECTOR: 
 
In FY 2009-10 total generation capacity was 5,823 
MW (up to May’10) including 3226 MW in public 
sector and 2045 Megawatt in private sector.  
 
Table 1: overview of Bangladesh power sector 
 
No. Items 2009-2010 
1. Installed Capacity, MW 5,823 
2. Generation Capacity 5,271 
3. Maximum Generation 4,606 
4. Net Generation, MKWh  26,533 
5. Transmission line, km 8,391 
6. Number of consumers  12 million 
7. No. of village electrified 53,281 
8. Per capita generation 220 
9. Access to electricity 47% 
 
 
Page 959
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
 2.1 Present Generation Capacity:  
 
Presently total generation capacity is 5,271 MW. Of 
this capacity 3,226 MW is from public sector and 
2045 MW is from the private sector, which is 62% 
and 38% respectively of the total generation 
capacity.  
Considering 10 - 15 % Maintenance and Forced 
Outage, Available Generation Capacity is in the 
range of 4500 – 4800 MW without fuel 
constraint.After Considering 10 - 15 % 
Maintenance and Forced Outage, Available 
Generation Capacity is in the range of 3400-3900 
MW in those plants where gas is used as fuel. 
 
2.2 Future Rolling Plans: 
  
Power is the pre condition for social and economic 
development. But currently consumers cannot be 
provided with uninterrupted and quality power 
supply due to inadequate generation compared to 
the national demand. To resolve the present 
shortfall and to meet the increasing demand for 
electricity, the government has taken an initiative to 
increase generation (installed) capacity to 13735 
MW by 2015. For this reason installation of new 
power plants and the maintenance of the old power 
plants has been given highest priority. 
 
2.3 Worldwide Electricity Generation: 
 
Figure 1: Worldwide Electricity Generation, coal is 
used to produce 39% of electricity worldwide 
 
2.4 Electricity Generation in Bangladesh:  
 
 
 
 
 
 
 
 
 
Figure 2: Electricity Generation in Bangladesh 
 
Coal is used to produce 4.29% of electricity in 
Bangladesh; where, natural gas is used to produce 
82.21%, furnace oil 5.75%, hydro 3.95%, diesel 
3.19% of electricity in Bangladesh.  
 
3. GAS SECTOR SENARIO IN 
BANGLADESH:  
 
Total recoverable gas: 21 TCF (Proven and 
probable) 
Reserve remaining: 13 TCF (more 2 TCF gas have 
been discovered now)  
National demand of natural gas: 2200 MMCFD  
Production capacity: 1880 MMCFD  
Power sector requirement: 921 MMCFD  
Power sector gets: 800 MMCFD  
 
 
3.1 Sector wise use of Gas in Bangladesh: 
  
 
 
 
Figure 3: Sector wise use of Natural gas in 
Bangladesh 
 
3.2 Next 5o Years Sector wise and Total Gas 
Demands: 
 
 
 
 
Figure 4: Sector wise and total gas demand 
projections for 50 years by Petrobangla 
 
 
 
39%
10%
15%
16%
16%
0% 10% 20% 30% 40% 50%
Coal
Oil
Gas
Neuclear
Hydro
51%
21%
11%
11%
1%
5%
Power
Fertilizer
Industrial
Domestic
Commercial
System loss
0 5 10
2001-10
2011-20
2021-30
others(Tc
f)
7 
5 
Page 960
  
3.3 Supportive Fuel For Energy Sector: 
 
Natural gas several uses like in domestic or 
industrial purpose. We have shown a data how the 
need of natural gas will rise in many sectors. 
Bangladesh is facing a critical energy shortage and, 
while requiring an estimated 5823 MW of 
electricity, is currently having a generation capacity 
of 4500-4800 MW. And from them, 3400-3900 
MW produced from those plants where natural gas 
is used as fuel. According to the vision 2021 plan of 
present government, within 2015, there will be a 
generation addition of 9426 MW, from where 5182 
MW will come from those plants where natural gas 
is used as fuel. Natural gas used only 15% to 
produce electricity worldwide, but in our country 
this is about 82.81%. Due to the high necessity of 
natural gas, it is very tough to depend very much on 
natural gas to produce electricity. 
Unit Conversion Factors: 
Gas volume:  1 Tcf = 28.3286 Gm3 
 Energy:  1 Kcal = 4186.75 j 
 
Energy Equivalence: 
1 Mt coal = 0.6967 Gm3 gas 
1 Gm3 gas = 1.4354 Mt Coal 
 
Daily requirement of Natural gas in the power 
sector = 921 MMCFD 
So, requirement of Natural gas to produce 1 MW of 
electricity = 0.2095 MMCFD 
Now, according to the present demand of 
Bangladesh, 1 Tcf gas can be used to produce 3500 
MW power per day for approximately for 4 years. 
 
4. COAL AND COAL BED METHANE (CBM): 
Coal is a sedimentary rock and basically lithified 
plant material. Bangladeshi coal is Premain in age 
and occurs within fault bounded Gondwana basins. 
Coal quality is high to medium volatile bituminous 
with high fixed carbon provides high calorific 
value. At North West of Bangladesh there are five 
major Gondwana coal fields contains 4744 million 
tons of coal (Barapukuria, Phulbari, Khalaspir, 
Dighipara, Jamalganj). The depths of coal seams 
below surface lie in range 118-1178m including 29 
coal seams in average thickness range of 38.4-
64m.These coals are high to medium volatile 
bituminous with high FC, including very little 
Sulphur 0.54-0.77%. Gondwana coal consists of 
90% methane,10% Carbon dioxide, Nitrogen,  
calorific value of 10450-11876 Btu/lb and average. 
All the data related with the coal fields are given 
below in the Table 5: 
 
 
Table 2: Description of five major coal fields of  
Bangladesh:   
 
 
 
(Table continued) 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
D
isc
ov
er
 (y
ea
r) 
D
ep
th
 (m
et
er
) 
N
o 
of
 c
oa
l s
ea
m
 
A
ve
ra
ge
 th
ic
kn
es
s o
f c
oa
l 
se
am
s (
m
et
er
) 
R
es
er
ve
 (m
t) 
Ja
m
al
ga
nj
 1962 640-1158 7 64 2513 
B
ar
ap
uk
ur
ia
 1985 118-506 6 51 377 
K
ha
lis
hp
ir 1989 257-451 8 42.3 828 
D
ig
hi
pa
ra
 1995 250 7 42 600 
Ph
ul
ba
ri 
1998 152-246 1 38 426 
To
ta
l 
- 29 - 4744 
9 
Page 961
  
 
 
 
For CBM project six geological characteristics to 
be considered: 
1. depth and thickness of coal seam 
2. rank of the coal 
3. fractures in the coal seam 
4. porosity and permeability 
5. hydrodynamic properties 
6. geothermal gradient 
 
Bangladesh is highly prospective for CBM project 
because it has satisfactory values of terms required, 
the minimum standard values and Bangladesh coal 
fields are compared below: 
 
Table 3: Comparison of minimum standard values 
for CBM and Bangladesh coal fields 
 
 Minimum 
Standard 
Bangladesh 
Coal Fields 
(average) 
Depth 300 meter 283-590 
meter 
Thickness of 
coalseam 
20 meter 38.4-64  
meter 
Rank of coal High 
volatile 
bituminous 
High to 
medium 
volatile 
bituminous 
Porosity > 1.6% 1.6-3.2% 
Permeability 5 Md 9.8-137.8 
Md 
Temperature <40°C 32-36°C 
CBM content 70 ft3/ton 200-400 
ft3/ton 
   
 
This chart is announcing the high possibility of 
CBM project in Bangladesh. There are 6.5-12.68 
m³/ton of gas content at Barapukuria, Gondwana 
coal contains 90% methane and 10 % carbon 
dioxide, nitrogen, carbon monoxide, ethane etc. So, 
we can say how prospective is CBM for 
Bangladesh.  
 
4.1 CBM Extraction-Basic Principal: 
The methane is absorbed into the solid coal matrix 
and is released when the coal seam is 
depressurized. To economically retrieve reserves of 
methane, wells are drilled into the coal seam, the 
seam is dewatered and then the methane is 
extracted from the seam, compressed and piped to 
market. The goal is to decrease the water pressure 
by pumping water from the well. The decrease in 
pressure allows methane to desorbs from the coal 
and flow as a gas up the well to the surface. 
While dewatering is occurring, the operator should 
make sure that the pump jack is not running too 
long. If the water level is pumped too low, this will 
C
oa
l Q
ua
lit
y 
A
sh
 C
on
te
nt
 %
 
Fi
xe
d 
C
ar
bo
n 
%
 
V
ol
at
ile
 M
at
te
r %
 
Su
lp
hu
r %
 
C
al
or
ifi
c 
V
al
ue
 (B
tu
/lb
) 
M
oi
st
ur
e 
Co
nt
en
t %
 
H
ig
h 
to
 
m
ed
iu
m
 
vo
la
til
e 
bi
tu
m
in
ou
s 
24
.2
 
36
.7
 
36
.9
 
0.
55
 
11
87
6 
3.
58
 
H
ig
h 
to
 
m
ed
iu
m
 
vo
la
til
e 
bi
tu
m
in
ou
s 
16
.2
 
46
.2
 
27
.6
 
0.
57
 
10
45
0 
 
H
ig
h 
to
 
m
ed
iu
m
 
vo
la
til
e 
bi
tu
m
in
ou
s 
21
.8
 
54
.1
 
22
.8
6 
0.
77
 
11
26
4 
1.
28
 
H
ig
h 
to
 
m
ed
iu
m
 
vo
la
til
e 
bi
tu
m
in
ou
s 
- - - <1
 
-  
H
ig
h 
to
 
m
ed
iu
m
 
vo
la
til
e 
bi
tu
m
in
ou
s 
15
 
- - <1
 
-  
- - - - - - - 
Page 962
 allow the gas to travel up the tubing into the water 
line, causing the well to become "gassy". The main  
                 Figure 5: A typical CBM well 
 
objective is not to put the gas in the water line, but 
to allow it to flow up the backside of the well 
(casing) and into the pipeline, where it can be 
transported to the compressor station and delivered 
to the customer for sales. Once the gas goes up the 
tubing, it is usually recovered in a water-gas 
separator at the surface. However, pumping water 
and gas is inefficient and can cause pump wear and 
breakdown. 
 
Most gas in coal is stored on the internal surfaces of 
organic matter. Because of its large internal surface 
area, coal stores 6 to 7 times more gas than the 
equivalent rock volume of a conventional gas 
reservoir. Gas content generally increases with coal 
rank, with depth of burial of the coal bed, and with 
reservoir pressure. Fractures, or cleats, that 
permeate coal beds are usually filled with water; 
the deeper the coal bed, the less water is present, 
but the more saline it becomes. In order for gas to 
be released from the coal, its partial pressure must 
be reduced, and this is accomplished by removing 
water from the coal bed. Large amounts of water, 
sometimes saline, are produced from coal bed 
methane wells, especially in the early stages of 
production. While economic quantities of methane 
can be produced, water disposal options that are 
environmentally acceptable and yet economically 
feasible, are a concern. Water may be discharged on 
the surface if it is relatively fresh, but often it is 
injected into rock at a depth where the quality of 
the injected water is less than that of the host rock. 
Another alternative, not yet attempted, is to 
evaporate the water and collect the potentially 
saleable solid residues; this scheme might be 
feasible in regions having high evaporation rates.  
 
5. MEASURING GAS CONTENT:  
Coal bed gas content measurements are commonly 
used in mine safety as well as coal bed methane 
resource assessment and recovery applications. Gas 
content determination techniques generally fall into 
two categories: (1) direct methods which actually 
measure the volume of gas released from a coal 
sample sealed into a desorption canister and (2) 
indirect methods based on empirical correlations, or 
laboratory derived sorption isotherm gas storage 
capacity data. 
The total gas content by the in direct methods is 
based on the empirical formula given by Meinser 
and Kim. The quantity of gas is determined by 
Meisner and Kim formula with using the moisture 
content, volatile content, volume of gas adsorbed 
on wet coal, fixed carbon, thickness of coal and 
temperature. 
Meinser (1984) observed that the amount of 
methane gas (VCH4) is related to volatile matter 
(daf) 
 
VCH4= -325.6 × log (V.M/37.8) 
 
Estimation of in-situ gas content of the coal will be 
evaluated by using Kim’s (Kim 1977) equation 
 
V = (100 -M - A) /100 × [ Vw /Vd ] [K(P)N – (b × 
T)] 
 
Where, V = Volume of methane gas adsorbed 
(cc/g), M = Moisture content (%), A = Ash content 
(%),b =Adsorption constant due to temperature 
change (cc/g/°C), N = Composition of coal (for 
most bituminous coals, F.C = Fixed carbon (%), 
VM = Volatile matter (%), Vw = Volume of gas 
adsorbed on wet coal (cc/g), Vd = Volume of gas 
adsorbed on dry coal (cc/g), T = Temperature at 
given depth, To = Ground temperature, h = Depth 
(m), The values of K and N depend on the rank of 
the coal and can be expressed in terms of ratio of 
fixed carbon (FC) to Volatile matter (VM).  
 
Vw / Vd = 1/(0.25 ×M + 1) 
K = 0.8 (F.C /V.M) + 5.6 
N = (0.39 - 0.013 × K) 
T = Geothermal Gradient × (h/ 100) + To 
 
Using the formula we get total CBM potential 0.8-
1.0 TCF in Bangladesh. So, according to the 
previous estimation, we can say that, using only 
CBM, Bangladesh can fulfill the present demand in 
power sector of 921 MMCFD approximately for 4 
years. But, if we use natural gas also with CBM, 
then we can use this CBM for more than 12 years.  
 
Page 963
  
6. ENVIRONMENTAL CONCERN FOR CBM:  
The environmental impacts of CBM development 
are considered by various governmental bodies 
during the permitting process and operation, which 
provide opportunities for public comment and 
intervention. Operators are required to obtain 
building permits for roads, pipelines and structures, 
obtain wastewater (produced water) discharge 
permits, and prepare Environmental Impact 
Statements. As with other natural resource 
utilization activities, the application and 
effectiveness of environmental laws, regulation, 
and enforcement vary with location. Violations of 
applicable laws and regulations are addressed 
through regulatory bodies and criminal and civil 
judicial proceedings. 
 
CBM wells are connected by a network of roads, 
pipelines, and compressor stations. These structures 
can compromise the scenic quality of the landscape, 
fragment wildlife habitat, and displace local 
wildlife populations. Over time, wells may be 
spaced more closely in order to extract the 
remaining methane. Additionally, the produced 
water may contain undesirable concentrations of 
dissolved substances. Water withdrawal may 
depress aquifers over a large area and affect 
groundwater flows. 
 
Large amount of water will be produced due to 
production of CBM which contains high amount 
of total dissolved solids (TDS) can cause salinity 
problems of soil, decrease the ground water 
level as well as affect the environment. Proper 
treatment and management of process can ensure 
the safety. 
 
7. CONCLUSION:  
 
The purpose of this review is not to laud the 
benefits of coal operation, but to raise awareness of 
CBM extraction approaches, which will provide an 
alternative energy for the power sector of 
Bangladesh. 
 
An electricity supply of around 5,271 MW is 
currently required to meet the needs of the people 
of Bangladesh, yet only 4,600-4,800 MW is being 
produced. Most of the electricity supply is 
generated by power plants fueled by natural gas and 
the reserves of our country’s natural gas are finite. 
If the present-day natural gas consumption rate 
were to increase at a rate of 10% per year, the 
proven and recoverable gas reserves (a maximum 
of about 340 Gm3 ), would be exhausted by 2019. 
 
No direct laboratory measurements have yet been 
made of the CBM gas content of coal samples from 
any of the Bangladesh coal basins. In the absence 
of such measurements, the current best estimate of 
the gas content of the coals is provided by the 
predictions of gas concentration based on the 
known characteristics of coal. These prediction 
suggest Bangladesh has a CBM resource of 0.8 Tcf 
to 1 Tcf. 
 
To limit the available options to mining only would 
fail to maximize the resource recovery. It would 
also, almost certainly, maximize the social and 
environmental costs of energy provision.  
Bangladesh has a limited reserve of gas. If we use 
natural gas as fuel for generating power in most of 
the power plants then we will be in a great scarcity 
by 2019. So, this is the time to use the alternative 
energy as fuel to generated power. 
 
Given the close proximity of all the basins, we can 
say that, the coal fields of Bangladesh are highly 
prospective for CBM project because it has 
satisfactory values of terms required. CBM provide 
an energy return that is less than that provided by 
coal itself, were it ti be mined. 
 
To release the dependence on the natural gas on the 
power sector, alternative fuel has to be used. CBM 
is one of the alternative fuels that can be use in the 
power plants as fuel to minimize the power crisis of 
Bangladesh. 
 
8. REFERANCE:   
 
1. Haider-Energy Crisis in Bangladesh, short term 
and long term solution, compiled.  
2. Imam & et al. - Coal Bed Methane Prospect of 
Jamalgonj Coal Field, Bangladesh. 
3. Imam -Energy Resources of Bangladesh. 
4. Islam - Potential for Coal Bed Methane in 
Bangladesh. 
5. Islam, lecturer, SUST-Articles about coal in 
Bangladesh published on different National 
Daily.  
6. Muller- How coal may produce energy without 
being mined.  
7. Muller- It’s not only about coal mining: Coal 
Bed Methane (CBM) and Underground coal 
gasification (UCG) potential in Bangladesh.  
8. Saleque- Bangladesh Power System Master 
Plan Review.  
9. Saleque- Petrobangla Coal Mining Challenges 
in Bangladesh.   
10. www.energybangla.com 
 
Page 964
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
                                                                    CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh  
 
*Corresponding Author: Mohammad Shahedul Hossain 
E-mail: shahedulhossain@gmail.com 
 
 
COMMONLY USED RESERVE ESTIMATION METHODOLOGY 
FOR GAS RESERVOIRS 
 
Mohammad Asad Ibne Hossain and Mohammad Shahedul Hossain* 
Department of Petroleum & Georesources Engineering, Shahjalal University of Science and 
Technology, Sylhet-3114, Bangladesh 
 
Engr. Salma Akhter 
Department of Chemical Engineering and Polymer Science, Shahjalal University of Science and 
Technology, Sylhet 3114, Bangladesh   
Reserve estimation is very crucial in order to gain the confidence on profitable extraction of gas from a gas 
reservoir. Because the degree of uncertainty is inherent in the assessment, the reserves are ‘estimated’ 
rather than ‘measured’. It is a dynamic process; reserves are updated and likely to change as more data are 
available in the course of the development of a gas field. After discovery, during initial delineation, 
volumetric method can be used. When adequate production data are available, material balance can be used 
to estimate the reserve. As depletion proceeds decline curve analysis can be used to determine the remanent 
amount of reserve. During the whole process recovery factor plays a vital part as it determines the 
percentage of the gas can be extracted from the gas initially in place.  
 Keywords: reserve definition, volumetric method, material balance method, decline curve analysis. 
1. INTRODUCTION 
Natural gas is the naturally occurring 
hydrocarbon gas predominantly composed of 
methane. It is found in underground traps formed 
by structural and  stratigraphic features called as 
reservoir. The prospect of accumulation of  
natural  gas depends on coexistence of several 
factors in the subsurface  which includes a) 
source rock, b) reservoir rock, c) trap,  d) seal or 
cap rock etc. Once a reservoir is discovered, it is 
necessary to estimate the reserve of it. Reserve is 
the quantity of gas that is recoverable from the 
underground gas deposits. In many places 
natural gas and crude oil are found coexisting 
because their origin and accumulation processes 
are similar in many accounts.  Ws shall discuss 
about the estimation process of dry gas reservoir 
as they are common in Bangladesh.  
In 1986, the Society of Petroleum Engineers 
(SPE) adopted the following definition for 
reserves : 
“Reserves are estimated volumes of crude oil, 
condensate , natural gas, natural gas liquids and 
associated marketable substances anticipated to 
be commercially recoverable and marketable 
from a given date forward, under existing 
economic conditions, by established operating 
practice, and under current government 
regulations. ” 
The process of estimating oil and gas reserves 
for a producing field continues throughout the 
life of the field. There is always uncertainty in 
making such estimates. The level of uncertainty 
is affected by the following factors: 
a) Reservoir type 
b)  Source of reservoir energy, 
c) Quantity and quality of the geological, 
engineering, and geophysical data, 
d) Assumptions adopted when making the 
estimate, 
e)   Available technology, and 
f)  Experience and knowledge of the 
evaluator. 
Page 965ISBN: 978-984-33-2140-4
  
 
Due to the degree of uncertainty is inherent in 
the assessment, the gas reserves are ‘estimated’ 
rather than ‘measured’.  Reserves are defined in 
different categories on the basis of uncertainty 
such as: 
a) Proved Reserve: up to 10% uncertainty 
b)  Probable Reserve: 10 to 50% 
uncertainty. 
c) Possible Reserve: uncertainty level is as 
high as 90% . 
2.  ESTIMATION METHODS 
Different methods can be used to estimate the 
reserve depending on the maturity of the 
reservoir. The commonly used methods are: 
a) Volumetric Method:  at early stages. 
b) Material Balance Method: when 
production data is available. 
c) Decline Curve Analysis:  when the 
reservoir reaches decline mode. 
2.1 Volumetric Method  
In the early stages of development, reserves 
estimates are restricted to the volumetric 
calculations. The volumetric method entails 
determining the physical size of the reservoir, the 
pore volume within the rock matrix, and the fluid 
content within the void space. This provides an 
estimate of the hydrocarbons-in-place, from 
which ultimate recovery can be estimated by 
using an appropriate recovery factor. 
For a gas reservoir: 
  FR
B
SVGIIP
gi
WiR .17758  
                                                                               
                                                  ……(1) 
Where: 
GIIP = Gas initially in place (SCF) 
VR = Reservoir volume (acre-ft) 
φ = Porosity (fraction) 
SWi = Interstitial water saturation (fraction) 
Bgi = Initial gas formation volume factor 
(res bbl/SCF) 
R.F = Recovery factor (fraction) 
2.1.1 Volume: The reservoir volume is obtained 
from geologic and fluid pressure analysis data. 
The geologist provides contour maps of the top 
and base of the reservoir, as shown in Figure: 1. 
 
       Figure 1: Contour Map 
Such maps have contour lines drawn for every 
20 feet, or so, the elevation can be determined by 
determining the gas water contact (GOC). 
2.1.2 Porosity, φ: Effective porosity of a sample 
is defined as the following ratio: 
 
volumeBulk
volumeporectedInterconnePorosityEffective 
 
 Effective porosity of the reservoir rock can be 
determined from study of core analysis. The 
porosity of clean sandstones may be calculated 
from electric logs. 
 
2.1.3 Interstitial water saturation, SWi : Water 
saturation is defined as the following ratio: 
 
spacesporetotalofVolume
spacesporeinpresentwaterofVolumesaturationWater 
 
Interstitial or connate water saturation may be 
determined from electric logging information or 
by laboratory determinations run on cores by 
restored state, evaporation mercury injection, or 
centrifuge methods. 
 
Page 966
  
 
2.1.4 Formation volume factor ,Bg,: Gas 
formation volume factor is the ratio of volume of 
gas at the reservoir condition to that of gas at the 
standard condition. Mathematically: 
  
bbi
iib
conditionbase
conditionreservoir
gi ZTp
ZTp
V
V
B
615.5

                                                      ………….(2) 
Where: 
Bgi= Initial gas formation volume factor (res 
bbl/SCF) 
pb= Base pressure  (psia) 
pi= Initial reservoir pressure (psia) 
Tb= Temperature at base conditions (0R) 
Ti= Temperature at initial conditions (0R) 
Zb= Gas deviation factor at base conditions 
Zi= Gas deviation factor at initial reservoir 
conditions. 
 
2.1.5 Recovery factor ( R.F) : Recovery factor 
is a number between zero and unity representing 
the fraction of recoverable oil. It depends on the 
following factors: 
a) Current economic circumstances. 
b) Environmental and ecological 
considerations. 
c) Governmental regulations as well as 
politics. 
d) Physics of the reservoir-fluid system. 
 
Finally, GIIP can be obtained by using all the 
parameters in the initial equation. Thus we 
obtain the estimated reserve of the gas reservoir. 
 
2.2 Material Balance Method 
 
Material balance methods provide a simple, but 
effective alternative to volumetric methods for 
estimating not only original gas in place, but also 
gas reserve at any stage of reservoir depletion. 
Material balance equation is simply a statement 
of conservation of mass, or  
 
(Original hydrocarbon mass)–(Produced 
hydrocarbon mass)=(Remaining hydrocarbon 
mass) 
 
The general material balance equation reduces to 
the conventional gas material balance equation 
as : 
 
  
wpgpe
wi
ifwiw
gig BWBGWS
ppcSc
BBG 615.5615.5
1
1 














                                                   ……..(3) 
Where: 
pG = Gas equivalent of the gas and liquid 
hydrocarbons produced on the surface 
pW = Free water from the reservoir 
Swi = the initial water saturation 
C w= Compressibility of water (psi-1) 
P i= Original mean pressure 
P= pressure after producing Gp  amount of gas. 
G=  Original standard cubic feet in free gas zone 
Bgi=Original gas volume facto 
We = Cumulative reservoir barrels of water influx 
into the volume  
Bw= Formation volume factor of water 
Bg=Formation volume factor of the evolved 
solution gas. 
Wp=Cumulative barrels of water produced 
Gp=Cumulative SCF of gas produced 
 
 
2.2.1 Without Water Influx : If there is no 
external energy from other sources, such as 
aquifer is applied, the reservoir is considered as 
completely enclosed. If Wp= 0; We= 0 and 
HCPV=constant, then the equation (3) reduces 
to: 
 
            







G
G
Z
p
Z
p
Z
p p
i
i
i
i  …(4) 
 
This equation is applicable for: 
1. Constant reservoir temperature 
2. No phase change in the reservoir 
3. No water influx 
4. No rock compaction 
5. No connate water expansion. 
  
From equation (4) a plot of p/Z vs. Gp  can be 
found. 
 
 
 
 
 
  
 
 
 
 
 
 
 
                              Figure 2: p/z vs Gp curve 
Page 967
  
 
 
 
2.2.2 With water influx 
 
 If there is a water drive in the reservoir, then the 
pore volume is reduced by the amount equal to 
the volume of encroaching water. Now, 
considering water influx, equation  (3) becomes: 
 
wpegpgi BWWBGGGB  )( ..(5) 
  
Now , using production data we can use equation 
(4) or (5) to determine the amount of gas 
remaining (G- Gp) in the reservoir. 
 
 
2.3 Decline Curve Analysis 
The production rate of wells, or groups of wells, 
generally declines with time. An empirical 
formula can sometimes be found that fits the 
observed data so well that it seems rather safe to 
use the formula to estimate future relationships. 
 
In most case the production will decline at a 
decreasing rate, that is, dq/dt will decrease with 
time. The figure below shows an identical curve. 
The t = 0 point can be chosen arbitrarily. q is the 
gas production rate and t is time. The area under 
the curve between the times t1 and  t2  is a  is a 
measure of the cumulative production during this 
time period since 
    
 

2
1
t
tp
dtqG
…….(6) 
 
 
 
 
 
 
 
 
 
 
 
There are three commonly recognized types of 
decline curves. Each of these has a separate 
mathematical form that is related to the second 
factor, which characterizes a decline curve, that 
is, the curvature. These types are referred to as: 
1. Constant-percentage or exponential 
decline. 
2. Hyperbolic decline. 
3. Harmonic decline. 
 
  
       
Figure 4 Exponential, Hyperbolic and Harmonic 
Decline Curve 
 
2.3.1 Exponential Decline: 
In the exponential decline, the well’s production 
data plots as a straight line on a semilog paper. 
The equation of the straight line on the semilog 
paper is given by:   
 
                q=qie-Dt           ……..(7) 
Where: 
q = well’s production rate at time t, SCF/day 
qi = well’s production rate at time 0, SCF/day 
D = nominal exponential decline rate, 1/day 
t = time, day 
 
 
2.3.2 Hyperbolic Decline: 
 
Alternatively, if the well’s production data 
plotted on a semilog paper concaves upward, 
then it is modeled with a hyperbolic decline. The 
equation of the hyperbolic decline is given by: 
          
               q=qi(1+bDit)-1/b ……..(8) 
 
Where: 
q = well’s production rate at time t, SCF/day 
qi = well’s production rate at time 0, SCF/day 
                    Figure 3: production rate vs time 
Page 968
  
 
Di = initial nominal exponential decline rate (t = 
0), 1/day 
b = hyperbolic exponent 
t = time, day 
 
2.3.3 Harmonic Decline : 
A special case of the hyperbolic decline is 
known as “harmonic decline”, where b is taken 
to be equal to 1. 
  
             
               q=qi(1+Dit)-1…………….(9) 
Where: 
q = well’s production rate at time t, SCF/day 
qi = well’s production rate at time 0, SCF/day 
Di = initial nominal exponential decline rate (t = 
0), 1/day 
b = hyperbolic exponent=1 
t = time, day 
 
Decline curve relationships are empirical, and 
rely on uniform, lengthy production periods. 
Decline curves are the most common means of 
forecasting production. They have many 
advantages such as: 
a) Data is easy to obtain, 
b) They are easy to plot, 
c) They yield results on a time basis, and 
d) They are easy to analyze 
 
3. CONCLUSION 
Reserve estimation is very important for a 
reserve to make decisions. Estimation provides 
the confidence about economical feasibility to 
produce from a reservoir; whether it is cost 
worthy or not. Here only a few common methods 
for dry gas reservoirs are discussed. Other 
methods like analogy, reservoir simulation are 
also used to estimate the reserve. Wet gas 
reservoirs and oil reservoirs can also be 
estimated by modified version of above methods.  
It should be noted that the total amount reserve 
may vary with respect to time due to 
accumulation or migration of gas. So reserve 
estimation should be done in a regular basis to 
have clear idea on current reserve. 
REFERENCES 
1. Lee, J. and Wattenbargar, R.A.(1996), 
Gas Reserve Estimation, SPE Textbook 
Series, Volume 5,  pp. 230-235 
2. Imam, B.(2005), Energy Resources of 
Bangladesh, University Grants 
Commission of Bangladesh, pp.62-66 
3. Dake, L.P.(1991), Fundamentals of 
reservoir engineering(twelfth edition), 
Elsevier,,Amsterdam. 
4. Craft, B.C. and Hawkins, 
M.F.(1991),Applied Petroleum 
Reservoir Engineering (second 
Edition),Prentice Hall, N.J 
5. Selley, R.C., Elements of Petroleum 
Geology(second edition), Academic 
Press, San Diego. pp. 291-297 
6. William, D. and Mccain, Jr., Petroleum 
Fluids(second Edition), Pennwell 
books, Tulsa,Oklahoma 
 
 
 
 
Page 969
 
  Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*Corresponding Author: M. Farhad Howladar  
E-mail: dmfh75@yahoo.com 
Comparable Analysis of Engineering Properties between Crushed 
Hardrock dust of Maddhyapara Granite Mine, Dinajpur and Natural 
Sand 
 
 
1Tareq-Uz-Zaman, 1M. Farhad Howladar*, 2Mushtaq Ahmed, 1M. Omar Faruque, 
1Golam Hossain  
1Dept. of Petroleum & Georesources Engineering, Shahjalal University of Science and 
Technology, Sylhet, Bangladesh 
2Dept. of Civil & Environmental Engineering, Shahjalal University of Science and Technology, 
Sylhet, Bangladesh 
 
 
This paper reports the experimental study undertaken to investigate some engineering properties of crushed 
hardrock dust of Maddhyapara Granite Mine (MGM), Dinajpur and natural sand. Engineering properties of 
these two materials have been compared to draw a conclusion for whether crushed hardrock dust can be used 
as an alternative of sand in construction work. The properties that were determined are fineness modulus, 
bulk Specific gravity, apparent specific gravity, absorption capacity, unit weight, percentage of voids and 
relative density. Results obtained indicate that all these properties have higher values for crushed hardrock 
dust of MGM than for natural sand. This has the effect of making the crushed hardrock dust relatively 
stronger fine aggregate than natural sand. 
 
Key words: Crushed hardrock dust; Sand; Engineering Properties 
 
1. INTRODUCTION 
 
Aggregates occupy 65 to 80% of the total volume 
of concrete and affect the fresh and hardened 
properties of concrete. In this paper, the focus will 
be placed on the characteristics of fine aggregate. 
Out of the total composition of aggregate, the fine 
aggregate consumes around 20 to 30% of the 
volume [2, 3]. Due to increase of construction 
activity, natural sand is becoming difficult to get 
and costly. The shortage of the resources of natural 
sand has opened the possibility for the use of quarry 
dust. Quarry dusts are by-product produced as a 
result of the aggregate crushing and production 
process. The utilization of by-products obtained as 
waste materials will be pronounced advantageous 
in the aspects of reduction in environmental load 
and waste management cost, reduction concrete 
production cost and enhancement in some 
properties of concrete. 
 
Crushed hardrock dust is produced from the 
production and crushing processes during quarrying 
activities in Maddhyapara Granite Mine. The 
handling and disposal of these crushed hardrock are 
some of the major problems facing the Mine. Now 
crushed hardrock dust is being used as fly ash in 
cement industry. But this does not consume 
sufficient amount of crushed hardrock dust 
produced in the mine. No research has been 
conducted to study the engineering properties of 
these crushed hardrock dust and the suitability of 
those properties to enable the crushed hardrock dust 
to be utilized in concrete mixes. The present study 
is an experimental study which attempts to 
investigate some engineering properties of crushed 
hardrock dust of MGM and natural sand and 
compare the properties of these two materials. 
Finally, a comparison between the crushed 
hardrock dust and natural sand will help out to draw 
a piece of advice for whether crushed hardrock dust 
can be used as an alternative of sand. 
 
2. OBJECTIVES 
 
The objectives of the study are to determine some 
engineering properties of crushed hardrock dust of 
MGM and natural sand and to discuss the 
suitability of these crushed hardrock dust as 
alternative material for sand in construction work. 
 
3. METHODOLOGY 
The properties of crushed hardrock dust and natural 
sand that were determined for this study are 
fineness modulus, bulk Specific gravity, apparent 
Page 970ISBN: 978-984-33-2140-4
  
specific gravity, absorption capacity, unit weight, 
percentage of voids and relative density.  
 
3.1 Fineness Modulus 
Fineness modulus was determined based on ASTM 
C 33 [4].  
 
3.2 Bulk Specific Gravity 
The Bulk Specific Gravity (BSG) was obtained 
based on the ASTM C 128 [4]. The principle by 
which this parameter is determined is the following. 
The material is placed in an oven for 24 hours at 
1000 C to drive off all absorbed moisture and then 
cooled to room temperature. The weight of the 
oven-dry material is measured. The material is then 
submerged in water for 24 hours and then taken to a 
Saturated Surface Dry (SSD) condition. At this 
point the weight of a picnometer filled with water 
should be known and a known weight of the 
material in SSD condition should then be placed in 
the picnometer. The weight of the picnometer with 
the SSD material and the water should be recorded 
in order to obtain the value of the volume of water 
displaced by the SSD material. The weight of the 
material in SSD condition divided by the volume of 
water that the SSD material displaces is the BSG in 
the SSD basis and the weight of the material in dry 
condition divided by the volume of water that the 
material displaces is the BSG in the oven-dry (O-D) 
basis. 
 
3.3 Apparent Specific Gravity 
The measurement of the Apparent Specific Gravity 
(ASG) is same as that of BSG except the weight of 
the picnometer with the oven-dry material and the 
water should be recorded in order to obtain the 
value of the volume of water displaced by the oven-
dry material. The weight of the material in oven-dry 
condition divided by the volume of water that the 
oven-dry material displaces is the ASG. 
 
3.4 Absorption Capacity 
The absorption capacity (AC) of the material is 
obtained from a sample in SSD condition. When 
the material is in SSD condition a known weight of 
the sample is placed in the oven for 24 hours at 
1000C. The weight difference as a percentage of the 
dry material is the absorption capacity. 
 
3.5 Unit Weight 
The test is performed in a container of known 
volume. The container is filled with oven-dried 
aggregates, in three layers of equal volume. Each 
layer is rodded 25 times and the top layer is then 
leveled off. The weight of the container plus its 
contents and the mass of the container alone were 
measured. The weight of the dry material divided 
by the volume of the container is known as the unit 
weight on a dry basis. The bulk density on a SSD 
basis is calculated taking into account the 
absorption capacity of the material as described by 
ASTM C 128. 
 
3.6 Percentage of Voids 
The percentage of voids in the aggregate was 
determined from the unit weight and bulk specific 
gravity (oven-dry basis) using the formula, 
% voids = 100[(S*W)-M]/(S*W) 
Where, 
M = unit weight of the aggregate 
S = bulk specific gravity (oven-dry basis) 
W = unit weight of water 
 
4. RESULTS AND DISCUSSION 
 
4.1 Gradation and Sieve analysis 
The aggregate gradation plays an important role on 
the fresh concrete properties. The sieve analysis of 
an aggregate gives a percentage of the material 
passing through an opening of a certain size. A 
representative sample tested will give the 
characteristics of the total amount of the aggregate 
to be used. 
 
From the sieve analysis of the fine aggregate a 
characteristic curve for the material and a number, 
known as the fineness modulus, will be obtained as 
described by ASTM C-33. The gradation curve will 
show the tendency of the material to be fine, coarse 
or deficient in a certain particle sizes [3]. The 
fineness modulus is a number represented by the 
sum of the cumulative percentages retained on the 
ASTM standard sieves number 4, 8, 16, 30, 50 and 
100. It is important to mention that the fineness 
modulus is not unique to a single gradation curve, 
i.e., the same fineness modulus could be obtained 
from different gradations. The fineness modulus by 
itself does not represent a gradation but its value 
can be used for the concrete mix design as stated in 
the ACI procedure. In figure 1, the gradations of the 
natural Sand and crushed hardrock dust of MGM 
are shown.  
 
The natural Sand remains below the coarse limit 
before the sieve number 100. From sieve number 
100 to sieve number 50 it remains in the middle of 
the fine and coarse limits established by ASTM. 
After sieve number 50 the natural Sand moves 
towards the finer limit and then crosses the finer 
limit established by ASTM. After sieve number 30 
it remains above the finer limit. 
 
The crushed hardrock dust of MGM remains above 
the finer limit from sieve number 200 to sieve 
number 50. After sieve number 50 it remains close 
to the coarse limit established by ASTM. However 
Page 971
  
after the sieve number 8 it moves towards the finer 
limit. 
 
 
 
Fig. 1: Gradations of natural sand and crushed    
hardrock dust of MGM according to ASTM C-33 
 
The amount of fines, percentage passing the #200 
sieve, for both of the materials is 0 percent. ASTM 
recommends the amount passing the #200 sieve for 
a concrete pavement application should be between 
1 and 3% as long as the material does not contain 
organic or deleterious impurities. Concrete mixes 
containing greater than 3% passing the #200 have 
exhibited diminished wearing resistance. It is 
important to mention that ASTM only gives 
recommendations and the gradations should fit the 
purpose of the project for which they will be used.  
 
The Fineness Modulus (FM) of the crushed 
hardrock dust of MGM is higher than that of the 
natural Sand. So the crushed hardrock dust of 
MGM is coarser than natural Sand. 
 
4.2 Bulk Specific Gravity, Apparent Specific 
Gravity, Absorption Capacity, Unit weight, 
Percentage of voids and Relative density 
Aggregate generally contain pore, both permeable 
and impermeable, for which specific gravity has to 
be carefully defined. With this specific gravity of 
each constituent known, its weight can be 
converted into solid volume and hence a theoretical 
yield of concrete per unit volume can be calculated. 
Specific gravity of aggregate is also required in 
calculating the compacting factor in connection 
with the workability measurements. 
 
Bulk specific gravity is defined as the ratio of the 
weight of the aggregate (oven-dry or saturated 
surface dry) to the weight of water occupying a 
volume equal to that of the solid excluding the 
impermeable pores. This is used for 1) calculation 
of the volume occupied by the aggregate in various 
mixtures containing aggregate on an absolute 
volume basis, 2) the computation of voids in 
aggregate and 3) the determination of moisture in 
aggregate. 
 
Apparent specific gravity is the ratio of the weight 
of the aggregate dried at oven at 100 to 1100C (212 
to 2300F) for 24 hours to the weight of water 
occupying a volume equal to that of the solid 
including the impermeable pores. This pertains to 
the relative density of the solid material making up 
the constituent particles not including the pore 
space within the particles that is accessible to water. 
 
Absorption values are used to calculate the change 
in the weight of an aggregate due to water absorbed 
in the pore spaces within the constituent particles, 
compared to the dry condition. For an aggregate 
that has been in contact with water and that has free 
moisture on the particle surfaces, the percentage of 
free moisture can be determined by deducting the 
absorption from the total moisture content. The 
absorption capacity is also used to make moisture 
corrections in order to maintain a consistent 
water/cement ratio between concrete mixes. 
 
Bulk specific gravity, apparent specific gravity, 
absorption capacity, unit weight, percentage of 
voids and relative density of crushed hardrock dust 
of MGM and natural sand are shown in table 1. 
 
Table 1.  Some engineering properties of crushed 
hardrock dust of MGM and natural sand 
 
Properties Crushed 
hardrock dust 
of MGM 
Natural sand 
BSG (SSD 
Basis) 
3.05 2.56 
BSG (O-D 
Basis) 
3.04 2.5 
ASG 3.08 2.67 
AC (%) 2.96 2.56 
Unit Weight 
(KN/m3) 
16.26 15.38 
Relative 
Density (%) 
50.29 34.81 
% Voids 45.38 37.15 
 
0.37548163050100200
0
10
20
30
40
50
60
70
80
90
100
ASTM SIEVE NUMBER
PE
R
C
E
N
TA
G
E
 P
A
SS
IN
G
Gradation According to ASTM C-33
 
 
ASTM Coarse
ASTM Fine
natural Sand
Crushed Hardrock of MGM
Fineness Modulus
natural sand = 2.23
crushed hardrock of
MGM = 2.613
Page 972
  
 
Fig. 2: Comparison of some engineering properties 
between crushed hardrock dust of MGM and 
natural sand 
 
When compared to the natural sand, the crushed 
hardrock dust used in this study exhibited higher 
bulk specific gravity, higher apparent specific 
gravity and also higher absorption capacity. It can 
be mentioned that there are no direct relationship 
between these properties and the strength and 
durability of concrete, but they might have minimal 
effects to the bond strength between cement paste 
and aggregate. 
 
The crushed hardrock dust of MGM has higher 
value for unit weight, relative density and 
percentage voids than the natural Sand. It is 
noticeable that both unit weight and percentage of 
voids of the crushed hardrock dust are larger than 
those of the Sand. Since the void content of the 
crushed hardrock dust of MGM is higher, there is a 
need for more paste to fill the voids. 
 
There is a noticeable difference between the 
particle shape and the surface characteristics of the 
crushed hardrock dust of MGM and natural sand. 
The sand particles are more rounded and smooth 
which is why the void content was measured lower 
than the crushed hardrock dust. The crushed 
hardrock dust has a more angular shape and micro 
roughness is revealed on the surface of the 
particles. 
 
The increased angularity and void content will also 
increase the water demand for a mix to obtain the 
same lump, but the mechanical properties of the 
material do not seem to be effected [1]. 
 
5. CONCLUSIONS 
Based on the results and discussion mentioned 
above, the following conclusion can be derived: 
 
The crushed hardrock dust of MGM is a relatively 
stronger fine aggregate when compared to the 
natural sand used in this study. Consequently, 
crushed hardrock dust if used as fine aggregate in 
concrete will increase strength of concrete. Thus, 
crushed hardrock dust of MGM can be used as 
alternative of sand in concrete. 
 
 
REFERENCES 
 
1. Kostmatka, S.H., and Parenese, W.C., “Design 
and Control of Concrete Mixtures”, Portland 
Cement Association, Skokie, IL, 1988. 
2. Mindess, S., J.F. Young and D. Darwin, 
“Concrete”, Prentice Hall, Upper Saddle River, 
NJ, 2003. 
3. Neville, AM, “Properties of Concrete”, (2000) 
fourth edition, Pearson education . 
4. Annual Book of ASTM Standards, (1996) 
Volume 04.02.  
 
0
10
20
30
40
50
Properties
V
al
ue
s
comparison between natural sand and crushed hardrock of MGM
 
 
natural sand
crushed hardrock of MGM
BSG(SSD
basis)
BSG(O-D
basis)
ASG AC(%) Unit
Weight
(KN/m3)
Relative
Density
(%)
% Voids
Page 973
 ENGINEERING CLASSIFICATION OF SHARI GHAT RIVER BED SAND AND 
PROSPECT OF IT’S UTILIZATION IN DIFFERENT CONSTRUCTION SECTORS 
A.S.M. Golam Hossain1, M. Farhad Howladar1, M. Saiful Islam2, M. Omar Faruque1 
& Tareq-Uz-Zaman1 
1Department of Petroleum & Geo-resources Engineering, 
ShahJalal University of Science and Technology, Sylhet, Bangladesh. 
2Department of Civil & Environmental  Engineering, 
Shah Jalal University of Science and Technology, Sylhet, Bangladesh. 
E-mail  Address: dmfh75@ yahoo.com 
 
ABSTRACT 
Sand is a natural resource can be used as an engineering material which plays an important role in 
engineering constructions. Generally sand is used as a fine aggregate in mortar, plaster, concrete and 
finishing works. It also used for filling under floor, basements. Sand should be pure silica (SiO2), but all 
types of sand are not suitable for such work. From this point of view, the present study assesses some 
engineering properties for understanding their suitability for construction works. The properties such as 
Fineness Modulus (FM), Specific Gravity, Silt & Clay content and Compressive Strength have been 
estimated in laboratory and the results revealed that the sand is best for mortar and concrete work and 
suitable for plastering and finishing work. Results also suggest that this sand can be used for filling up the 
roads and brick soling gap area. 
Keywords: River Bed Sand, Fineness Modulus (FM), Specific Gravity, Compressive Strength,   Utilization. 
 
1. INTRODUCTION 
Sand deposits are located mostly in the Sylhet 
area in Bangladesh. The studied area belonging to 
the Jaintapur Thana in Sylhet district that about 
45 km NNE direction of Sylhet town and is also 
about 189 km NNE of Dhaka. Shari river is 
located about 7 km from Jaintapur Thana parisad 
in the east direction. 
In the Shari river bed, vast amount of Sands will 
be deposited. This type of sands will be used in 
different construction sectors without any 
assessment.  
This studies aim that, proper utilization of sands 
in different construction sectors.  
Natural sand is available from local river beds or 
pits. An examination should be made on the 
fineness of the available sands. Based on this 
fineness, it should be considered to be used for 
the different sectors of construction. Sand is a 
loose, fragmented, naturally occurring material 
consisting of very small particles (fine to medium 
sized particles between 2 mm & 0.06 mm) of 
decomposed rocks, corals, or shells.  In 
concreting work it is usually termed as fine 
aggregate. 
Sand is form of silica (SiO2) and may be of 
argillaceous, siliceous or calcareous according to 
its composition. Sand is usually obtained from 
pits, shores, river beds, & seas. It mainly three 
kinds of sands in use: Pit Sand, River bed Sand & 
Sea Sand. Sand should be of pure Silica (SiO2). It 
should free from clay, silt, organic matter, shells 
& salts. Very good variety of sand is available in 
the districts of Dhaka, Mymensingh, Sylhet. 
Sand is available here and there, but all sand is 
not suitable for every sand related work. In this 
study, it is aimed that which sand are suitable for 
which purpose. It is preferable that sand should 
be washed before use in all engineering 
construction. 
Page 974ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
 2. METHODS 
In order to conduct this study steps like field 
observation, sample collection, analysis and 
laboratory test etc measures are considered. 
Methods for this investigation are composed of 
the following activities: 
2.1 Sample Collection 
Sample was collected from Shari Ghat river of 
Jaintapur. Disturebed samples are taken from 
river bed. After collecting the sample we perform 
various tests. For performing test, samples should 
have normal condition. As samples are collected 
the source, so it was not ready for test. At first it 
dried in room temperature for one week. 
2.2 Laboratory Test 
a) Sieve Analysis of Sand 
Sieve analysis is one of the oldest methods of size 
analysis and is accomplished by passing a known 
weight of sample material successively through 
fine sieve to determine the percentage weight in 
each size fraction (shown in figure 2.1)  
This test was performed to determine the 
percentage of different grain sizes within sands. 
Fineness Modulus (FM) is factor which is 
computed using the sieve analysis results. Lower 
FM indicates fine particle and Higher FM 
indicates coarse size particl
Fineness Modulus (FM) gets from an equation, 
ܯܨ =  [Cumulative % retained on standred ASTM sieves No.  4,   8,   16,    30,   50,   100]100  
b) Specific Gravity of Sand 
Specific gravity of the sand is defined as the ratio 
of the mass of a given volume of sands to the 
mass of an equal volume of water at 4⁰C. The 
specific gravity of sand is 2.65 – 2.68. The 
specific gravity is generally two types. Determine 
the specific gravity by Pycnometer method, 
shown in figure 2.2 Specific gravity depends on 
temperature so it has to be measured.
Calculate the specific gravity of the sands  
using the following formula; 
Specific gravity of sand, Gୗ = ୋ౐∗୛ో୛ోି(୛ాି୛ఽ)       
 
 
c) Compressive Strength Test 
Two types of test specimens are used in our 
country. This test methods covers determination 
of the compressive strength of Portland cement 
mortars , using 50 mm cube specimens. For 
making mortar sample same ratios are maintain 
for all type of sand particles and the ratios are 
water: cement: sand = 0.485: 1: 2.75 as a standard 
value but sometimes additional amount of water 
was applied to make the paste workable, shown 
in figure 2.3.  
The mortar sample is prepared following the 
standard procedure and released from the mould. 
It is placed at a bucket for curing then after the 
specific duration the mortar is taken out from the 
bucket and waited for half an hour for removing 
water and tested by the compression testing 
machine, shown in figure 3.4. The obtained result 
is analyzed and then discussion is prepared 
depending on the result obtained and field 
observant
 
3. RESULTS AND DISCUSSION 
3.1 Fineness Modulus of Shari Ghat River Bed Sand 
 
Fineness Modulus of fine aggregate is given tabulated form 
 
Where, 
WO = Mass of dry sample (sand) (gm) 
WA =Mass of empty clean pycnometer+ water (gm),  
WB = Mass of empty clean pycnometer+dry sand+ water (gm),  
GT = Specific gravity of water at temperature T⁰C,  
Temperature, T0 C =28 
 
Page 975
 Table 3.1: Fineness Modulus of fine aggregate 
 
Sieve size 
 
Standard 
Opening 
(mm)  
Material 
retained 
(gm) 
Percent of 
material 
retained 
(%) 
Cumulative 
Percent 
Retained 
(%) 
Percent 
finer 
Fineness 
Modulus 
(FM) 
No.4 4.75 0 0.0 0.0 100.0  
 
 
 
1.28 
No.8 2.36 1 0.1 0.1 99.9 
No.16 1.18 10 1.0 1.1 98.9 
No.30 0.60 38 3.8 4.9 95.1 
No.50 0.30 191 19.1 24.0 76.0 
No.100 0.15 743 74.3 98.3 1.7 
No.200 0.075 12 1.2 99.5 0.5 
Pan  5 0.5 100.0 0.0 
Total  1000    
 
Fineness Modulus (FM);  FM  = ଴ା.ଵାଵ.ଵାସ.ଽାଶସାଽ଼.ଷ
ଵ଴଴
  = 1.28     
From percent finer (%) and sieve size can draw particle size distribution curve or gradation curve of fine 
sand, shown in figure 3.1 
 
Figure 3.1: Gradation Curve of Shari Ghat River Sand (Fine) 
Fineness Modulus of medium aggregate is given tabulated form 
Table 3.2: Fineness Modulus of medium aggregate 
 
Sieve size 
 
Standard 
Opening 
(mm)  
Material 
retained 
(gm) 
Percent of 
material 
retained 
(%) 
Cumulative 
Percent 
Retained 
(%) 
Percent 
finer 
Fineness 
Modulus 
(FM) 
No.4 4.75 11 1.1 1.1 98.9  
 
 
 
2.94 
No.8 2.36 31 3.1 4.2 95.8 
No.16 1.18 284 28.4 32.6 67.4 
No.30 0.60 354 35.4 68.0 32.0 
No.50 0.30 205 20.5 88.5 11.5 
No.100 0.15 111 11.1 99.6 0.4 
No.200 0.075 3 0.3 99.9 0.1 
Pan  1 0.1 100.0 0.0 
Total  1000    
0
10
20
30
40
50
60
70
80
90
100
0.01 0.1 1 10
Pe
rc
en
t F
in
er
 (%
)
Sieve Size (mm)
Page 976
 Fineness Modulus (FM); FM = ଵ.ଵାସ.ଶାଷଶ.଺ା଺଼ା଼଼.ହାଽଽ.଺
ଵ଴଴
  = 2.94     
From percent finer (%) and sieve size can draw particle size distribution curve or gradation curve of medium 
sand, shown in figure 3.2 
 
Figure 3.2: Gradation Curve of Shari Ghat River Sand (Medium) 
 
From the experiment, Fineness Modulus of fine 
aggregate is 1.28 and Fineness Modulus of 
medium aggregate is 2.94. The Fineness Modulus 
(FM) range (1.24 – 2.94) of shari Ghat river bed 
sand is nearly similar to the FM range (2.0 – 2.6) 
of other area’s sand of Sylhet. The Fineness 
Modulus (FM) range of shari Ghat river bed sand 
compared with the different area in Bangladesh  
as  tabulated  form in  table 3.3
 
From the Gradation Curve, it is observed that        
this sand is not well graded and there is a gap  
grade between #4 to #100 sieve. In this sand 
all particle are similar size. 
 
Table 3.3: Compare of Fineness Modulus
3.2 Specific Gravity of Sand 
Specific Gravity of Fine aggregate                            Gୗ = ୋ౐∗୛ో୛ోି(୛ాି୛ఽ)     = 2.84 
Specific gravity of Fine sand at 280C is tabulated bellow: 
Table 3.4:  Specific gravity of Fine sand 
Observation 
No 
 
WP 
(gm) 
WO 
(gm) 
WPS 
(gm) 
WA 
(gm) 
WB 
(gm) 
GT 
(gm) 
GS 
(gm) 
Average 
Value of  GS 
1 274 10 284 1265 1271.5 0.9963 2.84  
2.88 2 274 10 284 1265 1272 0.9963 3.32 
3 274 10 284 1265 1271 0.9963 2.49 
0
10
20
30
40
50
60
70
80
90
100
0.01 0.1 1 10
Pe
rc
en
t F
in
er
 (%
)
Sieve Size (mm)
Location of Availability F.M. (Range) 
Sylhet area 2.0 – 2.6 
Dhaka  area 1.2 – 1.6 
Comilla area 1.3 – 1.5 
Mymensingh area 1.5 – 1.8 
Khulna area 1.2 – 1.5 
Bogra area 1.3 – 1.4 
Shari Ghat River 1.24 – 2.94 
Page 977
Specific Gravity of medium aggregate,     = 2.49 
                                
Specific gravity of Medium sand at 280C is tabulated bellow: 
Table 3.5:  Specific gravity of Medium sand 
Observation 
No 
 
WP 
(gm) 
WO 
(gm) 
WPS 
(gm) 
WA 
(gm) 
WB 
(gm) 
GT 
(gm) 
GS 
(gm) 
Average 
Value of  GS 
1 274 10 284 1265 1271 0.9963 2.49  
2.51 2 274 10 284 1265 1270.5 0.9963 2.21 
3 274 10 284 1265 1271.5 0.9963 2.84 
 
The Specific gravity of Fine sand is 2.88 and 
Specific gravity of Medium sand is 2.51. The 
Specific gravity of sand decreasing from fine to 
medium aggregate. The average specific gravity 
of Shari Ghat river bed sand is 2.695 
3.3 Compressive Strength of Sand–Cement Mortar  
The compressive strength of mortar with increasing curing period is tabulated bellow: 
Table 3.6: Compressive Strength of Sand–Cement Mortar 
 
Age (days) 
 
Specimen No. 
Specimen area (mm2) Compressive 
Strength (MPa) 
Average Value 
(MPa) 
 
3 
1 50 × 50 10.74  
10.65 2 50 × 50 11.18 
3 50 × 50 10.03 
 
7 
1 50 × 50 12.70  
12.28 2 50 × 50 11.98 
3 50 × 50 12.18 
 
28 
1 50 × 50 19.42  
19.48 2 50 × 50 21.10 
3 50 × 50 17.93 
 
The Experimental compressive strength 
compared with the standard requirement of 
minimum compressive strength. The effect of age 
on compressive strength of sand is shown in 
figure 3.3 It is shown that, the experimental 
compressive strength of sand is substantial 
deviated from the standard value. This deviation 
takes place due to impurities of sand, lack of lab 
facilities, experimental error, Instrumental error 
and effect of Portland cement and so on.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure 3.3: Effect of age on compressive strength 
0
500
1000
1500
2000
2500
3000
3500
4000
4500
0 5 10 15 20 25 30
Co
m
pr
es
si
ve
 S
tr
en
gt
h,
 p
si
Age, day
Measured Standard
Page 978
 3.3 Utilization Prospect 
This studies aim that, proper utilization of sands 
in different construction sectors. Sand size 
between 4.75mm and 0.15mm is called as fine 
aggregate. It is used for making concrete, mortar 
and plaster. It is also used for filling under floor, 
basements. It is also better to use for fill up the 
roads and brick soling gap area. Natural sand is 
available from local river beds or pits. An 
examination should be made on the fineness of 
the available sands. Based on this fineness, it 
should be considered to be used for the different 
sectors of construction such as plastering and 
finishing works, Mortar, Concrete & Filling sand. 
River bed Sand generally contains earthly 
impurities like gravels, pebbles etc. These 
impurities should be screened and washed before 
the sand is used. 
  
4. CONCLUSIONS 
It is necessary to use perfect sand for any purpose 
with due properties. From the study it is evident 
that fine to medium sand found in Shari Ghat 
river bed, which is good for plastering and 
finishing work. It is most suitable for fill up the 
roads and brick soling gap area. It is also better to 
use for Mortar and Concrete work. For 
stabilization purpose cement can be used as 
stabilizing agent. For economical purposes the 
percentage of cement should be used as much 
strength as required for construction. The 
compressive strength increases with the curing 
period.  
 
 REFERENCES 
1. E. R. Latif (2007) “ Engineering 
Materials ” Children & Earth, Dhaka, 
Page: 207 – 226 
2. Aziz, M. A. (1995) “ Engineering 
Materials ” Z & Z Computer & Printers, 
Dhaka,        Page: 95 – 102 & 122 
3. P. C. Varghese (2005) “ Building 
Material ” Meenakshi Art Printers, delhi, 
Page: 55 – 61 
4. Howard S. Peavey, Donald R. Rowe, 
George Tchobanoglous (1985) “ 
Environmental Engineering ” McGraw-
hill book CO, Singapore, Page: 177 
5. http://pubs.usgs.gov/of/2006/1046/htmld
oes/images/chart.gif 
6. IS 383 – 1970: Specification for Coarse 
and Fine Aggregate from Natural 
Sources for Concrete. 
7. IS 1542 – 1992: Sand for Plaster-
Specifications. 
8. IS 2116 – 1980: Specification for Sand 
for Masonry Mortar 
 
 
 
 
 
 
 
 
 
 
 
 
Page 979
 E-mail: dmfh75@yahoo.com 
 
FLOWING GAS MATERIAL BALANCE: A CASE STUDY OF TITAS 
GAS FIELD 
 
Sonia Aziz Chowdhury, Dr. M. Farhad Howladar and Mohammed Omar Faruque 
Department of Petroleum and Georesources Engineering, 
Shahjalal University of Science and Technology, Sylhet-3114. 
E-mail: dmfh75@yahoo.com 
 
ABSTRACT 
Reserve estimation is the most common and important task in evaluating an oil or gas field. Among several 
methods of reserve estimation, a most recent method namely Flowing Material Balance (FMB) is quick and 
easy to use in determining the original gas-in-place (OGIP). Traditional material balance plot for gas pools 
requires fully built-up reservoir pressures, obtained by shutting in the wells. Titas gas field is so far the 
largest gas field of Bangladesh. It is important to estimate its reserve precisely.  Among all other Petrobangla 
operated fields, Titas gas field lacks of shut-in pressure data records time to time. The estimates obtained in 
this paper are quite reasonable compared with other estimates done for this field, and hence proving the 
reliability of FMB analysis as a quick estimating tool. 
 
Key words: Flowing Material Balance, Titas gas field, reserve estimation, original gas-in-place, well 
interference. 
 
1. INTRODUCTION 
 
The determination of gas reserves is a fundamental 
calculation in reservoir engineering. Because it is 
important for the development of a production 
strategy, design of facilities, contracts and valuation 
of the reserves. Classically, reserves are estimated 
in three ways: volumetric, material balance and 
production decline. It is always commendable to do 
the estimation with as less data as possible. For 
traditional material balance, the well would be shut-
in at several points along its producing life and let 
the pressure in the reservoir to stabilize. Then the 
average reservoir pressure is obtained for each 
point from a properly conducted buildup test and 
interpretation. The duration of the shut-in is often 
not long enough to directly measure current average 
reservoir pressure. As a result, problems with 
testing and interpretation comprise some of the key 
causes of erratic pressure data often observed in 
traditional material balance plots. But in FMB there 
is no need to shutting in the well. Also it requires 
less data to accomplish the estimation than 
traditional analysis. In this paper FMB is used to 
estimate reserves of Titas gas field, Bangladesh. 
 
Titas gas field in Brahmanbaria district was 
discovered in 1962 by Pakistan Shell Oil Company 
(PSOC) by the exploratory well Titas-1. The gas 
field is operated by Bangladesh Gas Field Company 
limited. Following the drilling of three more wells, it 
was put into production in 1968. Titas field 
comprises three major reservoir sands namely: A, B 
and C. Three wells are producing from the B and C 
Sands and the rest in A Sands. At present, 15 wells 
are producing an average rate of about 396MMscf/d. 
The major objectives of this paper are to determine 
original gas-in-place (OGIP) of Titas gas field and 
to verify the strength of Flowing Gas Material 
Balance as a reserve estimation tool. 
 
2. METHODS 
 
2.1. Flowing Material Balance 
 
The Flowing Material Balance (FMB) uses the 
concept of stabilized or "pseudo-steady-state" flow 
to evaluate total in-place fluid volumes. In a 
conventional material-balance calculation, reservoir 
pressure is measured or extrapolated based on 
stabilized shut-in pressures at the well. In a flowing 
situation, the average reservoir pressure clearly 
cannot be measured. However, in a stabilized flow 
situation, there is very close connectivity between 
well flowing pressures (which can be measured) 
and the average reservoir pressure. Fig. 1 shows 
how these pressures are related. 
 
The figure illustrates that the pressure drop 
measured at the wellbore while the well is flowing 
at a constant rate is the same as the pressure drop 
that would be observed anywhere in the reservoir, 
Page 980
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
 including the location which represents average 
reservoir pressure. This is true only if pseudo-
steady-state conditions are present (all boundaries 
have been reached). 
 
 
 
Fig. 1: Pseudo-steady state condition showing 
constant pressure drop. (After L. Matter and R. 
McNeil) 
 
2.1.1. Constant Rate Flowing P/Z Plot for Gas: 
The p/z plot is a very useful tool for estimating 
Original Gas in Place of gas reservoirs. The 
conventional p/z plot uses the extrapolated straight-
line trend of measured shut-in pressures (for gas 
reservoirs) to predict OGIP.  The same can be done 
with flowing pressures, provided that the pseudo-
steady-state assumption is valid (i.e., constant rate 
boundary-dominated flow).  Fig. 2 shows how this 
is done. 
 
 
 
Fig. 2: The Flowing P/Z Plot- Constant Rate 
Production. (After L. Matter and R. McNeil) 
 
The above analysis is (Fig. 2) created by plotting 
measured flowing pressures (as p/z points) on a 
graph vs. produced gas.  The slope of the resulting 
line of best fit should be the same as the slope of 
the conventional p/z line.  Thus, the existing line 
needs only to be "shifted" upwards so that it falls 
though the initial p/z point.  The equation that 
describes this graphical procedure is as follows: 
 
   (1) 
 
Where,  
   = gas pseudo-pressure (which can be converted 
to p/z) 
PPwf = Pseudo gas bottom hole pressure 
q  = Gas flow rate 
 
 (2) 
 
Where, 
T = Formation temperature 
k = Formation Permeability 
h = Net thickness 
re = Reservoir radius 
rwa = Adjusted wellbore radius 
 
 represents the pressure loss due to the steady-
state inflow of gas, and is assumed to be constant 
over time.  The above definition applies to a 
vertical well in the center of a circular reservoir. 
 
Thus, for a constant rate system, equation (1) 
suggests a constant difference between average 
reservoir p/z and flowing p/z. 
 
2.1.2. Variable Rate Flowing P/Z Plot: 
Unfortunately most gas wells do not have extended 
periods of constant rate production.  It is for general 
gas production (variable rate/variable pressure) 
profiles that we require a reliable flowing p/z 
plot.  This can be accomplished with only a slight 
modification to the constant rate flowing p/z 
analysis. 
 
For a variable rate system, equation (1) clearly 
shows that the difference between reservoir p/z and 
flowing p/z is not constant, but a function of flow 
rate.  Since the flow rate is known, we need only to 
determine the value of bpss, using some independent 
method.  Note that the value of bpss did not have to 
be explicitly determined for the constant rate case 
because the total value of "q bpss" (the product of 
flow rate and bpss) is determined graphically. 
 
One way to obtain a reliable estimate of bpss is to 
plot the production and flowing pressure data in the 
following manner (Fig. 3). 
 
 
Fig. 3: bpss estimation for variable plot. 
 
Page 981
 The straight-line portion of this graph represents 
boundary dominated flow, and the y-intercept is 
bpss.  This value of bpss may then be used in equation 
(1) to calculate the average reservoir 
pressure.  Note that the value of bpss is always 
subject to interpretation as it depends on proper 
identification of the stabilized (straight-line) section 
of the above graph. 
 
2.1.3. Modified Agarwal-Gardner Analysis: An 
alternative to the flowing p/z plot is the Normalized 
Rate/Normalized Cumulative analysis.  The 
normalized rate approach applies to both oil and 
gas reservoirs, and works for constant or variable 
rate systems.  Its advantage is its flexibility and 
ease of use.  Its primary drawback is that the 
resulting analysis plot is not as intuitive as that of 
the flowing p/z. 
 
The procedure is similar to the pseudo-steady-state 
approach, but involves plotting the inverse of the 
pseudo-steady-state equation, so that a declining 
trend is produced. 
 
The equation developed for gas is, 
 
 (3) 
 
2.1.4. Calculation of Abandonment Pressure: 
From the bottomhole flowing pressure at the 
projected abandonment conditions the 
abandonment pressure (average reservoir pressure) 
is calculated as follows: 
 
 (4) 
Where, C = Units conversion constant (1.417e6 for 
field units) 
 
3. RESULTS AND DISCUSSION 
 
3.1. Single-well Analysis 
 
In this paper FMB analysis for individual wells is 
done first to show the results would appear if the 
interference of other wells is not considered. The 
production data upto May, 2007 is used for the 
analysis. The pressure data available is the flowing 
well head pressure which is converted to flowing 
bottomhole pressure using Gray correlation with 
appropriate wellbore data. In the analysis it is 
assumed that the flow is constant rate boundary-
dominated. The estimates are shown in Table.1 and 
some selected corresponding plots are shown in 
Fig. 4 and Fig. 5. 
 
The plots show the interference of other wells in the 
well being examined. The lower portion of the data 
points do not follow the straight line trend showing 
that the effect of other wells in the vicinity of the 
well being considered. Thus, the interference effect 
felt for another producing well should be 
considered to avoid overestimation or 
underestimation of OGIP from material balance 
methods. 
 
The analysis shows that the total reserve at Titas A 
Sand is 17.08 Tcf and ultimate recovery is 11.96 
Tcf for a recovery factor of 70%. The result seems 
to be overpredictive because the straight lines 
drawn in Fig. 4 and Fig. 5 to find OGIP have to be 
forced to follow the initial trend of the data points. 
 
Table. 1: OGIP from single-well analysis. 
 
Well No. OGIP (Bscf) 
Recovery 
Factor 
% 
Expected 
Ultimate 
Recovery 
(EUR), 
(Bscf) 
Titas-1 4484.16 70 3138.912 
Titas-2 2776.48 70 1943.536 
Titas-3 1511.92 70 1058.344 
Titas-4 1432.43 70 1002.701 
Titas-5 1553.04 70 1087.128 
Titas-6 989.13 70 692.391 
Titas-7 988.72 70 692.104 
Titas-11 1326.37 70 928.459 
Titas-12 416.22 70 291.354 
Titas-13 592.31 70 414.617 
Titas-14 511.44 70 358.008 
Titas-15 235.52 70 164.864 
Titas-16 264.82 70 185.374 
Total 17082.56  11957.79 
 
 
 
Fig. 4: OGIP of Titas-1 (single well analysis). 
Page 982
  
 
Fig. 5: OGIP of Titas-2 (single well analysis). 
 
3.2. Multi-well Analysis 
 
Multi-well FMB analysis is done to consider the 
interference of all wells to the older one. As Titas-1 
& Titas-2 both started production at about same 
time these wells are considered for multi-well 
analysis. The estimates are shown in Table. 2 and 
the corresponding plots are shown in Fig. 6 and Fig. 
7 
 
Beside the calculation by graphical FMB, Modified 
Agarwal-Gardner analysis is also used to estimate 
OGIP. The plots shows quite scattered data points 
as stated as its primary drawback, but it still can be 
used with a best fit line through the data points. 
Both methods give same result. 
 
In this paper the abandonment average pressure is 
also predicted assuming the abandonment flow rate 
of 1 MMscfd. The result is included in Table. 2. 
 
For analysis with Titas-1 the OGIP is 8.22 Tcf and 
Ultimate Recovery is 5.76 Tcf for a Recovery 
Factor of 70%. From analysis of Titas-2 the OGIP 
is 12.9 Tcf and Ultimate Recovery is 9.05 Tcf for a 
Recovery Factor of 70%. 
 
Table-2: OGIP from multi-well analysis. 
 
Well 
No. 
OGIP 
(Bscf) 
Expected 
Ultimate 
Recovery 
(EUR), 
(Bscf) 
Abandonment 
Pressure, Pab 
(Psia) 
Titas-1 8223.27 5756.29 864.4 
Titas-2 12922.2 9045.567 840.5 
 
 
 
Fig. 6: OGIP from Titas-1 (multi-well analysis). 
 
 
 
Fig. 7: OGIP from Titas-2 (multi-well analysis). 
 
The results obtained from above analysis shows 
quite reasonable estimate of gas reserves at Titas 
Gas Field. Different estimates obtained from multi-
well analysis (OGIP- 8.22 Tcf from Titas-1 and 
12.9 Tcf from Titas-2) are due to the difference in 
pressure decline trend of different wells (Titas-1 & 
Titas-2). This is due to the heterogeneity of 
reservoir which indicates that a rigorous analysis 
should be done at Titas Gas Field to find actual 
reserve and ultimate recovery. 
 
The single-well analysis shows quite erroneous 
result (17.08 Tcf) with respect to other estimates. 
The discrepancy arises due to the interference of 
wells in pressure decline trend. 
 
4. CONCLUSION 
 
In normal condition, production wells are not shut 
down usually. This constraints leads to a problem 
of accumulating sufficient representative shut-in 
pressure data calculate OGIP by traditional material 
balance method. The flowing material balance 
method presented in this paper is quite reasonable 
to use in such condition. However, this paper do not 
deny the importance of regular updating of the 
reserve estimation using different methods such as- 
Page 983
  
traditional material balance, type curve analysis and 
reservoir simulation in accordance with the added 
information gathered from various aspects of 
geophysical, geological and production phenomena. 
But FMB for both single-well and multiple well 
analyses can be helpful whenever the production 
data is insufficient to perform other methods with 
better accuracy. 
 
REFERENCES 
 
1. Dake, L. P., Fundamentals of Reservoir 
Engineering, Elsevier Science Publishers, 
Amsterdem (1978), 144. 
2. Imam B., Energy resources of Bangladesh. 
3. Matter L. and Mcneil R., The “Flowing” 
Gas Material Balance, JCPT (1998), 37, 
NO.2, 52. 
 
Page 984
  
* Corresponding Author: Mohammad Islam Miah 
E-mail: islampge@yahoo.com   
FORMATION WATER RESISTIVITY PREDICTION OF TITAS GAS 
FIELD USING SELF-POTENTIAL LOG DATA, BANGLADESH 
 
 Mohammad Islam Miah 1*, M. Farhad Howladar 1, Mohammed Omar Faruque 1 
and Md. Bodruddoza Mia 2 
 
1Department of Petroleum and Georesources Engineering 
Shahjalal University of Science and Technology, Sylhet-3114, Bangladesh 
2Department of Geology, Dhaka University, Bangladesh 
E-mail: dmfh75@yahoo.com, islampge@yahoo.com 
 
The Titas gas field is the biggest gas field in Bangladesh which lies in the south central part of the Surma 
Basin. This paper shows how to predict the formation water resistivity from Self-Potential (SP) wireline log 
data. The formation water resistivity is the most important rock fluid properties for saturation (water or hy-
drocarbon) estimation, Petrophysical analysis and Formation evaluation in the Petroleum field. The geo-
thermal gradient is 0.937 0F per 100 feet following surface temperature at 77 0F. The average formation tem-
perature is 159.18 0F of A2 gas sand based on log data. The average formation water resistivity is 0.1174 
ohm-meter of A2 gas sand based on SP log which implies formation water resistivity value is a slight lesser 
than the value estimated made by Reservoir Management Project-2 of Petrobangla (2009). This estimated 
result is reliable for calculating water or hydrocarbon saturation and formation evaluation for A2 gas sand of 
Titas gas field. 
 
Key Words: Titas Gas Field; Geothermal Gradient; Formation Temperature; Self-Potential Log; Formation 
Water Resistivity. 
 
1. INTRODUCTION 
 
The Titas gas field is situated in Brahmanbaria 
district in the vicinity of Brahmanbaria town 
about 4 km north of Brahmanbaria town and 96 
km ENE of Dhaka which is belonging to the 
south central part of the Surma Basin, and on the 
western margin of the Tripura high [8]. 
 
Formation water, sometimes called connate water 
is the water, uncontaminated by drilling mud that 
saturates the porous formation rock. The resistivi-
ty of this formation water (Rw) is important pa-
rameters since it is required for the calculation of 
saturation (water or hydrocarbon) from basic re-
sistivity logs. There are several sources for for-
mation water resistivity information which in-
cludes SP curve, chemical analysis, water cata-
logs, various resistivity-porosity computations 
and cross plots [9]. 
 
Interkomp Kanata Management (IKM) [4] studied 
about Geological, Geophysical and Petrophysical 
Analysis of the Titas Gas Field in December, 
1991 based on combined evidence of seismic 
data, well data and log data. Petrobangla also 
studied about Petrophysical analysis of Titas gas 
field based on Petro Log software in 2009, Ban-
gladesh [7].   
 
2. OBJECTIVES 
 
The objectives of the present study are to predict 
the formation water resistivity with self-potential 
(SP) log from field.  
 
3. GEOLOGYCAL STRUCTURE  
 
The Titas Field is an elongate asymmetrical anti-
cline with a simple four ways dip closure. The 
structural trend main axis lies S-N, with a broader 
northern nose and steeper eastern flank. The 
structure lies on the western margin of the Chit-
tagong-Tripura folded belt in the south central 
part of the Surma Basin. The maximum flank dip 
to the east is 120 and that to the west is 60. The 
dip is much gentler in the north-south direction at 
30 and indicates stronger compression and uplift. 
The structure was first mapped by Shell in 1960 
Page 985ISBN: 978-984-33-2140-4
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
  
with a single fold seismic grid. No faults were 
observed from the 2D seismic data over the Titas 
gas field and its vicinity [8]. The major gas sand of 
A-group is A2 sand (Figure-1). 
 
 
 
Fig. 1: Cross-sectional view of A2 gas sand (S-N 
direction) (Source: Reservoir and Data Manage-
ment Division, Petrobangla). 
 
4. MATERIALS AND METHODOLOGY 
 
The Methodology includes both manual interpre-
tation of the available log data and formula fol-
lowing standard rules and practices used in the oil 
and gas industry of the world.  
 
There are 16 wells drilled so far in Titas structure 
but this study selected only one well namely Ti-
tas-11 (Fig. 1) because of the availability of all 
necessary data for calculating formation water 
resistivity of this field. The available data are 
Caliper Log, Gamma Ray, SP log, Compensated 
Neutron and Density logs, Sonic Log and Resis-
tivity Logs.  
 
4.1 Data Quality and Modification 
 
The quality of log data of studied well is good but 
some of the paper prints are difficult to under-
stand. In well number 11, Caliper log shows bo-
rehole caving and washout is absence within sand 
zone. Mud-cake is so small which is negligible to 
count at the following depths: 8710-8784 feet and 
8792-8904 feet. No environmental corrections 
have been applied in the value of Gamma Ray 
and SP logs. 
 
4.2 Geothermal Gradient 
 
Geothermal gradient has been calculated as the 
following equation [6]: 
Gg = [{(BHT-Ts)/TD}×100] where BHT is the 
Bottom Hole Temperature in degree Fahrenheit, 
Ts is the Surface (ambient) Temperature in degree 
Fahrenheit and TD is the Total Depth in feet. 
 
4.3 Formation Temperature 
 
Formation Temperature (Tf) has been estimated 
as the following equation [1]: Tf = [Ts+ (Gg/100)]. 
 
4.4 Formation Water Resistivity 
 
Formation water resistivity (Rw) has been calcu-
lated using SP log as the following steps [2]:  
Step-1: Estimation of formation temperature (Tf), 
Step-2: Converting from Pseudo-Self Potential 
(PSS) to Static Self Potential (SSP) using SP cor-
rection factor, 
Step-3: Estimation of Rweq/Rmfeq from Schlum-
berger nomograph chart SP-1, 
Step-4: Determination of equivalent formation 
water resistivity (Rmfeq) from nomograph, 
Step-4: Estimation of Rweq from nomograph and  
Step-5: Correcting from Rweq to Rw at formation 
temperature from (Schlumberger) chart SP-2. 
 
5. RESULTS OF ANALYZED DATA 
AND DISCUSSIONS 
 
Petrophysical zonation has been used based on 
the log responses especially on Gamma Ray log 
response throughout the A2 gas sand.  Shale and 
sand zone have been identified with respect to 
Gamma Ray response and SP shale baseline (well 
no. 11) from 9300 feet to 9530 feet which indi-
cates SP value is 0 mV. High GR response and 
positive deflection of SP log from shale base line 
indicates the shale or clay zone. Also, Low GR 
response and negative deflection of SP log from 
shale base line indicates the clean sand and/shale 
sand zone. The Top and Base of the A2 gas sand 
are 8698 ft and 8904 ft respectively at measured 
depth. The surface temperature (Ts) has been used 
77 0F. The Bottom Hole Temperature (BHT) and 
Total Depth (TD) have been used 77 degree 
Fahrenheit and 10456 feet, respectively from log 
header. Geothermal gradient of the studied well is 
determined and shown in Table-1. From the anal-
ysis it is found that well no.11 shows the geo-
thermal gradient of 0.937 0F/100 feet. The forma-
tion temperature ranges from 158.58 to 160.05 0F. 
The equivalent formation water resistivity (Rweq) 
estimated from Schlumberger nomograph chart 
[10] SP-1 (Fig.2).Then, formation water resistivity 
(Rw) calculated from chart SP-2 at formation 
temperature ranges from 0.09 to 0.118 ohm-m. 
The average formation water resistivity is 0.1174 
ohm-m. A detailed result shows in Table-2. 
 
 
 
 
T-11 
A2 gas sand 
Page 986
  
Table-1: Geothermal gradient and formation tem-
perature of A2 gas sand. 
 
A2 
sand 
sub-
zone  
Depth 
Interval 
(feet) 
Average 
formation 
depth, 
feet 
Formation 
temperature 
(Tf) 0F 
1 8698-8710 8704 158.58 
2 8710-8732 8721 158.74 
3 8732-8784 8758 159.09 
4 8792-8800 8796 159.44 
5 8818-8904 8861 160.05 
 
 
 
Fig. 2: Rweq determination from SSP (mV) 
(Schlumberger well service chart, 1998) 
 
Table-2: Formation water resistivity (Rw) predic-
tion from SP log at formation temperature. 
 
Sand 
sub-
zone 
PSP 
(mV) 
SSP 
(mV) 
Formation resistivity 
(ohm-m) from nomo-
graph SP-1 and SP-2. 
Rmfe/
Rweq 
Rweq Rw 
1 -38 -57 4.9 0.098 0.113 
2 -34 -51 4.2 0.084 0.095 
3 -39 -58.5 5.1 0.100 0.118 
4 -35 -52.5 4.3 0.090 0.111 
5 -45 -67.5 6.4 0.132 0.150 
 
Formation water resistivity varies with respect to 
Self-Potential log responses and formation tem-
perature. In order to convert PSP to SSP, a cor-
rection factor 1.5 has been used which values 
may be changed with respect to invasion diameter 
and true resistivity correction for sub-zones of A2 
gas sand. 
 
 
 
 
Fig.3: Rw versus A2 sand sub zones. 
 
By SP method, based on SP responses, the calcu-
lated Rw is slightly lower than the Inverse Arc-
hie’s method (Rwa) [5] and estimation made by 
Reservoir Management Project-2, Petrobangla 
(2009a) [7]. 
 
 
6. CONCLUSIONS  
 
The estimated geothermal gradient can be used to 
calculate the formation temperature at any sub-
surface depth in this field. The predicted Rw val-
ue is reliable for calculating water or hydrocarbon 
saturation and formation evaluation for A2 gas 
sand of Titas gas field. 
 
REFERENCES 
 
1. Asquith, G. B., (1982), Basic well log 
analysis for geologists, American Asso-
ciation of Petroleum Geologists, Tulsa, 
Oklahoma. 
2. Bassiouni, Z., (1994), Theory, Mea-
surement, and Interpretation of Well 
Logs, First Printing, Henry L. Doherty 
Memorial Fund of AIME, SPE, Richard-
son.  
3. Crain E. R., (1986), The Log Analysis 
Handbook, Volume-1, Quantitative Log 
Analysis Methods, Penn Well Publish-
ing Company, Tulsa, Oklahoma. 
4. Interkomp Kanata Management (IKM), 
(1991), Gas Field Appraisal Project: 
Geological, Geophysical and Petrophys-
ical Report, Petrobangla, Dhaka, Ban-
gladesh. 
 
0.08
0.09
0.1
0.11
0.12
0.13
0.14
0.15
0.16
1 3 5
Fo
rm
at
io
n 
w
at
er
 re
si
st
iv
it
y,
 R
w
A2 sand sub-zone
Rw 
(o…
Rweq 
Page 987
  
 
5. Miah, Mohammad Islam, (2010), For-
mation Evaluation and Volumetric Re-
serve Estimation of A2 Gas Sand of Ti-
tas Gas Field, B. Sc. (Engg.) Thesis, De-
partment of PGE, SUST, Sylhet, Ban-
gladesh (Unpublished). 
6. Open hole log analysis notes, HLS Asia 
Limited, 2008. 
7. RPS Energy/ Reservoir Management 
Project (RMP)-2, (2009a), Titas Petro-
physical Report, Petrobangla, Bangla-
desh. 
8. RPS Energy/ Reservoir Management 
Project (RMP)-2, (2009b), Titas Geolog-
ical Study, Petrobangla, Bangladesh. 
9. Schlumberger, (1998a), Log Interpreta-
tion Principles/Applications, Seventh 
printing, Houston, Texas. 
10.  Schlumberger Well Services, (1998b), 
Log Interpretation Charts, Houston, 
Texas. 
 
Page 988
*Corresponding Author: Md. Mizanur Rahman 
E-mail: mizanurpe@yahoo.com 
MODELING AND ANALYSING PRESSURE BUILDUP DATA OF 
KAILASTILLA GAS FIELD (WELL NO. KTL-01 AND KTL-02) 
 
Md. Mizanur Rahman*, Arifur Rahman, Md. Jakaria, Mohammad Shahedul Hossain 
Department of Petroleum & Georesources Engineering 
Shahjalal University of Science and Technology, Sylhet-3114, Bangladesh 
Mobile: +88-01918766889 
E-mail: mizanurpe@yahoo.com 
 
ABSTRACT 
The vertical model simulates the pressure response in a vertical well within a rectangular shaped reservoir with 
homogeneous characteristics. The main objectives of this work were to estimate the reservoir parameters and 
construct a classical configuration for a dynamic reservoir system by history matching with a vertical model. For 
this study a homogeneous, single phase, rectangular shaped gas reservoir with vertical well is selected. At first 
the pressure transient data is analyzed and reservoir parameters-permeability, skin factor, average pressure, 
wellbore storage coefficient, reservoir drainage extent are estimated. To estimate these parameters, the 
deliverability test and buildup test (MBH) are used based on pressure transient data and production data. Then, 
the estimated parameters are matched by vertical modeling. Finally, type curves are used to validate these 
parameters. 
Key words: Pressure transient test, Vertical modeling, Type curve, Skin factor and wellbore storage, Reservoir 
configuration. 
1. INTRODUCTION 
Modeling is the process of history matching pressure 
transient data based on a mathematical model.  In 
order to optimize a development strategy for an oil or 
gas field, it is assumed a reservoir model is capable of 
predicting the dynamic behavior of the field in terms 
of production rate and fluid recovery. Such a model is 
constructed using geological, geophysical and well 
data. The necessary parameters are obtained from 
direct measurements (cores, cuttings, formation fluid 
samples, etc.) and from interpreted data (surface 
seismic, well logs, well tests, PVT analysis, etc.). 
While seismic data and well logs provide a static 
description of the reservoir, only well test data 
reflects information on dynamic reservoir response. 
The well test data is therefore a key element in the 
reservoir model construction1. 
  
Interpretation of these data leads to individual 
"models" (what the geophysicist, the petro-physicist 
and well analyst think the reservoir looks like). A 
brief understanding of the fundamental aspects of 
well test analysis is necessary in order to incorporate 
dynamic well test data into the reservoir model and it 
is the job of the reservoir engineer to incorporate 
these individual models into a cohesive reservoir 
model. In the initial phase of well tests, pressure 
measurements are dominated by wellbore storage 
effects.  
Page 989
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
In this paper, a simple model is developed that can 
explain the measured well test data. The model gives 
a rather simplified and idealistic view of the reservoir, 
characterized by: 
 
 Isotropic and homogenous reservoir volume, 
 Constant porosity, - absolute permeability, - 
viscosity and - reservoir height (reservoir 
thickness) 
 Test production with relative small pressure 
gradients 
 Horizontal radial flow paths (no cross flow) 
and 
 Constant flow rate 
 Darcy flow 
 
Even though these items place tight restrictions on the 
reservoir itself, some important information can be 
extracted from the models, explaining reservoir 
behavior on basis of the well test data.  
 
There are many different models available to match 
the data depending on the situation. Thus, it is 
important to analyze the pressure transient data before 
modeling because it forces the analyst to think about 
the probable reservoir configurations and provides 
good estimates of reservoir parameters.  Models are 
not unique (different model types can match the same 
set of data) and, as a result, it is essential that the 
choice of model type occur after the analysis step. 
The values of parameter obtained during the analysis 
step provide a good starting point for an appropriately 
chosen model type. Parameters can then be optimized 
by automatic parameter estimation (APE).  Before 
using the APE method, irrelevant data should be 
removed from the data set to for efficient matching. 
 
2.  OBJECTIVES OF THE STUDY 
The objectives of this study are to analyze the well 
test data available for well KTL-01 and, KTL-02, to 
estimate the following parameters and finally these 
estimated parameters are matched by vertical 
modeling. 
 The formation permeability  
 The skin effect 
 Average reservoir pressure 
 Wellbore storage effects 
 Reservoir areal extents 
 
3. MTHODOLOGIES AND STUDY 
PROCEDURES 
There are several methods may be used to 
estimate these parameters. The pressure build-up 
test, type curve analysis, Dietz_MBH method 
and vertical modeling are used to complete this 
study. Permeability and skin due to damage are 
estimated by build-up test of radial analysis by 
developing semi log and derivative type curves. 
These values of parameters are used as input 
parameters for Dietz_MBH method. After 
entering these parameters into “FEKETE 
software” the Dietz_MBH method gives the 
output values of reservoir areal extents and these 
areal extents again used as input parameters for 
Dietz_MBH method and finally the average 
reservoir pressure is estimated. The estimated 
parameters are used as input parameters for 
vertical modeling. Vertical model gives the 
output of all parameters on the basis of 
extrapolated pressure those are found by 
conventional analysis with dimensionless 
wellbore storage coefficient.  
 
 
4. RESULTS AND DISCUSSIONS 
From Table 1 and Table 2, it is obtained that the total 
skin effect () are negative for both well KTL-01 and 
well KTL-02. But it is tough to conclude that the 
wells are stimulated as all the skin components have 
not been analyzed here. 
 
The average reservoir pressure, Pavg (3499.3psia) 
from Dietz_MBH analysis for KTL-01 in Table-1 is 
closer to initial reservoir pressure indicates the test 
duration was small. But in case of KTL-02, the 
average reservoir pressure is greater than the initial 
reservoir pressure. This may be the error at the time 
of data recording. The areal extents indicate the 
reservoir is rectangular which is consistent with 
assumption. The results are tabulated here from 
pressure semi log plots, pressure derivative type 
curve and dimensionless type curve. The resultant 
values of a specific parameter obtained from all 
analysis methods are same. For this reason, the 
Page 990
specific method has not mentioned in table containing 
results. 
Extrapolated pressures were found P*= 3503.8 psia 
for KTL-01 and P*= 3223.8 psia for KTL-02 against 
the actual shut in pressure 3499.29 psia and 3222.37 
psia respectively.  
 
Though, all the estimated parameters are well 
matched with actual reservoir pressures but the 
quality of vertical model prediction deviates. It occurs 
very often as all of the models are developed 
theoretically. Therefore, it is better to avoid vertical 
model to predict the reservoir parameters. Other 
perturbing influences that may cause measured 
pressure data to deviate significantly from the basic 
theory include well stimulation, formation damage, 
perforations, fractures and a host of other formation   
and fluid heterogeneities. Another reason is that, 
some PVT properties were assumed here due to the 
lacking of available PVT data. 
Table-1: Comparison between conventional analysis 
parameters and vertical model analysis parameters of 
KTL-01  
 
 
 
 
 
  
 
 
 
 
 
 
Parameters Analysis Value 
Model 
value Remarks  
K(md) 46.0842 129.480 Average 
 permeability 
Kh(md.ft) 2995.47 8416.22 
Total 
permeability- 
thickness 
product 
S- -5.557 Not found Total Skin 
Sd Not found  -2.300 
Skin due  
to damage 
P*(psia) 3503.8 3505.3 Extrapolated  pressure 
P(avg.)(psia) 3499.3 3505.2 
Average 
reservoir 
 pressure 
P(syn)(psia) 3658.7 3516 Synthetic  pressure 
Xe(ft) 12736.735 10630.012 Reservoir length 
Ye(ft) 2188.818 38220.643 Reservoir 
width 
Xw(ft) 6368.367 5710.068 
Well location 
 in X-
direction  
Yw(ft) 1094.409 119.477 
Well location 
 in Y-
direction  
Page 991
          
     
808
812
816
820
824
828
832
836
ψψ ψψ
 
(1
0
 
(1
0
 
(1
0
 
(1
066 66
pi
σ
ι
pi
σ
ι
pi
σ
ι
pi
σ
ι22 22
/χ
Π
)
/χ
Π
)
/χ
Π
)
/χ
Π
)
3440
3450
3460
3470
3480
3490
3500
p
 (p
si(a))
1.0101102103104 2345678234567823456782345678
Superposition Radial Pseudo-Time (Σ∆ta) (h)
ψdata
ψmodel
pavg
Ext. ψmodel
Dietz_MBH output
 pi (syn) 3663.0 psi(a)
 pavg 3503.5 psi(a)
 Cumgas 17.909 MMscf
Dietz_MBH input parameters
 kh 2995.47 md.ft
 h 65.000 ft
 k 46.0842 md
 sd -5.557
 Xe 13461.412 ft
 Ye 2070.986 ft
 Xw 6730.706 ft
 Yw 1035.493 ft
Radial analysis results
 kh 2995.47 md.ft
 k 46.0842 md
 s' -5.557
 p* 3503.8 psi(a)
 pavg 3503.5 psi(a)
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Figure-1:Dietz_MBH Semi log plot of radial flow analysis for KTL-01 
 
 
 
 
 
 
 
 
 
Figure-2: Semi log plot showing pressure buildup test results comparison of diagnostic analysis and vertical 
model analysis for KTL-01 
 
 
 
 
 
  
 
 
 
Figure-3: Type curve plot showing pressure buildup test results comparison of diagnostic analysis and vertical 
model analysis for KTL-01 
          
     
808
812
816
820
824
828
832
836
ψψ ψψ
 
(10
6 p
si
2 /c
P)
3440
3450
3460
3470
3480
3490
3500
p
 (p
si(a))
1.0101102103104 2345678234567823456782345678
Superposition Radial Pseudo-Time (Σ∆ta) (h)
ψdata
ψmodel
pavg
Ext. ψmodel
Vertical modeling results
 pi (syn) 3516.0 psi(a)
 pavg 3505.2 psi(a)
 Cumgas 17.909 MMscf
Vertical modeling results
 kh 8416.22 md.ft
 h 65.000 ft
 k 129.4803 md
 sd -2.340
 Xe 10630.012 ft
 Ye 38220.643 ft
 Xw 5710.068 ft
 Yw 119.477 ft
Radial analysis results
 kh 2924.15 md.ft
 k 44.9869 md
 s' -5.556
 p* 3505.3 psi(a)
          
     
10-4
10-3
10-2
10-1
1.0
101
2
4
2
4
2
4
2
4
2
4
∆
ψ
∆
ψ
∆
ψ∆ψ
/q
 
/ D
er
iv
a
tiv
e 
((1
06
ps
i2 /
c
P)
/M
M
sc
fd
)
1.0
101
102
103
104
2
3
5
2
3
5
2
3
5
2
3
5
∆ψ∆ψ ∆ψ
∆ψ
/q
 (PPD)
 ((10 6p
si 2/cP)/(M
M
scfd)/h
r)
10-3 10-2 10-1 1.0 101 1022 3 4 5 6 7 8 2 3 4 5 6 7 8 2 3 4 5 6 7 8 2 3 4 5 6 7 8 2 3 4 5 6 7 8
Pseudo-Time  (h)
∆ψ/qdata
∆ψ/qmodel
Derivativedata
Derivativemodel
PPDdata
PPDmodel
Vertical modeling results
 pi (syn) 3516.0 psi(a)
 pavg 3505.2 psi(a)
 Cumgas 17.909 MMscf
Vertical modeling results
 kh 8416.22 md.ft
 h 65.000 ft
 k 129.4803 md
 sd -2.340
 Xe 10630.012 ft
 Ye 38220.643 ft
 Xw 5710.068 ft
 Yw 119.477 ft
Radial analysis results
 k 44.9869 md
 s' -5.556
 p* 3505.3 psi(a)
Page 992
Table-2: Comparison between conventional analysis  
parameters and vertical model analysis parameters of KTL-02 
 
 
 
 
 
 
 
 
 
 
                                                                                Figure-4: Dietz_MBH Semi log plot of radial flow analysis for 
KTL-02 
 
 
 
 
 
 
 
 
 
 
 
 
Figure-5: Semi log plot showing pressure buildup test results comparison of diagnostic analysis and vertical 
model analysis for KTL-01 
 
Parameters 
Analysis 
Value 
Model 
value 
K(md) 699.098 899.7578 
Kh(md.ft) 27963.92 35990.31 
S- -0.332 Not found 
Sd Not found 0.294 
P*(psia) 3223.8 3225.2 
P(avg.)(psia) 3222.4 3219.3 
P(syn)(psia) 3373.7 3340.5 
Xe(ft) 14032.289 6866.983 
Ye(ft) 1986.792 5046.971 
Xw(ft) 7016.135 90.492 
Yw(ft) 993.366 4148.806 
560
580
600
620
640
660
680
700
720
740
760
780
ψψ ψψ
 
(1
0
 
(1
0
 
(1
0
 
(1
066 66
pi
σ
ι
pi
σ
ι
pi
σ
ι
pi
σ
ι22 22
/χ
Π
)
/χ
Π
)
/χ
Π
)
/χ
Π
)
2700
2750
2800
2850
2900
2950
3000
3050
3100
3150
3200
3250
3300
p
 (p
si(a))
1.0101102103104 2345678234567823456782345678
Superposition Radial Pseudo-Time (Σ∆ta) (h)
ψdata
ψmodel
pavg
Ext. ψmodel
Vertical modeling results
 pi (syn) 3340.5 psi(a)
 pavg 3219.3 psi(a)
 Cumgas 14.512 MMscf
Vertical modeling results
 kh 35990.31 md.ft
 h 40.000 ft
 k 899.7578 md
 sd 0.294
 Xe 6866.983 ft
 Ye 5046.971 ft
 Xw 90.492 ft
 Yw 4148.806 ft
Radial analysis results
 kh 21622.13 md.ft
 k 540.5533 md
 s' -0.334
 p* 3229.7 psi(a)
560
580
600
620
640
660
680
700
720
740
760
780
800
820
ψψ ψψ
 
(1
0
 
(1
0
 
(1
0
 
(1
066 66
pi
σ
ι
pi
σ
ι
pi
σ
ι
pi
σ
ι22 22
/χ
Π
)
/χ
Π
)
/χ
Π
)
/χ
Π
)
2700
2800
2900
3000
3100
3200
3300
3400
p
 (p
si(a))
1.0101102103104 2345678234567823456782345678
Superposition Radial Pseudo-Time (Σ∆ta) (h)
ψdata
ψmodel
pavg
Ext. ψmodel
Dietz_MBH output
 pi (syn) 3373.7 psi(a)
 pavg 3222.4 psi(a)
 Cumgas 14.512 MMscf
Dietz_MBH input parameters
 kh 27963.92 md.ft
 h 40.000 ft
 k 699.0980 md
 sd -0.332
 Xe 14032.289 ft
 Ye 1986.732 ft
 Xw 7016.145 ft
 Yw 993.366 ft
Radial analysis results
 kh 27963.92 md.ft
 k 699.0980 md
 s' -0.332
 p* 3223.8 psi(a)
 pavg 3222.4 psi(a)
Page 993
  
 
 
 
 
 
Figure-6: Type curve plot showing pressure buildup test results comparison of diagnostic analysis and vertical 
model analysis for KTL-01 
 
5. CONCLUSION 
Finally it is concluded that modeling is not a good tool for estimating or predicting the reservoir parameters 
for a practical field.  
  
REFERENCES 
 
1. Lee, John and Wattenbarger, A.R. (1996). “Gas Reservoir Engineering”, SPE Textbook Series, Vol. 5 
(Dallas, TX: Society of Petroleum Engineers) 
2. Lee, John “Well Testing”, Society of Petroleum Engineers of AIME, New York (1982), Dallas. 
3. Dake, L.P., “Fundamentals of Reservoir Engineering”. Elsevier, Amsterdam-London-New York-Tokyo. 
4. Horne, N.Ronald, “Modern Well Test Analysis” A Computer-Aided Approach, Forth printing. 
5. Economides, J. Michael &Hill Daniel A., and Ehlig-Economides Christine. “Petroleum Production 
Systems”. Prentice Hall PTR, Upper Saddle River, New Jersey 07458. 
6. Imam, Badrul. “Energy Resources of Bangladesh”. UGC Publication No. 89, ISBN 984-809-020-1. 
7. Ursin,J.R. & Zolotukhin,A.B., “Reservoir Engineering”.  
8. Tiab, Djebbar, “Gas Reservoir Engineering”. PE 4613-Lecture Notes 
9. Horner, D.R.: “Pressure Build-Up in Wells,” Proc., Third World Pet. Congress, Sec II (1951) 503. 
10. Muskat, M.: Physical Principles of Oil Production, McGraw-Hill Book Co., Inc., New York, 1949, pp. 126. 
11. Cobb, W.M., Smith, J.T. and Denson, A.H.: “Determination of Well Drainage Pore Volume and Porosity 
from Pressure Buildup Tests,” SPEJ (August 1976) 209-216. 
12. Craft, B. C., and Hawkins, M. F., Applied Petroleum Reservoir Engineering,  
        PrenticeHall, Inc., Englewood Cliffs (1959). 
13. Rahman Md. Mizanur and Rahman Arifur (2010), “Pressure Data Analysis and Reservoir Parameter 
Estimation of Kailastilla Gas Field”. 
 
10-7
10-6
10-5
10-4
10-3
10-2
10-1
1.0
2
4
2
4
2
4
2
4
2
4
2
4
2
4
∆
ψ
∆
ψ
∆
ψ∆ψ
/q
 
/ D
e
riv
a
tiv
e
 
((1
06
ps
i2 /
cP
)/M
M
sc
fd
)
10-5
10-4
10-3
10-2
10-1
1.0
101
102
103
104
3
3
3
3
3
3
3
3
3
∆ψ∆ψ ∆ψ
∆ψ
/q
 (PPD)
 ((10 6p
si 2/cP)/(M
M
scfd)/h
r)
10-3 10-2 10-1 1.0 101 1022 3 4 5 6 7 8 2 3 4 5 6 7 8 2 3 4 5 6 7 8 2 3 4 5 6 7 8 2 3 4 5 6 7 8
Pseudo-Time  (h)
∆ψ/qdata
∆ψ/qmodel
Derivativedata
Derivativemodel
PPDdata
PPDmodel
Vertical modeling results
 pi (syn) 3340.5 psi(a)
 pavg 3219.3 psi(a)
 Cumgas 14.512 MMscf
VErtical modeling results
 kh 35990.31 md.ft
 h 40.000 ft
 k 899.7578 md
 sd 0.294
 Xe 6866.983 ft
 Ye 5046.971 ft
 Xw 90.492 ft
 Yw 4148.806 ft
Radial analysis results
 k 651.9017 md
 s' -0.334
 p* 3225.2 psi(a)
Page 994
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Modern Approach to Estimation of Gas Reserve with Dynamic 
Reservoir Simulation. 
- A Case Study of Narshingdi Gas Field. 
 
Farhana Akter 
Lecturer 
Petroleum & Geo-resources Engineering (PGE) 
Shahjalal University of Science & Technology (SUST), Sylhet, Bangladesh 
 
Jon Kleppe 
Professor 
Petroleum Engineering and Applied Geophysics 
Norwegian University of Science and Technology (NTNU), Trondheim, Norway 
 
 
Gas is the most valuable natural resource all over the world as well as in Bangladesh too. Estimating and 
updating the gas reserve helps the planners for drawing mid-term and long-term development plan from field 
development level to national level. So estimating correct reserve has become vital issue now days in terms 
of energy demand and economics.  
 
This paper presents the study of reserve estimation of Narshingdi Gas Field.  In this paper Dynamic 
Reservoir Simulation model developed by Petrel 2005 has  been  used  to  perform  a  history  match 
“pressure  and production” using Eclipse-100 for  reserve  estimation.  So the result of this study is expected 
to provide Gas Initially in Place (GIIP) in Narshingdi Gas Field. 
 
Because of data limitations, efforts were taken to use SWHP (Shut in Well Head Pressure) and FWHP 
(Flowing Well Head Pressure) data for reserve estimation analysis of this field. Some variables    like 
permeability,    fluid  contact, well  productivity    index,  pore  volume,    initial  pressure    have  been  
adjusted  to  obtain  a  good  match  to  the  observed  well  and  reservoir behaviour. Simultaneously some 
forecast scenarios have also been evaluated. Since there is no strong aquifer pressure support in the 
producing gas zone, so gas production continues from the reservoir due to pressure depletion which may 
limit the future gas recoverable volume. 
 
  
Key words: Gas Reserve Estimation, History Match, Forecasting, Sensitivity Analysis 
 
 
Introduction: 
Simulation is the way to describe quantitatively the 
flow of multiple phases (typically, oil, water, and 
gas) through porous media in a reservoir having a 
production schedule determined not only by the 
properties of the reservoir but also by the market 
demand, investment strategy which involves the 
performance predictions in intermediate and long 
term planning and government regulations.  
 
Two commercial accumulations of gas sands have 
been discovered which are of different depositional 
environment. The drilled section penetrated these 
two main gas sands and other four thin gas bearing 
sands of minor interest. Two major sands are 9.5m 
and 14m thick. Thickness of minor sands ranges 
from 0.6m to over 7m. Production is continuing 
only from lower gas sand and there is no production 
from upper gas sand yet. In Narshingdi Gas Field 
(lower gas sand) there are two wells named NAR-1 
and NAR-2. NAR-1 was drilled to a total depth of 
3450 meter in 1990 and production through this 
well commenced on 25th July 1996. Second well 
NAR-2 was drilled in the crest following new depth 
contour map in October 2006 and started 
Page 995ISBN: 978-984-33-2140-4
  
production on 18th February 2007. This well was 
drilled successfully to a depth of 3285m. Up to 
February 2008 the total gas production is 
approximately 82 Bcf (53% of GIIP). 1, 2, 3 
 
In different time different companies and 
organizations updated reserve figure and those 
figures were mainly based on volumetric 
calculation and material balance analysis. Highly 
developed simulator tool ECLIPSE-100 which 
provides  realistic and detailed reservoir behavior, 
is used to find out the gas reserve by performing 
history match “pressure and production’’ . 
 
Methodology: 
A reservoir model is a geometric model which 
contains a detailed description of geological 
properties and the dynamics of complex multiphase 
flow in a porous media. The reservoir model tries to 
describe the different static properties in all regions, 
along with the dynamic variables, i.e. saturations 
and pressures. The model needs to be discretized to 
use in simulations. The common approach is 
therefore to model the reservoir with spatial blocks, 
as a discretization in space. The blocks are known 
as grid blocks. Appropriate static and dynamic 
parameters are assigned to each grid block. 
 
The geological model had been built by using 
Petrel™-2005. The static model grid has dimension 
of 101×149×29 representing four sand layers of the 
field. It has been discretized into 328 x 328 ft grid 
blocks. For simulating of gas-water system the 
model grid layering was designed with average 
thickness of 10 ft, so up scaling is unnecessary in 
this case. Both middle gas sand-1 and middle gas 
sand-2 have no commercial value, so both of them 
are kept inactive. And this reduces the total number 
of active grid blocks to 66,966. The model has a 
minimum water saturation of 0.35 based on the 
initial water saturation distribution. 4 
 
 
 
Table-01: Properties of model layers. 
 
Sand layers Simulation 
layers 
Porosity 
 (%) 
Permeability Distribution, 
md 
Status 
Upper gas sand 1-4 0.15-0.22 77 Active 
Middle gas sand-1 5-15 - - Inactive 
Middle gas sand-2 16-24 - - Inactive 
Lower gas sand 25-29 0.07-0.22 1-100 Active 
 
During DST 3 and extended production test-1, two 
sets of experimental gas compositional data were 
found from the lower gas sand. From these two sets 
of tests, data from extended production test-1 is 
considered to be more representative of the 
reservoir fluid due to long duration of flow period. 
Long duration draw down periods provides more 
accurate estimate of gas-liquid ratio. So PVT 
properties are based on gas composition from 
production test-1 (NAR-1) in Lower Gas sand. 
 
 
Initial condition: 
From pressure temperature phase diagram (Fig: 01) 
types of reservoir can be defined by the location of 
the initial reservoir temperature and pressure. 3 
Here the initial condition of the reservoir is as 
follows- 
The initial reservoir temperature =205.8 oF=370K 
Initial pressure of upper gas sand=4054 psia=279.5 
bar 
Initial pressure of lower gas sand=4274 psia=294.7 
bar 
 
Fig. 1: Pressure temperature phase diagram of reservoir fluid. 
Page 996
  
The fluid left in the reservoir during production 
remains at 205.8 oF, so it will remain in the gas 
phase as the pressure declines. Liquid is condensed 
from the well effluent at temperature lower than 
100o F and pressure in the range of 1100 psia. So it 
can be said that the reservoir fluid of the Narshingdi 
Gas Field is non-retrograde at reservoir temperature 
and can be defined as lean gas since no condensate 
is formed in the reservoir during the life of 
production. The Narshingdi fluid contains over 
97% methane and ethane, a larger percentage of 
C7+ and significant amount of recoverable C5+ 
liquids. The condensate is highly viscous. The 
specific gravity of the reservoir fluid is 0.6 and 
condensate-gas-ratio (CGR) is about 2.24 
bbl/MMscf. 3 
         
Gas Properties: 
The gas properties were analyzed at the reservoir 
temperature of 205.8 oF and pressure range of 15 – 
5000 psia. The specific gravity of the gas is 0.60. 
There is an assumption for rock compressibility and 
the value is Cf = 3x10-6 psia—1. 
 
Fig. 2: Properties of Gas in the lower gas sand 
Fig. 3: Properties of Gas in the lower gas sand 
                                 
Relative Permeability: 
Brooks-Corey’s equations for two-phase flow have 
been used to generate relative permeability curves 
for the simulation. Here some assumptions are 
made to have value of pore size distribution index 
both for gas and water. It is assumed that the fluid 
flow is neither segregated nor evenly distributed 
and this gives Corey exponents- 4 for water and 2 
for gas to calculate relative permeability. Minimum 
water saturation is selected as the endpoint in the 
model.  
 
 
Fig. 4: gas water relative permeability curves. 
 
Well performance curve: 
To calculate well head pressure for history match 
and production forecast vertical lift performance 
(VFP) curve has been generated by using another 
commercial software IPM for two wells NAR-1 and 
NAR-2 having tubing size of 3.5 inch and 4.5 inch 
respectively. Through a series of graphical 
modules, control and data panels, it allows to study 
all aspects of pressure traverse calculations along 
wells. To calculate the pressure traverse, Beggs and 
Brill flow correlations has been chosen because it 
performs well in gas and gas condensate well.  
 
µg, Bg vs. Pressure
0
2
4
6
8
10
12
14
16
18
20
200 700 1200 1700 2200 2700 3200 3700 4200 4700 5200
Pressure,PR,psia
B
g,
di
m
en
si
on
le
ss
0
0.005
0.01
0.015
0.02
0.025
0.03
vi
sc
os
ity
,c
p
Bg Vs. Pressure
Viscosity vs. Pressure
Z-factor vs. Pressure
0.900
0.910
0.920
0.930
0.940
0.950
0.960
0.970
0.980
0.990
1.000
200 700 1200 1700 2200 2700 3200 3700 4200 4700 5200
Pressure,PR, psia
Z-
fa
ct
or
,d
im
en
si
on
le
ss
Relative permeability vs. Water saturation
0
0.2
0.4
0.6
0.8
1
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Sw,dimensionless
K
r,d
im
en
si
on
le
ss
Krw Krg
Page 997
  
 
 
Fig. 5: Vertical lift performance curve for NAR-1 
 
 
 
Fig. 6: Vertical lift performance curve for NAR-2 
 
History match: 
In this section the simulation model has been 
applied to match production and pressure data from 
wells of the volumetric reservoir to confirm the 
initial reservoir conditions and obtain an acceptable 
match of the observed reservoir behavior. There is a 
limitation of having shut-in BHP measurements in 
the field and no flowing BHP data but historical 
flowing THP is available for the two wells. That’s 
why in this article efforts are put on matching THP 
rather than BHP. For this purpose, some of the 
process parameters called history match variables 
are modified and the calculation repeated.  
 
 
 
History Match Variables: 
The following listed variables have been manually 
adjusted to obtain a good match to the observed 
well and reservoir behavior. 
 Permeability- in case of NAR-1, there is a 
good match between calculated and observed 
production rates (gas and water) but in case of 
NAR-2 the situation is not very good. It is 
observed that values of permeability in grid 
cells near the well bore of NAR-2 were low. So 
it was necessary to adjust the permeability 
(increased by up to a factor of 1000) to have 
improved match of gas and water production 
rate. 
 
 Fluid contact- There is no available pressure 
data for either the upper or lower gas sand to 
provide information about initial reservoir 
conditions. From NAR-1 log data, the lower 
gas sand has a touchy contact with shale and 
shows no indication of a gas water contact 
(GWC), but there is a gas-down-to (GDT) at 
10376 ft and from NAR-2 log data, GWC at 
10531ft Sub Sea. So, there remains uncertainty 
over the fluid contact in the lower gas sand.  
 
Here both wells (NAR-1 and NAR-2) are controlled 
on the gas rate and the matches in case of 
production rate, THP are quite good. A summary of 
all history match changes have been introduced to 
the simulation model and a set of graphs comparing 
model results with measured data are presented 
below. 
 
 
 
Fig. 7: Field gas production rate history match 
Field Gas Production Rate (FGPR) vs. Time
0
10000
20000
30000
40000
0 500 1000 1500 2000 2500 3000 3500 4000 4500 5000
Time, days
Fi
el
d 
G
as
 P
ro
du
ct
io
n 
R
at
e,
M
sc
f/d
ay
FGPR_History
FGPR
Page 998
  
 
 
Fig. 8: Well gas production rate history match for 
well NAR-1 
 
 
Fig. 9: Well gas production rate history match for 
well NAR-2 
 
 
Fig. 10: Tubing head pressure history match for 
NAR-1 
 
Fig. 11: Tubing head pressure history match for 
NAR-2 
 
Fig. 12: Field water production rate history match 
 
 
Fig. 13: Well water gas ratio history match for 
NAR-1 
Well Gas Production Rate (WGPR) vs. Time
0
5000
10000
15000
20000
25000
0 500 1000 1500 2000 2500 3000 3500 4000 4500 5000
Time,days
W
el
l G
as
 P
ro
du
ct
io
n 
R
at
e, 
M
sc
f/d
ay
WGPR WGPR_History
Well Gas Production Rate (WGPR) vs. Time
0
4000
8000
12000
16000
20000
0 500 1000 1500 2000 2500 3000 3500 4000 4500 5000
Time,days
W
el
l g
as
 p
ro
du
ct
io
n 
ra
te
,M
sc
f/d
ay
WGPR
WGPR_History
Tube Head Pressure (THP) vs. Time
0
500
1000
1500
2000
2500
3000
3500
0 2 4 6 8 10 12 14
Time,yrs
T
ub
e 
H
ea
d 
Pr
es
su
re
,p
si
a
THP THP_History
Tube Head Pressure (THP) vs. Time
0
500
1000
1500
2000
2500
3000
0 2 4 6 8 10 12 14
Time, yrs
T
ub
e 
H
ea
d 
Pr
es
su
re
, p
si
a
THP THP_History
Field Water Production Rate (FWPR) vs. Time
0
200
400
600
800
1000
1200
0 500 1000 1500 2000 2500 3000 3500 4000 4500 5000
Time, days
 F
ie
ld
 W
at
er
 P
ro
du
ct
io
n 
R
at
e,
 S
T
B/
da
y
FWPR_History FWPR
Well Water Gas Ration (WWGR) vs. Time
0
0.05
0.1
0.15
0.2
0.25
0.3
0 500 1000 1500 2000 2500 3000 3500 4000 4500 5000
Time, days
W
el
l W
at
er
 G
as
 R
at
io
, s
tb
/M
sc
f
WWGR WWGR_History
Page 999
  
 
Fig. 14: Well water gas ratio history match for 
NAR-2 
 
Sensitivity analysis 1 
Fluid Contact: The gas-down-to at 10376 ft Sub 
Sea seen in well NAR-1 is used as the fluid contact 
of the lower gas sand. This is investigated to 
observe the impact on initial gas volume and 
reservoir behavior. 
 
Fig. 15: NAR-1 THP history matches sensitivity 
 
Fig. 16: NAR-2 THP history matches sensitivity 
case-1 
 
There is a poor match to the pressure history of the 
two wells because part of their perforations fall 
below the contact. The poor match to the reservoir 
behavior show that the gas-down-to seen in well 
NAR-1 is deeper than the value interpreted from 
log. 
 
Sensitivity analysis 2:  
Aquifer pressure support: A numerical aquifer 
is modeled by a one-dimensional row of cells. A set 
of cells in the simulation grid is nominated to 
represent the aquifer, which then connect to 
specified faces of the reservoir. The properties of 
the aquifer grid blocks (length, cross-sectional area, 
porosity, permeability, initial pressure, depth) 
declared explicitly but PVT and saturation table 
numbers are based on the reservoir properties. This 
is to investigate the possibility of a weak pressure 
support. 
 
 
Fig. 17: NAR-1 THP history matches sensitivity 
case-2  
 
 
Fig. 18: NAR-2 THP history matches sensitivity 
case-2 
 
Well Water Gas Ration (WWGR) vs. Time
0
0.005
0.01
0.015
0.02
0.025
0.03
0.035
0 500 1000 1500 2000 2500 3000 3500 4000 4500 5000
Time, days
W
el
l W
at
er
 g
as
 r
at
io
, s
tb
/M
sc
f
WWGR WWGR_History
Tube Head Pressure (THP) vs. Time
0
500
1000
1500
2000
2500
3000
3500
0 2 4 6 8 10 12 14
Time,yrs
Tu
be
 H
ea
d 
Pr
es
su
re
,p
si
a
THP THP_History
Tube Head Pressure (THP) vs. Time
0
500
1000
1500
2000
2500
0 2 4 6 8 10 12 14
Time,yrs
T
ub
e 
H
ea
d 
Pr
es
su
re
,p
sia
THP THP_History
Tube Head Pressure (THP) vs. Time
0
500
1000
1500
2000
2500
3000
3500
1 3 5 7 9 11 13
Time,yrs
T
ub
e 
H
ea
d 
Pr
es
su
re
,p
si
a
THP
THP_History
Tube Head Pressure (THP) vs. Time
0
500
1000
1500
2000
2500
1 3 5 7 9 11 13
Time,yrs
Tu
be
 H
ea
d 
Pr
es
su
re
,p
sia
THP
THP_History
Page 1000
  
The influx from the aquifer attached to the 
simulation model is weak relative to the field 
production history. With this weak aquifer pressure 
support, a poor history match is obtained to THP in 
both wells. The results of this sensitivity case 
confirm that there is no aquifer pressure support to 
the lower gas sand.  
Interpreting the plot of cumulative gas produced 
against P/Z presented in Figure below, it can be 
seen that as a reservoir undergoing depletion with 
no aquifer support and this is to be consistent with 
the production data. 
 
 
Fig. 19: P/Z plot for lower gas sand 
 
 
Performance Projections: 
Sets of sensitivity prediction simulation runs have 
been performed using the history-matched model. 
All the forecast sensitivity cases are set up to run 
till December 2032 with the current well production 
capacity (NAR-1 – 20MMscf/D, NAR-2 – 15 
MMscfd/D). For this the plateau rates and 
following two constraints were used to shut well 
production when violated. 
 Economic rates – NAR-1: 3 MMscfd/day and 
NAR-2: 4 MMscfd/day. 
 Wellhead flowing pressure requirement – 1000 
psia. 
 
Forecast case 1: do-nothing scenario that involves 
predicting future production with the existing wells 
until the economic rates of the wells are reached.  
Forecast case 2: additional Horizontal well in the 
middle high permeability zone. 
Forecast case 3: additional horizontal well across 
all layers scheduled to start production from 
January 2013.  
 
The following figures present the production profile 
of the forecast case-1. Production from the field is 
controlled by declining reservoir pressure. The well 
NAR-2 has low bottomhole pressure, so due to this 
the production from this well is limited and ended 
before the well NAR-1. 
 
 
Fig. 20: Production profile for case-1 
 
 
Fig. 21: Simulated reservoir pressure behavior for 
case-1 
 
The following figures present the comparison 
among three cases. The additional horizontal well 
has some effect on the field gas rate production for 
some time but that would not last for longer time. 
As the reservoir pressure declining, so the 
additional well has low pressure support and 
production from this well is interfering with the 
production from other two wells NAR-1 and NAR-
2. 
 
P/Z vs. Cumulative Gas Production (Gp) 
0
1000
2000
3000
4000
5000
0 50 100 150 200 250 300 350
Gp, Bcf
P/
Z,
 p
si
a
Possible range of initial gas reserve
Based on ± 10 % error in pressure and flow 
GIIP=(250-315)Bcf and
 
Gp=82.4Bcf@Oct,2008
Field Gas Production Rate (FGPR) vs. Time
0
5
10
15
20
25
30
35
40
0 5 10 15 20 25 30 35 40 45 50
Time, yrs
Fi
el
d 
ga
s p
ro
du
ct
io
n 
ra
te
, 
M
M
sc
f/d
ay
0
50
100
150
200
250
Fi
el
d 
ga
s p
ro
du
ct
io
n 
to
ta
l, 
Bc
fFGPR_History_case1
FGPR_Forecast_case1
FGPT_Forecast_case1
FGPT_History_case1
Pressure vs. Time
0
1000
2000
3000
4000
5000
0 4 8 12 16 20 24 28 32
Time. yrs
Pr
es
su
re
, p
sia
Bottom Hole Pressure (BHP)_NAR2_case1
Tube Head Pressure (THP)_NAR2_case1
Bottom Hole Pressure (BHP)_NAR1_case1
Tube Head Pressure (THP)_NAR1_case1
Field Pressure (FPR)_case1
History Forecast
Page 1001
  
 
 
Fig. 22: Field gas production rate-impact of 
additional well  
 
 
Fig. 23: Field gas production total-impact of 
additional well 
 
Fig. 24: Impact of additional well on well gas 
production rate for NAR-1  
 
 
Fig. 25: Impact of additional well on well gas 
production rate for NAR-2 
 
Conclusions:  
The GIIP estimated for the lower gas sand from 
material balance analysis also agrees with the 
history-matched model. According to simulation 
model the total gas reserve is about 364.51 Bcf, 
where upper and lower gas sand contains 83.852 
Bcf and 284.662 Bcf respectively. Between these 
two gas sands (upper and lower gas sands), only the 
lower gas sand has been developed. So no material 
balance calculation is performed for upper gas 
sand. The material balance analysis gives the 
possible range of GIIP for the lower gas sand 250-
315 Bcf. 
 
From NAR-1 log data the fluid contact in the lower 
gas sand is to be 10376 ft. Good production and 
pressure history match is found by manipulating the 
contact based on information provided by 
PetroBangla about NAR-2. 
 
From production history no aquifer pressure 
support is found in the lower gas sand. However 
there is some uncertainty due to inadequate 
pressure data. A simulation sensitivity analysis 
confirms that there is no aquifer pressure support. 
Production is continuing because of pressure 
depletion. 
 
From the lower gas sand, future recoverable 
volume will increase by 118 Bcf at the end of field 
life which gives the total recoverable volume 200 
of Bcf based on the do nothing scenario (i.e. 70% 
recovery factor). 
 
The impact of drilling one horizontal well across all 
layers is that it will not accelerate the recovery. The 
total recoverable volume will be 195 Bcf (i.e. 68%). 
In this case reservoir pressure depletion will be 
more than do nothing scenario and makes field life 
shorter. 
Field Gas Production Rate (FGPR) vs. Time
0
10000
20000
30000
40000
50000
60000
0 4 8 12 16 20 24 28
Time, yrs
Fi
el
d 
ga
s 
pr
od
uc
tio
n 
ra
te
,
 M
sc
f/d
ay
FGPR_case1
FGPR_case2
FGPR_case3
FGPR_history
Field Gas Production Total (FGPT) vs. Time
0
50
100
150
200
250
0 6 12 18 24 30 36 42 48
Time, yrs
Fi
el
d 
ga
s 
pr
od
uc
tio
n 
to
ta
l, 
B
cf
FGPT_case1
FGPT_case2
FGPT_case3
Well Gas Production rate (WGPR) vs. Time
0
5
10
15
20
25
0 4 8 12 16 20 24 28 32
Time, yrs
W
el
l g
as
 p
ro
du
ct
io
n 
ra
te
, 
M
M
sc
f/d
ay
WGPR_history
WGPR_case1
WGPR_case2
WGPR_case3
Well Gas Production Rate (WGPR) vs. Time
0
5
10
15
20
0 4 8 12 16 20 24 28 32
Time, yrs
W
el
l g
as
 p
ro
du
ct
io
n 
ra
te
, 
M
M
sc
f/d
ay
WGPR_history
WGPR_case1
WGPR_case2
WGPR_case3
Page 1002
  
Again the horizontal well across maximum 
permeable zone through one layer does not seem 
very economic considering case 1. 197 Bcf gas 
could be produced giving 69% recovery. In case of 
individual well gas production rate, case-1 showed 
the better result rather than other two cases and  it 
gives the plateau rate for longer time. 
 
Recommendations: 
 The production companies need to adopt an 
integrated program of testing and pressure surveys. 
This will help to build a reliable production 
database and updating of reserves. 
 
 Additional seismic survey over the structure is 
required 
 
 There are some uncertainties in fluid contact 
(lower gas sand). So the interpretation of both 
NAR-1 and NAR-2 well log data is necessary to 
resolve this. In that case there may be a need to run 
a new log in the wells to find out the fluid contact. 
 
  All the analysis done in this article does not 
include economic analysis. So, for field 
development economic analysis for each of the 
forecast case is urgent. By doing this the optimum 
condition could be determined. 
 
 More forecast cases like maintaining THP by 
including compressor, additional vertical well in 
more permeable zone etc could be set up for further 
analysis to choose the optimum option. 
 
 
References: 
1. ‘‘Gas field appraisal project, Geological, 
geophysical and petrophysical report, Belabo 
Gas field, Bangladesh’’ Intercomp- Kanata 
Management Ltd (IKM) (1991).  
2.  ‘‘Well test report on Narshingdi gas field, well 
survey and testing section of development 
department’’ Bangladesh Gas Field Company 
Limited, 2007.   
3. ‘‘Gas field appraisal project, Reservoir 
engineering report, Belabo Gas field, 
Bangladesh.’’ Intercomp-Kanata Management 
Ltd (IKM) (1991). 
4. ‘‘Narshingdi Reservoir Study Prepared for 
Petrobangla, Bangladesh.’’ RPS Energy 
(September 2008). 
5. ‘‘Production report on Narshingdi gas field’’ 
Bangladesh Gas Field Company Limited, 
2008.   
 
Nomenclature: 
FBH               Flowing bottom hole pressure 
FGPT     Field gas production total 
FTHP    Flowing tubing head pressure 
GDT      Gas Down To 
GIIP      Gas Initially in Place 
GPR               Gas production rate 
GPRH     Gas production rate history 
GWC          Gas water contact 
Kr       Relative permeability 
Krg      Relative permeability of gas 
Kw      Relative permeability of water 
MMscf/day     Millions of standard cubic feet/day 
FPR                Average reservoir pressure  
THP                Tubing head pressure 
THPH             Tubing pressure history 
WBHPH         Well bottom- hole pressure 
WGRH           Water-gas-ratio history 
WGPR            Well gas production rate 
WGPRH         Well gas production rate history 
WWGR          Well water-gas-ratio 
WWGRH       Well water-gas-ratio history 
SIWHP           Shut in well head pressure 
 
 
 
Page 1003
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
 
*
 Corresponding Author: Md.Towhidul Islam  
E-mail: mrkhancep@yahoo.com 
 
  
Natural Gas Pipe Line Design from Ashugonj Valve Station#3 to Zia 
Fertilizer Company Limited and in an Arbitrary Power Plant 
 
*Md.Towhidul Islam, Md. Jakaria, Md. Shahedul Hossain, Hazzaz-Bin-Yousuf 
Department of Petroleum & Georesources Engineering, Shahjalal University of Science & Technology, 
Sylhet-3114, Bangladesh. 
 
Abstract  
This paper presents a details feasibility study on road selection, design and construction of a 
natural gas pipeline from Ashugonj valve station 3 to Zia Fertilizer Company Limited (ZFCL). 
In addition, it conducts feasibility study of a new pipeline to an arbitrary power plant of 1000 
mw capacity .5 km away from ZFCL. The proposed pipeline should contain the transmission 
capacity of 1500 MMSCFD of NG as the energy consumption is augmenting rapidly. It 
considers pipeline facility exist along the road to minimize the construction cost, it appears that 
there are some pipeline facility existed along the proposed road from Ashugonj VS 3 to ZFCL.  
Therefore, the main concern of the study is to develop .5 km pipeline to the power plant. To 
examine the technical and economical legitimacy of the study, a financial study for the next 20 
years has been performed. In addition, a comprehensive sensitivity analysis has been performed 
to check the reliability of the projects. The above study demonstrates that the project is 
technically and economically feasible and should be implemented to keep pace with energy 
demand in future.   
 
Introduction 
There is 3.5 km pipeline with 10 inches 
diameter from Ashugonj VS#3 to Zia 
Fertilizer Company. After the scrutinizing, 
the overall energy scenery of Bangladesh in 
the next 20 years there would be needed the 
1000 MW power plant the surrounding of 
Ashugonj. In that cases  
• Will the existence pipeline keep pace 
with the demand rising? 
• If not what will be recommended 
pipeline design and base of what? 
 
Page 1004
ISBN: 978-984-33-2140-4
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
 
*
 Corresponding Author: Md.Towhidul Islam  
E-mail: mrkhancep@yahoo.com 
 
According to the given data of TGTDCL the 
gas flow through the pipeline per day Q= 
175 MMSCFD, if we consider the 30% 
more (as pipeline thumb rule) with this flow 
it will be approximately 230MMSCFD. 
If we set up 1000MW power plant half 
kilometer away from Ashugonj ZFCL its 
consumed gas per day will be 850 
MMSCFD approximately (reference of 728 
MW power plant of Ashugonj) and if we 
deigned pipeline based on for the next 20 
years including 30 % more as pipeline 
thumb rule, the ultimate gas required per day 
is 1100 MMSCFD. 
In this circumstance it is well realized that 
the existing pipeline will not sustain with 
demand rising. 230 ≤ Q < 1100 
Basically, we can be solved this problem in 
two ways comparing   between two methods 
we will choose one which will give us less 
cost estimation delivering good one. 
The two methods are: 
• Series pipeline 
• Parallel pipeline 
 
Methodology: 
Review of the present demand of power 
scenario of Bangladesh, Review of the 
forecasted demand of power production, 
supply, Designing a pipeline for 
transmission of natural gas to that area, 
Financial analysis will be done of the 
proposed pipeline project. 
 
Analysis Bangladesh Power Development 
Board (BPDB) Annual report 2008-2009. 
[5.] We can forecast the near future installed 
capacity, generation capability, and demand 
augmentation  
 
 
 
 
The average demand growth of electricity 
has been about 10% per year at current 
tariffs. That means 500 MW of new 
generation capacity must be added every 
year just to satisfy demand growth [6]. 
 
Design Calcualtion: 
0
2000
4000
6000
8000
10000
12000
14000
M
W
Fiscal  Year
Installed Capacity,Generation Capability,Demand 
Forecast
Page 1005
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
 
*
 Corresponding Author: Md.Towhidul Islam  
E-mail: mrkhancep@yahoo.com 
 
For trnsporating a given quantity of gas at a 
given pressure drop, length is proportional to 
diameter raised to the power 16/3. 
         =       	



                        
                =   



 
       
The series line shown has a total equivalent 
length of, 
    =  +   
=  +  10


 
   =  −  +  10


 
 
The modified panhandle (panhandle B) 
equation –Horizontal flow, 
 =
737  ! !
"      #     $%&$%% '()'Υ*.,   -
..
  "..  
 
Combining the equivalent length equation 
and modified panhandle equation for 
horizontal flow and putting necessary data 
we get the following equation, 
  =     2.173665
1 − 10


 
Putting different value of DB in this equation 
we get the following table, 
Table: Pipeline diameter in respect of 
length  
(inches) (miles) 
11 5.4544 
12 3.4955 
13 2.8857 
14 2.6068 
15 2.4561 
16 2.3665 
17 2.3099 
18 2.2724 
19 2.2468 
20 2.2288 
21 2.2159 
22 2.2065 
23 2.1995 
24 2.1941 
25 2.1901 
26 2.1870 
27 2.1845 
28 2.1826 
29 2.1810 
30 2.1798 
31 2.1788 
32 2.1780 
33 2.1773 
34 2.1768 
     
Page 1006
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
 
*
 Corresponding Author: Md.Towhidul Islam  
E-mail: mrkhancep@yahoo.com 
 
The series pipeline will not suitable with our 
proposed pipeline demand. because as for 
example if choose to series 2.1941 miles of 
pipeline with a diameter 24 inches the rest of 
pipeline will be 1.3059 which is existing 10 
inches diameter pipe that will not sustain to 
deliver the whole demand. Therefore, we are 
going to looping pipeline design. 
 
                3 = 4&
56
5
7
4& 4(489:7
 
     
When, Y= 100% we get DB= 19.16 inches 
When, Y=98% we get DB= 30 inches 
diameter pipe, we will use this 30 inches in 
our proposed pipeline. 
 
To calculate pipe wall thickness, following 
formula is used. 
   t = DP/ 2YFLJT 
 
  t = Pipe wall thickness in mm 
  P= Design Pressure in Psig=960 psig  
 D= Outside diameter of pipe in inch=30in    
Y= Minimum Yield Strength in 
Psig=60,000 psig (Assume API 5LX 60 
Grade Steel Pipe) 
 F= Design Factor= 0.8 
L= Location Factor, it depends on the route 
of the pipeline. For the cross country pipeline 
this factor to 0.6 
 T= Temperature Derating factor= 1 for 
temperature up to 2500 F 
 J= Joint Factor, J=1 
Therefore using equation 3.6 we get, t=12.7 
mm 
Assume, corrosion allowance for steel pipe = 
2 mm 
Hence Pipe wall thickness = (12.7+2) mm= 
14.7 mm 
Compare this calculated pipe wall thickness 
to API 5L line Chart we get wall thickness 
from API chart = 12.7 mm [2]. 
 
Cost Estimation: 
Once a project is found technically sound, the 
next step is to check its soundness from 
financial standpoint. Financial analysis of 
development project deals with review of 
profitability analysis, efficiency analysis 
effectiveness analysis, cost effectiveness 
analysis and sustainability analysis. One 
important aspect of financial appraisal is to 
ensure that there is a financial plan that will 
make funds available to implement the 
project on schedule. (Financial analysis 
2000-2001, planning dept. of titas T & D Co. 
ltd.) [3] 
Page 1007
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
 
*
 Corresponding Author: Md.Towhidul Islam  
E-mail: mrkhancep@yahoo.com 
 
NPV= 32789.589 
BCR= 877.469 
IRR= 35% 
From table 2. 
Note:  
1. Land acquisition and requisition cost have been 
calculated in the basis of actual cost of Nalka- 
Bogra project  and the quality of land has been 
fixed as bare minimum base on the Natural Gas 
Safety rule 1991 amended on 2003 
2. Land development cost has been prepared in the 
basis of public Works  Department  (PWD) 
standard and rate as on 2004 
3. Accommodation area and Estimated cost for civil 
construction works have been prepared on the 
basis of Public Works Department (PWD) 
standard and rate as on 2004 
4. Cost of machinery and equipment has been 
calculated on the basis of proportionate value of 
actual cost of being implemented Nalka-bogra, 
Ashuganf-Monohordi project 
5.  LC= Local Price, FC= Foreign Price, Conversion 
rate 1 US$=70.02Tk. [8] 
 
Conclusion 
The objectives of this project were to design 
a new pipeline altering the existing one in 
order to provide gas flow at the design 
pressure and volume. Presently only 
maximum 225 MMSCFD gas can be 
supplied  through the existing pipeline, which 
is also reducing day by day with the 
increasing of gas demand along the pipeline     
Route. After completing the proposed pipe 
line it could be supplied around 1100 
MMSCFD gas per day. Presently supply is  
Just meet the present demand. To meet the 
future increasing demand it needs to increase  
Supply rationally. The total cost of the 
project is 342.287 lakh taka .Different 
technical evaluations such as NPV, BCR, 
IRR and EIA are formulated to analyze the 
profitability  
 
 
References 
1. Jhon L. Kennedy, Oil & Gas pipeline 
fundamentals (1993).  
2. E.W. McAllister, Editor Pipeline Rules of 
Thumb Handbook  
3. Nazimuzzaman, Md.,Network Analysis 
and Design of Natural Gas Distribution 
Narhsingdi  
4. ASME Code for Pressure Piping, B-31, 
Pipeline Transportation System for Liquid 
Hydrocarbon and other Liquids 
5. Bangladesh Power Development Board 
(BPDB) Annual report (2008-2009) 
6. Bangladesh Roadmap for Energy 
Efficiency Improvements and Demand Side 
Management (Dhaka, September, 2009)  
Page 1008
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
 
*
 Corresponding Author: Md.Towhidul Islam  
E-mail: mrkhancep@yahoo.com 
 
7. Hydrocarbon Unit (HCU)-NPD (2002): 
Joint Study of “Bangladesh Petroleum 
potential and Resources Assessment” 
8. Mohammad Sanwar Hossain, Feasibility 
study of gas supply to Rajshahi. 
 
Table – 2: Calculation of Financial Value of NPV, BCR, IRR  
Year Investment 
cost(millio
n taka) 
Operating 
cost(million 
taka) 
Total 
cost(million 
taka) 
Total 
revenue(million 
taka) 
Net 
income(million 
taka)  
Discount 
factor 
15% 
Discounted 
total 
cost(million 
taka) 
Discounte
d total 
revenue(m
illion 
taka) 
2010 34.2287  34.2287  (34.2287) 1.00 34.2287 - 
1  .51343 .51343 1455 1454.48 .870 .4466 1265 
2  .51343 .51343 3147 3146.49 .756 .3881 2379 
3  .51343 .51343 3467 3466.49 .658 .3378 2281 
4  .51343 .51343 3823 3822.49 .572 .2937 2186 
5  .51343 .51343 4215 4214.49 .497 .2552 2094 
6  .51343 .51343 4648 4647.49 .432 .2218 2007 
7  .51343 .51343 5124 5123.49 .376 .1930 1926 
8  .51343 .51343 5649 5648.49 .327 .1679 1847 
9  .51343 .51343 6228 6227.49 .284 .1458 1768 
10  .51343 .51343 6867 6866.49 .247 .1268 1696 
11  .51343 .51343 7572 7571.49 .215 .1103 1627 
12  .51343 .51343 8348 8347.49 .187 .0960 1561 
13  .51343 .51343 9203 9202.49 .163 .0837 1500 
14  .51343 .51343 10148 10147.49 .141 .0724 1430 
15  .51343 .51343 11186 11185.49 .123 .0632 1196 
16  .51343 .51343 12334 12333.49 .107 .0549 1319 
17  .51343 .51343 13598 13597.49 .093 .0477 1264 
18  .51343 .51343 14993 14992.49 .081 .0416 1214 
19  .51343 .51343 16526 16525.49 .070 .0359 1156 
2030  .51343 .51343 18223 18222.49 .061 .0313 1111 
Total =34.2287 37.411 32827 
 
Page 1009
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
 
*
 Corresponding Author: Md.Towhidul Islam  
E-mail: mrkhancep@yahoo.com 
 
 
 
Page 1010
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: Jun Fukai  
E-mail: jfukai@chem-eng.kyushu-u.ac.jp 
NUMERICAL INVESTIGATION OF PARTICLE PROPERTIES ON 
COAL GASIFICATION UNDER CO2 ATMOSPHERE 
 
 
Md. Saiful Alam1, Agung Tri Wijayanta2, Koichi Nakaso1 and Jun Fukai1* 
1Department of Chemical Engineering, Kyushu University, Fukuoka, Japan 
2Research and Education Center of Carbon Resources, Kyushu University, Fukuoka, Japan 
 
 
 
To achieve efficient energy from coal gasification using CO2 recycling and to reduce CO2 emission as well, 
oxy-combustion of coal becomes attracting interest worldwide. A 3D numerical simulation for coal 
gasification is carried out to investigate the effect of particle properties on coal gasification under CO2 
atmosphere. Reaction rate equation of n-th order type with the Random Pore Model is applied to the char 
gasification reaction. The presence of a much greater CO2 concentration than in a conventional air-fired 
reactor causes significant differences in gas physical properties, such as temperature, and in solid particle 
properties, such as temperature, density and burnout. The effects of CO2/O2 mixture on combustion 
characteristics during pulverized coal combustion are investigated. The CO2 gasification rate increases with 
increasing the CO2 partial pressure in CO2/O2 mixtures. The particle temperature and residence time for coal 
are examined with various mixtures of CO2/O2. Influence of inlet particle size is also studied and the results 
are presented in this paper.  
 
Key words: Oxy-combustion; coal gasification; CO2 emission; reaction rate  
 
1. INTRODUCTION 
 
Coal gasification is a process in which coal is 
partially oxidized to form mainly the following 
combustible gases: carbon monoxide, hydrogen and 
methane. The noncombustible products carbon 
dioxide and water are also formed. During the early 
19th century, almost all fuel gas was produced by 
coal gasification. During the 1940’s, natural gas 
became a cheaper alternative to gases derived from 
coal gasification. However, interest in coal 
gasification is renewed due to recent increases in 
natural gas prices and decreases in natural gas 
supply. A number of research programs are now 
under way all over the world to test and develop 
efficient and economical production of high heating 
value gas from coal. 
 
Coal is a major source of energy, accounting for 
27% of the world energy supplies and 35% of the 
world electricity generation (Williams et al., 2002 
and Alam et al., 2010). It is predicted that coal will 
continue to play an important role in meeting the 
world’s increasing energy demands in the 
foreseeable future. However, the use of coal faces 
several challenges. The major one is the 
considerable emission of CO2 which leads to 
climate change and air pollution. Carbon dioxide is 
believed to be a “greenhouse gas” which can lead to 
global warming (Bachu and Adams, 2003). 
 
Oxy-fuel combustion is recognized as a promising 
technology for pulverized coal-fired power plants 
to control CO2 emissions. In this process coal is 
burned in a mixture of oxygen and recycled flue gas 
(principally CO2). This produces an exhaust gas 
with a high concentration of CO2 ready for 
sequestration (Changdong and Yi, 2008). Pilot-
scale experiments demonstrate that oxy-fuel 
combustion can offer additional benefits of 
substantially reducing NOx, SO2, and Hg emissions 
(Croiset et al., 2000, Croiset et al., 2001). 
Therefore, it motivates numerous studies that cover 
many scientific and engineering fundamental issues 
on the application of this technology. The dry flue 
gas of oxyfuel combustion consists of mainly CO2 
and minor amount of O2, N2, and SO2, while that of 
air-fired combustion contains a great amount of N2 
as well as CO2, O2, and SO2. Such changes imply 
that the gas environment experienced by pulverized 
coal particles is significantly different. These 
differences is found to have impacts on combustion 
processes (Tan et al., 2005, Liu et al., 2005, 
Murphy and Shaddix, 2006, Molina and Shaddix, 
2007) including devolatilization and ignition, 
combustion characteristics, char reaction, and 
Page 1011ISBN: 978-984-33-2140-4
  
pollutant formation. The findings provide us in-
depth understandings of the phenomena and 
fundamentals for further research and development 
of this technology. The combustion of coal in the 
CO2/O2 atmosphere result in a much higher CO2 
concentration in flue gas than in conventional coal 
combustion (using air as an oxidant), which can 
greatly reduce the cost of CO2 capture. In our 
previous paper (Alam et al., 2010b), we studied that 
a high molar ratio of CO2 to O2 is suitable for 
achieving more syngas for pulverized coal 
combustion. However, this increase in CO2 
concentration will produce different gas 
environment and the particle will show different 
behavior during pulverized coal combustion. 
Therefore, to investigate the combustion behavior, 
it is also necessary to study the gas environment 
and the particle behaviors during coal combustion 
process under CO2 atmosphere. The authors 
concern on char-O2 and char-CO2 reaction in oxy-
fuel combustion process of pulverized coal.  
In this study, combustion characteristics of 
pulverized coal in various ratios of CO2/O2 
mixtures are investigated. The objectives of the 
present work are to numerically investigate the coal 
combustion behaviors under various ratios of 
CO2/O2 mixtures. The numerical results are used to 
investigate the particle properties and to study the 
char/CO2/O2 reactions. The present paper is also 
examined the effect of inlet particle size on particle 
behaviors showed during CO2/O2 combustion of 
pulverized coal. 
 
2. EXPERIMENTAL METHODS 
 
The experiment, explained by Schaffel et al., 2009, 
were carried out by the International Flame 
Research Foundation (IFRF) and shown in Fig. 1. 
 
Coal & Primary gas
Coal & Primary gas
Secondary gas
Outlet
Traverse 
1
Traverse 
2
T
raverse 
3
Traverse 
4
0.15 m
0.44 m
1.32 m
4.97 m
Coal & Primary gas
Coal & Primary gas
Secondary gas
2 m
2 m=0.75m x
z
y
6.25 m
Traverse 
Traverse 
T
raverse 
Traverse 
 
Fig. 1: Reactor geometry and the location of the 
data measurement 
 
 
 The burner consisted of a central 125 mm diameter 
pipe supplying the oxidizer and two 27.3 mm coal 
injectors (pipes) which were located 280 mm away 
from the burner center, as shown in Fig. 1. A 
constant wall temperature at 1500K was maintained 
for the reactor. The measurements were taken at 
several traverses (Fig. 1) in a horizontal plane 
cutting through the burner centerline. Detailed 
description of these measurements can be found in 
Weber et al., 2005. The experimental conditions are 
summarized in Tables 1 and 2. 
 
Table 1.  Experimental conditions (Schaffel et al., 
2009) 
 Flow rate (kg/s) Temperature (K) 
Coal 66 - 
Primary gas 130 313 
Secondary gas 675 1623 
 
Table 2.  Inlet composition for primary and 
secondary gas 
Primary gas O2=23, N2=77 
Secondary gas O2=22, H2O=9.5, CO2=12.5, N2=56 
 
3. NUMERICAL METHODS 
 
Three-dimensional simulations of a quarter of the 
furnace are performed under steady-state 
conditions. The coal combustion is modeled 
including pyrolysis, volatile combustion, and char 
burnout. All the gas phase reactions are calculated 
using global mechanisms. The interaction between 
chemistry and turbulence is modeled using the 
Eddy Dissipation model. Turbulence is calculated 
using the standard k– model whilst radiative heats 
transfer by P1 radiation method. The governing 
equations are discretized by the first-order upwind 
scheme. The pressure-velocity coupling was also 
corrected by using the SIMPLE scheme. The 
Venezuelan bituminous Guasare coal (Schaffel et 
al., 2009) is used to conduct the simulation. The 
proximate and ultimate analyses of Guasare coal 
are given in Table 3.  
 
Table 3.  Proximate and ultimate analysis of 
bituminous coal (Guasare) 
Proximate analysis (wt %) Ultimate analysis 
(wt % d.a.f) 
Moisture 2.9 C 81.6 
Volatile matter 37.1 H 5.5 
Fixed carbon 56.7 O 10.7 
Ash 3.3 N 1.5 
LCV(MJ/kg)                             31.74 
 
A quarter of the furnace is performed due to 
symmetry under steady-state conditions and 44,824 
tetrahedral cells are used with the cell size around 2 
mm. 
 
 
Page 1012
  
4. MATHEMATICAL METHODS 
 
The following general basic Equations (1) – (3) for 
fluid flow are considered to calculate the pulverized 
coal combustion modeling. 
Mass Conservation Equation: 
  mSt 


 .                       (1) 
Momentum Conservation Equation: 
     h
j
jj SJhpEEt









..  (2) 
Energy Conservation Equation:  
    Fgp
t







 ..
   
(3) 
The k- model (Launder and Spalding, 1974) with 
the following model constants: C1=1.44, C2=1.92, 
C=0.09, k=1.0, =1.3 are used for the flow 
predictions. The turbulence kinetic energy, k, and 
its rate of dissipation, , are obtained from the 
following two transport equations:  
   
kMbk
jk
t
j
i
i
SYGG
x
k
x
ku
x
k
t






























  
(4) 
   
  








S
k
CGCG
k
C
xx
u
xt
bk
j
t
j
i
i


























2
231
  
(5) 
The spherical harmonics (P1) model is used to 
calculate the radiation. The radiative transfer 
equation, Eq. 6 describes the transport of radiative 
intensity through a medium. 
     
'''4
0
4
2
.,
4
,,










 dsssrI
TansrIa
ds
srdI
s
s





      (6) 
where sa   is the optical thickness or opacity of 
the medium.  
The P1 method permits the total radiative intensity 
over all solid angles, G, to be written as a 
Helmholtz Eq. 8; 
 
4
IdG
     
                      (7) 
  043
1 4 







 TkGkG
k aasa


       (8) 
This enables the incident radiation to be solved as a 
scalar quantity within CFD codes.  
Combustions of the volatiles are simplistically 
represented by two overall reactions: 
 
C1.89H4.76O0.12N0.0342 + 3.02 O2 = 
     1.89 CO + 2.38 H2O + 0.0171 N2     (R1) CO + 0.5 O2 = CO2                          (R2)  
A turbulence chemistry interaction model, based on 
the work of Magnussen and Hjertager, 1976, called 
the Eddy Dissipation model employs for this 
simulation. The net reaction rate is taken as the 
minimum of these two Equations 11 and 12. 









RwrR
R
Riwriri M
Y
k
AMR
,
'
,
,
'
,, min 

        (9) 
jw
N
j rj
P P
iwriri
M
Y
k
ABMR
,
''
,
,
'
,,




      (10) 
where A and B are two model empirical constants 
equal to 4 and 0.5, respectively.  
In discrete phase modeling, coal particles of known 
size distributions and properties are injected into 
the combustion chamber and tracked in a 
Lagrangian fashion throughout the computational 
domain. The trajectory of a discrete phase particle 
is computed by integrating the forces acting on the 
particle. 
x
p
pz
pD F
g
uuF
dt
du




 )(
)(             (11) 
where Fx is an additional acceleration (force/unit 
particle mass) term, FD(u−up) is the drag force per 
unit particle mass and 
24
18
2
eD
pp
D
RC
d
F


                                     (12) 
Here, u is the fluid phase velocity, up is the particle 
velocity, µ is the molecular viscosity of the fluid,  
is the fluid density, p is the density of the particle, 
and dp is the particle diameter. Re is the relative 
Reynolds number, which is defined as 

 uud
R ppe

         (13) 
The devolatilization law is applied to a combusting 
particle when the temperature of the particle 
reaches the vaporization temperature. The constant 
rate devolatilization law indicates that volatiles are 
released at a constant rate with the following Eq. 
16;   
  00,0,0, 1
1 A
dt
dm
mff
p
pw




                    (14) 
For heterogeneous surface reactions, the following 
reactions (Watanabe and Otaka, 2006) are assumed 
to occur inside the gasifier during coal combustion. 
C + 0.5O2        (R3) 
C + CO2 = 2CO             (R4) 
Page 1013
  
C + H2O = CO + H2      (R5) 
The rate equation for char suggested by Kajitani et 
al., 2002 is based on the Random Pore Model and is 
used to conduct the simulation. The reaction rate is 
expressed as follows:  
)1ln(1)1(/ xxkdtdx ip         (15) 
where x indicates a conversion ratio of char and i 
is a dimensionless parameter indicating the initial 
pore structure. kp is the reaction constant that 
follows the Arrhenius equation. 







 

p
in
AiOip RT
EPAk exp            (16) 
  
5. RESULTS AND DISCUSSION 
 
Fig. 2 shows the comparisons of outlet species 
concentration and outlet temperature between 
experiment and simulation. For species O2, H2O, 
CO2 and N2, the comparisons are plotted in terms of 
outlet composition (wt %), and the outlet 
temperature is scaled in Kelvin (right scale in the 
Fig. 2).  This comparison shows that computation 
and the experiment (Schaffel et al., 2009) are in a 
good agreement. 
 
0
10
20
30
40
50
60
0
200
400
600
800
1000
1200
1400
1600
Tem
perature [K
]
O
2
C
om
po
si
tio
n 
[w
t %
] Experiment
Simulation
H
2
O CO
2
N
2
Temperature
 
Fig. 2: Comparison of calculated outlet species 
composition and temperature with experimental 
(Schaffel et al., 2009) 
 
In our previous study (Alam et al., 2010b), the 
temperature profiles, and the concentrations 
profiles for oxygen, carbon dioxide and carbon 
monoxide along the  measurement traverses (From 
the centerline 0.15m, 0.44m, 1.32m and 4.97m for 
the Traverse 1, 2, 3 and 4, respectively, in Fig. 1) 
are compared with experimental (Schaffel et al., 
2009). These comparisons confirm the validity of 
the current model.  
 
5.1 Gas temperature profile 
The Fig. 3 shows the gas temperature profiles at 
CO2 to O2 molar ratio of 3.3, 4.67 and 7.0 keeping 
constant CO2 inlet mole composition. It is found 
that the temperature decreases with increasing the 
ratio of CO2 to O2. It confirms the occurrence of 
char-CO2 reaction (R4) at higher CO2/O2 ratio. 
Because of the endothermic behavior of char-CO2 
reaction the temperature of the gas environment 
decreases. The rate of char reaction with CO2 and 
O2 are discussed in section 5.2. 
 
0
500
1000
1500
2000
0 0.25 0.5 0.75 1
Axial distance [m]
G
as
 te
m
pe
ra
tu
re
 [K
]
CO2/O2 = 3.3
CO2/O2 = 4.67
CO2/O2 = 7.0
CO2 inlet mole fraction = 0.7
 
Fig. 3: Temperature profile along axial distance for 
various CO2/O2 ratios (at constant CO2 inlet molar 
fraction) 
 
5.2 Particle rate of reaction 
The rate of char reaction with CO2 and O2 are 
investigated with various CO2/O2 ratios. At lower 
value of CO2/O2 ratio, the char-O2 reaction (R3) 
rate becomes dominant than char-CO2 reaction rate. 
But, the char-O2 reaction rate becomes negligible 
compared to char-CO2 reaction rate if the CO2/O2 
ratio increases. In Fig. 4, the rates of char reaction 
with CO2 and O2 are shown for two CO2/O2 ratios 
of 3.3 and 7.0. It is clear that char-O2 reaction and 
char-CO2 reaction rate are dominant at lower and 
higher CO2/O2 ratio, respectively. 
 
0
0.05
0.1
0.15
0 0.25 0.5 0.75 1
Axial distance [m]
dx
/d
t [
s-
1 ]
char/O2 (CO2/O2=3.3)
char/CO2 (CO2/O2=7.0)
CO2 inlet mole fraction = 0.7
char/CO2 (CO2/O2=3.3)
char/O2 (CO2/O2=7.0)
Fig. 4: Char rate of reaction profile along axial 
distance for various CO2/O2 ratios (at constant CO2 
inlet molar fraction) 
 
5.3 Particle temperature  
The changes of particle temperature with residence 
time for various CO2/O2 ratios at constant CO2 inlet 
molar fraction are shown in Fig. 5. It is found that 
high CO2/O2 ratio produces lower particle 
temperature. The particle residence time also 
Page 1014
  
reduces with higher concentration of CO2. This 
reduction in residence time is due to the occurrence 
of char-CO2 reaction. The lower residence time 
may reduce the heat loss by particle radiation 
during coal combustion. 
0
500
1000
1500
2000
0 0.07 0.14 0.21 0.28 0.35
Residence time [s]
Pa
rti
cl
e 
te
m
pe
ra
tu
re
 [K
] CO2/O2 = 3.3CO2/O2 = 4.67
CO2/O2 = 7.0
CO2 inlet mole fraction = 0.7
7.0
4.67
3.3
 
Fig. 5: Change of particle temperature with 
residence time for various CO2/O2 ratios (at 
constant CO2 inlet molar fraction) 
 
5.4 Effect of particle size 
The effects of inlet particle size are carried out by 
simulating the coal gasification with four different 
particle sizes (20, 30, 100 and 150m). For a single 
particle, the calculated results are shown in Fig. 6 
and Fig. 7. In the Fig. 6, it is seen that the particle 
shows much lower temperature if the inlet particle 
diameter is large. Therefore, to keep the high 
particle temperature, the particle size should be 
small. From the Fig. 6, it is also found that the 
residence time is also very high for large coal 
particle than that of smaller one. This indicates the 
rate of particle disappearance is faster for smaller 
size coal particle.  
 
0
500
1000
1500
2000
0 0.1 0.2 0.3 0.4
Residence time [s]
Te
m
pe
ra
tu
re
 [K
]
20
30
100
Fig. 6: Change of particle temperature with 
residence time for various inlet particle diameters 
 
 
The particle density is also changed during the coal 
combustion and the corresponding changes with 
particle residence time for different particle sizes 
are shown in Fig. 7. It is found that the large 
particle shows high density than the smaller size 
particle at same residence time. It is because of the 
rapid disappearance of coal particle for smaller size 
that is explained in previous paragraph. 
 
0
400
800
1200
1600
0 0.02 0.04 0.06 0.08
Residence time [s]
D
en
si
ty
 [k
g/
m
3 ]
 
Fig. 7: Change of particle density with residence 
time for various inlet particle diameters 
 
6. CONCLUSIONS 
 
The numerical simulations for pulverized coal 
combustion are carried out under various CO2/O2 
inlet molar ratios. The higher CO2/O2 ratio 
produces lower temperature for both gas phase and 
solid particle. But the rate of char-CO2 reaction 
increases significantly with increasing CO2/O2 
ratios. High CO2/O2 ratio also reduces the residence 
time for coal particle which are assumed to reduce 
the radiation heat loss during combustion. The 
particle size shows a significant role during 
pulverized coal combustion. Smaller size coal 
particle can perform higher temperature and shorter 
residence time in the reactor. It can minimize the 
gas and solid particle temperature not to become 
suddenly reduced under higher CO2/O2 ratio. For 
getting efficient coal combustion it is predicted that 
high CO2/O2 ratio with smaller coal particle would 
be preferable for pulverized coal combustion. 
 
 
NOMENCLATURE 
 
A Area, m2 
A0 Rate constant, s-1 
a Absorption coefficient, m-1 
Cw Swelling coefficient, dimensionless 
dp Particle diameter, m 
fv Particle’s volatiles fraction, dimensionless 
g  Gravitational acceleration, m/s2 
J  Mass flux, kg/m2-s 
I Radiation intensity, W m-2 s-1 
k  Turbulent kinetic energy, m2/s2 
150 m 
100 m 
20 m 
& 30m 
30 m 20 m 
100 m 
150 m 
Page 1015
  
mp Particle mass, kg 
Mw  Molecular weight, kg/kgmol 
p Pressure, Pa 
s Path length, m 
T Temperature, K 
t  Time, s 
v  Velocity, m/s 
Y  Mass fraction, dimensionless 
   Turbulent dissipation rate, m2/s3 
s  Scattering coefficient, m
-1 
  Stefan-Boltzmann constant, W/m2-K4 
  Phase function 
'  Solid angle, degree 
µ  Dynamic viscosity, Pa-s 
 Density, kg/m3 
r  Effectiveness factor, dimensionless 
 
ACKNOWLEDGMENTS 
 
This research is partially supported by NEDO 
project under Innovative Zero-emission Coal 
Gasification Power Generation Project. The authors 
would also like to acknowledge the GCOE for 
providing research funding. 
 
REFERENCES 
 
1. Williams, A., Backreedy, R., Habib, R., Jones, 
J.M. and Pourkashanian, M. (2002), Modeling 
coal combustion: the current position, Fuel, 81, 
pp. 605-618. 
2. Alam M.S., Wijayanta A.T., Nakaso K., Fukai 
J., Norinaga K. and Hayashi J. (2010), A 
reduced mechanism for primary reactions of 
coal volatiles in a plug flow reactor, 
Combustion Theory and Modelling, 14(6), pp. 
841–853. 
3. Bachu, S. and Adams, J.J. (2003), 
Sequestration of CO2 in geological media in 
response to climate change: capacity of deep 
saline aquifers to sequester CO2 in solution, 
Energy Conversion and Management, 44, pp. 
3151–3175. 
4. Changdong S. and Yi L. (2008), Experimental 
study of ash formation during pulverized coal 
combustion in O2/CO2 mixtures, Fuel, 87, pp. 
1297–1305. 
5. Croiset E., Thambimuthu K.V. and Palmer A. 
(2000), Coal combustion in O2/CO2 mixtures 
compared with air. Can. J. Chem. Engg., 78, 
pp. 402–407. 
6. Croiset E. and Thambimuthu K.V. (2001), 
NOx and SO2 emissions from O2/CO2 
recycled coal combustion, Fuel, 80, pp. 2117–
2121. 
7. Tan Y.W., Croiset E., Douglas M.A. and 
Thambimuthu K.V. (2005), Combustion 
characteristics of coal in a mixture of oxygen 
and recycled flue gas, Fuel, 85, pp. 507–512. 
8. Liu H., Zailani R. and Gibbs B.M. (2005), 
Comparisons of pulverized coal combustion in 
air and in mixtures of O2/CO2, Fuel, 84, pp. 
833–840. 
9. Murphy J.J. and Shaddix C.R. (2006), 
Combustion kinetics of coal chars in oxygen-
enriched environments. Combustion and 
Flame, 144, pp. 710–729. 
10. Molina A. and Shaddix C.R. (2007), Ignition 
and devolatilization of pulverized bituminous 
coal particles during oxygen/carbon dioxide 
coal combustion. Proceedings of Combustion 
Institute, 31, pp. 1905–1912. 
11. Alam M.S., Wijayanta A.T., Nakaso K. and  
Fukai J. (2010b), Numerical predictions of 
syngas from mild combustion of pulverised 
coal, The second International Symposium on 
Gasification and Its Application (ISGA 2010), 
Fukuoka, Japan. 
12. Schaffel N., Mancini M., Szlek A. and Weber 
R. (2009), Mathematical modeling of MILD 
combustion of pulverized coal, Combustion 
and Flame, 156, pp. 1771-1784. 
13. Weber R., Smart J. and Vdkamp W. (2005), On 
the MILD combustion of gaseous, liquid, and 
solid fuels in high temperature preheated air, 
Proceedings of Combustion Institute, 30, pp. 
2623–2629. 
14. Launder B.E. and Spalding D.B. (1974), The 
numerical computation of turbulent flows, 
Comput. Meth. Appl. Mech. Eng., 3, pp. 269–
289. 
15. Magnussen B. F. and Hjertager B. H. (1976), 
16th International Symposium on Combustion, 
the Combustion Institute. 
16. Watanabe H. and Otaka M. (2006), Numerical 
simulation of coal gasification in entrained 
flow coal gasifier, Fuel, 85, pp. 1935-1943. 
17. Kajitani S., Hara S. and Matsuda H. (2002), 
Gasification rate analysis of coal char with a 
pressurized drop tube furnace, Fuel, 81, pp. 
539-546. 
Page 1016
*Corresponding Author: Md. Mizanur Rahman 
E-mail: mizanurpe@yahoo.com 
PRESSURE DATA ANALYSIS AND RESERVOIR PARAMETER ESTIMATION OF 
KAILASTILLA GAS FIELD (WELL NO. KTL-01& KTL-02) 
Md. Mizanur Rahman*, Arifur Rahman, Mohammad Shahedul Hossain, Md. Jakaria  
Department of Petroleum & Georesources Engineering 
Shahjalal University of Science and Technology, Sylhet-3114, Bangladesh 
Mobile: +88-01918766889 
E-mail: mizanurpe@yahoo.com 
ABSTRACT 
The reservoir parameter estimation on the basis of pressure transient data and production data at the well is an 
essential part in the prediction of reservoir behavior. The estimation of these parameters in a dynamical system is 
referred to as parameter estimation, identification or inverse problem. In this paper the reservoir parameters-
permeability, skin factor, average pressure, wellbore storage coefficient, reservoir drainage extent are estimated 
on the basis of pressure data observed at the wellbore and production data using build up test (MBH) and 
deliverability test methods. This paper represents the contribution in quantifying the effects of wellbore storage 
along with the skin intensity on deliverability from gas wells. Generalized charts for type curve studies on gas 
wells, based on pseudo-pressure and pressure squared concepts, along with wellbore storage, are presented with 
applications and support from field data. 
 
Key words: Single phase gas reservoir, type curve analysis, pressure transient test, skin factor and wellbore 
storage, inflow performance curve.  
 
1. INTRODUCTION  
Gas well test analysis is a branch of petroleum 
engineering. Information derived from flow and 
pressure transient tests about in-situ reservoir 
conditions is important in many phases of 
petroleum engineering. The reservoir engineer must 
have sufficient information about the reservoir/well 
conditions and characteristics to adequately analyze 
reservoir performance and forecast future 
production under various modes of operation. 
Pressures are most valuable and useful data in 
reservoir engineering. Directly or indirectly, they 
enter into all phases of reservoir engineering 
calculations. Therefore accurate determination of 
reservoir parameters is very important. In general, 
gas well test analysis is conducted to meet the 
following objectives: 
 Formation permeability 
 Average reservoir pressure 
 Connected reservoir pore volume 
 Degree of formation damage or 
stimulation 
 Distance to a fault if present 
 Fracture length 
 Fracture conductivity 
 Wellbore storage coefficient 
 Detection of reservoir heterogeneities such 
as fractures, layering and mobility changes 
 Reservoir areal extent 
 To estimate skin factor or drilling and 
completion related damage   
 
 
 
Page 1017
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
2. METHODOLOGIES AND 
OBJECTIVES  
         
2.1   OBJECTIVES  
The objectives of this study are to analyze the well 
test data available for well KTL-01 and KTL-02 to 
estimate the following parameters and finally these 
estimated parameters are compared with the 
previous study was conducted by Al Mansoori 
Wireline Services. 
 The formation permeability  
 The skin effect 
 Average reservoir pressure 
 Wellbore storage coefficient 
 Reservoir areal extents 
 Productivity of the formation and  
deliverability of the wells 
 The Absolute-Open-Flow-Potential 
(AOFP) of the wells 
 
2.2 Data Collection and Processing 
To accomplish this study all data are collected from 
“Sylhet Gas Fields Limited (SGFL)” through 
“Petrobangla” of Bangladesh.  
 
The raw data file contains some pressure data 
recorded before and after the test period, when 
pressure gauges were running and pulling 
respectively. The pressure data recorded before and 
after test period create some problem during 
analysis. It is not possible to obtain the desired 
parameters until remove these extra pressures data. 
To avoid complication in test interpretation and to 
obtain better results these data are filtered in the 
following ways. 
 
2.2.1 Data Removing 
There are three methods used to filter data. Here 
two methods, grid method and plot method are 
used. In grid method, highlighted the last row of 
“data recorded before test”, clicked right button of 
mouse over the row number column and finally 
clicked “delete all rows before” from the pop-up 
menu to delete selected rows. In the same way, the 
data recorded after the test is removed. 
In plot method, the specific point can be removed. 
In this study, the data outside the curve are 
removed by this method. Just, the specific data 
point is selected and clicked on delete button on the 
same toolbar to remove the point.  
 
 
 
2.2.2 Data Filtering 
To filter the data logarithmic time steps (300 points 
per log cycle) for build-up periods and arithmetic 
time steps (0.25 hr per time step) for flow periods 
are used. Data are filtered for obtaining better 
results only.  
 
The production data is entered manually into well 
testing software “FEKETE” after processing the 
pressure data. Finally, the PVT data and reservoir 
properties are entered. To estimate the desired 
parameters the semi log, log-log and derivative 
plots are used for pressure transient test  and, AOF 
and IPR curves are created for flow-after-flow test. 
These plots are analyzed and desired parameters are 
obtained.  
 
      2.3   Methodologies 
There are several methods may be used to estimate 
the reservoir parameters. The pressure build-up test, 
type curve analysis, Dietz_MBH method, and flow 
after flow test methods are used to complete this 
study. Permeability and skin due to damage are 
estimated by build-up test of radial analysis by 
developing semi log and derivative type curves. 
These values of parameters are used as input 
parameters for Dietz_MBH method. After entering 
these parameters into “FEKETE software” the 
Dietz_MBH method gives the output values of 
reservoir areal extents and these areal extents again 
used as input parameters for Dietz_MBH method 
and finally the average reservoir pressure is 
estimated. Finally, the absolute open flow potential 
(AOFP) is estimated by the flow after flow test. To 
conduct the flow after flow test the reservoir 
production rate and the pressure of sand face and 
well head are used. For this, inflow performance 
(IPR) and outflow performance (OPR) curves are 
created.  
 
 
 
 
 
Page 1018
3 RESULTS AND DISCUSSIONS 
3.1 Buildup Analysis 
From Table-1 it is obtained that the total skin effect 
( ) are negative for both well KTL-01 and well 
KTL-02. But it is tough to conclude that the wells 
are stimulated as all the skin components have not 
been analyzed here. 
 
The average reservoir pressure, Pavg (3499.3 psia) 
from Dietz_MBH analysis for KTL-01 in Table-1 is 
closer to initial reservoir pressure indicates that the 
reservoir is at its early stage of production. But in 
case of KTL-02 the average reservoir pressure is 
greater than the initial reservoir pressure. This may 
be the error at the time of data recording. The areal 
extents indicate the reservoir is rectangular in shape 
which is consistent with assumption. The results are 
tabulated here from pressure semi log plots, 
pressure derivative type curves and dimensionless 
type curves. The resultant values of a specific 
parameter obtained from all analysis methods are 
same. For this reason, the specific method has not 
been mentioned in Table containing results. 
 
The obtain results from this study are so much 
dissimilar with the results of Al Mansoori Wire 
lines Services model study though all the input 
parameters are near about same. The main reason of 
this dissimilarity is that, Al Mansoori Wire lines 
Services did not perform any diagnostic analysis. 
They found their results by model analysis only. It 
is also highly pointed out that, they mentioned in 
their report that their results were erroneous but 
they did not mention any reason of this erroneous 
results.   
 
 
 
 
 
Table-1: Results and comparison of this study and Al Mansoori Wireline Services for well KTL-01 and KTL-02 
 
 
 
Parameters 
Analysis Value Al Mansoori Wireline Services 
model value Remarks 
Well KTL-01 Well KTL-02 Well KTL-01 Well KTL-02 
K(md) 46.0842 699.098 147 4700 Average permeability 
Kh(md.ft) 2995.47 27963.92 9550 197000 Total permeability-
thickness product 
S- -5.557 -0.332 3 25 Total skin 
Sd Not found Not found Not available Not available Skin due to damage 
Pi(psia) 3515 3221 3515 3221 Initial pressure 
P*(psia) 3503.8 3223.8 Not available Not available Extrapolated pressure 
P(avg.)(psia) 3499.3 3222.4 Not available Not available Average reservoir pressure 
P(syn)(psia) 3658.7 3373.7 Not available Not available Synthetic pressure 
Xe(ft) 12736.735 14032.289 6000 4000 Reservoir length 
Ye(ft) 2188.818 1986.792 6000 4000 Reservoir width 
Xw(ft) 6368.367 7016.135 300 Not available Well location in X- direction 
Yw(ft) 1094.409 993.366 300 Not available Well location in Y-direction 
Page 1019
  
Figure-1: Semi log plots of radial analysis and Dietz_MBH model analysis for KTL-01  
 
 
 
 
 
 
 
 
 
 
 
 
Figure-2: Semi log plots of radial analysis and Dietz_MBH model analysis for KTL-02 
          
     
808
812
816
820
824
828
832
836
ψψ ψψ
 
(1
0
 
(1
0
 
(1
0
 
(1
066 66
pi
σ
ι
pi
σ
ι
pi
σ
ι
pi
σ
ι22 22
/χ
Π
)
/χ
Π
)
/χ
Π
)
/χ
Π
)
3440
3450
3460
3470
3480
3490
3500
p
 (p
si(a))
1.0101102103104 2345678234567823456782345678
Superposition Radial Pseudo-Time (Σ∆ta) (h)
ψdata
ψmodel
pavg
Ext. ψmodel
Dietz_MBH output
 pi (syn) 3663.0 psi(a)
 pavg 3503.5 psi(a)
 Cumgas 17.909 MMscf
Dietz_MBH input parameters
 kh 2995.47 md.ft
 h 65.000 ft
 k 46.0842 md
 sd -5.557
 Xe 13461.412 ft
 Ye 2070.986 ft
 Xw 6730.706 ft
 Yw 1035.493 ft
Radial analysis results
 kh 2995.47 md.ft
 k 46.0842 md
 s' -5.557
 p* 3503.8 psi(a)
 pavg 3503.5 psi(a)
560
580
600
620
640
660
680
700
720
740
760
780
800
820
ψψ ψψ
 
(1
0
 
(1
0
 
(1
0
 
(1
066 66
pi
σ
ι
pi
σ
ι
pi
σ
ι
pi
σ
ι22 22
/χ
Π
)
/χ
Π
)
/χ
Π
)
/χ
Π
)
2700
2800
2900
3000
3100
3200
3300
3400
p
 (p
si(a))
1.0101102103104 2345678234567823456782345678
Superposition Radial Pseudo-Time (Σ∆ta) (h)
ψdata
ψmodel
pavg
Ext. ψmodel
Dietz_MBH output
 pi (syn) 3373.7 psi(a)
 pavg 3222.4 psi(a)
 Cumgas 14.512 MMscf
Dietz_MBH input parameters
 kh 27963.92 md.ft
 h 40.000 ft
 k 699.0980 md
 sd -0.332
 Xe 14032.289 ft
 Ye 1986.732 ft
 Xw 7016.145 ft
 Yw 993.366 ft
Radial analysis results
 kh 27963.92 md.ft
 k 699.0980 md
 s' -0.332
 p* 3223.8 psi(a)
 pavg 3222.4 psi(a)
Page 1020
3.2 Flow-After-Flow Test Analysis  
The obtained value of ‘n’ for KTL-01 from both 
pseudo-pressure method and pressure squared 
method in case of sand face flow and well head 
flow indicate the Darcy flow which are consistent 
with assumption of the empirical equation . On the 
other hand, the value of n for KTL-02 in case of 
sand face flow indicates the non-Darcy flow but in 
case well head flow it indicates a Darcy flow. This 
is because; it was not possible to record the 
production test appropriately for KTL-02 due to 
inactiveness of gas flow meter. 
The flow-after-flow test analysis results obtained 
from this study are so much dissimilar with the 
results obtained from Al Mansoori Wire Lines 
Services. This may happen for several causes as, Al 
Mansoori Wire Lines Services was performed 
model analysis only which is theoretical, the 
obtained value of ‘n’ from their study is 1.15 for 
KTL-01 which should be in between 0.5 to 1.0.  
Table-2: Deliverability test results for KTL-01 in 
terms of pressure squared 
Parameter 
Sand face 
value 
Well head 
value 
Pavg(psia) 3499.3 2860 
AOF(mmscfd) 293.210 237.292 
C[(mmscfd/106)/(psi2)n] 8.50e02 2.57e02 
N 0.781 0.863 
 
 
 
 
 
 
 
Table-3: Deliverability test results for KTL-02 in 
terms of pressure squared 
Parameter 
Sand face 
value 
Well head 
value 
Pavg(psia) 3222.4 2714.7 
AOF(mmscfd) 531.567 216.251 
C[(mmscfd/106)/(psi2)n] 1.65e05 2.93e01 
n 0.5 1.0 
 
Table-4: Comparison of sand face flow-after-flow 
test results in terms of Pseudo-pressure with Al 
Mansoori Wireline Services model results for KTL-
01 
Parameters 
Analysis 
Value 
Al 
Mansoori 
value 
AOF (mmscfd) 336.961 852.2 
C 
[mmscfd/(106psi2/cp)n] 
1.80 4.86e01 
n 0.778 1.15 
 
Table-5: Comparison of sand face flow-after-flow 
test results in terms of Pseudo-pressure with Al 
Mansoori Wireline Services model for KTL-02  
Parameters 
Analysis 
Value 
Al 
Mansoori 
value 
AOF (mmscfd) 583.610 3575 
C 
[mmscfd/(106psi2/cp)n] 
2.1401 7.99e05 
n 0.5 0.638 
 
 
 
Page 1021
 Figure-3: Sand face flow after flow test analysis curve in terms of Pseudo-pressure for KTL-01 
 
 
Figure-4: Sand face flow after flow test analysis in terms of Pseudo-pressure for KTL-02 
 
          
     
101
102
103
2
3
4
6
2
3
4
6
2
3
5
∆
ψ
∆
ψ
∆
ψ∆ψ
 
(1
0
 
(1
0
 
(1
0
 
(1
066 66
pi
σ
ι
pi
σ
ι
pi
σ
ι
pi
σ
ι22 22
/χ
Π
)
/χ
Π
)
/χ
Π
)
/χ
Π
)
101 102 1032 3 4 5 6 7 8 9 2 3 4 5 6 7 8 9
Gas Rate  (MMscfd)
Isochronal Points
FAF test(sandface)
analysis output
 AOF 336.961 MMscfd
 n 0.778
 C 1.80e+00 MMscfd/(106psi2/cP)n
 pi 3499.3 psi(a)
10-2
10-1
1.0
101
102
103
2
4
2
4
2
4
2
4
2
4
2
4
∆∆ ∆∆
ψψ ψψ
 
(10
6 p
si
2 /c
P)
1.0 101 102 1032 3 4 5 6 7 8 9 2 3 4 5 6 7 8 9 2 3 4 5 6 7 8 9
Gas Rate  (MMscfd)
Isochronal Points
FAF test (sandface)
analysis output
 AOF 583.610 MMscfd
 n 0.500
 C 2.14e+01 MMscfd/(106psi2/cP)n
 pi 3222.4 psi(a)
Page 1022
CONCLUSION 
In this study pressure buildup data and 
deliverability data are analyzed and different 
reservoir parameters are estimated. These 
parameters are compared with the previous study of 
Al Mansoori Wire Lines Services, which revealed 
better results of this study and fortified the robust 
analysis procedure. 
 
 
REFERENCES 
1. Al Mansoori Wireline Services (2007), 
Pressure Transient Analysis Report of 
Kailastilla Gas Field. 
2. Cobb, W.M., Smith, J.T. and Denson, A.H.: 
“Determination of Well Drainage Pore Volume 
and Porosity from Pressure Buildup Tests,” 
SPEJ (August 1976) 209-216. 
3. Craft, B. C., and Hawkins, M. F., Applied 
Petroleum Reservoir Engineering,  
 PrenticeHall, Inc., Englewood Cliffs (1959).  
4. Dake, L.P., “Fundamentals of Reservoir 
Engineering”. Elsevier, Amsterdam-London-
New York-Tokyo. 
5. Economides, J. Michael &Hill Daniel A., and 
Ehlig-Economides Christine. “Petroleum 
Production Systems”. Prentice Hall PTR, 
Upper Saddle River, New Jersey 07458. 
6. Horne, N.Ronald, “Modern Well Test 
Analysis” A Computer-Aided Approach, Forth 
printing. 
7. Horner, D.R.: “Pressure Build-Up in Wells,” 
Proc., Third World Pet. Congress, Sec II 
(1951) 503. 
8. Imam, Badrul. “Energy Resources of 
Bangladesh”. UGC Publication No. 89, ISBN 
984-809-020-1. 
9. Lee, John and Wattenbarger, A.R. (1996). “Gas 
Reservoir Engineering”, SPE Textbook Series, 
Vol. 5 (Dallas, TX: Society of Petroleum 
Engineers) 
10. Lee, John “Well Testing”, Society of 
Petroleum Engineers of AIME, New York 
(1982), Dallas. 
11. Rahman Md. Mizanur and Rahman Arifur 
(2010), “Pressure Data Analysis and Reservoir 
Parameter Estimation of Kailastilla Gas Field”. 
12. Muskat, M.: Physical Principles of Oil 
Production, McGraw-Hill Book Co., Inc., New 
York, 1949, pp. 126. 
13. Tiab, Djebbar, “Gas Reservoir Engineering”. 
PE 4613-Lecture Notes 
14. Ursin,J.R. & Zolotukhin,A.B., “Reservoir 
Engineering”.  
 
 
Page 1023
 
Paper ID No.: CERIE-393 
Field of work: Petroleum Engineering 
E-mail: bakhtiar_pe@yahoo.com  
 
RESERVOIR CHARACTERIZATION USING GEOSTATISTICAL 
METHOD 
 
Bakhtiar Ahmed and Md. Jakaria 
Departement of Petroleum and Georesources Engineering, 
Shahjalal University of Science and Technology, Sylhet, Bangladesh. 
 
Dr. M. Mahbubur Rahman 
             Department of Petroleum & Mineral Resources Engineering, BUET, Dhaka, Bangladesh 
 
ABSTRACT 
 
Reservoir characterization is the process of describing various reservoir characteristics with the exploitation 
of available data. Petroleum reservoirs are generally heterogeneous in nature. This heterogeneity is captured 
with different reservoir properties. Geostatistics is a statistical technique that accounts the spatial variation of 
these reservoir properties. This paper focuses on geostatistical approach to provide porosity distributions of 
the reservoir based on available porosity-permeability data at different well locations. Isotropic variogram 
models are applied first and then kriging technique to estimate spatial distribution of porosity. Cokriging 
technique is then applied to incorporate a second variable- the permeability and the result is the more robust 
estimation of the variable. The final porosity distribution is presented in a 2-D map. Finally, the cross 
validation is completed to assess the reliability of estimation. 
 
Keywords: Reservoir characterization, Geostatistics, Variogram, Kriging, porosity-permeability. 
 
1. INTRODUCTION 
 
Reservoir characterization on the basis of available 
data is essential for proper reservoir management. 
Ideally, all the different sources of data should be 
incorporated for reservoir characterization for better 
description. In practice, however, several problems 
are associated with the utilization of all the data at a 
time. The problems include: all the data are not 
available at the same time, the quality of data 
collected from various sources may differ, 
information collected from different sources may 
not be measured at the same scale and data 
interpretation may be qualitative rather than 
quantitative. As a result of these limitations, the 
reservoir characterization is usually completed 
based on the part of the available data. 
 
Another problem in reservoir characterization arises 
due to the spatial heterogeneity associated with a 
reservoir. The data dealt under this study such as 
permeability and porosity are macroscopic 
heterogeneities measured at a core level. 
Geostatistics is an excellent tool to capture 
reservoir heterogeneity and generate spatial 
distribution of reservoir properties for each virtual 
grid. 
2. GEOSTATISTICS 
 
The main reason of using Geostatistics for reservoir 
characterization is that, geostatistical procedures are 
versatile enough to apply in several purposes 
related to reservoir description. This includes- 
interpolation and extrapolation of the values at 
unsampled locations, providing the quantitative 
relationship describing the spatial variability of a 
reservoir property, providing different ways of 
defining uncertainties in estimated values at 
unsampled locations, incorporating other variables 
to estimate one variable. The relationships may 
include information concerning how neighboring 
values of the same variable are related to each other 
or information concerning what the chances are that 
two different variables are close to each other. This 
can not be done by conventional statistical methods 
such as inverse-distance-weight (IDW) or normal-
distance-weight (NDW). 
 
The basic principle of Geostatistics is that, in many 
natural phenomena, data values that are close 
together intrinsically have higher spatial correlation 
than points that have higher separation distance. 
Application of Geostatistics is a three-step 
procedure: 1) assumption of stationarity, 2) spatial 
Page 1024
  
modeling of sample data (variogram analysis and 
modeling), and 3) estimation of a variable value at 
unsampled locations (kriging or cokriging). 
 
3. METHODS 
 
Before performing the modeling and estimation, 
data should be carefully analyzed to identify 
patterns within the known data to determine if 
points are uniform, random, isotropic or 
anisotropic, correlated or clustered. The data 
analysis is performed through the calculation of 
mean, variance, minimum, maximum, standard 
deviation, histograms, scatter plots, cross plots etc. 
The final analysis begins according to the 
knowledge of these summarized results. 
 
3.1. Measures of spatial distribution 
 
3.1.1. Variogram: The most common spatial 
distribution analysis is variogram analysis and 
modeling. Variogram is a prerequisite for 
estimation by kriging and cokriging. The 
variogram, γ(h), is half the average squared 
difference between paired data values. 
Mathematically it is defined as 
 
γ(h) = [1 / 2N(h)] Σ [ xi – xi+h ]2          (1) 
 
where, 
γ(h) = Semivariance for interval distance class h; 
xi = measured sample value at point i; 
xi +h = measured sample value at point i+h; and 
N(h) = total number of sample couples for the lag 
interval h.  
 
3.1.2. Isotropic variogram models: The variogram 
is a graph of semivariance vs. separation distance. 
Where autocorrelation is present, semivariance is 
lower at smaller separation distances 
(autocorrelation is greater). This typically yields a 
curve such as that described in Figure-1, which can 
be modeled using three terms – a nugget variance, a 
sill, and a range.  
 
There are three most common types of isotropic 
models (Spherical, Exponential and Gaussian), each 
of which can be described based on three 
parameters: 
  
Nugget Variance or Co – the y-intercept of the 
model; the nugget variance can never be greater 
than the sill.  
 
Sill or Co+C – the model asymptote; the sill can 
never be less than the nugget variance.  
 
Range (A) – the separation distance over which 
spatial dependence is apparent. This is sometimes 
called Effective Range in order to distinguish range 
(A) from a model’s range parameter (Ao). The 
Range A is calculated from Ao as described later in 
the formulas for the different models. 
 
The spherical isotropic model is a modified 
quadratic function for which at some distance A0 
pairs of points will no longer be autocorrelated and 
the semivariogram reaches an asymptote. The 
formula used for this model is:  
 
γ(h) = C0 + C [1.5(h / A0) - 0.5(h / A0)3] (2) 
for h ≤ A0 
 
γ(h) = C0 + C    (3) 
for h > A0 
 
In the case of the spherical model, the effective 
range A = A0. 
 
The exponential isotropic model is similar to the 
spherical in that it approaches the sill gradually, but 
different from the spherical in the rate at which the 
sill is approached and in the fact that the model and 
the sill never actually converge. The formula used 
for this model is:  
 
γ(h) = C0 + C[1 - exp(-h / A0)]  (4) 
 
In the case of the exponential model, the effective 
range A = 3A0. 
 
The Gaussian or hyperbolic isotropic model is 
similar to the exponential model but assumes a 
gradual rise for the y-intercept. The formula used 
for this model is:  
 
γ(h) = C0 + C[1 - exp(-h2 / A02)]  (5) 
 
In the case of the Gaussian model, the effective 
range A = 30.5A0. The sill never meets the 
asymptote in the Gaussian or exponential models. 
 
3.2. Estimation techniques 
 
3.2.2. Kriging: The Kriging technique uses a linear 
estimation procedure to estimate a value at 
unsampled locations. In principle, the technique 
assumes that the value at the unsampled location is 
estimated by 
 
ܺ∗ ( ݑ଴ሬሬሬሬ⃗  ) =  ∑   ߣ௜ ܺ ( ݑሬ⃗ ௜)௡௜ୀ଴   (6) 
 
Where, 
ܺ∗ ( ݑ଴ሬሬሬሬ⃗  ) = the estimated value at the unsampled 
location, 
Page 1025
  
ܺ ( ݑሬ⃗ ௜) = the value at the neighboring location, ݑሬ⃗ ௜ ,  
n = the total number of samples selected within a 
search neighborhood, and 
ߣ௜  = the weight assigned to the neighboring value. 
 
In other words, the estimated value is a weighted 
average of the neighboring values. All of the 
kriging algorithms use this basic equation with 
minor variations, depending on the particular 
application. 
 
There are two common types of kriging procedures: 
simple kriging and ordinary kriging. Simple kriging 
requires knowledge of the mean, which may not be 
known in practice without prior assumptions. 
Therefore, this type of kriging procedure is not very 
popular. Simple kriging starts with the assumption 
that a value at an unsampled location can be 
estimated by 
 
ܺ∗  ( ݑ଴ሬሬሬሬ⃗  ) =  ߣ௢ +  ∑   ߣ௜  ܺ( ݑሬ⃗ ௜)௡௜ୀଵ       (7) 
 
Where, ߣ௢  is a constant. 
 
Ordinary kriging is the most popular technique, 
which eliminates the need for knowledge of the 
mean value. It also is easier to adapt to local 
variations. It is the most widely applied kriging 
technique. The estimate is written as 
 
ܺ∗  (ݑሬ⃗ ଴) = ∑ ߣ௜  ܺ (ݑሬ⃗ ௜)௡௜ୀଵ                           (12) 
 
forcing ߣ௢  to be zero. 
 
3.2.3. Cokriging: Cokriging is an interpolation 
technique that allows one to better estimate map 
values if the distribution of a secondary variate is 
known. The secondary variate (also called a 
covariate or Y) is sampled from the same locations 
as the primary variate X, and also from a number of 
additional locations. If the primary variate is 
difficult or expensive to measure, then cokriging 
can greatly improve interpolation estimates without 
having to more intensely sample the primary 
variate. 
 
The cokriging estimate is based not only on 
distance to nearby sample locations for X and the 
variogram for X, but also distance to nearby sample 
locations for Y, the variogram for Y, and the cross-
variogram for X x Y. This can provide a more 
robust estimate of X at unsampled locations if X 
and Y are sufficiently correlated. 
 
Prior to cokriging one must a) define a covariate, b) 
perform semivariance analysis (including 
variogram modeling) for the primary variate X, for 
the covariate Y, and c) for the cross variate X x Y. 
To estimate a value, ݑ)∗ݔሬ⃗ ଴) at the unsampled 
location, ݑሬ⃗ ଴ we can write the estimation equation as 
 
ܺ∗(ݑሬ⃗ ଴) =  ∑ ߣ௫೔∗௡௜ୀଵ ܺ൫ݑሬ⃗ ௫೔൯+  ∑ ߣ௬ೖ∗௡௞ୀଵ ܻ(ݑሬ⃗ ௬ೖ) (15) 
 
Where, ߣ௫೔  is the weight assigned to the sample, 
ܺ(ݑሬ⃗ ௫೔), located at ݑሬ⃗ ௫೔ and ߣ௬ೖ is the weight 
assigned to the sample, ܻ(ݑሬ⃗ ௬ೖ), located at ݑሬ⃗ ௬ೖ. 
 
3.3. Cross validation 
 
Cross validation involves the estimation of values 
at the sampled locations so that the estimation can 
be compared with the sampled values. The most 
common cross validation involves the “leaving one 
out” method. In this method, one sample point at a 
time is removed from the sample data, and using 
the remaining sample points, the value of the 
variable at the now “unsampled” location is 
estimated. The estimated value is then compared 
with observed value. The procedure is repeated at 
all sampled locations, to have an estimated value at 
every sampled location.  
 
4. RESULTS AND DISCUSSIONS 
 
4.1. Porosity prediction 
 
To determine the spatial relationship of porosity 
values several variograms are calculated. Three 
variogram models (Spherical, Exponential and 
Gaussian) are analyzed to capture best continuity. 
Only spherical model is shown in Fig. 1. 
 
 
Fig. 1: Spherical isotropic variogram of porosity. 
(Nugget = 0.69, Sill = 10.29, range = 2170 meters). 
 
The variogram properties are then used for ordinary 
kriging. The result shows how kriging produces a 
crude contour of actual data samples (Fig. 2). Near 
the well points and at small search neighborhoods, 
bull’s eyes are apparent. The erroneous constant 
porosity region shows the lack of well control and 
effect of extrapolation. The standard deviation near 
the well points is around 0.7 and more than 3 where 
0.0
 
 
2.7
 
 
5.5
 
 
8.2
 
 
11.0
0.00   2856.89   5713.78   8570.67
Se
m
iv
ar
ia
nc
e
Separation Distance (h)
Page 1026
 estimation lacks of well control. Cross validation 
(Fig. 3) shows standard error of ±69.8%, showing 
that the kriging estimation model is highly 
erroneous. 
 
 
 
 
Fig. 2: Porosity distribution map resulted from ordinary kriging. 
 
Fig. 3: Cross validation for ordinary kriging. 
 
To minimize the estimation error, cokriging is 
performed incorporating a second variable 
(permeability) to establish the porosity distribution.  
 
The process of estimation by cokriging is similar to 
kriging except it exploits a second variable and thus 
the variogram of permeability and a cross 
variogram of porosity-permeability have to be 
calculated. The variograms are shown in Fig. 4 and 
Fig. 5. 
 
 
 
 
 
Fig. 4: Spherical isotropic variogram of 
permeability. (Nugget = 2700, Sill = 64080, range 
= 2180 meters). 
 
 
2853700.  2855563.  2857425.  2859288.  2861150.
X direction
691400.
 
 
694333.
 
 
697267.
 
 
700200.
Y 
di
re
ct
io
n
x
x
x
xx
x
x
x
x
x
x
x
x
x
x
Porosity
26.4
25.5
24.7
23.9
23.0
22.2
21.4
20.5
19.7
18.9
18.0
17.2
16.4
15.5
14.7
13.9
0.
 
 
16650.
 
 
33300.
 
 
49950.
 
 
66601.
0.00   2856.89   5713.78   8570.67
Se
m
iv
ar
ia
nc
e
Separation Distance (h)
Page 1027
  
 
Fig. 5: Spherical isotropic cross variogram of 
porosity and permeability. (Nugget = 6, Sill = 
597.7, range = 1990 meters). 
 
The estimation map obtained from simple cokriging 
provides relatively better picture of porosity 
distribution (Fig. 8). Cross validation (Fig. 10) with 
a standard error of ±7% indicates a good estimation 
model. 
 
However, in both cases bull’s eyes and crude 
contouring around well points are apparent which is 
due to the lack of sufficient sample points and may 
be the aberration of stationarity at extreme values. 
 
 
 
 
 
Fig. 6: Porosity distribution map resulted from simple cokriging. 
 
 
 
Fig. 7: Cross validation of simple cokriging estimate. (SE=0.007) 
0.
 
 
160.
 
 
320.
 
 
480.
 
 
641.
0.00   2856.89   5713.78   8570.67
Se
m
iv
ar
ia
nc
e
Separation Distance (h)
2853700.  2855563.  2857425.  2859288.  2861150.
X direction
691400.
 
 
694333.
 
 
697267.
 
 
700200.
Y 
di
re
ct
io
n
x
x
x
xx
x
x
x
x
x
x
x
x
x
x
Porosity
26.3
25.4
24.6
23.8
22.9
22.1
21.3
20.4
19.6
18.8
18.0
17.1
16.3
15.5
14.6
13.8
Page 1028
  
5. CONCLUSION 
 
Characterizing a gas reservoir is a complex and 
costly procedure. Prediction of reservoir properties 
in different grids is essential for numerical reservoir 
simulation. Geostatistics provides good estimation 
techniques allowing the analysis of spatial 
distribution of values and error analysis. In this 
study, porosity distribution model predicted by 
cokriging gives good estimation as expected. 
However, the methods applied here could not 
produce a clear picture at a distance apart from the 
well points and the distinct zone may represent 
different zone of stationarity. The estimation model 
can be improved by incorporating other well points 
from future wells. Besides, the methods are 
versatile enough to estimate heterogeneous 
reservoir properties. 
 
REFERENCE 
 
1. Alqassab, H. M., and Heine, C. J., 1999, A 
geostatistical approach to attribute 
interpolation using facies templates, an 
advanced technique in reservoir 
characterization. Saudi Aramco Journal of 
Technology, Spring 1999, P. 53 – 64. 
2. Deutsch, C. V., Journel, A. G., 1997, GSLIB: 
Geostatistical software library and user’s 
guide. 
3. Dubrule, O., and Damsleth, E., 2000, 
Achievements and challenges in petroleum 
geostatistics. Petroleum Geoscience, Vol. 7, 
2001, P. S1–S7. 
4. Gosse, C. L. G., November 1999, 
Geostatistical Analysis Of Little Bow Oil 
Field, Alberta, Canada. Department of Geology 
and Geophysics, University of Calgary, 
Alberta, Canada. 84 pages. 
5. Kelkar, M., Perrez, G., Applied Geostatistics 
for Reservoir Characterization, SPE, 2002. 
6. Issaks, E. H., and Srivastava, R. M., 1989, An 
Introduction to Applied Geostatistics, Oxford 
University Press. 
 
 
 
Page 1029
 Structural Analysis of Fenchugonj Gas Field 
*Pulok Kanti Deb and M. Farhad Howladar  
Department of Petroleum & Georesources Engineering,  
Shahjalal University of Science & Technology, Sylhet-3114, Bangladesh. 
E-mail: dmfh75@yahoo.com  
ABSTRACT 
The Fenchugonj structure is located in the southern part of the Surma Basin, Bangladesh. The paper presents 
an integrated interpretation of seismic data considering the available geologic information. Nine seismic 
sections of this area have been analyzed to interpret the subsurface geology, structure and stratigraphy. 
Based on the seismic sections and well data, two prominent reflecting horizons have been identified. The 
litho-stratigraphy of the Fenchugonj structure is prepared on the basis of well information. The lithological 
sequences encountered in the area ranging from Oligocene to Pliocene age. The gas bearing sands of the 
structure are within Lower Bokabil to Upper Bhuban Formations of the Late Miocene age. The seismic study 
indicates that the Fenchugonj structure is a low hillock, high amplitude fold which is EW elongated anticline 
affected by a major reverse fault on the eastern flank. It is an asymmetrical anticline with the axis of steep 
north flank and gentle south flank. 
Keyword: Fenchugonj structure, Seismic interpretation, Stratigraphy, Reverse fault.  
1. INTRODUCTION 
Bangladesh belongs to a young deltaic sedimentary 
basin named as the Bengal basin. The development 
of the Bengal Basin meets the geological require-
ments for the generation and accumulation of natu-
ral gas in the subsurface. Fenchugonj field is lo-
cated near the western margin of the folded belt 
into the Bengal Basin which appeared as a re-
versely faulted anticline with a NNE-SSW 
trending axis. It is bounded by Longitude E 91053’ 
– 920 and Latitude N 24030’ – 24037’ and is 30 km 
long and 8 km wide. Fenchugonj structure is si-
tuated on the Sylhet trough, formed due to con-
tinuous uplift of Shillong Massif with simulta-
neous subsidence, is oval shaped and 
represents negative anomaly. It is sharply 
asymmetric with steep north flank and gentle 
south flank. Fenchugonj structure is consisting of 
alternate shale and sandstone in varying proportion. 
The eastern folded belt comprises sediments of 
Oligocene to Recent age. This field was discovered 
by Petrobangla in 1988 and it should be noted here 
that after discovering this field, no significant re-
search have yet been performed on the Structural 
development of the area. Thus, the objective of this 
research is to reconstruct structural maps of the 
interfaces between formations, identifies channel, 
fault and other structure delegation at seismic lines 
and finally interprete the analyzed results for under-
standing the Structural development of the area. 
2. METHODOLOGY  
Seismic prospecting is the best and most popular 
indirect method used for locating subsurface struc-
tures and stratigraphy that may contain hydrocar-
bons. The basic seismic method is consisting of 
data acquisition, processing and interpretation 
equipment which has three main components such 
as an input source, an array of detectors and a re-
cording instrument. The type and relative size of 
the acoustic-impedance changes called the Reflec-
tion coefficient and the time taken from the initial 
bang to the recording of a reflection is called Two-
way time (TWT). At the processing stage,  basically 
five items of correction (such as Preprocess, Cor-
rection of amplitude, Correction of travel time, 
CDP stacking and Imaging) have done to get a clear 
image of the subsurface structure from the raw shot 
record. In each stage of processing, careful analysis 
of data and parameter tests are required to optimize 
the result. The actual requirements and equipment 
also needed to carry out a seismic interpretation. 
In this paper, seismic reflection and well log data 
were mainly used which were obtained from Ban-
gladesh Petroleum Exploration & Production Com-
*Pulok Kanti Deb 
E-mail: pulok_pe@yahoo.com 
Page 1030
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
  
pany Limited (BAPEX) which has been interpreted 
to obtain information on the structure of the area. 
Nine 2-D seismic reflection sections of the study 
area have been analyzed. In order to interpret seis-
mic sections, seismic marker horizons were se-
lected and reflection times were picked to make the 
cross-sectional maps by developing time and depth 
structure maps. 
3. RESULT & ANALYSIS OF INTER-
PRETATION 
3.1 Interpretation of Seismic data 
Seismic interpretation is the process of determining 
information about the subsurface of the earth from 
seismic data. There are two main approaches to the 
interpretation of seismic sections: Structural analy-
sis which is the study of reflector geometry on the 
basis of reflection times, and Stratigraphic analysis 
which is the analysis of reflection sequences as the 
seismic expression of lithologically distinct deposi-
tional sequences. Structural interpretation is the 
first major step of geophysical interpretation and 
main application is in the search for structural traps 
containing hydrocarbon. During 1979 – 1981, Prak-
la Seismos carried out multifold seismic survey on 
behalf of BOGMC (then BAPEX, subsidiary of 
Petrobangla). The seismic data has 12 fold stacking, 
finite difference migrated sections, in which three 
(3) strike lines (such as: PKFG-2 EXT., PKFG-9 & 
PKFG-8) and six (6) dip lines (such as: PKFG-1, 
PKFG-3, PKFG-4 EXT., PKFG-5, PKFG-6 & 
PKFG-7) were shot using in UP (Underground 
Point) location map of Fenchugonj structure. The 
quality of the seismic data used for this interpreta-
tion was fair to good. 
A structure contour is an imaginary line connecting 
points of equal altitude on a single horizon. The 
closer the structure contours are to each other, the 
steeper is the dip. The slope is also the steeper (Bil-
lings, 2005). For structural interpretation, well #3 is 
considered, seismic line PKFG–4 is considered as 
the basis strike line at SP (Shot point) 214 m. show 
two gas horizons, which are named Upper and 
Lower gas sands respectively. All sections were 
interpreted manually by hand and prepared time & 
depth structure contour maps, where depth conver-
sions by using T-Z (Time-Depth) curve, which are 
more authentic. 
3.2 Cross-sectional map of Fenchugonj 
structure 
Cross-sectional maps were constructed from depth 
contour maps, which graphically representation of 
structure. It is the easiest method for anyone to un-
derstand the ground structure and true subsurface 
geometry (Figures 1& 2). 
 
 
Fig. 1: Cross -sectional map for Upper Gas Sand 
Page 1031
  
 
Fig. 2: Cross -sectional map for Lower Gas Sand 
3.3 Structural Interpretation 
The time contour map shows the structure having 
the NNE-SSW structural trends. The structural 
trend of this gas sand is marked in the contour map. 
The horizons in the seismic sections are interpreted 
and show that they are high amplitude folds with 
single fault. Especially, this fault is termed as anti-
clinal reverse fault. 
Billings (2005) stated that reverse fault is genetic 
type of thrust fault and formed when dips more than 
450. They may develop in crystalline rocks or in 
sedimentary rocks before or after they are folded. 
Rocks are relatively brittle; a sharp break may de-
velop on one side of an anticline, as a result of 
which the older rocks are thrust over the younger 
rocks. A thrust running parallel to the axis, parti-
tions the anticline of the Fenchugonj area. The fault 
system in the area has been interpreted as an N-S 
oriented fault zone, which is compatible with re-
gional fault trend and stress regime of the eastern 
folded belt of Bengal Basin. Its affects on the east-
ern part of the anticline are visible in all the dip 
lines, mainly in PKFG-1, PKFG-4 and PKFG-6. 
The fault planes of the area were correlated in a 
band type fashion and the displacement of fault is 
more prominent in the northern part than in the 
south, which indicates that in the northern part 
thrusting effect is high and towards the south 
thrusting is less. Moreover, from surface geological 
map, the amount of dips in the eastern flank varies 
from 300-350 and in the western flank varies from 
200-250. From this point of view, genetically we can 
compare this fault with thrust fault and termed as 
reverse fault. 
4. CONCLUSION  
The Fenchugonj gas field comprises three wells. 
The Fenchugonj well #1 was drilled to evaluate dry 
well and well #3 was drilled to appraise and devel-
op the well. The Fenchugonj well #2 was drilled to 
evaluate gas prospect, where two gas zones (UGS 
& LGS) were identified. Only Reverse faults can be 
clearly identified by structural interpretation. Chan-
nel and other features could not be identified due to 
limitation of field data. The structural configuration 
of the Fenchugonj anticline is smooth and uniform 
throughout the area. The contour shape is elongated 
in NNE-SSW direction. An EW oriented fault zone 
in the area has been interpreted, which is compati-
ble with regional fault trend and stress regime of 
the Eastern fold belt of the Bengal Basin. Finite 
difference migrated seismic lines has good perfor-
mance with low S/N ratios and is adaptable to hori-
zontal velocity gradients. This is also relatively 
expensive and has difficulty with steep deep. The 
success of interpretation also will depend on the 
density of the seismic grid. 
 
 
  
Page 1032
  
REFERENCES 
1. Badley, M.E., 1985: Practical Seismic Interpreta-
tion, D. Reidel Publishing Company, Boston/ Dor-
drecht/ Lancaster, p. 1-4, 79, 133-135, 140, 147, 
158, 165, 188, 195-196, 203, 222-227. 
2. BAPEX, Geological Division, 1988: Well Report 
On Fenchugonj Well no. #2, [unpublished]. 
3. BAPEX, Geological Division: Well Report On 
Fenchugonj Well no. #3, [unpublished]. 
4. Billing, M. P. 2005: Structural Geology (3rd 
ed.). Prentice Hall of India Private Limited, 
India. p. 196, 214 – 216, 229, 230, 236, 534 – 
536. 
5. Imam, B., 2005: Energy Resources of Bangla-
desh, Published by University Grants Commission 
of Bangladesh, Dhaka. p. 19-32, 50-54, 67, 85, 105, 
168. 
6. HCU & NPD, 2004: Bangladesh Gas Reserve 
Estimation,  Published by Energy & Mineral Re-
sources Division, Ministry of Power, Energy and 
Mineral Resources, Bangladesh & Norwegian Pe-
troleum Directorate (NPD), Norway. p. 4, 153-158, 
168, 211.
 
 
Page 1033
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author 
E-mail: sho_fiq@yahoo.com 
The orientation of Dauki Fault: an approximation using the 2D finite 
element modeling 
 
 
Md. Shofiqul Islam*1, 2 and Ryuichi Shinjo1 
1. Faculty of Science, University of the Ryukyus, Senbaru 1, Nishihara, Okinawa, 903-0213, Japan 
2. Department of Petroleum and Georesources Engineering, Shahjalal University of Science and 
Technology, Sylhet 3114, Bangladesh 
 
 
The Dauki Fault is a major fault along the southern boundary of the Shillong Plateau. Its location may be a 
cause of the formation of destructive seismic hazard for the adjoining areas, including northeastern 
Bangladesh. In this study, we simulated the present-day stress distribution and the ongoing convergent-
induced deformation within the study area using numerical simulation. This is an attempt to reveal the 
proper orientation of the Dauki Fault reflected in different models but maintaining realistic boundary 
conditions. The maximum compressive stresses which show the significant stress orientations helped us 
recreate the type of tectonic environment and the faulting patterns of the study area. The model predicts the 
compressive stress regime in the study area but excluded the uppermost-part of the Shillong Plateau, the 
Bengal Basin and Assam areas where extensional stress regimes are known to exist. These extensional stress 
regimes support the NE-SW normal faulting over the plateau area. Rock domain properties and Mohr-
Coulomb’s failure criterion were used to calculate failures in stress field. The failure elements within the 
model are comparable with the observed earthquake data that referred the Dauki fault as a north-dipping 
thrust fault. 
 
Key words: Dauki Fault, Bengal Basin, tectonic stress, earthquake.  
 
1. INTRODUCTION 
 
The Dauki Fault runs from East to West of the 
Shillong Plateau and has a major role on the 
regional deformation of the adjoining areas.  The 
fault may be a potential zone for future earthquake 
in Bangladesh (Islam et al., 2010a, b). The Dauki 
Fault separates the plateau by ~17 km thick Tertiary 
to recent thick sediments of the Bengal basin to the 
south (Uddin and Lundberg, 1998). However, the 
Shillong Plateau is characterized by seismically 
active and geologically complex region (Fig. 1). 
The surface of the 2-km-high plateau consists of 
Archaean rocks, and equivalent rocks lie 4±5 km 
below sea level to the north and south of the plateau 
(Evan, 1964, Bilham and England, 2001). Bilham 
and England (2001) suggested that the Assam 
earthquake was caused by the ‘pop up’ tectonics 
between the north dipping of the Dauki Fault and 
south dipping hidden in the Odham Fault, though 
the existence of the Oldham Fault is controversial 
and recent studies (Srinivasan, 2004; Das et al., 
2005; Rajendran et al., 2004; Islam et al., 2010a) do 
not support the existence of the Oldham fault. 
Moreover, Rajendran et al. (2004) proposed that 
Brahmaputra fault (~20 km away from proposed 
Oldham Fault) may be the northern boundary fault 
of the Shillong Plateau. On the contrary, Evans 
(1964) and Nandy (2001) argued that the Dauki 
Fault is nearer to a vertical or a south dipping strike 
slip/normal fault than to a north dipping thrust fault. 
However, Gravity data and earthquake focal 
mechanisms (Verma and Mukhopadhyay, 1977; 
Chen and Molnar, 1990; Mitra et al., 2005) support 
the existence of thrust or reverse faults beneath at 
the southern part of the Shillong Plateau (Oldham, 
1899; Evan 1964; Hiller and Elahi, 1984; Johnson 
and Alam, 1991; Bilham and England, 2001; 
Srinivasan, 2005; Clark and Bilham, 2008). 
 
Due to political boundary between Bangladesh and 
India, the Dauki Fault was ignored from tectonic 
synthesis. In fact, no detailed geophysical survey 
had been or yet to be conducted. Definitely, there 
are many unanswered questions regarding the 
Dauki Fault’s dynamics including its orientation in 
the present time. However, there are few tectonics 
model proposed by several researchers (e.g., 
Bilham and England, 2001; Kayal et al., 2006, 
Clark and Bilham, 2008) regarding the evolution 
and deformation in the Shillong Plateau and its 
adjoining areas. Among these, Bilham and 
Page 1034ISBN: 978-984-33-2140-4
  
Fig. 1: Major tectonic features in the study region (modified after Bhattachrya et al., 2008). Line A-A/ 
indicates the location of the cross-section used in this study. DuF=Dudhnoi Fault; CF=Chedrang Fault; 
BS=Barapani Shear Zone. 
 
England’s (2001) ‘pop-up’ model is mostly 
discussed and created a controversy on the tectonic 
study. In such circumstances, it is important to 
explain the realistic ongoing deformation in this 
study area with appropriate proxies (parameters). 
Therefore, this study aims to examine the 
contemporary stress field and ongoing deformation 
in the study area using finite element modeling. We 
proposed different orientations of the Dauki Fault 
on the basis of aforesaid discussion on its 
orientation. We further compare our model study 
with the regional tectonic stress, seismicity, 
earthquake focal mechanism solution and other 
geophysical studies for validation of our results. 
 
2. GEOLOGY AND PLATE 
VELOCITY OF THE STUDY AREA 
 
The Shillong Plateau is located between the arcs 
(Fig. 1) of the Himalaya to the North and Indo-
Burmese to the East and is connected to the 
Himalayan fronts through faults and lineaments 
(Rajasekhar and Mishra, 2008). The E-W, N-S and  
NE-SW oriented major faults and lineaments (e.g., 
Dudhnoi Fault, Chedrang Fault, and Barapani Shear 
Zone) over the Shillong Plateau might be the result 
of plate tectonic forces in these directions. 
Evidently, the Dauki Fault and the Brahmaputra 
Fault are the southern and northern margin of the 
Shillong Plateau, which are oriented in E-W 
direction. In addition, the Dauki Fault 
Page 1035
  
accommodates ~25% of the regional velocity of the 
Indian plate (Islam et al., 2010b). 
 
The Shillong Plateau is at present behaving like a 
rigid body tied with the Indian shield at a velocity 
of 46.5 1 mm/yr in a direction N 51°E (Jade et al., 
2007). The preceding studies (e.g., Malaimani et 
 
Fig. 2: GPS velocity of the study area (modified 
after Mukul et al., 2010). The GPS stations are 
GHTU=Guwahati University, TZPR=Tezpur, 
LUMA=Lumami, IMPH=Imphal, and 
AIWL=Aizawl, MUNG=Mungpu, NIMC=Nim, 
TURA=Tura, MOPE=Mopen MUNN=Mun, 
GHTY=Guwahati and SILC=Silchar. 
 
al., 2000; Chen et al., 2000; Shen et al., 2000; Holt 
et al., 2000; Paul et al., 2001; Sella et al., 2002; 
Socquet et al., 2006) show that the velocity of 
Indian plate relative to Euresia is between 34.8 to 
43.7 mm/yr, slightly slower than the 45 mm/yr rate 
which has been observed using the NUVEL-1A 
modeling (De Mets et al., 1994). Furthermore, very 
recent studies (Angelier and Baruah, 2009; Mukul 
et al., 2010) confirm similar direction of Indian 
plate’s motion (Fig. 2) which are opposite to the 
results of former studies. 
 
3. MODELING 
 
The stress field modeling of a particular area helped 
us understand the mechanism of earthquakes in that 
area. The present modeling is constrained by using 
the simple geometric cross-section (Fig. 3) that is 
used in Bilham and England (2001). Three 
geometric models with eleven rock layers have 
been constructed based on the different orientation 
of the Dauki Fault (Figs. 3a-c). The mesh of all 
three models is consisted of 1200 nodes and 2242 
elements. The spatial distribution and orientation of 
the stress were obtained at each node of the mesh.  
The boundary conditions that have been applied to 
the models are at 200-m convergent within the 
study area between the Indian and the Eurasian 
plates. In the models, horizontal displacement has 
been applied at the bottom side of the model, along 
the x-axis, running from right to left. However, 
vertical dimension are fixed and the displacement 
in the area gradually decreases from zero point 
towards left at rear nodal point. All nodal points at 
the right side of the model have equivalent vertical 
dimensions as with the left side, thus mirroring the 
displacement of the left side. We fixed rear nodal 
point at the bottom of the left side while a free slip 
boundary condition was used along left wall of the 
model such that left side is fixed in horizontal 
dimension and free along y-axis. All of the upper 
part of the model is kept free to move and was 
designed to represent the Earth’s surface. 
 
Table 1. Rock layer properties used in the plane 
strain models. 
Poisson’s ratio is 0.25.  
References: Khan and Hoque, 2006; Rajeskhar and 
Mishra, 2008; Clark, 1966; Joshi and Hayashi, 
2008a, b; Islam et al., 2010a, b and this study. 
 
The rock layer properties manipulate the results of 
numerical simulation and the state of stress within 
the model as well. For Instance, we consider 
different rock parameters (density, Young’s 
modulus of elasticity, Poisson’s ratio, Cohesion and 
internal angle of friction) during simulation as 
listed in table 1. The density values are taken from 
Rajeskhar and Mishra (2007) and Khan and Hoque 
(2005). The value of Young’s modulus of elasticity 
Layer Density 
(kg/m3) 
Young’s 
modulus 
(GPa) 
Cohe-
sion 
(MPa) 
Internal 
friction 
angle 
(degrees) 
1 3300 65 21 46 
2 2900 60 18 45 
3 2000 1 10 32 
4 2000 1 10 32 
5 2600 56 16 46 
6 2450 50 15 44 
7 2400 45 16 42 
8 2800 55 18 45 
9 2000 1 10 32 
10 2850 48 15 45 
11 2400 40 14 30 
Page 1036
  
 
Fig. 3: a) North-south cross-section (A-A/ shown in Fig. 1) from Tibet to the Bay of Bengal, showing 
schematic “pop-up” geometry of the Shillong Plateau (simplified from Bilham and England, 2001), b) b) 
simplified geometry of model 1, c) simplified geometry of model 2, (d) simplified geometry of model 3, and 
(e) boundary condition of the model. 1=Upper mantle, 2=Indian crust, 3=MBT, 4=MCT, 5=Upper Indian 
crust in Tibet, 6=Area between MBT and MCT, 7=Assam, 8=Shillong Plateau, 9=Dauki fault zone, 
10=Upper part of the Bengal basin and 11=Lower part of the Bengal basin. 
Page 1037
  
is designed by using equation 1 (Timoserko and 
Goodier, 1970; Hayashi, 2008), 
  
)1(
)21)(1(2





 pVE   --------------------------(1) 
Where Vp is P- wave velocity,  is Poisson’s ratio 
and  is density of rock.  
 
The values of Vp are based on the values from 
Mitra et al. (2005) and we used Poisson’s ratio () 
.25 in our simulation. The two other physical 
parameters, Cohesion and internal angle of friction 
were adapted from Clark (1966). The simulation of 
this study was performed using FE software 
package of Hayashi (2008). 
 
4. RESULTS 
 
Simulating the state of stress is one of the 
techniques that are helpful in understanding the 
proximities of the ongoing crustal deformation and 
neotectonics. The Dauki Fault is the prominent 
southern boundary fault of Shillong Plateau which 
plays a significant role in the deformation patterns 
observed in the study area that control the 
contemporary stress field (Islam et al., 2010a). The 
simulated stress field, faulting pattern, predict the 
significant change under the applied convergent 
displacement within the model. The modeling 
results presented here are based on (i) stress 
distribution and (ii) the fault and failure element in 
the models. 
 
4.1 Stress Distribution 
 
Figures 4a-c represent the simulated principal stress 
distribution under 200-m convergent displacement 
for the model 1, 2, and 3. The maximum 
compressive stress (σ1) and minimum compressive 
stress (σ3) are aligned along vertical and horizontal 
in the Bengal Basin and Assam as observed in the 
models except for the region close to the faults. 
However, substantial stresses change within the 
deeper part of model near the Dauki Fault which 
may indicate function of weaker zone within the 
region. The fault region predicts that the orientation  
 
Fig. 4: Distribution of principal stresses for model 1 (a), and model 2 (b), model 3 (c), at 200-m of 
convergent displacement. The circle represents extensional stress. 
 
Page 1038
  
of σ1 is normal to the fault with small magnitude 
from the neighboring areas, which is sign of 
accommodation of the deformation velocity within 
it. A complex stress distribution is exists beneath 
the Shillong Plateau in the model 1 (Fig. 4a). The 
upper part of the Shillong Plateau, the Assam 
valley, and the Bengal Basin predict the extensional 
stress regime, whereas deeper part predicts 
compressional regime. The extensional stress is 
mainly predominant in the Bengal Basin area for 
model 2 (Fig. 4b). However, some extensional 
stresses are to be predicted within the model 3 (Fig. 
4c) for the shallow depth in the Bengal Basin, the 
Shillong Plateau and Assam valley. 
 
5.2 Fault and failure elements in the models 
 
Our simulated results predict the seismotectonic 
deformation and fault development within the study 
area as shown in the Figs. 5a-c. Each and every 
model shows the different pattern of faults 
development and deformation style. The Dauki 
Fault is predicted to be as the thrust fault with 
strike-slip component in model 1 (Fig. 5a). 
However, the model 2 (Fig. 5b) predicts the Dauki 
Fault as strike-slip fault. As a result, the significant 
failure elements have been predicted in the Bengal 
Basin, the Shillong Plateau, and the Assam valley 
within model 1 (Fig. 5a). The failures within the 
Dauki Fault zone are recommended to be related 
with compressional state. In spite of these, the 
upper part of all models is linked with extensional 
failures. Moreover, there are few failures predicted 
within the Bengal Basin, the Shillong Plateau, and 
Assam valley at shallow depth (<30 km). 
 
5. DISCUSSION  
5.1 Neotectonics stress field 
 
The study area is very tectonically dynamic and 
connected with the compressional regime (Gowd et 
al., 1992). In the Bengal Basin, the orientation of 
maximum horizontal principal stress (σHmax) in the 
sedimentary pile is NE-SW (Rajendran et al., 
1992), but north-trending folds and thrusts in the 
eastern part of Bengal Basin is also a sign of E-W 
compression. The northeastern part of Assam is 
consistent with regional NE-SW stress orientation 
(Islam et al., 2010b), whereas other parts of this 
area has no constant direction of maximum 
principal stresses (Rajendran et al., 1992). 
However, one powerful earthquake event 
(December 1984), shook the Silchar town of 
southern Assam that created numerous ground 
cracks and these cracks are linked with NE-SW 
σHmax (Gowd et al., 1992). Focal mechanism 
solution also indicates that the Shillong Plateau has 
been subjected to N-S, NW-SE and NE-SW 
compression stresses (Verma, 1991; Angelier and 
Baruah, 20009). Islam et al. (2010b) predicted that 
the Sylhet trough, the Dauki Fault, southern part of 
the Shillong Plateau, and the eastern Bengal Basin 
have also similar direction (NE-SW) of σHmax. 
However, this study predicts that the study area is 
under compressional stress regime, except for the 
shallow depth. 
 
5.2 Seismicity and earthquake focal 
mechanism solution 
 
The earthquake records revealed that the Shillong 
Plateau and its neighboring areas is typical 
laboratory of active tectonics with high seismic 
activity. The number of lineament structures is 
coupled in with this plateau. Dozens of large 
earthquakes are recorded in the Himalayan region 
with Ms>7 in past 110 yrs and among those 1897 
Assam earthquake’s occurred around the SP 
(Sukhija et al., 1999). 
 
Rajendran et al., (2004) showed that most of the 
earthquakes occurred during 1986-1999 in the 
Shillong Plateau and the Brahmaputra valley with 
shallow (depth <30 km) epicenters. Besides, 
seismic events in the Bengal Basin are linked with 
strike-slip faulting at deep depth ~48-55 km (Kayal 
et al., 2006; Khan and Hoque, 2006) with low Vp 
(Bhattacharya et al., 2008). Moreover, Das et al. 
(1995) suggested that the area south of the Dauki 
Fault has high tectonic activity of shallow and 
deep-seated earthquakes in the past. Bhattacharya et 
al. (2008) reported a well-defined clustering of 
earthquake’s epicenter in the Shillong Plateau with 
high Vp velocity, which may be a sign of active 
seismicity of the region. Our simulated failure 
elements under stress field explain the more 
realistic faulting pattern of the study area. These 
results predict a comparable failure location with 
observed data (Figs. 5d-e). Nonetheless, the best-fit 
model (Fig. 5a) does not reproduce the failure in 
the exact location of study area but it explains most 
of the area of model properly and realistically. 
Moreover, it is evident from simulation that the 
failures are restricted within shallow depth 
(especially < 30 km), and failure patterns also 
support the opinion’s of Kayal et al. (2006) on 
depth of earthquake activities. 
The earthquake focal mechanism solutions indicate 
that the Shillong-Mikir hills-Assam valley is mostly 
dominated by thrust faults with N-S compression 
(Chen and Molnar, 1990; Bhattacharya et al., 
2008). Furthermore, the simulated results predicted 
compressional state of stress under imposed 
boundary condition (Fig. 4). Kayal et al. (2006) 
stated that the study area dominated by 
Page 1039
  
Fig. 5. Principal stress within failure elements for model 1 (a), model 2 (b), model 3 (c) at 200-m convergent 
displacement. The circle represents extensional stress. (d) Epicenter distribution downloaded from 
www.usgs.org., (e) Epicenter distribution taken from Fig. 4 of Nayak et al. (2008). BF=Brahmaputra Fault, 
OF=Oldham Fault. 
Page 1040
  
by thrust/reverse faulting, as is normally found in 
the Dauki fault. In addition, Islam et al. (2010a, b) 
predicted that the Dauki Fault as thrust fault with 
strike-slip component is also supported by this 
present study. However, the best-fit model (model 
1) predicts that the Dauki Fault is thrusting with 
strike-slip component (Fig. 4a). 
 
5.3 Implication for the Dauki Fault’s 
Orientation 
 
Indeed, the Dauki Fault has a great role in the 
deformation of the Shillong Plateau and its 
surrounding (Islam et al. (2010a, b) areas. The 
fault’s and its orientation is highly related with the 
deformation style observed in the region, as what 
has been found in the simulated results. Stress 
distribution, fault pattern, and failure elements 
depict distinct pattern with the Dauki Fault’s 
orientation. The Dauki Fault with north-dipping 
orientation (model 1) predicts realistic failures 
within the model (Fig. 5a), which are comparable 
with the earthquake epicenters distribution (Fig. 
5d). In contrast, models 1 and 2, where the Dauki 
Fault is south-dipping or vertical, (Fig. 5a and 5b) 
realistic failures cannot be predicted. The failures 
within these two models are mismatched with 
geophysical or geodetic observed data. However, 
the best fit model (model 1) does not reproduce 
proper location of failure as have seen in the 
observed data (Fig. 5d). This mismatching may be 
caused by some faults within the Shillong Plateau, 
Assam and the Bengal Basin which were not 
considered in this study. 
 
6. CONCLUSIONS 
 
The 2D finite element modeling is applied to 
explain the quantitative estimation of present-day 
stress field and describe deformation style within 
the study area. The results of simulation are found 
to be consistently similar with existing micro and 
macro seismic activity and active faulting. The 
comparison between the simulated results and the 
existing data indicates that our best-fit model 
(model 1) predicts more realistic contemporary 
stress field and faulting pattern of the study area. 
The modeling results predict that the Bengal Basin 
and Assam Valley is under compressional stress 
regime. While, the upper part of the Shillong 
Plateau shows extension stress regime, the deeper 
part indicates compressional stress regime. Our 
computed result also predicted that the Dauki fault 
is thrust fault with strike-slip component. The 
Shillong Plateau region shows the normal faults 
under extensional stress condition under regional 
NE-SW σHmax. Accordingly, north-dipping 
orientation of the Dauki fault gives realistic failure 
within the model that recommended its relative 
orientation. For confirming the actual orientation, 
geophysical and borehole data is needed to come 
into conclusion. 
 
7. ACKNOWLEDGEMENTS 
 
M. S. I. is grateful to the Ministry of Education, 
Culture, Sports, Science and Technology 
(Monbukagakusho) Japan for providing a 
scholarship to carry out this research. We thank 
Mamoru Nakamura at the University of the 
Ryukyus for his help during manuscript 
preparation. 
 
 
8. REFERENCES 
 
1.  Angelier, J. and Baruah, S., 2009. 
Seismotectonics in Northeast India: a stress 
analysis of focal mechanism solution of 
earthquakes and its kinematic implications. 
Geophysical Journal International, 178, pp. 
303–326. 
2.  Bhattacharya, P.M., Mukhopadhyay, S., 
Majumdar, R.K., Kayal, J.R., 2008. 3-D 
seismic structure of the northeast India region 
and its implication for local and regional 
tectonics. Journal of Asian Earth Scince, 33, 
pp. 25-41. 
3.  Bilham, R. and England, P., 2001. Plateau 
‘pop up’ in the great 1897 Assam earthquake. 
Nature, 410, pp. 806-809. 
4.  Chen, P., Molnar, P., 1990. Source parameters 
of Earthquakes and Interplate Deformation 
Beneath the Shillong Plateau and the Northern 
Indoburman Ranges. Journal of Geophysical 
Research, 95, pp. 12527-12552. 
5.  Chen, Z., Burchfiel, B.C., Liu, Y., King, R.W., 
Royden, L.H., Tang, W., Wang, E., Zhao, J., 
Zhang, X., 2000. Global Positioning System 
measurements from eastern Tibet and their 
implications for India/Eurasia intercontinental 
deformation. Journal of Geophysical Research, 
105, pp. 16215-16227. 
6.  Clark, M.K., Bilham, R., 2008. Miocene rise 
of the Shillong Plateau and the beginning of 
the end for the Eastern Himalaya. Earth and 
Planetary Science Letters, 269, pp. 337-351. 
7.  Clark, JR. S.P.R., 1966. Handbook of Physical 
Constants. Geological Society of America, 
Memory, 97p. 
8.  Das, J.D., Saraf, A. K., Jain, A.K., 1995. Fault 
tectonics of the shillong plateau and adjoining 
regions, north-east India using remote sensing 
data. International Journal of Remote Sensing, 
16(9), pp. 1633-1646. 
Page 1041
  
9. DeMets, C., Gordon, R.G., Argus, D.F. and 
Stien, S., 1994. Effect of Recent Revisions to 
the Geomagnetic Time Scale on Estimates of 
Current Plate Motion. Geophysical Research 
Letter, 21, pp. 2191-2194. 
10. Evans, P., 1964. The tectonic framework of 
Assam. Journal of the Geological society of 
India, 5, pp. 80-96. 
11.  Gowd, T.,  Rao, S., Gaur, V., 1992. Tectonic 
stress field in the Indian Subcontinent. Journal 
of Geophysical Research, 97(B8), pp. 11879-
11888. 
12.  Hayashi, D., 2008. Theoritical basis of FE 
simulation software package. Bulletin of 
Faculty of Sciences University of the Ryukyus, 
No. 85, pp. 81-95.  
13.  Hiller, K., Elahi, M., 1984. Structural 
development and hydrocarbon entrapment in 
the Surma Basin, Bangladesh (Northwest Indo-
Burman Fold Belt), paper presented at 5th 
Offshore Southeast Asia Conference, Offshore 
Southeast Asia Petroleum Limited, Singapore. 
14.  Holt, W.E., Chamot-Rooke, N., Pichon, L.X., 
Shen-Tu, B., and Ren, J. Haines, A.J., 2000. 
Velocity field in Asia inferred from Quaternary 
fault slip rates and Global Positioning System 
observations. Journal of Geophysical 
Research, 105(B8),  pp. 185-19,209. 
15.  Islam, M.S., Shinjo, R., Kayal J.R., 2010a. 
Pop-up tectonics of the Shillong Plateau in 
northeastern India: Insight from numerical 
simulations, Gondwana Research (submitted).  
16.  Islam, M.S., Shinjo, R., Kayal J.R., 2010b. 
The tectonic stress field and deformation 
pattern of northeast India, the Bengal basin and 
the Indo-Burma Ranges: a numerical approach, 
Journal of Asian Earth Sciences (in press). 
17.  Jade, S., Mukul, M., Bhattacharyya, A.K., 
Vijayan, M.S.M., Jaganathan, S., Kumar, A., 
Tiwari, R.P., Kumar, A., Kalita, S., Sahu, S.C., 
Krishna, A.P., Gupta, S.S., Murthy, M.V.R.L., 
Gaur, V. K., 2007. Estimste of interseismic 
deformation in Northeast India from GPS 
measurements. Earth and Planetary Science 
Letters, 263, pp. 221-234. 
18.  Johnson, S.Y., Alam, A.M.N., 1991. 
Sedimentation and tectonics of the Sylhet 
trough, Bangladesh. Geological Society of 
America Bulletin, 103, 1513-1527. 
19.  Joshi, G.R. and Hayshi, D., 2008a. Numerical 
modeling of neotectonic movements and state 
stresses in the central seismic gap region, 
Garhwal Himalaya. Journal of Mountain 
Science, 5, pp. 279-295.        
20.  Joshi, G.R. and Hayshi, D., 2008b. 
Neotectonic deformation and shortening along 
the Himalayanfront in the Garhwal region by 
finite element modelling. Bulletino di 
Geofisica teorica ed applicata, 49, pp. 228-
233.  
21. Kayal, J.R., Arefiev, S.S., Barua, S., Hazarika, 
D., Gogoi, N., Kumar, A., Chowdhury, S.N. 
and Kalita, S., 2006. Shillong plateau 
earthquakes in northeast India region: complex 
tectonic model. Current Science, 91(1), pp. 
109-114. 
22. Khan, A.A., Hoque, M.A., 2005. Crustal 
Dynamics, Seismicity and Seismotectonics of 
the Bengal basin. Proc. 1st Bangladesh 
earthquake symp. Bangladesh Earthquake 
Society, pp. 45-54. 
23. Malaimani, E.C., Campbell, J., Gorres, B., 
Kothoff, H., Smaritschnik, S., 2000. Indian 
plate kinemtics studies by GPS-geodesy. Letter 
of Earth Planet Space, 52, pp. 741-745. 
24. Mitra, S., Priestley, K., Bhattacharyya, A. K. 
and Gaur, V. K., 2005. Crustal structure and 
earthquake focal depths beneath northeastern 
India and southern Tibet. Geophysical Journal 
International, 160, pp. 227-248. 
25. Mukul, M., Jade, S., Bhattacharya, A.K., 
Bhushan, K., 2010. Crustal Shortening in 
Convergent Orogens: Insights from Global 
Positioning System (GPS) Measurements in 
Northeast India. Journal Geological Society of 
India, 75, pp. 302-312. 
26. Nandy, D.R., 2001. Geodynamics of 
Northeastern India and the Adjoining Region, 
ACB Publication, Kolkata, 209 p. 
27. Oldham, R.D., 1899. Report of the great 
earthquake of 12th June, 1897. Memory 
Geological Survey of India, 46, pp. 257-276. 
28. Paul, J., Burgmann, R., Gaur, V.K., Bilham, 
R., Larson, K.M., Ananda, M.B., Jade, S., 
Mukal, M., Anuama, T.S., Satyal, G., Kimar, 
D., 2001. The motion and active deformation 
of India. Geophysical Research Letters, 28(4), 
pp. 647-650. 
29. Rajesekhar, R.P., Mishra, D.C., 2008. Crustal 
structure of Bengal basin and Shillong Plateau: 
Extension of Eastern Ghat and Saatpura 
Mobile Belts to Himalyan fronts and 
seismotectonics. Gondwana Research, 14(3), 
pp. 523-534,doi:10.1016/j.gr.2007.10.009. 
30. Rajendran, K., Talwani, P., Gupta, H.K., 1992. 
State of stress in the Indian Subcontinent: A 
review. Current Science, 62(1&2), pp. 86-93. 
31. Rajendran, C.P., Rajendran, K., Daurah, B.P. 
and Earnest, A., 2004. Interpreting the style of 
faulting and paleoseismicity associated with 
the Shillong, northeast India, earthquake: 
Implication for regional tectonism. Tectonics, 
23, TC4009, doi:10.1029/2003TC001605. 
32. Sella, G.F., Dixon, T.H., Mao, A., 2002. 
REVEL: a model for the recent plate velocities 
from space geodesy. Journal of Geophysical 
Page 1042
  
Research, 107(B4), 2081, 
10.1029/2000JB000033. 
33. Shen, Z.K., Zhao, C., Yin, A., Li, Y., Jackson, 
D.D., Fang, P., Dong, D., 2000. Contemporary 
crustal deformation in east Asia constrained 
from Global Positioning System 
measurements. Journal of Geophysical 
Research, 105, pp. 5721-5734. 
34. Shukhija, B. S., Rao, M. N., Reddy, D. V., 
Nagabhushanam, P., Hossain, S., Chadha, R. 
K. and Gupta, H. K., 1999. Timing  and return 
period of major paleoseismic events in the 
Shillong Plateau, India. Tectonophysics, 308, 
pp. 53-65. 
35. Socquet, A., Vigny, C., Rooke, N.C., Simons, 
W., Rangin, C., Ambrosious, B., 2006. India 
and Sunda plate motion and deformation along 
their boundary in Myanmar determined by 
GPS. Journal of Geophysical Research, 111, 
(B05406). doi:10.1029/2000JB000033. 
36. Srinivasan, V., 2003. Deciphering differential 
uplift in Shillong plateau using remote sensing. 
Journal of Geological Society of India, 62, pp. 
773-777. 
37. Timoshenko, S. P. and Goodier, J. N., 1970. 
Theory of elasticity. McGrew-Hill. 567p. 
38. Uddin, A., Lundberg, N., 2004. Miocene 
sedimentation and subsidence during 
continent–continent collision, Bengal basin, 
Bangladesh. Sedimentary geology, 164, pp. 
131–146. 
39. Verma, R.K., Mukhopadhyay, M., 1977. An 
Analysis of the Gravity field in northeastern 
India. Tectonophysics, 42, pp. 283-317. 
40. Verma, R.K., 1991. Geodynamics of the Indian 
peninsula and the Indian plate margin  
Oxford & IBH Pub. Co., New Delhi. 347p. 
 
Page 1043
Underground or Open Pit Mining Method – an Unresolved Debate 
Delaying Coal Mining in Bangladesh 
Md. Alomgir Hossain* and Md. Mehedi Hasan, 
Department of Petroleum and Georesources Engineering, Shahjalal University of Science and 
Technology, Sylhet-3114, Bangladesh; *jibon_04@yahoo.com 
ABSTRACT: 
Bangladesh is blessed with coal-basins in the northwest and natural-gas fields are profuse in the eastern 
region. The current GDP growth of the country is proportionally related on its power generated from natural 
gas (82%), oil (9%), hydro (4%) and coal (5%) resources. The recoverable gas reserve (proven and probable) 
of discovered gas fields of the country is 20.63 TCF of which 7.42 TCF has been used so far leaving 13.21 
TCF. Evidently, coal would be the only available alternative resource to meet the upcoming demand. 
Around 3 billion tones of high-grade coal were discovered at 5 coal-basins in northwest Bangladesh. 
Significant amount of coal mining has yet not been started, though first discovery of coal came in 1959. 
There are two coal mining methods: open pit and underground mining, are used in the world. Experts 
proposed both methods to extract the coal from Bangladesh-coal fields and also CBM (Coal Bed Methane) 
for deep 300-500m or more. Despite all well-meaning intentions, it appears that selection of mining method 
has been delaying the coal mining in Bangladesh. This critical review would provide rationales in favour of 
underground mining over open pit mining method in Bangladesh.   
Keywords: Gondwana coal, Open pit mining, Underground mining, Northwest Bangladesh, Groundwater. 
 
1. INTRODUCTION: 
The peoples of Republic of Bangladesh emerged 
1971 from Pakistan. The country covers an area 
of 1, 44,000 sq km of onshore and 63,000 sq km 
offshore. Bangladesh extents from 20°34’N to 
20°38’N and 88°01’E to 92°41’E. It is a densely 
populated developing country situated in the 
south-east Asia in the world (1099.3 percent per 
sq km) (source-Wikipedia). 
Bangladesh is undoubtedly heading towards a 
major energy crisis in the days to come. But with 
the reserve of coal, even if recovered even by 
open pit mining, will at best contribute a pond, if 
not a drop, in an ocean. So we must explore 
multiple options like undertaking massive search 
for oil, gas and coal, tapping wind energy in the 
*Corresponding Authors: Md. Alomgir Hossain 
jibon_04@yahoo.com   
coastal belt, generating small-scale hydro-
electricity in the hilly terrains, solar energy, and 
coal extraction by underground mining only from 
the known deposits.  
The primary objectives of this over view is to 
provide the reader with a better understanding 
about the geological formation of the North-
Western part of Bangladesh and different types of 
mining methods basically underground mining 
and open pit mining which is best applicable in 
Bangladesh. In finally in the discussion and 
conclusion emphasis is given which method is 
more applicable in Bangladesh. 
 2. GEOLOGICAL STRUCTURE OF 
BANGLADESH: 
Page 1044
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
Conference on Engineering Research, Innovation and Education 2011 
Proceedings of the 
ISBN: 978-984-33-2140-4
2.1 Plate Tectonic Evolution of 
Bangladesh: 
The Bengal basin has evolved from collision of 
Indian plate and the Asian plate. According to the 
plate tectonic theory, the north western part of 
Bangladesh (Bogra-Rangpur-Dinajpur area) was 
initially jointed along with Indian land mass with 
Antarctica, Australia and other forming a vast 
super continent named Gondwanaland far in the 
southern hemisphere. About 110 million year 
ago, during the cretaceous time, the 
Gondwanaland super continent began to breakup 
and Indian began drifting toward north. The 
Bengal basin was initiated during this time with 
the rifting of the Indian plate from Antarctica. 
Then Indian plate collided with Asian plate and 
formed the Himalayan Mountain. The remaining 
landmass of Bangladesh formed from the 
sediment that coming from Himalayan mountain.  
With the above outline the tectonic framework of 
Bangladesh may be broadly divide into two main 
units: (1)Stable platform in the northwest (2) 
Deep basin to the southeast and a third unit a 
narrow northeast, southwest trending zone called 
hinge zone separate to above two unit. 
Stable Platform unit occupies Rajshahi-Bogra-
Rangpur-Dinajpur area and is characterized by 
limited to moderate thickness of sedimentary 
rock above a Precambrian igneous and 
metamorphic basement. Based on the thickness 
stable platform divided into two parts: (a) 
Rangpur saddle in the north with thin to limited 
(130m to 1000m) sedimentary cover above the 
Precambrian basement and (b) Bogra shelf with 
moderate (1 to 6 km) sediment covers over the 
Precambrian basement. Deep (geosynclinals) 
Basin unit lies to the south and east of the stable 
platform and is characterized by huge thickness 
(maximum 22 km) of sedimentary rocks mostly 
sandstone and shale of Tertiary age. It occupies 
greater Dhaka-Faridpur-Noakhali-Sylhet-
Comilla-Chittagong and Chittagong Hill tracts 
areas and Bay of Bengal. And a third unit is 
called Hinge Zone unit which is a 25 km wide 
northeast-southwest zone that separates 
Precambrian platform from Deep basin to the 
southeast. There are no surface expressions of 
this unit. From the tectonic evolution of Bengal 
Basin and structural framework of Bangladesh 
we see that the coal layers are situated in the 
stable platform. 
 
Figure 01: Geological map of Bangladesh.  
2.2 Stratigraphy of the Bangladesh Coal 
Field: 
Most of the coal fields are located in stable 
platforms in North-Western part of Bangladesh. 
The major coal fields are Jamalganj coal field, 
Barapukuria coal field, Phulbari coal field, 
Dighipara coal field, Khalashpir coal field.  
General Stratigraphy of the North-western part is 
given below:  
 
Figure 02: Stratigraphy of stable platform in 
Bangladesh  
 
 
 
Page 1045
Table 01: Stratigraphy Succession of North Western in Bangladesh: 
 
2.3 General Characters of Bangladesh 
Coal Fields: 
 The coal found in NW Bangladesh is 
high volatile bituminous coal. The 
quality of the coal is very good. 
 The coal is Permian in age and occurs 
within fault bounded Gondwana basins. 
 The coal seams occur at depth range 
from 118m to 1000m. Thick to very 
thick multiple coal layers are found in 
the coal fields of Bangladesh. 
 The coal deposits are covered 
unconformable at the top by 100m to 
200m thick loose to poorly consolidated 
water bearing sand layer. 
 The coal basins are bounded by major 
normal fault forming half graben. 
 Bangladesh’s coal is over 245-286 m.y. 
old. 
 Coal was deposited in swampy 
environment.  
 
 
 
 
3. FACTORS OF CONSIDERING 
THE SELECTION OF MINING 
METHODS: 
 Depth of the seam 
 Thickness of the seam 
 Seam configuration (in terms of 
horizontal or vertical dimension) 
 Lateral continuity of the seam 
 The compositions of the overburden  
 Overburden and seam hardness 
 Proximity to surface water or an active 
ground water system 
 Total deposit of coal 
 Economical profitable 
4. DIFFERENT MINING METHODS 
IN THE WORLD: 
Coal is commercially won by either of two basic 
methods: surface mining or Underground mining. 
When an ore bed has been located relatively close 
to Earth's surface, it can be mined by surface  
 
 
Period Formation Lithology Hydrogeology 
Resent to sub resent 
(Holocene) 
Alluvium Silty clay  
Pleistocene Barind  Clay Clay and sandy clay  
Pliocene Dupi Tila Sandstone, loosely compact 
sandstone 
Unconfined 
Aquifer 
Upper Oligocene to 
Miocene 
Jamalganj formation Silty fine sand, clay, Shaly 
clay, sandstone, shaly coal 
 
Eocene Kopili Shale 
Sylhet Limestone 
Tura sandstone 
Sandstone, shale and small 
limestone 
 
Permian to Cretaceous Shibganj Trapwash 
Rajmahal Trap 
Paharpur kuchma 
Medium to very coarse 
grained off- white feld pathic 
sandstone frequently 
interbeded with conglomerate 
and coal layer with sandstone 
sequence 
 
Precambrian 
Crystalline Basement 
 Igneous and metamorphic 
rocks 
 
Page 1046
Table 02: the advantage and disadvantage of main two mining methods (open-pit mining and underground 
mining)  
 
techniques. Surface mining can be subdivided 
into two large categories: open-pit mining and 
strip mining. Open-pit mining is used when an 
ore bed covers a very large area in both distance 
and depth. Mining begins when scrapers remove 
any non-ore material (called overburden) on top 
of the ore.  
 
Figure 03: open pit coal mining. 
 When an ore bed covers a wide area but is not 
very deep, strip mining is used. It begins the same 
as open-pit mining, with scrapers and other 
machines removing any overburden. This step 
involves the removal of two long parallel rows of 
material. Coal is normally extracted by 
underground mining techniques when the depth  
 
of the seam is greater than 300 feet. Other types 
of mining methods are proposed when depth is 
greater than 500m named CBM (coal bed 
methane).  
 
Figure 04: Underground coal mining 
 
5. PROBLEMS FACING IN 
UNDERGROUND AND OPEN PIT 
MINING METHODS: 
 
Item Open pit mining Underground mining 
Development work Minimum development work Needed major development work 
Overburden Need to excavate large volume of 
overburden to extract coal. 
Most excavation, apart from entry and 
tunneling, are made in saleable coal. 
Surface area loss Large area of land temporarily lost. Only the area around pit-top is visibly 
disturbed. 
Environmental 
effect 
Noise and coal dust pollution in and around 
mining area. 
No surface pollution; subsidence above 
workings may affect surface 
installation. 
Mine safety Greater safety, no danger of explosion or 
fire; however danger includes landslides on 
excavation or spoils pile. 
Methane gas explosion, spontaneous 
combustion, roof collapse, water 
flooding pose danger to mine 
personnel. 
Affect of climate Mining is affected by rigorous climate 
condition like heavy rain or snow 
Climate do not affect the mining 
Depth of mining Maximum depth of mining limited by cost 
of overburden removal 
Can work coal to greater depth; 
overburden to coal ratio not critical 
Machinery Simple machinery needed More complex machinery needed 
Recovery of coal Almost all in situ coal may be recovered.  Less than 60% of the in situ coal 
commonly recovered. 
Water discharge 
cost 
High discharge cost Less discharge cost than open pit 
mining. 
Page 1047
5.1 Impact on Hydro-geological 
Environment: 
Potential and major groundwater reservoir of 
Bangladesh lies in its north-western region 
covering greater Dinajpur and Rangpur districts. 
The groundwater resource of this region is the 
main aquifer of Bangladesh which is about 80-
120 meters thick in the DupiTila formation and 
situated at about 10-12 meters below the surface. 
Extraction of coal adopting open-pit mining 
method can be disastrous for the north-western 
region in particular and Bangladesh in general 
due to dewatering of arsenic contamination free 
source of drinking and irrigation groundwater 
from DupiTila formation from a depth of 250 to 
300 meters. Dewatering in the open pit mining 
area may not only disturb but also damage the 
aquifer, making the area a desert like place. 
During monsoon, already mined out area will be 
filled up by rain water, which is required to be 
pumped out again. During rainy season mining 
will be difficult and may have to be postponed to 
facilitate pumping of water out of the mine. Thus 
2-3 months in a year may be lost due to this. Thus 
uninterrupted supply of coal to the power station 
and other coal consumers may not be possible. 
There are lower DupiTila which is impermeable 
for that underground mining is suitable than open 
pit mining. 
 
5.2 Subsidence/landslide 
Subsidence in the context of underground mining 
is the lowering of the earth surface due to 
collapse of bed rock and unconsolidated material 
(sand, gravel, silt and clay) into mine area. This 
geological hazard is like an earthquake. The mine 
subsidence is controlled by many factors include 
mined out area, width of unsupported mine roof, 
thickness of overburden, competency (strength) 
of bed rock, hydrology and time. The area of 
mine subsidence increases proportionally with 
increasing width of unsupported roof rock. From 
the structural geology and Stratigraphy of 
Bangladesh, rock strength is high so the 
subsidence is low but DupiTila formation has 
high permeability and porosity so the quality of 
landslide high for the upper formation. In open 
pit there is landslide due to loose, incompact 
DupiTila formation. 
5.3 High Geothermal Gradient: 
The temperature rise will be caused by the heat 
dissipated from the human, and duct and pipe, the 
heat of blasting and etc. The temperature rise will 
worsen the underground environment, influence 
seriously the workers health and the laborer 
productivity, and finally become heat harm. 
According to the supplementary geological 
survey report, the temperature at the zone of 
invariable temperature of the mine is about 
25.50℃; the depth is about 30m; ground 
temperature gradient in average is 3.51℃/100m. 
According to above mentioned the 
comprehensive measured necessary for lowering 
the temperature should be taken. So for 
underground mining better ventilation system 
must be needed. 
5.4 Air Pollution: 
Coal mining operations are sources of air 
pollution in the form of coal or rock dust from the 
mine itself. Gaseous air pollutants may also be 
generated by the transport operations within the 
mine area. The production of electric power used 
for in-mine ventilation, conveying, digging, 
loading, transfer, and other operations can 
contribute to air pollution indirectly. For most 
underground mines ventilation rates range from 5 
to 40 cubic feet per minute per ton of coal per 
day, this translates to 10,000 to 200,000 cubic 
feet per minute for an average mine. 
Underground mines will release coal dust 
particles from blasting or loading operations, as 
well as gases such as hydrogen sulfide, sulfur 
dioxide, methane, and other hydrocarbons, 
although in relatively low concentrations. 
 
5.5 Gas Explosion:  
Gas is one of the main disasters to coal mine. It 
has large harmfulness. It cannot only suffocate 
the people but also burn and explode easily, also 
break down the middle and small size facilities 
seriously and thus stop the production. In the 
view of the whole mine, the main place with the 
gas build up are: working and heading face so the 
working place of the shearer and the tunneling 
machine coal falling place by mining, goaf, air 
sealed zone, airless zone, air supply stopping 
zone and the corner zone with poor ventilation. 
The gas explosion is less in open pit mining but 
environmental impact is relatively high.  
5.6 Particulate Emissions: 
Particulate emissions in underground mining are 
relatively minimal, ranging from 0 to 0.0005 
Page 1048
Ib/ton of coal. The particulate concentrations in 
the ventilation exhaust gases can range from 
below 100 to more than 1,000 ft-Lg/m3depending 
on the ventilation rate, the type of mining method 
and the moisture content of the coal. The 
particulate dust losses from surface mining are 
greater, 0.005 to 6.600 Ibs/ton of coal mined, 
because of the open exposure to the atmosphere 
as compared to the confined tunnels in 
underground mines. The magnitude of these dust 
losses is largely dependent upon the surface 
mining method used as well as the local 
geography. Coal and soil dust losses are generally 
greater from area than from contour surface 
mining operations (0.04 to 0.05 vs. 0.005 to 0.007 
Ib/ton coal mined.  
5.7 Solid Wastes: 
Solid wastes are produced from both 
underground and surface mining operations in 
varying quantities. Wastes generated from 
underground mining are the waste rock from 
shaft tunneling, and refuse and coal fines 
removed during preparation. The solid wastes 
generated from surface mining include 
overburden from removal of the soil plus rock 
and impurities removed during preparation. The 
total solid wastes from underground mining are 
0.06 to 0.10 Ib/ton of coal when waste removal is 
not required and 2.0 to 80 Ibs/ton of coal when 
required because of the need to remove 
impurities, refuse, and "gob". These materials can 
be used as backfill for the mine shafts once the 
mining operation is completed to minimize the 
need for surface disposal. Solid wastes generated 
from surface mining operations are generally 
much greater when uncontrolled because of the 
large overburden soil washout. When careful land 
reclamation is practiced, the amount of 
overburden waste is greatly reduced. Much of the 
solid waste materials from coal preparation and 
waste water treatment can also be backfilled in 
the mined-out pits following mining before the 
land is reclaimed.  
 
6. UNDERGROUND OR OPEN PIT 
MINING METHOD WHICH IS 
PERFECT IN BANGLADESH 
6.1 Views Favoring Underground Method 
in Bangladesh 
The 100 to 200 meter thick unconsolidated and 
water bearing sandy layer (DupiTila formation) 
overlying the coal deposit is an active ground 
water aquifer. The amount of water that would be 
released in an open pit mining is not manageable 
and will create several problems. The monsoon 
rain may make the water problem even worst. 
The presents of loose sandy water bearing aquifer 
above cold deposit is also responsible for large 
scale land sides in open pit mining. An open pit 
mining method would take up significant amount 
of agricultural land then underground mining 
method. For example an underground mine will 
take 0.96sq.km. of land where an open pit mine 
would require 16sq.km.of land The coal fields are 
located very depth, which is not very encouraging 
for an open pit mine. 
 
6.2 Views Favoring Open Pit Mining 
Method in Bangladesh 
The loose water bearing 100 to 200m thick 
DupiTila sand layer above the coal deposit 
renders the shaft sinking for underground mine 
very difficult under normal circumstances. A time 
consuming and expensive freezing technique is 
required for the above purpose. This increase the 
project cost to a significant amount. The average 
stripping ratio is nearly 6:1 in m3/ton (cubic meter 
of over burden per ton of coal). This ratio is 
suitable for open pit mining. The extraction ratio 
is very high in open pit mining. The open pit 
mining is very safety. In Bangladesh the coal is 
overlying by younger sediment. The Permian 
sand stone also moderately fractured and jointed. 
It has low strength so it could not able to sustain 
the overburden stress / pressure. 
 
7.CONCLUSION AND DISCUSSION:  
Bangladesh is facing a serious challenge in terms 
of meeting the demands in the energy sector. 
Bangladesh needs to build national capability, 
formulate legal and organizational frameworks 
and mine coal so that she can retain and use the 
entire quantity to meet domestic energy needs. 
Finally, in such a national capability-based coal 
mining, Bangladesh needs to use coal mining 
methods that best suits the socio-economic, 
cultural, geologic, and environmental settings. 
 
The government may undertake a detail hydro-
geological study on major and potential aquifer in 
the north-western region of Bangladesh in the 
light of Asia Energy's proposal for open-pit coal 
mining in Bangladesh coal fields. At the same 
time Asia Energy may give a second thought to 
their proposal and examine underground mining 
prospects in the Bangladesh coal fields. The most 
pressing issue is the method to be used for coal 
mining in Bangladesh. Based on publicly 
available information on socio-economic and 
environmental feasibility studies done on the 
possibility of open-pit coal mining in Phulbari 
and other coal fields in Bangladesh, it is safe to 
conclude that open-pit coal mining will cause 
Page 1049
huge economic loss, social unrest, and 
environmental degradation of unprecedented 
nature. There are several other viable alternatives 
to open-pit coal mining that are being practiced in 
various countries in the world. Given the socio-
economic, cultural, and environmental settings, 
Bangladesh should consider a combination of 
underground coal mining, extraction of coal bed 
methane (CBM), and underground coal 
gasification (UCG) projects. 
 
REFERENCES: 
1.  AHAMD R (2008): Open pit mining method 
is most suitable for Bangladesh, The New 
Energy, June-23, 2008.   
http://www.weeklyeconomictimes.com/news-
details.php?recordID=1172  
2.  IMAM . B. (2005), Energy Resources of 
Bangladesh, pg-(19-29, 179-215) University 
Grants Commission of Bangladesh. 
3.  ISLAM R.M (2009,2010):No reason for 
Bangladesh to go for open- pit mining, The Daily 
New Age, October 28, 2010 Problems for open 
pit coal mining in northwest Bangladesh, The 
Daily New Age, January19, 2010.  
http://www.newagebd.com/2009/sep/08/anni09/1
0.html.  Coal deposits, mining perspective in 
northwestern Bangladesh, The Daily New Age, 
August26, 2009. 
http://www.newagebd.com/2009/aug/26/edit.html
#2 Brainstorming on coal policy: an outsider’s 
perspective, The Daily New Age, July12, 2009 
http://www.newagebd.com/2009/jul/12/oped.html  
4. KHAN F.H (1991), Geology of Bangladesh, 
page 190-201 The University Press Limited  
5. MUKUL M (2008): Geologic condition of coal 
basin & extraction debate, The Weekly Economic 
Times July-1, 2007.  
6. REIMAN. K.U (1993), Geology of 
Bangladesh, pg 1-8, Gebruder Borntraeger Berlin 
Stuttgart 
7. SALEQUE. K.A (2009) Coal Mining 
Challenges in Bangladesh [Part -1], The Energy 
Bangla, April 26, 2009 
8.  SHAMSUDDIN A K M (2007):  Phulbari 
Coal: Hydro-geological environment not 
favorable for open pit mining, The Daily Star, 
September 29, 2007. 
http://www.thedailystar.net/forum/2007/septembe
r/coal.html. 
9. TAMIM (24-06-2008), Coal Policy Review 
Almost Complete, The New Energy, June-24, 
2008.  http://www.ep-bd.com/  
10. The Daily Naya Diganto (08-08-2010, 27-05-
2010,11-04-2010) 
11. The Daily New Age (2007), open pit coal 
mining not viable 
12. The News Today, 2010, Extracting energy 
from coal mines Experts see CBM, UCG 
methods feasible, News Report 
13. Wikipedia Encyclopedia, 2010.Overview of 
Bangladesh. http://www.wikipedia.com/ 
14.  ZAMAN Z. (2008): Dewatering in open pit 
mining: Concern or Benefit? ,The New Energy, 
June-25, 2008  http://www.ep-
bd.com/archive/2nd-issue_07/index.html
 
Page 1050
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
*Md. Tanvir Ishtaique-ul Huque,  
E-mail: tanvirishtaique@yahoo.com 
  
DESIGN AND SIMULATION OF FOUR BANDS MICROSTRIP 
PATCH ANTENNA ARRAY FOR MULTIBAND APPLICATIONS 
 
 
Md. Tanvir Ishtaique-ul Huque* and Md. Kamal Hosain 
Department of Electronics and Telecommunication Engineering 
Rajshahi University of Engineering & Technology, Rajshahi-6204, Bangladesh 
 
Md. Shah Alam 
Department of Electrical and Electronic Engineering 
Rajshahi University of Engineering & Technology, Rajshahi-6204, Bangladesh 
 
 
In this paper, a four band microstrip antenna with very straightforward configuration is proposed. This paper 
presents an array antenna which can be operated in four different bands. The designed array adopts four 
series feed rectangular microstrip patches having different sizes. The simulation has been performed by 
using SONNET version V12.56 simulator which is a commercially available antenna simulator. The 
intended antenna is designed by using Taconic TLY-5 dielectric substrate with permittivity, ࢿ࢘ = 2.2 and 
height, h =1.588 mm. The size of the antenna is 83.5 x 16.9 x 1.602 mm and four resonant frequencies are 
7.6GHz, 8.0GHz, 9.3GHz and 10.1GHz. The result confirms satisfactory performance having maximum 
achievable directive gain of 15.16 dB and return loss of -23.67 dB. The main features of the presented 
antenna are simplicity and flexibility to be designed for any numbers of operating frequencies. 
 
Key words: Microstrip Antenna; Rectangular Microstrip; Multiband Array Antenna; Series Feed Array 
 
1. INTRODUCTION 
 
With the rapid growth of the wireless 
communication system, the future technologies 
need a very small and multiband antenna.  
Nowadays, people demand multiband wireless 
phone supporting more than one network, having 
different frequencies and simultaneous transmission 
of audio, video and data. These services are 
possible with the help of microstrip antenna 
because of its broad band and multiband 
characteristics. The advantages of microstrip 
antenna makes them popular in many applications 
requiring a low profile antenna and this antenna is 
promising to be a good candidate for the future 
technology due to the flexibility of the structure as 
it can be easily incorporate into the communication 
equipments [1]. Many researchers have studied 
different structure and different techniques to 
increase the radiation efficiency and to have 
multiband in single element antenna by using 
double PIFA[1], U-slot [2] and other structures. In 
this paper, an investigation on the design of 
microstrip array antenna to control four bands by 
matching the impedance of successive elements and 
using the quarter wavelength transformer method 
[3] is made. This paper aims to decrease the size of 
the antenna and at the same time to improve the 
radiation performance of the patch antenna in terms 
of directivity, maximum radiation, return loss and 
efficiency. As an advantage, the resonant frequency 
of this antenna can be easily controlled by either 
increasing or decreasing some parameters such as, 
width and length of each element. Here, the 
designed tetra band microstrip antenna supports 
four bands at 7.6GHz, 8GHz, 9.3Ghz and, 
10.1GHz. Furthermore, this antenna could be 
designed for any number of operating frequency at 
any range by varying some parameter and adding 
more elements. Another promising advantage of 
this antenna is very simple structure and 
compatibility of multiband applications. 
 
 
2. ANTENNA CONFIGURATION AND   
    DESIGN PROCEDURE 
 
This antenna has a simple structure fed by 50Ω 
microstrip line. Fig. 1 demonstrates the dimensions 
of the proposed antenna used for theoretical and 
simulated study where the dimensions are in mm 
range. The dielectric material selected for the 
design is Taconic TLY-5 which has dielectric 
Page 1051
ISBN: 978-984-33-2140-4
 constant of 2.2 and the height of dielectric substrate 
of (h) = 1.588 mm. Generally the overall dimension 
of the antenna is 83.5 x 16.9 x 1.602 mm. Here, 
SONNET version V12.56 package is used to obtain 
the return loss and the radiation patterns.  
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 1: Detailed dimensions of 
the proposed microstrip antenna 
 
For an efficient radiation, practical width of the 
patch is [3] 
 
                                                                              (1) 
 
 
and the length of the antenna is [3] 
                                                                             
                                                                              (2) 
 
where, 
 
                                                                              (3)                                                                                           
and 
                                                                                   
                                                                 (4) 
 
 
Where, λ is t he wave length,  is the resonance 
frequency, L and W are the length and width of the 
patch element and   is the dielectric constant. 
Here, the antenna seems to be a series feed array 
network [5]. But each element has designed for 
different operating frequency. In Fig. 1 the antenna 
has designed only for four bands. The 1st, 2nd, 3rd 
and 4th  elements of the rectangular array antenna 
is the rectangular slot having the area of 11.9 x 9.1 
mm, 13.2 x 10.2 mm, 14.8 x 11.6 mm and  16.9 x 
13.5 mm operating at 10.1 GHz, 9.3 GHz, 8 GHz 
and 7.6 GHz frequency respectively. Although, 
each element covers specific operating frequency, 
because of their array network configuration the 
antenna provides efficient radiation performance in 
term of gain and directivity. In this array network 
configuration two successive patch elements are 
matched by using quarter wavelength transformer 
method where in case of selecting the length of the 
transformer the operating frequency of the patch 
element near by the source has been chosen [5]. 
 
3. ANTENNA SIMULATION AND 
RESULT 
 
The return loss response of the proposed microstrip 
array antenna simulated in the SONNET version 
V12.56 is shown in Fig. 2, where the minimum 
return loss i.e. -23.67dB is found at 10.1 GHz 
operating frequency. The other three dip values of 
return losses are -14.0dB, -3.67dB and -4.0dB at 
9.3GHz, 8GHz, and 7.6GHz frequencies 
respectively. This indicates that the proposed 
antenna has lower return loss at higher frequency 
than lower frequency. Therefore, the highest 
radiation efficiency is at 10.1GHz among the total 
frequency band. Again, the radiation patterns of this 
four band antenna for the four operating 
frequencies are shown in Fig. 3 using the same 
simulator. The directive gain for the antenna with 
the operating frequencies 7.6 GHz, 8 GHz, 9.3 GHz 
and 10.1 GHz have values 15.16dB, 15.15dB, 
13.12dB and 12.15 dB respectively. Fig 3 illustrates 
that the antenna has higher directivity at lower 
frequencies than higher frequencies.  
 
4th Element 
3rd Element 
2nd Element 
1st Element 
1
2
2
1
00 

rrf
w

)8.0(
)264.0(
*
258.0
3.0
41.0





h
w
h
w
hL
eff
eff


w
h
rr
eff
1212
1
2
1







L
effrf
L  2
002
1

Page 1052
  
 
Fig. 2: Return loss response of the antenna array 
 
 
 
Fig. 3: Radiation pattern at 7.6 GHz, 8 GHz, 9.3 
GHz and 10.1 GHz of the microstrip array antenna 
 
For the convenience, the effect of the individual 
element on the overall performance and their 
comparison with the same sized single element 
microstrip patch antenna are summarized below. 
From the result shown in the following tables it can 
be concluded that the designed antenna outperform 
the conventional one with respect to the directive 
gain, return loss and radiation efficiency. It is also 
summarized that each element in array contributes 
better than the element as a single antenna.  
 
Table 1. Comparison of the effect of the 1st 
element on array configuration and single element 
microstrip antenna 
Antenna 
Type 
Performance Parameter 
Directive 
gain HPBW 
Return 
loss 
1st element 
on array 12.15 dB 50
o -23.67 dB 
Single 
element 
configuration  
6.25 dB 130º -8.4 dB 
Table 2. Comparison of the effect of the 2nd 
element on array configuration and single element 
microstrip antenna 
Antenna 
Type 
Performance Parameter 
Directive 
gain HPBW 
Return 
loss 
2nd element 
on array 13.12 dB 36
o -13.84 dB 
Single 
element 
configuration  
6.38 dB 1400 -4.9 dB 
 
Table 3. Comparison of the effect of the 3rd 
element on array configuration and single element 
microstrip antenna 
Antenna 
Type 
Performance Parameter 
Directive 
gain HPBW 
Return 
loss 
3rd element 
on array 15.15 dB 100
o -3.67 dB 
Single 
element 
configuration  
6.5 dB 130o -2.7 dB 
 
Table 4. Comparison of the effect of the 4th 
element on array configuration and single element 
microstrip antenna 
Antenna 
Type 
Performance Parameter 
Directive 
gain HPBW 
Return 
loss 
4th element 
on array 15.16 dB 76
o -3.88 dB 
Single 
element 
configuration  
6.6 dB 140.3o Above 3 dB 
 
 
4. CONCLUSION 
 
The unique feature of this antenna is its simplicity 
to get improved performance for multiband 
applications. This paper presents a geometric 
configuration for a, microstrip antenna array which 
provides a mean to get higher directive gain and 
maximum radiation efficiency than the 
conventional antenna structure using simple 
technique. Other benefits of this designed antenna 
are, it can be used as a single band as well as 
multiband and it would also be possible to design 
the antenna operating at any other system such as 
WLAN, WiMAX or other wireless system by 
changing the dimension of the patch elements. 
Here, the series fed array configuration has been 
investigated and in future the corporate-series feed 
Page 1053
  
array configuration could be designed and 
simulated operating at multiple frequencies and 
having higher directive gain. 
 
 
 
REFERENCES 
 
1. P. S. Hall, E.Lee, C. T. P. Song, Planar 
Inverted-F Antennas, Chapter7, “Printed 
Antennas for wireless  Communications” 
Edited by R. Waterhouse, John Wiley & Sons, 
Ltd., 2007. 
2. H. F. AbuTarboush, H. S. Al-Raweshidy, R. 
Nilavalan,“Triple Band Double U-Slots Patch 
Antenna for WiMAX Mobile Applications”, 
14th Asia-Pacific Conference on 
Communications, Japan, pp. 1-3, 2008. 
3. C. A. Balanis, “Antenna Theory”, 2nd Edition, 
John Wiley  & Sons,Inc., 1997. 
4. R. A. Bhatti, Young Sin Shin, Ngoc-Anh 
Nguyen and Seong-Ook Park, "Design of a 
Novel Multiband Planar Inverted-F Antenna 
for Mobile Terminals," Antenna Technology: 
Small Antennas and Novel Metamaterials, 
2008. iWAT 2008.International Workshop on, 
pp. 530- 533, 2008. 
5. Garg, R., P. Bhartia, I. Bahl, and A. Ittipiboon, 
“Microstrip Antenna Design Handbook”,  
Artech House,Inc., 2001. 
6. Md. Shihabul Islam and Md. Tanvir Ishtaique-
ul Huque,“Design, Simulation and 
Performance Analysis Microstrip  Array 
Antenna”,  B.Sc. Engg. thesis, Dept. of ETE 
Rajshahi University of Engineering & 
Technology(RUET), Rajshahi, Bangladesh, 
April 2010. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Page 1054
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
*Corresponding Author: Bobby Barua, 
E-mail: bobby@aust.edu 
 
             FREE-SPACE OPTICAL COMMUNICATION SYSTEM 
UNDER STRONG TURBULENCE WITH Q-ARY  
           PULSE-POSITION MODULATION 
 
                  Bobby Barua* and Dalia Barua  
               Department of EEE, Ahsanullah University of Science and Technology, Dhaka, 
Bangladesh   
 
        Free-space optical communication is an attractive an d cost-effective solution for high-rate image, voice, and 
data transmission. However, optical wave propagation through the air experiences fluctuation in amplitude 
and phase due to atmospheric turbulence. The use of multiple laser transmitters combined with multiple photo 
detectors has the potential for combating fading effects on turbulent optical channels. For strong turbulence 
gamma-gamma models are treated. In this paper, the modulation format is Q-ary PPM across lasers, with 
intensity modulation. Ideal photodetectors are assumed, with and without background radiation. The 
performance results are evaluated in terms of symbol error probability for several system parameters.  
                             
Keywords: Free space optics (FSO), multiple input/multiple output(MIMO) , pulse position modulation 
(PPM), probability of       density function (PDF) , symbol error probability (SEP) 
                
1. INTRODUCTION 
 
Free-space optical (FSO) communication has 
received significant attention recently, as a possible 
alternative to solve the bottleneck connectivity 
problem, and as a supplement to more conventional 
RF/microwave links [1-6]. However, optical wave 
propagation through the air experiences fluctuation 
in amplitude and phase due to atmospheric 
turbulence. This intensity fluctuation, also known as 
scintillation is one of the most important factors that 
degrade the performance of an FSO communication 
link even under the clear sky condition. Two primary 
challenges are attached to free-space optical 
communication. First, the narrow beam-width 
implies the need for careful pointing, and perhaps a 
need for active pointing and tracking mechanisms to 
combat building sway, etc. Second, the need to 
combat link fading due to scattering and scintillation. 
To enable the transmission under the strong 
atmospheric turbulence the use of the multi-laser 
multi-detector (MLMD) concept has been reported 
in Ref. [4, 6]. Specifically, we envision separate 
lasers, assumed to be intensity-modulated only, 
together with photodetectors (PDs), assumed to be 
ideal noncoherent (direct-detection) receivers. The 
sources and detectors are physically situated so that 
the fading experienced between source–detector 
pairs is statistically independent, and thus, diversity 
benefits can accrue from the multiple-input multiple-
output (MIMO) channel. Obviously, the assumption 
of independence may not be valid, depending upon 
the spacing of the devices, and on the nature of the 
fading. For example, a cloud or fog bank that fills 
most of the link will obviously induce large fades on 
all source–detector pairs. Alternative means of 
operation in such environments must be considered.  
 
In this paper, we propose an analytical approach to 
evaluate the performance under strong turbulence 
with Q-ary PPM. The proposed scheme allows 
aggregation of RF/microwave signals and a 
conversion to the optical domain in a very natural 
way and may be a good candidate for hybrid 
RF/microwave-FSO systems. The symbol error 
probability (SEP) are evaluated with and without 
fading in the presence of background radiation. The 
symbol error probability are determined assuming 
that p.i.n. photodiodes are used, and the channel is 
modeled using Gamma-Gamma distribution. 
 
2. SYSTEM MODEL 
 
Fig. 1 depicts a block diagram of the physical system 
under study. M laser sources, all pointed toward a 
distant array of N PDs, are intensity-modulated by 
an information source. The laser beam-widths are 
narrow, but sufficiently wide to illuminate the entire 
PD array. For example, if the half-power beam-
width is 10 mrads, the half-power spot size at 
Page 1055
ISBN: 978-984-33-2140-4
                             
 
 
Fig. 1. Atmospheric optical MIMO system with Q-ary PPM  
 
 
distance 1 km has diameter 10 m. The MN optical 
path pairs may experience fading, and we designate 
Anm as the amplitude of the path gain (field strength 
multiplier)  from m source to detector. A Q-ary PPM 
scheme transmits L=log2Q bits per symbol, 
providing high power efficiency. In the transmitter, 
the signals are described by the waveforms 
 
  
0
1
2
3
( ) 2 , 0 4 '00 '
( ) 2 , 4 2 '01'
( ) 2 , 2 3 4 '10 '
( ) 2 , 3 4 4 '11'
s
s s
s s
s s
s t A P t T
s t A P T t T
s t A P T t T
s t A P T t T
= = ≤ ≤
= = ≤ ≤
= = ≤ ≤
= = ≤ ≤
           (1) 
 
At the receiver the received signal r(t) after 
optical/electrical conversion is: 
 
          0( ) ( ) ( )r t h t I n tη= +                          (2) 
 
where I0 =the average transmitted light intensity and  
          I  =hI0 =the corresponding received intensity  
                         in an ON PPM slot.                   
          h  =the channel fading coefficient 
          n  =receiver noise. 
 
The aggregate optical field is detected by each PD, 
assuming an ideal photon counting model with 
typical quantum efficiency. Also a single-channel 
link analysis is included to suggest typical link 
parameters. Though the transmission rate is rather 
flexible, we have in mind systems sending in the 
range of 100 Mb/s. Here we consider the chosen 
parameters rate 100 Mb/s, the expected number of 
detected photoelectrons per slot is on the order of 
300 in either binary or quaternary PPM. Though this 
is more than adequate for the desired performance 
with the ideal photon-counting model, fading and 
other parameter choices could make this number 
much smaller. We next present specific details 
regarding the optical MIMO model.  
3. CHANNEL MODELING 
 
To characterize the FSO channel from a 
communication theory perspective, it is useful to 
give a statistical representation of the scintillation. 
The reliability of the communication link can be 
determined if we use a good probabilistic model for 
the turbulence. Several probability density functions 
(PDFs) have been proposed for the intensity 
variations at the receiver of an optical link. Al-
Habash et al. [7] proposed a statistical model that 
factorizes the irradiance as the product of two 
independent random processes each with a Gamma 
PDF. The PDF of the intensity fluctuation is given 
by [7] 
 
 
( )( )/2 1
2
( )
2( )
( ) (2 ), 0
( ) ( )
f I I K I I
α βα β
α β
αβ αβ
α β
++ −
−= >Γ Γ
    (3) 
 
I is the signal intensity, Г(.)  is the gamma function, 
and Kαβ is the modified Bessel function of the 
second kind and order αβ. α and β are PDF 
parameters describing the scintillation experienced 
by plane waves, and in the case of zero-inner scale 
are given by [7] 
             
2
12/5 7 /6
1
0.49
exp 1
(1 1.11 )
R
R
α
σ
σ
=
 
− + 
                      (4)                         
         
2
12/5 5/6
1
0.51
exp 1
(1 0.69 )
R
R
β
σ
σ
=
 
− + 
                        (5)                                                            
where σR
2 is the Rytov variance given by[2] 
 
             σR
2 =1.23C2n k
7/6L11/6                                         (6) 
 
Page 1056
  
 
 
 
 
k = 2π/(is the optical wave number, L is 
propagation distance, and Cn2 is the 
refractive index structure parameter, which 
we assume to be constant for horizontal 
paths. 
 
4. THEORETICAL ANALYSIS  
 
Symbol error probability (SEP) of the system 
 
We consider four cases: with or without channel 
fading, and with or without background radiation. 
 
Case:1No Fading, No Background Radiation 
 
First, consider the case of negligible background 
radiation and equal-gain links i.e. ,Anm=1almost 
surely, n=1,………..,N, m=1,…….M with no loss of 
generality, assume that each laser sends energy in 
slot 1. The only possibility for decision error is that 
each detector registers zero counts in time slot 1, 
since the other slots register zero counts by 
assumption (λb=0)  By the Poisson property and 
independence, we have SEP 
 
     
( )
1 1
r
s
s
Np
M T E NM
hfQ hf
s
Q Q
P e e
Q Q
η η
− −
 
− − = = 
  
      (7)             
 
Case:2 Fading, No Background Radiation 
 
First, we assume the channel gain of every laser-
detector pair is fixed over a symbol duration. Letting 
amn denote the amplitude fading on the path from 
laser m to photodetector n, we define the channel 
gain matrix as A with element [anm, n =1,……,N, m 
= 1, ……M]. The probability of symbol error 
conditioned on the fading variables is 
 
2
|
1
( ) ( )
Esa
M
hf
MN
s s A
Q
P P f I dI e f I dI
Q
η  
 −
  
  −  = =   
  
   
∫ ∫   (8)   
Case:3 No Fading, Background Radiation  
At the receiver end, it received a matrix Z with 
elements [Znq, n = 1,……….,N, q =1,……..,Q]. λb is 
the Poisson count random variable parameter due to 
the background radiation, and if slot q is an ‘off’ 
slot, Znq will be also a Poisson distributed random 
variable with parameter λb. The upper bound of 
error probability  for this case 
 
 
 
                                                                                
                                                                                (9) 
In case there is no channel fading, the ML detector 
does not need to weight Znq. The ML detector just 
compares the sum of the photoelectrons counts of 
all N photodetector in every slots and chooses the 
largest w slots. Expanding the exponent with a 
Taylor series SEP can be given by, 
 
                                                                              (10) 
                                                                  
Case:4 Fading background Radiation 
For this most general case, the optimal detector is as 
described by  the following equation. We propose 
instead a more realistic design of simply summing 
over the received PD counts for each time slot as 
was optimal for the cases   presented above. Channel 
estimation at the receiver is thereby avoided in 
exchange for a small performance penalty. 
( ) ( )
1
( )1
/
1 0
( )
1
! !
s b b
Qi N Ni
s b b
S X
i j
N e N je
P X
i j
λ λ λλ λ λ
−
− + −∞ −
= =
 +
= − 
  
∑∑ (11) 
5. RESULTS AND DISCUSSION 
 
Following the analytical approach presented in 
section IV, we evaluate the symbol error probability 
result of a MIMO FSO link with Q-ary PPM and 
direct detection scheme under strong turbulence 
condition.  
0 0.5 1 1.5 2 2.5 3 3.5 4
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
I
f(
I)
 
 
SI=3
SI=6
 
Fig2:   Probability of Distribution Function for 
Gamma-Gamma. 
 
[ ]( )
( )
1
1 2 1
1
1
1 2
1 0
1 1
1 ,
Q
s q
Q
i
i j
P P all Z Z P Z Z
P Z i Z j
=
−
−
∞ −
= =
 < − < = − < 
 
= − = = 
 
∑ ∑
2( )
exp
2 4
S
S
b
w Q w
P
λ
λ
 −
≅ − 
 
Page 1057
  
 
 
-195 -190 -185 -180 -175 -170
10
-12
10
-10
10
-8
10
-6
10
-4
10
-2
10
0
Non fading for varying N
Es in dBJ
P
s
 
 
MIMO, N=1
MIMO, N=4
MIMO, N=8
 
Fig3: SEP with varying N, for gamma-gamma non- 
fading  with S.I. = 3, Q= 2.   M=1  and  no 
background noise 
          
The simulations are performed using matlab, the 
influence of scintillation is modeled assuming a 
Gamma-Gamma distribution, and an ideal photon 
counting receiver is employed. The plots of the 
probability density function in Fig. 2 for gamma 
gamma cases with several typical values of 
scintillation index (S.I) and turbulence strength. 
 
-200 -195 -190 -185 -180 -175 -170 -165 -160
10
-12
10
-10
10
-8
10
-6
10
-4
10
-2
10
0
Esdb
P
s
fading varying with M and N
 
 
MIMO,M=1,N=1
MIMO,M=2,N=2
MIMO,M=4,N=4
MIMO,M=8,N=8
 
Fig.4 :SEP with varying both M and N, for gamma-
gamma fading  with S.I. =3.  Q= 2 and no 
background noise. 
 
.In particular, notice the gamma-gamma model has a 
much higher density in the high amplitude region, 
leading to a more severe impact on system 
performance.  Fig. 3 shows the SEP under strong 
turbulence for non faded system with Q-ary scheme. 
The SEP are shown in Fig. 4 for several 
combinations of transmitting and receiving antennas  
 
 
 
under faded condition.. The symbol energy due to 
background light is set to -170 dBJ for both system 
It is noticed that, SEP improves as the numbers of 
lasers and photodetectors are increased and in the 
presence of background light the SEP decreases as 
the order of the Q-ary PPM scheme increases. 
 
6. CONCLUSIONS  
 
We have analyzed an optical MIMO system 
employing QPPM across sources, together with 
direct detection. Gamma gamma  model has been 
treated, assuming independent fading on source–
detector pairs. The analysis shows the beneficial 
effects from a diversity standpoint of multiple 
sources and detectors, and transmit diversity is 
achieved here without additional special coding. 
Some aspects of the optical MIMO system here 
mimic those of the microwave MIMO systems. Full 
transmit diversity can be shown analytically for the 
no-background-noise case. Even for the case of 
normal background radiation, QPPM is still able to 
approach the performance of the unfaded case by 
increasing the number of transmitter. The proposed 
MIMO scheme provides excellent gains for different 
atmospheric turbulence conditions, ranging from the 
weak to the strong turbulence regimes.        
                              
7. REFERENCES 
 
1. Cvijetic N., Wilson S.G., and Brandt- 
Pearce M., “Receiver optimization in 
turbulent free-space optical MIMO 
Channels  with APDs  and Q-ary 
PPM,”IEEE photon tehnol.Lett.18, 1491-
1493 (2006) 
 
2.    Wilson S.G., Brands-Pearce M., Cao Q., 
and Leveque J.J.H.,III, “Free-Space optical 
MIMO transmission with Q-ary PPM,” 
IEEE Trans. Commun.53,1402-1412(2005) 
 
3.  L. C. Andrews, R. L. Phillips, C. Y.    
Hopen, M. A. Al-Habash, “Theory of 
optical scintillation,” J. Opt. Soc. Am. A 16, 
1417–1429   (1999).  
 
4.  J. Strohbehn, Ed. “Laser Beam  
Propagation in the Atmosphere” New York: 
Springer, 1978. 
 
5.  B. Saleh, Photoelectron Statistics.  Berlin,    
Germany: Springer- Verlag,1978. 
 
6.    G. Ochse, Optical Detection Theory for 
Laser  Applications. NewYork: Wiley-  
Interscience, 2002. 
 
7.  M.A. Al-Habash, L.C. Andrews, and R. L. 
Phillips, Optical Engineering  40,pp.1554- 
1562 (2001). 
Page 1058
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
1 likhon@uap-bd.edu 
2 khairul.uapstu@gmail.com 
3ummenurmafi@gmail.com, 4shawkatmatin@yahoo.com 
INTELLIGENT TRAFFIC CONTROL BY CCTV, PIC16F877A 
MICROCONTROLLER AND IR ROAD SENSOR   
 
 
Md. Nur-Us-Safa1 and Md. Khairul Alam2 
The University of Asia Pacific, Dhaka 
 
Umme Nur Mafiha Majid3, Shawkat Matin4 
The University of Asia Pacific, Dhaka 
 
 
                In view of domestic traffic, the traffic flow has been increasing dramatically in recent years, whereas traffic 
control is deficient. This paper presents a design of intelligent traffic control which contains road sensor, 
emergency sound detector, traffic signal violation detector and live human-computer interaction. Road 
sensor will determine the traffic density and according to the traffic density the microcontroller will organize 
the signal light. Emergency sound detector can detect ambulance, fire brigade and other emergency car and 
the microcontroller will give precedence for this kind of emergency vehicles. The regulation violation 
detector can detect vehicle if they violate the traffic signal and take the picture of number-plate of violating 
vehicles. In any kind of unexpected situation the signal light can be controlled by the computer.  
Key words: Road sensor; Infrared; Traffic Control; Microcontroller; intelligent 
 
1. INTRODUCTION 
 
Bottleneck of traditional traffic signal controller is 
not intelligent, and the mode of control is quite 
unitary. Obviously traditional traffic signal 
controller can not meet the complicated and 
diversified traffic control in modern city [1-5].  In 
the existing traffic control system of Bangladesh 
the traffic signals are repeated at certain time 
intervals, without taking into consideration the 
traffic load in the roads. It works at a constant time 
interval irrespective of the crowd density at any 
time [6]. So it is very common that a nearly empty 
road is enjoying the green signal while a more 
congested road is under the red signal. The 
proposed system has the capacity to realize the 
traffic load. Basically some road sensors count the 
vehicles in various roads. Here it is tried to 
minimize traffic jam by assigning slots of sensor to 
each road. Every crowded slot has a predefined 
time. In a easy way it can say that, the road sensors 
count vehicles in various roads and according to 
this count microcontroller determines which road 
has more vehicles and give more time for green 
signal in that road compare to other roads which 
have lesser vehicle. As more crowded road will find 
more time for green signal, a balance will be 
maintained among different roads and the traffic 
jam will be reduced. Traffic signal violation 
detector identifies vehicle which violate signal and 
camera will take picture of number-plate from back 
sides of this car. Any time signal light can be 
controlled by computer command also. Thus it can 
intelligently accomplish human-computer 
interaction, control signal according to traffic 
density, detect vehicle if any one go against to 
signal. 
2. MAIN PARTS OF THE SYSTEM 
 
The main parts of the system are road sensors, 
emergency sound detectors, traffic signal violation 
detectors, cameras, processing unit and signal 
lights. From road sensors and sound detector 
processor (a microcontroller) takes input and 
according to input it controls the signal lights. 
Figure 1 signifies the block diagram of the system.  
 
 
  
 
 
 
 
 
 
Fig. 1: Block Diagram 
 
Processing 
Unit 
Road Sensor 
Emergency sound detector 
Camera 
Control Room 
RS232 Interfacing 
Signal lights 
Traffic signal 
violation  
Detector 
Page 1059
  
Details of each block are given one by one below. 
 
2.1 Processing Unit 
Processing unit is the heart of this system. Here 
used a PIC16F877A microcontroller as processor. It 
is an 8bit microcontroller introduced by Microchip 
corporations [7-8]. Program for this microcontroller 
is written in Assembly language. For program 
editing, compiling and simulation, MPLAB IDE 
was used.  The output of sensors is taken as input 
by microcontroller an according to this output delay 
for signal lights are calculated and implemented 
automatically according to program’s instruction. A 
serial port programmer was used for program 
writing into microcontroller.  
 
2.2 Road Sensor  
Road sensor’s has two parts, a light source and a 
receiver. An infrared generator acts as light source 
and photoresistor acts as receiver. When light 
(Infrared) from light source fall into receiver 
(photoresistor) the output of the sensor is zero as 
resistance of the photoresistor decreases. When no 
light in the receiver the resistance of it is high and 
for this output is high. Fig. 2 shows how it works. 
 
 
 
Fig. 2: How road sensors work 
 
 
Fig. 2: How road sensors work 
The sensors output is connected to the 
microcontroller and microcontroller gets this output 
as digital input (0 for low and 1 for high). Receiver 
is connected in series with a resistor and act as 
voltage divider. When resistance of photoresistor is 
low then ground will appear as output and when 
resistance of photoresistor is high then +v will 
appear as output.   
The main work of road sensor is to count vehicle in 
various roads.  Infrared sensor is used as road 
sensor. Infrared LEDs are placed at one side of the 
road. Another side contains infrared receivers. 
Infrared rays are focused to receiver from infrared 
LEDs. When there is no vehicle in the road infrared 
rays fall to the receivers and it shows low 
resistance. When the vehicles obstruct the light to 
fall receiver then it shows high resistance. A road is 
divided into several slots and every slot contains a 
set of sensors. A fixed time is predefined for every 
slot. According to the filled slot with vehicles the 
microcontroller calculates the duration of signaling 
time. 
 
Let, the predefined time for a slot is a, 
Filled slots are n, 
So the duration of the green signal for this roads = 
a*n. 
 
Consider a junction of four roads. Let, at a time 1 
slot of first road’s, 3 slots of second road’s, 2 slots 
of 3rd road’s and 4 slots of 4th road’s is filled. 
Assume predefined time for each slot is a=5 
second. As forth road has maximum number of 
filled slot (4 slot) compare to other in this junction, 
so the duration of green signal corresponding to 
forth road will be maximum (4*5=20 seconds). For 
first, second and third road green signal’s duration 
will be 5, 3*5=15 and 2*5=10 respectively. So 
from here it is clear that a more congested road will 
get more time automatically by this system. It is 
frequently occurred in the existing traffic control 
system in Bangladesh that, a nearly empty road 
enjoys the green signal while a more congested 
road enjoys red signal. By this automatic traffic 
control system the problem will be minimized as 
well as reduced traffic jam. 
 
2.3 Emergency sound detector 
When ambulance, fire brigade, VIP cars are entered 
in a road, emergency sound detector of that road 
detects this and microcontroller takes this as an 
interrupt and turn on the green signal of the 
corresponding road. Microphone and band pass 
filter are used as sound detector. Figure 3 represents 
how emergency sound detector will work. Sound 
detector contains a MIC and a band pass filter 
which allows to pass emergency sound band such 
as 2 kHz - 3.5 kHz only. The signal from band pass 
Page 1060
  
filters then sent to amplifier section for 
amplification.  Microcontroller takes amplified 
output of amplifier as input and input is high only 
for frequency which will pass from band pass filter. 
 
  Audio signal                    Electric  
                                            Signal                              
                                    
                                       
   Electric signal only for 
 emergency sound band 
     
                              
                                 Amplified  
                                               Signal   
 
 
 
Fig. 3: How emergency sound detector works 
 
Microphone (MIC) is used as transducer and 
convert audio signal into electrical signal. This 
electrical signal contains energy for all rang of 
audio frequencies (Fig. 4a). But the system needs 
signal only for emergency vehicles, so it is then 
passed through a band pass filter which frequency 
band is for emergency sound rang (such as 2KHz to 
3.2 KHz). Now the output contains electric energy 
only for emergency sound band (Fig. 4b).   
 
 
Fig. 4a: frequency response before filtering 
 
 
Fig. 4b: frequency response after filtering       
The output energy is very low (at milli volt). So 
amplifier is used for amplification of signal. Figure 
5 shows frequency response of amplified signal. 
 
 
Fig. 5: Frequency response of amplifier’s output 
 
2.4 CCTV and PC Interfacing 
With RS232 interfacing standard the system can 
communicate with computer. It is one kind of serial 
communication with computer. Serial terminal 
program is needed for user interfacing with pc. 
Windows default terminal program ‘Hyper 
Terminal’ can be used. CCTV camera is set in 
every traffic point. Several points can be control 
from a control room. The overall view of o point 
can be seen from the room and can send control 
instruction to the signal. All video will be saved 
into video server in the control room for future 
investigation. From the control room if it is seen 
that a traffic signal point should need more 40 
second for green signal to pass vehicle because of 
an unexpected situation occurred. So it is very easy 
to do this job. Simply press 40 in Hyper Terminal 
input box and press enter. Microcontroller takes it 
as a serial interrupt and instantly implements this 
into corresponding signal. If more 20 seconds 
needed it is also possible in the same way. 
 
2.5     Traffic signal violation detector 
If any time a road is under red signal and then if 
any vehicle pass the last limit violation detector 
identify it and instantly camera take the picture of 
the number plate of that vehicle from its back side. 
Traffic rule violation detector contains sensor and 
camera. Sensor is like road sensor but it sets up at 
the starting of the road from junction. Figure 6 
shows the setup of violation detector. When any 
vehicle crosses the last limit of road at the time of 
red signal, microcontroller gets an interrupt and 
instantly switched the camera to take picture. 
Camera is sat as this way that, it can take picture 
from the back side of the car which violates the 
rule. Getting the picture proper action could be 
taken against the violator. 
 
Microcontroller Amplifier 
MIC Band Pass 
Filter 
Page 1061
  
 
Signal light post          
 
 
                                 Last limit 
                                       
 Sensor 
 
 
Fig. 6: Signal violation sensor setup in a 4 roads 
junction 
 
3. CONCLUSIONS 
 
The system represented here used very basic 
element. So implementing of this system will be 
cost efficient. The system can automatically control 
the traffic signal considering traffic density, can 
detect vehicle that disobey the traffic signal. The 
duration of a signal light can also be defined from a 
computer.  The overall view of a traffic point can 
be viewed by CCTV cameras and any time the 
signal can be controlled by computer from a remote 
control room. The CCTV can also be used for 
security purpose.  In case of violating traffic signal 
camera take the picture of number plate. By this 
necessary steps can take against violator. As it is 
automatic so people will keep alert and traffic 
discipline can be improved. By this intelligent 
system safety will improve and chances of accident 
will fall. Emergency vehicles will get automatic 
priority. The system will also improve the security 
of the traffic point as well as the road. 
 
REFERENCES 
 
1. Haimeng Zhao, Intelligent Traffic Control 
System Based on DSP and Nois II, 
International Asia Conference on Informatics 
and control, Automation and Robotics, 2009.  
2. Bishop R, A servey of intelligent vehicle 
applications worldwide, Proceedings of the 
IEEE Intelligent Vehicle Symposium 2000, 
Dearborn, USA, 2000, pp. 24-30. 
3. He G G, North G, Urban traffic control system 
a general analysis from the point of view of 
control theory, Transportation System, 1997,  
vol 2,  pp. 501-506. 
4. Goto K, Higashikubo M, Aoki M, A spatial 
image processing traffic flow sensor and its 
applications for signal control, surveillance and 
warning system, Transactions of the Institute of 
Electrical Engineers, 2001, 121(1),  pp. 99-104. 
5. Wang Gesi, Zhang Yongjum(2004), Study of 
intelligent transportation signal controller, 
Information technology, 28(8), pp. 42-43. 
6. Sadat Mazumder, Sanjib Saha, Intelligent 
traffic Control System, Star campus, 2(12), 
April 01, 2007. 
7. Tim Wilmshurst(2007), Designing Embedded 
Systems with PIC Microcontrollers: Principles 
and applications, 1st Edition,  Newnes 
publications. 
8. Mohammad Ali Mazidi, Rolin D. McKinlay & 
Danny Causey, Pic Microcontroller and 
Embedded Systems, 1st Edition, Pearson 
Education, 2008. 
 
Page 1062
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Ummee Tania Ahmed,  
INTERFERENCE REDUCTION AND CAPACITY ENHANCEMENT 
USING SMART ANTENNAS IN CDMA NETWORKS 
 
 
Ummee Tania Ahmed1* and Md. Abdul Matin2 
1. The University of Asia Pacific (UAP), Dhaka. 
2. Bangladesh University of Engineering and Technology (BUET), Dhaka. 
 
Md. Sekendar Ali1and Abdul Matin Patwari1 
1. The University of Asia Pacific (UAP), Dhaka. 
 
 
In this paper a high-resolution direction finding algorithm called ESPAR (electronically steerable parasitic 
array radiator) using MUSIC with periodic signals is employed on a smart antenna. The modified MUSIC 
algorithm is free from the negative influences of the mutual coupling among antenna elements. The 
simulation confirmed that a smart system has ability to distinguish between signals of interest and 
interference by directing beams in the directions of the desired signals and nulls in the directions of the 
interfererences. Moreover, signal distortion problem of a CDMA system can be resolved with the help of a 
omnidirectional pattern of a circular array. 
 
Key words: Smart antenna, CDMA, Direction of arrival estimation, Multiple signal classification . 
 
1. INTRODUCTION 
 
The limited capacity analog cellular AMPS 
(Automatic Mobile Phone System) is being 
replaced by more advanced digital cellular CDMA 
system in some parts of the USA. With the 
introduction of PCS frequencies, GSM and CDMA 
technologies are making giant strides in 
commercial wireless markets across the world [1]. 
In CDMA systems the frequency reuse factor is 1 
which enables it to offer higher capacities and the 
capacity improvement by CDMA technology may 
be as high as 13 times that of TDMA. But in 
CDMA all subscribers use same frequency and this 
creates inter-cell & intra-cell co-channel 
interference. Thus the actual performance of a 
CDMA system is still interference limited and is 
affected by adverse channel conditions created by 
multipath propagation. It is obvious that the 
capacity of CDMA based wireless communication 
system can be improved by different interference 
reduction techniques and that can be achieved by 
using smart antennas such as switched beam smart 
antenna (SBSA) or adaptive array smart antenna 
[2]-[3]. Reactance loading of circular array for 
omnidierctional beamforming has been considered 
in [4]. In our analysis, we have shown that perfect 
omnidirectinal beam pattern can be obtained by 
Music algorithm and by varying reactance loading 
of a circular array designed for CDMA. 
 
2. DIRECTION OF ARRIVAL 
ESTIMATION 
 
Direction of arrival (DOA) estimation is a basic and 
important technique in array signal processing for 
wireless communication systems. In signal 
processing literature, direction of arrival denotes 
the direction from which usually a propagating 
wave arrives at a point, where usually a set of 
sensors are located. This set of sensors forms a 
sensor array [5]. 
 
 
 
 
 
 
 
 
      
 
 
Fig. 1: Configuration of the smart antenna 
Page 1063
ISBN: 978-984-33-2140-4
  
As shown in Fig.1 a uniform linear array composed 
of N elements with inter-element spacing d is 
considered. In this case, M Electromagnetic waves 
(which are supposed to be narrowband plane waves 
with central frequency ω) impinge on the array 
from directions Mmm ,....1, =θ .  It is generally 
assumed that M < N, though there exist approaches 
that do not place this constraint. In practice, the 
estimation is made difficult by the fact that there 
are usually an unknown number of signals 
impinging on the array simultaneously, each from 
unknown directions and with unknown amplitudes. 
Also, the received signals are always corrupted by 
noise. Nevertheless, there are several methods to 
estimate the number of signals and their directions. 
In this paper, MUSIC algorithm is used to estimate 
the DOA of signals [6]-[8]. 
 
3. THE MUSIC ALGORITHM 
 
MUSIC is an abbreviation for Multiple Signal 
Classification. The multiple signal classification 
(MUSIC) method is a simple and efficient eigen 
structure variant of DOA estimation methods. It is 
perhaps the most studied method in its class and has 
many variations. It is the most promising and a 
leading candidate for further study and actual 
hardware implementation. MUSIC algorithm is 
popular due to its generality. It is an algorithm used 
for frequency estimation and emitter location. 
 
It is applicable to arrays of arbitrary but known 
configuration and response, and can be used to 
estimate multiple parameters per source (e.g., 
azimuth, elevation, range, polarization, etc.). 
However, this generality is accompanied with the 
expense that the array response must be known for 
all possible combinations of source parameters; i.e., 
the response must be either measured (calibrated) 
and stored, or one must be able to characterize it 
analytically (e.g., as in the case of root-MUSIC). In 
addition, MUSIC requires a priori knowledge of 
the second-order spatial statistics of the background 
noise and interference field. [9] – [11]. 
 
The signal and noise subspaces are first identified 
using eigen decomposition of the received signal 
covariance matrix. Then MUSIC spatial spectrum is 
computed, from which the DOAs are estimated. 
Inside the algorithm, we first define the general 
array manifold to be the set 
A={a(θi) : θi € θ} 
 
The structure of the exact covariance matrix with 
the spatial white noise assumption implies that its 
spectral decomposition can be expressed as [12]-
[13] 
Rxx=AUssAH+Ω2I=Us sΛ UHs+Ω2UnUnH 
where, assuming AU
ss
A
H 
to be of full rank, the 
diagonal matrix Λ
s 
contains the L largest 
eigenvalues. Since the eigenvectors in U
n 
(the noise 
eigenvectors) are orthogonal to A, we have, 
 
UnHa(θ)=0,       θ ∈ {θ1, θ2,…………θL} 
 
Here, the eigen decomposition of Rxx will give the 
eigenvalues λn such that λ1 > λ2 > . . . > λK > 
λK+1 = λK+2 = . . . = λN = Ω2n and the 
corresponding eigenvectors Un ϵ CN, n = 1, 2, . . . , 
N, of Rxx. 
 
To allow for unique DOA estimates, the array is 
usually assumed to be unambiguous, that is, any 
collection of M steering vectors corresponding to 
distinct DOAs η
k 
forms a linearly independent set 
{a(η1), . . . , a(ηM)}, where L<M. If a(θ) satisfies 
these conditions and R
xx
has full rank, then AU
ss
A
H 
is also of full rank. It then follows that θ1, . . . , θL 
are the only possible solutions to the relation in 
Eqn. (2), which could therefore be used to exactly 
locate the DOAs. In practice, an estimate R
xx
of the 
covariance matrix is obtained and its eigenvectors 
are separated into the signal and noise eigenvectors. 
The orthogonal projector onto the noise subspace is 
estimated as 
P ^ ┴A = Un^    Un^H 
 
The MUSIC spatial spectrum is then defined as 
 
PL(Ө) = [aH(Ө)a(Ө)] / { aH(Ө) P ^ ┴A a(Ө } 
 
Although P
L
(θ)is not a true spectrum in any sense 
(it is merely the distance between two subspaces), it 
exhibits peaks in the vicinity of the true DOAs. The 
performance improvement of the MUSIC estimator 
was so significant that it became an alternative to 
most existing methods. Thus, in contrast to the 
beam forming techniques, the MUSIC algorithm 
provides statistically consistent estimates. The 
DOA’s of each of the incident signals can be 
estimated by plotting the spatial spectrum given by 
P
L
(θ ) [14] -[16]. 
 
 
4. SIMULATION RESULT 
 
The following cases are considered for      
MATLAB simulation:- 
 
The antenna generates a directional beam based on 
load reactances (x1, x2, . . . , x6). The signal 
Page 1064
  
100 110 120 130 140 150 160 170 180
-250
-200
-150
-100
-50
  10
  20
  30
30
210
60
240
90
270
120
300
150
330
180 0
100 110 120 130 140 150 160 170 180
-250
-200
-150
-100
-50
  10
  20
  30
30
210
60
240
90
270
120
300
150
330
180 0
100 110 120 130 140 150 160 170 180
-250
-200
-150
-100
-50
impinging directions are set arbitrarily to 120◦ and 
150◦ in the azimuth plane, respectively. As a result, 
all the spectra reach the peak values at the 
respective signal directions. Here, three different 
reactance load settings are studied to investigate 
their influence on the performance of the DOA 
estimation. The signal-to-noise ratio (SNR) is 30 
dB for each individual signal source. 
 
When we set equal load reactances   to the elements 
of the circular array considered, the antenna 
exhibits a nearly omnidirectional beam pattern. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
After that, we took ordered but unequal load 
reactance and set x1 = 0Ω, x2 = 60Ω, x3 =0Ω, x4 
= 60Ω, x5 = 60Ω, and x6 = 60Ω. As a result, it 
slightly influence MUSIC spectrum and provide 
insufficient beam patterns for rotation. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Finally, we randomly set x1 = 0Ω, x2 = 30Ω,           
x3 =60Ω, x4 = 90Ω, x5 = 120Ω, and x6 = 150Ω. It 
gives the directional information like an adaptive 
beam processor. 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 2.1: MUSIC spectrum for SNR=30dB in 
the signal direction 120o and 150o in the 
azimuth plane. 
 
Fig. 2.2: Beam pattern in the azimuth plane for 
x1=30Ω, x2=30Ω, x3=30Ω, x4=30Ω, x5=30Ω and 
x6=30Ω  
Fig. 2.3: MUSIC spectrum for SNR=30dB in 
the signal direction 120o and 150o in the 
azimuth plane. 
 
Fig. 2.4: Beam pattern in the azimuth plane for 
x1=0Ω, x2=60Ω,x3=0Ω, x4=60Ω, x5=60Ω and 
x6=60Ω  
Fig. 2.5: MUSIC spectrum for SNR=30dB in the 
signal direction 120o and 150o in the azimuth 
plane. 
Page 1065
  
  10
  20
  30
30
210
60
240
90
270
120
300
150
330
180 0
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
7. CONCLUSIONS 
 
From the above investigations, we can conclude 
that the manner of load settings for the elements of 
a circular smart array greatly influences the DOA 
estimation performances. The load setting that 
gives deep nulls in radiation patterns in certain 
directions should be avoided, because signals 
coming from that region could be received with low 
power levels, or even be nulled. Consequently, the 
information of signal in the null region cannot be 
extracted. Moreover, Signal distortion is prominent 
in multiple beam forming. This problem should be 
resolved for a CDMA system where binary pulses 
are extensively used. Omnidirectional pattern of a 
smart antenna system can resolve this problem. We 
have shown how an omnidirectinal pattern can be 
obtained by a circular smart array of parasitic 
elements by parameter adjustment. For example, 
Fig-2.2 corresponding to 30Ω -100Ω reactance 
loading for each element in a circular array gives 
omnidirectional pattern which can resolve the 
problems of signal distortion 
 
 
REFERENCES 
 
1. M.A. Matin, “Smart Antenna, The Technology 
of Future.” The Daily Financial Express, 
Dhaka. Monday, March 2, 2009 page-4. 
2. U. T. Ahmed,  M. N. Shaheed, M. Hoque,M. S. 
Ali,  A.l M. Patwari  and  
M.A.Matin,“MATLAB Simulation of a Smart 
Antenna Using MUSIC Algorithm”, 
Proceedings of  Bangladesh Electronic Society 
Conference, National Seminar on Electronics  
and Telecommunications for Digital 
Bangladesh held in AEC Dhaka, during 2-3 
June 2010 , p.p 148-153. 
3. A.Y.Hasan , A.N.M. Shamsuddin, S. khaled, 
T.Ahmed, S.A.Hasan and M.A.Matin, 
“Simulation of Smart Antenna by Using Smart 
Algorithm”, Proceedings of  Bangladesh 
Electronic Society Conference ,National 
Seminar on Electronics  and 
Telecommunications for Digital Bangladesh 
held in AEC Dhaka, during 2-3 June 2010, p.p 
237-240. 
4. Nemai C. Karmakar and Chen Sun ‘’Direction 
of Arrival Estimation with a NovelSingle-Port 
Smart Antenna’’,EURASIP Journal on Applied 
Signal Processing 2004:9, 1364–1375_c 2004 
Hindawi Publishing Corporation.  
5. U. T. Ahmed, M.A.Matin, M. S. Ali and A.l 
M. Patwari, “The Way ESPRIT Algorithm 
Based on DOA Estimation Exploits on a Smart 
Antenna”  to be published. 
6. M. Pastorino and A. Randazzo, “A Smart 
Antenna System for Direction of Arrival 
Estimation Based on a Support Vector 
Regression”, IEEE Transaction on Antennas 
and Propagation, Vol.53, No.7,July 2005. 
7. A. H. El Zooghby, C. G. Christodoulou, and 
M. Georgiopoulos, “Performance of radial-
basis  function network for direction arrival 
estimation with antenna arrays,” IEEE Trans. 
Antennas Propag., Vol. 45, pp.1611–1617, 
Nov. 1997. 
8.  V. Vapnik, S. Golowich, and A. J. Smola, 
“Support vector method for function 
approximation, regression estimation, and 
signal processing,” in Neural Information 
Processing Systems. Cambridge, MA: MIT 
Press, 1997, Vol. 9. 
9. L.C. Godara, " Smart Antennas," CRC Press 
Inc.N.Y. 2004. 
10. F. B. Gross,’’Smart Antennas for Wireless 
Communications With MATLAB’’,2005, 
McGraw-Hill. 
11. Liberti, J. C, Rappaport, T. S.” Smart Antennas 
for Wireless Communications”. New Jersey, 
Prentice Hall, 1999. 
12. A. L. Swindlehurst and T. Kailath, “A 
performance analysis of subspace-based 
methods in the presence of model errors. Part I: 
The MUSIC algorithm,” IEEE Trans. Signal 
Process., vol. 40, no. 7, pp. 1758–1774, July 
1992. 
13. A. J. Barabell, J. Capon, D. F. Delong, J. R. 
Johnson, and K. Senne, “Performance 
Comparison of Superresolution Array 
Processing Algorithms,” Lincoln Laboratory, 
M.I.T., Tech. Rep. TST-72, 1984. 
14. G.Sivaradje, K.Ayyappan and 
P.Dananjayan,”Direction of Arrival Based 
Interference Reduction and Capacity 
Enhancement Using Smart Antennas in CDMA 
Networks”, ” IEEE Personal Comm.,1998. 
Fig. 2.6: Beam pattern in the azimuth plane 
for x1=0Ω,x2=30Ω,x3=60Ω, x4=90Ω, x5=120Ω 
and x6=150Ω  
Page 1066
  
15. S. Durrani and M. E. Bialkowski, “Interference 
rejection capabilities of different types of 
antenna arrays in cellular systems,” IEE 
Electronics Letters, vol. 38, pp.617-619, June 
2002. 
16. R. Schmidt, “Multiple emitter location and 
signal parameter estimation,” IEEE Trans. 
Antennas Propagat., vol. 34, no. 3, pp. 276–
280, Mar. 1986.  
Page 1067
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Debabrata Kumar Karmokar  
E-mail: debeee_kuet@yahoo.com 
MULTIBAND STRIP ANTENNA FOR 2.3/2.5/5.5 GHZ WIMAX AND 
2.4 GHZ WLAN OPERATIONS  
 
Debabrata Kumar Karmokar*, Md. Selim Hossain, Khaled Mahbub Morshed, Md. 
Arafat Hossain and A. N. M. Enamul Kabir  
Faculty of Electrical & Electronic Engineering 
Khulna University of Engineering & Technology, Khulna-9203, Bangladesh 
 
Md. Nurunnabi Mollah 
Department of Engineering & Technology, Eastern University, Dhaka, Bangladesh 
 
 
Abstract— This paper presents a multiband strip antenna for 2.3/2.5/5.5 GHz WiMAX and 2.4 GHz WLAN 
operations by means of numerical simulations. The dimension of the antenna is 39×30 mm2 and provides an 
impedance bandwidth of 300 MHz (2350-2650 MHz) and 130 MHz (5490-5620 MHz) at lower and upper 
frequency band respectively, which fully covers the 2.4, 2.5 and partially covers the 2.3, 5.5 GHz bands. The 
antenna contains very high peak gains of 8.25, 8.43, 8.46 and 6.43 dBi at 2.3, 2.4, 2.5 and 5.5 GHz band 
respectively with less than 0.2, 0.1, 0.3 and 1.5 dBi gain variations within the 10 dB return loss bandwidth. 
The VSWR of the antenna varies between 1.20~1.80 and 1.06~1.83 at the lower and upper resonant 
frequency bands respectively and the peak values of the return loss are -20.85 and -30.71dB. The antenna 
has good omnidirectional radiation characteristics at E-plane and H-plane.  
 
Key words: Strip Antenna; Multiband Antenna; Numerical Electromagnetic Code (NEC); WiMAX; WLAN 
 
 
1. INTRODUCTION 
 
At present the demand of wireless local area 
networks (WLANs) and worldwide interoperability 
for microwave access (WiMAX) are increasing 
numerously worldwide for commercial 
communication because WLAN provides high 
speed connectivity and easy access to networks 
without wiring and WiMAX can provide a long 
operating range with a high data rate for mobile 
broadband wireless access, faultless internet access 
for wireless users becomes more popular. Also in 
recent times the function of various portable 
devices is increasing, so the antenna designer’s 
encountered difficulty in designing antennas that 
could provide multiband operations with high gain 
in each operating band. The fast growing WLAN 
protocols operating bands are IEEE 802.11 b/a/g at 
2.4 GHz (2400–2484 MHz), 5.2 GHz (5150–5350 
MHz) and 5.8 GHz (5725–5825 MHz), the 
operating bands of WiMAX is 2.5/3.5/5-GHz (2500 
–2690/3400–3600/5250–5850 MHz) bands (Pan et. 
al., 2007, Pazin et. al., 2008, Wu et. al., 2005, Su 
and Wong, 2006).  
                                                                                  
A dual wideband printed monopole antenna for 
WLAN/WiMAX applications (Pan et. al., 2007), a 
multiband flat-plate Inverted-F antenna for Wi-
Fi/WiMAX operation (Pazin et. al., 2008), a T-
shaped monopole antenna with shorted L-shaped 
strip-sleeves for WLAN 2.4/5.8-GHz operation 
(Wu et. al., 2005), an internal PIFA’s for 
UMTS/WLAN/WiMAX multi-network operation 
for a USB dongle (Su and Wong, 2006),  a CPW-
fed triangle-shaped monopole antenna for 2.4/5 
GHz WLAN and 3.4 GHz WiMAX applications 
(Song, et. al., 2007), a capacitively fed hybrid 
monopole/slot chip antenna has been proposed for 
2.5/3.5/5.5 GHz WiMAX operation in the mobile 
phone (Lai and Wong, 2008), a printed antenna 
with a quasi-self-complementary structure for 
5.2/5.8 GHz WLAN operation (Wong, et. al., 
2003), a compact monopole antenna has been 
proposed for dual ISM band (2.4 and 5.8 GHz) 
operation (Jung, et. al., 2009), a printed antenna 
which is working in 2.4 GHz bluetooth, 3.5 and 5.8 
GHz WiMAX, 2.4–2.5 and 5.0–5.8 GHz Wi-Fi,  
2.4–2.84 GHz, 5.15–5.35 and 5.72–5.83 GHz 
WLAN operation (Sun et. al., 2009), a broadband 
low-profile printed T-shaped monopole antenna for 
5 GHz WLAN application (Su et. al., 2004) and a 
compact PIFA for bluetooth, S-DMB, WiBro, 
WiMAX and WLAN applications (Shin and Park, 
2007)  have been proposed. 
Page 1068
ISBN: 978-984-33-2140-4
  
Feed 
d l 
t 
h h1 
 
s 
To provide the rising demand and cover up the 
widespread applications of WiMAX and WLAN an 
antenna with high gain, satisfactory bandwidth and 
less gain variation within the antenna bandwidth are 
desired. To meet up most of mentioned 
requirements, multiband strip antenna is one of the 
superior candidates within the micro-strip printed 
antennas. 
 
2. ANTENNA DESIGN 
 
In designing multiband strip antenna for WiMAX, 
and WLAN operation, we examine the possibility 
of increasing antenna gain and number of operating 
bands. Using MoM’s in Numerical Electromagnetic 
Code (Burke, and Poggio, 1981), we conducted 
parameter studies to ascertain the effect of different 
loading on the antenna performance to find out the 
optimal design. In our analysis we assume the 
copper conductor and the antenna is assumed to 
feed by 50 Ω coaxial connector, with its central 
conductor connected to the feeding point and its 
outer conductor connected to the ground plane just 
across the feeding point. Fig. 1 represents the basic 
geometry of the IFA. Here one leg of IFA directly 
connected to the feeding and another leg spaced s 
from the ground plane. For the simulation we 
consider printed circuit board (PCB) with 
permittivity of εr = 2.2 and substrate thickness of 
1.58 mm. In the analysis the dimensions of the 
ground plane considered as 60 mm × 60 mm. Fig. 2 
and 3 represents the loaded IFA, called the double 
branch inverted-F antenna (DBIFA) and   triple 
branch inverted-F antenna (TBIFA) respectively. 
Fig. 4 represents the proposed strip antenna. 
 
 
 
 
 
 
 
 
Fig. 1: Structure of inverted-F antenna (IFA) 
 
 
 
 
 
 
 
 
 
                                              
Fig. 2: Structure of double branch IFA (DBIFA) 
 
 
 
 
            
            
      
 
 
 
 
                                                      
Fig. 3: Structure of triple branch IFA (TBIFA) 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                      
Fig. 4: Structure of proposed strip antenna 
 
For IFA of Fig. 1, the resonant frequency related to 
d given as (Huynh, 2000) 
 
      
 
Where c is the speed of light.  The effective length 
of the current is l+t+h1+d. Under this case the 
resonant condition can be expressed as 
 
      
 
The other resonant frequency that is a part of linear 
combination with the case 0<d< (1+t) and is 
expressed as 
       
 
 
The resonant frequency (fr) is a linear combination 
of resonant frequency associated with the limiting 
case. For the antenna geometry of Fig. 1, fr can be 
written from equation (1) and (2) as (Hirisawa and 
Haneishi, 1992) 
 
 
 
Where r=d/(l+t). Fig. 5 shows the return loss 
variation with frequency of IFA, DBIFA, TBIFA 
(1)                    )(4 11 htl
cf
++
=
(2)                      
4
0
1
λ
=+++ dhtl
(3)                  )(4 12 dhtl
cf
−++
=
s Feed 
d 
t 
h h1 
h2 h2 
l 
(4)                    )1(. 21 frfrf r −+=
 
s Feed 
d 
t 
h h1 
h2 
    h2 
t l 
Feed 
t 
d 
t 
h h1 
h2 
 
s 
h3 
h2 
    h2 
h2 
h2 
l 
Page 1069
  
and strip antenna. It represent that the return loss of 
IFA is like dual band shape but both band stay 
above the required 10 dB level. As the performance 
of IFA is not satisfactory for the multiband 
operation then we apply a small suitable structured 
load on the horizontal branch of the IFA named 
double branch IFA (DBIFA) as shown in Fig. 2.  
 
From Fig. 5 we observe that when we apply that 
load then the antenna performance improves 
significantly but the performance of the lower 
frequency band is not till satisfactory. So we further 
modify the applied load (as shown if Fig. 3) and 
observe that the antenna has achievable return loss 
characteristic for both operating band. We continue 
advanced analysis on the loaded IFA for achieving 
best performance from the antenna structure 
(shown in Fig. 4 called strip antenna). Fig. 6, 7 and 
8 show the effects of L, h2 and t on the performance 
of strip antenna (antenna structure of Fig. 4). Table 
1 represents the optimized dimensions of the 
proposed antenna of Fig. 4.  
 
  Table 1. Dimension of the proposed antenna of 
Fig. 4                                                                  
Antenna 
name 
Antenna 
parameters 
Values 
(mm) 
Dimension 
(mm2) 
Strip antenna 
l 33 
39×30 
t 6 
L=l+t 39 
h1 13.4 
h2 4 
h3 12 
h 14 
d 2 
s 0.6 
 
 
2 3 4 5 6 7
-40
-30
-20
-10
0
S 1
1 
(dB
)
Frequency (GHz)
 IFA
 DBIFA
 TBIFA
 Strip Antenna
 
Fig. 5: Variations of return loss for different types 
of antennas 
 
2 3 4 5 6 7
-40
-30
-20
-10
0
S 1
1 
(dB
)
Frequency (GHz)
 L=34 mm
 L=39 mm
 L=44 mm
 
                                         (a) 
 
2 3 4 5 6 7
-10
-5
0
5
10
G
ai
n
 
(dB
i)
Frequency (GHz)
 L=34 mm
 L=39 mm
 L=44 mm
 
(b) 
Fig. 6: Variation of (a) return loss and (b) gain for 
different values of L of strip antenna 
 
2 3 4 5 6 7
-40
-30
-20
-10
0
S 1
1 
(dB
)
Frequency (GHz)
 h2=3 mm
 h2=4 mm
 h2=5 mm
 
(a) 
Page 1070
  
2 3 4 5 6 7
-10
-5
0
5
10
G
ai
n
 
(dB
i)
Frequency (GHz)
 h2=3 mm
 h2=4 mm
 h2=5 mm
 
(b) 
Fig. 7: Variation of (a) return loss and (b) gain for 
different values of d of strip antenna 
2 3 4 5 6 7
-40
-30
-20
-10
0
S 1
1 
(dB
)
Frequency (GHz)
 t=4 mm
 t=6 mm
 t=8 mm
 
(a) 
2 3 4 5 6 7
-10
-5
0
5
10
G
ai
n
 
(dB
i)
Frequency (GHz)
 t=4 mm
 t=6 mm
 t=8 mm
 
(b) 
Fig. 8: Variation of (a) return loss and (b) gain for 
different values of t of strip antenna 
 
 3.  SIMULATION RESULTS 
 
The proposed antenna is constructed and 
numerically analyzed using MoM’s. The numerical 
results of the antenna are shown below. The 
proposed antenna have the return loss appreciable 
than the commonly required 10 dB level. Fig. 9 
represents the voltage standing wave ratio (VSWR) 
variation and Fig. 10 represents the return loss 
variation of strip antenna with frequency. The strip 
antenna provides a large impedance bandwidth of 
300 MHz (2350-2650 MHz) and 130 MHz (5490-
5620 MHz) which fully covers the 2.4, 2.5 GHz 
and partially covers the 2.3 and 5.5 GHz bands. The 
values of the VSWR of the antenna vary between 
1.20~1.80 and 1.06~1.83 at the lower and upper 
frequency bands respectively (shown in Fig. 9) and 
the peak values of the return loss are -20.85 and -
30.71 dB at lower and upper frequency band 
respectively (as in Fig.10).  Fig. 11 shows the peak 
gains of the proposed antenna. The peak gains of 
the antenna are 8.25, 8.43, 8.46 and 6.43 dBi at 2.3, 
2.4, 2.5 and 5.5 GHz band respectively, with less 
than 0.2, 0.1, 0.3 and 1.5 dBi gain variations within 
the 10 dB return loss bandwidth. Fig.12 represents 
the impedance variation of frequency.  From the 
simulated data, the proposed antenna is near about 
50 Ω at operating frequency bands so extra 
impedance matching network is not essential for the 
operation of the antenna. Fig. 13 represents the 
antenna phase shift causes due to the impedance 
mismatch as a function of frequency. Also, from 
the simulation study, the antenna offers a phase 
shift of -14.4840, -18.7430, -7.0660 and -25.2770 at 
2.3, 2.4, 2.5 and 5.5 GHz band respectively. So 
phase shift of strip antenna closer to 00 all over the 
antenna bandwidth. Fig. 14 and 15 show the 
normalized radiation patterns of strip antenna at 2.4 
and 5.5 GHz bands respectively. Normalized 
radiation patterns for two resonant frequencies are 
shown as: total gain in H-plane (YZ/XZ plane) and 
E-plane (XY plane). The antenna’s normalized total 
radiation in H and E-plane is almost 
omnidirectional at the 2.3/2.5/5.5 GHz WiMAX 
and 2.4 GHz WLAN operating frequency band. 
2 3 4 5 6 7
0
5
10
15
20
25
30
35
40
V
SW
R
Frequency (GHz)
 
Fig. 9: VSWR variation of strip antenna with 
frequency 
Page 1071
  
2 3 4 5 6 7
-40
-30
-20
-10
0
S 1
1 
(dB
)
Frequency (GHz)
 
Fig. 10: Return loss variation of strip antenna with 
frequency 
 
2 3 4 5 6 7
-10
-5
0
5
10
G
ai
n
 
(dB
i)
Frequency (GHz)
 
Fig. 11: Gain variation of strip antenna with 
frequency 
 
Printed monopole antenna (Pan et. al., 2007), flat-
plate Inverted-F  antenna (Pazin et. al., 2008),  T-
shaped monopole antenna with shorted L-shaped 
strip-sleeves (Wu et. al., 2005),  internal PIFA’s  
(Su and Wong, 2006), CPW-fed triangle-shaped 
monopole antenna (Song, et. al., 2007),  
capacitively fed hybrid monopole/slot chip antenna 
(Lai and Wong, 2008), printed quasi-self-
complementary antenna (Wong, et. al., 2003), 
compact monopole antenna (Jung, et. al., 2009),  
printed antenna (Sun et. al., 2009), low-profile 
printed T-shaped monopole antenna (Su et. al., 
2004),  compact PIFA antenna ( Shin and Park, 
2007),  suffer from the gain limitations for required 
applications. But the gain of the proposed antenna 
is much better with stable gain variation within the 
antenna bandwidth than the antennas proposed 
earlier. In overall considerations, the performance 
of the proposed strip antenna is much better than all 
other antennas.  
 
2 3 4 5 6 7
0
500
1000
1500
2000
Im
pe
da
n
ce
 
(O
hm
)
Frequency (GHz)
 
Fig 12: Impedance variation of strip antenna with 
frequency 
 
2 3 4 5 6 7
-90
-60
-30
0
30
60
90
Ph
as
e 
(de
gr
ee
)
Frequency (GHz)
 
Fig 13: Phase shift variation of strip antenna with 
frequency 
 
-30
-20
-10
0
10
0
30
6090120
150
180
210
240 270 300
330
-20
-10
0
10
 
 
-30
-20
-10
0
10
0 30
60
90
120
150180210
240
270
300
330
-20
-10
0
10
 
 
       (a)          (b) 
-30
-20
-10
0
10
0 30
60
90
120
150180210
240
270
300
330
-20
-10
0
10
 
 
-40
-20
0
0
30
6090120
150
180
210
240 270 300
330
-40
-20
0
 
 
       (c)       (d) 
Fig. 14: Normalized radiation pattern (a) total gain 
in E-plane (b) total gain in H-plane, (c) vertical 
gain in H-plane and (d) horizontal gain in E-plane 
of strip antenna at 2.4 GHz 
Page 1072
  
-30
-20
-10
0
10
0
30
6090120
150
180
210
240 270 300
330
-20
-10
0
10
 
 
-30
-20
-10
0
10
0 30
60
90
120
150180210
240
270
300
330
-20
-10
0
10
 
 
        (a)       (b) 
-30
-20
-10
0
10
0 30
60
90
120
150180210
240
270
300
330
-20
-10
0
10
 
 
-40
-20
0
0
30
6090120
150
180
210
240 270 300
330
-40
-20
0
 
 
       (c)     (d) 
Fig. 15: Normalized radiation pattern (a) total gain 
in E-plane (b) total gain in H-plane, (c) vertical 
gain in H-plane and (d) horizontal gain in E-plane 
of strip antenna at 5.5 GHz 
 
4. CONCLUSIONS 
 
A multiband strip antenna has been proposed and 
investigated by means of numerical simulations 
using method of moments in NEC. The antenna 
occupies a very small area of 39×30 mm2 with 
bandwidths of 300 MHz (2350-2650 MHz) and 130 
MHz (5490-5620 MHz) at lower and upper 
frequency band respectively. Moreover the gain of 
the antenna is very high and the gain variation of 
the antenna is very low at the operating bands. The 
simulated pattern, return loss and radiation 
characteristics indicates the suitability of the 
antenna for 2.3/2.5/5.5 GHz WiMAX and 2.4 GHz 
WLAN operations. As the antenna occupies small 
area, so it is promising to be embedded within the 
different portable devices employing WiMAX and 
WLAN applications.   
 
 
REFERENCES 
 
1. Pan, C. -Y., Horng, T. -S., Chen, W. -S.  and 
Huang, C. -H., (2007),  “Dual Wideband 
Printed Monopole Antenna for 
WLAN/WiMAX Applications”, IEEE 
Antennas and Wireless Propagation Letters, 6, 
pp. 149-151 
2. Pazin, L., Telzhensky, N. and  Leviatan, Y., 
(2008), “Multiband Flat-Plate Inverted-F 
Antenna for Wi-Fi/WiMAX Operation”, IEEE 
Antennas and Wireless Propagation Letters, 7, 
pp. 197-200 
3. Wu, J. -W., Wang, Y. -D., Hsiao, H. -M.  and 
Lu, J. -H., (2005), “T-Shaped Monopole 
Antenna with Shorted L-Shaped Strip-Sleeves 
for WLAN 2.4/5.8-GHz Operation”,  
Microwave and Optical Technology Letters,  
46(1), pp. 65-69 
4. Su, W. -C.  and Wong, K. -L., (2006),  
“Internal PIFA’s for UMTS/WLAN/WiMAX 
Multi-Network Operation for a USB Dongle”,  
Microwave and Optical Technology Letters,  
48(11), pp. 2249-2253  
5. Song, Y.,  Jiao, Y. -C., Zhao, G. and Zhang 
F. -S., (2007), “Multiband CPW-Fed 
Triangle-Shaped Monopole Antenna for 
Wireless Applications”, Progress in 
Electromagnetics Research, PIER 70, pp. 
329–336 
6. Lai, P. -Y. and Wong, K. -L., (2008), 
“Capacitively Fed Hybrid Monopole/Slot 
Chip Antenna for 2.5/3.5/5.5 GHz WiMAX 
Operation in the Mobile Phone”, Microwave 
and Optical Technology Letters, 50(10), pp. 
2689-2694 
7. Wong, K. -L., Wu, T. -Y., Su, S. -W. and 
Lai, J. -W., (2003), “Broadband Printed 
Quasi-Self-Complementary Antenna for 
5.2/5.8 GHz WLAN Operation”,  Microwave 
and Optical Technology Letters,  39(6), pp. 
495-496 
8. Jung, J., Lee, H. and Lim, Y., (2009), 
“Compact Monopole Antenna for Dual ISM-
Bands (2.4 and 5.8 GHz) Operation”, 
Microwave and Optical Technology Letters, 
51(9), pp. 2227-2229 
9. Sun, S. -Y., Huang, S. -Y. and Sun, J. -S., 
(2009), “A Printed Multiband Antenna for 
Cellphone Applications”, Microwave and 
Optical Technology Letters, 51(3), pp. 742-
744 
10. Su, S. -W., Wong, K. -L. and Chen, H. -T., 
(2004), “Broadband Low-Profile Printed T-
Shaped Monopole Antenna for 5-GHz 
WLAN Operation”,  Microwave and Optical 
Technology Letters, 42(3), pp. 243-245 
11. Shin, Y.-S. and Park, S.-O., (2007),  “A 
novel compact PIFA for Wireless 
Communication applications”,  IEEE Region 
10 Conference 2007, pp. 1-3 
12. Burke, G. J. and Poggio, A. J., (1981), 
“Numerical Electromagnetic Code-2”, Ver. 
5.7.5, Arie Voors.  
13. Huynh, M. –C. T., (2000), “A Numerical and 
Experimental Investigation of Planar 
Inverted-F Antennas for Wireless 
Communication Applications”, M.Sc. 
Thesis, Virginia Polytechnic Institute and 
State University. 
14. Hirisawa, K. and Haneishi, M., (1992), 
“Analysis, Design, and Measurement of 
small and Low-Profile Antennas”, Artech 
House, Boston. 
Page 1073
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: MMG Rashed  
E-mail: mgrashed@daffodilvarsity.edu.bd 
    PERFORMANCE ANALYSIS OF WIFI NETWORK  
FOR INDOOR ENVIRONMENT 
 
Mohammad Mirza Golam Rashed*, Md.Taslim Arefin and Samia Alam Mishu 
Daffodil International University, Dhaka 
 
Mr. Nizar Rahman 
Bangladesh Enterprise Ltd, Dhaka 
 
 
 
 
This paper gives a picture of the performance of a WiFi network in Indoor Environment. To observe the 
performance, a WiFi network of 802.11b standard is established in an office. The performance analysis is 
conducted  in terms of two parameters: Throughput and RSSI (Received Signal Strength Indicator) . The 
analysis shows that for a coverage area of 20 meter radius the signal strength remains around 60%-70% and 
a power level is -25dB to -85 dB.Analysis also shows the pattern of change of the signal strength with in 
range of 8 feet to 35feet. A Maximum throughput of 7.9Mbps is observed where as the Upload data rate is 
4.9Mbps and Download data rate is 143.2 kbps. 
   
   Keywords: Wireless Fidelity, RSSI, Throughput, Transfer Rate, SSID 
 
  1. INTRODUCTION 
The term "Wi-Fi." is the short form of "wireless 
fidelity." All the modern devices increasingly come 
ready to work with Wi-Fi. (One example: By 2007, 
according to IDC Research of Framingham, Mass., 
98% of all new notebok PCs will be sold with Wi-
Fi capability) [1]. Wi-Fi refers to products certified 
to work with the high-tech industry's global 
standard for high-speed wireless networking.A 
person with a Wi-Fi enabled device such as a PC, 
cell phone or PDA can connect to the Internet when 
in proximity of an access point [2]. The region 
covered by one or several access points is called a 
hotspot. Hotspots can range from a single room to 
many square miles of overlapping hotspots. A huge 
number of the people of the world are now enjoying 
the service of the hotspots. But the problem is they 
are not actually happy with the speed they are 
getting. Actually it is not always possible to achieve 
the data speed guaranteed by the IEEE standards 
802.11. In reality the speed is really different in 
most of the cases. In this paper we have tried to 
investigate the performance of a WiFi network in 
an official environment through the process of site  
Survey. The survey is conducted with the help of 
two software WirelessMon and DuMeter. 
2. PLAN FOR THE NETWORK 
An experimental network is designed using a 
variety of antennas, antenna cables and connectors, 
a laptop computer (or PDA) with a wireless PC 
card, Wireless client pc, some site survey utility 
software such as ‘‘Wireless Mon” and “Du meter”. 
Two personal computers of having following 
configuration are considered: 
PC No: 1  
Configuration: 
System requirements: Windows XP 
IP address: 192.168.2.115 
AP configuration: Bel_WiFi 
Adapter: Shiro WA54-U 
Software: Wirelessmon and DU meter 
PC No: 2 
Configuration: 
System requirements: Windows XP 
IP address: 192.168.2.139 
AP configuration: Bel_WiFi 
Adapter: Belkin N Wireless Adapter 
Software: Wirelessmon and DU meter 
 
Page 1074ISBN: 978-984-33-2140-4
 *
 Corresponding Author: MMG Rashed  
3. PARAMETERS USED FOR 
PERFORMANCE MEASURENT 
3.1. RSSI reading (Radio Signal Strength 
Indicator) 
The received signal strength indicator (RSSI) is an 
optional 802.11 parameter with a value from 0 to 
255. It is designed to be used by the hardware 
manufacturer as a relative measurement of the RF 
power that is received[3]. The RSSI is one of the 
indicators that are used by a wireless device to 
determine if another device is transmitting. Here we 
have used a simulation Software “WirelessMon” to 
get RSSI reading from AP to wireless adapter.  
 
3.2 Throughput reading 
The throughput is a measure of how efficiently a 
data communication takes place through a network. 
In this experiment we have used software called 
“DU METER” for the measurement of throughput. 
 
4. EXPERIMENTAL RESULTS 
In simulation part there are two steps which are as 
follows: 
 Sending Data 
 Receiving Data 
4.1 RSSI reading while Sending Data 
From figure we may see that the signal strength 
while transferring data through the access point.The 
signal strength and RSSIdependas upon the 
coverage and the distace area from the Access 
point.While sending data through the network using 
the CISCO Router as the accessp point to a base 
station set or a Wifi network client pc.For this step 
we took the wireless client pc having the 
configuration of pc no 1 and got the following 
informations from the given figures: 
 
Fig 1.Signal Strength(In dB) Vs Time  curve 
From the figure[ Fig 1.] we may observe  that the 
signal strength lies between 60%-80%  and the 
figure [Fig. 2] gives us a report on RSSI reading. 
 
 
Fig 2. RSSI report for sending  data 
From figure [ Fig. 2] it is observed that the  the 
signal strength is -75 dB and it is 65%  for  the 
distance of 20 feet between the client and access 
point.The distance between the two PCs is 25 feet. 
4.2 RSSI Reading while receiving Data 
In this experiment we have used the 2nd pc as the 
receiver and the measured the performance of the 
signal received by this pc. 
 
Fig 3.Signal Strength(%) Vs Time  curve. 
From figure [Fig. 4] it is observed that the stregth 
of the signal lies between 60% to 0%.Figure[Fig.5] 
provides a report on the RSSI level of the received 
data. 
Page 1075
 *
 Corresponding Author: MMG Rashed  
 
Fig 4. RSSI report for receiving  data 
The above figure [Fig. 5] shows the RSSI level of 
the received data is  -77 db  and in terms of 
percentage it is 65%. 
4.3 ThroughPut reading while sending data  
To take throughput reading a WiFi network named 
Bel_WiFi, with operating Frequency 2.4 GHz is 
selected and this network is designed using CISCO 
AP with wireless pc client with wireless adapter of 
Shiro WA54-U. Throughput reading is taken using 
FTP protocol. While sending data through the 
access point in 802.11b Mode we observed a 
Maximum throughput of 7.9Mbps [Fig. 5] at that 
time Upload data rate was 4.9Mbps and Download 
data rate was 143.2 kbps. 
 
Fig. 5: Throughput performance for sending data 
 
 
 
 
From the above figure we get the following data 
while transferring data through the network:  
Transfer Rate Incoming Outgoing 
Maximum 
Transfer rate 
198.0 Kbps 7.9 Mbps 
Average 
Transfer rate 
115.5 Kbps 3.8 Mbps 
Current 
Transfer rate 
160.8 Kbps 4.9 Mbps 
                                                      
From the above figure we may see that during 
receiving data through a specific WiFi network 
namedBel_WiFi the signal strenth is between 60%-
70%.          
4.4 Throughput Reading while receiving 
data  
To take throughput reading of the received data 
same WiFi network named Bel_WiFi, with 
operating Frequency 2.4 GHz is used. In this 
experiment we used the wireless pc client having 
wireless adapter of Belkin N Wireless Adapter. 
The throughput performance is evaluated named 
“DU Meter” .While receiving data through the 
access point’s Band in 802.11b Mode named 
Bel_WiFi we got a Maximum throughput of 
9.7Mbps [Fig. 6] at that time Upload data rate was 
160.8Mbps and Download data rate was 4.2 Mbps. 
          
 
Fig. 6: Throughput performance for receiving data. 
 
 
 
 
 
 
 
Page 1076
*
 Corresponding Author: MMG Rashed  
From the above figure we may see that the transfer 
rate during receiving data through a particular net 
work which SSID is Bel_WiFi and the transfer rate 
during the elapsed time is as follows: 
 
 
4.5 Overall Performance of the Network
The following table [ Table: 1] provides the data of  
RSSI , Signal strength and throughput for all the 
clients of the netowork and the fiigure[
shows the overall performacne of the network in 
terms of distance and signal strength. 
 
Table 1: Data Sheet of performacne of the newtork
 
           
Fig.7: Performance of the nework in terms distance 
and signal strength. 
 
 
Transfer 
Rate 
Incoming 
Maximum 
Transfer rate 
8.0 Mbps 
Average 
Transfer rate 
3.9 Mbps 
Current 
Transfer rate 
5.5 Mbps 
PC(IP 
Address) 
 
Distance 
From 
AP 
     
RSSI 
Signal 
Strength 
192.168.2.130 08ft 
 -   25 
db 92%
192.168.2.137 15ft 
  -  
60db 72%
192.168.2.115 20 ft 
   -  
77db 65%
192.168.2.135 35ft  
  -   
82 
db 43%
 
 Fig. 7] 
 
 
5. CONCLUSIONS 
A complete site survey for of a WiFi network is 
executed for indoor environment in this 
performance analysis for the data sending shows 
that signal strength lies between 60%
maximum  throughput is 7.9 Mbps.For data 
reciving signal strength lies between 60%
the maximum  throughput is 9.7 Mbps.
found that the strength of the signal gradually 
decreases with the distance which is not perfectly 
linear. All the peroformance found in the 
experiment doesn’t match with the performacne 
claimed by the IEEE standard which may be caused 
various reasons and this a scope for 
invesitgaion. 
 
 
REFERENCES 
1. Technofile: Why Wi-Fi? By Anne Stuart
2003 2. Wi-Fi Technology by Ranjith | October 
11th, 2009. 
3. Bandwidth Efficiency of Wireless Networks of 
WPAN, WLAN, WMAN and WWAN by  Ing. 
Milan Šimek, Ing. Ivan Míča, Ing. Jan Kacálek, 
Ing. Radim BurgetDepartment of 
Telecommunications, Brno University of 
Technology,Czech Republic 
4. Notebook And Wifi Standards
Sedycias. Chapter 1 
 
5. IEEE 802.11g New Draft Standard Clarifies 
Future of Wireless LAN By William Carney, 
Marketing Manager,  Wireless Networking 
Business Unit, Texas Instruments 
 
 
 
 
 
Outgoing 
573.8 Kbps 
140.6 Kbps 
158.6 Kbps 
 
      
Throughput 
 9.7 Mbps 
 8.7 Mbps 
 7.9 Mbps 
 4.5 Mbps 
 
work. The 
-80%  and the 
-70%  and 
It is also 
future 
 | Sep 1, 
 by Roberto 
Page 1077
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
 
* Corresponding Author: S. R. Sabuj,  
E-mail: saifuriict@gmail.com 
 
PERFORMANCE OF MIMO-OFDM OVER FLAT FADING 
CHANNEL USING CONVOLUTION CODING 
 
 
S. R. Sabuj* and M. S. Islam 
Institute of Information and Communication Technology 
Bangladesh University of Engineering and Technology, Bangladesh 
 
 
Orthogonal frequency division multiplexing (OFDM) is a popular method for high data rate as well as high 
spectral efficiency. In multiple input multiple output (MIMO) system, deploying multiple antennas at both 
the transmitter and receiver achieve higher data rate without increasing transmission power or bandwidth. As 
a promising technology for future wireless communication, MIMO-OFDM has gained more and more 
wellbeing in recent years. In this paper, we have derived an analytical bit error rate (BER) expression in 
MIMO-OFDM system and the performance of convolution encoding and viterbi decoding are investigated 
through simulation. It is found that the theoretical and simulation result of convolution coding signal in 
terms of BER are better than without coding signal. The BER performance for convolution coding has been 
reduced about 3dB at BER of 10-2 than without coding system. 
 
Keywords: Orthogonal frequency division multiplexing, single input single output, convolution coding, 
viterbi decoding, multiple input multiple output, bit error rate. 
 
1. INTRODUCTION 
  
In a conventional wireless communication system, 
there is only one antenna at both transmitter and 
receiver which is called the single input single 
output (SISO) antenna. Future wireless services 
demand much higher data rate transmission. In 
order to increase the capacity of the SISO systems 
to meet such demand, the bandwidth and 
transmission power have to be increased 
significantly. Fortunately, recent developments 
have shown that using multiple input multiple 
output (MIMO) systems increase the capacity in 
wireless communication substantially without 
increasing the transmission power and bandwidth 
[1, 2]. The MIMO systems offer very higher data 
rates in the same bandwidth as compared to the 
SISO systems. In the MIMO systems, multiple 
antenna elements are required at both transmitter 
and receiver. 
 
OFDM is a multicarrier modulation technique 
which a single high rate data stream is divided into 
multiple low rate data streams and is modulated 
using subcarriers which are orthogonal to each 
other [3]. On each subcarrier channel, lower data 
rate brings longer symbol duration. The main 
advantage of the OFDM system is its ability to 
convert a frequency selective fading channel into 
several flat fading channels. In frequency selective 
fading channels, wideband signals suffer inter 
symbol interference (ISI), but ISI is eliminated in 
OFDM because of its flat fading channel. At 
present OFDM is mainly used in digital audio 
broadcasting (DAB), digital video broadcasting 
(DVB), Wireless LAN and MAN such as 
IEEE802.11a, IEEE802.11g and IEEE802.16a, 
HIPERLAN/2 and other high speed data 
application for both wireless and wired 
communications. 
 
To achieve satisfactory performance, coding is 
needed for wireless communication. Coding is a 
technique where redundancy is added to original bit 
sequence to increase the reliability of the 
communication [4]. Convolution code is one of the 
most widely used channel coding in practical 
communication systems. Convolution codes 
convert the entire data stream into one single 
codeword. It is a type of forward error correction 
(FEC) which its function is to improve the capacity 
of a channel by adding redundant information to the 
data being transmitted through the channel. Viterbi 
decoding is one of decoding algorithms used with 
convolution encoding. The other type is sequential 
decoding.  Sequential  decoding  has  the advantage  
Page 1078ISBN: 978-984-33-2140-4
  
 
 
 
Fig. 1: Block diagram of MIMO-OFDM system model (a) Transmitter (b) Receiver 
 
that it can perform very well with long constraint 
length convolution codes, but it has a variable 
decoding time. Viterbi decoding has the advantage 
that it has a fixed decoding time. It is well suited to 
hardware decoder implementation. But its 
computational requirements grow exponentially as 
a function of the constraint length. Viterbi decoding 
is essentially performs the maximum likelihood 
decoding. It reduces the computational load by 
taking advantage of special structure in code trellis 
[5]. 
 
In this paper, we have established analytical BER 
of MIMO-OFDM systems in presence of frequency 
offset and phase noise.  Convolution coding and 
without coding for QPSK scheme have been 
developed theoretically and simulated using 
MATLAB. We use convolution coding scheme at 
the transmitter and associated viterbi decoding 
scheme at the receiver. We evaluate the BER 
performance of our proposed scheme. 
 
2. SYSTEM MODEL IN MIMO-
OFDM 
 
The block diagram of a typical discrete time 
baseband equivalent model of 2x2 MIMO-OFDM 
systems is shown in Fig. 1. As shown, Convolution 
encoder is placed at the first stage and then serial 
input bit encoded by using suitable modulation 
technique like (BPSK, QPSK or M-QAM). The N 
symbols are transferred by the serial to parallel 
converter (S/P), in this stage duration of input bits 
is increased. After S/P converter, the same data 
symbols will be transmitted on the first and second 
antenna. Both antennas, the modulated symbols are 
serialized using a parallel-to-serial converter (P/S), 
then converted to analog via the digital to analog 
converter (DAC) and passing high power amplifier 
before being send to the channel. At the receiver 
side, the received symbols are passed low noise 
amplifier and converted from analog to digital 
using the analog to digital converter (ADC) and 
transferred by the S/P both antenna. The original 
signal can be recovered from the simple relation of 
21
kkk YYY  . Here, 
1
kY  and 
2
kY are the first 
antenna and second antenna kth subcarrier data. 
Then viterbi decoded in order to recover the 
transmitted data. 
 
3. THEORETICAL ANALYSIS OF 
BER IN MIMO-OFDM  
 
The complex baseband MIMO-OFDM signal after 
IFFT at the transmitter [6]: 




1
0
)
2
(
)(
N
k
kn
N
jt
keXn
t
x

           for 0 ≤ n ≤ N-1                                                                                      
                                                     t = 1 or 2           (1)            
Where, j = 1  , N is the total number of 
subcarriers, t means transmitter antenna number, 
t
kX  is data symbol for kth subcarrier. 
 
Page 1079
  
Received signal is affected by phase noise and 
frequency offset. So, it can be expressed as, 
)](2[
2
1
)]}()()([{)( ntfjt
t
t enwnhnxnr
  

 
                                         τ = 1 or 2                                                                                                            
                                                                              (2) 
  
Where, Δfτ and φτ(n) are frequency offset and phase 
noise. τ means received antenna number. x(n), h(n), 
w(n), r(n) are transmitted signal, channel impulse 
response, complex Gaussian noise and received 
signal respectively. 
   
Furthermore, the received signal after FFT can be 
expressed as, 
kn
N
jN
n
enr
Nk
Y
]2[1
0
)(1

 

  
k
N
l
nnkl
N
jt
l
t
l
t
N
n
NeHX
N
 






1
0
)]())(2[(2
1
1
0
1  
 
k
N
l
kl
t
l
t
l
t
NQHX  




1
0
2
1
                               (3)         
     
Where, Yk, Xl and Hl are the frequency domain 
expression of r(n), x(n), h(n) . Nk is the complex 
AWGN. Here, ε is the normalized frequency offset 
and is given by ΔfτT. Δf is the frequency difference 
between the transmitted and received carrier 
frequencies and T is the subcarrier symbol period. 
 

LQ  is defined as follows: 





1
0
)]())(2[(1 N
n
nnL
N
j
L eN
Q
 

                        (4) 
 
Using phase noise linear approximation method, 
suppose φ[n] is so small that e jφ[n] can be 
approximated into 1+ jφ [n]. So, LQ can be defined 
as follows: 
))(1(1
1
0
]))(2[(
nje
N
Q
N
n
nL
N
j
L


 

 



         (5) 
 
Frequency offset and phase noise is analyzed 
independently and channels have similar flat 
frequency response in two paths such 
as 121  ll HH . In this paper, all received signal 

kY  equation after FFT. Transmitted signal is 
supposed to have zero mean and statistically 
independence.  
 
In the MIMO-OFDM, both antennas transmit the 
same signal as the form of kll XXX 
21 the 
kth subcarrier signal is expressed as, 
      kY = 


1
0
2
][1
N
n
kn
N
j
enr
N

   
            =  k
N
l
kl
t
l
t
l
t
NQHX 




1
0
2
1
            (6) 
 
The received signal at the receiver 1 (RX1) can be 
expressed as, 
k
N
l
klll
N
l
klllk NQHXQHXY 1
1
0
122
1
0
1111  






k
N
kll
klll
kk
N
kll
klllkk
NQHX
QHXQHXQHX
1
1
,0
122
1
0
2
1
,0
1111
0
1
..
......










 
k
N
kll
klllklll
kkk
NQHXQHX
QHQHX
1
1
,0
122111
1
0
21
0
1
}....{
}..{






         
k
N
kll
klllklll
kkkk
NQHXQHX
QHQHXX
1
1
,0
122111
1
0
21
0
1
}....{
}1..{






                                                                              (7) 
 
Similarly, the received signal at the receiver 2 
(RX2) can be expressed as, 
k
N
l
klll
N
l
klllk NQHXQHXY 2
1
0
222
1
0
2112  






k
N
kll
klllklll
kkkk
NQHXQHX
QHQHXX
2
1
,0
222211
2
0
22
0
1
}....{
}1..{






                                                                             (8)                                                     
Final signal are achieved as follows, 
           21 kkk YYY   
}2).().({2 20
1
0
22
0
1
0
1  QQHQQHXX kkkk
       }....{
1
,0
211111


 
N
kll
klllklll QHXQHX  
     


 
1
,0
222122 }....{
N
kll
kklllklll NQHXQHX  
Page 1080
  
}1){(22 20
1
0  QQXX kk
k
N
kll
klllklll NQXXQXX  


 }).().{(
1
,0
221121
                                                                             (9)           
              
In order to evaluate the statistical properties [7], 
assuming average channel gain 
          1
2221 






ll HEHE and     
        
22221 XXEXE ll 





               (10) 
][E  denotes the expectation value. 
 
The desired received signal power can be 
represented by 
21
0
2122 ].[].[ QHEXE kkDRS     
              
21
0
222 ].[].[ QHEXE kk  
              
22
0
212 ].[].[ QHEXE kk  
              
22
0
222 ].[].[ QHEXE kk  
            }..{2
22
0
221
0
2 QXQX   
            }{2
22
0
21
0
2 QQX                        (11) 
 
Hence, the ICI power is 




22
ICIICI IE  
        



1
,0
212121 ].[].[
N
kll
klll QHEXE  
         



1
,0
212222 ].[].[
N
kll
klll QHEXE      
         



1
,0
222121 ].[].[
N
kll
klll QHEXE  
        



1
,0
222222 ].[].[
N
kll
klll QHEXE  
         



1
1
222212 ..2
N
l
ll QXQX  
         



1
1
22212 }.{2
N
l
ll QQX                   (12) 
 
Bit error rate (BER) of a communication system is 
defined as the ratio of number of error bits and total 
number of bits transmitted during a specific period. 
BER of QPSK modulated MIMO-OFDM system is 
given, 
  2
2
2
1
ICI
DRS
N
QBER



  
      





 1
1
22212
22212
}.{2
}.{.2
2
1
N
l
ll
ll
QQXN
QQX
Q  
 
      






1
1
2221
2
2221
2
}.{21
}.{.2
2
1
N
l
ll
ll
QQ
N
X
QQ
N
X
Q  
 
      





 1
1
2221
2221
}.{21
}.{.2
2
1
N
l
ll
b
ll
b
QQ
N
E
QQ
N
E
Q                
                                                                            (13) 
 
BER of QPSK modulated in MIMO-OFDM system 
with convolution coding is given  
    
t
S
NC
EQBER
2
1
                                      (14) 
 
Where, Ct = coding rate. BER of QPSK modulated 
for ½ convolution coding rate in MIMO-OFDM 
system is given 
    2
22
2
1
ICI
DRS
N
QBER



  
             





 1
1
2221
2221
}.{21
}.{.4
2
1
N
l
ll
b
ll
b
QQ
N
E
QQ
N
E
Q       
                                                                            (15) 
 
4. RESULT AND DISCUSSION 
 
In order to compare the MIMO-OFDM without and 
with convolution coding. In theoretically, the 
system has examined 64 subcarriers, QPSK 
modulation, normalized frequency offset with ε = 
0.1, phase noise variance with 2
 = 0.02 rad
2. In 
the simulation, same subcarrier, alike modulation, 
IFFT and FFT size 128 and ½ convolution coding. 
 
Page 1081
  
Fig. 2 shows the theoretical graph of BER vs Eb/N 
for  QPSK  modulation  in  MIMO-OFDM  scheme. 
From the BER curves, convolution coding signal 
illustrates better performance than without coding 
signal. At the Eb/N of 10 dB, BER of without 
convolution coding is very high giving a value of 
210738.1   while that of convolution coding 
channel is 310566.2  in MIMO-OFDM. This 
shows a very significant improvement coding has 
on the channel performance. 
 
 
Fig 2:    Theoretical plots of bit error rate vs. Eb/N 
 
 
Fig 3:    Simulation plots of bit error rate vs. Eb/N 
 
From the Fig. 3, it can be concluded that simulation 
results of BER. For QPSK modulation, the values 
of BER for convolution coding and without coding 
in MIMO-OFDM are approximately 110591.3   
and 110188.5   respectively at same Eb/N. We 
also found that coding leads to a substantial 
improvement in terms of BER. This also agreed 
with theoretical calculations. 
 
5. CONCLUSION 
 
In this paper, the BER performances are obtained 
from the theoretical and simulation of the 
convolution coding in flat fading channel. Coding 
is essential for improving the bit error rate in the 
presence of noise and interference. A rate ½ 
convolution encoder and its corresponding viterbi 
decoder on the receiver were used to improve BER. 
It is shown that the improvement of BER using the 
convolution coding provides a better performance 
than without coding signal.  
 
REFERENCES  
 
1. Foschini, C. E., (1996), “Layered space-time 
architecture for wireless communication in a 
fading environment when using multi-element 
antennas,” Bell Labs Tech Jour., 1(2), pp. 41-
59. 
2. Foschini, G.J., and Gans, M. J., (1998), “On 
limits of wireless communications in a fading 
environment when using multiple antennas,” 
Journal of wireless personal communications, 
6(3), pp. 311-335. 
3. Cimini, L. J. and Jr., (1985) “Analysis and 
simulation of a digital mobile channel using 
orthogonal frequency division multiplexing” 
IEEE Trans. on Communications. 33, pp. 665-
675. 
4. Kumar, P., Kanaujia, B. K. and 
Gangadharappa, M., (2010) “BER Performance 
Analysis of Rake Receiver in Rayleigh Fading 
Channel for UMTS environment,” 
International Journal of Engineering Science 
and Technology, 2(6), pp. 1690-1698. 
5. Kumar, R., Kumar, V., singh, M., Kumari S. 
and Sirohi, K., (2010) “Comparison of CDMA 
and OFDM Using Simulink,” International 
Journal of Wireless Communication and 
Simulation, 2(1), pp. 39-50. 
6. Li, Y.-S., Ryu, H.-G., Li, J.-W., Sun, D.-Y., 
Liu, H.-Y., Zhou, L.-J. and Wu, Y., (2008) 
“ICI compensation in MISO-OFDM system 
affected by frequency offset and phase noise,”  
Wireless Commun., Networking and Mobile 
Computing ( WiCOM '08), 5(12), pp. 32-38. 
7. Dwivedi, V. K. and Singh, G., (2008) “An 
Efficient BER Analysis of OFDM Systems 
with ICI Conjugate Cancellation Method” 
PIERS Proceedings, pp. 166-171, Cambridge, 
USA. 
Page 1082
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Atikur Rahman Baizid,  
E-mail: sustatik2@gmail.com   
The infrastructural advancement of e-learning in Bangladesh: A case 
study of present status and future expectations 
 
Atikur Rahman Baizid* and Ahsan Habib 
*
 Leading University, Sylhet, Bangladesh 
Metropolitan University, Sylhet, Bangladesh 
 
Due to globalization, the world is becoming a global village, distances are reduced, and the world is going to 
make a knowledge based society. At this stage, as a developing country, Bangladesh is going to start e-
learning that is the distance learning based on electronic media. To establish this, Bangladesh needs to 
develop the infrastructural part of e-learning. The main theme of this paper is to study the present status of 
infrastructural development, gap of the development, and how to establish a framework for e-learning in 
Bangladesh. 
 
Key words: E-learning, distance learning, Digital Bangladesh, e-learning framework, E-governance, ICT.  
 
1. INTRODUCTION 
 
Education is said to be one of the most important 
factors for poverty alleviation and economic growth 
in developing countries. The rapid change of the 
information and knowledge society does not stop at 
education [1]. Many western countries, Japan, 
Israel, Australia, and Malaysia are established 
distance or e-learning successfully [2]. The interest 
is using information and communication 
technologies (ICTs) for dissemination of education 
is growing and is believed to have a huge potential 
for government. E-learning has a very distinct role 
to play in the context of scarcity of resources in 
developing countries. The most significant 
limitation of educational framework in these 
countries is the dearth of educational institution and 
qualified trainers for higher studies. There exist 
only few institutions facilitating continuing 
education for the professional. But the need of such 
facilities for professional development of the 
technologies is well recognized. Its demand is 
further enhanced by rapid evaluation of technology 
and role of the technologists in economic 
development of the country. Despite having the 
potential to contribute in the educational 
advancement of developing countries, e-learning 
need to be designed carefully to overcome the 
technological and infrastructural limitations [3]. 
 
1.1 E-Learning 
E-learning is the way of facilitating education to 
students who are unable to attend a traditional 
campus of university or institution [4]. E-learning 
includes both purely internet web-based training 
and hybrid or blended learning that combines web 
based and traditional approaches is growing faster 
than any other sector of post secondary and 
professional education. Students like accessibility 
of virtual classrooms. Employer love savings they 
can take to the bank [5]. Internet based education is 
a form of distance education is a form of distance 
education in which the course contents are 
delivered and the interaction are provided by the 
technologies and methodologies of the Internet. It 
may occur in places where there is none, extends 
resources where there are few, expends the learning 
day and opens the learning place. It is possible to 
connect people, communities and resources to 
support learning [5]. 
 
1.2 Scope of E-Learning 
The scope of e-learning is more comprehensive 
than the commonly accepted issue of electronic 
delivery instructional and learning materials. E-
learning will open the lifelong learning for the 
human being. To read a book, to see a journal, to 
download video recorded lectures, to open the new 
horizon of learning by communicating with the 
foreign elites, and to know any sort of unknowns e-
learning will play the vital role in this context.  
 
To complete a course of higher studies, E-learning 
ensures rapid evaluation, collaboration of the users’ 
community, and enhanced security due to source 
code availability. It is less time dependent and not 
subject to the geographical locations [2].  
 
The web classroom makes the process of learning 
quicker and more efficient, solves the problems of 
finding study literature, old exams, exercises. 
Page 1083ISBN: 978-984-33-2140-4
  
Lecturers can post the course materials, exercises 
and exam dates quickly. 
 
2. E-LEARNING IN BANGLADESH 
 
There are some universities of Bangladesh where 
E-learning are implemented. These are Bangladesh 
University of Engineering and Technology 
(BUET), Dhaka University (DU), Rajshahi 
University (RU), Bangladesh Open University 
(BOU) etc. 
 
2.1 Bangladesh University of Engineering 
and Technology (BUET) 
In October 2004 BUET joined to the E-learning 
system of School on the Internet Asia Project (SOI 
Asia) and the Institute of Information and 
Communication Technology (IICT) was the focal 
point of SOI Asia. BUET has participated in the 
live lecture and shared various lecturer contents 
provided by SOI Asia such as Information 
Technology, Disaster Management and so on. 
BUET professors (2007) also contribute to this 
project by delivering course contents, especially in 
field of renewable energy [5]. 
 
2.2 Bangladesh Open University (BOU) 
After the establishment of the Bangladesh Open 
University (BOU) in 1992, the remarkable progress 
of E-learning has been done. BOU enrolls over 
250000 students all over Bangladesh. BOU is the 
only public university in Bangladesh that delivers 
education in open and distance mode. The course is 
delivered to the students via TV, radio and mobile 
phones with text books as self study materials. 
Students have the option to go to a learning centre 
every other Friday to get assistants from teachers 
and other students. These learning centers provide 
face to face lectures and some of them are equipped 
with TVs and mobile phones. There are about 1000 
learning centers in Bangladesh of BOU [6]. BOU 
has been offered various types of academic 
programs from certificate to masters levels using, 
print, TV, audio broadcasts, audio cassettes and 
face to face tutorials as the media of delivering its 
academic courses. Asian University of Bangladesh 
has also been offered some formal academic 
program through distance mode [7]. 
 
3. E-LEARNING FRAMEWORK  
 
3.1. Infrastructural framework of taking 
classes 
The students who can attend their class room will 
attend there and who cannot attend their traditional 
class room can take the lectures from the server 
(video recorded by the lecturers) or participate 
through television Channel (Though it is more 
expensive to broadcast). Students can also 
download the lectures by their mobile phone using 
mobile network described in the fig. 2. 
 
3.2. Infrastructural framework for taking 
examinations 
The examinations contain basically three parts 
through internet that is E-assessment [8]: (i) 
Assignments (ii) MCQ type tutorials (iii) Short 
question type tutorials. Final term should be set at 
the traditional examination hall at a fixed time. All 
the payments should be taken by mobile phone 
through short message system. The result should be 
published on the internet. Certificates should be 
sent to the e-mail addresses of the students with 
digital signature of the concerned authority. 
 
4. CHALLENGES 
 
Limited internet connectivity, insufficient computer 
and communication infrastructure are the major 
limitations of implementing e-learning in different 
universities and institutions. However the 
followings are the specific fields that are the main 
obstacles for establishing e-learning in Bangladesh. 
 
4.1 Lack of Finance  
The major problem of implementing e-learning is 
the lack of finance. Without strong financial 
support e-learning will remain a hope for the 
nation.  
 
4.2 Insufficient Infrastructure 
 The administrations of the universities do not feel 
any need to provide computer lab facilities, 
communication equipments, other information 
science components and necessary infrastructures 
required. E-learning requires a certain investment 
of hardware, software, and support staff. 
 
4.3 Lack of Knowledge 
One of the main limitations of e-learning is that 
students do not know how to use a particular 
information technology. We have also insufficient 
high teachers to implement e-learning in the 
universities. 
 
4.4 Lacking of supporting national policy 
The Government has not implemented any policy 
for improving e-learning in Bangladesh. 
 
4.5 Lacking of High Quality Teachers 
Most of the senior teachers of old age and they are 
not ready to any change in the nature of the subject. 
There exists skilled fresh teachers but they stand as 
juniors and work under pressure of seniors. 
Page 1084
  
Experienced senior teachers are not much involved 
in the distance education program for lacking of 
appropriate training [10].  
 
4.6 Language proficiency 
From different sources, it has been learnt that, 
English literacy rate in Bangladesh is less than one 
percent. Whereas, English literacy rates in India 
and Pakistan are 60% and 20% respectively. There 
is a strong correlation between English literacy and 
e-learning. Hence, English literacy is a must for e-
learning implementation. Unfortunately, in this case 
our position is the worst in the sub-continent [11]. 
 
 
Fig. 1: E-Learning Framework 
 
Fig. 2: Mobile based E-Learning [9] 
Television 
Channel 
Teacher  
Board  
Students  
Televisions  
Video 
recording 
Channel 
Internet 
Page 1085
  
5. RECOMMENDATIONS 
 
Latest statistics reveal that Bangladesh faces a 
power deficit of up to 2000 MW against a demand 
of 5000 MW daily. It may be noted that for proper 
ICT development an uninterrupted power supply is 
a must [11]. For establishing e-learning strong ICT 
infrastructure is a must. To build up strong ICT 
infrastructure the government should arrange the 
broadband internet facilities up to grass root levels 
using fiber optic cables; reduce the cost of PCs and 
accessories. University Grants commission (UGC), 
and different universities should arrange seminars, 
conference for making awareness of e-learning in 
Bangladesh. 
 
6. REFERENCES 
 
1. Stratagy and e-Protfolios in Education, iJET-
Volume 3, Issue 1, March 2008. 
2. Michael F. Beaudoin, Gila Kurtz, Experiences 
and Opinions of E-learners: What works, what 
are the challenges, and What Competencies 
Ensure successful Online Learning, 
Interdisciplinary Journal of E-learning and 
Learning Objects, Volume 5, 2009. 
3. Alam, M.J.B.L, Kabir, S.M.L and Elizabeth E-
learning in Bangladesh Implementation and 
Evaluation of a Pilot Project,Accessed 
at:http://www.codewitz.net/papers/MMT_77-
82_e-Learning_in_Bangladesh.pdf 
4. Shona Leitch and Mathew J. warren, Analyzing 
Online Teaching and Learning Systems Using 
MEAD, Interdisiplinary Journal of E-learning 
and Learning objects, Volume 4, 2008. 
5. M.S.Islam, J.B.Alam and S.M.L. Kabir, Satellite 
Based Internet Education Delivery and E-
learning Object Evaluation: SOI Asia and 
Codewitz Perspective, International Conference 
on Teaching and Learning(iCTL 2007),15-16 
November, Malaysia. 
6. Annika andersson. Letters From the Field:e-
Learning Students change of Learning 
behaviour in Sri Lanka and Bangladesh,  
Orebro, Sweden . 
7. Md. Saiful Islam, Dr. Salma Chowdhury, Md, 
Awarul Islam, LIS Education in E-learning 
Environment : Problems and Proposals for 
Bangladesh, Asia-Pacific Conference on Library 
and Information Education & Practice, 2009. 
8. M. Cubric, V.Tripathi, A Semantic Web 
Framework for Generating Collaborative E-
learning Environments, iJJET-Volume 4, Issue 
3, September 2009 doi:10.3991/ijet.v4i3.823 
9. Ahsan Habib, A. S. M. Latiful Hoque, towards 
mobile based e-learning in Bangladesh: A 
framework, Proceedings of ICCIT 2010 (to be 
published).  
10. Shalni Gulati, Technology–Enhanced Learning 
in Developing Nations: A review, International 
Review of Research in Open and Distance 
Learning, Volume 9, ISSN: 1492-3831. 
11. Ahsan Habib, Atikur Rahman Baizid, E-
governance Initiatives in Bangladesh , 
Proceedings of ICEGOV 2010, ACM 
Publication, USA. 
Page 1086
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
*
 Corresponding Author: S. Islam,  
E-mail: sharif_sust_cee@yahoo.com 
COMPARATIVE STUDY OF HAZARDS BY FLOODS AND 
CYCLONES IN BANGLADESH 
 
 
S. Islam*, M.M. Islam and M.A.H. Badsha   
Department of Civil Engineering, IUBAT— International University of Business Agriculture and 
Technology, Dhaka, Bangladesh 
 
M.J.B. Alam and M. A. Haque 
Department of Civil and Environmental Engineering, Shahjalal University of Science and 
Technology, Sylhet, Bangladesh 
 
 
Bangladesh is one of the most natural disaster prone countries in the World. Most of the disasters are water 
related such as flood, cyclone, drought, river erosion etc. Almost every year the country faces severe 
catastrophic natural hazards. This study is conducted in July 2010 to find and compare property and live 
losses in major floods and cyclone in Bangladesh. Here only major floods and strong devastated cyclone are 
considered which have precise records. The results of this study reveal that from 1987 to present, average 
yearly death loss is 283 persons and property loss is 377 million USD by major floods. But strong cyclone 
from 1970 to 2010, average yearly death loss is 19500 persons and property loss is 366 million USD. 
Cyclone causes huge scale yearly live loss compared to floods while average property are near about to same 
by these two natural disaster. 
 
Key words: Natural hazards; Floods; Cyclone 
 
1. INTRODUCTION 
 
The Earth is a dynamic system and experiencing a 
lot of natural changes within the system. The 
natural changes often cause great havoc to human 
being. When a natural phenomena cause destruction 
of human life and property, it termed as hazard. 
Various hazards are categorized according to the 
natural components or related to them such as 
water, wind etc. Common water related hazards are 
flood, drought, storm-surge and riverbank erosion. 
Every year, peoples of the different regions of the 
world are affected by natural hazards (Chowdhury, 
2006). Bangladesh is located between latitude 20° 
34' to 26° 38' N and longitude 88° 01' to 92°41' E 
which is a flood and cyclone affected country. 
These two events occasionally devastate a large 
amount of properties and lives.  
 
Unusual or above normal surface-water flow that 
inundates the high ground is called a flood.  About 
one half of the land area in Bangladesh is at an 
elevation of less than 8 meters above mean sea 
level. The height ranges from 60 m above mean sea 
level at the northern tip to less than 3 m at the 
southern coast. Bangladesh, a low-lying delta plain, 
is one of the world's most vulnerable regions to 
floods because of its geographical location. 
Bangladesh has been experiencing more 
devastating floods than ever before and the 
intensity of floods is increasing year to year (Khalil, 
1990, and Islam & Sado, 2000 & 2002). 
 
Floods are two types: ‘major’ and ‘minor’. These 
two types can be differentiated in terms of the 
intensity and duration of inundation (Paul and 
Rashid, 1987 and Khalequzzaman, 2000). The 
former refers to the less frequent but catastrophic 
that inundates 35% or more area of the country and 
continues for two months or more. Devastating 
floods usually occurs at longer interval, but during 
the recent years, repetitions of abnormal floods 
were frequent with an increase in its magnitude 
(Saqui, 1992). In the 19th century there were six 
major floods occurring in1842, 1858, 1871, 1875, 
1885 and 1992. 18 major floods occurred in the 20th 
century which are: 1900, 1902, 1907, 1918, 1922, 
1954, 1955, 1956, 1962, 1963, 1968, 1970, 1971, 
1974, 1984, 1987, 1988, and 1998 were of 
catastrophic consequence and the latest two severe 
floods in the 21st century are 2004 and 2007. 
According to Islam et al., 2010, property loss in 
every major flood is roughly more than 1 billion 
U.S. dollar and also kills huge human beings. 
Page 1087ISBN: 978-984-33-2140-4
  
Cyclone is another natural disaster which also 
damages lots of properties and lives. Out of sixty 
four districts, nineteen southern districts having 
proximity to the Bay of Bengal have been grouped 
into the coastal zone in terms of three geo-physical 
characteristics: interplay of tidal regime, salinity in 
soil and water, and cyclone and storm surge 
(Miyan, 2010). Almost every year, strong or weak 
cyclone hits Bangladesh. According to Cyclone 
Shelter Preparatory Study (CSPS), 38 small or large 
cyclone affected Bangladesh in between 1960 and 
1995, which took at least 780000 human lives. 
Every cyclone costs a large amount of property of 
the country which creates a huge burden for 
development of the country. A large number of 
lives were lost due super cyclone of 1991, which 
mainly struck in three coastal districts in the 
Eastern Zone: Chittagong (79,697 dead and 2600 
injured), Cox’s Bazar (51.147 dead and 133,000 
injured) and Noakhali (8,878 dead and 995 injured). 
The economic losses alone from the cyclone were 
estimated at US$ 2.4 billion. The main 
characteristic of this cyclone was a strong storm of 
exceptional intensity with wind velocities up to 225 
km/hr. However, the losses of life were 
substantially less than the 1.2 million people killed 
by the 1970 cyclone (MOHFW, 1992). According 
to Wikipedia, live loss in Cyclone Sidr (2007) are 
10,000, it is lower compared with 1970 and 1991 
due to the improved preparedness and concern of 
people and government. It damaged property which 
value is US $1.7 billion. Again cyclone Nargis 
(2008) damaged more properties compared to Sidr 
which is equivalent to US $10 billion and killed 
138,366 human lives. Cyclone Aila devastated 
properties of US $552.6 million and killed 325 
people and remained missing of 8,000 people 
(Wikipedia). 
 
 
2. METHODOLOGY 
 
The major floods and strong devastated cyclones 
which have precise records were considered only 
for this study. The data of different floods and 
cyclones were presented in tabular format. Yearly 
average of live and property losses were calculated 
for both cases to observe their effects and 
devastation. 
 
 
3. RESULTS AND DISCUSSION 
 
3.1 Effects of different Floods 
In 1954, severe flood surrounded about 54% land 
area of Bangladesh causing damage to crops of 1.14 
million ha. In 1974, approximately 57% of the land 
area went under flood water. Approximately 30 
million people were affected and crop loss was 
estimated to be nearly 2 million tons (Sahabuddin, 
1991). In 1984 flood, struck for different times, the 
crops were lost excluding life and property that was 
estimated to be 0.15 million (BBS, 1987). The 
effects of major floods from 1987 to present are 
presented in table- 1. 
 
Table 1. The effects of different major floods in Bangladesh 
Year Area Inundated Duration of flood 
(days) 
Property Loss 
($ USD) 
Death Loss 
1987 57,300km2 (40% of the 
country), 40 districts affected 
> 40 0.95 billion Affected 
41,000,000 
1988 82,000km2 (60% of the area), 
52 districts affected 
15-20 1.8 billion 3,000 (Affected 
30,000,000) 
1998 100,000 km² (68 percent of 
the country) 
> 65 2-3 billion > 2,000 (Affected 
30,000,000) 
2004 55,000 km2(38 % of the 
country), 39 districts affected 
12 2.2 billion 800 (Affected 
36,000,000) 
2007 39 districts affected 44 1.1 billion 1000 (Affected 
16,000,000) 
    Source: Islam et al., 2010 
 
3.2 Effects of different Cyclones 
The impact of cyclone on human lives and 
properties along with lowest wind pressure and 
maximum wind velocity are presented during the 
period 1970 to present, which has precise records, 
are depicted in Table 2. 
 
 
 
Page 1088
  
Table 2. The effects of different cyclones in Bangladesh 
Year Type of Cyclone Lowest 
Pressure 
(mbar) 
Wind 
Velocity 
(km/hr) 
Property 
Loss 
($ USD) 
Death 
Loss 
1970 
(Bhola) 
Very severe cyclonic storm (IMD) 
Category 3 tropical cyclone (SSHS) 
966 185 (3 min) 
205 (1 min) 
480 million 300,000-
500,000 
1991 Super cyclonic storm (IMD) Category 
5 tropical cyclone (SSHS) 
918 240 (3 min) 
260 (1 min)  
2 billion 138,000 
2007 
(Sidr) 
Very severe cyclonic storm (IMD) 
Category 5 cyclone (SSHS) 
944 215 (3 min) 
260 (1 min) 
1.8 billion 10,000 
2008 
(Nargis) 
Very severe cyclonic storm (IMD) 
Category 4 Tropical Cyclone (SSHS) 
962 165 (3 min) 
215 (1 min) 
10.1 billion 138,366 
2009 
(Aila) 
Severe cyclonic storm (IMD) 
Category 1 cyclone (SSHS) 
968 110 (3 min) 
120 (1 min) 
553 million 8325 
 
  Source: Wikipedia 
 
From 1987 to 2010, total live loss by major floods 
is 6800 persons and property loss is US $ 9.05 
billion; the average yearly death loss is 283 persons 
and property loss is US $ 377 million. Cyclone of 
1970 to 2010 has destructed more lives compared 
to major floods. The total death toll by cyclone is 
near about to 80000 persons and property loss is US 
$15 billion; average yearly death loss is 19500 
persons and property loss is US $ 366 million. 
Average live loss and property loss clearly show 
that cyclone destructs more life than that of major 
floods while property losses by these two disasters 
are near about to same. Besides these effects many 
people has affected by various types of diseases 
which will create long term sufferings. Huge 
numbers of people lost their future prospects and 
hopes due to effects of floods and cyclone. 
 
7. CONCLUSIONS 
 
Cyclone is a short term disaster compared to floods. 
During floods people get time to prepare 
themselves transferring from one place to another 
but when cyclone occurs in many cases people do 
not have time to transfer themselves. So during 
cyclone, human beings affected more than floods 
and loose their lives. To safe the life of people from 
cyclone, the warning system should be modernized 
and make it easy understand to all level of people. 
Management and rescue systems after cyclone 
should be developed in such a way that rescue team 
can be activated immediately after cyclone. The 
analysis of major floods data indicates that, death 
loss is decreased even in a strong major flood 
which causes huge property loss; this may be due to 
the increase of awareness among the people. When 
floods and cyclone take place, they disrupt normal 
agricultural activities and render agricultural related 
people jobless. It hinders the development of the 
countries progress and for a developing country like 
Bangladesh left many people hungry and may cause 
famine. So, Government of Bangladesh should take 
steps to educate or warn people about the 
devastating effects of cyclone and floods by mass 
media. Proper forecasting and warning may save a 
significant amount of damage. So more researches 
and works on cyclones and floods are deemed to 
minimize the future devastation. 
 
 
REFERENCES 
 
1. BBS (1987), Statistical Year Book, pp 12-35. 
2. Chowdhury, R.K. (2006), Formulation of a 
General Risk Assessment Framework for the 
Water Related Disasters of Bangladesh, ARPN 
Journal of Engineering and Applied Sciences, 
Vol. 1, No. 1, pp 46-50. 
3. Islam, S, Alam, M.J.B., Islam, M.A., Haque, 
M.A. and Hossain, M.S. (2010), Major Floods 
in Bangladesh: Return Period and Their Effects 
in Bangladesh, Journal of Environmental 
Science and Natural Resources, Vol. 3, No. 1, 
pp 93-95. 
4. Islam, M. and Sado, K. (2000), Development 
of Flood Hazard Maps of Bangladesh using 
NOAA-AVHRR images with GIS, Journal of 
Hydrological- des Science Hydologiques, Vol. 
45, No. 3, pp 337-355. 
5. Islam, M. and Sado, K. (2002), Development 
of Priority Map for Flood Counter Measures by 
Remote Sensing Data with Geographical 
Information, Journal of Hydrologic 
Engineering, Vol. 45, No. 5, ASCE, pp 346-
355. 
6. Khalequzzaman, M. (2000), “Flood Control in 
Bangladesh through Best Management 
Practices” in M. Feroze Ahmed (ed.) 
Bangladesh Environment 2000, Bangladesh 
Paribesh Andolon. 
Page 1089
  
7. Khalil, G.M. (1990), Floods in Bangladesh: A 
question of disciplining the rivers, Journal of 
Natural Hazards, Springer Netherlands, Vol. 3, 
No. 4, pp 379-401. 
8. Miyan, M.A. (2010), Cyclone Disaster 
Mitigation in Bangladesh, South Asian 
Disaster Management Center (SADMC), 
IUBAT- International University of Business 
Agriculture and Technology. 
9. MOHFW, (1992), Workshop Proceedings on 
Lessons Learnt During Cyclone-April 1991, 
MOHFW and WHO, Dhaka. 
10. Paul, B. and Rashid, H. (1987), “Flood 
Problems in Bangladesh: Is There Any 
Indigenous Solutions?” Environmental 
Management, Vol. 11, No. 2, pp 155 -173. 
11. Saqui, M.A.A. (1992), Protection of Land 
against Floods and Their Impacts on 
Agricultural Production in Bangladesh, 
Internationales Symposion- BERN, 
Tagunspublikation, Band 1, Seite 413-422. 
12. Sahabuddin, Q. (1991), Pleasant Behavior 
under Uncertainty, Windrock International, 
Dhaka, pp 1-205. 
Page 1090
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Rabeya Mariam,  
E-mail: rabeya.mariam@gmail.com 
DEVELOPMENT OF A HOUSEHOLD COMPOST GENERATION 
SYSTEM WITH ORGANIC HOUSEHOLD WASTE 
 
 
 
Rabeya Mariam and Abdul Kadir Ibne Kamal 
 Jahangirnagar University, Savar  
 
 
 Dr.-Ing. Anwarul Azim 
Formerly at Bangladesh University of Engineering and Technology (BUET), Dhaka 
 
 
Bangladesh is a heavily populated country, specially its townships. Due to the lifestyle and the food habit its 
citizens produce enormous amount of house-hold solid waste. It is quite difficult for the local governments 
of the townships to manage this bulk amount of solid wastes and keep townships environmentally clean and 
habitable. As these wastes are mostly organic (more than 75%), one of the solutions lies in composting the 
solid waste. In this study a composter was developed for this purpose. Samples of 5-6kg house-hold solid 
wastes were put to test in the composter. After 15 days of composting the average production of the compost 
was appx. 38%. The quality of the compost was good enough as the manure met the national standards. The 
produced compost contained 21.5% organic matter, 2.9% Potassium (K), 2.56% Total Nitrogen(N), 1.52% 
Phosphorus (P), 0.59%  Sulfur (S) and 0.01% Zinc (Zn).  
 
Key words: Environmental pollution, waste management, solid waste, compost, manure  
 
1. INTRODUCTION AND 
LITERATURE REVIEW  
 
The climbing of the human civilization has its basis 
on the utilization of natural and other resources. 
People cannot obviously utilize these resources 
fully, which results in wastes. With the growth of 
civilization, especially of the urban based 
civilization and of the human population these 
wastes grew to an insurmountable size, demanding 
the management of the same. The waste generation 
of DCC (Dhaka City Corporation) area was no less 
than 3,700 tons per day (Imtiaz and Alam, 2002). 
DCC sources and some other reports state that the 
waste generated in the DCC area is about 4,000 to 
5,000 tons/day (The Daily Star, 21 June 2004). 
Only 42% of the waste is collected by DCC and 
disposed off in open crude landfill site. As a result 
uncollected waste lies on road sides, open drains, 
low lying areas, thus contributing to the 
deteriorating quality of life and environment of the 
city (JICA, 2004). 
 
Despite high demand for all forms of recyclable 
material in Bangladesh and a large number of 
people involved collecting and recycling industrial, 
commercial and kitchen refuge, solid waste is one 
of the most visible forms of pollutants found in city 
streets, open areas, unused public and private lands, 
ditches and water bodies (World Bank, 2000), 
which demands its systematic and economic 
management.  
 
Solid Waste Management refers to all activities 
pertaining to control, collection, transportation, 
processing and disposal of the waste in accordance 
with the best principles of public health, economics, 
engineering, conservation, aesthetics and other 
environmental considerations. It includes all the 
procedures from the source to the final disposal in a 
socio-legally acceptable, economically viable, 
technically feasible and environmental friendly 
manner. 
 
Page 1091ISBN: 978-984-33-2140-4
  
Problems associated with improper management of 
solid waste: 
• Can cause more than 40 diseases(diarrhea, 
cholera, etc); 
Bobeck, M. (2010) reported on environmental 
impacts and health hazards as a result from 
inadequate management of organic household 
waste in developing countries. Her report gave 
details of water and soil contamination, air 
pollution and spread of diseases through expanding 
breeding grounds for pathogens, vectors and 
rodents.  
 
• Pollution of surface water, ground water, 
soil and air; 
• Emission of Green House Gas (GHG) 
from crude dumping sites; 
• Organic waste is left unutilized 
 
Modes of removal of solid waste 
 
• Dumping-  
Open dumping of solid wastes is practiced 
extensively in Bangladesh, because it is cheap and 
requires little planning. But dumping of solid waste 
has a lot of disadvantages e.g., it creates bad odor 
and inconvenience to the population, pollutes the 
surface water, the ground water and the soil, 
unsystematic dumping blocks the drainage system 
resulting in flooding of the locality and the 
generation of mosquito. Furthermore, the 
population loses its economic value. Added to this, 
Bangladeshi city administrations collect only 40% 
to 50% of waste generated with open dumping  
• Composting 
Composting is an ideal process to manage organic 
waste and the compost produced has a commercial 
value, because it can be sold as fertilizer and the 
by-product is biogas. Field trials (Mbuligwe et al., 
2002) of the compost product improved yields of 
vegetable crops by more than 35% and extended 
their production period by more than a month. 
Also, the temperature developed during the waste 
composting process was high enough to kill 
pathogens, making the solid waste safer for soil 
application and disposal. 
• Incineration 
Open burning of waste leads to toxic contamination 
of both ground water and air. Closed incineration 
needs high investment in the hardware. 
• Generation of electricity 
Alam and Bole (2001) analyzed the electrical 
energy recovery potential from urban solid waste of 
Dhaka city and its economic feasibility and 
emphasized that the 1.28 million tonnes of 
municipal waste generated annually in the Dhaka 
city could potentially produce about 71MW of 
electricity. 
2. OBJECTIVE OF THE STUDY 
 
Table 1 shows that 80 – 84% of solid waste of 
Dhaka City originates in kitchens. 
This study concentrates on the composting of 
house-hold organic solid waste (mainly the kitchen 
waste). In such a case the composting can be 
carried out at the house hold level without asking 
for an industrial venture. Other points in favour are: 
 There is no need for collection, 
transportation, storage and subsequent 
marketing 
 Low income families can take the 
advantage of its economic value 
and/or its use to fertilize their 
backyards.  
 If composting can be carried out at a 
large scale, the nation can get rid of 
significant amount of chemical 
fertilizer  
 
Table 1: The composition of solid waste in Dhaka 
City 
 
Materials Quantity (%) 
 
Residential 
Area 
Commercial 
Area 
Food waste 
(organic) 
84.37 
 
79.49 
Paper/cardboard 
 
5.68 7.22 
Textiles 
 
1.83 1.59 
Plastics 
 
1.74 
 
1.48 
Glass/metals and 
construction 
debris 
6.38 10.22 
 
 
3. EXPERIMENTAL DESIGN 
 
The aerated waste decomposes to form fertilizer 
and leachate. The leachate can also be used as 
liquid fertilizer. Decomposition is a time dependant 
activity. The longer time the waste is left for 
decomposition, the more matured is the produced 
fertilizer. But with time the process becomes 
costlier and more kitchen waste accumulates on the 
sidelines. The waste, dumped into the aerated waste 
collector was left for 15 days, which was sufficient 
enough to achieve the national standard of 
fertilizer. 
 
 
 
 
Page 1092
  
The duration of composting was limited to 15 days 
for two reasons-  
• The longer the duration, the larger is the 
quantity of organic waste, which will demand the 
larger storage space and pollute the house-hold 
environment through pollution,  
• The larger amount of organic waste will 
need bigger composter and more investment. 
 
Composter: 
The composter has the following components: 
1. The digester is a metallic box (fig.1), 
which houses the waste collector and the leachate 
collector. It has a lid, on which the gas vane is 
fixed. 
2. The waste is stored in the plastic waste 
collector, which is 9.5 inch in diameter and 16 inch 
in height. 0.2 inch holes were drilled on its surface 
one inch apart. The holes at the top facilitate 
aeration of the compost and those at the bottom 
helps oozing out of the leachate from the waste 
collector. 
3. The leachate collector collects the 
leachate. 
4. The gas vane lets out the bio-gas, which is 
odorous, at a sufficient height away from human 
range. 
 
The height of the composter was 7 ft. Its cost was 
tk. 2000. 
 
 
Figure 1: The designed composter 
 
 
 
 
 
 
 
4. EXPERIMENTAL RESULTS 
 
Table 2: Amount of compost generated from the 
organic waste by using the prototype composter. 
 
No. of 
experiments  
Sample 
1 
Sample 
2 
Sample 
3 
Sample 
4 
Amount of 
waste (kg) 
1.5 4.5 4 5 
Amount of 
compost by 
weight (kg) 
0.5 1.6 1.6 2 
Produced 
leachate 
(ml) 
250 750 690 850 
Time 
duration 
(days) 
15 15 15 15 
 
The average yield of compost from the organic 
waste was about 38%. The amount is higher than 
25%, because the time duration the waste left in the 
digester for composting was less. The moisture in 
the compost was removed by sun-drying process 
and the weight was brought down to 25% of the 
original weight. Chemical test was then performed.  
  
Table 3: Chemical characteristics of produced 
compost 
 
Parameters/ 
samples 
Sample 
1 (%) 
Sample 
2 (%) 
Sample 
3(%) 
Sample 
4 (%) 
Average  
pH 7.8 7.4 7.5 7.6 7.575 
Organic 
matter 
21 20 22 23 
21.5 
Potassium 
K 
3.15 2.90 2.85 2.75 
2.9125 
Total 
Nitrogen N 
2.80 2.51 2.30 2.65 
2.565 
Phosphorus 
P 
1.8 1.5 1.4 1.4 
1.525 
Sulfur 0.76 0.52 0.51 0.6 0.5975 
Zinc 0.01 0.01 0.1 0.1 0.01 
 
 
 
pH value 
The pH value varies from 7.4 to 7.8, the average 
being 7.6 which is within the National Fertilizer 
Standard (6 – 8.5) 
. 
 
 
 
 
 
Page 1093
  
Organic matter 
The content of organic matter varies from 20% to 
23%, the average reading being 21.5% 
 
Potassium K 
Potassium varies from 2.75% to 3.15%, the average 
being 2.91% which is within the National Fertilizer 
Standard (1-3%). 
 
Total Nitrogen N 
It varies from 2.30 % to 2.80%, the average reading 
of 2.56%. This average is in agreement with the 
National Fertilizer Standard (0.5- 4%) 
 
Phosphorus P 
The content of Phosphorus varies from 1.4 to 1.8%, 
whose average is 1.525%. The National Fertilizer 
standard states that phosphorus should be between 
0.5 and 1.5%. 
 
Zinc 
It varies from .01 to 0.1%, bringing the average 
value to 0.055%. According to National Fertilizer 
Standard, Zinc can be present upto a maximum of 
0.1%. 
  
 
5. CONCLUSION 
 
This study is one step towards the disposal of the 
kitchen waste in a socio-legally acceptable, 
economically viable, technically feasible and 
environment-friendly manner. Important 
conclusions include:  the disposal of the kitchen 
waste can be done at source (there is no need for 
collection and transportation) and low income 
families can take the advantage of its economic 
value and/or use it as fertilizer in their backyard. 
If composting can be carried out at a large scale, the 
nation can get rid of significant amount of chemical 
fertilizer 
Further studies may be carried out comparing 
composting with the disposal with electricity 
generation. 
 
 
 
 
REFERENCES 
 
1. Imtiaz, N., Alam, S.M. (2002), Health Care 
Waste of Dhaka City: A Socio-Environmental 
Assessment. In Ahmed, A.F., Tanveer, S.A., 
Badruzzaman, A.B.M. (edts.) Bangladesh 
Environment, Bangladesh Poribesh Andolon, 
Dhaka. 
2. The Daily Star, 21 June 2004, viewed 22nd 
September 2010. 
3. JICA, 2004. Draft Final Report of “Clean 
Dhaka Master Plan”. Japan International 
Cooperation Agency. Dhaka. Available at: 
www.cleandhaka.com/pages /drftreport.htm 
4. World Bank, 2000 Urban Development 
Strategy and City Assistance Program in South 
Asia (Bangladesh), Interim Report, p.2-34. 
5. Bobeck, M. (2010), Organic Household Waste 
in Developing Countries: An overview of 
environmental and health consequences, and 
appropriate decentralised technologies and 
strategies for sustainable management  
Environmental Science BAC, Individual 
Assignment, Department of Engineering and 
Sustainable Development, Mid Sweden 
University 
6. Mbuligwe, S. E., Kassenga, G. R., Kaseva, M. 
E. and Chaggu, E. J. (2002),  Potential and 
constraints of composting domestic solid waste 
in developing countries: findings from a pilot 
study in Dar es Salaam, Tanzania, Resources, 
Conservation and Recycling Vol 36, Issue 1, 
July pp. 45-59 
7. Alam, M.J. and Bole, B. (2001), Energy 
recovery form municipal solid waste in Dhaka 
city. In: Proceedings of the International 
Conference on Mechanical Engineering, 26–28 
December 2001, Dhaka, pp. 125–130. 
 
Page 1094
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Md. Imran Kabir,  
E-mail: imran-cee@sust.edu; imran_kabir_ce@yahoo.com  
HEAVY METAL REMOVAL USING GRAFTED ACRYLIC ACID 
FOR THE WATER COMING FROM ABANDONED MINES 
 
Md. Imran Kabir1,* 
1Department of Civil and Environmental Engineering,  
Shahjalal University of Science and Technology, Sylhet, Bangladesh 
 
Md. Abdullah Bin Hossain2 and Md. Moinul Haque Choudhury 3 
2Department of Environmental Engineering, Chungju National University, South Korea  
3Department of Polymer Science and Engineering, Chungju National University, South Korea 
 
 
Heavy metal contamination of water around abandoned mines was observed in South Korea. In that 
assessment, the highest concentrations of 88, 5, 116 and 244µg L-1 of copper (Cu), cadmium (Cd), lead (Pb) 
and zinc (Zn), respectively, were found in water within 1km from the mine. Acrylic acid was graft 
polymerized onto plasma-treated cellulose filter papers to develop a sorbent capable of removing the heavy 
metals. The ability of the grafted sorbent to remove a mixture of Cu, Cd, Pb and Zn from synthetic mine-
water samples was evaluated in batch test at a starting pH of 6.5. The sorbent dosage was set at 20g L -1. The 
Freundlich isotherm model also explained the data. Three different grafting percentages of 42, 122 and 148 
were used to evaluate the effect of percentage grafting on adsorption. The amount of metal adsorption 
decreased with increasing percentage graft. The solid phase adsorption for the different grafted percentages 
decreased in the following order: Zn > Cu > (Cd ≈ Pb). Admittedly, it was found that one gram of plasma-
treated acrylic acid filter paper was capable of removing approximately 111, 39, 36 and 117µg of Cu, Cd, Pb 
and Zn respectively. 
 
Key words: Abandoned mine; Freundlich isotherm; Grafting; Metal removal; Oxygen plasma 
 
1. INTRODUCTION 
 
Mining and milling operations, together with 
grinding, concentrating ores and disposal of 
tailings, provide obvious sources of contamination 
in the surface environment, along with mine and 
mill wastewater. In Korea, various mines were 
distributed all over the country and were actively 
operated until the early 1980s, since then, however, 
most have been closed, mainly due to economic 
reasons. After mine closure, mine waste materials, 
including tailings, were left without full 
environmental treatment, leading to the 
contamination of soils, plants, waters and sediments 
in the vicinity of the mines by potentially toxic 
elements from tailings by clastic movement through 
wind and water. The extent and degree of heavy 
metal contamination around the mines vary 
depending on the geochemical characteristics and 
mineralization of the tailings. For example, tailings 
containing large quantities of sulfide minerals could 
influence nearby agricultural lands and streams. In 
2008, metal contamination around 44 abandoned 
mines in South Korea was measured and the 
highest concentrations of Cu, Cd, Pb and Zn in 
surface water were 88, 5, 116 and 244µg L-1 
respectively. 
 
Sorption, utilizing low-cost filter materials, is an 
attractive option for small businesses, industries 
and municipalities to remove significant portions of 
the total metal concentrations to levels which will 
be less detrimental to public health and 
environmental quality (Okieimen et. al., 2005). 
Graft copolymers of cellulosic materials have 
advantages such as chemical resistance, radiation 
stability and inexpensive production compared to 
conventional ion exchange (Chauhan et. al., 2000). 
Many investigators have studied the feasibility of 
less expensive materials such as bone char (Cheung 
et. al., 2000), bagasse (Mohan and Singh, 2002) etc. 
for the removal of heavy metals from water. In this 
study, filter paper was used as a cellulose source. 
Oxygen (O2) plasma was treated to form a reactive 
surface on filter paper for the further reaction with 
acrylic acid (AA). The main objective of the study 
was to form a sorbent capable of enhancing heavy 
metal removal from mine’s surface water. Plasma-
induced graft polymerization is an attractive way of 
modifying the surface chemistry and morphology 
Page 1095
ISBN: 978-984-33-2140-4
ISBN: 978-984-33-2140-4
  
of polymeric materials (Gupta et. al., 2002). 
 
2. MATERIALS AND METHODS 
 
AA underwent graft polymerization by a two-step 
method (Gupta et. al., 2002). Cellulose filter papers 
were treated for 120s in an argon (Ar) plasma 
reactor operating at a radio frequency (RF) of 
13.6MHz, gas pressure of 5mbar, argon flow rate of 
50sccm and power of 100W, as described 
elsewhere (Gupta et. al., 2002). Immediately after 
the treatment, O2 was introduced into the chamber 
that was maintained at atmospheric pressure for 1h 
to generate hydroperoxide as well as other 
functional groups on the sample surface. The 
operation of plasma onto cellulose filter paper, as 
shown in Fig. 1, was done through Plasma 
Enhanced Chemical Vapor Deposition (PECVD) 
apparatus. It had a cylindrical reactor made of 
stainless steel (diameter 50cm) and a parallel plate 
electrode configuration with an electrode spacing of 
14cm. Both of the stainless steel electrodes were 
circular in shape; the lower grounded electrode was 
30cm in diameter. The precursor gas was fed 
through a gas shower head built in the upper 
electrode. The pressure of the reaction chamber was 
measured through a Baratron gauge (122B, MKS 
Instruments). The chamber was evacuated to a base 
pressure of 1.6Pa using a rotary pump before 
plasma treatment. AA was graft polymerized onto 
the plasma-treated filter papers under a nitrogen 
atmosphere (Gupta et. al., 2002). The filter papers 
were placed in a tube containing aqueous AA of 
predetermined concentration (30%) and nitrogen 
was bubbled through the solution. The tube 
equipped with a positive nitrogen pressure was 
subsequently placed in a constant temperature 
water bath for 1~5h. After the grafting reaction, the 
filter papers were removed from the tube and 
underwent soxhlet extraction with water overnight 
to remove any homopolymer adhering to their 
surface (Gupta et. al., 2002). The percentage graft 
was calculated from the following relation 
(Eromosele and Bayero, 2000): 
 
Percentage grafting = W2-W1
W1
×100 
where, W1 and W2 are the weights of the filter 
paper and the grafted filter paper respectively. 
 
Sorption experiments were carried out using 
synthetic solutions in 50 ml beakers at room 
temperature (28 1ºC). The required concentrations 
of Cd, Cu, Pb and Zn were obtained by step-by-step 
diluting their stock commercial solutions to the 
desired concentrations. The ionic strength of the 
water samples was controlled using 0.01M NaCl, 
and the pH changes during the experiments were 
minimized using 0.003M NaHCO3 (Genç-Fuhrman 
et. al., 2007). Before starting the batch experiments, 
the pH of all solutions was adjusted to 6.5 using 
strong acid or base solutions. Afterwards, the 
dosage of plasma-treated AA-filter paper (PAAF) 
was set at 20g L-1 (Genç-Fuhrman et. al., 2007) in 
the predetermined synthetic solutions. The 
solutions with sorbents were then mixed by gently 
shaking the batches in a mechanical shaker at 100 
rpm for 24h. Later, the batches were taken from the 
shaker and filtered through 0.45µm filter paper, 
after which the filtrates were acidified to pH 1.5~2 
and stored at 4ºC until the heavy metal 
measurements. One set was also run as a control 
batch with sorbent but without any heavy metal 
addition. All the chemicals used were reagent grade 
and were used without any further purification. 
 
 
 
 
Fig. 1: Schematic diagram of PECVD system 
 
In this study, we attempted to use realistic 
concentration ranges where the lowest values were 
below or about US Environmental Protection 
Agency’s fresh water acute limits and the highest 
values were significantly higher, as shown in Table 
1. The purpose was to evaluate and compare the 
sorbents at both highly and slightly polluted 
conditions, since some sorbents are known to be 
effective at rather high concentrations but are less 
efficient at low concentration (Genç-Fuhrman et. 
al., 2007). 
 
For PAAF, the solid phase heavy metal 
concentration, qe (µg g-1), was determined by 
analyzing the corresponding heavy metal 
concentration before and after the treatment using 
the equation, qe= 
(C0-Ce)
X
, where, Ce is the equilibrium 
heavy metal concentration in the solution (µg L-1), 
and X the sorbent dosage (g L-1). Moreover, the 
equation, log qe=logK+ 
1
n
logCe was used as the 
linear form of the Freundlich isotherm to fit the 
sorption data where, K is correlated with the 
quantity of sorbate associated with the sorbent, and 
n is the Freundlich isotherm constant related to the 
strength of the sorption. 
Page 1096
  
 
Table 1: Initial concentrations (C0) of heavy metals 
for batch experiments 
 
 
C0 (µg L-1) 
Cd Cu Pb Zn 
USEPA 2 13 65 120 
Batch 1 9018 10900 9726 11020 
Batch 2 4425 5242 4715 5850 
Batch 3 2664 3130 2832 3287 
Batch 4 892 1041 976 1192 
Batch 5 438 520 516 722 
Batch 6 90 120 170 323 
Batch 7 3 22 73 161 
 
 
3. RESULTS AND DISCUSSION 
 
Table 2 shows Freundlich isotherm constants with 
the r2 values for all grafting percentages 
investigated in this study. For Pb, at the percentage 
grafting of 42, the r2 values were comparatively 
lower. However, the r2 values ≥ 0.5 signify 
statistically significant correlation. Although r2 ≥ 
0.5 shows a fair correlation, using the estimated 
Freundlich isotherm for prediction is considered 
highly uncertain unless r2 is close to 1 (Genç-
Fuhrman et. al., 2007). Accordingly, most of the 
investigated heavy metals showed the most 
correlated result to fit the isotherm. Cu showed a 
better correlation than the others as 0.95 ≤ r2 ≤ 0.98. 
 
The solid phase adsorption of metal was corrected 
for the grafting percentages in the batches. As 
depicted in Fig. 2, the adsorption per dosage of 
adsorbent versus grafting percentage was drawn 
while keeping the other parameters constant. The 
adsorption per dosage of the adsorbent generally 
improved with low grafting percentage at all heavy 
metal concentrations. Alternatively, the amount of 
metal sorbed decreased with increasing percentage 
graft. Pb and Cd showed similar sorption criteria 
that were lower than those of Zn and Cu sorption. 
In the study, Zn was more sorbed than Cu. 
 
The results of the simultaneous removal of Cd, Cu, 
Pb and Zn are presented in Fig. 3 on a double 
logarithmic scale for batch tests. As expected, the 
amount of heavy metal removed increased with 
increasing initial heavy metal concentration in all of 
the batches. The sorbent dosage was set at 20g L-1 
for all the batches. All of the batches were 
investigated at three different grafting percentages. 
The highest amount of adsorbed Cu in batch 1 was 
111µg g-1. 
 
 
Table 2: Freundlich isotherm constants for different 
grafting percentages 
 
H
ea
v
y 
m
et
al
s Percentage grafting 
42 122 148 
K 1/n r2 K 1/n r2 K 1/n r2 
Cd 0.
06
 
0.
67
 
0.
96
 
0.
00
6 
0.
89
 
0.
92
 
0.
00
1 
0.
98
 
0.
98
 
Cu 0.
08
 
0.
76
 
0.
95
 
0.
03
 
0.
85
 
0.
98
 
0.
01
9 
0.
87
 
0.
98
 
Pb 0.
82
 
0.
36
 
0.
84
 
0.
00
1 
1.
06
 
0.
87
 
0.
00
1 
0.
89
 
0.
91
 
Zn 1.
41
 
0.
45
 
0.
90
 
0.
00
4 
1.
10
 
0.
96
 
0.
00
5 
1.
00
 
0.
99
 
 
 
 
 
 
Fig. 2: Solid phase sorption of Cd, Cu, Pb and Zn at 
different grafting percentages 
 
4. CONCLUSION 
 
This study has presented the effective use of PAAF 
to remove trace heavy metal elements in the water 
coming from abandoned mines. The heavy metal 
sorption showed satisfactory results in the batch 
study. The sorption of the heavy metals was 
dependent on the grafting percentage with a lower 
grafting percentage exhibiting better solid phase 
metal sorption. PAAF was suitable for batches with 
low concentrations of heavy metals. 
 
No sorbent leaching occurred during the batch tests, 
indicating an acceptable adsorbent quality. The 
effect of sorbent dosage should be investigated in 
future study to determine the effects on heavy metal 
removal. 
 
Page 1097
  
 
 
Fig. 3: Cd (♦), Cu (■), Pb (∆) and Zn (○) removal at 
the following different grafting percentages:  
(a) 42%, (b) 122% and (c) 148% 
 
 
REFERENCES 
 
1. Chauhan, G.S., Mahajan, S. and Guleria, L.K., 
(2000), Polymers from renewable resources: 
sorption of Cu+2 ions by cellulose graft 
copolymers, Desalination, 130, pp. 85-88 
2. Cheung, C.W., Porter, J.F. and Mckay, G., 
(2000), Elovich equation and modified second-
order equation for sorption of cadmium ions 
onto bone char, J. Chem. Technol. Biotechnol., 
75, pp. 963-970 
3. Eromosele, I.C. and Bayero, S.S., (2000), 
Adsorption of chromium and zinc ions from 
aqueous solutions by cellulosic graft 
copolymers, Bioresource Technology, 71, pp. 
279-281 
4. Genç-Fuhrman, H., Mikkelsen, P.S. and Ledin, 
A., (2007), Simultaneous removal of As, Cd, 
Cr, Cu, Ni and Zn from stormwater: 
Experimental comparison of 11 different 
sorbents, Water Research, 41, pp. 591-602 
5. Gupta, B., Plummer, C., Bisson, I., Frey, P. 
and Hilborn, J., (2002), Plasma-induced graft 
polymerization of acrylic acid onto poly 
(ethylene terephthalate) films: characterization 
and human smooth muscle cell growth on 
grafted films, Biomaterials, 23, pp. 863-871 
6. Kesraoui-Ouki, S., Cheeseman, C.R. and Perry, 
R., (1994), Natural zeolite utilization in 
pollution control: a review of application to 
metal’s effluents, J. Chem. Technol. 
Biotechnol., 59, pp. 121-126 
7. Mohan, D. and Singh, K.P., (2002), Single- 
and multi-component adsorption of cadmium 
and zinc using activated carbon derived from 
bagasse ─ an agricultural waste, Water 
Research, 36, pp. 2304-2318 
8. Okieimen, F.E., Sogbaike C.E. and Ebhoaye 
J.E., (2005), Removal of cadmium and copper 
ions from aqueous solution with cellulose graft 
copolymers, Separation and Purification 
Technology, 44, pp. 85-89 
9. Viraraghavan, T. and Rao, G.A.K., (1991), 
Adsorption of cadmium and chromium from 
wastewater by fly ash, J. Environ. Sci. Health, 
26A(5), pp. 721-753 
 
Page 1098
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
Md. Misbah Uddin,  
E-mail: mun_cee@yahoo.co.uk 
IMPACT ON SUSTAINABILITY OF HAIL HAOR BY INTEGRATED WATER 
MANAGEMNT ACTIVIIES 
 
1Md. Misbah Uddin, 1Dr. J. B. Alam, 2Faruq Uddin 
1Department of Civil and Environmental Engineering, Shahjalal University of Science and Technology 
2 Department of Sociology, Shahjalal University of Science and Technology 
 
ABSTRACT 
 
This study concerns with the activities running through the projects under different well-known institutions 
and the effects of the projects on sustainability of the environment of Hail haor. Hail haor is the main water 
reservoir of Moulobhi bazar-Sreemangal area. Hundreds of Choras discharge water in this haor. Huge 
amount of water also carries tones of sediments. This causes siltation of the haor as well as the Choras. As 
the depth of the haor decreases, the living place of the aquatic animals reduces. As the water reservation 
capacity of the haor and conveying capacity of the discharge channel reduces; as a result, in the Monsoon the 
haor can’t provide sufficient places for incoming water, which causes flood. Moreover, in the month of April 
and May flash flood occur which causes devastating damage to the crops (specially the Boro crops) and 
breaks down the local economic condition. Again, flood carries much of silts which make the soil fertile. If it 
is possible to save the Boro crops up to mid-May from flash flood then it would be very much beneficial. On 
other hand, deficiency of water occurs tremendously in the dry season. 
 
KEY WORDS: Sustainability, Haor, Integrated water management, Checklist. 
 
1.  INTRODUCTION 
 
Sustainable development is an approach to 
economic planning that attempts to foster economic 
growth while preserving the quality of the 
environment for future generations. Proper water 
management is essential for sustainable 
development (Hunter and Jones, 2002). Depending 
on the terrain, water management may involve 
extensive works to achieve optimum utilization and 
to get the maximum benefit from a water reservoir 
in such a way that its quality should be preserved in 
its original or a controlled condition as a means of 
future use. It includes storing, discharging of 
surplus water, protection of surrounding areas from 
flood and draught, providence of safe and sufficient 
places for aquatic plants and animals, satisfy the 
needs of the people who depends on it etc. 
 
Haor is a large saucer like low land with a very 
smooth and gentle slope which have some natural 
contributory streams and a well defined outlet and 
which is being used as temporary water reservoir 
and velocity controller especially at monsoon. GIS 
can be used for scientific investigations, resource 
management and development planning. 
 
The topography of the north-eastern part of 
Bangladesh is uneven. Hills surround the Hail Haor 
basin to the west, east and north. Approximately 
50% of the watershed area is hilly and managed by 
different tea estates, lemon-pineapple garden 
owners and the State Forest Department. People are 
converting the landscape by cutting hills for 
different patterns of agricultural farming and also 
for making roads and establishing human 
settlements. The elevation of hilltops ranges from 
60 to 66 meter above mean sea level (MSL) while 
the base of the hills range from 25 to 35 meter; and 
wetland basin itself is in the range of 2-6 m above 
MSL. The water shed area of Hail haor is about to 
600 square kilometer (237 sq-miles). All water in 
the basin originates from the surrounding hills, with 
approximately 85% from India and 15% from 
within Bangladesh. Hail haor plays an important 
role in balancing ecosystem of the country. Here, 
all the hilly charas are coming from the hills and 
met in the flood plain area of the haor and drain 
though the only outfall the Gopla river, which 
ultimately fall into Old Surma river (Alam, 2002). 
Therefore, the flooding, drainage and water logging 
are largely depended on the functional capacity of 
the Gopla River. So, an attempt has been taken in 
this study to check the sustainability of the hail 
hoar. 
 
2. OBJECTIVES 
 
The specific objectives of the study are as follows: 
Page 1099ISBN: 978-984-33-2140-4
  
 
 
(i) To find out the present situation and the impact 
of different activities running through different 
projects on sustainability of the environment of 
Hail haor. 
(ii) To recommend some measures for the 
sustainability of the environment of Hail haor. 
 
 
3. METHODOLOGY 
 
Step-1: Visiting of the Whole Area 
 Survey work has been conducted from 
Jan’05 to December’05. 
 Using of the resource full libraries of 
different institutions to square knowledge 
about different national and international 
water management projects. 
 Almost the whole area was visited well 
enough to observe and know the way of 
the project execution with a specialist. 
 Different hydrology measuring stations 
were observed properly when they were 
performing their duties. 
 Different Important choras were observed. 
 Different types of dam were observed with 
their constructional specialties. 
 Getting of information from different field 
offices. 
 Observation of the conditions of the flood 
control structures with the effects. 
 
Step-2: Consultations with the Stakeholders 
 Consultation was done under RRA (Rapid 
rural appraisal) and PRA (Participatory 
rapid appraisal) projects. 
 Consultations with different peoples of 
different places and standards about the 
present situation. 
 Consultations with different peoples of 
different places and standards about the 
remaining problems. 
 Consultations with different peoples of 
different places and standards about their 
thinking of solutions with their benefits. 
 
Step-3: Consultation with the Specialists 
 
Consultation with Hydrologists 
Consultation with different hydrologists was done 
in different context of Hail haor. Flow pattern of 
water of Hail haor, different flood problem, causes, 
after effects etc. were being discussed with him. 
Effect of the projects on natural hydrology was also 
being discussed with him. 
 
Consultation with Environmentalists 
Present condition of the environment on Hail haor 
was being discussed with him. Effects of the 
running projects on the environment were also 
being discussed. 
 
Consultation with Construction Engineers 
Consultation with the dam designers and engineers 
was being done. Constructing materials with the 
design considerations and the objectives of the dam 
was discussed with practical observations in field 
with future plans. 
 
Consultation with the Hydrology Monitoring 
Personnel 
Consultation with the monitoring personnel was 
being done in details. How the instruments works 
was being observed. 
 
Step-4: Taking Help from GIS Lab 
Different uses of GIS in planning, monitoring and 
future prediction were discussed. Ecology, depth of 
the haor in different positions, moisture holding 
ecosystem of different stages, geographical 
locations, agricultural land, settlements, hilly 
regions etc were discussed with them through the 
satellite image of Hail haor. 
 
Step-5: Sustainability Evaluation with Checklist 
Method 
200 experts from different BWDB *(Bangladesh 
Water Development Board), CEGIS (centre for 
Environment and Geographical Information 
System), IWM (Institute of Water Modeling) and 
NGO’s related with wetland management (MACH, 
IDEA, IUCN) have been introduced a scale on 
environmental parameters for sustainability 
checking (Hossain and Chowdhuary, 2003). From 
the checklist, the sustainability has been evaluated. 
 
Scale of point measurement 
Impacts Severity (s) 
1=No effect 
2=Minor effect (single receptor) 
3=Minor effect (multiple receptor) 
4=Significant effect (single receptor) 
5=Significant effect (multiple receptor) 
6= Dynamic effect on single/multiple receptor 
 
Probability (p) 
1=Negligible 
2=Slight 
3=Possible 
4=Likely 
5=Very likely 
6=Inevitable 
 
Grading 
 Impact Value (IV) = p * s        Insignificant      < 4 
                 ,,                                           Low            4 to 8 
          ,,                                       Medium         8 to 10 
          ,,                                           High              > 10 
Page 1100
  
 
 
4. RESULTS AND DISCUSSION 
 
Hail Haor, through the View of GIS 
 
Ecology 
Hail Haor is composed of unique status in the 
region as the largest shallow permanent lake unlike 
other haors of the northeast of Bangladesh. Hail 
haor supports highest biodiversity of plants and 
animals in its unique geographical location.  
 
The area is confined three sides by hilly lands so 
there are about 352 charas originated from the 
surrounding hills and entered into the Hail haor. 
Out of 352 charas only 56 charas are live and 
contributing huge amount surface runoff that 
generates flash flood in every year. In addition to 
these charas, there are a number of rivers namely 
Gopla River, Dainka River, Buda River, Bilash 
River and Kodaligang River in the haor area. 
Among the river, Gopla is most important river, 
which runs through north to south and the main 
water discharge channel (MACH , 2004).  
 
Depending on water retention by depth and 
duration, moisture holding capacity of soils, 
topography and vegetation, Hail haor area can be 
divided described as following ecological zones 
through the white broken line drawn in figure 1: 
 
 
Figure 1.  Lansat Image of 2003, the white broken 
line touch almost all ecosystem of Hail haor areas. 
 
Deepest part of the haor 
These areas (Figure 1) are represented by deep-blue 
to blackish dark color in the Landsat image. Most 
of the lower perennial water bodies are within this 
range. This perennial wetlands situated under the 
Kalapur union almost at the center of the haor. 
More than hundred (locally popular 352 choras of 
streams finally reaches the hail haor deeper areas. 
Water from hills of three sides (east, west and 
south) arrives at the center first. These areas act as 
primary reservoir unlike haors of the north like 
Korchar or halir haors. These areas act as over 
wintering ground for all aquatic resident creatures. 
Water then spell to the next ecosystem, the high 
moisture holding ecosystem. 
 
High Moisture Holding Ecosystem 
These areas (Figure 1) are represented by Indigo 
color in the Landsat image. These are most 
important shallow aquatic ecosystem that act as 
best grazing land for all aquatic and wetland 
depended creatures. High moisture holding 
capacity, fertile soils and consistency provides 
highest biodiversity of flora and fauna of the 
overall haor. The area covers the inner part 
(towards haor center) of the following unions the 
Mirjaput Nazirabad, Giasnagar, eastern part of 
Kalaput part of Srimangal and Bhunabir. Makhna 
(Eurayle ferox) and Padoo (Nelumbo nucifera), 
both rooted floating plants, are still found only in 
Hail Haor. These plants grow under this ecosystem.  
 
Rivers and Choras 
There is only one major river that cross the hail 
haor name Gopla River and the minor river name 
Fulchori which is also connected with Golpla 
River. Gopla River finally meet with Surma River 
in the north crossing all type of ecosystem. Gopla is 
the only drainage outlet for hail haor. Water flows 
unidirectional in choras. Rainwater or water from 
hills comes to the haor almost round the year. 
During the monsoon these are so vigorous that 
washes every thing along the sides and finally take 
to the haors. Wastes from urban areas of Srimongal 
and Maulavibazar, Tea garden wastes, rural 
household wastes and finally agricultural runoff 
turn haor to acidic condition and post monsoon. 
The vast agricultural land of the nearby ecosystem 
contributes filling wetlands. Intensive agricultural 
intrusions over this ecosystem caused serious 
ecological disaster and eliminate lot of haor 
characteristics permanently. Loss of wetland 
seasonal vegetation, resident and migratory birds 
and habitat conversion for invertebrates are major 
changes. 
 
Low Moisture Holding and Hard Dry Soils 
Agricultural Land 
These areas (Figure 1) are represented by 
conspicuous pink color in the Landsat image. These 
are genuine agricultural land. Within these land 
mass and it periphery are the next ecosystem the 
settlements.  
 
Settlements 
Except the northern side the settlements of Hail 
haor are designed as marginal. The northern 
Page 1101
  
 
 
settlements are scattered and can be recognized as 
unplanned invasion by time. These areas (Figure 1) 
are represented by Pale green color in the Landsat 
image. The invasion of human settlement between 
haor wetland areas and the connecting road 
between Upper Kagabata and the Maulvibazar 
sadar are not older than 50 years. As long as going 
inner side of haor areas land conversion took place 
from all sides. Settlements are well vegetated and 
orchards are used as vegetable cultivation and rice 
processing. Big landowners manage their land by 
poorer community, which encourage using more 
land with lower yield of crops rather than 
minimizing agricultural land with higher 
production.  
 
Foothills and Hilly Areas 
Teagardens, major marginal permanent settlements, 
schools, roads, other infrastructures and fellow land 
areas can be encompasses under this ecosystem. 
These areas are well vegetated. Jackfruits, Shimul, 
Koroi and Bettlenuts are dominating vegetation. 
 
Problems Identified 
Conflict between fishers and farmers 
There is conflict between farmer and fisherman. In 
the Boro plantation period farmer wants to remove 
water rapidly, but fisherman created obstacle on the 
river with different fishing gear. So, some time 
plantation has delayed. Project will have to go for 
appropriate measures for resolution of conflicts. 
 
Conflict between farmer and sand traders 
There is conflict between farmer and sand traders in 
the area. Sand traders want more sand from Choras 
for their more profit but some time sand carpeting 
is a very much problematic for farmer in haor area. 
Here it is noted that, now days sand carpeting is 
regular problem than previous time. In the past Hill 
was covered full by different type of bush and tree 
but now it is clean from bush or tree for different 
crop cultivation as a result sand come more and 
more.  
 
Problems remains 
As the work of the project is done in two steps but 
it has been not possible to ensure the internal 
extraction system properly. As a result, flashy water 
from more than 50 Choras of south-west and 
because of rain water in April/May flood occurs 
here. As the water cannot be removed too fast, 
water congestion damages the crop fields. 
Moreover, Water congestion also damages the 
Aman fields. Gopla river is the main outlet of Hail 
haor. Because of the lack of proper maintenances 
the bed of some contributory cannels around the 
haor and Gopla River is being partially clogged 
because of over siltation as a result the capability of 
transportation of water is being reduced. 
Consequently, every year rain water and the flashy 
water from upstream causes water clogging on the 
vicinity of the haor in April/May. 
 
Effects of the projects on local environment 
After surveying the project area and analyzing the 
project activities of Hail haor rehabilitation and 
development project, the effects found on 
environmental factors have been shown in table 1.  
 
Running water management projects have very few 
negative effects on the environment. Hail haor 
rehabilitation and development project (BWDB) 
assures full protection of the residential area of the 
haor area and protection of the agricultural area 
only for a short period of time (Up to harvest of the 
Boro crop). It also helps to Solve the over siltation 
problem as well as causing no harm to the aquatic 
animals. Management of Aquatic Ecosystem 
through Community Husbandry (MACH) does not 
concern with flood protection, it only deals with the 
diversity of the aquatic ecosystem, which has no 
adverse effect of the environment. It also helps to 
provide erosion of the Choras at upstream. It does 
not hamper any natural process. So, through the 
observed water management projects sustainability 
of environment assures in almost all ways. 
 
Present and future scenarios of Hail haor 
If sedimentation continues in Hail Haor at present 
rate, around 75 % of the present dry season water 
area will be reduced by 20 years (figure 2). This 
result is obtained considering the above parameters. 
EGIS lab facilities have been taken to predict the 
future condition. 
 
 
 
Figure 2: Around 75% of the present dry season 
water area will be reduced by 20 years. 
Page 1102
  
 
 
 
 
 
Environmental Component Types of Impact Evaluated Grading 
 
Pr
o
ba
bi
lit
y 
(p)
 
Se
v
er
ity
 
(s)
 
Im
pa
ct
 
V
al
u
e 
(IV
)  =
 
p 
*
 
s 
N
o
 Im
pa
ct
 
Po
sit
iv
e 
Im
pa
ct
 
N
eg
at
iv
e 
im
pa
ct
 
In
sig
ni
fic
an
t 
Lo
w
 
M
ed
iu
m
 
H
ig
h 
ENVIRONMENTAL FACTORS           
Water resource           
Water quality 1 1 1 √   √    
Ferry transportation 3 4 12  √     √ 
Flood protection 5 4 20  √     √ 
Deposition of silt 1 1 1 √   √    
Irrigation 5 5 25  √     √ 
Extraction of flood water 4 5 20  √     √ 
Aquatic resource           
Fish 3 4 12   √    √ 
Fish diseases 1 1 1 √   √    
Human resource related           
Destruction of houses 1 1 1 √   √    
Transportation 4 2 8  √   √   
Educational system (Training) 1 1 1 √   √    
Income from fishing 4 5 20  √     √ 
Status of life 3 5 15  √     √ 
Erosion of soil 1 1 1 √   √    
Employment in agriculture 4 3 12  √     √ 
Different ways to income 4 5 20  √     √ 
Problems           
Destruction of embankment 6 6 36  √     √ 
Destruction of river bank 1 1 1 √   √    
Conflicts between groups 1 1 1 √   √    
Table 1: Checklist for sustainability evaluation (Source: Chowdhuary, 2006) 
 
 
RECOMMENDATIONS 
 
Immediate Measures 
The eroded sediments are carried by the streams 
and ultimately reaching to Haor, filling beels. If this 
process keeps continued for a decade several inches 
of sediment will be pilled up and many beels will 
lose their perennial nature and lose habitats. 
Therefore, sediment intrusion into the Haor will be 
stopped immediately. 
 
Check dam construction: As immediate measures, 
Check Dams may be constructed on some sediment 
carrying streams to accumulate some portion of the 
carrying sediment at a specified location. Check 
dam concept is new in Bangladesh but widely used 
Page 1103
  
 
 
in many countries like Indonesia, Philippines, and 
India. This is also known as sediment storage dam, 
this artificial dam is usually designed to intercept 
and trap waterborne sediment. The dam has a 
principal spillway that allows water to slowly flow 
through, allowing the sediment to settle out. The 
spillway may be in the form of notch or box inlet. 
Already Chhora Resource Management 
Organization (CRMO) has been formed in the Joita 
Chhora reach. So, as an experimental basis, Check 
dams may be constructed on this Chhora. The 
CRMO can manage the check-dam, remove 
sediment each year from the site and earn money by 
selling the sand. Therefore, there are two-way 
benefits from the check dam, rapid sedimentation 
of beels will be slow down and the local people will 
have a source of income (Garg, 1999). 
 
Bank protection: There are some places along the 
stream reach which are vulnerable to bank erosion. 
These skewed portion of the Choras need to be 
protected from erosion immediately. 
 
Long-term Measures  
Check dam and others are not the permanent 
solution of stopping rapid sedimentation. To reduce 
the soil erosion proper watershed management is 
must by the active participation of the community. 
The following measures should be taken. 
 
Riparian plantation: Riparian plantation along the 
Chhora reach will help in dissipate energy of the 
hilly streams by creating obstruction and thereby 
reduce the bank erosion. 
 
Cropping pattern change: Present cropping 
pattern of lemon and pineapple is a major cause of 
soil erosion. Vertical plantation of the pineapple 
will be changed to contour plantation. Already 
MACH has demonstrated a contour pineapple 
garden in Sreemongal, and MACH is receiving 
very positive response from the professional 
pineapple garden owner (BWDB, 2003). 
Upper shed plantation: Upper shed plantation is 
necessary to develop the sub- watershed. 
 
Controlling herbicides use in tea garden: Study 
showed that tea estate has also great contribution to 
present sediment loading. Though the tea land is 
covered with trees, splashing of rain can’t reach to 
the soil, however the soil is beard due to the use of 
herbicides which is extensively being used in the 
tea estate. The use of herbicides should be 
controlled. 
 
Proper use of stream water: Stream is the only 
source of irrigation water in Hail Haor site. Earthen 
dams usually constructed across the stream to pile 
up water at a section and gravitational irrigation is 
done. Therefore, virtually stream flow can’t reach 
up to Haor causing water scarcity in the Haor in the 
dry season. Most of the cases, diversion of water 
continued beyond the actual demand of water. 
Therefore, proper sharing of water is essential 
leaving a portion of water for Haor (CEGIS, 2004; 
NEMAP, 1995). 
 
REFERENCES 
BWDB (2003), Final report part, Integral water 
resource management plan, BWDB, 
Bangladesh. 
 
CEGIS (2004), Inception report, 
Environmental and social studies along with 
stakeholders’ consultation under Haor 
rehabilitation scheme, CEGIS, Dhaka 
 
Chowdhuary, M. S. H. (2006), A study on 
sustainability of environment through water 
management projects of a selected haor (hail 
haor), An undergraduate thesis submitted to the 
Department of Civil & Environmental 
Engineering of Shahjalal University of Science 
& Technology, Sylhet, 2006. 
 
Garg S.K. (1999), Irrigation engineering and 
Hydraulic structures, 7th edition, Khanna 
Publisher, New Delhi 
 
Hossain, A. (2002), Evaluation of surface 
water quality: a case study on Surma river, An 
undergraduate thesis submitted to the 
Department of Civil & Environmental 
Engineering of Shahjalal University of Science 
& Technology, Sylhet. 
 
Hossain, M.H. and Chowdhury, A.H.M.N.R. 
(2003), Risk assessment due to surface water 
quality in Sylhet municipality using GIS.  An 
undergraduate thesis submitted to the 
Department of Civil & Environmental 
Engineering of Shahjalal University of Science 
& Technology, Sylhet. 
 
Hunter, J. W. and Jones, T. (2002), 
Globalization and Sustainable development. 
International review for Environmental 
strategies, 3(1).   
 
MACH (2004), Draft hydrology report, 
Management of aquatic ecosystem through 
community husbandry, MACH, Shrimangal, 
Bangladesh. 
 
NEMAP (1995), National Environment 
Management Plan, Ministry of Environment 
and Forest, Government of the People’s 
Republic of Bangladesh. 
Page 1104
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January, Sylhet, Bangladesh 
Md. Misbah Uddin,  
E-mail: mun_cee@yahoo.co.uk 
IMPORTANCE AND SCOPE OF CONSERVATION OF WETLAND TO 
PROTECT ENVIRONMENTAL DEGRADATION  
 
 Md. Misbah Uddin, Dr. Mushtaq Ahmad  
Department of Civil and Environmental Engineering, Shahjalal University of Science and Technology 
 
ABSTRACT 
 
Wetlands constitute a part of human heritage. It has played a significant role in the development of human 
culture and society. More over it contains very rich components of biodiversity of local, national, and 
regional significance. They also provide habitat for a variety of resident and migratory waterfowl, a 
significant number of endangered species, and a large number of commercially important species. Mangrove 
wetlands are unique environments of floral-faunal assemblages, providing a complex detritus-based food-
web for a number of marine and brackish water organisms. Wetlands in Bangladesh have great importance 
for the country’s economic, industrial, ecological, socioeconomic, and cultural aspects. There are 43 
designated wetlands, and some are under threat from indiscriminate utilization, encroachments and 
reclamation, urbanization and drawbacks from agricultural development, and flood control. Almost 50% of 
the country’s people are directly dependent on wetlands resources. The vast majority of the poor people in 
the wetlands areas are dependent on wetlands resources for their nourishment. Wetlands have potential and 
have been recognized as a driving force for biodiversity conservation and rural socioeconomic improvement. 
Smart-use of wetlands can solve the ecosystems problems in the floodplain areas. A comprehensive analysis 
of the various issues leading to wetlands degradation is made in this study. The country needs an adequate 
interdisciplinary policy and political will to implement it for sustainable management and protection of 
wetlands and ecologically sensitive ecosystems in Bangladesh. Therefore, considering the causes and effects 
of degradation of wetland, a reliable guideline is provided in this study to enhance the conservation measures 
initiated by the Government. 
 
Key words: Wetland; Environment; Degradation; Conservation; Guideline 
 
 
1.  INTRODUCTION 
 
Wetlands are defined as low-lying ecosystems 
where the groundwater table is always at or near 
the surface, including areas of marsh, fen, bog, 
floodplain, and shallow coastal areas (Alam and 
Chowdhury 2003). In other words, wetlands are 
transitional lands between terrestrial and aquatic 
ecosystems where the water table is usually at or 
near the surface or the land is covered by 
shallow water (Mitsch and Gosselink 1986). 
They are neither just land, nor just water. They 
can actually be both at the same time, or 
seasonally aquatic, or terrestrial. To be 
classified as a wetland, the area must have one 
or more of the following attributes: 
i.  at least periodically, the land supports 
plants or animals that are adapted to and 
dependent on living in wet conditions for 
at least part of their life cycle, or  
ii. the substratum is predominantly undrained 
soils that are saturated, flooded or ponded 
long enough to develop anaerobic 
conditions in the upper layers, or  
iii. the substratum is not soil and is saturated 
with water, or covered by water at some 
time.  
The main characteristic of the geography of 
Bangladesh is abundance of water and wetlands. 
Most of Bangladesh lies in the largest delta in the 
world, the Bengal Basin, formed by the Ganges, 
Brahmaputra, and Meghna (GBM) river system 
(Fig. 1). It comprises only 7% of the total GBM 
catchment area (Coleman 1969). The Bengal Basin 
is vast lowland. It is thought that this lowland basin 
was once one of the largest wetlands in the world; 
during the past few thousand years, the wetlands 
have almost all been converted into rice-growing 
areas (Chowdhury 1998). During the monsoon 
season, the total area of wetlands in Bangladesh is 
estimated to be 7–8 million hectares, or about 50% 
of its total land surface (Khan 1993). This includes 
Page 1105
ISBN: 978-984-33-2140-4
  
5.4 million hectares of open and closed lakes on 
floodplains that are inundated every year (Ali 
1990). Ninety percent of wetlands of Bangladesh 
are dependent on flow from three major rivers, but 
are now threatened by diversion of water in India 
from the Ganga–Padma river (Gopal 1995). 
 
Fig-1: GBM Basin 
 
2. OBJECTIVES 
 
The specific objectives of the study are as follows: 
(i) To understand the present ecological 
situation of wetlands in Bangladesh 
and the environmentally sensitive 
ecosystems, economic benefits, and 
its significance in different aspects 
(ii) Provide a guideline to enhance the 
conservation measures of these 
wetlands. 
 
3. METHODOLOGY 
 
This paper is mainly based on primary and 
secondary data. Primary data were collected 
through participatory rural appraisal (PRA), field 
survey, observation, and interview with experts. 
Critical perusals of secondary data included 
relevant books, articles, reports, unpublished theses, 
maps, relevant documents, newspaper cuttings, and 
in situ personal experiences. Collected data were 
critically reviewed and discussions carried out with 
experts and local people. It is believed that the 
management issues of wetlands of Bangladesh have 
been brought together herein. 
 
4. RESULTS AND DISCUSSION 
 
Wetland Resources: 
Wetlands in Bangladesh have great importance for 
the country’s economic, industrial, ecological, 
socioeconomic, and cultural context (Islam and 
Gnauck, 2007a). They contain very rich 
components of biodiversity of all valuable 
ecosystems (Kundzewicz, 2003). This ecosystem 
serves as habitat for a variety of resident and 
migratory waterfowl and endangered and 
commercially important species of national and 
international interest (Nishat, 1993; Islam and 
Gnauck, 2007b,2009a). Wetlands support essential 
natural resources and services, and the people of 
Bangladesh depend on wetlands for fishery and 
agriculture. The fate of Bangladesh, its people, and 
its prospects for sustainable development are 
determined by the association of water and 
wetlands, and they are the central pillar of the 
natural resource base. It is observed that 
communities are most densely settled in and around 
wetlands, and for centuries society adapted a 
culture that maintained a close relationship between 
wetlands nature and human actions.  
 
Wetlands encompass many different habitats, 
including ponds, marshes, and swamps, and are 
ecologically significant areas as they are the 
meeting place of land and water, and are 
themselves wet. Plants and animals that are present 
in wetlands are from both land and water habitats. 
They are very rich depositories of vegetations, 
aquatic plants, reeds, and algae, which make them 
highly productive environments. The flora 
composition is relatively uniform throughout the 
haors, beels, jheels, and baors but dominance varies 
seasonally. Typical wetlands trees are hizal 
(Barringtonia acutangula), tamal (Diospyros 
cordifolia), barun (Crataeva nurvala), madar 
(Erythrina variegata), gab (Diospyros peregrina), 
dumur (Ficus hispida), chalta (Dillenia indica), and 
dehua (Artocarpus lacucha) (Alam and Chowdhury 
2003). Wetlands function as ecotones, transitions 
between different habitats, and have characteristics 
of both aquatic and terrestrial ecosystems. 
 
Values of Wetland: 
Wetlands are the most productive ecosystems, and 
countless species of plants and animals depend on 
them for survival. A high concentration of fishes, 
amphibians, reptiles, birds, mammals, and 
invertebrate species are supported by them (Khan et 
al. 1994). Fishes from wetlands provide the main 
source of protein for the people of Bangladesh. 
Rice cultivated in wetlands is the main food in 
Bangladesh. They also provide important 
ecological functions, socioeconomic services, and 
products, and are important for their ecological, 
socioeconomic, and commercial value. Wetlands 
contain very rich components of biodiversity of 
local, national, and regional significance. Among 
the estimated 5,000 species of flowering plants and 
1,500 species of vertebrates in the country, up to 
300 plant species and some 400 vertebrate species 
are judged to be dependent on wetlands for all or 
part of their lifespan. Wetlands also provide habitat 
for a variety of resident and migratory waterfowl, a 
significant number of endangered species of 
Page 1106
  
international interest, and a large number of 
commercially important species. The inland capture 
fishery is based on the vast freshwater resources, 
with some 260 species of finfishes and 25 
shellfishes (Khan et al. 1994). Wetlands are 
precious for the environment, ecology, and 
biodiversity. They are an integral part of the local 
ecosystem and closely related with local cultures, 
and also support the livelihoods of millions of 
people based on diverse activities such as fishing 
and agriculture. Values of wetlands are increasingly 
receiving attention as they contribute to a healthy 
environment in many ways. The values of the 
wetlands of Bangladesh can be classified into three 
major groups: environmental, economic, and social. 
Storage and recycling of nutrients and organic 
waste, recharge and discharge of groundwater and 
storage of surface water, natural drainage, flood 
control and flow regulation, fish breeding ground, 
and maintaining ecological balance are some 
examples of the environmental value of wetlands. 
Wetlands agriculture, freshwater, fish, wild foods, 
forest resources, agricultural land, and biomass are 
some examples of the economic value of wetlands. 
Transportation, human habitat and settlement, 
research, education, and aesthetic are some 
examples of the social value of wetlands in 
Bangladesh. Table 1 summarizes the overall values                                                                                              
of wetlands of Bangladesh.
 
 
 
Table 1 Values of wetlands in Bangladesh 
 
Category Values 
Environmental Storage and recycling of nutrients and organic waste, storage and discharge of surface 
water, recharge and discharge of groundwater, natural drainage, control of flooding and 
regulation of water flow and water regimes, reduction of water logging and storage of 
flood water, transport of sediments and sediment/toxicant retention, storage and recycling 
of human waste, control of erosion and salinity, purification of water and maintaining the 
water table high and relatively stable, relief of drought and stabilization of climate and 
control of microclimate, stabilization of shoreline and reduction of erosion, reduction of 
sediment and pollutant load, maintenance of soil structure and helping soil formation, 
protection against river bank erosion, helping nutrient retention/removal, protection against 
storm surges, helping carbon sequestration, maintaining ecosystem stability and the 
integrity of other ecosystems, fish breeding grounds, maintaining biological and genetic 
diversity, supporting food chains and habitat for wildlife and protecting wildlife, helping 
pollination, work as ecotones (vital links between land and water), habitats for a variety of 
resident waterfowl and a significant number of endangered species of international interest 
and as internationally important wintering areas for migratory waterfowl, principally ducks 
and shorebirds 
Economic Agricultural activities, crop production, freshwater fish production, provision of forage 
resources, production of wild food, production of vegetables, as agricultural land, 
providing forest resources, supply of irrigation water, helping stock farming, grazing places 
for domestic livestock, helping water duckery, supply of wildlife, supply of fuel wood, as a 
place of primary activities, provision of medicinal plants and genetic resources, provision 
of subsistence-oriented economy and livelihoods, supply of raw materials for building, 
construction, and industrial use, provision of places for industrial and pharmaceuticals 
plants, as places of primary economic activities, as pasture, and as storehouses of plant 
genetic material 
Social For transportation, tourism and recreation, provision of settlement places, help in research 
and education, uniqueness, cultural heritage, cultural value, aesthetic value, heritage value, 
spiritual and inspirational values, bequest value, ecotourism, as leisure or recreational 
place, place of education and amusement, fostering of beneficial rural-urban links, and 
transformation and empowerment of poor user groups as resource managers 
 
Present State of Wetland: 
Since independence there has been an accelerated 
expansion of physical infrastructure in the 
floodplains and haor areas. In recent years, 
decentralization of administration at the Upazila 
(sub-district) level also led to a rapid expansion of 
roads and feeder roads even in the rural areas of the 
haor basins. These infrastructures were often done 
without proper planning or due regard to natural 
water flows. These poorly planed roads and 
drainage structures created water logging and had 
serious impact on the water regimes in the flood 
plains.  
Page 1107
  
Nishat, A. 1993 pointed out that the degradation of 
wetlands in Bangladesh were mainly due to:  
increase of population and expansion of human 
habitats; expansion of agriculture and subsequent 
conversion of wetlands through drainage into rice 
fields; flood control and irrigation project for 
enhancement of agricultural productivity; national, 
local and rural infrastructures like ill-planed roads; 
narrow culvert etc.; over-felling of wetland trees; 
over-grazing by livestock; over-fishing and 
associated disturbances; siltation due to 
degradation of watershed areas which are often 
transboundary in nature; indiscriminate control/ 
regulation / use of water flows of main river 
systems in upper riparian; and pollution of water 
due to industrial, urban, agrichemical and other 
types of pollutants including pollution from 
transboundary sources. 
 
Causes and effects of wetlands degradation: 
Wetlands and their habitats are under constant 
threat due to various causes. Wetlands productivity 
and biodiversity are declining all over the country. 
The overall cause and effect relationships of the 
wetlands degradation of Bangladesh may be stated 
as follows:
 
Causes Effects 
1. Population growth. 
2. Extensive agriculture and urbanization. 
3. Expansion of human habitats in the wetlands. 
4. Land reclamation and expansion of agriculture. 
5. Conversion of wetlands through drainage of water     
bodies in to rice growing fields. 
6. Flood Control Drainage and Irrigation (FCDI) 
projects for enhancement of agricultural productivity 
and control flood. 
7. Ill-planned national, local and rural infrastructure 
like roads, narrow culverts etc. 
8. Lack of institutional coordination among 
infrastructure development authorities. 
9. Lack of awareness and top-down approach during 
project implementation. 
10. Lack of community involvement in Government 
project for management of wetlands. 
11. Over fishing and introduce of alien species and 
extensive shrimp cultivation. 
12. Over-cutting of wetlands vegetations without 
replacement. 
13. Siltation due to the degradation of associated 
watershed areas. 
14. Increased use of fertilizer and pesticides for rice 
monoculture.  
  
1. Change in chemical and physical properties 
of (such as nutrient availability, degree of 
substrate anoxia, soil salinity, sediment 
properties and pH.) 
2. Extinction and reduction of wildlife. 
3. Many species of flora and fauna of 
wetlands are threatened. 
4. Extinction of many indigenous wild and 
domesticated rice varieties. 
5. Loss of many indigenous aquatic plants, 
herbs, shrubs and weeds. 
6. Degeneration of wetland based ecosystem. 
7.  Reduction of fish diversity and depleted 
the resource bases, particularly fisheries of 
many of the fresh water wetlands. 
8. Deterioration of fisheries habitat. 
9. Loss of biodiversity. 
10. Loss of natural water reservoirs and of their 
resultant benefits and increase in the 
occurrence of flooding and loss of natural 
soil nutrients. 
11. Worsen of wetland’s water quality.  
12. Decrease of crops productivity. 
13. Heavy siltation, water logging and 
increased water pollution. 
14. Weakening of wetlands based occupations, 
socio-economic institutions and cultures. 
 
5. CONCLUSION 
 
From the findings of the study, for stopping further 
degradation of the wetland and to enhance the 
conservation measures of wetlands following 
recommendations may be concluded: 
 
(i) For stopping further degradation of 
wetlands: 
• Significance of wetlands in the national, 
zonal and local level planning process 
must be recognized;      
• Sustainable and comprehensive 
agricultural practices and land use patterns 
need to be devised; 
• Functions of selected wetlands be 
rehabilitated; 
• Introduction of sustainable management 
practices at all levels;  
• Technical knowledge, planning and 
management capabilities be enhanced; 
Attention given to awareness, education 
and research aspects. 
Page 1108
  
(ii) Towards proper management of 
wetlands: 
• Wetland mapping and landscape planning 
• Declaration of critical wetlands as 
protected areas, if considered necessary. 
• Identification of problems through PRA 
exercise; conservation and protection 
measures including eutrophication 
abatement, 
• Wildlife conservation and fisheries 
development; 
• Environmental awareness and 
organizational set-up.  
• Develop institutional funding 
arrangements through integrated 
mechanisms at national, regional and 
international levels. 
• Legislation is needed to regulate all 
activities which impact wetlands. 
6. REFERENCES 
 
1. Alam SM, Chowdhury HM (2003) 
Wetland. Banglapedia: National 
Encyclopedia of Bangladesh, Banglapedia 
Trust, Asiatic Society of Bangladesh 
 
2. Ali MY (1990) Open water fisheries and 
environmental changes. In: Rahman AA, 
Huq S, Conway GR (eds) Environmental 
aspects of surface water systems of 
Bangladesh. University Press Ltd, Dhaka 
 
3. BWDB (2007) Perennial and main 
wetlands of Bangladesh. Ministry of 
Water Resources, Bangladesh 
 
4. Chowdhury S (1998) Saving our oceans: 
some thoughts on fisheries conservation. 
The Daily Star, vol 2, No. 100, Dhaka 
 
5. Coleman JM (1969) Brahmaputra river: 
channel processes and sedimentation. 
Sedimentary Geology B129-239 
 
6. GOB (1999) NWP (National Water 
Policy). Ministry of Water Resources, 
Bangladesh 
 
7. Gopal B (1995) Limnology in developing 
countries. vol 1. SILInternational 
Association for Limnology, New Delhi 
 
8. Islam S N, Gnauck A (2007a). Effects of 
salinity intrusion in mangrove wetlands 
ecosystems in the Sundarbans: an 
alternative approach for sustainable 
management. In: Okruszko T, Jerecka M, 
Kosinski K, eds. Wetlands: Monitoring 
Modelling and Management. Leiden: 
Taylor & Francis/Balkema, 315–322 
 
9. Islam S N, Gnauck A (2007b). Salinity 
intrusion due to freshwater scarcity in the 
Ganges catchment: a challenege for urban 
drinking water and mangrove wetland 
ecosystems in the Sundarbans region, 
Bangladesh. In: Proceedings of 
6thWorldWideWorkshop for Young 
Environmental Scientists 2007, Paris. 
Paris: CEREVE Enpc, 20–30 
 
10. IUCN (2007) Community based haor and 
floodplain resource management project 
document. Ministry of Environment and 
Forests, Bangladesh 
 
11. Khan AA (1993) Freshwater wetlands in 
Bangladesh: opportunities and options. In: 
Nishat A, Hussain Z, Roy MK, Karim A 
(eds) Freshwater wetlands in 
Bangladesh—issues and approaches for 
management. IUCN, Dhaka 
 
12. Khan S M, Haq E, Huq S, Rahman A A, 
Rashid S M A, Ahmed H (1994). 
Wetlands of Bangladesh. Dhaka: Holiday 
Printers Limited, 1–88 
 
13. Kundzewicz Z W (2003). Ecohydrology 
for sustainable wetlands under global 
change — data, models, management. In: 
Igner S, Nowakowski P, Okruszko, eds. 
Measurement techniques and data 
assessment in wetlands hydrology. 
Warsaw: Warsaw Agricultural University 
Press, 25–35 
 
14. Mitsch WI, Gosselink IG (1986) 
Wetlands. Van Nostrand Reinhold, New 
York 
 
15. Nishat A (1993). Fresh water wetlands in 
Bangladesh: Status and issues. In: Nishat 
A, Hossain B, Roy M K, Karim A, eds. 
Freshwater Wetlands in Bangladesh — 
Issues and Approaches for Management. 
Dhaka: IUCN, 9–22 
 
16. Nishat A (2003) Management of fresh 
water wetlands in Bangladesh: issues and 
strategy at 
‘‘http://www.doebd.org/cwbmp/inception
_report/grp3_nishat_wetl_use.ppt’’ visited 
on 26 October 2007 
Page 1109
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 
*
 Corresponding Author: S. Islam,  
E-mail: sharif_sust_cee@yahoo.com 
PREDICTION OF FUTURE TEMPERATURE IN NORTH-EASTERN 
REGION OF BANGLADESH BY USING HISTORICAL DATA 
 
 
M. Ahmed, P.C. Das and M.A. Kashem  
Department of Civil and Environmental Engineering, Shahjalal University of Science and 
Technology, Sylhet, Bangladesh 
 
S. Islam* 
Department of Civil Engineering, IUBAT- International University of Business Agriculture and 
Technology, Dhaka, Bangladesh 
 
 
The temperature of the World is increasing day by day. This has a tremendous impact on global climate 
change; Bangladesh is not the exception of this trend, which is revealed from several studies on temperature 
performed in recent years in various parts of the country. This study was conducted using historical data of 
temperature from 1975 to 2007 of north-eastern region of Bangladesh collecting from Bangladesh 
Meteorological Department. The data of average maximum and minimum temperature is analyzed dividing 
the season in two parts: wet season (May to October) and dry season (November to April). The highest 
maximum temperature is 32.1°C in August (wet season) and lowest minimum temperature was found 12.3°C 
in January (dry season). Analyzing the maximum temperature of August and minimum temperature of 
January, it is found that temperature shows an increasing trend and two equations are derived to predict the 
future temperature. The predicted temperature in 2100 for maximum temperature of August and minimum 
temperature of January are 37.62° C and 20.95° C respectively. The results predict that the winter season 
may be abolished and temperature all the year round will be high. 
 
Key words: Climate change; temperature change; north-eastern region; wet season; dry season 
 
1. INTRODUCTION 
 
As a study area North-Eastern region of 
Bangladesh, Sylhet, is very interesting because of 
its natural resources like Tilas (small hills) and 
Hills, jungles, over 150 tea gardens which are 
sensitive to heavy rainfall, nearly 400 Haors of 
around 4,450 to 25,000 km square and its role to 
the ecosystem of that area supporting diverse 
livestock’s including human. This region 
recharging ground water table greatly to keep the 
natural balance through out the country due to 
having rainfall around 5000 mm per year. Sylhet 
region is suffering from regular flash flood, river 
erosion, heat waves, storms, contamination of iron 
and arsenic in ground water. The temperature of 
this region is also increasing due to various reasons 
(Das and Kashem, 2009), which will increase these 
natural calamities. 
 
It is now proved from scientific study that our 
mother climate has undergone an abnormal human 
induced change. This change mainly occurs due to 
change of global temperature.  According to 
Intergovernmental Panel on Climate Change 
(IPCC) global surface temperature increased 0.74 ± 
0.18 °C during the 100 years ending in 2005. It also 
noticed that the rise of mean annual temperature 
will be 3.3 °C per century (IPCC, 2007). The mean 
annual temperature of Bangladesh has increased 
during the period of 1895-1980 at 0.31°C over the 
past two decades (Parathasarathy et al., 1987 and 
Divya and Mehritra, 1995). Another study which 
use the data of 1961-1990 for Bangladesh projected 
that annual mean maximum temperature will 
increase to 0.4°C and 0.73°C by the year of 2050 
and 2100 respectively (Karmakar and Shrestha, 
2000). By using historical data of some selected 
meteorological stations Chowdhury, Debsharma 
(1992) and Mia (2003) also revealed the fact that 
the temperature has been changed in Bangladesh in 
last decades. 
 
The objective of this study is to analyze the changes 
of temperature and derive an equation using 
historical data of temperature to predict the future 
maximum and minimum temperature in the north 
eastern region of Bangladesh. 
Page 1110
ISBN: 978-984-33-2140-4
  
2. METHODS 
 
The data of average maximum and minimum 
temperature from 1975 to 2007 is collected from 
Bangladesh Meteorological Department. The 
average temperature is sorted in two seasons: wet 
season (May to October) and dry season 
(November to April). Separate graphs are drawn for 
average maximum and minimum temperature 
against under the category of dry season and wet 
season. The months of highest maximum and 
lowest minimum temperature are selected from 
these graphs. Then two separate graphs are drawn 
for maximum and minimum temperature for these 
two particular months of maximum and minimum 
temperature for the year 1975-2007. Two equations 
are derived by Microsoft excel for the trend of 
maximum and minimum temperature and the future 
temperature is predicted using these two equations. 
 
3. RESULTS AND DISCUSSION 
 
Fig. 1 and 2 show the average maximum temperature for dry and wet season respectively from 1975 to 2007. 
 
 
 
Fig. 1 Average maximum temperature for dry season (1975-2007) 
 
 
 
Fig. 2 Average maximum temperature for wet season (1975-2007) 
 
From Fig. 1 and 2, it is found that in dry season the 
maximum temperature is highest in April (30.8°C) 
and in wet season it is found in August (32.1°C). 
Again maximum temperature is lowest in January 
(25.7°C) for dry season and for wet season it is 
found in May (30.9°C). It is also found that the 
temperature of wet season is higher than that of dry 
season. The average maximum highest temperature 
of the whole year is found in August which is 
32.1°C and the maximum lowest temperature is in 
January which is 25.7°C. 
Conversely, Fig. 3 and 4 shows the average 
minimum temperature for dry and wet season 
respectively from 1975 to 2007. These figures 
reveal that in dry season the minimum temperature 
is highest in April (21°C) and in wet season it is 
found in May (27.4°C). Average minimum 
temperature is lowest in January (12.3°C) for dry 
season and for wet season it is found in October 
(22.8°C). The So average minimum temperature for 
the whole year is 12.3°C which is prevailed in 
January. Temperature variation during the whole 
year is from 12.3°C to 32.1°C. 
 
 
 
 
0
10
20
30
40
november december january february march april
Te
m
pe
ra
tu
re
 
(°C
)
Month
30
30.5
31
31.5
32
32.5
may june july august september octoberTe
m
pe
ra
tu
re
 
(°C
)
Month
Page 1111
  
 
 
 
 
 
 
 
 
 
 
 
Fig. 3 Average minimum temperature for dry season (1975-2007) 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 4 Average minimum temperature for wet season (1975-2007) 
 
Fig. 5 shows maximum temperature for August and 
Fig. 6 minimum temperature for January from 1975 
to 2007. In the brackets of Fig. 5 and 6 indicate the 
values of variable x. For maximum temperature in 
August the trend line equation of y = 0.052x + 
31.07 is found. Using this equation the maximum 
temperature in August for the future can be 
predicted. In 2020, 2040, 2060, 2080 and 2100 the 
maximum temperature can be predicted as 33.34, 
34.50, 35.54, 36.58 and 37.62° C respectively. For 
minimum temperature in January the estimated 
equation is y = 0.08x + 10.87. Using the equation of 
minimum temperature of January, in 2020, 2040, 
2060, 2080 and 2100 the predicted temperatures are 
14.55, 16.15, 17.75, 19.35 and 20.95° C 
respectively. So, in 2100 the maximum temperature 
will reach to 37.62° C and minimum lowest 
temperature will reach to 20.95° C which indicates 
there will be no winter season if present trend 
continues.
 
 
Fig. 5 Maximum temperature variation for August 
 
0
10
20
30
november december january february march aprilTe
m
pe
ra
tu
re
 
(°C
)  
Month
0
10
20
30
may june july august september octoberTe
m
pe
ra
tu
re
 
(°C
)
Month
y = 0.052x + 31.07
26
28
30
32
34
36
19
75
 
(1)
19
77
 
(3)
19
79
 
(5)
19
81
 
(7)
19
83
 
(9)
19
85
 
(11
)
19
87
 
(13
)
19
89
 
(15
)
19
91
 
(17
)
19
93
 
(19
)
19
95
 
(21
)
19
97
 
(23
)
19
99
 
(25
)
20
01
 
(27
)
20
03
 
(29
)
20
05
 
(31
)
20
07
 
(33
)T
em
pe
ra
tu
re
 
( °° °°C
)
Year (Serial No.)
Page 1112
  
 
Fig. 6 Minimum temperature variation for January 
 
4. CONCLUSION 
 
It is found from the analysis that presently the 
maximum temperature is highest in August and 
minimum temperature is lowest in January. The 
trend line equation of temperature variation reveals 
that the maximum (August) and minimum 
(January) temperature will be 37.62 and 20.95° C 
respectively in 2100. In further study, more than 
one month of maximum and minimum temperature 
should be taken to get more appropriate maximum 
and minimum temperature in 2100. In future, the 
trend of temperature variation may be changed and 
the predicted temperature may be different from the 
actual temperature. 
 
 
REFERENCES 
 
1. Chowdhury, M.H.K. and Debsharma, S.K. 
(1992), “Climate change in Bangladesh – A 
statistical review”, Report on IOC-UNEP 
Workshop on Impacts of Sea Level Rise due to 
Global Warming, NOAMI, held during 16-19 
November 1992, Bangladesh. 
2. Das, P.C. and Kashem, M.A. (2009), 
Temperature variation analysis in North-
Eastern region of Bangladesh, B.Sc. 
Engineering Thesis, Shahjalal University of 
Science and Technology, Sylhet, Bangladesh. 
3. Divya, Mehrotra, R. (1995) “Climate Change 
and hydrology with emphasis on the Indian 
subcontinent”, Hydrologic Sciences Journal, 
40, pp. 231-241. 
4. IPCC (2007), Climate Change 2007: The 
physical science basis: IPCC Working Group I 
Fourth Assessment Report: Summary for 
Policymakers, IPCC, Geneva. 
5. Karmakar, S. and Shrestha, M.L. (2000) 
“Recent climate change in Bangladesh”, SMRC 
No.4, SMRC, Dhaka.  
6. Mia, N.M. (2003) “Variations of temperature 
of Bangladesh”, In Proceedings of SAARC 
Seminars on Climate Variability In the South 
Asian Region and its Impacts, SMRC, Dhaka. 
7. Parthasarathy, B., Sontake, N.A., Monot, A.A., 
and Kothawale, D.R. (1987) “Drought-flood in 
the summer monsoon season over different 
meteorological subdivisions of India for the 
period 1871-1984”, Journal of Climatology, 7, 
pp. 57-70.  
y = 0.08x + 10.87
0
2
4
6
8
10
12
14
1
9
7
5
 (
1
)
1
9
7
7
 (
3
)
1
9
7
9
 (
5
)
1
9
8
1
 (
7
)
1
9
8
3
 (
9
)
1
9
8
5
 (
1
1
)
1
9
8
7
 (
1
3
)
1
9
8
9
 (
1
5
)
1
9
9
1
 (
1
7
)
1
9
9
3
 (
1
9
)
1
9
9
5
 (
2
1
)
1
9
9
7
 (
2
3
)
1
9
9
9
 (
2
5
)
2
0
0
1
 (
2
7
)
2
0
0
3
 (
2
9
)
2
0
0
5
 (
3
1
)
2
0
0
7
 (
3
3
)
T
e
m
p
e
ra
tu
re
 (
°° °°
C
)
Year (Serial No.)
Page 1113
  Proceedings of the Conference on Engineering Research, Innovation and Education 2011 CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
 * Corresponding Author E-mail: ikbal87@yahoo.com  
                   
                       Resource Recovery from Water Treatment Sludge 
                                Husne Ara Moriom,   Md. Ikbal Mahmud*, Salma A. Iqbal 
   Department of Chemical Engineering & Polymer Science, Shahjalal University of science & Technology 
                                                                    Sylhet, Bangladesh 
 
Abstract: 
Due to rapid urbanization and industrialization, number of water treatment plant is increasing day by day. 
Subsequently the production of water treatment sludge is also increasing. And it is becoming a concern to manage 
this huge amount of sludge effectively as it causes many environmental problems. The motto of our research is to 
contribute to the reduction of environmental problem as well as recover the resource from water treatment sludge. 
These sludge contains significant amount of many metals. In this thesis work, we studied with sludge from Arsenic 
Iron Removal Plant (AIRP) of Manikganj. First we determined the amount of arsenic and iron in sludge. Then 
sludge was used incorporate with clay at a definite weight percentage to produce ceramic tiles. Finally we observed 
various parameters like compressive strength, water absorption, firing shrinkage, density and loss on ignition (LOI) 
which are the key factors in using these tiles in various purposes. The tiles made with mixed proportion of sludge (0-
15%) and clay were found to satisfy desired properties and quality. Ultimately this study showed that arsenic and 
iron sludge could be used as raw material for tiles. 
 
Key words:  Water treatment sludge, tiles, compressive strength, firing shrinkage, loss on ignition.
 
Introduction: 
Arsenic is a contaminant of well-known toxicity and 
it is not an uncommon contaminant in groundwater. It 
is the twentieth most abundant element in the earth’s 
crust, fourteenth in seawater and it is the twelfth most 
abundant element in the human body(Cullen & 
Reimer, 1989). Although arsenic is necessary as a 
nutrient to humans in small quantities, it also leads to 
death in chronic intakes. Arsenic contamination of 
the surface and subsurface water has been reported in 
many parts of the world, including South-Western 
Taiwan, Southern Thailand, Inner Mongolia, China, 
West Bengal of India, Bangladesh, and Northern 
Mexico. It is present in many different minerals, the 
most common of which is arsenopyrite. Arsenic is 
also found in the atmosphere. One-third has entered 
naturally, most from volcanic eruption. Organic 
forms of arsenic that may be present in food are less 
toxic to humans; however, inorganic forms of arsenic 
dissolved in drinking water constitute the most 
significant toxicity. Recent studies conducted to 
understand the long term health risks associated with 
ingestion of low levels of arsenic have indicated that 
arsenic in drinking water is more dangerous than 
previously suspected. Therefore, the World Health 
Organization (WHO) and The U.S. Environmental 
Protection Agency (USEPA) promulgated more 
stringent arsenic regulations to minimize these risks. 
Arsenic could be concentrated in liver, kidney, lung 
and skin tissues by ingestion of arsenic in drinking 
water (Bissen & Frimmel, 2003). In Bangladesh 
,ground water is contaminated by As. Thousands of 
people have already have shown the symptoms of 
arsenic  and several millions are at risk. It is also 
evident that  arsenic contaminated water also contain 
ample amount of iron that is also not good for health 
and other purpose. Ferric iron is seldom found in true 
solution in water. Unless they are highly acidic, 
because of formation of insoluble ferric oxide 
hydrate. Different technologies available at present 
,which may offer solution to this menace. Using the 
available (oxidation,  precipitation, absorption onto 
coagulated flocs ,ion-exchange ,membrane 
technique)technologies ,arsenic and iron can be 
removed from drinking water. There is a strong 
demand for environmentally safe reuse of and 
effective disposal methods for iron and arsenic 
contaminated sludge out of water treatment plant due 
to the increasing amount of sludge generated by the 
water treatment plants in Bangladesh. At present, 18 
number of large scale Arsenic and Iron Treatment 
Plant are in Bangladesh (Rouf & Hossain, 2003). As 
the volume of sludge generated continues to increase, 
traditional sludge  disposal methods are coming 
under increasing pressure to change. The sludge 
Page 1114ISBN: 978-984-33-2140-4
                     
disposed during the various water treatment 
processes can be a major concern for water treatment 
plants. Our environment is polluted due to 
uncontrolled disposal of sludge. By taking proper 
steps it can be possible to reduce the pollution of 
surface water, ground water and mainly to make our 
environment pollution free. The use of water 
treatment sludge in various industrial and commercial 
manufacturing processes has been reported in UK, 
USA, Taiwan and other parts of the world. 
Successful pilot and full-scale trials have been 
undertaken in brick manufacture, cement 
manufacture, commercial land application 
(Tay,1987). The mineralogical composition of the 
“water treatment sludge” is particularly close to that 
of clay and shale. This fact encourages the use of 
water treatment sludge in  manufacturing of bricks, 
tiles. In this paper an attempt is taken to find a way  
to use arsenic-iron sludge in ceramic tiles which  has 
some economic values. All the tests were performed 
in the laboratories of the Department of chemical 
engineering & polymer science and the Department 
of Civil And Environmental engineering, Shahjalal 
University of Science & Technology, Sylhet. The 
time of completion of all the testes was  August to 
November,2010. 
Materials and methods: 
The sludge used in this study were the arsenic and 
iron sludge collected from Arsenic And Iron 
Removal Plant (AIRP)  of Manikganj Sadar of 
Manikgang district near the Pourashava office. After 
collecting ,sludge sample were oven dried for 24 
hours  at 105 c and allowed for cooling for 24 hours. 
Then the dried sludge was blended by manual 
blending using a pestle and mortar to reduce the size 
of  large particles. Major chemical composition of the 
sludge  were aluminum, iron, arsenic, nickel and, 
magnesium. Basic physicochemical  characteristic 
including moisture content and pH of arsenic and 
iron was determined by acid digestion with a 
HNO3:HCL volume of ratio of 1:3. 
           The clay sample  of these tiles was collected 
from Khadim Ceramic located at Khadim Nagar in 
Sylhet. Three types of soil are available there. Here 
we use white colored clay soil which is 50% 
Madobpur and 50% Mymensingh clay. Small amount 
of water was added to moisture the powder  and also 
for 
homogenous mixing. Various proportion of sludge 
was mixed with clay soil on basis weight( 
5%,10%,15%).One batch of 100% clay was prepared 
for reference purpose .After complete mixing, the 
samples were fired at 11800 C for 56 hours. By this 
process the samples were gain hardness, strength, 
stability and reduced porosity. At last the samples 
produced were analyzed for various parameter such 
as compressive strength, loss on ignition, firing 
shrinkage and water absorption. 
 
 
                            
                                               
 
 
 
 
 
                                Figure: 
Photography of tiles with varying sludge percentage 
 
Page 1115
                     
                                                    
Result and discussion: 
Sludge property analysis: 
The suitability of arsenic iron sludge were  
determined by analysis of some physical properties 
such as moisture content ,pH etc.Table-2 represent 
the various physicochemical   properties of arsenic 
iron sludge 
Table-1 : Physicochemical properties of  water 
treatment sludge 
 
Serial 
No. 
Physicochemical 
property parameter 
    
Unit                     
                  
Values 
      1   Moisture content     %  79.82 
     2        pH   7.12 
     3       Arsenic mg/g 0.0945 
     4        Iron mg/g  10.12 
 
 
Effect of sludge addition on compressive strength: 
Compressive strength determines the potential for 
application of the tiles. It is usually affected by the  
porosity, pore size, and type of crystallization. 
Compressive strength is usually defined as the failure 
stress measured normal to the bed face of the tiles. 
The compressive strength is the most important for 
assuring the quality of tiles. The result of this test on 
the tile made from clay and sludge mixtures are 
shown in following figure.            Error! Not a 
valid link. 
Figure: Compressive strength of tiles from various 
additions of sludge 
 
 
 
 
 
 
Effect of sludge addition on water absorption: 
 Water absorption means the mass of water absorbed 
by a porous ceramic material, under specified 
condition ,expressed as  a percentage of the of the dry 
material. It  is a  key factor affecting the durability 
and strength of the tiles. Low water absorption 
ceramic tiles are generally referred to as fully 
vitrified, impervious and porcelain. Water absorption 
is calculated from the amount of water absorbed by 
the tiles after immersion in water for 24 hours. 
 
Water absorption (%)=[(W2-W1)/W1]*100% 
 
Where W1 and W2=weight of the specimens before 
and after the immersion. The result of this test is 
graphically shown bellow. 
 
 
 
 
Error! Not a valid link.  
Figure: Water absorption of tiles from various 
additions of sludge 
 
 
 
 
 
 
 
 
 
 
 
Effect of sludge addition on loss on ignition: 
 
Loss on ignition is a test used in inorganic analytical 
chemistry, particularly in the analysis of minerals. 
This test is designed to measure the amount of 
moisture or impurities lost when the sample is ignited 
under the  condition specified in the individual 
monograph. LOI  is consist of strongly heating a 
sample of the material at a specified temperature, 
allowing  volatile substance to escape. This may be 
done in air or inert atmosphere. The LOI is calculated 
as- 
LOI= [(W1-W2)/W1]*100% 
 
Where W1 and W2=weight of the specimen before 
and after sintering respectively. . The result of this 
test is graphically shown bellow.  
                              
Page 1116
                     
Figure: Loss on ignition of tiles from various addition 
of sludge 
 
                                 
 
 
 
Effect of sludge addition on firing shrinkage: 
 
Firing shrinkage  is the key factor for using tiles in 
various purposes. The quality of tiles can be assured 
according to the degree of firing shrinkage. 
The firing shrinkage is calculated as follows- 
 
Firing shrinkage = [(V1-V2)/V1]*100% 
 
Where V1 and V2  are volumes of specimen before 
and after sintering respectively. . The result of this 
test is graphically shown bellow. 
 
 
 
Figure: Firing shrinkage of tiles from various 
additions of sludge.
 
 
 
 
 
Conclusion:  
Based on the experimental program executed in this 
research, and limited on both the tested materials and 
the testing procedures employed, we can conclude 
that tiles can be successfully produced from water 
treatment plant sludge under the conditions, firing 
temperatures, and manufacturing methods used in 
this study. The water treatment plant sludge almost 
resembled the tiles clay in its chemical composition 
but higher sintering temperatures are required. 
Incineration of water treatment plant sludge is needed 
before using in brick manufacturing to evaporate the 
major part of its relatively high organic content, 
which indicated by its high loss on ignition (L.O.I) 
value. The physical properties of sludge tiles can be 
enhanced by the addition of clay, but the maximum 
percentage of water treatment plant sludge, which 
can be used in the mixture, is dominated by the 
practiced firing temperatures. By operating at the 
temperatures commonly practiced in the brick 
factories, 5% was the optimum sludge addition to 
produce tiles. This research evaluates the exact 
proportion of sludge which will not affect the quality 
of tiles. Further study may be conducted to determine 
the strength of tiles at different firing temperature. 
More research works may be conducted to make 
hollow bricks or blocks using the arsenic-iron 
contaminated sludge.  
References:  
% Sludge Vs Firing shrinkage (%)
0
5
10
15
20
25
30
35
0 5 10 15 20
% Sludge
 F
ir
in
g 
sh
ri
nk
ag
e 
(%
)
Series1
Series2
Series3
Sludge (%) Vs Loss on ignition (%)
0
5
10
15
20
25
30
35
0 5 10 15 20
Sludge (%)
Lo
ss
 o
n 
ig
ni
tio
n 
(%
)
Series1
Series2
Series3
Page 1117
                     
1. Personal communication with Md. Rabiul Hasan 
Rony, IC, Q.C department & Shajal Chandra 
Biswash, Industrial Engineer, Khadim Ceramics Ltd. 
 
2. Tay, J.H. (1987), "Bricks Manufactured from 
Sludge”, ASCE Journal of Environmental 
Engineering, , Vol. 113 (2), p. 278-283. 
 
3. Cullen W. R., Reimer K. J. (1989) Arsenic 
speciation in the environment, Chem. Rev. 
 
4. Bissen M., Frimmel F. H. (2003a) Arsenic- a 
review. Part I: Occurrence, toxicity, speciation. 
 
5. Rouf, M. A.; Hossain, M. D., (2003). Effect of 
using arseniciron sludge in brick making. The 
international symposium on fate of arsenic in the 
environment organized by Bangladesh University of 
Engineering and Technology (BUET), Dhaka, 
Bangladesh and The United Nations University, 
Tokyo, Japan with assistance from ITN Centre, 
Bangladesh.
 
Page 1118
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2010 
CERIE 2010, 11-13 January, Sylhet, Bangladesh 
 
*
 Corresponding Author: Dr. Md. Niamul Bari  
E-mail: niamulbari@yahoo.com 
SELECTION OF POTENTIAL STRAIN FOR THE PRODUCTION OF 
CITRIC ACID BY SOLID STATE BIOCONVERSION USING OIL 
PALM EMPTY FRUIT BUNCHES 
 
 
Md. Niamul Baria,b,*, Md. Zahangir Alamb, Suleyman A Muyibib, Parveen Jamalb, 
Abdullah-Al-Mamunb 
 
a Department of Civil Engineering, Rajshahi University of Engineering & Technology, 
Bangladesh 
b Bioenvironmental Engineering Research Unit (BERU), Department of Biotechnology 
Engineering, Faculty of Engineering, International Islamic University Malaysia (IIUM), Gombak, 
50728 Kuala Lumpur, Malaysia 
An investigation was carried out to select the potential strain of Aspergillus niger for the production of citric 
acid from oil palm empty fruit bunches (EFB) through solid state bioconversion (SSB). This study evaluated 
the potentiality of twenty six wild strains of Aspergillus niger which were isolated from sewage treatment 
plant sludge, lemon and orange. Factors considered in the evaluation process were citric acid production, 
sugar consumption and protein content as growth indicator. Two strains of Aspergillus niger, IBO-103MNB 
and IBO-114MNB isolated from orange were found to have great potential with citric acid production 
128.43±6.3 and 140.50±1 g/kg of dry EFB; sugar consumption 63.43±3.4% and 57.29±0.9% of initial sugar 
(50 g/kg of EFB); protein content as growth indicator 26.05±3.7 and 32.93±1.7 g/kg of treated EFB; pH 
evolution of 2.72±0 and 2.64±0 and bioconversion time 4 and 8 days, respectively. Therefore, the strains 
IBO-103MNB and IBO-114MNB can be used as the potential strains for the production of citric acid from 
EFB by solid state bioconversion.  
Keywords: citric acid, solid state bioconversion, wild strain, Aspergillus niger, empty fruit bunches 
1. INTRODUCTION 
Citric acid is one of the largest and most demanded 
fermentation products which is widely used in the 
household, preparation of numerous industrial 
products and many industrial areas such as food 
processing, beverage, cosmetic, pharmaceutical, 
chemical, textile, electroplating industry (Lofty et al. 
2007).  It is also used as a cleaning agent (Lofty et al. 
2007) and for bioremediation of heavy metal 
contaminated soil (Kim and Barrington, 2003). The 
demand for citric acid is increasing by 4-5% every 
year (Pandey et al. 2001) that can only be met 
economically by using less expensive and renewable 
agro industrial residues as raw materials through 
solid state bioconversion with appropriate 
microorganism (Barrington and Kim, 2008).  
The oil palm empty fruit bunches (EFB) as a 
lignocellulosic residue is produced from oil palm 
industries, which are abundantly available in 
Malaysia. The annual production of EFB is more 
than 17 million tones (Chew and Bhatia, 2008) 
which shows a great challenge to the solid waste 
management for its safe, scientific and environment 
friendly disposal. Therefore, oil palm EFB was 
considered to be a potential alternative renewable 
raw material for the citric acid production by solid 
state bioconversion with locally isolated Aspergillus 
niger. Empty fruit bunches (EFB) is a lignocellulosic 
material, which is mainly polysaccharides (lignin 
21.2%, cellulose 49.6% and hemicellulose18%) 
(Tanaka et al. 2006; Khalil et al. 2007). The efficient 
bioconversion of EFB towards the production of 
citric acid through degradation of polysaccharides to 
monosaccharide and its utilization depends on 
potentiality of strain to produce lignocellulolytic 
enzymes and citric acid. In such a situation, a 
microbial mixed culture might be advantageous over 
a single culture to produce the different metabolic 
products through the same bioconversion.  
Page 1119ISBN: 978-984-33-2140-4
 Mixed microbial culture can influence better 
substrate utilization in bioconversion process 
through effective multi enzymatic systems 
(Kubicek, 1992). The symbiotic mixed culture 
improves their colonization on the substrate and 
increases the yield (Duenas et al. 1995). The vital 
and the most important determinants in mixed 
culture are strain compatibility (Duenas et al. 
1995). On the other hand, detrimental results may 
occur with an incompatible association. Therefore, 
this study was undertaken to ascertain the single 
potential strain or potential compatible mixed 
culture of locally isolated A. niger for the 
production of citric acid from EFB as a new 
substrate through solid state bioconversion.  
2. MATERIALS AND METHODS 
2.1 Microorganisms and Inoculum 
A total 26 wild strains of A. niger were isolated, 
purified and identified. A thorough screening 
experiment was carried out for citric acid production 
from EFB and three fungal strains of local isolates A. 
niger IBO-103MNB (IMI396649),  A. niger IBO-
109MNB (IMI396650) and A. niger IBO-114MNB 
(IMI396651) were selected from twenty six isolates 
(Alam et al., 2010). Finally, the best potential strain 
was selected through mixed culture among them. 
The stock cultures were maintained on 3.9% w/v of 
potato dextrose agar (PDA, Mark) slants, sub-
cultured once in a month and stored at 40C. The 
cultures were grown on PDA plates at 320C for 4 
days for inoculum preparation. Plate cultures were 
washed with sterilized distilled water and collected 
in 100 ml Erlenmeyer flask by filtering with 
Whatman No. 1 filter paper. The spores were 
counted by haemocytometer to maintain the 
concentration of inoculum at 1×108 spores/ml.  
2.2 Fermentation Media  
Twenty gram of media containing five gram (25% 
w/w) of major substrate – EFB (particle size ≤1 mm) 
with 1 gm (5% w/w) of sucrose and 1 ml (5% v/w) 
of mineral solution containing NH4H2PO4 (2 g/l), 
KH2PO4 (0.6 g/l), K2HPO4 (0.4 g/l), MgSO4.7H2O 
(0.5 g/l), CaCl2.2H2O (74 mg/l), Ferric acid citrate 
(12 mg/l), ZnSO4.7H2O (6.6 mg/l), MnSO4 (5 mg/l), 
CuSO4.5H2O (1 mg/l) and balance of substrate are 
consisting of water and inoculum..  
2.3 Experimental Design and Procedures for 
Fungal Mixed Culture 
The experiment was carried out to evaluate the 
compatibility/incompatyibility through plate culture 
on PDA and   flask culture with nutrient media. 
Three different strains of A. niger IBO-103MNB, A. 
niger IBO-109MNB and A. niger IBO-114MNB 
were represented as A, B and C, respectively. The 
experiment for fungal mixed culture was designed 
with four combinations of AB, AC, BC and ABC. A 
total of seven experiments (three single cultures and 
four their mixed cultures) were conducted to evaluate 
the potential of single and mixed cultures. The 
parameters observed were mutual growth in plate 
cultures, citric acid production, sugar utilization, 
protein (growth) content in flask cultures. 
2.4 Evaluation of Mutual Growth in the 
Plate Cultures 
The PDA plate culture was carried out to examine 
the compatibility/incompatibility of mixed cultures. 
The spores of each strain were placed at 4 cm apart 
from each other for mixed cultures on PDA plate 
and at the center of the plate for single cultures. The 
PDA plates with mixed culture and single culture 
were incubated at 320C for 7 days. The interactions 
of mixed fungal growth were studied by dual and 
triple direct opposition mycelial cultures. 
Interactions between the opposition colonies were 
visually assessed using a key based on the 
observations of Porter (1924) and Stahl and 
Christensen (1992) which are shown in Table 1.
 
Table 1. Modes of interactions in fungal mixed cultures 
Modes of interactions [Porter (1924)] Modes of interactions [Stahl and Christensen (1992)] 
a. Mutually intermingling growth where both fungi 
grew into one another without any macroscopic 
signs of interactions. 
a. Neutral intermingling – one or both colonies grow 
into the other with no apparent adverse effect on the 
mycelium of either. 
b. (i) Intermingling growth, where the fungus being 
served is growing into the opposed fungus either above or 
below or above and below its colony, and its corollary. 
b. Replacement – one mycelium grows into the other 
and begins to consume and replace it. 
 
b. (ii) Intermingling growth, where the fungus under 
observation has ceased growth and is being over-
growth by another colony. 
c. Deadlock – neither mycelium can enter territory 
occupied by the other 
c. Slight inhibition, where the fungi approached each other 
until almost in contact and a narrow demarcation line, 1-2 
mm, between the two colonies was clearly visible. 
 
d. Mutual inhibition at a distance of >2 mm.  
Page 1120
 The observation and measurement of growth in 
plate culture were carried out after 3 and 7 days. 
The parameters recorded were: growth rate (grown 
individually), maximum colony diameter (grown 
with partner and individually), mycelial growth 
towards the other colony, mycelial growth 
transversely of the other colony, mycelial growth 
away from the other colony. Outcomes of the 
interactions were also recorded at the time while 
the interactions were taken place properly. 
2.5 Evaluation of Strain for Citric Acid 
Production through Single and Mixed Culture  
The experiments were carried out according to 
experimental design in 250 ml Erlenmeyer flask with 
initial moisture content of 70% by weight adjusted 
with mineral solution, distilled water and inoculum. 
The sample was inoculated with 5% spore 
suspension inoculum (1×108 spores/ml) after 
autoclaving at 1210C for 15 minutes. Mixed culture 
of two strains was inoculated with equal 2.5% 
inoculum of each strain and 1.67% inoculum of each 
strain was used for mixed culture of three strains. 
The culture was incubated at 320C for 10 days. 
2.6 Extraction of Citric Acid 
Citric acid was extracted from fermented substrate 
by adding 50 ml (2.5 times of total substrate) 
distilled water and shaking for 1 hour at 150 rpm at 
the room temperature (28±10C). The supernatant 
was collected by filtering with Whatman no. 1 filter 
paper and immediately analyzed to determine the 
content of citric acid.  
2.7 Analytical Methods 
The concentration of citric acid in extraction was 
determined by using spectrophotometer at 420 nm 
using pyridine-acetic anhydride method as suggested 
by Marrier and Boulet (1958). The consumption of 
total sugar during the bioconversion was estimated 
by subtracting the existing total sugar after 
bioconversion from the initial total sugar and sugar 
released from EFB during the bioconversion. The 
existing total sugar was determined by the phenol 
sulfuric acid method of Dubois et al. (1956).  Folin-
Phenol-Reagent method was adopted to analyze 
soluble protein using Bovine Serum Albumin (BSA) 
as standard (Lowry et al. 1951). Biomass was 
estimated by subtracting the initial protein content of 
sample from the protein content of treated sample 
after bioconversion. 
3. RESULTS AND DISCUSSION 
3.1 Evaluation of Mixed Culture on PDA  
The growth rates of cultures grown on PDA plate 
were measured in diameter after 3 days of 
incubation. From the observation, it was found that 
the strains ‘A. niger C’ was first growing with the 
growth rate of 2.43 cm/day. The less growing was 
strain ‘A. niger A’ with the growth rate of 2.20 
cm/day. The growth rate of the strain ‘A. niger B’ 
was found 2.33 cm/day (Table 2). 
Similar growth patterns and interactions were 
observed in all combinations of mixed culture. The 
two fungal strains met with each other and further 
growing ceased after the contact point (case iva). 
None of the situations of (i) mutual intermingling, 
(ii) partial mutual intermingling, (iii) 
inversion/replacement (a: early stage and b: later 
stage) and (ivb) inhibition/deadlock at distance as 
shown in Fig.1 were recorded in any of the mixed 
cultures.   
 
 
 
 
 
 
 
 
Fig. 1. Schematic diagram of interactions between 
two different fungal strains 
   Table 2: Interaction responses of fungal isolates at day 3 and 7 grown on PDA plate  
 
The growth of the strain ‘A. niger A’ towards and 
transverse directions of the strain ‘A. niger B’ were 
4.2 and 6.6 cm after 3 days (Table 2, Fig. 2). 
Similarly, growth of ‘A. niger B’ towards and 
transverse directions of ‘A. niger A’ were 4.8 and 
7.2 cm at the same day. The antagonistic (inhibition 
Fungal 
culture 
Day 3 Day 7 
Diameter (cm) Gap  Outcomes 
 
diameter (cm) Gap  Outcomes 
Towards Transverse Towards Transverse 
A+B 4.2+4.8 6.6+7.2 No No 4.2+4.8 Full plate No No 
A+C 4.2+4.8 6.6+7.3 No No 4.2+4.8 Full plate No No 
B+C 4.45+4.55 7.1+7.3 No No 4.45+4.55 Full plate No No 
A+ 
B+ 
C 
3.2, 3.3 
3.6, 3.8 
3.6, 3.9 
3.5 
4.1 
4.3 
No No 3.2, 3.3 
3.6, 3.8 
3.6, 3.9 
Full plate 
Full plate 
Full plate 
No No 
i ii iii(a) 
iii(b) iv(a) iv (b) 
Page 1121
 or deadlock) behaviour to each other at the contact point appeared.  
 
 
 
 
 
 
 
 
 
 
 
 
 
Fig. 2. Mixed cultures of A. niger (A+B, A+C, B+C and A+B+C) grown on PDA plate for 3 day 
In the second combination, the growth of ‘A. niger 
A’ towards and transverse directions of the ‘A. 
niger C’ were same as that of the first combination 
with ‘A. niger B’ (Table 2, Fig. 2). In case of ‘A. 
niger C’, growths were 4.8 and 7.3 cm towards and 
transverse directions of ‘A. niger A’ respectively 
after 3 days. Here again antagonistic (inhibition or 
deadlock) behaviour to each other at the contact 
point was observed.  
Almost same growths (4.45 and 4.55 cm) were 
observed between ‘A. niger B’ and ‘A. niger C’ 
towards each other, but in transverse direction it 
was 7.1 and 7.3 cm respectively after 3 days (Table 
2, Fig. 2). Similar antagonistic (inhibition or 
deadlock) behaviour was exhibited to each other at 
the contact point. The antagonistic (inhibition or 
deadlock) behaviours to each other at the contact 
point among the three strains were very pronounced 
when they were cultured in a same plate (Table 2, 
Fig. 2). It was also observed that there was no 
secretion appeared in the contact points of the 
mixed cultures.  
3.2 Evaluation of Compatible/Incompatible 
of Mixed Cultures through Citric Acid 
Production  
The production of citric acid by single culture of A. 
niger (A), A. niger (B) and A. niger (C) and their 
mixed cultures were observed to evaluate the 
compatibility (Fig. 3). The maximum production of 
citric acid was 181.25±1.5 g/kg of dry EFB obtained 
by single culture of A. niger (C) after 8 days of 
bioconversion followed by other single cultures of A. 
niger (A) and A. niger (B) after 6 days of 
bioconversion as well as their mixed culture 
combinations of BC, AC, ABC and AB in 
decreasing order after 4, 8, 8 and 6 days of 
bioconversion respectively. It was observed that the 
combination BC produced higher citric acid 
compared to the mixed culture of all combinations.  
 Fig. 3. Production of citric acid by single and 
mixed culture 
The highest production of 95.26±1 g/kg from third 
combination BC was 92% and 52% of their 
individual production, respectively. Again, the 
production of citric acid by the combination AC 
and BC was nearly the same and 1.6 and 1.7 times 
higher than the production by the combination AB. 
It revealed that the presence of the strain A. niger C 
in any combination produced more citric acid. This 
is due to might be its in higher production 
capability that also observed in its single culture.  
The rate of citric acid production varied from 17.3-
25.4 g/kg-day and 9.50-23.81 g/kg-day among the 
single cultures and mixed cultures respectively. The 
maximum rate of citric acid production was 25.40 
g/kg-day obtained from the single culture of strain 
A. niger C, while second highest rate of citric acid 
production was 23.81 g/kg-day obtained from the 
mixed culture combination BC. The yield of citric 
acid production on the basis of sugar consumption 
for A. niger (A) was 89.5% which was more than 
the yield obtained (85%) by Prado et al. (2005b) 
from cassava bagasse. 
 
0
40
80
120
160
200
0 2 4 6 8 10 12
Ci
tr
ic
 
ac
id
 
(g/
kg
) .
Fermentation time (day)
A B C AB
AC BC ABC
Fr
o
n
t v
ie
w
 
B
ac
k 
v
ie
w
 
In
hi
bi
tio
n
/d
ea
dl
o
ck
 
at
 
co
n
ta
ct
 
po
in
t 
In
hi
bi
tio
n
/d
ea
dl
o
ck
 
at
 
co
n
ta
ct
 
po
in
t 
A B A C C B 
B 
A C 
Page 1122
 3.3 Consumption of Sugar 
Utilization of substrate is an important parameter 
for the evaluation of microbial potentiality to 
produce the product. At the beginning of the 
bioconversion, total sugar was 272 g/kg of dry 
EFB. Sugar consumptions by the single cultures 
varied from 23.6 to 37.1, 66.2 to 111.1, 139.4 to 
151.4, 154.2 to 184.4, 158.6 to 162.2 and 166.3 to 
174.3 g/kg of dry EFB after 1, 2, 4, 6, 8 and 10 
days of bioconversion respectively while it was 
varied by the mixed cultures from 41 to 58, 78.5 to 
87.9, 134.3 to 147.7, 164.1 to 191.4, 162.6 to 176.5 
and 174.1 to 189.2 g/kg of dry EFB with similar 
bioconversion period, respectively (Fig. 4).  
 
Fig. 4. Consumption of sugar during the 
bioconversion of EFB for citric acid production 
 
It was observed that the consumption of sugar by 
the mixed cultures was almost 1.5-2 times higher 
that the single cultures on day 1 of bioconversion. 
On the other hand, sugar consumptions were 
comparatively higher by the single cultures on day 
2 of bioconversion. However, sugar consumption 
for both the single cultures and mixed cultures were 
almost same on the other days of bioconversion 
except on 6 day of bioconversion by the mixed 
culture combination AC.  
The consumption of sugar was very high within the 
first 2 days compared to those of 4, 6, 8 and 10 
days of bioconversion. These phenomena could be 
explained by the fact that initially more sugar might 
be needed for initial fungal growth and the 
metabolism (Kumar et al. 2005). Furthermore, the 
rates of consumption of sugar were 23.38, 30.73 
and 17.43 g/kg-day by the single cultures of strain 
A. niger (A), A. niger (B) and A. niger (C), 
respectively. On the other hand, the consumption 
rates varied from 17.68 to 18.92 g/kg-day for the 
mixed cultures except for the combination AC. The 
mixed culture combination AC consumed sugar at 
the highest rate of 31.90 g/kg-day.  
 
3.4 Protein Content as Growth Indicator 
One of the most important factors of solid state 
bioconversion with filamentous fungus, both in 
laboratory and industrial scale, is the estimation of 
biomass. It is known that growth limitation is an 
important factor in citric acid production (Prado et 
al. 2005). In fact, there is no direct method to 
determine the fungal growth in SSB. However, 
protein measurement is a simple indirect method 
for the estimation of fungal growth (Raghavarao et 
al. 2002). 
Fig. 5 shows the protein content as fungal growth 
indicator in treated substrate during the solid state 
bioconversion. The maximum fungal growth in 
terms of protein content was observed for both 
single and mixed culture during 4 to 6 day of 
bioconversion. The maximum protein content of 
34±0.3 g/kg of dry treated EFB was obtained for A. 
niger (A) after 6 days of bioconversion. The results 
showed that the growth indicated by the protein for 
all the treatments was found in similar trend of 
batch growth pattern. The growth of single cultures 
was almost 1.5 times higher than the growths of 
mixed cultures which correlated the production of 
citric acid (Fig. 3 and 5). It was also observed that 
the lag phase was within 0-1 day and exponential 
phase of growth was within 1-2 day in terms of 
protein content.  
Fig. 5: Protein content as growth indicator in 
treated EFB 
4. CONCLUSIONS 
The result obtained in this study through plate 
culture indicated that all the combinations of fungal 
strains did not grow mutually intermingling, rather 
grow as inhibition/deadlock at the contact point. 
The results of flask cultures showed that the 
production of citric acid reduced by the mixed 
cultures compared to the single cultures due to their 
antagonistic effect during bioconversion process. 
Therefore, the single culture of A. niger (A) and A. 
niger (B) which have shown superiority with higher 
productivity would be potential for citric acid 
production from EFB through solid state 
0
50
100
150
200
250
300
0 2 4 6 8 10 12
R
em
ai
n
in
g 
su
ga
r 
 
 
 
 
 
 
 
(g/
kg
 
o
f E
FB
)   
 
 
 
 
 
 
Bioconvertion time (day)
A B C AB
AC BC ABC
0
5
10
15
20
25
30
35
40
0 2 4 6 8 10 12
Pr
o
te
in
 
co
n
te
n
t (
g/k
g) 
.
Bioconversion time (day)
A B C AB
AC BC ABC
Page 1123
 bioconversion and production could be enhanced 
with further process development.  
5. ACKNOWLEDGEMENTS 
The authors are grateful to the Department of 
Biotechnology Engineering, International Islamic 
University Malaysia for their support, and to the 
Ministry of Science, Technology and Innovation 
(MOSTI), Malaysia, for financing the research 
project (No. 02-01-08-SF0050).   
6. REFERENCES 
1. Alam, M.Z., Bari, M.N., Suleyman, A.M., 
Jamal, P., Mamun, A.A. (2010). Solid state 
bioconversion of oil palm empty fruit bunches 
for production of citric acid by wild 
Aspergillus niger, Food Biotechnol. 24: 19-36. 
2. Barrington S, Kim J-W (2008) Response 
surface optimization of medium components 
for citric acid production by Aspergillus niger 
NRRL 567 grown in peat moss. Bioresour 
Technol 99: 368–377. 
3. Chew, T.L. Bhatia, S. (2008) Catalytic 
processes towards the production of biofuels in 
a palm oil and oil palm biomass-based 
biorefinery.  Bioresource Technology 99: 
7911-7922. 
4. Dubois M, Gilles KA, Hamilton JK, Rebers 
PA, Smith F (1956) Colorimetric method for 
determination of sugars and related substrates. 
Anal Chem 28: 350-356. 
5. Duenas R, Tengerdy RP, Gutierrez-Correa M 
(1995) Cellulase production by mixed fungi in 
solid-substrate fermentation of bagasse. World 
Journal of Microbiol & Biotechnol 11: 333-337. 
6. Khalil HPSA, Hanida S, Kang CW, Fuaad NAN 
(2007) Agro-hybrid Composite: The Effects on 
Mechanical and Physical Properties of Oil Palm 
Fiber (EFB)/Glass Hybrid Reinforced Polyester 
Composites. Journal of reinforced plastics and 
composites 26(2): 203-218. 
7. Kim J-W, Barrington SF (2003) Optimal 
Glucose Level for Citric Acid Production by 
Aspergillus niger NRL 567 for Soil Heavy 
Metal Bioremediation. The Canadian Society 
for engineering in agricultural, food, and 
biological systems. 03-348. 
8. Kubicek CP (1992) The cellulase proteins of 
Trichoderma reesei: structure, multiplicity, mode 
of action and regulation. Advance Biochem Eng 
and Biotechnol 45: 1-27. 
9. Kumar D, Jain VK, Shanker G, Srivastava A 
(2005) Utilization of fruit waste for citric acid 
production by solid state fermentation. Process 
Biochem 38: 1725-1729.  
10. Lofty WA, Ghanem KM, El-Helow ER (2007) 
Citric acid production by a novel Aspergillus 
niger isolate: II. Optimization of process 
parameters through statistical experimental 
designs. Bioresour Technol 98: 3470-3477. 
11. Lowry OH, Rosebrough NJ, Farr AL, Randall RJ 
(1951) Protein measurement with the Folin 
Phenol Reagent. J of Biolog Chem 193: 265-275. 
12. Marrier JR, Boulet M (1958) Direct 
determination of citric acid in milk with an 
improved, pyridine acetic anhydride method. J. 
Dairy Sci 41: 1683. 
13. Pandey A, Soccol CR, Rodriguez-Leon JA, 
Nigam P (2001) Production of Organic Acids by 
Solid-State Fermentation. In: Solid-State 
Fermentation in Biotechnology – Fundamentals 
and Applications, Asiatech Publishers Inc., New 
Delhi, India 113-126. 
14. Porter CL (1924) Concerning the characters of 
certain fungi as exhibited by their growth in the 
presence of other fungi. American Journal of 
Botany 11: 168-188. 
15. Prado FC, Vandenberghe LPS, Soccol CR 
(2005) Relation between citric acid production 
by solid-state fermentation from cassava 
bagasse and respiration of Aspergillus niger 
LPB21 in semi-pilot scale. Brazilian Archives 
of Biology and Technology 48: 29-36. 
16. Raghavarao KSMS, Ranganathan TV, Karanth 
NG (2002) Some engineering aspects of solid-
state fermentation. Biochem Eng J 13: 127-135. 
17. Stahl PD, Christensen M (1992) In vitro 
mycelial interactions among members of a soil 
microfungal community. Soil Biology and 
Biochem 24: 309-316. 
18. Tanaka R, Yutaka M, Akihiko K (2006) 
Utilization of Oil Palm Empty Fruit Bunches 
as ‘Solid Materials’. 3rd Biomass WS 2006. 
Page 1124
 
Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
* Corresponding Author: M. S. A. Amin  
E-mail: msaamin-cep@sust.edu  
TECHNO-ECONOMICAL EVALUATION OF WATER FILTRATION 
SYSTEM BY USING LOCAL INGREDIENTS 
 
 
 
M.A. Islam, M.S.A.Amin*, M.S.Rahman, A.I.H.Laskar, M.A. Khan, A. Khan 
Center for Environmental Process Engineering 
Dept. of Chemical Engineering and Polymer Science 
Shahjalal University of Science and Technology 
Sylhet-3114, Bangladesh 
 
This paper presents the findings of a comprehensive evaluation for the water supply system of an urban 
building to remove iron from storage water. An integrated filtration system was introduced by using locally 
available materials for the drinking and washing purpose and academic building ‘B’ of Shahjalal University 
of Science and Technology was selected as a model object. The technical target was to reduce iron to 
standard iron level. The cost calculation was based on the analysis of its several components such as 
construction materials and their respective quantities, required mechanical equipment, energy consumption, 
chemical consumption and operational and maintenance expenses. This integrated filtration system was 
compared to the traditional unitary filtration system and all pecuniary flows were converted into local market 
price. The result provides a first level of estimation, which could be utilized for a quick financial evaluation 
of the similar systems as well as the general decision making plan. 
 
KEYWORDS: Ground water; Iron removal; Cost 
 
1. INTRODUCTION 
 
Iron is a harmless, though sometimes annoying, 
element present in public and private water supplies 
which is categorized under the secondary standards 
of pollutants in water according to Environmental 
Protection Agency (EPA). The conscious people 
now-a-days use general filter which is described as 
unitary filtration system here, is not totally out of 
risk as the water undergoes heat treatment (boiling) 
and this water can form bacteria on the filtration 
medium which annihilates the purpose of safe 
water. Standard Secondary Maximum Contaminant 
Level (SMCL) of iron is 0.3 milligrams per liter 
(mg/L) for drinking water (Colter and Mahler, 
2006). Though the concentration of iron varies in 
the range of 0.5-3 mg/L around the Sylhet city, the 
concentration is >1 mg/L in Shahjalal University of 
Science and Technology (SUST). The objective is 
to find a way to reduce the iron concentration to 0.3 
mg/L and to do so; we proposed an integrated 
filtration system which is unique in perspective of 
SUST.  We projected the system anticipating that it 
will be capable of filtering 2500 liters serving 500 
people for drinking and washing purpose per day (5 
liters per person per day) (Garg, 2004). At the end 
we also performed an approximate cost analysis to 
compare this system with the prevailing unitary 
filtration systems. 
 
 
2. PROPOSED IDEA 
 
The idea of this system is based on minimal 
operating cost and power consumption. The system 
constitutes four tanks, 
i) Sedimentation tank 
ii) Filtration tank 
iii) Disinfection tank and 
iv) Storage tank 
 
2.1 Sedimentation tank: 
 
The inlet water comes from the water reservoir due 
to gravitational force through a control valve and a 
nozzle. The purpose of the former is to control the 
flow rate and later is to aerate the water. Baffles are 
used to increase the aeration time. We can use the 
Stokes’ equation to determine the settling velocity 
assuming that the particle diameter is 0.05 
millimeter and the average specific gravity of the 
particle present in the water is 2.65 gm/cm3 (ASAE 
data, 1984). For these conditions, we find settling 
velocity 13.2 cm/min. As we know, for the 
Page 1125ISBN: 978-984-33-2140-4
  
sedimentation purpose, settling velocity should be 
greater than over flow velocity. In engineering 
practice, overflow velocity is assumed maximum 
80% of the settling velocity (Garg, 2004); thus 
overflow becomes 5cm/min.m2. We take detention 
time 20 minutes as the 75 microns diameter 
particles settle in 5 to 10 minutes (Haman, 1984). 
After the sequential calculations, we find the 
approximate length 1m, height 0.4 m (including 
sludge zone) and a width of 0.25m. 
 
 
 
 
 
 
 
 
 
 
 
 
2.2 Filtration tank: 
 
Sedimentation removes a large percentage of 
suspended particles; nonetheless the resultant water 
will not be pure and may contain fine particles and 
impurities. To produce potable water, the water is 
filtered through the beds of fine granular materials 
(filters). In this system, water flows from the 
bottom to the top of the tank which is exceptional 
from the conventional filtration system, with the 
intention that the iron precipitates, co-joining with 
the iron particles on its way of deposition will form 
floating coagulation and will accelerate the rate of 
deposition. It is also beneficial in a way that the 
iron precipitates can be removed easily from the 
tank using the discharge valve. When the water 
exits filtration tank, it is almost iron free and can be 
used in washing purpose. 
As the requirement of water is low (104 liter/hour), 
we used ‘slow sand filter’ system, as the rate of this 
type of filtration is 100-200 liters per hour per sq 
meter (Garg, 2004). This filtration process is 
attributable to mechanical straining, flocculation 
and sedimentation in the voids of filter and 
biological metabolism. The filtration rate diverges 
with the type and size of particles which should be 
experimental. Assuming the filtration rate 200 liter 
per hour per sq meter and the bed height 0.5 m, the 
required surface area for the demand of 2500 liter is 
0.52 m2 and the length and breadth is 0.72 m 
(assuming they are equal). 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
The stone chips are kept 30-40 mm at the bottom, 
15-25 mm in the middle and 3-5 mm at the top. As 
the water flows from bottom to top, a space of 0.3 
m is kept both at the bottom and top of the filter 
bed at the filtration tank and thus the height of the 
unit is 1.1 m. The service life of filter bed is based 
on experimentation and should be done in 
laboratory scale. 
The sludge produced is rich in iron content, which 
can be used for arsenic removal.  
 
2.3 Disinfection tank: 
 
Disinfection tank comprises a disinfection unit and 
a storage tank. The water inflowing this tank is 
almost free from iron as most of the iron was 
separated as colloidal particles in the filtration tank. 
We used a traditional disinfection unit consists of 
ceramic material in semicircular shape which is 
available in local markets. The disinfection unit has 
a dimension of 0.68 m × 0.68 m × 0.3 m, where 72 
 
Reservoir 
Valve: 2 
Valve: 
3 
Valve: 4  
 
800 liter 
2000 liter 
d 
d 
d d 
Drinking 
Water 
Valve: 1 
 
Reservoir 
Figure: Schematic diagram of the proposed integrated filtration system 
a)Sedimentation Tank; b)Filtration Tank; c)Disinfection Tank; d)Storage Tank 
Page 1126
  
semi-circular ceramic filter balls (diameter 4.5 cm 
and height 6 cm) are placed onto a fixed surface in 
two independent stages. The filter balls and the 
disinfection unit can be removed individually 
which permits easy replacement for former and 
mobility for the later. These filters even block the 
penetration of bacteria. 
This tank should not be exposed to direct sunlight 
as it tends to form algae and pathogen of cholera. 
After completing the disinfection period the water 
is totally pure and safe to drink. 
 
2.4. Storage tank: 
 
The water found from the filtration tank is almost 
free from iron and can be utilized for washing and 
household purposes. Based on the consumption of 
2500 liters, we assumed 750 liters will be used as 
drinking purpose and the rest (1750 liters) will be 
used as washing and household purpose, which will 
go directly to the storage tank from the filtration 
tank. 
 
 
3. OPERATING SCHEDULE 
 
The maneuver of the system is simple and based on 
manual controlling. Controlling system consists of 
four control valves. The operation of the valves is 
time centric and the cycle of the operation is based 
on our university office hour as far as the labor cost 
concern. Valve 1 controls the flow of the water to 
the sedimentation tank from the reservoir. Valve 2 
and valve 3 control the flows to the storage tank 
and disinfection unit respectively. At 9:30 am valve 
2 is closed and valve 3 remains open until 5 pm, 
which delivers water to the disinfection unit. At 5 
pm, valve 3 closes and valve 2 remains open until 
9:30 am next morning, and the time being water 
flows from the filtration tank to the storage tank 
directly. At 9:30 am, valve 2 closes and valve 3 
opens again. The water of the storage tank is 
pumped to the supply system by a 1.5 HP pump. 
An additional Valve 4 controls the water flow from 
storage tank to distribution unit, in cases of water 
level in disinfection unit is lowered and starting the 
operation at disinfection unit. 
 
 
4. COST ANALYSIS 
 
The project evaluation was based on the following 
assumption: 
 
Project life: 20 years 
 
 
4.1. Initial Fixed Investment: 
 
4.1.1. Land 
Total Area = 12 Sq m 
Construction Area = 10 Sq m 
Open Space = 2 Sq m 
Cost of Land = Not applicable for present model 
(provided by university) 
 
4.1.2. Constructional Cost 
 
 Cost of concrete tank per m3 = Tk 9,000 
Cost of plastic tank per liter capacity = Tk 7.2 
 
Types  Total cost 
 
Sedimentation tank 
 
Tk 6,000 
Filtration tank Tk 5,500 
Storage tanks (two 
pieces) 
Reservoir  
Tk 20,160 
 
Tk 20,000 
    
4.1.3. Cost of Machineries and Equipments 
 
Types 
 
Quantity 
 
Total cost 
 
Disinfection 
unit (ceramic 
balls) 
 
72 
 
Tk 14,400 
Filter bed 1 Tk 5,000 
Piping and 
fittings 
 Tk 6,500 
Valves 4 Tk 1,000 
Pump 1 Tk 7,500 
 
4.1.4. Others                                      Tk 6,000 
 
Total Initial Fixed Investment = Tk (6,000 + 
5,500+20,160+20,000+14,400+5,000+6,500+1,000
+7,500+6,000) = Tk 91,560 
 
4.2. Operating Cost 
 
The operating cost components and their costs are 
given below. 
 
4.2.1. Raw material Cost: Not applicable 
 
4.2.2. Cost of other inputs 
 
Labor cost Not applicable (University 
operator will be assigned) 
Electric power/month Tk 50 
Electric power per 
annum 
Tk 600 
Stone chips Tk 200 
 
Total cost per annum = Tk (600 + 200) = Tk 800 
Page 1127
  
4.2.3. Maintenance Cost at 10 percent of Sale Price 
of Supplier per annum 
 
Filter balls Tk 1,440 
Pumps Tk 750 
Total maintenance cost Tk 2,190 
 
4.2.4. Depreciation 
Not applicable 
 
Total operating cost per annum = Tk (800 + 2,190)       
= Tk 2,990 
 
4.2.5. Expenditure in the base year 
 
Initial fixed investment Tk 91,560 
Operating cost Nil  
 
4.2.6. Expenditure in Future Years 
      
In future, no investment in terms of machinery and 
equipment will be involved. Operating cost as in 
the first year of operation will be there in all years. 
 
4.3. Benefits 
 
The benefits were calculated on the basis of the 
following data: 
 
Volume of water processed per batch = 750 liter 
Volume of water processed per annum = 750 
liter×300(batches) = 225,000 liter 
Fixed cost return per annum = Total fixed cost / 
Desired life time = 91,560 / 20 = Tk 4,578 
Total operating cost per annum = Tk 2,990 
Cost of processed water per liter = Tk (4,578+ 
2,990) / 225,000 liter = Tk 0.034 
 
 
5. COMPARISON 
 
Though the initial set up cost is huge compared to 
the unitary filtration system used in domestic 
purpose, regarding the service life and amount of 
water to be treated, this system is much more 
competent than the traditional system. As the 
economical comparison not only depends on the 
monetary matter but also on socioeconomic and 
health issues, this system provides much 
beneficiation in those sectors. 
 
 
6. REFERENCES 
 
1. ASAE data, 1984 
2. Colter, A., and Mahler, R.L. (2006), Iron 
in drinking water. 
3. Garg, S.K., Water Supply Engineering 
(2004). 
4. Haman, D.Z. (1984), ‘Settling basins for 
trickle irrigation in Florida’ paper 
presented in Institute of Food and 
Agricultural Sciences, University of 
Florida, May, 1989. 
5. Khan, M.R. (2007), ‘Techno-economic 
evaluation of Chromium recovery pilot 
plant installed at Kasur Tanneries 
Complex, Pakistan’, The Pakistan 
Development Review, 46 : 4 part II 
(Winter 2007), pp. 1155-1166. 
Page 1128
 Proceedings of the 
Conference on Engineering Research, Innovation and Education 2011 
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh 
*
 Corresponding Author: Dr. Md. Monirul Islam  
E-mail: rs_gism@yahoo.com 
VULNERABILITY ANALYSIS OF BANGLADESH DUE TO 
MULTIPLE NATURAL HAZARDS USING GIS TECHNIQUE 
 
Dr. Md. Monirul Islam* and Md. Abu Hashnat Badsha   
Department of Civil Engineering, IUBAT−International University of Business Agriculture and 
Technology, 4 Embankment Drive Road, Uttara, Dhaka 
 
 
Bangladesh is one of the most natural disaster prone areas in the World. The different types of disasters like 
flood, cyclonic storms, tidal surges, droughts, tornadoes, riverbank erosion, earthquake, etc. occur frequently 
in Bangladesh. Identifying the vulnerable areas with reference to natural hazards causing damage to the 
housing stock and the related infrastructure are most important for infrastructures development.  
In this study, four natural hazards which are the most common for damaging in Bangladesh, namely 
earthquake, cyclones, tornadoes and floods are considered to develop the district wise map on the basis of 
combination of local hazard intensity and vulnerability on observed performance. Risk analysis as indicated 
in the district-wise are trying to be identified.  
 
This study will find out the disaster prone areas of Bangladesh and also the damages, history, severity of 
these areas, intensities of those natural disasters and housing vulnerability. GIS based disaster database is 
very crucial and an important aspect for environmental management strategy for planning and disaster 
mitigation, preparedness and preventive actions. The information will assist the environmental management, 
different field of sciences such as engineering, agriculture, fisheries, and policy making and planning of 
Bangladesh and should be an integral part of the whole process of economic and social development in 
Bangladesh. The findings of this study would be beneficial for engineers and city planners. They constitute a 
fundamental means which should guide officials at the national and regional levels in the formulation of 
development strategies in multi-hazard active zones, land use management, revision and enforcement of 
appropriate building codes and formulation of plans for mitigating measures against hazard risks affecting 
the region considered. 
 
Keywords: Tornado, Earthquake, Cyclone, Flood and Natural Hazards 
1. INTRODUCTION 
 
Bangladesh is one of the most natural disaster 
prone areas in the World. The different types of 
disasters like flood, cyclonic storms, tidal surges, 
droughts, tornadoes, riverbank erosion, earthquake, 
etc. occur frequently in Bangladesh. The most 
devastating cyclones and floods of the world 
occurred in Bangladesh. The 1988 flood killed 
1517 people and nearly half of the population was 
affected (Islam & Sado, 2002). The 1970 cyclone 
killed almost 500,000 people. About 1300 people 
were killed by tornado at Saturia of Manikganj 
district in Bangladesh in 1989 (EIA, 2004). The 
1897 Great Indian Earthquake with a magnitude of 
8.7, which was one of the severe damaged 
earthquakes in the world, killed 1542 peoples and 
affected almost the whole of Bangladesh. Crop and 
livestock losses were extremely high.  
 
Major factors responsible for disasters in 
Bangladesh are flat topography, rapid run-off and 
drainage congestion, low relief of the floods plains, 
low river gradients, heavy monsoon rainfall, and 
enormous discharge of sediments, funnel shapes 
and shallow Bay of Bengal etc. 
 
Cyclones and floods are the major disasters in 
Bangladesh. But other disasters are also creating 
severe damages. Drought leaves a permanent 
damage and encourages the desertification process 
that is going on in some parts of North Bengal. 
River erosion takes away thousands of hectares of 
land every year in a country where land is the 
Page 1129ISBN: 978-984-33-2140-4
  
scarcest resource. Earthquakes may cause billions 
of Taka worth of damage. Perhaps the most 
disturbing but ignored fact about disasters is that 
they are all linked to each other. 
 
At times, some areas normally subjected to drought 
situation have got flooded in certain years. Hazards 
like earthquakes, landslides, etc. occur quite 
suddenly but they are restricted in their impact in 
terms of time. The extent of the impact of an 
earthquake depends on its magnitude. Natural 
calamities may be broadly grouped into major and 
minor types depending upon their potential to cause 
damage to human life and property. While natural 
hazards like earthquakes, droughts, floods, 
Tornadoes and cyclones could be regarded as major 
landslides, riverbank erosion, groundwater 
contamination, fires, tsunamis etc., whose impact is 
localized and intensity of the damage is much less 
can be categorized as minor hazards. So far as 
damage to housing and infrastructure is concerned, 
floods, cyclones, tornadoes and earthquakes turn 
out as the four major disasters confronting the 
country.  
 
Considering the major disasters of Bangladesh, 
disaster mitigation is needed and should be 
undertaken. Generally the hazards should be 
evaluated. In particular, the first step in disaster 
mitigation is to recognize the existence of these 
risks. The next step is to quantify the risks and to 
minimize the effects. The total elimination of risks 
may be difficult and impractical. Moreover in 
developing countries like Bangladesh, economic 
considerations usually take precedence over safety 
and engineering design. 
 
Multihazard maps are practical tools in disaster 
mitigation planning, design of structures because 
they provide important guidance when it is not 
feasible to do the hazard assessment at particular 
sites. These maps give a good indication on the area 
extent of expected high risk areas for overall natural 
disaster. The risk score is the indicator of the 
severity of areas affected by overall natural disaster 
situation for a particular area. Intensity scales gives 
the damage severity of disasters. Intensity scales 
are subjective and depend upon social condition 
and construction status of a country, they need 
revising from time to time.  
 
This study will find out the disaster prone areas of 
Bangladesh and also the damages, history, severity 
of these areas, intensities of those natural disasters 
and housing vulnerability. GIS based disaster 
database is very crucial and an important aspect for 
environmental management strategy for planning 
and disaster mitigation, preparedness and 
preventive actions. The information will assist the 
environmental management, different field of 
sciences such as engineering, agriculture, fisheries, 
and policy making and planning of Bangladesh and 
should be an integral part of the whole process of 
economic and social development in Bangladesh. 
The findings of this study would benefit engineers 
and city planners. They constitute a fundamental 
means which should guide officials at the national 
and regional levels in the formulation of 
development strategies in multihazard active zones, 
land use management, revision and enforcement of 
appropriate building codes and formulation of plans 
for mitigating measures against hazard risks 
affecting the region considered. 
 
2. METHODOLOGY 
 
A proper methodology is always necessary for the 
successful completion of a research work. It is 
helpful regarding the organization of the 
experiences, observations, examinations and 
analysis of found data and information and their 
logical interpretation in a systemic process to 
achieve the ultimate goal and the objectives of the 
research.  
 
An extensive survey of all the available and 
relevant literature was made to analyze the findings 
and recommendations from different journals, 
research publications and study reports related with 
this research topic were considered. At the same 
time this tool of literature survey has been used to 
collect secondary data and information also. 
 
Secondary data and information have been 
collected from the census report as well as various 
government, non-government and international 
organizations such as Bangladesh Meteorological 
Department (BMD), SPARRSO, Disaster 
Management Bureau (DMB) and concerned non-
government organizations (NGO). Besides this, 
some information was collected from the CDMP/ 
UNDP projects and web sites of different 
organizations. 
 
2.1 Identify the disaster prone areas for 
multi-hazard with GIS 
The study has been executed exploring the 
historical disaster events, duration and damages 
information, and Geographic Information System 
(GIS). As GIS is a powerful planning tool which 
has been used to identify the disaster prone area in 
Bangladesh, the large amount of disaster data were 
collected from different organizations and sources. 
The zoning maps prepared by different organization 
in different time were also used in this study. 
Further the disaster data and zoning maps were 
analyzed and comparing the data and zoning map, 
Page 1130
  
all the zoning maps were digitized and converted to 
geo-referenced maps separately and then the data 
were converted into GIS and finally superimposed 
to the base map. The location, type, year and 
damages etc were digitized to put the database into 
GIS system. The available historical data gathered 
from different sources for the disaster prone area of 
Bangladesh have been identified through GIS based 
analysis and finally a multi hazard map is prepared 
by using GIS technique. 
 
3. ESTIMATION OF RELATIVE RISK 
SCORE FOR NATURAL HAZARD 
 
Risk Score [for particular hazard e.g. Cyclone(c) / 
Flood (f)/ Tornado (t) / Earthquake (e)] = 
Weighting factor (WT)   
   WT  = ∫(Frequency (fr)) × Risk (R=potential 
damage magnitude) 
     
 TR (c/ f/ t/ e) = WT= f  × R      (1.1) 
 
 For Cyclone:  
R(c)i    (1.2) 
 where i=0, 1, 2, 3, 4 ,5 and w=wind, h=storm 
surge, cp=central pressure 
 
WT(c)j     (1.3) 
 
 where j=1, 2, 3, 4 ,5, 6, 7, 8, 9, 10  
and  =frequency  
 
TR(c)=R(c)i×0.1WT(c)j   (1.4) 
 For Tornado:  
R(t)i     (2.1) 
  
where i=0 and 5 and w=wind 
 
WT(t)j     (2.2) 
 
 where j=1, 2, 3, 4 ,5, 6, 7, 8, 9, 10  
and  =frequency  
 
TR(c)=R(t)i×0.1WT(t)j    (2.3) 
For Flood: 
R(f)i     (3.1) 
  
where i=1, 2, 3, 4 ,5 and hw=water height 
 
WT(f)j     (3.2) 
  
where j=1, 2, 3, 4 ,5, 6, 7, 8, 9, 10  
and  =frequency  
 
TR(c)=R(f)i×0.1WT(f)j    (3.3) 
For Earthquake:                     
R(e)i     (4.1) 
  
where i=2, 3, 4 and m=magnitude, p=peak 
ground acceleration 
 
WT(e)j     (4.2) 
 where j=1, 2, 3, 4 ,5, 6, 7, 8, 9, 10  
and  =frequency  
 
TR(c)=R(e)i×0.1WT(e)j    (4.3) 
Total Risk Score: 
 
TR k   (5.0)  
 
Where, k=1 for cyclone, k=2 for tornado, k=3 
earthquake, k=4 for flood, and k=n disaster.  In 
these equations, two of the hazards have locations 
with a risk score of 0 (Cyclone and Tornado). In 
case of Cyclone, the maximum extent of the hazard 
risk does not realistically include the entire county 
and is limited to proximity to coastal waters. 
Tornado may always have high risk, i.e score 5 for 
all the tornado prone area. For the locations with no 
consideration of risk for Tornado was given a score 
of 0. Again earthquake hazard of Bangladesh was 
expressed as minimum by 2 and as maximum by 4. 
 
The minimum risk score for each of the remaining 
hazards is 1 since there is some potential that each 
of these hazards could occur anywhere throughout 
the county. This scoring system has been used 
according to our district-based database. For 
particular district of Bangladesh the hazard for 
Earthquake, Tornado, Cyclone and Flood is 
calculated. Then adding those scores, then the total 
risk score for each of the 64 districts was 
determined. 
 
 
 
Page 1131
  
Table 1. Proposed Risk Score 
 
SL. 
No. 
District  Name  Risk Score/Disaster Type Total Risk Score 
Tornado Earthquake Cyclone Flood 
1. Dhaka 9.0 4.8 0.0 7.6 21.4 
2. Narayanganj 5.5 4.4 0.0 7.6 17.5 
3. Munshiganj 6.0 4.8 0.0 7.2 18 
4. Narsingdi 1.0 6.0 0.0 7.6 14.6 
5. Manikganj 7.0 5.2 0.0 7.6 19.8 
6. Gazipur 7.0 6.5 0.0 5.7 19.2 
7. Mymensingh 9.0 7.0 0.0 6.0 22 
8. Kishoreganj 7.5 7.0 0.0 8.0 22.5 
9. Jamalpur 7.0 8.5 0.0 8.0 23.5 
10. Sherpur 5.5 8.5 0.0 5.7 19.7 
11. Netrokona 5.5 8.5 0.0 5.7 19.7 
12. Tangail 6.0 7.0 0.0 8.0 21 
13. Faridpur 7.5 4.8 0.0 7.6 19.9 
14. Madaripur 5.5 4.4 1.0 7.6 18.5 
15. Shariatpur 6.5 4.4 1.0 7.6 19.5 
16. Rajbari 5.5 5.2 0.0 7.6 18.3 
17. Gopalganj 6.5 3.3 1.0 5.7 16.5 
18. Chittagong 5.5 5.2 9.0 7.2 26.9 
19. Rangmati 1.0 6.5 1.0 1.4 9.9 
20. Cox’s bazar 5.5 6.5 8.5 6.4 26.9 
21. Bandaban 1.0 6.5 1.0 6.0 14.5 
22. Khgrachari 1.0 6.0 1.0 1.0 9.0 
23. Noakhali 8.0 4.4 7.5 5.1 25 
24. Lakshmipur 5.5 4.4 5.0 7.2 22.1 
25. Feni 5.5 4.4 5.5 5.1 20.5 
26. Comilla 7.0 4.8 1.1 7.2 20.1 
27. Chandpur 5.5 4.8 1.1 8.0 19.4 
28. Brahmanbaria 1.0 6.0 0.0 7.6 14.6 
29. Rajshahi 5.5 4.8 0.0 7.2 17.5 
30. Nawabganj 1.0 4.4 0.0 7.2 12.6 
31. Natore 1.0 5.2 0.0 7.6 13.8 
32. Naogaon 1.0 4.8 0.0 7.6 13.4 
33. Pabana 6.0 5.2 0.0 7.6 18.8 
34. Sirajganj 7.0 6.5 0.0 7.6 21.1 
35. Bogra 5.5 7.0 0.0 7.6 20.1 
36. Joypurhat 1.0 6.5 0.0 4.8 12.3 
37. Rangpur 6.0 6.5 0.0 7.6 20.1 
38. Kurigram 5.5 8.0 0.0 8.0 21.5 
39. Nilphamari 6.0 5.5 0.0 7.2 18.7 
40. Lalmonirhat 6.0 7.0 0.0 5.1 18.1 
41. Gaibandha 7.0 7.5 0.0 7.6 22.1 
42. Dinajpur 1.0 4.4 0.0 6.4 11.8 
43. Thakurgoan 1.0 5.5 0.0 1.4 7.9 
44. Panchagarh 5.5 5.5 0.0 1.5 12.5 
45. Khulna 6.5 3.3 7.5 1.0 18.3 
46. Bagerhat 6.0 3.3 6.0 1.6 16.9 
47. Satkhira 1 3.3 6.0 1.4 11.7 
48. Jessore 6.0 3.3 0.0 1.4 10.7 
49. Magura 6.0 4.8 0.0 5.4 16.2 
50. Jhenaidah 1 4.4 0.0 1.0 6.4 
51. Narail 7.0 3.6 0.0 3.8 14.4 
52. kushtia 6.0 4.8 0.0 6.0 16.8 
53. Meherpur 5.5 4.8 0.0 1.4 11.7 
54. Chuadanga 1 4.4 0.0 4.2 9.6 
55. Barishal 6.5 3.3 8.0 7.6 25.4 
56. Jhalkati 1 3.3 1.0 1.4 6.7 
57. Pirojpur 5.5 3.3 1.0 3.0 12.8 
58. Potualkali 1 3.3 6.5 1.0 11.8 
59. Barguna 1 3.3 5.5 1.5 11.3 
60. Bhola 6.0 3.3 6.0 5.1 20.4 
61. Sylhet 1 8.0 0.0 8.0 17 
62. Sunamganj 1 8.0 0.0 8.0 17 
63. Habiganj 1 7.0 0.0 8.0 16 
64. Moulvibazar 5.5 8.0 0.0 6.0 19.5 
 
Page 1132
  
 
4. DISTRICT WISE RISK SCORES 
 
Total Risk Scores for four individual hazards 
(Tornado, Earthquake, Cyclone and Flood) for 
each of 64 districts were estimated following the 
above methods. Table 1 summarizes the total risk 
scores for individual Districts of Bangladesh. This 
table is calculated by the summation of four 
individual hazard score calculated by using Eq. 
1.1-5. For Dhaka district Total Score for Tornado, 
Earthquake, Cyclone and Flood are respectively 
9.0, 4.8, 0.0 and 7.6. So the total risk score for 
Dhaka district is 21.4. Similarly total risk score 
for others districts were calculated. 
 
From the proposed risk score, a district risk-
ranking map for Bangladesh is proposed which is 
shown in Figure 1. This map indicates the risky 
districts of Bangladesh for multi hazard (Cyclone, 
Flood, Tornado and Earthquake) which also 
shows risk scenario of Bangladesh at a glance.  
 
The risk areas were combined and the scores were 
added together to create summary scores for every 
location in the county. These summary scores 
were used to develop a summary risk area map. 
The summary scores also provide the foundation 
for ranking high-risk areas in the remainder of the 
assessment. The ranking of the risk scores are 
categorized in the Table 2. From the Table 1 and 
2 the hazard index for all districts of Bangladesh 
were categorized by total risk score of different 
districts of Bangladesh for different hazards like 
tornado, flood, cyclone and earthquake shown in 
the Table 3. 
 
5. RESULT AND DISCUSSION  
 
To develop a multi-hazard map of Bangladesh 
based on a recently compiled disaster database, . 
Tornado, Earthquake, Flood and Cyclone 
zonation data were considered and the data base 
was updated 
 
5.1 Development of individual hazard 
map  
The prime objective of this study is to identify the 
vulnerable areas with reference to natural hazards 
causing damage to the housing stock for 
earthquakes, cyclones, tornadoes and floods. Due 
to that for a basic requirement a complete 
database of those natural hazards were prepared 
for this study. Different intensity scales for these 
disasters were also reviewed. The GIS maps of 
earthquake, cyclone, tornado and flood hazards 
were developed and these data were used to 
Table 3. Explanation of the multi hazard zonation map 
                    (for Chittagong Division) 
 
SN. Code Explanation 
1. Z(TP_EZ2_CHR_FM) Zone: Tornado Prone Area 
           Earthquake Zone 2=0.15g 
           Cyclone High Risk Area 
           Moderate Flooding Area 
2. Z(TP_EZ2_CHR_FL) Zone: Tornado Prone Area 
           Earthquake Zone 2=0.15g 
           Cyclone High Risk Area 
           Low Flooding Area 
3. Z(TP_EZ2_CHR_FN) Zone: Tornado Prone Area 
           Earthquake Zone 2=0.15g 
           Cyclone High Risk Area 
           Non Flood Affected Area 
4. Z(TP_EZ2_CR_FS) Zone: Tornado Prone Area 
           Earthquake Zone 2=0.15g 
           Cyclone Risk Area 
           Severe Flooding Area 
5. Z(TP_EZ2_CR_FM) Zone: Tornado Prone Area 
           Earthquake Zone 2=0.15g 
           Cyclone Risk Area 
           Moderate Flooding Area 
6. Z(TP_EZ2_CR_FL) Zone: Tornado Prone Area 
           Earthquake Zone 2=0.15g 
           Cyclone Risk Area 
           Low Flooding Area 
7. Z(TP_EZ2_CR_FN) Zone: Tornado Prone Area 
           Earthquake Zone 2=0.15g 
           Cyclone Risk Area 
           Non Flood Affected Area 
8. Z(TP_EZ2_CW_FS) Zone: Tornado Prone Area 
           Earthquake Zone 2=0.15g 
           High Wind Area 
           Severe Flooding Area 
9. Z(TP_EZ2_CW_FM) Zone: Tornado Prone Area 
           Earthquake Zone 2=0.15g 
           High Wind Area 
           Moderate Flooding Area 
10. Z(TP_EZ2_CW_FL) Zone: Tornado Prone Area 
           Earthquake Zone 2=0.15g 
           High Wind Area 
           Low Flooding Area 
Table 2. Hazard index and risk score 
 
SN HI TRS Hazardous Districts 
1. High 20-30 Dhaka, Bogra, Sirajganj, Feni, 
Comilla, Cox’s bazaar, Lakshmipur, 
Noakhali, Chittagong, Tangail, 
Mymensingh, Kishoreganj, Jamalpur, 
Rangpur, Bhola, Barishal, Kurigram, 
Gaibandha 
2. Modera
te 
10-20 Sylhet, Gazipur, Manikganj, 
Narsingdi, Narayanganj, Munshiganj, 
Netrokona, Sherpur, Gopalganj, 
Rajbari, Shariatpur, Madaripur, 
Sunamganj, Pabana, Bandaban, 
Faridpur, Naogaon, Natore, 
Nawabganj, Rajshahi, Brahmanbaria, 
Joypurhat, Chandpur, Lalmonirhat, 
Nilphamari, Dinajpur, Magura, 
Khulna, Satkhira, Bagerhat, Jessore, 
Panchagarh, Meherpur, kushtia, 
Habiganj, Narail, Moulvibazar, 
Potualkali, Pirojpur, Borguna. 
3. Low 1-10 Jhalkati, Chuadanga, Rangmati, 
Thakurgoan, Khgrachari, Jhenaidah 
            HI:Hazard Index, TRS=Total Risk Score 
Page 1133
  
vulnerability risk analysis of Bangladesh, wherein 
the risk score was tabulated for different districts of 
Bangladesh which is not shown in this paper.  
 
5.2 Development of multi-hazard map 
The district of Bangladesh was subdivided in to 
three risk areas based on risk score (shown in Table 
2). The districts of Dhaka, Bogra, Sirajganj, Feni, 
Comilla, Cox’s bazaar, Lakshmipur, Noakhali, 
Chittagong, Tangail, Mymensingh, Kishoreganj, 
Jamalpur, Rangpur, Bhola, Barishal, Kurigram, 
Gaibandha show the high risk score while Jhalkati, 
Chuadanga, Rangmati, Thakurgoan, Khgrachari, 
Jhenaidah district show the total low score and 
remaining districts show the moderate total score 
(shown in Fig. 1). By using the risk score and 
different individual maps for different hazard 
(Cyclone, Flood, Tornado and Earthquake), a 
zonation map for different degrees of risks for 
Tornado, earth quake, high wind velocity and flood 
was developed and which is proposed as a multi-
hazard map (shown in Fig. 2). Legend of the map 
for Chittagong divisions is only shown in this 
Figure among the 60 different combinations for 6 
divisions. This multihazard map can be used by 
policy makers to take decision for disaster 
management and preparedness. From this map one 
can easily identify the hazard area with the hazard 
type and intensity. This map will be easily 
comprehensible to everybody.  
 
The probabilities of occurrence for different 
disasters were not considered in the risk score 
assessment. The probabilities of occurrence of 
different disaster of same time duration make this 
risk score assessment more reliable. 
Model-GIS interface and Digital Elevation Models 
(DEM) are widely used to assess risk and 
development of floodplain zoning maps all over the 
world. The main constraint to develop such maps in 
Bangladesh is that the topographic and land 
elevation data are very old (Karim 2004). 
 
6. CONCLUSIONS  
 
The research findings are crucial and an important 
aspect for management strategy for planning and 
disaster mitigation, preparedness and preventive 
actions. The information will assist the 
environmental management, different field of 
sciences such as engineering and policy making and 
planning of Bangladesh and should be an integral 
part of the whole process of socio-economic 
development in Bangladesh. 
 
REFERENCES 
 
1. Islam, M. M. and Sado, K. (2002). 
Development priority map for flood counter 
measure by remote sensing data with 
geographical information system, Journal of 
Hydrologic Engineering, JSCE, 7(5), 346-355. 
2. IAEE (1981). A manual of earthquake resistant 
non-engineered construction, International 
Association of Earthquake Engineering. 
3.  Karim, A. K. M (1996). Formation of planning 
and land-use policies for disaster management 
in Chittagong metropolitan area of Bangladesh, 
UNCRD-BUET joint research, Department of 
Urban and Regional Planning, BUET, 
Bangladesh. 
 
 
Fig. 2: Proposed Multi Hazard Zonation Map 
of Bangladesh (legend is only for Chittagong 
Division according to Table 3) 
 
 
                 Fig. 1: Multi hazard map 
Page 1134
Proceedings of the
Conference on Engineering Research, Innovation and Education 2011
CERIE 2011, 11-13 January 2011, Sylhet, Bangladesh
* Corresponding Author: Md. Imran Kabir, 
E-mail: imran-cee@sust.edu; imran_kabir_ce@yahoo.com
SIMULATION OF THE BREAKTHROUGH CURVE FOR THE 
REMOVAL OF METHYLENE BLUE FROM WASTEWATER BY 
ACTIVATED CARBON OF Bombax Ceiba
Ahmad Hasan Nury and Md. Imran Kabir*
Department of Civil and Environmental Engineering, 
Shahjalal University of Science and Technology, Sylhet, Bangladesh
Computer simulation is necessary while the performance of dynamic experiments is not feasible. In this 
study, a breakthrough curve was formulated for the removal criteria of Bombax Ceiba over Methylene Blue. 
The performance of packed bed adsorbent (activated carbon of Bombax Ceiba) was discussed by the 
breakthrough curve. Concentration, time interval, volumetric water content, dispersivity, distribution 
coefficient, retardation factor, flux density, bulk density and depth increment were chosen in account as the 
simulation parameters. Both batch and column studies were done. In column, after comparing the simulated 
breakthrough curve with experimented one, the effluent concentration was found zero after 120min, 180min 
and 270min for the adsorbent bed 15cm, 20cm and 25cm respectively. Admittedly, the breakpoint time for 
15-, 20 and 25cm were nearly at 158-, 169 and 198min accordingly whereas the respective bed exhaustion 
time were 270min, 360min and 420min. Finally, satisfactory fitness of the simulated breakthrough curve 
with the experimented one was found. 
Key Words: Simulation, Adsorption, breakthrough curve, Methylene Blue, Wood charcoal of Bombax ceiba
1. INTRODUCTION
Water pollution due to colour from dyestuff 
industries is a topic of major concern of scientists 
today. Many industries use dyes extensively in 
different operations such as textile, paper, plastic, 
leather tanning etc. Dyes exhibit considerable 
structural diversity (Vnekatraman Hase and 
Raymahasahay Gode, 1975). Dyes are commonly 
found in trace quantities at industrial scale and in 
industrial effluents. It is a fact that due to their 
visibility, dyes are recognized easily even at the 
levels as less as 1ppm (S. Mohan, 2007). The 
discharge of color waste is not only damaging the 
aesthetic nature of receiving streams but also wide-
spreading toxicity to aquatic life (Rouse, R.D., 
1979). In addition, color interferes with the 
transmission of sunlight into the stream and 
therefore reduces photosynthetic action. Toxicity of 
dyes to fauna and flora is well documented 
(Ghoreishi and S.M. Haghighi, 2003). Dyes also 
inhibit several biological processes. Colour of 
textile effluents escalates environmental problem 
mainly because of its non-biodegradable 
characteristics (Yusuff. R.O., Sonibare, J.A., 2005). 
The removal of dye in an economic fashion remains 
an important problem. Considerable work has been 
carried out on the removal of dye from wastewater 
adsorption, coagulation, flocculation, oxidation, 
precipitation filtration, electrochemical processes, 
etc are the common techniques reported for the 
removal of dyes from effluents (Howard S. Peavy 
and Donald R Rowe, 1985). Chemical methods of 
dye removal accumulate sludge that can create 
disposal problems. These methods require 
chemicals and require large amount of electrical 
energy which further poses problems for 
environment.  Processes such as membrane 
separation, coagulation and ion exchange are also 
used for the removal of color from dye wastewater, 
but the cost of the process is the main drawback of 
these techniques. Amongst the techniques, 
adsorption seems to be one of the most effective 
methods because of simple operation and easy 
handling (Metcalf & Eddy, 1999). Different 
adsorbents such as zeolite, perlite, benotite, kaolite, 
rice husk, maize cob, coconut coir, bagasse pith, 
etc. have been employed for removal of dyes from 
effluents. 
The purpose of the study was to remove Methylene 
Blue from aqueous solution using wood charcoal of 
Bombax Ceiba. Wood charcoal adsorption 
treatment has been proven to be an effective 
replacement for the combined biological and 
chemical treatment (F.K.Bangash and A.Manaf, 
ISBN: 978-984-33-2140-4
Page 1135
2005). The performance of wood charcoal 
treatment process depends on the type of charcoal 
and the characteristic of the wastewater in addition 
to the operating conditions.
By interfacing a process simulation, a realistic 
environment can be created without the cost. It can 
be used to predict the behavior of the process under 
different conditions.
2. METHODOLOGY
To disaggregate the wood material, the collected 
Bombax Ceiba was boiled at 100°C in a 10% 
Phosphoric acid (H3PO4) for 1h. After the pre-
treatment, the solution was kept at room 
temperature for 24h and also burned afterward at 
400°C as well as crushed and passed through 
0.6µm sieve to get the activated carbon from the 
wood charcoal (F.K.Bangash and A.Manaf, 2005).
Batch study was performed in five 250ml stopper 
bottles to determine the equilibrium adsorption 
parameters. In each bottle 200ml of dye sample of 
five different concentrations, such as 1-, 2-, 3-, 4 
and 5mg/l was poured. A fixed amount of adsorbent 
is added to each solution. The samples are then 
shaken with a flask shaker at 450 osc for 8-10 hrs. 
Within this time the system reaches equilibrium. 
The solutions are then centrifuged for 10-15min to 
settle down the adsorbent. The dye solution is then 
separated and the concentration of the solution is 
determined with UV-vis spectrophotometer at 
455nm wavelength (C.J. Geankoplis, 1999). 
The Langmuir adsorption isotherm (B.S. Bahl, 
G.D.Tuli and Arun Bahl, 2005-06) for solid-liquid 
adsorption system is represented by the following 
equation:
where, qe is the adsorption density at equilibrium 
(Kg adsorbate/Kg adsorbent), Ce is the equilibrium 
concentration of the adsorbate in the solution 
(Kg/m3), q∞ is the adsorption capacity (Kg 
adsorbate/Kg adsorbent) and K is an empirical 
constant (m3/Kg).
Fixed bed column studies were conducted in a glass 
cylindrical column. The column was designed with 
an internal diameter of 6.5 cm and 45 cm in length.
The column was packed with adsorbent between 
two supporting layers of glass wool. The dye 
(methylene blue) containing wastewater was passed 
through column in down flow mode.  The samples 
were collected at certain time intervals and the 
concentration of dye was determined 
spectrophotometrically by monitoring of the 
absorbance at 455 nm. Schematic diagram for the 
experimental procedure are shown in Fig. 1.
Fig. 1: Schematic diagram for experimental method 
to treat colored water
Considering a sorbing chemical is being moved 
through a homogeneous medium at a study, 
uniform flow rate, the transport equation (Bhabani 
S. Das, 1998) can be written as
where, c = volume averaged concentration, s = 
amount of solute adsorbed, D = dispersion 
coefficient, v = pore water velocity,  θ = volumetric 
water content, ρ = bulk density, x = distance and t = 
time. The first term represents accumulation of 
solute in the liquid. The second term in the left 
hand side of the equation describes the chemical 
interaction. The third term represents axial 
dispersion of solute in the bed, which leads to 
mixing of the solute and solvent. Last term of the 
equation is the amount of solute flowing in by 
convection to the section of the bed minus that 
flowing out. The equation can be rearranged to 
yield as
where, R is the retardation factor, . As 
seen, R(c) can be explicitly written if a relationship 
between s and c, called the sorption isotherm is 
available. For brevity, a detailed description of the 
sorption isotherm will be presented in the following 
section. A general relationship that combines an isotherm function Г, describing sorption to a homogeneous surface at the stoichiometric level and a weighing function ω, describing the effects of site specific binding is written as
Page 1136
where, ST is the total amount of sorption sites and ξ 
is an affinity coefficient (Kouichi Miura and Kenji 
Hashimoto, 1977). Various isotherms for sorption 
are then derived by choosing appropriate functional 
forms for Г and ω. For example a generalized 
Langmuir-Freundlich isotherm, is 
derived by choosing 
and
where k and α are constants. The retardation factor 
thus can be written as
Thus the governing equation in the tri-diagonal 
form can be shown as
For i = 1 and i = m, the above equation can be 
written as follows
where, ρ is bulk density, KF is distribution 
coefficient, θ is volumetric water content, D is
dispersivity and v is the flux density.
Bed height of 15cm, 20cm and 25cm; initial 
concentration of 10ppm and 15ppm; amount of 
adsorbent of 80gm, 120gm and 160gm; temperature 
of 26±2°C; pH of 6.8 as well as the flow rate of 
25ml/min and 30 ml/min were used for this study. 
For simulation, Pascal Programming software was 
used. The variables are bed height (15cm, 20cm 
and 25cm), initial concentration of the dye solution 
(10mg/l, and 15mg/l) and flow rate (25ml/min and 
30ml/min). The system considered was an 
isothermal adsorption column packed with porous 
adsorbent (wood charcoal of Bombax ceiba). The 
simulated breakthrough curve was drawn from the 
output of the simulation and compared with the 
experimental breakthrough curve. The used 
parameters are given in Table 1.
Table 1: Parameters used in the simulation
Parameter value
Volumetric water content 0.5
Dispersivity, cm 0.5
Distribution coefficient 2.0
Time interval, min 30
Flux density, cm/h 5.0/24.0
Bulk density, g/cm3 1.2
Alpha 0.8
Omega 20
3. RESULTS AND DISCUSSION
The comparison between the simulated and
experimental breakthrough curve are given in Fig.
2.
Fig. 2: Comparison between the simulated and 
experimental breakthrough curve
Page 1137
From the above figures, it is clearly seen that 
relative concentrations are zero up to 120min, 
180min and 270min respectively. This is because 
initially the solutes are adsorbed by pore space of 
adsorbent. After this time the concentration rise 
slowly up to 157.5min, 168.9min and 198.3min for 
15cm, 20cm and 25cm bed height respectively 
which is called the break point. Most of the bed 
capacity is used at the break point. This point is the 
level of permissible limit of water parameter. It 
increases at higher bed height. Because pores take 
more time to adjust for higher bed depth. After the 
break point time is reached, the outlet concentration 
rises very rapidly up to point of bed exhaustion. 
This is because particles were adjusted and the 
pores between the particles reduced to adsorb. The 
bed exhaustion time for 15cm, 20cm and 25cm bed 
are 270min, 360min and 420min respectively. At 
bed exhaustion time the bed is considered as 
ineffective.
4. CONCLUSION
Comparing simulated breakthrough curve with 
experimental breakthrough curve of bed height 15 
cm (initial concentration 15mg/l and 25 ml/min), it 
is seen that for both curve relative concentrations 
are zero up to 120min, breakpoint time is 157.5min 
and the bed exhaustion time  for simulated & 
experimental breakthrough curve are 270min & 
300min respectively. For simulated & experimental 
breakthrough curve of bed height 20 cm (initial 
concentration 10mg/l and 25 ml/min),  relative 
concentrations are zero up to 180min, breakpoint 
time is 168.9min and bed exhaustion time is 
360min. For simulated & experimental 
breakthrough curve of bed height 25 cm (initial 
concentration 10mg/l and 30 ml/min) relative 
concentrations are zero up to 270min, breakpoint 
time is 198.3min and bed exhaustion time is 
420min. So the agreement between the 
experimental and the simulated breakthrough 
curves appear to be satisfactory since the simulated 
results obtained agreed with the experimental 
results. The simulated breakthrough curve will be 
helpful to design the adsorption column for dye 
removal operation.
REFERENCES
1. Bahl, B.S., Tuli, G.D. and Bahl, A., Essentials 
of physical chemistry (2005-2006), S. Chand & 
Company Ltd., India.
2. Bangash, F.K. and Manaf, A. (2005), Dyes 
removal from aqueous solution using wood 
charcoal, Journal of the Chinese Chemical 
Society, 52, pp. 489-494
3. Bhabani S. Das, An implicit finite difference 
scheme for a convection dispersion equation 
with the nonlinear and equilibrium sorption 
isotherm (1998), Birla Institute of Technology 
& Science, India.
4. Geankoplis, C.J., Transport Processes and Unit 
Operations, Third edition, (1999), Prentice-
Hall of India, New Delhi, India.
5. Ghoreishi, S. and Haghighi, M. (2003), 
Chemical Catalytic Reaction and biological 
Oxidation for Treatment of non-biodegradable 
Textile Effluent, Chemical Engineering 
Journal, 95, pp. 163-169
6. Hase, V. and Gode, R. (1975), Adsorptive 
removal of a basic dye from water and
wastewater by activated carbon, Journal of 
Applied Science in Environmental Sanitation, 
4(1), pp. 21-28
7. Metcalf and Eddy, Wastewater Engineering, 
Third edition (1999), Tata McGraw-Hill 
Publishing Company Limited, New Delhi, 
India.
8. Miura, K. and Hashimoto, K. (1977), 
Analytical solutions for the breakthrough 
curves of fixed bed adsorbers under constant 
pattern and linear driving force 
approximations, Journal of Chemical 
Engineering of Japan, 10(6), pp. 490-493
9. Mohan, S. (2007), Adsorptive removal of 
reactive and direct dyes using non conventional 
adsorbent column studies, Journal of Scientific 
and Industrial Research, 68, pp. 894-899
10. Peavy, H.S. and Rowe, D.R., Environmental 
Engineering (1985), McGraw-hill international 
editions.
11. Rouse, R.D. (1979), Water quality 
management in pond fish culture, Research 
and Development Series, 22, project: 
AID/DSAN-G 0039, Auburn University, 
Alabama, USA.
12. Yusuff, R.O. and Sonibare, J.A., (2005), 
Characterization of textile industries effluents 
in Kaduna, Nigeria and pollution implications,
Global Nest: the Int. J., 6(3), pp. 212-221
Page 1134
Page 1138
